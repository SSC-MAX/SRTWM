[
    {
        "original_text": "We present results on the composition of the eta-prime meson in terms of quarks and gluons, obtained by applying the QCD sum rule method to the correlation function of two pseudoscalars with different flavors.  We find that the eta prime is dominantly composed of strange quark pairs (ss) at low energies but becomes more nonstrange as energy increases. The mass difference between the eta and eta prime mesons can be explained if we assume that the eta prime contains an additional ss pair compared to the eta. This result supports our previous finding based on the analysis of the decay widths of these mesons into pions and kaons. \nPACS numbers: 11.10.Kk, 12.38.Gc, 13 .60.Hb  PACS number(s): 11.10.Kn, 12.38.Bx, 13 .60.Jz",
        "watermark_text": "We present results on the composition of the eta - prime meson in terms of quarks and gluons , obtained by using the QCD sum rule method to the correlation function of two pseudoscalars with varying flavors . We see that the eta prime is dominantly composed of odd quark combinations ( ss ) at low energies but gets more nonstrange as energy rises .The mass ratio between the eta and eta prime mesons can be described if we suppose that the eta prime forms an additional ss pair relative to the eta . This result confirms our previous finding based on the examination of the decay widths of these mesons into pions and kaons .PACS codes : 11 . 10 . Kk , 12 . 38 . Gc , 13 . 60 . Hb PACS number ( s ) : 11 . 10 . Kn , 12 . 38 . Bx , 13 . 60 . Jz",
        "rewrite_text": "We present findings regarding the quark and gluon composition of the eta-prime meson, derived using the QCD sum rule method applied to the correlation function of two pseudoscalars with different flavors. Our results indicate that at low energies, the eta-prime meson is primarily made up of odd quark combinations (ss), but as energy increases, its composition becomes more nonstrange. To explain the mass ratio between the eta and eta-prime mesons, we propose that the eta-prime forms an additional ss pair in relation to the eta. This observation aligns with our previous analysis, which assessed the decay widths of these mesons into pions and kaons. PACS codes: 11.10.Kk, 12.38.Gc, 13.60.Hb. PACS numbers: 11.10.Kn, 12.38.Bx, 13.60.Jz.",
        "ori-fast-z-score": -0.9258200997725514,
        "water-fast-z-score": 3.7032803990902057,
        "rewrite-fast-z-score": 0.9045340337332909
    },
    {
        "original_text": "The Large Area Telescope (LAT) on the Fermi Gamma-ray Space Telescope will be launched in June 2008, with an expected launch date of August 7, 2007.  The LAT is designed to detect gamma rays between 20 MeV and 300 GeV over a large field-of-view (2 steradians), making it possible for the first time to study the entire sky at these energies every three hours. This talk will discuss how supernova remnants are likely to appear as sources of high-energy emission when observed by this new instrument. In particular I will focus on:  - How many remnants should we expect to see? - What types of remnants might show up? - What can we learn about particle acceleration mechanisms? - What can we do to prepare for the observations? - Other topics that may come up during discussion. The Large Area Telescope (L AT ) on the Fermi Gamma-ray Sp ace T elescope w ill b e la unched i n J une 2 008 , wi th an ex pected l aunch d ate o f A ugust 7 , 2 007 .",
        "watermark_text": "The Large Area Telescope ( LAT ) on the Fermi Gamma - ray Space Telescope will be launched in June 2008 , with an anticipated flight date of August 7 , 2007 . The LAT is designed to identify gamma radiation between 20 MeV and 300 GeV over a large field - of - view ( 2 steradians ) , making it able for the first time to study the entire sky at these frequencies every three years .This discussion will explore how supernova remnants are likely to appear as causes of high - energy emission when observed by this new instrument . In particular I will focus on : - How many ruins should we expect to see ?- What kinds of remnants may show up ? - What can we find about particle particle processes ?- What can we do to organize for the discoveries ? - Other topics that might come up during discussion .The Large Area Telescope ( L AT ) on the Fermi Gamma - ray Sp ace T elescope l ill b e la unched i n J une 2 008 , wi th an Ex pected w aunch d ate o g A ugust 7 , 2 007 .",
        "rewrite_text": "The Large Area Telescope (LAT) aboard the Fermi Gamma-ray Space Telescope is set to be launched in June 2008, with a targeted launch date of August 7, 2007. The LAT is engineered to detect gamma radiation ranging from 20 MeV to 300 GeV across a vast field of view (2 steradians). This capability allows it to observe the entire sky at these frequencies every three years for the first time. This discussion will investigate how supernova remnants are likely to be associated with high-energy emissions observed by this innovative instrument. Specifically, I will focus on several key questions: - How many remnants should we expect to observe? - What types of remnants are likely to be detected? - What insights can we gain regarding particle interactions? - How can we prepare for these discoveries? - Additional topics that may arise during our discussion.",
        "ori-fast-z-score": 1.5882027766319677,
        "water-fast-z-score": 6.893123494842633,
        "rewrite-fast-z-score": 2.626128657194451
    },
    {
        "original_text": "We present an efficient computational method to compute the elastic properties, vibrational frequencies and normal modes of proteins using finite element analysis (FEA). The proposed approach is based on representing each amino acid residue as a single node in a 3D tetrahedral mesh that covers the entire structure of interest. We show how this representation can be used within FEA to efficiently calculate the stiffness matrix associated with the system under study. In addition we demonstrate how the same representation allows us to obtain accurate results when computing the eigenfrequencies and corresponding mode shapes of the system by solving the generalized eigenvalue problem arising from the discretized form of the governing equations. Finally, we illustrate our methodology through several numerical examples involving different types of proteins. Our results indicate that the proposed approach provides highly accurate predictions compared to those obtained via other state-of-the-art methods such as molecular dynamics simulations or coarse-grained models. This work was supported by NSERC Discovery Grants RGPIN-2014-04567 and RGPIN-2016-05189 .",
        "watermark_text": "We introduce an efficient numerical technique to compute the elastic properties , vibrational speeds and normal mechanisms of proteins using finite element assessment ( FEA ) . The proposed approach is based on representing each amino residue compound as a single node in a 3D tetrahedral mesh that covers the entire structure of interest .We see how this representation can be used within FEA to easily calculate the stiffness matrix associated with the system under research . In addition we prove how the same representation enables us to obtain precise conclusions when computing the eigenfrequencies and corresponding mode shapes of the system by handling the generalized eigenvalue problem emerging from the discretized form of the governing equations .Finally , we explain our technique through several mathematical examples involving varying kinds of proteins . Our results show that the suggested approach offers highly precise predictions compared to those achieved via other state - of - the - art methods such as protein behavior simulations or fine - grained estimates .This project was supported by NSERC Discovery Grants RGPIN - 2014 - 04567 and RGPIN - 2016 - 05189 .",
        "rewrite_text": "We present a highly efficient numerical method for determining the elastic properties, vibrational speeds, and normal modes of proteins through finite element analysis (FEA). This innovative approach involves modeling each amino acid residue as a single node within a three-dimensional tetrahedral mesh that encompasses the entire structure of interest. We demonstrate how this representation facilitates the straightforward calculation of the stiffness matrix for the system under investigation. Furthermore, we illustrate that this same representation allows for accurate determination of the eigenfrequencies and corresponding mode shapes by addressing the generalized eigenvalue problem derived from the discretized governing equations. Finally, we elucidate our technique with various mathematical examples involving different types of proteins. Our findings indicate that the proposed method yields highly accurate predictions compared to other advanced techniques, such as protein behavior simulations and fine-grained estimates. This project has received support from NSERC Discovery Grants RGPIN-2014-04567 and RGPIN-2016-05189.",
        "ori-fast-z-score": -1.091089451179962,
        "water-fast-z-score": 5.965587590013045,
        "rewrite-fast-z-score": 0.45291081365783825
    },
    {
        "original_text": "The statistical mechanics of time-independent non-dissipative nonequilibrium states is studied in the framework of generalized entropy production and fluctuation theorem. The main results are formulated for systems with discrete energy levels, but they can be extended to continuous spectrum as well. It is shown that the probability distribution function (PDF) of the total entropy production has an exponential tail at large values of entropy production. This result agrees with recent experimental data on PDFs of heat fluxes between two reservoirs connected by a single molecule junction. In addition it is demonstrated how this approach allows one to calculate the average value of the total entropy production and its fluctuations. Finally we discuss possible applications of these results to transport phenomena in molecular junctions. We show that our theory predicts correctly the dependence of the current-voltage characteristics on temperature difference between the leads. Statistical mechanics of time independent non-dissipative non-equilibrium states is studied within the framework of generalized entropy-production and fluctuation theorem. Main results are formulated for systems having discrete energy-levels, however extension to continuum spectra is also discussed. It is shown that probability-distribution-function (PDF) of total entropy-production has exponential tails at large values of entropy-production. This result agrees with recently obtained experimental data on PDF s of heat-fluxes between two reservoirs coupled via a single-molecule-junction. In addition it is shown how this approach allows us to calculate the average-value of total entropy-production and it s fluctuations. Finally we discuss possibilities of applying these results to transport phenomena occurring in molecular junctions.",
        "watermark_text": "The statistical mechanics of time - independent non - dissipative nonequilibrium states is studied in the framework of generalized entropy production and fluctuation theorem . The main results are formulated for models with discrete energy levels , but they can be applied to continuous spectrum as also .It is demonstrated that the probability distribution relation ( PDF ) of the total entropy production has an exponential tail at large values of entropy production . This result agrees with recent experimental evidence on PDFs of thermal fluxes between two basins connected by a single molecule interchange .In addition it is demonstrated how this methodology allows one to estimate the average value of the total entropy production and its fluctuations . Finally we explain possible use of these results to transport phenomena in molecular junctions .We see that our theory predicts correctly the relationship of the current - electrical properties on temperature difference between the leads . Statistical mechanics of time independent non - dissipative non - equilibrium states is studied within the framework of generalized entropy - production and fluctuation principle .Main findings are formulated for models having discrete energy - rates , however application to continuum spectra is also discussed . It is seen that probability - distribution - function ( PDF ) of gross entropy - production has exponential tails at large values of entropy - production .This result agrees with recently obtained experimental evidence on PDF s of temperature - fluxes between two basins coupled via a single - atom - junction . In addition it is demonstrated how this methodology allows us to estimate the average - value of gross entropy - production and it s fluctuations .Finally we explain options of using these results to transport phenomena occurring in molecular junctions .",
        "rewrite_text": "The study of the statistical mechanics of time-independent, non-dissipative nonequilibrium states is conducted through the lens of generalized entropy production and the fluctuation theorem. While the primary findings are centered on models with discrete energy levels, these results can also be extended to continuous spectra. It is shown that the probability distribution function (PDF) of total entropy production exhibits an exponential tail for large entropy production values. This finding is consistent with recent experimental observations regarding the PDFs of thermal fluxes in systems connected by a single molecular interchange. Furthermore, the methodology provides a way to estimate both the average total entropy production and its fluctuations. Finally, we discuss potential applications of these findings in the context of transport phenomena in molecular junctions, illustrating that our theory accurately predicts the relationship between current and electrical properties as a function of temperature differences between the leads.",
        "ori-fast-z-score": 1.8347785189881796,
        "water-fast-z-score": 8.30018853827986,
        "rewrite-fast-z-score": 1.4142135623730951
    },
    {
        "original_text": "We report the itinerant-to-localized crossover of 5f electrons in an antiferromagnetically ordered and superconducting compound, UPd2Al3 (Tc = 3 K). The temperature dependence of electrical resistivity shows that the system undergoes a metal-insulator-like transition at TMI ~ 50 K with a large residual resistance ratio RRR = 300. This is accompanied by a change in the electronic structure as revealed by x-ray photoemission spectroscopy measurements. We find that the Fermi surface volume decreases rapidly below TMIl while the density-of-states near EF increases significantly. These results suggest that the magnetic ordering plays an important role for the formation of heavy fermion state in this material. Heavy-fermion compounds are characterized by their unique physical properties such as high specific heat coefficient γ, enhanced Pauli susceptibility χp, and large effective mass m*. In these materials, strong hybridization between conduction electron states and localized 4f or 5f orbitals leads to the formation of heavy quasiparticles which give rise to many interesting phenomena including unconventional superconductivity1-5 . However, it has been difficult to understand how the local moments interact with each other because they often order magnetically at low temperatures6-8 .\nRecently, several new classes of heavy-fermion systems have been discovered9-12 , where the local moments do not order magnetically down to very low temperatures13-15 . For example, YbMgGaO16 does not show any sign of magnetic ordering down to 0.03 K14-16 . It was suggested that the lack of magnetic ordering may be due to quantum fluctuations caused by the proximity effect17-19 . Another possibility is that the ground-state wave function becomes more complex than simple product of single-site wave functions20-22 .",
        "watermark_text": "We report the itinerant - to - localized crossover of 5f electrons in an antiferromagnetically ordered and superconducting compound , UPd2Al3 ( Tc = 3 K ) . The temperature dependence of electrical resistivity indicates that the system undergoes a metal - insulator - like process at TMI ~ 50 K with a large residual resistance ratio RRR = 300 .This is accompanied by a change in the electronic configuration as revealed by x - ray photoemission spectroscopy observations . We see that the Fermi boundary pressure reduces rapidly below TMIl while the density - of - states near EF increases strongly .These data suggest that the magnetic ordering plays an important role for the formation of heavy fermion state in this material . Heavy - fermion compounds are characterized by their specific physical properties such as high specific hot coefficient γ , enhanced Pauli susceptibility χp , and large effective mass m * .In these materials , deep hybridization between conduction ion states and localized 4f or 5f orbitals causes to the formation of large quasiparticles which provide rise to many interesting phenomena including unconventional superconductivity1 - 5 . However , it has been difficult to explain how the local moments interact with each other because they frequently order magnetically at low temperatures6 - 8 .Recently , several novel classes of heavy - fermion systems have been discovered9 - 12 , where the local moments do not order magnetically down to very low temperatures13 - 15 . For instance , YbMgGaO16 does not show any sign of magnetic ordering down to 0 . 03 K14 - 16 .It was suggested that the lack of magnetic ordering might be due to quantum fluctuations made by the proximity effect17 - 19 . Another possibility is that the ground - state wave function becomes more sophisticated than simple combination of single - location wave functions20 - 22 .",
        "rewrite_text": "We present findings on the transition of 5f electrons from itinerant to localized states in the antiferromagnetically ordered and superconducting compound UPd2Al3 (Tc = 3 K). The temperature-dependent electrical resistivity suggests that this system experiences a metal-insulator-like transition around TMI ~ 50 K, along with a significant residual resistance ratio (RRR) of 300. Accompanying this is a shift in the electronic configuration, as indicated by x-ray photoemission spectroscopy. Notably, we observe a rapid decrease in the Fermi boundary pressure below TMIl, contrasted by a substantial increase in the density of states near the Fermi level (EF). These findings imply that magnetic ordering plays a crucial role in the development of the heavy fermion state in this compound. Heavy-fermion materials are known for distinct physical properties, including a high specific heat coefficient (γ), enhanced Pauli susceptibility (χp), and notably large effective mass (m*). Such compounds typically feature deep hybridization between conduction electron states and localized 4f or 5f orbitals, leading to the formation of large quasiparticles, which give rise to various intriguing phenomena, including unconventional superconductivity. However, understanding the interactions among local moments remains challenging, particularly as they often exhibit magnetic ordering at low temperatures. Recently, new classes of heavy-fermion systems have been identified where local moments do not display magnetic ordering even at very low temperatures, such as YbMgGaO, which shows no signs of magnetic order down to 0.03 K. This absence of magnetic ordering may stem from quantum fluctuations due to proximity effects, or it could indicate a more complex ground-state wave function than a mere combination of single-site wave functions.",
        "ori-fast-z-score": 0.8320502943378436,
        "water-fast-z-score": 4.899851733322857,
        "rewrite-fast-z-score": 0.5222329678670935
    },
    {
        "original_text": "We report scanning magnetoresistance microscopy (SMRM) measurements on an atom chip with gold wires and microtraps fabricated by focused ion beam milling. The SMRM images show the magnetic field distribution in the vicinity of the wire structures, which are used to transport cold atoms between different trapping sites. We find that the magnetic fields generated by these wires can be accurately described using Biot-Savart s law for straight current-carrying conductors. In addition we observe small deviations from this model at distances below 100 nm from the surface of the wires. These deviations may arise due to stray currents induced in the substrate or due to nontrivial geometries of the wires close to their surfaces. Our results demonstrate that SMRM is well suited to study complex magnetic field distributions near microscopic objects such as atom chips. Atom chips have been developed over recent years as miniaturized devices for manipulating neutral atomic matter waves  1, 2  . They consist of arrays of metallic wires and microtraps produced by focused-ion-beam (FIB) milling  3  , where ultracold atoms are transported along the wires before being trapped in the microtraps  4  .\nIn order to optimize the performance of atom chips it is important to understand how the magnetic fields created by the wires affect the motion of the atoms. This requires detailed knowledge about the spatial structure of the magnetic fields around the wires. However, direct measurement techniques like SQUID-based magnetometry  5  cannot resolve the magnetic field distribution inside the wires because they are too thin  6  . Therefore indirect methods based on imaging the trajectories of atoms released from traps  7, 8  or measuring the forces acting on them  9  were employed instead. Recently, scanning Hall probe microscopy was applied to measure the local magnetic field strength  10  . Here we present scanning magnetoresistance microscopy  11  data obtained on an atom chip consisting of two parallel gold wires connected via a junction  12  . By comparing our experimental results with theoretical predictions we obtain information about the magnetic field distribution in proximity of the wires.",
        "watermark_text": "We report scanning magnetoresistance microscopy ( SMRM ) observations on an atom chip with gold wires and microtraps fabricated by concentrated ion beam milling . The SMRM pictures show the magnetic field spread in the vicinity of the wire structures , which are applied to transport cold molecules between various trap places .We see that the magnetic waves generated by these cables can be correctly explained following Biot - Savart s law for straight current - transporting conductors . In addition we study small deviations from this description at distances below 100 nm from the surface of the wires .These deviations might arise due to stray currents induced in the substrate or due to nontrivial geometries of the wires close to their edges . Our results show that SMRM is well suited to study difficult magnetic field distributions near microscopic structures such as atom devices .Atom devices have been created over recent years as miniaturized devices for manipulating neutral atomic matter waves 1 , 2 . They comprise of arrays of metallic wires and microtraps produced by concentrated - ion - laser ( FIB ) processing 3 , where ultracold atoms are transported along the wires before being trapped in the microtraps 4 .In order to optimize the performance of atom devices it is important to realize how the magnetic waves created by the wires affect the movement of the atoms . This requires complete understanding about the spatial shape of the magnetic waves around the wires .However , direct detection methods like SQUID - based magnetometry 5 cannot determine the magnetic field spread inside the wires because they are too thin 6 . Therefore indirect approaches derived on observing the trajectories of atoms released from nets 7 , 8 or tracking the forces working on them 9 were utilized instead .Recently , scanning Hall probe microscopy was used to measure the local magnetic force force 10 . Here we present scan magnetoresistance microscopy 11 data derived on an molecular computer comprised of two connected gold wires coupled via a junction 12 .By matching our experimental results with theoretical predictions we obtain knowledge about the magnetic force density in proximity of the wires .",
        "rewrite_text": "We present observations from scanning magnetoresistance microscopy (SMRM) conducted on an atom chip featuring gold wires and microtraps, which were fabricated using concentrated ion beam milling. The SMRM images reveal the magnetic field distribution around the wire structures, which facilitate the transport of cold molecules between various trapping locations. Our findings confirm that the magnetic fields generated by these wires can be accurately described by Biot-Savart's law for straight current-carrying conductors. Additionally, we investigate small deviations from this model at distances under 100 nm from the wire surfaces. These deviations may be attributable to stray currents in the substrate or to complex geometries near the edges of the wires. Our results demonstrate that SMRM is an effective technique for studying intricate magnetic field distributions near microscopic structures such as atom devices. Over recent years, atom devices have emerged as compact systems for manipulating neutral atomic matter waves. They consist of arrays of metallic wires and microtraps created through focused ion beam (FIB) processing, allowing ultracold atoms to be moved along the wires before being captured in the microtraps. To enhance the performance of these atom devices, it is crucial to understand how the magnetic fields generated by the wires influence atomic movement, necessitating a comprehensive understanding of the spatial configuration of these magnetic fields. However, direct detection methods, such as SQUID-based magnetometry, cannot effectively measure the magnetic fields within the thin wires. Thus, alternative approaches have been employed, including observing the trajectories of atoms released from nets and analyzing the forces acting on them. Recently, scanning Hall probe microscopy has been utilized to assess the local magnetic force. In this study, we present SMRM data obtained from a molecular computer consisting of two connected gold wires linked via a junction. By aligning our experimental results with theoretical models, we gain insights into the magnetic force density near the wires.",
        "ori-fast-z-score": -0.6923076923076923,
        "water-fast-z-score": 8.590007875090548,
        "rewrite-fast-z-score": 2.030258904551879
    },
    {
        "original_text": "The driving mechanism for jets and outflows is still an open question, especially when the jet/outflow source has no clear central engine such as black holes or protostars. In this work we propose that magnetic reconnection can be responsible for launching jets and outflows in star formation process. We show that magnetic reconnection can accelerate particles to relativistic energies efficiently via Fermi acceleration at shocks driven by the reconnecting current sheet (RCS). The accelerated electrons will produce synchrotron emission which may explain radio observations of jets and outflows. Furthermore, the energetic protons produced during RCS also contribute to nonthermal emissions through inverse Compton scattering with background photons. Finally, we discuss how our model could account for some observational features of jets and outflows. \n \n Keywords: Magnetic reconnection; Jet; Particle acceleration; Shocks; Synchrotron radiation; Nonthermal emission",
        "watermark_text": "The pushing mechanism for rockets and outflows is also an open question , particularly when the jet / outflow source has no clear central fuel such as black holes or protostars . In this research we propose that magnetic reconnection can be responsible for launching jets and outflows in star formation process .We see that magnetic reconnection can accelerate particles to relativistic energies efficiently via Fermi acceleration at shocks driven by the reconnecting current sheet ( RCS ) . The driven electrons will generate synchrotron emission which would cause radio observations of jets and outflows .Furthermore , the energetic protons generated during RCS also contribute to nonthermal emissions through inverse Compton absorption with background photons . Finally , we talk how our model could account for some observational characteristics of jets and outflows .Keywords : Magnetic reconnection ; Jet ; Particle acceleration ; Shocks ; Synchrotron emission ; Nonthermal emission",
        "rewrite_text": "The mechanism behind the propulsion of rockets and outflows remains an unresolved issue, especially when the source of jets or outflows lacks a distinct central fuel source, such as black holes or protostars. In this study, we propose that magnetic reconnection may play a crucial role in launching jets and outflows during the star formation process. Our findings suggest that magnetic reconnection can effectively accelerate particles to relativistic energies through Fermi acceleration at shocks created by the reconnecting current sheet (RCS). The accelerated electrons produce synchrotron emissions, leading to radio observations of jets and outflows. Additionally, energetic protons generated in the RCS contribute to nonthermal emissions through inverse Compton scattering with background photons. Finally, we discuss how our model could explain certain observational features of jets and outflows. \n\nKeywords: Magnetic reconnection; Jet; Particle acceleration; Shocks; Synchrotron emission; Nonthermal emission.",
        "ori-fast-z-score": -0.6509445549041194,
        "water-fast-z-score": 3.8729833462074166,
        "rewrite-fast-z-score": 1.75
    },
    {
        "original_text": "The search is performed using data collected by the BABAR experiment at SLAC in 1999-2000, corresponding to an integrated luminosity of about 40 fb-1 . No signal candidates are observed and upper limits on the branching fraction are set as a function of the mass of the lepton pair.  These results improve upon previous measurements made with similar techniques but smaller datasets. The analysis uses a technique that exploits the kinematic properties of the final state particles to suppress backgrounds. This method has been used previously to measure the branching fractions of other rare decays such as B+ --> K*(892)0 pi+ , B+ --> D*0 pi+ , and B+ --> J/psi K- .\nPACS numbers: 11.30.Er, 12.15.Hh, 13.20.He  We report here our measurement of the branching fraction for the decay B+ --> gamma +l+nu (where l = e or mu), which proceeds through one-loop electroweak penguin diagrams involving W bosons and heavy quarks. In this process, the photon arises from the internal bremsstrahlung of the charged lepton produced in association with the neutrino. The Standard Model predicts a branching fraction of 1.1 x 10-6  1  . A number of extensions to the Standard Model predict enhancements over this value  2  .  For example, supersymmetric models can enhance the rate by several orders of magnitude  3  ; however, these predictions depend strongly on the masses of the superpartners involved  4  .",
        "watermark_text": "The survey is conducted using data taken by the BABAR study at SLAC in 1999 - 2000 , corresponding to an integrated luminosity of about 40 fb - 1 . No signal candidates are observed and upper limits on the branching fraction are set as a function of the mass of the lepton pair .These conclusions build upon recent observations made with similar method but smaller datasets . The analysis involves a technique that exploits the kinematic effects of the finished state particles to suppress patterns .This method has been used earlier to measure the branching fractions of other rare decays such as B + - - > K * ( 892 ) 0 pi + , B + - - > D * 0 pi + , and B + - - > J / psi K - . PACS scores : 11 . 30 . Er , 12 . 15 . Hh , 13 . 20 . He We report here our measurement of the branching percentage for the decay B + - - > gamma + l + nu ( where l = e or mu ) , which goes through one - ring electroweak penguin diagrams featuring W bosons and light quarks .In this process , the photon arises from the internal bremsstrahlung of the charged lepton generated in association with the neutrino . The Standard Model predicts a branching fraction of 1 . 1 x 10 - 6 1 .A variety of extensions to the Standard Model predict enhancements over this value 2 . For instance , supersymmetric theories can increase the rate by many orders of magnitude 3 ; however , these predictions rely highly on the masses of the superpartners involved 4 .",
        "rewrite_text": "The survey utilizes data from the BABAR experiment conducted at SLAC during 1999 and 2000, which corresponds to an integrated luminosity of approximately 40 fb⁻¹. No signal candidates were detected, leading to the establishment of upper limits on the branching fraction as a function of the lepton pair mass. These findings build on recent observations obtained using similar methods but with smaller datasets. The analysis employs a technique that harnesses the kinematic effects of the final state particles to mitigate patterns. This method has previously been applied to measure the branching fractions of other rare decays, including B⁺ → K*(892)⁰π⁺, B⁺ → D*⁰π⁺, and B⁺ → J/ψK⁻. The PACS codes are 11.30.Er, 12.15.Hh, and 13.20.He. In this report, we present our measurement of the branching fraction for the decay B⁺ → γ + l⁺ + ν (where l = e or μ), which is mediated by one-loop electroweak penguin diagrams involving W bosons and light quarks. In this process, the photon is produced via internal bremsstrahlung associated with the charged lepton and the neutrino. The Standard Model predicts a branching fraction of 1.1 x 10⁻⁶. Various extensions to the Standard Model suggest potential enhancements to this value; for example, supersymmetric theories may increase the rate by several orders of magnitude, although these predictions are highly dependent on the masses of the involved superpartners.",
        "ori-fast-z-score": -2.0855209398041166,
        "water-fast-z-score": 4.2808061395979236,
        "rewrite-fast-z-score": -0.6546536707079772
    },
    {
        "original_text": "The observed smallness of the vacuum energy density is one of the most puzzling problems in physics today, and it has been suggested that this problem may be solved by considering quantum gravity effects on the vacuum fluctuations.  In this work we show how such an effect can arise naturally within the context of loop quantum gravity (LQG). We consider a model where the gravitational field is quantized using LQG techniques while matter fields are treated classically. The resulting effective action contains terms which depend explicitly on the scale factor of the universe as well as its time derivatives. These terms lead to corrections to the standard Friedmann equations at high energies. Using these modified equations together with observational data we find that the present day value of the vacuum energy density agrees very well with observations if the initial conditions are chosen appropriately. This result suggests that our approach provides a natural solution to the cosmological constant problem. The observed smallness of the cosmological constant poses one of the greatest challenges facing modern theoretical physics  1  . It is generally believed that quantum gravity will play an important role in understanding why the vacuum energy density associated with quantum fluctuations of all fields is so much smaller than what would naively be expected  2  .\nIn recent years there have been several attempts to address this issue within the framework of loop quantum gravity  3  -  8  , but none of them seem to provide a satisfactory answer  9  . In particular, the results obtained in Refs.  6  -  8  do not agree with each other or with current experimental bounds  10  . Here we propose a new mechanism based on ideas developed recently in Ref.  11  . Our starting point is the observation that the Wheeler-DeWitt equation derived from the canonical formulation of general relativity leads to modifications of the usual Schrödinger equation when applied to states describing macroscopic systems  12  . As shown in Ref.  13  , these modifications can be interpreted as arising due to the presence of additional degrees of freedom corresponding to the gravitational field itself.",
        "watermark_text": "The observed smallness of the vacuum energy density is one of the most puzzling difficulties in science today , and it has been proposed that this question could be answered by investigating quantum gravitational influences on the vacuum fluctuations . In this research we explain how such an influence can arise naturally within the context of loop quantum gravitational ( LQG ) .We consider a description where the gravitational field is quantized utilizing LQG techniques while matter forces are treated classically . The resulting effective action contains terms which depend explicitly on the scale factor of the universe as well as its time functions .These terms lead to corrections to the standard Friedmann equations at high energies . Using these modified equations together with observational data we find that the present day value of the vacuum energy density agrees very best with observations if the first terms are chosen properly .This result suggests that our approach offers a natural solution to the cosmological constant problem . The observed smallness of the cosmological constant presents one of the greatest challenges facing current theoretical physics 1 .It is usually thought that quantum gravitational will take an important role in understanding why the vacuum energy density associated with quantum fluctuations of all fields is so even smaller than what would naively be anticipated 2 . In recent history there have been numerous attempts to tackle this question within the framework of loop quantum gravitational 3 - 8 , but none of them seem to provide a adequate answer 9 .In particular , the results derived in Refs . 6 - 8 do not comply with each other or with current experimental bounds 10 .Here we propose a new method using on ideas developed lately in Ref . 11 .Our starting point is the observation that the Wheeler - DeWitt equation derived from the canonical formulation of general relativity leads to modifications of the usual Schrödinger equation when applied to states describing macroscopic systems 12 . As seen in Ref .13 , these alterations can be interpreted as occurring due to the presence of added degrees of freedom corresponding to the gravitational field itself .",
        "rewrite_text": "The small value of vacuum energy density is one of the most perplexing issues in contemporary science. It has been suggested that exploring the quantum gravitational effects on vacuum fluctuations may provide insight into this dilemma. In our research, we demonstrate how such influences can naturally emerge within the framework of loop quantum gravity (LQG). We adopt a model in which the gravitational field is quantized using LQG techniques, while matter interactions are treated classically. The resulting effective action features terms that explicitly depend on the universe's scale factor and its time evolution. These terms introduce corrections to the standard Friedmann equations at high energy levels. By utilizing these modified equations alongside observational data, we find that the current value of vacuum energy density aligns best with observations when the initial terms are appropriately selected. This finding implies that our approach could provide a viable solution to the cosmological constant problem—one of the most significant challenges in modern theoretical physics. It is widely believed that quantum gravity plays a crucial role in explaining why the vacuum energy density related to quantum fluctuations across all fields is considerably smaller than would be expected. While numerous efforts have been made recently to address this issue within the loop quantum gravity framework, they have not yielded satisfactory answers, particularly as results from various studies have been inconsistent with each other and with current experimental data. Here, we introduce a new method inspired by recent developments. Our approach begins with the observation that the Wheeler-DeWitt equation, derived from the canonical formulation of general relativity, modifies the traditional Schrödinger equation when applied to macroscopic states. These modifications, as illustrated in prior work, can be understood as arising from the inclusion of extra degrees of freedom linked to the gravitational field itself.",
        "ori-fast-z-score": 1.323448205074589,
        "water-fast-z-score": 8.17423891369599,
        "rewrite-fast-z-score": -0.24096579867074966
    },
    {
        "original_text": "We report the observation of dynamic condensation of water vapor on crack tips during slow fracture experiments performed under vacuum conditions (10-6 mbar) and low temperature (77 K). The condensed water is found to be localized along the crack front, where it forms a thin film that covers the entire surface of the crack tip. This phenomenon has been observed for cracks propagating both perpendicularly and parallel to the direction of maximum tensile stress. We propose a model based on molecular dynamics simulations which explains this effect by considering the presence of an electric field generated by the moving crack tip. In addition we show how the formation of such films can affect the mechanical properties of the material. Condensation phenomena are ubiquitous in nature but have rarely been reported in materials science. Here we present experimental evidence showing that water condenses onto the crack surfaces when they propagate through fused silica glasses. These results were obtained using a combination of optical microscopy techniques with environmental scanning electron microscopy (ESEM), Raman spectroscopy and infrared reflection absorption spectroscopy (IRAS).",
        "watermark_text": "We report the observation of dynamic condensation of liquid vapor on break tips during slow fracture studies performed under vacuum environments ( 10 - 6 mbar ) and low heat ( 77 K ) . The condensed water is found to be localized along the crack front , where it creates a thin film that covers the entire surface of the crack tip .This phenomenon has been observed for faults propagating both perpendicularly and parallel to the direction of maximum tensile tension . We suggest a theory based on protein mechanics simulations which explains this effect by assuming the presence of an electric field produced by the moved crack edge .In addition we study how the formation of such films can affect the structural properties of the material . Condensation problems are ubiquitous in nature but have seldom been reported in materials science .Here we present experimental evidence showing that water condenses onto the crack surfaces when they propagate through fused silica glasses . These conclusions were obtained using a combination of optical microscopy methods with environmental scan electron microscopy ( ESEM ) , Raman spectroscopy and infrared reflection detection spectroscopy ( IRAS ) .",
        "rewrite_text": "We present our findings on the dynamic condensation of liquid vapor occurring at crack tips during slow fracture experiments conducted under low vacuum conditions (10^-6 mbar) and at low temperatures (77 K). The condensed water is observed to accumulate along the crack front, forming a thin film that spans the entire surface of the crack tip. This phenomenon has been noted in faults propagating both perpendicularly and parallel to the direction of maximum tensile stress. We propose a theoretical framework based on simulations of protein mechanics, suggesting that this effect may arise from an electric field generated by the moving crack edge. Additionally, we investigate how the formation of these films influences the structural properties of the material. While condensation phenomena are common in nature, they have been infrequently reported in materials science. Our experimental evidence demonstrates that water condenses on the crack surfaces during the propagation of fractures in fused silica glasses. These findings were obtained through a combination of optical microscopy, environmental scanning electron microscopy (ESEM), Raman spectroscopy, and infrared reflection absorption spectroscopy (IRAS).",
        "ori-fast-z-score": -0.32539568672798425,
        "water-fast-z-score": 5.1759731137650435,
        "rewrite-fast-z-score": 1.5275252316519468
    },
    {
        "original_text": "We propose an alternative switching mechanism for spintronic devices based on domain walls (DWs). The proposed device consists of two ferromagnetic layers separated by a non-magnetic spacer layer, where DWs can be driven between different positions in each magnetic layer using spin-orbit torques and electric fields. We show that this new type of device is able to operate at lower current densities than conventional spin valves with comparable magnetoresistance values. In addition we demonstrate how the energy barrier associated with the motion of the DWs can be tuned through changes in the thicknesses of both the ferromagnets and the non-magnetic spacer. This allows us to optimize the energy landscape such that the DWs are trapped in their equilibrium position when no external field or voltage bias is applied. Finally, we discuss possible applications of our proposal as well as its limitations. Spintronics has emerged over recent years as one of the most promising technologies for future information processing systems  1  . One of the main challenges faced by these devices is the development of efficient ways to control the flow of charge carriers without compromising their high mobility  2  .\nIn order to overcome this problem several groups have recently investigated the possibility of controlling the direction of electron transport via the manipulation of magnetic textures  3  , which include vortex states  4  , skyrmions  5  and domain walls  6  . Domain walls are particularly interesting since they can be manipulated electrically  7, 8  and thermally  9  , making them ideal candidates for low-power consumption devices  10  . However, despite significant progress made towards understanding the physics behind the dynamics of domain walls  11  , there remains much uncertainty about the exact nature of the mechanisms responsible for driving their motion  12  .",
        "watermark_text": "We suggest an additional switching method for spintronic systems relying on domain barriers ( DWs ) . The proposed system consists of two ferromagnetic layers divided by a non - magnetic spacer membrane , where DWs can be pushed between various positions in each magnetic layer involving spin - orbit torques and electric forces .We suggest that this new kind of device is could to work at lower current densities than conventional spin tubes with similar magnetoresistance ratings . In addition we prove how the electricity barrier associated with the movement of the DWs can be tuned through variations in the thicknesses of both the ferromagnets and the non - magnetic spacer .This enables us to optimize the electricity landscape such that the DWs are locked in their equilibrium place when no external field or voltage bias is applied . Finally , we study possible users of our proposal as well as its limitations .Spintronics has emerged over recent years as one of the most attractive devices for future data processing applications 1 . One of the main problems faced by these machines is the development of effective means to manage the transfer of charge carriers without compromising their high mobility 2 .In try to overcome this situation several organizations have recently examined the prospect of controlling the direction of electron transport via the manipulation of magnetic textures 3 , which contain vortex states 4 , skyrmions 5 and domain barriers 6 . Domain barriers are particularly attractive since they can be manipulated electrically 7 , 8 and thermally 9 , making them ideal candidates for low - energy consumption devices 10 .However , despite considerable progress made towards studying the physics behind the dynamics of domain walls 11 , there exists much uncertainty about the exact nature of the mechanisms involved for controlling their motion 12 .",
        "rewrite_text": "We propose a novel switching method for spintronic systems that utilizes domain walls (DWs). This system features two ferromagnetic layers separated by a non-magnetic spacer membrane, allowing DWs to be manipulated among different positions within each magnetic layer through the application of spin-orbit torques and electric forces. Our design could potentially operate at lower current densities compared to traditional spintronic devices with similar magnetoresistance characteristics. Furthermore, we demonstrate that the electric barrier related to DW movement can be adjusted by modifying the thickness of both ferromagnetic layers and the non-magnetic spacer. This adjustment allows us to optimize the electrical landscape, ensuring that DWs remain locked in equilibrium when no external field or voltage bias is applied. Finally, we explore potential applications of our approach, as well as its limitations. Spintronics has recently emerged as a promising avenue for future data processing applications. A significant challenge for these technologies lies in developing efficient methods to control charge carrier movement without hindering their high mobility. To address this issue, several organizations have investigated the possibility of directing electron transport by manipulating magnetic textures, which include vortex states, skyrmions, and domain barriers. Domain barriers are particularly appealing because they can be controlled both electrically and thermally, making them excellent candidates for low-energy consumption devices. However, despite the significant advances in understanding domain wall dynamics, there remains considerable uncertainty regarding the precise mechanisms for controlling their motion.",
        "ori-fast-z-score": -0.5980503604017327,
        "water-fast-z-score": 8.629012342939285,
        "rewrite-fast-z-score": 2.3772174470791843
    },
    {
        "original_text": "The parity violating asymmetry in the scattering of polarized electrons off unpolarized protons is measured at Jefferson Lab to determine the proton s weak charge with an uncertainty comparable to that achieved for the electron and neutron.  The experiment uses longitudinally polarized electrons produced by CEBAF, which are scattered off a liquid hydrogen target located inside Hall A. The data were taken during two experimental runs between October 2009 and May 2011 using beam currents ranging from 0.5 nA to 1.0 µA. This measurement improves upon previous results obtained at SLAC (1998) and JLab (2005), where systematic uncertainties dominated over statistical ones. In this analysis we have reduced these systematics significantly through improved understanding of the detector response as well as new techniques used to extract the signal. We find Qweak = -0.0018 ± 0.0007(stat.) ± 0.0003(syst.), consistent with Standard Model predictions within one standard deviation.",
        "watermark_text": "The parity violating asymmetry in the scattering of polarized ions off unpolarized protons is measured at Jefferson Lab to estimate the proton s weak charge with an uncertainty comparable to that attained for the electron and neutron . The observation utilizes longitudinally polarized particles generated by CEBAF , which are scattered off a liquid hydrogen target located inside Hall A .The data were took during two test runs between October 2009 and May 2011 using beam currents ranging from 0 . 5 nA to 1 . 0 µA . This measurement improves upon preceding results derived at SLAC ( 1998 ) and JLab ( 2005 ) , where empirical uncertainties prevailed over quantitative ones .In this analysis we have reduced these systematics substantially through improved understanding of the detector response as well as modern procedures used to extract the signal . We get Qweak = - 0 . 0018 ± 0 . 0007 ( stat . )± 0 . 0003 ( syst . ) , compatible with Standard Model estimates within one standard deviation .",
        "rewrite_text": "At Jefferson Lab, researchers measured the parity-violating asymmetry in the scattering of polarized ions off unpolarized protons to estimate the weak charge of the proton, achieving an uncertainty similar to that of previous measurements for the electron and neutron. This experiment utilized longitudinally polarized particles produced by CEBAF, which were directed at a liquid hydrogen target situated in Hall A. Data were collected during two test runs conducted between October 2009 and May 2011, with beam currents varying from 0.5 nA to 1.0 µA. This measurement represents an improvement over earlier results obtained at SLAC in 1998 and JLab in 2005, where the uncertainties were primarily empirical rather than quantitative. In this analysis, we significantly reduced systematic uncertainties by enhancing our understanding of the detector response and adopting modern signal extraction techniques. Our findings yield Qweak = -0.0018 ± 0.0007 (stat.) ± 0.0003 (syst.), which is consistent with Standard Model predictions within one standard deviation.",
        "ori-fast-z-score": -0.13483997249264842,
        "water-fast-z-score": 5.879747322073337,
        "rewrite-fast-z-score": 0.5163977794943222
    },
    {
        "original_text": "We study the circular and non-circular motion near the event horizons of rotating black holes by using the Hamilton-Jacobi method, which is an extension of the standard geodesic approach to include higher-order corrections due to gravitational radiation reaction effects. We find that for both circular and non-circular motions there exist two families of solutions with different orbital frequencies at the same radius. The inner family has smaller orbital frequency than the outer one; it corresponds to bound orbits while the outer solution describes unbound orbits. For circular orbits we show how these results can be obtained directly from the first law of black hole mechanics. In addition, we also present numerical evidence showing that the innermost stable circular orbit (ISCO) moves inward as the spin parameter increases. Finally, we discuss some implications of our results on astrophysical phenomena such as accretion disks around spinning black holes. Introduction -The discovery of the first binary pulsar PSR1913+16  1  , together with its subsequent measurement of the mass ratio between the neutron star and its companion white dwarf  2  , led to the prediction  3  that most likely all massive stars end their lives as black holes surrounded by accretion disks  4  . Since then many other observations have been made confirming this picture  5  .\nIn order to understand the dynamics of matter falling into black holes, it is important to know where particles are trapped or scattered out  6  . This information is encoded in the location of the so-called Innermost Stable Circular Orbit (ISCO), i.e., the smallest possible radius r ISCO of a particle s circular orbit  7, 8  . It turns out that the value of r ISCO depends sensitively on the spin angular momentum J = Ma 2 /(2r g ) of the black hole  9  : if J < M 2 , then r ISCO > 3M ; but when J approaches M 2 , r ISCO decreases rapidly until finally it reaches the Schwarzschild radius R s ≡ 2GM/c 2  10  . Therefore, knowing the exact position of the ISCO will help us better understand the physics behind various processes taking place close to",
        "watermark_text": "We explore the circular and non - circular motion near the event horizons of spinning black holes by using the Hamilton - Jacobi method , which is an extension of the standard geodesic approach to use larger - order corrections due to gravitational radiation process effects . We see that for both circular and non - circular movements there exist two families of solutions with varying orbital frequencies at the same radius .The inner family has less orbital frequency than the inner one ; it corresponds to bound orbits while the inner solution refers unbound orbits . For circular orbits we give how these results can be obtained directly from the first law of brown hole mechanics .In addition , we also discuss numerical information demonstrating that the innermost stable circular orbit ( ISCO ) moving inward as the spin parameter grows . Finally , we explain some implications of our findings on astrophysical processes such as accretion balls around spun dark holes .Introduction - The observation of the first binary pulsar PSR1913 + 16 1 , combined with its subsequent calculation of the mass ratio between the neutron star and its companion white dwarf 2 , leading to the scenario 3 that most likely all large galaxies begin their careers as black holes populated by accretion disks 4 . Since then many other experiments have been made confirming this picture 5 .In order to comprehend the dynamics of matter falling into black holes , it is important to consider where ions are captured or scattered out 6 . This knowledge is stored in the location of the so - called Innermost Stable Circular Orbit ( ISCO ) , i . e . , the smallest available diameter r ISCO of a particle s circular orbit 7 , 8 .It turns out that the value of r ISCO relies sensitively on the spin angular velocity J = Ma 2 / ( 2r g ) of the dark hole 9 : if J < M 2 , then r ISCO > 3M ; but when J approaches M 2 , r ISCO falls slowly until finally it meets the Schwarzschild diameter R s ≡ 2GM / c 2 10 . Therefore , knowing the exact position of the ISCO will assist us better understand the physics behind several mechanisms taking place nearby to",
        "rewrite_text": "We investigate both circular and non-circular motion near the event horizons of rotating black holes using the Hamilton-Jacobi method. This approach enhances the conventional geodesic method by incorporating higher-order corrections due to the effects of gravitational radiation. Our findings reveal that for both types of motion, there are two distinct families of solutions that present different orbital frequencies at the same radius. The outer family exhibits a lower orbital frequency, which corresponds to bound orbits, while the inner family corresponds to unbound orbits. For circular orbits, we explain how these results can be derived directly from the first law of black hole mechanics. Additionally, we present numerical data showing that the innermost stable circular orbit (ISCO) moves inward as the spin parameter increases. We also explore the implications of our results for astrophysical phenomena, such as the behavior of accretion disks around rotating black holes.\n\nIntroduction - The discovery of the binary pulsar PSR1913 + 16, along with subsequent measurements of the mass ratio between the neutron star and its companion white dwarf, has led to the hypothesis that most large galaxies likely commence their evolution as black holes surrounded by accretion disks. Numerous experiments have since supported this model. To understand the dynamics of matter falling into black holes, it is crucial to analyze the capture and scattering of ions. This understanding is encapsulated in the concept of the Innermost Stable Circular Orbit (ISCO), which denotes the smallest possible radius for a particle’s circular orbit. The value of the ISCO radius is highly sensitive to the spin angular momentum \\(J = \\frac{Ma^2}{2r_g}\\) of the black hole. Specifically, if \\(J < M^2\\), then \\(r_{ISCO} > 3M\\); however, as \\(J\\) approaches \\(M^2\\), \\(r_{ISCO}\\) gradually decreases until it converges at the Schwarzschild radius \\(R_s \\equiv \\frac{2GM}{c^2}\\). Thus, determining the precise location of the ISCO is essential for enhancing our understanding of various physical processes occurring in the vicinity of black holes.",
        "ori-fast-z-score": -1.7905475715715027,
        "water-fast-z-score": 6.6577138248976375,
        "rewrite-fast-z-score": -0.9607689228305227
    },
    {
        "original_text": "We present the first results for gravitational waves generated by binary black holes in full general relativity, using both post-post-Newtonian (PPN) theory and numerical relativity. We find that our PPN-calculated waveform agrees with the numerical one to within 1% at frequencies above 100 Hz. This is an improvement over previous calculations which used only PN theory or numerical relativity alone. \n \n The agreement between these two methods provides us with confidence that we can use this hybrid approach as part of future searches for gravitational waves produced during mergers of compact objects such as neutron stars and/or black holes. In addition, it allows us to test whether current models are accurate enough to detect gravitational waves emitted by merging binaries containing supermassive black holes. These tests will be performed on data collected by LIGO/VIRGO detectors when they become operational later this year. Finally, we show how the hybrid method could also be useful for testing alternative theories of gravity.",
        "watermark_text": "We present the first findings for gravitational waves generated by binary dark holes in full general relativity , using both post - post - Newtonian ( PPN ) theory and mathematical relativity . We see that our PPN - calculated waveform agrees with the numerical one to within 1 % at speeds above 100 Hz .This is an improvement over past calculations which employed only PN theory or numerical relativity alone . The agreement between these two models provides us with confidence that we can using this hybrid approach as part of later searches for gravitational waves produced during mergers of compact galaxies such as neutron galaxies and / or black holes .In addition , it allows us to test whether current theories are accurate sufficient to identify gravitational waves emitted by merging binaries bearing supermassive black holes . These analyses will be performed on evidence generated by LIGO / VIRGO detectors when they become active later this year .Finally , we show how the hybrid technique could also be used for studying alternative theories of gravitational .",
        "rewrite_text": "We present initial findings on gravitational waves produced by binary dark holes, based on full general relativity and employing both post-post-Newtonian (PPN) theory and mathematical relativity. Our results indicate that the waveforms calculated using PPN theory align with those derived from numerical methods within 1% at frequencies exceeding 100 Hz. This marks an advancement over previous studies that relied solely on either post-Newtonian theory or numerical relativity. The close agreement between these two approaches bolsters our confidence in using this hybrid methodology for future searches for gravitational waves generated during the mergers of compact astronomical objects, such as neutron stars and black holes. Furthermore, it enables us to assess the accuracy of current theories in detecting gravitational waves from merging binaries containing supermassive black holes. These analyses will utilize data from the LIGO/VIRGO detectors once they commence operations later this year. Lastly, we discuss how this hybrid technique could also apply to exploring alternative theories of gravity.",
        "ori-fast-z-score": 0.44172610429938614,
        "water-fast-z-score": 6.47609133939173,
        "rewrite-fast-z-score": 0.7592566023652966
    },
    {
        "original_text": "We present the results of an unbiased survey for compact HII regions in the southern Galactic plane using data obtained with the Australia Telescope Compact Array (ATCA). The sample consists of all known OB stars within |b| < 1 degree and distances less than 5 kpc, which are associated with IRAS point sources that have been classified as having infrared excesses indicative of circumstellar disks or envelopes. We detect over 100 new compact HII regions at frequencies between 2.1 GHz and 6.0 GHz. These objects range in size from 0.01 pc to 0.5 pc and their luminosities vary by more than four orders of magnitude. Most of these newly detected compact HII regions appear to be excited by single O-type stars; however we also find several examples where two or three bright radio components are separated by only a few arcseconds. In addition, we identify a number of previously uncatalogued ultracompact HII regions whose sizes are smaller than 0.01 pc.",
        "watermark_text": "We present the conclusion of an unbiased survey for compact HII locations in the southern Galactic jet using data acquired with the Australia Telescope Compact Array ( ATCA ) . The sample consists of all known OB stars within | b | < 1 degree and altitudes lower than 5 kpc , which are identified with IRAS point bodies that have been classified as having infrared excesses indicative of circumstellar disks or envelopes .We detect over 100 new compact HII zones at speeds between 2 . 1 GHz and 6 . 0 GHz . These objects range in height from 0 . 01 pc to 0 . 5 pc and their luminosities vary by more than four orders of magnitude .Most of these newly observed compact HII regions seem to be excited by single O - class stars ; however we also find various instances where two or three dark radio components are split by only a few arcseconds . In addition , we identify a number of previously uncatalogued ultracompact HII zones whose sizes are smaller than 0 . 01 pc .",
        "rewrite_text": "We present the findings of an impartial survey of compact HII regions in the southern Galactic jet, utilizing data collected from the Australia Telescope Compact Array (ATCA). The sample includes all known OB stars within |b| < 1 degree and altitudes less than 5 kpc, which are associated with IRAS point sources identified as having infrared excesses indicative of circumstellar disks or envelopes. Our survey has identified over 100 new compact HII regions at frequencies ranging from 2.1 GHz to 6.0 GHz. These regions vary in size from 0.01 pc to 0.5 pc and exhibit luminosities that differ by more than four orders of magnitude. Most of the newly detected compact HII regions appear to be excited by individual O-class stars; however, we also observe several cases where two or three faint radio components are located just a few arcseconds apart. Additionally, we have discovered several previously unclassified ultracompact HII regions measuring less than 0.01 pc in size.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.993438317382943,
        "rewrite-fast-z-score": -1.860521018838127
    },
    {
        "original_text": "We present results from three-dimensional hydrodynamic simulations of accreting white dwarfs in close binary systems, focusing on the boundary layer between the disk and the star. We find that the flow is highly turbulent with strong shocks forming at the interface between the two flows. The density structure shows significant departures from spherical symmetry due to the presence of spiral arms which form as a result of the interaction between the stellar magnetic field and the gas stream flowing towards the surface of the white dwarf. These spiral arms are responsible for driving an outflow along the polar axis of the system. In addition we find evidence for large-scale convection cells within the boundary layer. Our models suggest that the observed X-ray emission may be produced by these convective motions rather than by shock heating alone. This work was supported by NASA grant NAG5-7262. \n \n Keywords: Hydrodynamics; Shock waves; Convection",
        "watermark_text": "We present results from three - dimensional hydrodynamic simulations of accreting white dwarfs in close binary systems , concentrating on the boundary layer between the disk and the star . We see that the flow is strongly chaotic with powerful shocks producing at the interface between the two flows .The density structure exhibits significant departures from spherical symmetry thanks to the presence of spiral arms which occur as a product of the interaction between the stellar magnetic force and the gas stream running towards the surface of the white dwarf . These spiral arms are responsible for producing an outflow along the polar axis of the system .In addition we find proof for large - scale convection cells within the boundary layer . Our models suggest that the seen X - ray radiation may be made by these convective movements rather than by shock heating alone .This project was supported by NASA gift NAG5 - 7262 . Keywords : Hydrodynamics ; Shock currents ; Convection",
        "rewrite_text": "We present findings from three-dimensional hydrodynamic simulations of accreting white dwarfs in close binary systems, focusing on the boundary layer between the accretion disk and the star. Our results indicate that the flow is highly chaotic, characterized by strong shocks at the interface of the two flows. The density distribution shows notable deviations from spherical symmetry, largely due to the formation of spiral arms that arise from the interaction of the stellar magnetic field and the gas stream directed toward the white dwarf’s surface. These spiral structures contribute to an outflow along the system's polar axis. Additionally, we observe evidence of large-scale convection cells within the boundary layer. Our models imply that the X-ray radiation observed may originate from these convective motions rather than solely from shock heating. This research was supported by NASA grant NAG5-7262. Keywords: Hydrodynamics; Shock currents; Convection.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.88240082724041,
        "rewrite-fast-z-score": 0.23249527748763857
    },
    {
        "original_text": "We present the results of our analysis on blazars detected by both the Wilkinson Microwave Anisotropy Probe (WMAP) satellite and the Swift observatory in the first year of operation, 2004-05. We find that there are no significant differences between the two samples when we compare their distributions for redshift, luminosity distance, radio flux density at 1 GHz, optical magnitude, or X-ray photon index. The only difference is found to be in the distribution of redshifts; this may be due to selection effects caused by the different energy bands used by each instrument. \n \n Keywords: Blazar, Swift, WMAP, survey, cosmology, statistics, gamma-ray bursts, galaxy clusters, dark matter, dark energy, neutrino mass, cosmic microwave background radiation, anisotropies, large-scale structure, gravitational lensing, relativistic jets, quasar, active galactic nuclei",
        "watermark_text": "We present the conclusion of our analysis on blazars detected by both the Wilkinson Microwave Anisotropy Probe ( WMAP ) satellite and the Swift telescope in the first year of operation , 2004 - 05 . We see that there are no considerable changes between the two specimens when we compare their distributions for redshift , luminosity distance , radio flux concentration at 1 GHz , optical magnitude , or X - ray photon index .The only difference is found to be in the distribution of redshifts ; this might be due to choice influences resulting by the different energy bands used by each instrument . Keywords : Blazar , Swift , WMAP , survey , cosmology , statistics , gamma - ray clusters , galaxy rings , soft material , soft energy , neutrino mass , cosmic microwave background radiation , anisotropies , large - scale structure , gravity lensing , relativistic jets , quasar , active galactic nuclei",
        "rewrite_text": "We summarize the findings of our analysis regarding blazars detected by both the Wilkinson Microwave Anisotropy Probe (WMAP) and the Swift telescope during their first operational year, 2004-2005. Our comparison reveals no significant differences in the distributions of redshift, luminosity distance, radio flux at 1 GHz, optical magnitude, or X-ray photon index between the two sets of data. The only notable distinction lies in the distribution of redshifts, which may be attributed to selection biases arising from the different energy bands utilized by each instrument. \n\nKeywords: Blazar, Swift, WMAP, survey, cosmology, statistics, gamma-ray clusters, galaxy rings, soft material, soft energy, neutrino mass, cosmic microwave background radiation, anisotropies, large-scale structure, gravitational lensing, relativistic jets, quasar, active galactic nuclei.",
        "ori-fast-z-score": -0.39735970711951313,
        "water-fast-z-score": 3.3113308926626095,
        "rewrite-fast-z-score": -0.39735970711951313
    },
    {
        "original_text": "We present the first measurement of the cosmic streaming field in the local universe, using data from the Sloan Digital Sky Survey (SDSS). The streaming field is defined as the curl-free component of the peculiar velocity field and can be used to measure the net effect of tidal forces on galaxy clusters. We use a sample of 13,000 galaxy groups with spectroscopic redshifts between 0.01 < z < 0.1 selected by applying an adaptive halo mass cut to the SDSS maxBCG cluster catalog. Using this sample we find that the amplitude of the streaming field decreases rapidly towards lower redshift, consistent with theoretical predictions for the growth rate of large-scale structure. In addition, we show that the direction of the streaming field changes significantly over time due to the coherent infall into superclusters. Finally, we demonstrate how our results can be used to test cosmological models against observations. This work was supported by NSF grant AST-0707766.",
        "watermark_text": "We present the first measurement of the cosmic streaming force in the local universe , using data from the Sloan Digital Sky Survey ( SDSS ) . The streaming field is characterized as the curl - free component of the peculiar speed field and can be used to measure the net effect of tidal forces on star clusters .We use a sample of 13 , 000 galaxy groups with spectroscopic redshifts between 0 . 01 < z < 0 . 1 selected by using an adaptive halo weight cut to the SDSS maxBCG cluster catalog . Using this specimen we find that the frequency of the streaming force tends rapidly towards lower redshift , compatible with theoretical expectations for the development time of large - scale structure .In addition , we prove that the direction of the streaming field shifts significantly over time due to the coherent infall into superclusters . Finally , we prove how our findings can be used to test cosmological predictions against measurements .This project was supported by NSF grant AST - 0707766 .",
        "rewrite_text": "We present the inaugural measurement of the cosmic streaming force in the local universe, utilizing data from the Sloan Digital Sky Survey (SDSS). The streaming field is defined as the curl-free component of the peculiar velocity field and serves as a tool to assess the overall impact of tidal forces on star clusters. Our analysis involves a sample of 13,000 galaxy groups with spectroscopic redshifts in the range of 0.01 < z < 0.1, selected using an adaptive halo weight cut from the SDSS maxBCG cluster catalog. Our results indicate that the prevalence of the streaming force decreases rapidly as redshift lowers, aligning with theoretical predictions regarding the evolution of large-scale structure. Moreover, we demonstrate that the direction of the streaming field undergoes significant changes over time due to the coherent infall into superclusters. Lastly, we illustrate how our findings can be utilized to evaluate cosmological predictions against empirical measurements. This research was supported by NSF grant AST-0707766.",
        "ori-fast-z-score": -0.5698028822981898,
        "water-fast-z-score": 4.358898943540673,
        "rewrite-fast-z-score": 0.11547005383792514
    },
    {
        "original_text": "The authors present the results of their study on the properties of two different types of systems, which are both characterized by an asymmetric distribution of charge carriers and exhibit unconventional superconducting behavior.  The first type is represented by layered compounds with alternating layers of conducting and insulating material (e.g., SrTiO3/SrRuO3/LaAlO3). In these materials, the presence of strong electron correlations leads to the formation of two-dimensional electronic states at the interface between the layers that can be described as a doped Mott insulator. These interfaces act like Josephson junctions and give rise to a spontaneous current perpendicular to the layers. This current causes a magnetic field to penetrate into the sample even when no external magnetic fields are applied. The second class consists of quasi-one-dimensional conductors such as carbon nanotubes or semiconductor nanowires. Here, the asymmetry arises because one end of the wire has been terminated by chemical functionalization.",
        "watermark_text": "The authors present the conclusion of their experiment on the properties of two different kinds of structures , which are both defined by an asymmetric distribution of charge carriers and undergo interesting superconducting behavior . The first class is represented by stacked molecules with alternating layers of conducting and insulating material ( e . g . , SrTiO3 / SrRuO3 / LaAlO3 ) .In these materials , the presence of stable electron correlations causes to the formation of two - dimensional electronic states at the interface between the layers that can be described as a doped Mott insulator . These interfaces act like Josephson junctions and giving rise to a spontaneous current perpendicular to the layers .This voltage creates a magnetic current to reach into the sample even when no external magnetic fields are applied . The second class consists of quasi - one - dimensional conductors such as carbon nanotubes or semiconductor nanowires .Here , the asymmetry arises because one end of the wire has been terminated by chemical functionalization .",
        "rewrite_text": "The authors summarize the findings of their experiment, which explores the characteristics of two distinct types of structures that exhibit fascinating superconducting behaviors due to their asymmetric distribution of charge carriers. The first type features stacked molecules composed of alternating layers of conductive and insulating materials, such as SrTiO3/SrRuO3/LaAlO3. In these structures, stable electron correlations lead to the emergence of two-dimensional electronic states at the interfaces where the layers meet, effectively behaving as a doped Mott insulator. These interfaces function like Josephson junctions, generating a spontaneous current that flows perpendicular to the layers. This current produces a magnetic field that extends into the sample, even in the absence of external magnetic fields. The second type encompasses quasi-one-dimensional conductors, including carbon nanotubes and semiconductor nanowires. In this case, the asymmetry is introduced by chemically functionalizing one end of the wire.",
        "ori-fast-z-score": 0.9701425001453319,
        "water-fast-z-score": 4.85071250072666,
        "rewrite-fast-z-score": 1.61245154965971
    },
    {
        "original_text": "We report on saturation effects observed in the sub-Dopplerbroadened absorption spectrum of cesium atoms confined to a cell with thickness L = 0.5 mm and length l = 1 cm, which is much thinner than the Doppler width (~30mm). The experimental results are compared with theoretical predictions based on the solution of Maxwell-Bloch equations for two-level systems under conditions where the relaxation rates depend strongly on the atomic density. We find that our model describes well both the shape and intensity dependence of the saturated absorption lineshape as well as the linewidths at different intensities. Our measurements show that the optical depth per unit area increases by more than one order of magnitude when going from thick cells to extremely thin ones. This opens up new possibilities for high-resolution spectroscopic studies using such samples. \n \n In recent years there has been growing interest in studying dilute vapors confined inside very thin cells  1  . These experiments have led to important advances in understanding many phenomena related to quantum optics  2  , nonlinear optics  3  , laser cooling  4  , and precision measurement  5  .\nIn this work we present some interesting features of the sub-Doppler-broadened absorption spectrum  6  of cesium atoms confined within an extremely thin cell  7, 8  . Such a sample can be considered as a quasi-two-dimensional gas  9  whose properties differ significantly from those of three-dimensional gases  10  . For example, it was shown recently  11  that the relaxation rate Γ1 of the excited state population depends strongly on the atomic density n0 due to dipole-dipole interactions between neighboring atoms  12  . As a result, the effective homogeneous broadening of the transition becomes dependent on the number N of atoms contained in the probing beam volume V  13  : \n \n Δνeff ~ N/V \n\n\nwhere ΔνD is the Doppler width associated with the thermal motion of the atoms along the direction perpendicular to the probe beam axis. It follows then that the optical depth per atom OD/N also varies with the number of atoms in the probing region:",
        "watermark_text": "We report on saturation effects encountered in the sub - Dopplerbroadened absorption spectrum of cesium atoms confined to a cell with thickness L = 0 . 5 mm and size l = 1 cm , which is much thinner than the Doppler size ( ~ 30mm ) . The empirical results are compared with theoretical estimates based on the solve of Maxwell - Bloch coefficients for two - level systems under conditions where the relaxation frequencies rely highly on the atomic concentration .We see that our model describes well both the form and intensity dependence of the saturated absorption lineshape as also as the linewidths at different intensities . Our measurements show that the optical height per unit area grows by more than one order of magnitude when going from thick cells to incredibly thin ones .This opens up new possibilities for high - resolution spectroscopic studies using such samples . In recent years there has been growing interest in investigating dilute vapors restricted inside very thin cells 1 .These studies have led to significant advances in understanding several phenomena related to quantum optics 2 , nonlinear optics 3 , laser cooling 4 , and accuracy detection 5 . In this research we present some interesting features of the sub - Doppler - broadened absorption spectrum 6 of cesium atoms confined within an incredibly thin cell 7 , 8 .Such a sample can be regarded as a quasi - two - dimensional gas 9 whose characteristics vary significantly from those of three - dimensional gases 10 . For instance , it was shown recently 11 that the relaxation frequency Γ1 of the excited state population relies highly on the atomic concentration n0 due to dipole - dipole bonds between neighboring atoms 12 .As a result , the effective homogeneous broadening of the transition becomes dependent on the number N of atoms enclosed in the probing laser volume V 13 : Δνeff ~ N / V where ΔνD is the Doppler size associated with the thermal motion of the atoms along the direction perpendicular to the probe laser axis . It follows then that the optical height per atom OD / N also varies with the quantity of atoms in the probing zone :",
        "rewrite_text": "We discuss the saturation effects observed in the sub-Doppler broadened absorption spectrum of cesium atoms confined within a cell measuring 0.5 mm in thickness and 1 cm in size, which is significantly thinner than the Doppler width (~30 mm). Our empirical findings are contrasted with theoretical predictions derived from the Maxwell-Bloch equations for two-level systems, particularly in scenarios where the relaxation frequencies are highly dependent on atomic concentration. The model effectively captures both the shape and intensity dependence of the saturated absorption lines and the linewidth variations at different intensities. Notably, our measurements indicate that the optical height per unit area increases by over an order of magnitude when transitioning from thicker to exceptionally thin cells, presenting new opportunities for high-resolution spectroscopic investigations using these samples. In recent years, there has been an increased interest in studying dilute vapors confined in very thin cells. Such research has contributed to advancements in various areas related to quantum optics, nonlinear optics, laser cooling, and precision detection. In this study, we highlight intriguing characteristics of the sub-Doppler broadened absorption spectrum of cesium atoms in an extremely thin cell. This configuration can be seen as a quasi-two-dimensional gas, exhibiting properties that differ markedly from those of three-dimensional gases. Recent findings indicate that the relaxation frequency (Γ1) of the excited state population is significantly influenced by atomic concentration (n0), due to dipole-dipole interactions among adjacent atoms. Consequently, the effective homogeneous broadening of the transition becomes linked to the number of atoms (N) within the probing laser volume (V), following the relation Δνeff ~ N / V, where ΔνD represents the Doppler width arising from the thermal motion of the atoms perpendicular to the probe laser direction. This implies that the optical depth per atom (OD / N) also changes with the number of atoms present in the probing region.",
        "ori-fast-z-score": 1.516365080488482,
        "water-fast-z-score": 9.01838179448413,
        "rewrite-fast-z-score": 1.212678125181665
    },
    {
        "original_text": "We present results on modeling the spectral energy distribution (SED) and variability of the blazar 3C 66A observed by the Whole Earth Blazar Telescope (WEBT). The SED is modeled with an accretion disk, synchrotron emission from relativistic electrons in jets, inverse Compton scattering off soft photons produced within the jet or external to it, and thermal radiation from dusty clouds surrounding the central engine. We find that the model can reproduce most features of the SED: the optical-UV spectrum; the X-ray spectrum; the infrared-optical flux ratio; and the radio-to-optical spectral index. However, we cannot explain why there are two peaks in the UV spectrum at ~1400 Å and ~1900 Å simultaneously. In addition, our model fails to account for the rapid flares detected in the light curve of this source. This suggests that either additional components should be included into the model and/or some physical processes have been neglected. \n \n Keywords: blazars, 3C 66A",
        "watermark_text": "We report findings on studying the spectral power distribution ( SED ) and variability of the blazar 3C 66A observed by the Whole Earth Blazar Telescope ( WEBT ) . The SED is modeled with an accretion disk , synchrotron emission from relativistic electrons in jets , inverse Compton absorption off hard photons generated within the jet or external to it , and thermal rays from damp clouds surrounding the main motor .We see that the model can predict most elements of the SED : the optical - UV signal ; the X - ray signal ; the infrared - optical flux ratio ; and the radio - to - optical wavelength index . However , we cannot explain why there are two peaks in the UV range at ~ 1400 Å and ~ 1900 Å simultaneously .In addition , our model refuses to compensate for the fast flares detected in the light spiral of this source . This implies that either additional components should be included into the model and / or some physical processes have been neglected .Keywords: blazars, 3C 66A",
        "rewrite_text": "We present our findings on the spectral energy distribution (SED) and variability of the blazar 3C 66A, as observed by the Whole Earth Blazar Telescope (WEBT). The SED is characterized by modeling components such as an accretion disk, synchrotron emission from relativistic electrons in jets, inverse Compton scattering from hard photons—both generated within the jet and externally—and thermal radiation from surrounding damp clouds. Our model successfully predicts most aspects of the SED, including the optical-UV signal, the X-ray signal, the infrared-optical flux ratio, and the radio-to-optical wavelength index. However, we are unable to account for the presence of two peaks in the UV range, at approximately 1400 Å and 1900 Å, occurring simultaneously. Additionally, our model does not adequately explain the rapid flares observed in the light curve of this source. This suggests that either additional components need to be incorporated into the model or that certain physical processes may have been overlooked. Keywords: blazars, 3C 66A.",
        "ori-fast-z-score": -0.12403473458920847,
        "water-fast-z-score": 5.75,
        "rewrite-fast-z-score": 1.9123657749350298
    },
    {
        "original_text": "The Moon is exposed to solar wind and magnetospheric plasma, which can be modelled by using data from spacecraft such as Cluster or Geotail. The aim of this study was to investigate how these interactions have changed over time. We used magnetic field measurements from Cluster 1 (C1) between 2001 and 2010 to calculate the flux density of energetic electrons at the Moon s surface for each orbit. This allowed us to determine when the Moon was most likely to be bombarded with high energy particles. In addition we calculated the total number of times that C1 crossed the Moon s bow shock during its lifetime. These results were compared against previous studies on the evolution of the Earth s magnetosphere. It has been suggested that there are two main types of interaction between the Earth and the Sun; coronal mass ejections (CMEs), which occur less frequently but produce more intense events than streamer belt driven storms.",
        "watermark_text": "The Moon is subjected to solar wind and magnetospheric plasma , which can be described by using data from satellites such as Cluster or Geotail . The goal of this study was to examine how these interactions have shifted over time .We utilized magnetic force observations from Cluster 1 ( C1 ) between 2001 and 2010 to estimate the flux concentration of energetic electrons at the Moon s surface for each trajectory . This able us to predict when the Moon was most likely to be bombarded with high energy ions .In addition we calculated the total number of times that C1 crossed the Moon s bow shock during its lifetime . These data were compared against prior studies on the evolution of the Earth s magnetosphere .It has been proposed that there are two principal kinds of collision between the Earth and the Sun ; coronal mass ejections ( CMEs ) , which occur smaller regularly but generate more intense events than streamer belt driven storms .",
        "rewrite_text": "The Moon experiences interactions with solar wind and magnetospheric plasma, which can be analyzed using data from satellites like Cluster and Geotail. This study aimed to investigate how these interactions have evolved over time. We analyzed magnetic force observations from Cluster 1 (C1) collected between 2001 and 2010 to estimate the flux concentration of energetic electrons at the Moon's surface for each trajectory. This analysis allowed us to predict periods when the Moon was most likely to encounter high-energy ion bombardment. Additionally, we calculated the total number of times C1 crossed the Moon's bow shock throughout its mission. Our findings were compared with previous studies on the evolution of Earth's magnetosphere. It has been suggested that there are two main types of interactions between the Earth and the Sun: coronal mass ejections (CMEs), which are less frequent but produce more intense events compared to those driven by streamer belt storms.",
        "ori-fast-z-score": -0.13018891098082389,
        "water-fast-z-score": 5.337745350213779,
        "rewrite-fast-z-score": 2.25
    },
    {
        "original_text": "We consider the effective inverse spectral problems (EISP) associated with rational Lax matrices, which are generalizations of classical EISP in terms of Jacobi matrices. We show that these new EISPs can be reduced to some special cases of classical EISP by using an explicit formula for the coefficients of the characteristic polynomial of a rational matrix. As examples we study two classes of rational Lax matrices: one is related to the Toda lattice hierarchy and another is connected with the modified Volterra lattice hierarchy. In particular, we give a complete description on all solutions of the corresponding EISPs. Finally, as applications of our results, we present several interesting properties about the spectra of these rational Lax matrices. The research was supported by NSFC under Grant No.11571040. Keywords: Effective inverse spectral problem; Rational Lax matrices; Toda lattice hierarchy; Modified Volterra lattice hierarchy",
        "watermark_text": "We consider the effective inverse spectral questions ( EISP ) associated with rational Lax matrices , which are generalizations of classical EISP in terms of Jacobi matrices . We see that these new EISPs can be reduced to some general cases of classical EISP by using an explicit formula for the coefficients of the characteristic polynomial of a rational matrix .As instance we study two groups of rational Lax matrices : one is related to the Toda lattice hierarchy and another is linked with the modified Volterra lattice hierarchy . In particular , we give a complete overview on all solutions of the associated EISPs .Finally , as applications of our results , we present several interesting properties about the spectra of these rational Lax matrices . The research was supported by NSFC under Grant No . 11571040 .Keywords : Effective inverse spectral problem ; Rational Lax matrices ; Toda lattice hierarchy ; Modified Volterra lattice hierarchy",
        "rewrite_text": "We explore the effective inverse spectral problems (EISP) related to rational Lax matrices, which extend the traditional EISP associated with Jacobi matrices. Our findings indicate that these new EISPs can be reduced to specific classical EISP cases through an explicit formula for the coefficients of the characteristic polynomial of a rational matrix. Specifically, we analyze two categories of rational Lax matrices: one connected to the Toda lattice hierarchy and the other to the modified Volterra lattice hierarchy. We provide a comprehensive overview of all solutions related to the corresponding EISPs. Additionally, we highlight several fascinating properties concerning the spectra of these rational Lax matrices as a result of our research. This work was supported by the National Natural Science Foundation of China under Grant No. 11571040.  \nKeywords: Effective inverse spectral problem; Rational Lax matrices; Toda lattice hierarchy; Modified Volterra lattice hierarchy.",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 2.6887744785908154,
        "rewrite-fast-z-score": -0.8962581595302719
    },
    {
        "original_text": "We have performed in-orbit focal adjustment (IFA) for the infrared camera onboard AKARI satellite using its own data taken in orbit. The IFA was carried out by comparing the observed point spread function (PSF) and that simulated based on ray tracing analysis, which is one of the most accurate methods to determine the best focus position. We found that the PSFs were not always consistent between different bands even after the IFA had been completed. This inconsistency may be caused by some errors in the optical design or manufacturing process. In addition, we also found that there are still some problems remaining in the calibration accuracy of the detector pixel size. These results will help us improve our understanding about the performance of the instrument as well as provide useful information for future space missions. Keywords: Space mission, Focal adjustment, Point spread function, Ray tracing analysis, Infrared astronomy, Infrared camera",
        "watermark_text": "We have done in - orbit lens adjustment ( IFA ) for the infrared camera onboard AKARI vehicle using its own signal taken in orbit . The IFA was carried out by comparing the seen point spread distribution ( PSF ) and that simulated based on ray tracing imaging , which is one of the most accurate ways to identify the best view point .We determined that the PSFs were not always compatible between various frequencies even after the IFA had been completed . This inconsistency may be caused by some failures in the optical design or manufacturing system .In addition , we also discovered that there are still some problems existing in the calibration reliability of the sensor pixel size . These data will assist us improve our knowing about the performance of the instrument as also as give valuable info for future orbital flights .Keywords : Space mission , Focal correction , Point spread value , Ray tracing investigation , Infrared astronomy , Infrared camera",
        "rewrite_text": "We have performed in-orbit lens adjustments (IFA) on the infrared camera aboard the AKARI satellite using data acquired during its mission. The IFA process involved comparing the observed point spread function (PSF) with a simulated PSF generated through ray tracing imaging, which is a highly precise method for determining the optimal viewpoint. Despite completing the IFA, we found that the PSFs did not align consistently across different frequencies. This discrepancy may be attributed to potential issues in the optical design or manufacturing process. Additionally, we identified ongoing challenges regarding the calibration accuracy of sensor pixel sizes. The insights gained from this data will enhance our understanding of the instrument's performance and provide valuable information for future space missions. \n\nKeywords: Space mission, Focal correction, Point spread function, Ray tracing analysis, Infrared astronomy, Infrared camera.",
        "ori-fast-z-score": -0.8307471607356973,
        "water-fast-z-score": 6.052586456788652,
        "rewrite-fast-z-score": 1.1952286093343936
    },
    {
        "original_text": "We present the first results on the soft X-ray emission in two nearby elliptical galaxies, NGC 2992 (M60) and NGC 3081 (M84). The observations were made with the Chandra X-Ray Observatory using the Advanced CCD Imaging Spectrometer (ACIS-S3), which has an energy resolution of about 130 eV at 6 keV. We find that both galaxies show extended diffuse emission around their central regions. In addition, we detect several point sources within each galaxy s field-of-view. For these point sources, we have extracted spectra for individual source components as well as combined them into one spectrum per galaxy. Using spectral fitting techniques, we found that all but three of the detected point sources are consistent with being background AGNs or foreground stars. However, there is evidence that some of the brightest point sources may be associated with the host galaxies themselves. Finally, we also fit the diffuse component of the X-ray emission with thermal plasma models.",
        "watermark_text": "We present the first findings on the soft X - ray radiation in two nearby elliptical galaxies , NGC 2992 ( M60 ) and NGC 3081 ( M84 ) . The findings were made with the Chandra X - Ray Observatory using the Advanced CCD Imaging Spectrometer ( ACIS - S3 ) , which has an energy resolution of about 130 eV at 6 keV .We see that both nuclei display extended diffuse emission around their central regions . In addition , we locate many point sources within each galaxy s field - of - view .For these point sources , we have gathered spectra for individual source components as well as blended them into one spectrum per galaxy . Using spectral fitting methods , we concluded that all but three of the recovered point sources are consistent with being background AGNs or foreground stars .However , there is evidence that some of the brightest point sources might be identified with the host galaxies themselves . Finally , we also fitted the diffuse component of the X - ray radiation with thermal plasma estimates .",
        "rewrite_text": "We report the initial findings on soft X-ray radiation from two nearby elliptical galaxies, NGC 2992 (M60) and NGC 3081 (M84). These observations were conducted using the Chandra X-Ray Observatory's Advanced CCD Imaging Spectrometer (ACIS-S3), which has an energy resolution of approximately 130 eV at 6 keV. Our analysis reveals that both galaxies exhibit extended diffuse emission around their nuclei. Additionally, we identified numerous point sources within each galaxy's field of view. For these point sources, we collected individual spectra as well as combined spectra for each galaxy. Through spectral fitting techniques, we determined that nearly all recovered point sources can be attributed to background AGNs or foreground stars, with the exception of three sources. Notably, some of the brightest point sources may correspond to the host galaxies themselves. Lastly, we also fitted the diffuse X-ray radiation component using thermal plasma models.",
        "ori-fast-z-score": -1.116312611302876,
        "water-fast-z-score": 3.3489378339086286,
        "rewrite-fast-z-score": 0.5
    },
    {
        "original_text": "The following is an excerpt from the author s thesis, which can be downloaded at http://arxiv.org/abs/1306.5189. \n \n The formula evaluation problem for propositional logic formulas in conjunctive normal form (CNF) has been studied extensively and many efficient algorithms have been developed. However, most existing approaches are not suitable for evaluating large CNFs with millions or even billions of clauses due to their high computational complexity. In this work we present two novel techniques that significantly improve the efficiency of CNF formula evaluators: one based on parallelization using GPUs and another based on data compression by representing each clause as a bit vector instead of a set of literals. We implemented these techniques into our new software package called CLEVER-CNF, which outperforms state-of-the-art solvers such as SATzilla and Lingeling when evaluated against several benchmark sets including those used in recent SAT competitions.",
        "watermark_text": "The following is an excerpt from the writer s thesis , which can be downloaded at http : / / arxiv . org / abs / 1306 . 5189 . The formula evaluation problem for propositional logic formulas in conjunctive normal form ( CNF ) has been studied thoroughly and many efficient methods have been built .However , most existing techniques are not suitable for evaluating large CNFs with thousands or maybe billions of clauses due to their high computational complexity . In this research we present two novel techniques that significantly improve the performance of CNF formula evaluators : one based on parallelization use GPUs and another based on data encoding by representing each sentence as a bit vector rather of a group of literals .We introduced these techniques into our new software suite named CLEVER - CNF , which outperforms state - of - the - art solvers such as SATzilla and Lingeling when evaluated against several benchmark sets including those utilized in recent SAT tests .",
        "rewrite_text": "This excerpt is taken from the author's thesis, which is available for download at http://arxiv.org/abs/1306.5189. The evaluation of propositional logic formulas in conjunctive normal form (CNF) has been extensively researched, leading to the development of many efficient methodologies. However, most of these existing techniques struggle to handle large CNF formulas containing thousands or even billions of clauses due to their high computational demands. In this study, we introduce two innovative techniques that enhance the performance of CNF formula evaluators: one leverages parallel processing using GPUs, while the other employs data encoding by representing each sentence as a bit vector instead of a collection of literals. We have integrated these techniques into a new software suite called CLEVER-CNF, which surpasses state-of-the-art solvers like SATzilla and Lingeling in performance when tested against several benchmark sets, including those used in recent SAT competitions.",
        "ori-fast-z-score": -0.629940788348712,
        "water-fast-z-score": 4.25,
        "rewrite-fast-z-score": 1.25
    },
    {
        "original_text": "We present the results of our analysis on the statistical properties of dust FIR emission in nearby galaxies, based on data obtained by ISO and Spitzer space telescopes. We find that the distribution function of dust FIR luminosity is well described by a log-normal form with an exponential tail at high luminosities. The mean value of the logarithmic luminosity dispersion for all samples considered here is 0.3 dex (factor of 2). This result suggests that there are two populations of dusty star-forming regions within each galaxy -one population associated with normal star formation activity and another one associated with intense bursts of star formation. Our study also shows that the fraction of galaxies containing such extreme objects increases towards higher redshifts. These findings have important implications for understanding the physical processes responsible for the evolution of distant galaxies as well as their contribution to the cosmic infrared background radiation. \n \n Keywords: Infrared, Galaxy",
        "watermark_text": "We present the conclusion of our analysis on the statistical characteristics of dust FIR pollution in nearby galaxies , using on evidence derived by ISO and Spitzer space telescopes . We see that the distribution function of dust FIR luminosity is well described by a log - normal shape with an exponential tail at high luminosities .The mean value of the logarithmic luminosity dispersion for all specimens considered here is 0 . 3 dex ( factor of 2 ) . This result suggests that there are two communities of dusty star - creating areas within each galaxy - one community associated with normal star formation activity and another one linked with aggressive bursts of galaxy formation .Our study also shows that the fraction of stars bearing such extreme objects increases towards higher redshifts . These studies have important implications for studying the physical processes responsible for the evolution of distant galaxies as also as their impact to the cosmic infrared background radiation .Keywords: Infrared, Galaxy",
        "rewrite_text": "In this analysis, we summarize our findings on the statistical properties of dust FIR pollution in nearby galaxies, based on data obtained from the ISO and Spitzer space telescopes. Our results reveal that the distribution function of dust FIR luminosity follows a log-normal distribution, characterized by an exponential tail at high luminosities. The average logarithmic luminosity dispersion for all galaxies analyzed is 0.3 dex (equivalent to a factor of 2). This indicates the existence of two distinct communities of dusty star-forming regions within each galaxy: one linked to standard star formation and the other associated with vigorous bursts of galaxy formation. Furthermore, our study demonstrates that the prevalence of stars harboring such extreme objects increases with higher redshifts. These findings have significant implications for understanding the physical processes driving the evolution of distant galaxies and their contribution to the cosmic infrared background radiation. Keywords: Infrared, Galaxy.",
        "ori-fast-z-score": 0.3464101615137754,
        "water-fast-z-score": 5.427092530382482,
        "rewrite-fast-z-score": 0.9561828874675149
    },
    {
        "original_text": "We present proper motions for stars with magnitudes between 8 and 16, obtained by combining data from two epochs of photographic plates taken at the Palomar Observatory (POSS-I) and one epoch of digital images taken with the Hubble Space Telescope (HST). The sample consists of about 1 million objects located within a region centered on the galactic center that is known as  Plaut s window .  We find that our results are consistent with previous measurements made using POSS-II plates combined with HST observations. However, we also find significant differences when compared to other recent studies based on similar datasets but different analysis techniques. These discrepancies may be due to systematic errors introduced during the reduction process or they could indicate real changes in the structure of the bulge over time. Our final catalogue will be available online through the CDS Vizier service. This work was supported by NASA grant NAG5-13523.",
        "watermark_text": "We present proper motions for stars with magnitudes between 8 and 16 , obtained by combining information from two epochs of photographic sheets taken at the Palomar Observatory ( POSS - I ) and one epoch of digital photographs took with the Hubble Space Telescope ( HST ) . The sample consists of about 1 million items located within a region focused on the galactic center that is known as Plaut s window .We see that our findings are compatible with previous measurements made use POSS - II plates combined with HST observations . However , we also find considerable variations when compared to other recent studies relying on similar datasets but different analysis methods .These discrepancies may be due to systematic errors acquired during the reduction phase or they may indicate real shifts in the composition of the bulge over time . Our last catalogue will be available digital through the CDS Vizier network .This project was supported by NASA gift NAG5 - 13523 .",
        "rewrite_text": "We present proper motions for stars with magnitudes ranging from 8 to 16, derived from data collected at two different epochs using photographic plates from the Palomar Observatory (POSS-I) and one epoch of digital images captured by the Hubble Space Telescope (HST). The study sample comprises approximately 1 million stars located within a region centered on the galactic core, commonly referred to as Plaut's window. Our results align with prior measurements obtained using POSS-II plates in conjunction with HST observations. However, we noted significant discrepancies when compared to other recent studies that utilized similar datasets but employed different analysis techniques. These differences could arise from systematic errors during the data reduction process or may reflect actual changes in the composition of the bulge over time. Our final catalog will be available digitally through the CDS Vizier network. This research was supported by NASA grant NAG5-13523.",
        "ori-fast-z-score": 0.24618298195866545,
        "water-fast-z-score": 6.077701994871215,
        "rewrite-fast-z-score": -1.5650160901149996
    },
    {
        "original_text": "We report an experimental realization of a novel type of 3D Brownian motors based on colloidal particles trapped in periodic potentials created by laser interference patterns. The potential landscape is engineered to have two different types of local minima separated by barriers with varying heights and widths. We show that this design allows for controlling both directional transport as well as its speed over several orders of magnitude. This work opens up new possibilities for designing active materials with tunable properties. A growing number of applications require systems capable of converting energy into directed motion at low Reynolds numbers  1  . In recent years, there has been significant progress towards realizing such devices known as  Brownian motors   2  , which are typically composed of many interacting particles moving through complex environments  3  .\nIn particular, it was shown theoretically  4  and experimentally  5  that one can create a unidirectional current of colloids using optical traps arranged in a 2D square or honeycomb pattern  6  . However, these designs cannot be easily extended to three dimensions (3D) due to technical limitations associated with creating stable trapping sites  7, 8  . Here we demonstrate how to overcome those challenges by engineering the shape of the potential wells and barriers in order to achieve robust 3D transport. Our approach relies on the use of holographic optical tweezers  9  to trap polystyrene microspheres suspended in water inside a glass capillary tube  10  . By changing the phase between the beams forming each individual trap  11  , we were able to generate a variety of potential landscapes  12  ranging from simple double-well structures  13  to more complicated ones containing multiple barriers  14  .",
        "watermark_text": "We report an research realization of a new kind of 3D Brownian motors based on colloidal particles caught in periodic potentials created by laser interference patterns . The potential landscape is designed to have two different kinds of local minima separated by barriers with varying heights and widths .We see that this design allows for controlling both directional travel as well as its velocity over several orders of magnitude . This project opens up new possibilities for designing active materials with tunable properties .A growing number of applications need devices capable of converting energy into guided motion at low Reynolds value 1 . In past decades , there has been significant progress towards realizing such machines called as Brownian cars 2 , which are typically consists of several interacting molecules moving through complex environments 3 .In particular , it was shown theoretically 4 and experimentally 5 that one can create a unidirectional current of colloids using optical trapping ordered in a 2D square or honeycomb shape 6 . However , these designs cannot be easily enlarged to three dimensions ( 3D ) due to technical restrictions associated with creating stable trap places 7 , 8 .Here we prove how to overcome those obstacles by designing the form of the potential reservoirs and barriers in order to achieve robust 3D transport . Our solution uses on the using of holographic optical tweezers 9 to capture polystyrene microspheres hanging in water inside a glass capillary frame 10 .By changing the phase between the beams making each individual trap 11 , we were could to produce a variety of potential landscapes 12 ranging from basic double - well complexes 13 to more complicated ones featuring multiple barriers 14 .",
        "rewrite_text": "We present a groundbreaking realization of a novel type of 3D Brownian motors utilizing colloidal particles trapped within periodic potentials generated by laser interference patterns. The constructed potential landscape features two distinct local minima, separated by barriers of varying heights and widths. This innovative design facilitates control over both the direction of travel and the velocity, spanning several orders of magnitude. This project paves the way for the development of active materials with adjustable properties. There is an increasing need for devices capable of transforming energy into directed motion at low Reynolds numbers. In recent decades, significant advancements have been made towards creating such machines, commonly referred to as Brownian cars, which typically consist of numerous interacting molecules navigating through complex environments. Theoretical and experimental studies have demonstrated the feasibility of generating a unidirectional flow of colloidal particles utilizing optical trapping arranged in 2D square or honeycomb formations. However, scaling these designs to three dimensions (3D) has been challenging due to technical limitations in establishing stable trapping configurations. Here, we demonstrate a method to overcome these challenges by strategically designing the shapes of potential reservoirs and barriers to enable reliable 3D transport. Our approach employs holographic optical tweezers to capture polystyrene microspheres suspended in water within a glass capillary frame. By adjusting the phase of the beams that create each individual trap, we can generate a variety of potential landscapes, ranging from simple double-well configurations to more complex structures featuring multiple barriers.",
        "ori-fast-z-score": -0.17025130615174972,
        "water-fast-z-score": 6.810052246069989,
        "rewrite-fast-z-score": 1.4852968963237645
    },
    {
        "original_text": "We study the minimal size of a barchan, which is one of the most common types of sand dunes in nature. We show that this problem can be formulated as an optimal control problem for a nonlinear partial differential equation with nonlocal boundary conditions and prove existence of solutions by using variational methods. The numerical results are obtained by applying finite element method to discretize the state equations and then solving them by Newton s iteration scheme. Finally we present some examples illustrating our theoretical findings. Sand dunes are among the most beautiful natural phenomena on Earth. They have been studied extensively since the 19th century  1  . One of the simplest forms of sand dunes is called barchan  2  , see Figure 1 (a). It has a crescent shape with its horns pointing away from the wind direction. Barchans occur naturally over large areas around the world such as Australia  3  , Namibia  4  , Saudi Arabia  5  , China  6  , Japan  7  , etc.. In recent years there has been growing interest in studying mathematical models describing formation of sand dunes  8, 9, 10  .\nIn this work we consider the following model proposed by Kroy et al  11  : \nwhere u(x) denotes the height of the sand bed at position x ∈ Ω =  0, L  × R + ; f > 0 represents the rate of deposition; g ≥ 0 stands for the erosion coefficient; h(u) describes the effect of surface tension; p(x), q(x) represent the pressure terms due to gravity and friction respectively; α > 0 measures the strength of the wind blowing along x-axis; β > 0 characterizes the resistance against the flow of air; γ > 0 is related to the cohesion between grains of sand; θ is the angle of repose of sand particles; c > 0 is the constant volume fraction of sand per unit area; finally, n is the outward normal vector to the boundary Γ = {0 < x < L} × {0} ∪ {L} × R + . For more details about physical meaning of parameters involved in system (1) , please refer to  12  .",
        "watermark_text": "We research the reduced size of a barchan , which is one of the most common kinds of beach dunes in nature . We see that this question can be formulated as an optimal control problem for a nonlinear partial differential function with nonlocal boundary constraints and prove existence of solutions by using variational techniques .The mathematical findings are derived by using finite element method to discretize the state equations and then solving them by Newton s iteration scheme . Finally we present some examples illustrating our theory findings .Sand dunes are among the most beautiful natural creatures on Earth . They have been studied thoroughly since the 19th century 1 .One of the simplest forms of dunes dunes is known barchan 2 , see Figure 1 ( a ) . It has a crescent shape with its horns pointing away from the wind position .Barchans occur naturally over large areas around the world such as Australia 3 , Namibia 4 , Saudi Arabia 5 , China 6 , Japan 7 , etc . . In recent years there has been growing interest in studying numerical models explaining formation of dunes dunes 8 , 9 , 10 .In this study we consider the following model proposed by Kroy et al 11 : where u ( x ) denotes the height of the sand bed at position x ∈ Ω = 0 , L × R + ; f > 0 represents the speed of deposition ; g ≥ 0 stands for the erosion factor ; h ( u ) refers the impact of surface friction ; p ( x ) , q ( x ) describe the pressure terms due to gravity and tension respectively ; α > 0 measures the strength of the wind blowing along x - axis ; β > 0 characterizes the tolerance against the movement of air ; γ > 0 is related to the cohesion between particles of dust ; θ is the angle of repose of dust particles ; c > 0 is the constant volume fraction of dunes per unit area ; finally , n is the outward normal vector to the boundary Γ = { 0 < x < L } × { 0 } ∪ { L } × R + . For more details about physical meaning of components concerned in system ( 1 ) , please refer to 12 .",
        "rewrite_text": "We investigate the reduced size of a barchan, one of the most prevalent types of beach dunes found in nature. This inquiry can be framed as an optimal control problem involving a nonlinear partial differential equation with nonlocal boundary conditions. We establish the existence of solutions using variational methods. Our mathematical analysis employs the finite element method to discretize the state equations, followed by their resolution through Newton's iteration scheme. We also provide several examples that illustrate our theoretical findings. Sand dunes are among the most stunning natural formations on Earth and have been extensively studied since the 19th century. One of the simplest forms of these dunes is the barchan, characterized by its crescent shape with horns extending away from the wind. Barchans can be found across various regions globally, including Australia, Namibia, Saudi Arabia, China, and Japan. Recently, there has been increased interest in developing numerical models to explain dune formation. In this study, we focus on the model introduced by Kroy et al., where \\( u(x) \\) represents the height of the sand bed at the position \\( x \\in \\Omega = (0, L) \\times \\mathbb{R}^{+} \\); \\( f > 0 \\) denotes the deposition speed; \\( g \\geq 0 \\) indicates the erosion factor; \\( h(u) \\) reflects the effects of surface friction; \\( p(x) \\) and \\( q(x) \\) account for pressure from gravity and tension, respectively; \\( \\alpha > 0 \\) measures the wind's strength along the x-axis; \\( \\beta > 0 \\) signifies resistance to air movement; \\( \\gamma > 0 \\) represents cohesion between dust particles; \\( \\theta \\) is the angle of repose for the dust; \\( c > 0 \\) indicates the constant volume fraction of dunes per unit area; and \\( n \\) is the outward normal vector to the boundary \\( \\Gamma = \\{ (0 < x < L) \\times \\{0\\} \\} \\cup \\{ (L) \\times \\mathbb{R}^{+} \\} \\). For a detailed discussion regarding the physical significance of these components in the system, please refer to source [12].",
        "ori-fast-z-score": -0.9072647087265548,
        "water-fast-z-score": 5.793241220216576,
        "rewrite-fast-z-score": 1.643989873053573
    },
    {
        "original_text": "We present new near-infrared (NIR) and millimeter-wave observations of the starless dense core FeSt 1-457, which is located in the Taurus molecular cloud complex at a distance of 140 pc. The NIR data were obtained with the Subaru telescope using the SofI instrument on 2005 May 24-25 UT. We detected two sources within the central 0.5 arcmin region; one source was found to be associated with an infrared dark cloud (IRDC), while another source was not. Both sources are embedded deeply inside the dusty envelope surrounding the dense core. In addition, we observed this object simultaneously with the Nobeyama 45 m radio telescope at 1 mm wavelength during the same night as our NIR observation. No significant emission line features were seen in either spectrum. Using these observational results, we discuss possible scenarios for the formation of stars in such a young dense core.",
        "watermark_text": "We report new near - infrared ( NIR ) and millimeter - wave studies of the starless rich core FeSt 1 - 457 , which is situated in the Taurus molecular mist complex at a distance of 140 pc . The NIR data were obtained with the Subaru observatory using the SofI camera on 2005 May 24 - 25 UT .We observed two sources within the inner 0 . 5 arcmin region ; one source was reported to be involved with an infrared shadow cloud ( IRDC ) , while another source was not . Both sources are lodged deeply inside the dusty envelope surrounding the dense core .In addition , we studied this body simultaneously with the Nobeyama 45 m radio telescope at 1 mm frequency during the same night as our NIR observation . No notable emission line characteristics were witnessed in either spectrum .Using these observational results , we explain possible strategies for the formation of stars in such a young dense core .",
        "rewrite_text": "We present new near-infrared (NIR) and millimeter-wave observations of the starless, dense core FeSt 1-457, located within the Taurus molecular cloud complex at a distance of 140 parsecs. The NIR data were collected using the SofI camera at the Subaru Observatory on May 24-25, 2005. Within the inner 0.5 arcminute region, we identified two sources; one is associated with an infrared dark cloud (IRDC), while the other is not. Both sources are situated deep within the dusty envelope enveloping the dense core. Additionally, we conducted simultaneous observations with the Nobeyama 45 m radio telescope at a frequency of 1 mm on the same night as our NIR study. We did not detect any significant emission line features in either spectrum. Based on these observational findings, we discuss potential mechanisms for star formation in this young, dense core.",
        "ori-fast-z-score": -0.8962581595302719,
        "water-fast-z-score": 4.572004572006858,
        "rewrite-fast-z-score": 1.7529196424044293
    },
    {
        "original_text": "The brain is an organ that has evolved to be dynamic and plastic, constantly changing its structure in response to internal and external stimuli.  The human brain can change throughout life by forming new connections between neurons or eliminating existing ones.   This ability allows humans to adapt to their environment and learn continuously.   However, this flexibility also makes it vulnerable to damage caused by disease, trauma, aging, etc., which may lead to neurological disorders such as Alzheimer s Disease, Parkinson s Disease, Huntington s Disease, Epilepsy, Traumatic Brain Injury, Multiple Sclerosis, etc.   In recent years there have been significant advances in neuroscience research aimed at understanding how the brain works and developing treatments for these diseases.   One approach involves using neural prosthetic devices to replace damaged parts of the brain with artificial components that are capable of performing similar functions.   Neural prosthetics are electronic systems designed to interface directly with the nervous system to restore lost function due to injury or disease.   These devices include microelectrodes implanted into the brain tissue to record electrical activity; stimulating electrodes placed on or near nerves to deliver electrical stimulation; and wireless communication links used to transmit data recorded by the recording electrodes and/or control signals generated by the stimulating electrodes back to a computer located outside the body.   ...",
        "watermark_text": "The mind is an organ that has evolution to be dynamic and plastic , constantly shifting its composition in reaction to internal and external stimuli . The human mind can shift throughout life by forming fresh connections between brains or eliminating existing ones .This skill allows individuals to adapt to their environment and learn continuously . However , this flexibility still makes it susceptible to disruption caused by illness , trauma , aging , etc . , which sometimes lead to neurological disorders such as Alzheimer s Disease , Parkinson s Disease , Huntington s Disease , Epilepsy , Traumatic Brain Injury , Multiple Sclerosis , etc .In past decades there have been significant advances in neuroscience work aiming at studying how the brain acts and developing treatments for these diseases . One approach involves utilizing neural prosthetic devices to replace injured parts of the brain with artificial components that are capable of executing identical functions .Neural prosthetics are electronic systems designed to interface directly with the nervous system to restore lost activity resulting to trauma or disease . These systems include microelectrodes implanted into the brain skin to track electrical behavior ; stimulating electrodes put on or close muscle to provide electrical stimulation ; and wireless communication connections utilized to transmit data produced by the recording electrodes and / or control messages produced by the stimulating electrodes forward to a computer situated outside the brain ....",
        "rewrite_text": "The mind is an organ that has evolved to be dynamic and adaptable, consistently altering its structure in response to both internal and external stimuli. Throughout life, the human mind can change by forming new connections between neurons or discarding existing ones. This adaptability enables individuals to respond to their environments and engage in continuous learning. However, this flexibility also leaves the mind vulnerable to disruptions caused by illness, trauma, aging, and other factors, which can sometimes result in neurological disorders like Alzheimer’s disease, Parkinson’s disease, Huntington’s disease, epilepsy, traumatic brain injury, and multiple sclerosis. In recent decades, there have been significant advancements in neuroscience aimed at understanding brain function and developing treatments for these conditions. One promising approach involves the use of neural prosthetic devices, which can replace damaged areas of the brain with artificial components that perform similar functions. Neural prosthetics are electronic systems designed to connect directly with the nervous system in order to restore lost activity resulting from trauma or disease. These systems may include microelectrodes implanted in the brain to monitor electrical activity, stimulating electrodes placed on or near muscles to provide electrical stimulation, and wireless communication links to transmit data from recording electrodes and control signals from stimulating electrodes to an external computer.",
        "ori-fast-z-score": -1.2339053944782488,
        "water-fast-z-score": 7.627700713964739,
        "rewrite-fast-z-score": 0.7627700713964739
    },
    {
        "original_text": "We discuss how chiral symmetry is realized in QCD, with particular emphasis on its implications for the spectrum of excited states. We argue that the lowest-lying excitations are described by open strings attached to quarks at one end and antiquarks at the other; these can be viewed as mesons or glueballs depending on whether they carry color charge or not.  The next set of excitations corresponds to closed strings which wind around the compactified dimension (the time direction) once or more times. These correspond to baryon resonances. Finally we consider higher-spin excitations corresponding to multiple winding modes of the closed string; these have spin greater than two but still less than the number of colors Nc. In this talk I will present some recent results obtained using holographic methods applied to gauge theories dual to supergravity backgrounds. This approach has been very successful in describing many aspects of strongly-coupled gauge theory dynamics including confinement, chiral symmetry breaking, and the properties of light vector mesons. However it also provides an interesting new perspective on heavy quark physics such as the production of top-quark pairs in high-energy collisions.",
        "watermark_text": "We discuss how chiral symmetry is realized in QCD , with particular focusing on its consequences for the spectrum of excited states . We argue that the smallest - lying excitations are explained by open strings attached to quarks at one end and antiquarks at the other ; these can be viewed as mesons or glueballs depending on whether they carry color energy or not .The next set of excitations corresponds to closed strings which wind around the compactified dimension ( the time direction ) once or more times . These correspond to baryon resonances .Finally we study greater - spinning excitations corresponding to multiple winding modes of the shut string ; these have spin greater than two but still less than the number of colors Nc . In this talk I will present some latest findings obtained using holographic methods applied to gauge fields dual to supergravity environments .This method has been very effective in understanding several elements of highly - coupled gauge theory physics including confinement , chiral symmetry breaking , and the properties of light vector mesons . However it also provides an interesting recent perspective on heavy quark theory such as the production of top - quark pairs in high - energy collisions .",
        "rewrite_text": "In this discussion, we explore the realization of chiral symmetry in Quantum Chromodynamics (QCD), with a particular emphasis on its implications for the spectrum of excited states. We propose that the lowest-lying excitations can be understood as open strings, one end attached to quarks and the other to antiquarks. Depending on whether these strings carry color energy, they can be interpreted as either mesons or glueballs. The next category of excitations consists of closed strings that loop around the compactified dimension (representing time) one or more times, correlating with baryon resonances. Additionally, we examine higher-spin excitations associated with multiple winding modes of the closed string, which possess spin greater than two but remain below the number of colors, \\(N_c\\). In this presentation, I will share the latest findings derived from holographic techniques applied to gauge fields that correspond to supergravity settings. This approach has proven highly effective in elucidating various aspects of strongly coupled gauge theory phenomena, including confinement, chiral symmetry breaking, and the characteristics of light vector mesons. Moreover, it offers intriguing new insights into heavy quark physics, such as the production of top-quark pairs in high-energy collisions.",
        "ori-fast-z-score": 1.8973665961010275,
        "water-fast-z-score": 6.324555320336758,
        "rewrite-fast-z-score": 1.0540925533894598
    },
    {
        "original_text": "We present new observational constraints on the cosmic ray (CR) energy density and its evolution with redshift, based on gamma-ray observations by Fermi/LAT in the range 0 < z < 1.5. We find that CRs contribute at most 10% to the total pressure budget of the universe at redshifts below 2. This upper limit is consistent with theoretical expectations for the contribution of CRs accelerated by supernovae. The results are also compatible with previous measurements using radio data. These limits can be used as priors when modeling the effects of CRs on cosmological observables such as galaxy clustering or weak lensing. Cosmic rays (CRs), charged particles which fill space uniformly over large volumes, have been observed throughout our Galaxy and beyond. They play an important role in many astrophysical phenomena including galactic winds, star formation, and possibly even the acceleration of ultra-high-energy cosmic rays  1  . However, their origin remains unknown  2  .\nIn this work we use gamma-ray observations made by the Large Area Telescope (LAT) aboard the Fermi satellite  3  , to place tight constraints on the amount of CRs contributing to the overall pressure budget of the Universe  4  . In particular, we consider two different models for the CR distribution function f(p,z). First, we assume that it follows a power law spectrum dN/dE ~ E^{-alpha} between energies Emin = 10 GeV and Emax = 100 TeV; secondly, we adopt a broken power-law model where the spectral index changes from alpha1 = -2.2 to alpha2 = -3 above some break energy Eb = 50 GeV. For both cases, we fix the normalization factor A by requiring that the integral of f(p,z) over all momenta equals unity. \nThe resulting CR distributions are shown in Figure 1 . \nTo calculate the effect of these CR populations on the expansion history of the universe, we solve numerically the coupled system of equations describing the time-evolution of the background...",
        "watermark_text": "We introduce novel observational restrictions on the cosmic ray ( CR ) energy density and its progression with redshift , using on gamma - ray observations by Fermi / LAT in the range 0 < z < 1 . 5 . We see that CRs contribute at most 10 % to the total pressure budget of the universe at redshifts below 2 .This upper maximum is compatible with theoretical expectations for the impact of CRs accelerated by supernovae . The results are also consistent with previous measurements involving radio data .These restrictions can be used as priors when modeling the effects of CRs on cosmological observables such as galaxy clustering or strong lensing . Cosmic rays ( CRs ) , charged particles which fill space uniformly over large quantities , have been observed throughout our Galaxy and beyond .They play an important role in different astrophysical processes including galactic winds , sun formation , and maybe even the acceleration of ultra - large - energy cosmic rays 1 . However , their source remains unidentified 2 .In this research we utilize gamma - ray observations made by the Large Area Telescope ( LAT ) aboard the Fermi satellite 3 , to place secure constraints on the proportion of CRs causing to the overall pressure budget of the Universe 4 . In particular , we consider two different models for the CR distribution relation h ( p , z ) .First , we suppose that it takes a power law spectrum dN / dE ~ E ^ { - alpha } between frequencies Emin = 10 GeV and Emax = 100 TeV ; secondly , we adopt a broken power - law description where the spectral index shifts from alpha1 = - 2 . 2 to alpha2 = - 3 above some broken power Eb = 50 GeV . For both cases , we solve the normalization factor A by requiring that the integral of f ( p , z ) over all momenta equals unity .The resulting CR variables are shown in Figure 1 . To estimate the impact of these CR populations on the expansion history of the universe , we solve numerically the coupled system of equations explaining the period - progression of the background . . .",
        "rewrite_text": "We present new observational constraints on the energy density of cosmic rays (CRs) and how it changes with redshift, utilizing gamma-ray data from the Fermi/LAT in the range of 0 < z < 1.5. Our analysis reveals that CRs account for a maximum of 10% of the total pressure budget of the universe at redshifts below 2. This maximum is consistent with theoretical predictions regarding the effects of CRs accelerated by supernovae. Furthermore, our findings align with previous measurements derived from radio data. These constraints can serve as useful priors when modeling the influence of CRs on cosmological observations like galaxy clustering or strong lensing. Cosmic rays, which are charged particles that uniformly permeate space in large quantities, have been detected both within our Galaxy and in distant regions. They are crucial in various astrophysical processes, including galactic winds, star formation, and potentially the acceleration of ultra-high-energy cosmic rays. However, their origins remain unidentified. In this study, we utilize gamma-ray observations from the Large Area Telescope (LAT) aboard the Fermi satellite to impose stringent constraints on the contribution of CRs to the universe's overall pressure budget. Specifically, we explore two different models for the CR distribution relationship h(p, z). First, we assume a power-law spectrum described by dN/dE ~ E^{-α} from the frequency range Emin = 10 GeV to Emax = 100 TeV. Second, we consider a broken power-law model where the spectral index transitions from α1 = -2.2 to α2 = -3 above a breakpoint energy Eb = 50 GeV. In both cases, we determine the normalization factor A by ensuring the integral of f(p, z) over all momenta equals one. The resulting CR parameters are illustrated in Figure 1. To evaluate the impact of these CR populations on the universe's expansion history, we numerically solve the coupled equations that describe the evolution of the background.",
        "ori-fast-z-score": 1.0215078369104984,
        "water-fast-z-score": 8.342314001435737,
        "rewrite-fast-z-score": 2.088931871468374
    },
    {
        "original_text": "The physisorption of nucleobases (adenine, cytosine, guanine and thymine) onto graphene is investigated by density functional theory calculations at the B3LYP/6-31G(d) level in vacuum conditions. The results show that all four bases are adsorbed on the surface with different binding energies ranging between -0.27 eV for adenine to -1.10 eV for cytosine. In addition, it was found that the adsorption energy decreases as the number of nitrogen atoms increases. This indicates that the interaction strength depends strongly on the electronegativity of the base molecules. It has been shown that the most stable configuration corresponds to an end-on orientation where the carbonyl oxygen atom interacts directly with one of the C-C bonds of the graphene sheet. \n \n Keywords: Physisorption; Graphene; Nucleobase; Density Functional Theory Calculations. Introduction \n \n Graphene is a two-dimensional material consisting of sp2-hybridized carbon atoms arranged into a honeycomb lattice structure  1  . Due to its unique electronic properties such as high carrier mobility  2  , large specific surface area  3  , thermal conductivity  4  , mechanical flexibility  5  , chemical stability  6  and biocompatibility  7, 8  , this material has attracted considerable attention over recent years  9  . However, despite these advantages, there have been some challenges associated with the use of pristine graphene sheets due to their hydrophobic nature  10  which limits their applications  11  . Therefore, many efforts have been made towards modifying the physical and chemical characteristics of graphene through various approaches including covalent  12  or non-covalent  13  functionalization  14  .\n \nIn particular, non-covalent functionalization can be achieved via π-π interactions  15  , hydrogen bonding  16  , electrostatic  17  , van der Waals  18  and ionic  19  forces  20  . Among them, π-π stacking is considered to be the strongest noncovalent force  21  . For example, several studies have reported that aromatic compounds  22  , fullerenes  23  , porphyrins  24  , metal complexes  25  and biomolecules  26  could interact with graphene surfaces via π-",
        "watermark_text": "The physisorption of nucleobases ( adenine , cytosine , guanine and thymine ) onto graphene is investigated by density functional theory analyses at the B3LYP / 6 - 31G ( d ) level in vacuum environments . The results show that all four bases are adsorbed on the surface with various binding frequencies ranging between - 0 . 27 eV for adenine to - 1 . 10 eV for cytosine .In addition , it was shown that the adsorption energy decreases as the number of nitrogen atoms increases . This implies that the interaction strength depends strongly on the electronegativity of the base atoms .It has been shown that the most stable configuration relates to an ending - on position where the carbonyl oxygen element interacts closely with one of the C - C bonds of the graphene sheet . Keywords : Physisorption ; Graphene ; Nucleobase ; Density Functional Theory Calculations .Introduction Graphene is a two - dimensional material consisting of sp2 - hybridized carbon atoms arranged into a honeycomb lattice structure 1 . Due to its unique electronic properties such as wide carrier density 2 , large specific surface region 3 , thermal conductivity 4 , electronic flexibility 5 , chemical integrity 6 and biocompatibility 7 , 8 , this metal has garnered considerable focus over recent years 9 .However , despite these benefits , there have been some challenges associated with the using of pristine graphene strips due to their hydrophobic properties 10 which restricted their functionality 11 . Therefore , various efforts have been placed towards modifying the physical and biological qualities of graphene through several methods namely covalent 12 or non - covalent 13 functionalization 14 .In particular , non - covalent functionalization can be obtained via π - π interactions 15 , hydrogen bonding 16 , electrostatic 17 , van der Waals 18 and ionic 19 forces 20 . Among them , π - π stacking is regarded to be the greatest noncovalent force 21 .For instance , various trials have reported that aromatic molecules 22 , fullerenes 23 , porphyrins 24 , metal ions 25 and biomolecules 26 could interact with graphene surfaces via π -",
        "rewrite_text": "The physisorption of nucleobases (adenine, cytosine, guanine, and thymine) onto graphene has been examined using density functional theory (DFT) at the B3LYP/6-31G(d) level in vacuum conditions. The findings indicate that all four nucleobases are adsorbed onto the graphene surface, with binding energies ranging from -0.27 eV for adenine to -1.10 eV for cytosine. Additionally, the results suggest that the adsorption energy decreases with an increasing number of nitrogen atoms, indicating that the strength of interaction is strongly influenced by the electronegativity of the atoms within the bases. The most stable configuration is observed in an end-on position, where the carbonyl oxygen forms a close interaction with one of the C-C bonds in the graphene sheet. \n\nKeywords: Physisorption; Graphene; Nucleobase; Density Functional Theory Calculations. \n\nIntroduction: Graphene is a two-dimensional material made up of sp²-hybridized carbon atoms arranged in a honeycomb lattice. Due to its unique electronic characteristics—such as a broad carrier density, large specific surface area, high thermal conductivity, electronic flexibility, chemical stability, and biocompatibility—this material has gained significant attention in recent years. Despite these advantages, the use of pristine graphene strips has faced some challenges due to their hydrophobic nature, limiting their functionality. Consequently, considerable efforts have been directed towards enhancing the physical and biological properties of graphene through various modification techniques, including both covalent and non-covalent functionalization. In particular, non-covalent functionalization can occur via π-π interactions, hydrogen bonding, electrostatic forces, van der Waals forces, and ionic interactions. Among these, π-π stacking is considered the most significant non-covalent force. Numerous studies have documented that aromatic molecules, fullerenes, porphyrins, metal ions, and biomolecules can interact with graphene surfaces through π-π interactions.",
        "ori-fast-z-score": 0.09325048082403138,
        "water-fast-z-score": 7.366787985098479,
        "rewrite-fast-z-score": -0.5477225575051661
    },
    {
        "original_text": "The influence of pulsed magnetic fields on the relaxation processes in HTSC was investigated by measuring the temperature dependence of resistance and Hall coefficient for samples with different oxygen content (d = 0, 1). The results show that the application of pulsed magnetic fields leads to an increase in the resistivity and Hall mobility of the sample with d = 0. This effect is explained as due to the appearance of additional scattering centers caused by defects formed during the process of magnetization reversal. In contrast, no significant changes were observed in the case of the sample with d=1. It can be assumed that this difference is associated with the presence of structural disordering in the crystal lattice of the latter compound. \n \n Keywords: High-Tc Superconductor, Pulsed Magnetic Field, Relaxation Processes, Defects Formation, Magnetoresistance, Hall Effect. Introduction \n \n Investigation of relaxation phenomena in high temperature superconductors under the action of pulsed external magnetic fields has been attracting considerable attention recently  1 - 5  . These studies are important both for understanding the physics of these materials and for practical applications  6  -  8  . \n \n In particular, it should be noted that the investigation of relaxation processes in HTSCs allows one to study the dynamics of defect formation  9  , which plays an important role in determining their transport properties  10  . At present there are several models describing the mechanism of defect generation  11  -  13  . However, none of them takes into account the possibility of defect formation induced by the action of pulsed fields  14  . \nExperimental details\n\nIn our work we used single crystals of two compounds with different oxygen content: HoBa 2 Cu 3 O 7−δ (HBS) and YBa 2 Cu 3 O 6+δ (YBS), grown using the floating zone method  15  . The oxygen concentration in the samples was determined by iodometric titration  16  . The typical size of the samples was about 5 × 4 mm 2 . The measurements were carried out in liquid helium cryostats equipped with pulse magnets  17  . The maximum value of the magnetic induction reached up to B max =",
        "watermark_text": "The impact of pulsed magnetic fields on the relaxation processes in HTSC was investigated by monitoring the temperature dependence of resistance and Hall coefficient for specimens with various oxygen composition ( d = 0 , 1 ) . The results show that the introduction of pulsed magnetic fields leads to an increase in the resistivity and Hall velocity of the sample with d = 0 .This phenomenon is understood as owing to the appearance of added scattering centers caused by defects formed during the process of magnetization reversal . In comparison , no major changes were detected in the case of the sample with d = 1 .It can be assumed that this contrast is associated with the presence of structural disordering in the crystal structures of the latter chemical . Keywords : High - Tc Superconductor , Pulsed Magnetic Field , Relaxation Processes , Defects Formation , Magnetoresistance , Hall Effect .Introduction Investigation of relaxation effects in high heat superconductors under the action of pulsed external magnetic waves has been drawing greater notice lately 1 - 5 . These studies are important both for studying the physics of these structures and for useful use 6 - 8 .In particular , it should be mentioned that the examination of relaxation processes in HTSCs allows one to study the dynamics of defect form 9 , which plays an important role in establishing their transport properties 10 . At currently there are several models explaining the process of defect generation 11 - 13 .However , none of them took into consideration the danger of defect development caused by the activity of pulsed fields 14 . Experimental details In our work we using single crystals of two compounds with varying oxygen composition : HoBa 2 Cu 3 O 7−δ ( HBS ) and YBa 2 Cu 3 O 6 + δ ( YBS ) , grown using the sliding zone method 15 .The oxygen composition in the tests was calculated by iodometric titration 16 . The typical size of the samples was about 5 × 4 mm 2 .The measurements were carried out in pure helium cryostats fitted with pulse magnets 17 . The maximum value of the magnetic induction reached up to B max =",
        "rewrite_text": "The influence of pulsed magnetic fields on relaxation processes in high-temperature superconductors (HTSC) was examined by analyzing the temperature-dependent resistance and Hall coefficient of samples with different oxygen compositions (d = 0, 1). The findings indicate that applying pulsed magnetic fields results in increased resistivity and Hall velocity in the sample with d = 0. This effect is attributed to the emergence of additional scattering centers, which arise from defects generated during magnetization reversal. In contrast, the sample with d = 1 did not exhibit significant changes. This difference is likely linked to the presence of structural disorder within the crystal structure of the latter material. \n\nKeywords: High-Tc Superconductor, Pulsed Magnetic Field, Relaxation Processes, Defect Formation, Magnetoresistance, Hall Effect.\n\n**Introduction**  \nRecent research has increasingly focused on relaxation effects in high-temperature superconductors under pulsed external magnetic fields. These investigations are crucial for advancing our understanding of the physics governing these materials and their practical applications. Notably, studying relaxation processes in HTSCs provides insights into defect dynamics, which significantly influence their transport properties. While several models have been proposed to explain defect generation, none have adequately addressed the potential for defect formation induced by pulsed fields.\n\n**Experimental Details**  \nIn this study, we utilized single crystals of two compounds with varying oxygen compositions: HoBa2Cu3O7−δ (HBS) and YBa2Cu3O6+δ (YBS), which were synthesized using the sliding zone method. The oxygen content was determined through iodometric titration. The typical dimensions of the samples measured approximately 5 × 4 mm². Measurements were conducted in pure helium cryostats equipped with pulse magnets, with the maximum magnetic induction reaching B_max = ",
        "ori-fast-z-score": -1.1832159566199232,
        "water-fast-z-score": 7.268326590665242,
        "rewrite-fast-z-score": 0.6163156344279367
    },
    {
        "original_text": "We present the first results on infrared high-resolution spectroscopy (HRS) of post-AGB disks, obtained with CRIRES/VLT and NIRSPEC/Keck II. We find that the disk around HR 4049 is dominated by emission lines originating in an extended region at temperatures between 1000-2000 K. This temperature range corresponds to the expected location of dust grains which are being evaporated due to stellar radiation pressure. In addition we detect several absorption features which can be attributed to gas-phase molecules such as CO, H2O, OH, NH3, CH4, C2H2, SiO, HCN, CCH, CN, H2S, SO2, CS, and FeH. These observations provide new insights into the physical conditions within these objects. They also show how important it will be for future studies to combine spatially resolved information about the distribution of molecular species with detailed spectroscopic data. \n \n Keywords: circumstellar disk",
        "watermark_text": "We present the first findings on infrared high - resolution spectroscopy ( HRS ) of post - AGB disks , obtained with CRIRES / VLT and NIRSPEC / Keck II . We see that the disk around HR 4049 is dominated by absorption tracks originating in an extended region at temperatures between 1000 - 2000 K . This temperature spectrum refers to the expected location of dust grains which are being evaporated due to stellar radiation stress .In addition we locate many absorption properties which can be due to gas - phase molecules such as CO , H2O , OH , NH3 , CH4 , C2H2 , SiO , HCN , CCH , CN , H2S , SO2 , CS , and FeH . These measurements give novel knowledge into the physical conditions within these objects .They also demonstrate how important it will be for future research to mix spatially resolved data about the distribution of molecular species with comprehensive spectroscopic data . Keywords : circumstellar disk",
        "rewrite_text": "We present our initial findings on infrared high-resolution spectroscopy (HRS) of post-AGB disks, obtained using CRIRES at the VLT and NIRSPEC at Keck II. Our observations indicate that the disk surrounding HR 4049 is primarily characterized by absorption features from an extended region with temperatures ranging from 1000 to 2000 K. This temperature range aligns with the expected locations of dust grains that are being vaporized by stellar radiation pressure. Furthermore, we identify various absorption signatures likely attributed to gas-phase molecules, including CO, H2O, OH, NH3, CH4, C2H2, SiO, HCN, CCH, CN, H2S, SO2, CS, and FeH. These measurements provide new insights into the physical conditions of these celestial objects. They also highlight the need for future studies to combine spatially resolved data on the distribution of molecular species with detailed spectroscopic information. Keywords: circumstellar disk.",
        "ori-fast-z-score": -0.5252257314388902,
        "water-fast-z-score": 4.727031582950012,
        "rewrite-fast-z-score": 0.3779644730092272
    },
    {
        "original_text": "We present new results on interstellar absorption lines toward early type stars observed with UVES at VLT, as part of the ESO-POP project (ESO program 085.D-0571). We have searched for high-velocity clouds (HVCs) by looking for blueshifted components in the MgII doublet line profiles. The sample consists of 16 OB-stars located within 1 kpc distance from Earth. In addition to previously known HVCs we find several new ones. Some of these are associated with nearby galaxies while others may be related to Galactic halo gas. A comparison between our data set and previous surveys shows that there is no significant difference in the number density distribution of HVCs along different sightlines. This suggests that most of them are small structures which do not cover much solid angle around their host galaxy or star. \n \n Keywords: Interstellar medium",
        "watermark_text": "We release new results on interstellar absorption lines toward early type stars observed with UVES at VLT , as part of the ESO - POP project ( ESO program 085 . D - 0571 ) . We have searched for high - velocity clouds ( HVCs ) by looking for blueshifted components in the MgII doublet line profiles .The sample consists of 16 OB - stars situated within 1 kpc radius from Earth . In addition to formerly notable HVCs we find several new ones .Some of these are identified with nearby galaxies while several might be connected to Galactic halo gas . A comparison between our information set and previous searches reveals that there is no considerable difference in the number density spread of HVCs along various sightlines .This implies that most of them are small structures which do not cover many solid angle around their target galaxy or star . Keywords : Interstellar medium",
        "rewrite_text": "We present new findings on interstellar absorption lines observed in early-type stars using UVES at the VLT, as part of the ESO-POP project (ESO program 085.D-0571). Our investigation focused on identifying high-velocity clouds (HVCs) by examining blueshifted components in the Mg II doublet line profiles. The study sampled 16 OB stars located within a radius of 1 kpc from Earth. In addition to previously identified notable HVCs, we discovered several new cases. Some of these new HVCs are associated with nearby galaxies, while others may be linked to gas in the Galactic halo. A comparison of our data with earlier studies shows no significant variation in the density distribution of HVCs across different sightlines. This suggests that many of these clouds are small, localized structures that do not cover a large solid angle around their respective galaxy or star. Keywords: Interstellar medium.",
        "ori-fast-z-score": -1.6644794391276478,
        "water-fast-z-score": 2.4327007187250236,
        "rewrite-fast-z-score": -2.182820625326997
    },
    {
        "original_text": "We propose a new string derived model with stable proton in which the lightest supersymmetric particle (LSP) is not neutralino but gravitino. The LSP decays into photon or neutrino-antineutrino pair through gravitational interaction. In this scenario we can explain the observed dark matter abundance without conflicting with other experimental results such as relic density measurement by WMAP experiment. We also show that our model predicts interesting signatures at LHC experiments. Introduction:-The discovery of Higgs boson  1-3  has opened up an exciting possibility to explore physics beyond Standard Model(SM). Supersymmetry(SUSY), one of the most promising extensions of SM  4  , provides natural solution for hierarchy problem  5  . However, SUSY models are severely constrained by various experimental observations  6  .\nIn order to solve these problems, several authors have proposed different mechanisms  7-9 . One of them is introducing additional gauge symmetries  10  . Another way is adding extra dimensions  11  . Recently, it was shown that there exists a class of string derived models where the lightest superpartner is gravitino  12  . Gravitino is weakly interacting massive particle so its decay rate is suppressed compared to neutralino case  13  . This feature makes gravitino a good candidate for cold dark matter  14  . Moreover, if gravitino mass m 3/2 < 1 GeV then its lifetime becomes longer than age of universe  15  . Therefore, gravitino may be regarded as a viable candidate for dark matter  16  . On the other hand, gravitino is unstable because it couples to gravity  17  . It decays into photon or lepton-neutrino pairs  18  . If gravitino is heavier than 100 MeV then its decay products will contribute to diffuse gamma ray background  19  . Thus, gravitino should satisfy following conditions  20  :",
        "watermark_text": "We suggest a new string derived model with stable proton in which the lightest supersymmetric object ( LSP ) is not neutralino but gravitino . The LSP decays into photon or neutrino - antineutrino bond through gravity interaction .In this situation we can describe the seen dark matter density without conflicting with other experimental outcome such as relic volume observation by WMAP study . We additionally prove that our model predicts exciting signatures at LHC experiments .Introduction : - The observation of Higgs boson 1 - 3 has opened up an exciting possibility to study physics beyond Standard Model ( SM ) . Supersymmetry ( SUSY ) , one of the most attractive extensions of SM 4 , offers natural solution for hierarchy problem 5 .However , SUSY models are severely constrained by various experimental studies 6 . In try to solve these problems , various scientists have proposed different processes 7 - 9 .One of them is adding additional gauge symmetries 10 . Another means is adding extra dimensions 11 .Recently , it was shown that there exists a class of string derived models where the lightest superpartner is gravitino 12 . Gravitino is weakly interacting massive object so its degradation rate is suppressed compared to neutralino case 13 .This characteristic makes gravitino a better contender for cold gray material 14 . Moreover , if gravitino mass m 3 / 2 < 1 GeV then its duration remains longer than age of universe 15 .Therefore , gravitino might be regarded as a viable contender for black matter 16 . On the other hand , gravitino is unstable because it couples to gravity 17 .It decays into photon or lepton - neutrino pairs 18 . If gravitino is heavier than 100 MeV then its degradation elements will contribute to diffuse gamma ray background 19 .Thus , gravitino should satisfy following conditions 20 :",
        "rewrite_text": "We propose a novel model derived from string theory that includes a stable proton, where the lightest supersymmetric particle (LSP) is a gravitino rather than a neutralino. In this framework, the LSP decays into a photon or a neutrino-antineutrino pair via gravitational interactions. This model allows us to account for the observed dark matter density without conflicting with other experimental results, such as the relic abundance measurements provided by the WMAP study. Furthermore, we show that our model predicts intriguing signatures that could be detected in LHC experiments. \n\nIntroduction: The discovery of the Higgs boson has opened up new avenues for exploring physics beyond the Standard Model (SM). Supersymmetry (SUSY), one of the most compelling extensions of the SM, offers a natural solution to the hierarchy problem. However, various experimental studies have placed significant constraints on SUSY models. In an effort to address these challenges, researchers have proposed different approaches. One approach involves introducing additional gauge symmetries, while another entails the incorporation of extra dimensions. Recently, a class of string-derived models has been identified where the lightest superpartner is the gravitino. Being a weakly interacting massive particle, the gravitino has a decay rate that is significantly lower than that of the neutralino, making it a more suitable candidate for cold dark matter. Furthermore, if the mass of the gravitino is less than 1 GeV, its lifetime exceeds the age of the universe, establishing it as a potential candidate for dark matter. However, due to its coupling to gravity, the gravitino is unstable and decays into photons or lepton-neutrino pairs. If the gravitino mass exceeds 100 MeV, its decay products could contribute to the diffuse gamma-ray background. Therefore, the gravitino must meet the following conditions:",
        "ori-fast-z-score": -0.19069251784911848,
        "water-fast-z-score": 6.620784138506228,
        "rewrite-fast-z-score": 0.5477225575051661
    },
    {
        "original_text": "We present an algorithm for synthesizing phase screens that are optimal in the sense of minimizing the mean-square error between the synthesized and desired phases, subject to constraints on the maximum number of degrees of freedom (DOF) available for synthesis.  The method is based on representing each screen as a linear combination of basis functions derived by applying the Karhunen-Loeve transform to a set of reference phase screens generated using standard methods such as those described by Kolmogorov or von Kàrmàn statistics.   We show how this representation can be used to generate new phase screens whose statistical properties match closely those of the original reference screens while simultaneously satisfying user-specified bounds on the total number of DOF required to represent all N screens in the sequence. This approach has been implemented within the context of the SPARTA software package developed at NASA s Goddard Space Flight Center. In addition we describe several techniques which have been incorporated into our implementation to improve computational efficiency when generating large sequences of phase screens.",
        "watermark_text": "We present an algorithm for synthesizing phase screens that are optimal in the sense of minimizing the mean - square error between the extracted and desired stages , subject to constraints on the maximum number of degrees of liberty ( DOF ) accessible for synthesis . The method is based on representing each window as a linear mixture of basis functions derived by using the Karhunen - Loeve transform to a group of reference phase screens assembled using conventional methods such as those given by Kolmogorov or von Kàrmàn statistics .We see how this representation can be used to create additional phase screens whose statistical characteristics match tightly those of the previous reference displays while simultaneously satisfying user - defined bounds on the total number of DOF required to depict all N screens in the sequence . This method has been utilized within the context of the SPARTA tool package built at NASA s Goddard Space Flight Center .In addition we define various methods which have been incorporated into our implementation to improve computational efficiency when constructing large sequences of phase screens .",
        "rewrite_text": "We introduce an algorithm designed to synthesize phase screens that minimize the mean-square error between the extracted and intended stages, while adhering to limitations on the maximum degrees of freedom (DOF) available for synthesis. This approach models each window as a linear combination of basis functions generated through the Karhunen-Loeve transform applied to a set of reference phase screens created using traditional techniques, such as those based on Kolmogorov or von Kármán statistics. Our representation allows for the generation of additional phase screens that closely match the statistical properties of the original reference screens, all while meeting user-defined constraints on the total number of DOF needed to represent all N screens in the sequence. This method has been integrated into the SPARTA tool package developed at NASA's Goddard Space Flight Center. Furthermore, we outline several strategies incorporated into our implementation to enhance computational efficiency in constructing extensive sequences of phase screens.",
        "ori-fast-z-score": -1.9409899176618914,
        "water-fast-z-score": 4.960307567358167,
        "rewrite-fast-z-score": -1.118033988749895
    },
    {
        "original_text": "The concept of molecular descriptors is central to the development of quantitative structure-activity relationships (QSARs). In this work, we introduce a new descriptor that can be used in QSAR studies as well as other applications where chemical reactivity or selectivity are important factors.  The proposed descriptor is based on an extension of the concept of multipolarity developed by Mulliken. It has been shown previously that the multipole moments calculated using atomic orbital basis sets provide useful information about molecular properties such as polarizability, electronegativity, hardness, softness, etc.. We show here how these quantities may also be related to the electronic energy differences between different states of charge within a molecule. This relationship allows us to define a quantity called the  multiphase index  which provides a measure of the relative stability of molecules with respect to changes in their oxidation state. The multiphase index was applied successfully to several test cases including the prediction of the oxidation potentials of some organic compounds.",
        "watermark_text": "The concept of molecular descriptors is central to the development of statistical structure - activity relationships ( QSARs ) . In this research , we provide a new descriptor that can be used in QSAR studies as well as other applications where chemical reactivity or selectivity are important factors .The proposed descriptor is based on an extension of the idea of multipolarity developed by Mulliken . It has been shown ago that the multipole minutes measured using atomic orbital basis sets offer useful details about molecular properties such as polarizability , electronegativity , hardness , softness , etc . . We see here how these quantities might additionally be connected to the electronic energy differences between various states of charge within a molecule .This relationship permits us to define a quantity called the multiphase index which offers a measure of the relative structure of molecules with regard to changes in their oxidation state . The multiphase index was used successfully to several test cases including the determination of the oxidation potentials of some organic reactions .",
        "rewrite_text": "Molecular descriptors play a crucial role in the development of quantitative structure-activity relationships (QSARs). In this study, we introduce a novel descriptor applicable not only in QSAR analysis but also in other fields where chemical reactivity or selectivity is critical. This new descriptor builds on Mulliken's concept of multipolarity. Previous research has demonstrated that multipole moments calculated using atomic orbital basis sets provide valuable insights into molecular properties such as polarizability, electronegativity, hardness, and softness. In this work, we explore how these properties correlate with the electronic energy differences among various charge states within a molecule. This connection allows us to define a quantity termed the multiphase index, which quantifies the structural variations of molecules in relation to changes in their oxidation states. We successfully applied the multiphase index to several case studies, including the determination of oxidation potentials in organic reactions.",
        "ori-fast-z-score": 1.6059101370939322,
        "water-fast-z-score": 5.658032638058332,
        "rewrite-fast-z-score": 1.805787796286538
    },
    {
        "original_text": "We have analyzed the shapes of interstellar extinction curves in the infrared through ultraviolet wavelength range using data for more than 100 sight lines with known distances and reddenings, including those obtained by us at Kitt Peak National Observatory (KPNO) and Cerro Tololo Inter-American Observatory (CTIO). We find that all observed extinction curves can be fitted well by a single power law function A(lambda) = lambda -alpha , where alpha is an index ranging between 1.5 to 2.0. This result suggests that there are no significant differences among various types of interstellar dust grains as far as their optical properties are concerned. In addition, we show that the value of alpha correlates strongly with the total-to-selective extinction ratio Rv . These results suggest that the shape of interstellar extinction curve may provide important information on the physical conditions of interstellar matter along individual sight lines. Keywords: Interstellar extinction; Power-law index; Reddening; Dust grain",
        "watermark_text": "We have analyzed the shapes of interstellar extinction lines in the infrared through ultraviolet frequency range utilizing information for more than 100 sight lines with reported distances and reddenings , notably those acquired by us at Kitt Peak National Observatory ( KPNO ) and Cerro Tololo Inter - American Observatory ( CTIO ) . We see that all observed extinction lines can be fit well by a single power law relation A ( lambda ) = lambda - alpha , where alpha is an index ranging between 1 . 5 to 2 . 0 .This result suggests that there are no major changes among various types of interstellar dust grains as long as their optical properties are concerned . In addition , we find that the value of α correlates heavily with the total - to - selective extinction ratio Rv .These data suggest that the form of interstellar extinction curve might give important information on the physical conditions of interstellar matter along individual sight lines . Keywords : Interstellar extinction ; Power - law index ; Reddening ; Dust grain",
        "rewrite_text": "We have examined the characteristics of interstellar extinction lines across the infrared to ultraviolet spectrum, using data from over 100 sight lines with documented distances and reddenings, particularly those collected at the Kitt Peak National Observatory (KPNO) and Cerro Tololo Inter-American Observatory (CTIO). Our analysis reveals that all observed extinction lines can be accurately described by a single power law relationship, A(λ) = λ^(-α), where α varies between 1.5 and 2.0. This finding indicates that there are no significant variations in the optical properties of different types of interstellar dust grains. Furthermore, we observe a strong correlation between the value of α and the total-to-selective extinction ratio Rv. These results imply that the structure of the interstellar extinction curve may provide valuable insights into the physical conditions of the interstellar medium along specific sight lines. Keywords: Interstellar extinction; Power-law index; Reddening; Dust grain.",
        "ori-fast-z-score": 1.0834726777719228,
        "water-fast-z-score": 5.820855000871991,
        "rewrite-fast-z-score": 1.4552137502179978
    },
    {
        "original_text": "We present an analysis of the concept of algorithmically reducible problems in computational complexity theory, focusing on its role as a bridge between different areas within this field. We argue that there are at least two distinct ways to understand what it means for one problem to be reduced to another by an algorithm; these correspond roughly to the notions of polynomial-time reductions and Turing reductions respectively. The former is more commonly used than the latter, but we show how both can be understood in terms of each other using the notion of relativised polynomial time. In particular, we prove that every problem which is not NP-complete under Turing reductions must have some property which makes it easy to solve relative to any oracle set containing all NP sets. This result has implications for the relationship between P and NP, and also provides new insights into the structure of NP itself. Algorithmic reductions play a central role in computational complexity theory, providing a way of relating seemingly disparate classes of decision problems such as those belonging to the class NP (the non-deterministic polynomial time computable problems) with those belonging to the class co-NP (the complements of NP problems). However, despite their importance, relatively little attention has been paid to the precise meaning of the phrase  algorithmically reduces to ; indeed, even basic questions about the nature of this concept remain unanswered.",
        "watermark_text": "We present an assessment of the idea of algorithmically reducible challenges in computational complexity analysis , concentrating on its role as a bridge between various fields within this area . We argue that there are at least two different means to comprehend what it means for one question to be reduced to another by an algorithm ; these correspond roughly to the concepts of polynomial - time reductions and Turing reductions respectively .The first is more frequently used than the former , but we prove how both can be understood in terms of each other using the notion of relativised polynomial time . In particular , we prove that every question which is not NP - full under Turing reductions must have some property which makes it easy to solve relative to any oracle set containing all NP sets .This result has implications for the relationship between P and NP , and also provides new understanding into the formation of NP itself . Algorithmic reductions serve a central role in computational complexity analysis , providing a way of comparing surprisingly disparate classes of decision cases such as those belonging to the class NP ( the non - deterministic polynomial time computable problems ) with those belonging to the class co - NP ( the complements of NP problems ) .However , despite their importance , fairly little attention has been paid to the exact significance of the phrase algorithmically reduces to ; consequently , even basic concerns about the nature of this concept continue unanswered .",
        "rewrite_text": "We provide an evaluation of the concept of algorithmically reducible challenges in the field of computational complexity analysis, highlighting its importance as a link among various disciplines within this domain. We contend that there are at least two distinct ways to understand the reduction of one problem to another through an algorithm: these align roughly with the notions of polynomial-time reductions and Turing reductions. While polynomial-time reductions are more commonly referenced, we demonstrate that both types can be related to one another through the concept of relativized polynomial time. Specifically, we show that any problem not deemed NP-complete under Turing reductions exhibits some characteristic that simplifies its solution in the context of any oracle set encompassing all NP problems. This finding has significant implications for the P versus NP debate and enhances our understanding of the NP class itself. Algorithmic reductions play a crucial role in computational complexity analysis, enabling comparisons between seemingly disparate classes of decision problems, such as those in NP (nondeterministic polynomial time problems) and co-NP (the complements of NP problems). However, despite their critical importance, relatively little focus has been directed towards fully understanding the phrase \"algorithmically reduces to,\" leaving fundamental questions regarding its nature still unresolved.",
        "ori-fast-z-score": 0.7035264706814485,
        "water-fast-z-score": 6.6,
        "rewrite-fast-z-score": 0.3216337604513384
    },
    {
        "original_text": "BiFeO3 is an antiferromagnetic insulator with high Curie temperature (TC = 1103 K) that exhibits ferroelectricity at room temperature when doped or under pressure. Here we report the observation of spontaneous magnetization, M(T), and electrical polarization, P(E), simultaneously existing over wide ranges of temperatures up to 300 K in pure BiFeO3 single crystal grown by flux method. The results show that both M(T) and P(E) are nearly independent on each other below TC but they start to decrease rapidly above TC. We also found that the magnitude of M(T) decreases faster than that of P(E). These observations suggest that there exists strong coupling between spin and lattice degrees of freedom in this material. \n \n Keywords: Room-temperature multiferroic materials, BiFeO3, Electric polarization, Magnetic properties, Flux growth technique.",
        "watermark_text": "BiFeO3 is an antiferromagnetic insulator with high Curie temperature ( TC = 1103 K ) that exhibits ferroelectricity at room temperature when doped or under pressure . Here we document the observation of induced magnetization , M ( T ) , and electrical polarization , P ( E ) , independently operating over broad ranges of conditions up to 300 K in pure BiFeO3 single crystal grown by flux technology .The results show that both M ( T ) and P ( E ) are nearly independent on each other below TC but they start to decline rapidly above TC . We additionally found that the magnitude of M ( T ) decreases quicker than that of P ( E ) .These measurements suggest that there exists strong coupling between spin and lattice degrees of liberty in this material . Keywords : Room - temperature multiferroic materials , BiFeO3 , Electric polarization , Magnetic properties , Flux growth technique .",
        "rewrite_text": "BiFeO3 is an antiferromagnetic insulator with a high Curie temperature (TC = 1103 K) that manifests ferroelectricity at room temperature when subjected to doping or pressure. In this study, we present observations of induced magnetization, M(T), and electrical polarization, P(E), both functioning independently across a wide range of conditions up to 300 K in a pure BiFeO3 single crystal grown using flux technology. Our findings indicate that below TC, M(T) and P(E) are largely independent of one another; however, they both experience a significant decline above TC. Notably, the reduction in M(T) occurs more rapidly than that of P(E). These results imply a strong coupling between the spin and lattice degrees of freedom in this material. Keywords: Room-temperature multiferroic materials, BiFeO3, Electric polarization, Magnetic properties, Flux growth technique.",
        "ori-fast-z-score": 0.14285714285714285,
        "water-fast-z-score": 3.857142857142857,
        "rewrite-fast-z-score": 0.8660254037844387
    },
    {
        "original_text": "We present an immersive visualization system for exploring and analyzing large volumes of genomic data, which is based on the concept of immersive graph-based exploration (IGE). The IGE approach allows users to explore complex relationships between different types of biological entities in 3D space using interactive visualizations. We implemented our system as a web application that can be accessed via any standard Web browser without requiring installation or configuration. Our system supports multiple simultaneous user interactions with the same dataset through collaborative visualization. In addition, we provide several advanced features such as automatic layout adjustment according to the number of nodes displayed at each time step, dynamic node labeling, and support for zoom-in/zoom-out operations. Finally, we demonstrate how our system can be used to analyze two real-world datasets related to human diseases. This article is part of a Special Issue entitled  Bioinformatics Visualization  guest edited by Michael R. Davidson, David A. Bader, and Mark J. Stubbs",
        "watermark_text": "We create an immersive visualization scheme for studying and analyzing large quantities of genomic evidence , which is based on the idea of immersive graph - based exploration ( IGE ) . The IGE method enables users to examine complex relationships between various types of biological entities in 3D space using interactive visualizations .We introduced our system as a web application that can be downloaded via any typical Web server without need installation or configuration . Our application supports multiple simultaneous customer encounters with the same dataset through collaborative visualization .In addition , we provide several advanced features such as electronic layout control according to the quantity of vertices displayed at each time step , dynamic node labeling , and support for zoom - in / zoom - out operations . Finally , we prove how our system can be used to analyze two actual - global datasets pertaining to human diseases .This page is part of a Special Issue entitled Bioinformatics Visualization guest edited by Michael R . Davidson , David A . Bader , and Mark J . Stubbs",
        "rewrite_text": "We have developed an immersive visualization framework for the analysis of extensive genomic data, grounded in the concept of immersive graph-based exploration (IGE). This IGE approach allows users to explore intricate relationships among various biological entities in a 3D environment through interactive visualizations. Our system is presented as a web application, easily accessible for download from any standard web server, requiring no installation or configuration. The application facilitates multiple users to interact with the same dataset simultaneously through collaborative visualization. Additionally, it offers several advanced features, including electronic layout control based on the number of displayed vertices, dynamic node labeling, and the ability to zoom in and out. We also demonstrate how our system can be utilized to analyze two significant global datasets related to human diseases. This work is included in a Special Issue of Bioinformatics Visualization, guest edited by Michael R. Davidson, David A. Bader, and Mark J. Stubbs.",
        "ori-fast-z-score": 1.1470786693528088,
        "water-fast-z-score": 7.341303483857976,
        "rewrite-fast-z-score": 1.0681034923744679
    },
    {
        "original_text": "We report on diffuse X-ray emission in the Carina Nebula observed by Suzaku. The spectrum is well reproduced by thermal plasma models at kT = 0.7-1 keV and nH = (0.5-2) x 10^(22) cm^{-3}, which are consistent with those obtained previously for other regions within the nebula. We find that the total luminosity of this component amounts to Lx ~ 1.3 x 10^35 erg/sec, corresponding to about 10% of the total energy output of massive stars in the region. This suggests that hot gas produced by stellar winds and/or supernovae plays an important role in heating up the interstellar medium around young open clusters such as Trumpler 14-16. \n \n \n \n Keywords: Diffuse X-rays, Hot plasma, Open cluster, Supernova remnant, Stellar wind, Carina Nebula",
        "watermark_text": "We report on diffuse X - ray radiation in the Carina Nebula observed by Suzaku . The spectrum is well illustrated by thermal plasma estimates at kT = 0 . 7 - 1 keV and nH = ( 0 . 5 - 2 ) x 10 ^ ( 22 ) cm ^ { - 3 } , which are compatible with those observed previously for other regions within the nebula .We see that the total luminosity of this constituent amounts to Lx ~ 1 . 3 x 10 ^ 35 erg / sec , equivalent to about 10 % of the total energy produced of large galaxies in the region . This implies that hard gas created by stellar winds and / or supernovae plays an important role in heating up the interstellar medium around young open complexes such as Trumpler 14 - 16 .Keywords : Diffuse X - radiation , Hot plasma , Open core , Supernova remnant , Stellar wind , Carina Nebula",
        "rewrite_text": "We present our findings on the diffuse X-ray radiation detected in the Carina Nebula by the Suzaku satellite. The spectrum aligns well with thermal plasma models, indicating temperatures in the range of kT = 0.7 - 1 keV and hydrogen densities of nH = (0.5 - 2) x 10^(22) cm^(-3), consistent with previous observations from other regions in the nebula. Our analysis shows that the total luminosity of this component is approximately Lx ~ 1.3 x 10^(35) erg/sec, which accounts for about 10% of the total energy generated by large galaxies in the vicinity. This suggests that hot gas produced by stellar winds and supernovae significantly contributes to the heating of the interstellar medium surrounding young open clusters such as Trumpler 14-16. \n\nKeywords: Diffuse X-ray radiation, hot plasma, open cluster, supernova remnant, stellar wind, Carina Nebula.",
        "ori-fast-z-score": -1.3127849234810511,
        "water-fast-z-score": 3.646624787447364,
        "rewrite-fast-z-score": -0.39735970711951313
    },
    {
        "original_text": "The Galois group is the fundamental object in classical Galois theory, which studies the solvability of polynomial equations over finite fields.  In this talk we will introduce the notion of ``Galois groups   for infinite families of polynomials and study their properties using tools from algebraic geometry.   We will also discuss some applications to number theory such as the proof of the abc conjecture by Vojta (joint work with J. Pila). The main results are joint works with A. Chambert-Loir, D. Ghioca, M. Harris, C. Lairez, S. Popescu-Tarauca, B. Stoll, E. Szpiro, T. Tucker-Drob, and V. Vojta. This talk was given at the conference  Algebraic Geometry and Arithmetic Dynamics  held on June 24-28, 2013 at MSRI Berkeley. It has been recorded by Adam Hartung.",
        "watermark_text": "The Galois group is the fundamental object in classical Galois theory , which studies the solvability of polynomial equations over polynomial fields . In this talk we will explore the notion of ` ` Galois classes for arbitrary families of polynomials and study their characteristics utilizing techniques from algebraic geometry .We will also discuss some applications to number theory such as the proof of the abc conjecture by Vojta ( collaboration work with J . Pila ) . The main results are joint works with A . Chambert - Loir , D . Ghioca , M . Harris , C . Lairez , S . Popescu - Tarauca , B . Stoll , E . Szpiro , T . Tucker - Drob , and V . Vojta .This speech was given at the meeting Algebraic Geometry and Arithmetic Dynamics holding on June 24 - 28 , 2013 at MSRI Berkeley . It has been recorded by Adam Hartung .",
        "rewrite_text": "The Galois group is a central concept in classical Galois theory, which examines the solvability of polynomial equations over polynomial fields. In this presentation, we will investigate the idea of \"Galois classes\" for various families of polynomials and analyze their properties using methods from algebraic geometry. Additionally, we will cover some applications in number theory, including Vojta's proof of the abc conjecture, a collaborative effort with J. Pila. The key findings are joint work with A. Chambert-Loir, D. Ghioca, M. Harris, C. Lairez, S. Popescu-Tarauca, B. Stoll, E. Szpiro, T. Tucker-Drob, and V. Vojta. This talk was delivered at the Algebraic Geometry and Arithmetic Dynamics meeting, which took place from June 24-28, 2013, at MSRI Berkeley, and was recorded by Adam Hartung.",
        "ori-fast-z-score": -0.31622776601683794,
        "water-fast-z-score": 2.5298221281347035,
        "rewrite-fast-z-score": -0.4685212856658182
    },
    {
        "original_text": "We report on spectroscopic observations made with the Nordic Optical Telescope (NOT) and the William Herschel Telescope (WHT). The NOT data were obtained during two observing runs, one in August 2002 and another in September 2003. We used the ALFOSC instrument to obtain time-resolved spectroscopy covering the wavelength range 3700-7000 Å at a resolution of about 1 Å . The WHT data were taken between October 2004 and January 2005 using ISIS spectrographs equipped with gratings R600B and R1200R giving a spectral coverage of 3600-9200 Å at a resolving power of about 1000. In total we have collected more than 100 spectra for this object. All our new data are presented along with previously published results by Vogt et al. (1987) , Vogt & Hatzes (1991), Vogt et al. (1994a-c) . Our analysis shows that the system is composed of an M4V star orbited by a white dwarf companion.",
        "watermark_text": "We report on spectroscopic observations made with the Nordic Optical Telescope ( NOT ) and the William Herschel Telescope ( WHT ) . The NOT results were obtained during two observing walks , one in August 2002 and another in September 2003 .We utilized the ALFOSC instrument to obtain time - resolved spectroscopy spanning the frequency spectrum 3700 - 7000 Å at a resolution of about 1 Å . The WHT measurements were took between October 2004 and January 2005 utilizing ISIS spectrographs equipped with gratings R600B and R1200R giving a spectral coverage of 3600 - 9200 Å at a resolving power of about 1000 .In total we have gathered more than 100 spectra for this object . All our new data are presented along with former reported results by Vogt et al .( 1987 ) , Vogt & Hatzes ( 1991 ) , Vogt et al . ( 1994a - c ) .Our study shows that the system is composed of an M4V star orbited by a white dwarf companion .",
        "rewrite_text": "We present our findings from spectroscopic observations conducted using both the Nordic Optical Telescope (NOT) and the William Herschel Telescope (WHT). The NOT data were collected during two observing runs: one in August 2002 and the second in September 2003. We employed the ALFOSC instrument to perform time-resolved spectroscopy across a wavelength range of 3700 - 7000 Å, achieving a resolution of approximately 1 Å. The WHT observations took place between October 2004 and January 2005, utilizing ISIS spectrographs with R600B and R1200R gratings, which provided spectral coverage from 3600 - 9200 Å at a resolving power of about 1000. In total, we amassed over 100 spectra for this object. Our new data is presented alongside previously reported results from Vogt et al. (1987), Vogt & Hatzes (1991), and Vogt et al. (1994a-c). Our research concludes that the system consists of an M4V star with a white dwarf companion.",
        "ori-fast-z-score": 1.3127849234810511,
        "water-fast-z-score": 5.10527470242631,
        "rewrite-fast-z-score": 0.5547001962252291
    },
    {
        "original_text": "We present microscopic theory for the interaction between single photons and semiconductor quantum dots (QDs). We show that QD emission is strongly modified by the presence of nearby QDs, which leads to an effective dipole-dipole coupling in the system. This results in new phenomena such as superradiant lasing and subradiance. The latter can be used to create efficient on-chip optical switches. Our approach allows us to calculate all relevant quantities including spontaneous emission rates, absorption cross sections, and scattering matrices. These are important parameters for applications ranging from photonic devices to quantum information processing. \nTheory\n\nQuantum dots interact via their electric fields.\n\nThis gives rise to collective effects like superradiance or subradiance. \n\nThese effects can be observed in experiments using microcavities.  \n\nExperiments\n\nIn this work we study the influence of these collective effects on the emission properties of individual quantum dots embedded into a microcavity. \n\n\nResults",
        "watermark_text": "We present microscopic theory for the interaction between single photons and semiconductor quantum dots ( QDs ) . We suggest that QD radiation is strongly altered by the presence of neighbouring QDs , which results to an efficient dipole - dipole coupling in the system .This results in novel concepts such as superradiant lasing and subradiance . The latter can be used to create fast on - chip optical networks .Our solution enables us to estimate all relevant quantities namely spontaneous emission rates , absorption cross sections , and scattering matrices . These are important characteristics for applications extending from photonic devices to quantum information processing .Theory Quantum dots interact via their electric forces . This gives rise to collective effects like superradiance or subradiance .These effects can be experienced in experiments using microcavities . Experiments In this research we study the impact of these collective effects on the emission behavior of individual quantum dots inserted into a microcavity .Results",
        "rewrite_text": "We introduce a microscopic theory that examines the interaction between individual photons and semiconductor quantum dots (QDs). Our findings indicate that the radiation emitted by QDs is significantly influenced by the presence of nearby QDs, leading to an effective dipole-dipole coupling within the system. This interaction gives rise to intriguing phenomena such as superradiant lasing and subradiance. Notably, subradiance can be harnessed to develop rapid on-chip optical networks. Our approach allows us to calculate various important metrics, including spontaneous emission rates, absorption cross sections, and scattering matrices, all of which are crucial for applications ranging from photonic devices to quantum information processing. In terms of theory, quantum dots interact through their electric fields, which can produce collective effects like superradiance and subradiance. These phenomena can be observed experimentally in microcavities. In this study, we explore how these collective effects influence the emission behavior of individual quantum dots placed within a microcavity.",
        "ori-fast-z-score": -0.11867816581938533,
        "water-fast-z-score": 4.865804798594798,
        "rewrite-fast-z-score": 1.2874526191574363
    },
    {
        "original_text": "We present an analysis of multi-wavelength observations of the pulsar wind nebula (PWN) associated with PSR B1509-58 in the supernova remnant (SNR) G328.4+0. \n2. The radio emission is modeled as synchrotron radiation produced by relativistic electrons accelerated at the termination shock between the pulsar s magnetosphere and the surrounding medium. \n \n We find that the observed properties of this system are consistent with those expected for a young energetic pulsar surrounded by a dense shell of swept-up material. In particular, we show that: \n \n \n \n 1. The total energy contained within the SNR is ~1050 erg, which implies a kinetic energy of ~500 erg for the progenitor star prior to explosion; \n \n 2. The age of the pulsar is estimated to be ~20 kyr based on the spin-down luminosity and characteristic age; \n \n 3. The distance to the source is constrained to be <5 kpc using the dispersion measure and assuming a nominal value for the electron density along the line-of-sight; \n \n 4. The magnetic field strength near the pulsar is inferred to be ~1 mGauss based on modeling of the spectral index distribution across the face of the PWN; \n \n 5. The radius of the PWN is found to be ~0.3 pc, corresponding to a dynamical age of ~30 yrs; \n \n 6. The mass loss rate of the progenitor star was >10-5 Msun/yr during the last few thousand years before core collapse; \n \n 7. The initial mass of the progenitor star was ~25-30 Msuns, implying a red supergiant or blue hypergiant classification; \n \n 8. The ejecta mass of the progenitor star is estimated to be ~7-8 Msuns, indicating that it underwent significant mass loss prior to exploding; \n \n 9. The expansion velocity of the outer edge of the PWN is ~1000 km/sec, comparable to the speed of sound in the shocked gas; \n \n 10. The X-ray",
        "watermark_text": "We present an assessment of multi - wavelength images of the pulsar wind nebula ( PWN ) associated with PSR B1509 - 58 in the supernova remnant ( SNR ) G328 . 4 + 0 . 2 .The radio emission is modeled as synchrotron emission created by relativistic electrons accelerated at the termination shock between the pulsar s magnetosphere and the nearby medium . We see that the seen characteristics of this scheme are compatible with those expected for a young energetic pulsar surrounded by a dense shell of washed - up material .In particular , we find that : 1 . The total energy contained within the SNR is ~ 1050 erg , which implies a kinetic power of ~ 500 erg for the progenitor star previous to explosion ; 2 .The age of the pulsar is predicted to be ~ 20 kyr based on the spin - down luminosity and typical age ; 3 . The distance to the origin is constrained to be < 5 kpc using the dispersion measure and assuming a nominal value for the electron concentration along the line - of - view ; 4 .The magnetic force speed near the pulsar is inferred to be ~ 1 mGauss based on mapping of the spectral index distribution across the face of the PWN ; 5 . The radius of the PWN is found to be ~ 0 . 3 pc , equivalent to a dynamical age of ~ 30 yrs ; 6 .The mass loss rate of the progenitor star was > 10 - 5 Msun / yr during the last few thousand years before core breakup ; 7 . The initial mass of the progenitor star was ~ 25 - 30 Msuns , indicate a blue supergiant or blue hypergiant classification ; 8 .The ejecta mass of the progenitor star is predicted to be ~ 7 - 8 Msuns , showing that it underwent considerable mass loss prior to exploding ; 9 . The expansion velocity of the exterior boundary of the PWN is ~ 1000 kilometers / sec , comparable to the speed of noise in the excited gas ; 10 .The X-ray",
        "rewrite_text": "We provide an analysis of multi-wavelength images of the pulsar wind nebula (PWN) associated with PSR B1509-58 within the supernova remnant (SNR) G328.4+0.2. The radio emissions are interpreted as synchrotron radiation produced by relativistic electrons that are accelerated at the termination shock between the pulsar's magnetosphere and the surrounding medium. Our observations indicate that the characteristics of this model align well with expectations for a young, energetic pulsar encircled by a dense shell of accumulated material. Specifically, we determine the following: 1. The total energy within the SNR is approximately \\(10^{50}\\) ergs, suggesting a kinetic power of about 500 ergs for the progenitor star prior to its explosion; 2. The pulsar’s age is estimated to be around 20,000 years, based on its spin-down luminosity and typical aging patterns; 3. The distance to the source is limited to less than 5 kpc, using the dispersion measure and a standard value for electron density along the line of sight; 4. The magnetic field strength near the pulsar is estimated to be about 1 mGauss, derived from mapping the spectral index distribution across the PWN; 5. The radius of the PWN is measured to be approximately 0.3 pc, indicating a dynamical age of about 30 years; 6. The mass loss rate of the progenitor star was greater than \\(10^{-5}\\) M☉/yr over the last few thousand years leading up to its core collapse; 7. The initial mass of the progenitor star is estimated to be between 25 and 30 M☉, suggesting it was a blue supergiant or blue hypergiant; 8. The ejected mass of the progenitor star is predicted to be around 7 to 8 M☉, indicating significant mass loss prior to the explosion; 9. The expansion velocity of the outer boundary of the PWN is roughly 1000 kilometers per second, comparable to the speed of sound in the ionized gas; 10. The X-ray...",
        "ori-fast-z-score": 1.539600717839002,
        "water-fast-z-score": 7.890453678924885,
        "rewrite-fast-z-score": 2.108406543164886
    },
    {
        "original_text": "We report on the observation of vortex formation in two trapped condensates that are merged together using an optical lattice potential. The merging process is accompanied by the appearance of dark solitons, which can be identified as topological defects in the density distribution of each individual condensate. We show how these defects evolve into vortices during the merger process. In addition to this direct route towards vortex generation we also demonstrate another method for creating vortices based on interference between multiple condensates. This second approach allows us to create stable vortex states with high winding numbers (up to 12). Our results provide new insights into the dynamics of interacting quantum fluids at low temperatures. Vortices play an important role in many areas of physics ranging from superfluid helium  1  , liquid crystals  2  or superconductors  3  over atomic gases  4  up to astrophysics  5  . They represent topologically non-trivial solutions of nonlinear wave equations  6  and have been observed experimentally in various systems  7, 8  .\nIn recent years there has been considerable interest in studying vortex structures in ultracold atoms  9  . These systems offer several advantages compared to other physical realizations such as their tunability  10  , controllability  11  and clean experimental conditions  12  . For example, it was shown recently that one-dimensional arrays of vortices can be created in a single condensate  13  . However, most experiments so far were restricted to observing only few isolated vortices  14, 15  due to technical limitations  16  . Here we present two different methods for generating large ensembles of vortices in a controlled way.",
        "watermark_text": "We report on the observation of vortex form in two trapped condensates that are united together utilizing an optical lattice potential . The merging process is accompanied by the appearance of darkened solitons , which can be identified as topological flaws in the density density of each individual condensate .We see how these defects evolve into vortices during the merger process . In addition to this direct route towards vortex generation we also demonstrate another technique for producing vortices based on interference between multiple condensates .This second method enables us to create stable vortex states with high winding numbers ( up to 12 ) . Our results bring fresh insights into the dynamics of interacting quantum fluids at low temperatures .Vortices play an important role in multiple fields of science ranging from superfluid helium 1 , fluid crystals 2 or superconductors 3 over nuclear gases 4 up to astrophysics 5 . They represent topologically non - trivial solutions of nonlinear wave equations 6 and have been observed experimentally in different systems 7 , 8 .In recent years there has been substantial interest in investigating vortex structures in ultracold atoms 9 . These systems promise several advantages compared to other structural realizations such as their tunability 10 , controllability 11 and clean experimental environments 12 .For instance , it was shown ago that one - dimensional arrays of vortices can be formed in a single condensate 13 . However , most studies so far were restricted to observing only few isolated vortices 14 , 15 due to technical restrictions 16 .Here we present two different methods for generating huge groups of vortices in a controlled manner .",
        "rewrite_text": "We report our findings on the formation of vortices in two trapped condensates that are connected via an optical lattice potential. This merging process leads to the emergence of dark solitons, which can be recognized as topological defects within the density of each individual condensate. We observe how these defects transform into vortices during the merging process. In addition to this direct method of generating vortices, we also demonstrate an alternative technique that involves the interference of multiple condensates. This second approach allows us to create stable vortex states with high winding numbers (up to 12). Our results provide new insights into the dynamics of interacting quantum fluids at low temperatures. Vortices are significant in various scientific domains, including superfluid helium, liquid crystals, superconductors, nuclear gases, and astrophysics. They represent topologically non-trivial solutions to nonlinear wave equations and have been experimentally observed in different systems. Recently, there has been considerable interest in exploring vortex structures in ultracold atom systems, which offer advantages such as tunability, controllability, and clean experimental environments. For example, it has previously been demonstrated that one-dimensional arrays of vortices can form in a single condensate. However, much of the prior research has been limited to observing only a few isolated vortices due to technical constraints. In this work, we present two distinct methods for generating large groups of vortices in a controlled manner.",
        "ori-fast-z-score": 0.3746343246326776,
        "water-fast-z-score": 6.556100681071857,
        "rewrite-fast-z-score": 1.5689290811054724
    },
    {
        "original_text": "We present the results of our analysis on simulated galaxy clusters, which are used to study how different physical processes affect SZ observables (profiles and scaling relations). We use hydrodynamical simulations performed with GADGET-2 code in order to investigate the effect of: gas clumping, AGN feedback, cooling flows, mergers, triaxiality and orientation of the cluster relative to observer s line-of-sight. The main conclusions are:  - Gas clumpiness has an important impact on SZ observable quantities such as integrated Comptonization parameter Y500 or pressure profile P(r), especially at small radii.  - Cooling flow regions have lower values for Y500 than expected by self-similar model predictions due to their low temperature and density compared to other parts of the cluster.  - Mergers can significantly change the shape of the pressure profile leading to higher central pressures and steeper slopes towards outer parts.  - Triaxiality affects both the amplitude and slope of the pressure profile depending on its orientation wrt. the observer s line-of-sigh.  - Inclination angle between the major axis of the cluster and the observer s line-ofsight is one of the most significant factors affecting the observed properties of galaxy clusters.",
        "watermark_text": "We publish the conclusion of our analysis on virtual galaxy galaxies , which are using to study how various physical processes affect SZ observables ( profiles and scaling relations ) . We use hydrodynamical simulations conducted with GADGET - 2 code in trying to examine the impact of : gas clumping , AGN feedback , cooling flows , mergers , triaxiality and position of the cluster relative to observer s line - of - view .The main results are : - Gas clumpiness has an important effects on SZ observable variables such as integrated Comptonization value Y500 or temperature profile P ( r ) , particularly at small radii . - Cooling circulation regions have smaller estimates for Y500 than expected by self - similar model calculations owing to their low heat and density relative to other parts of the cluster .- Mergers can significantly change the form of the pressure profile resulting to higher central temperatures and steeper slopes towards outer parts . - Triaxiality affects both the frequency and slope of the pressure profile depending on its angle wrt .the observer s line - of - sigh . - Inclination angle between the main axis of the cluster and the observer s line - ofsight is one of the most significant events concerning the seen characteristics of galaxy clusters .",
        "rewrite_text": "We present the conclusions from our analysis of virtual galaxy clusters, which we are utilizing to investigate the effects of various physical processes on SZ observables, including profiles and scaling relations. Our study employs hydrodynamical simulations conducted with the GADGET-2 code to assess the impacts of factors such as gas clumping, AGN feedback, cooling flows, mergers, triaxiality, and the cluster's positional relationship to the observer’s line of sight. The key findings are as follows: \n\n- Gas clumpiness significantly influences SZ observable parameters, such as the integrated Comptonization value Y500 and the temperature profile P(r), particularly at smaller radii. \n- Regions with cooling flows yield lower Y500 estimates than anticipated from self-similar model calculations due to their reduced heat and density compared to other areas of the cluster.\n- Mergers can notably alter the shape of the pressure profile, resulting in increased central temperatures and steeper slopes toward the outer regions.\n- Triaxiality influences both the frequency and slope of the pressure profile, depending on its angle relative to the observer’s line of sight.\n- The inclination angle between the main axis of the cluster and the observer’s line of sight is crucial for the observed characteristics of galaxy clusters.",
        "ori-fast-z-score": -0.9332565252573828,
        "water-fast-z-score": 6.325405337855594,
        "rewrite-fast-z-score": 0.8164965809277261
    },
    {
        "original_text": "We present the results of an optical spectroscopic survey aimed at finding tidal dwarf galaxies (TDGs) candidates among a sample of ultraluminous infrared galaxies (ULIRG). We have obtained spectra with FORS2@VLT and GMOS-N@Gemini telescopes, covering the wavelength range between 3600 Å and 9200 Å , for a total of 16 ULIRGs selected on the basis of their high far-infrared luminosity (L FIR > 10 12 L ⊙ ) and low redshift (z < 0.1).\nThe main goal is to find TDGs that are expected to be found around interacting systems such as ULIRGs. The presence of young stars in these objects would make them detectable through strong emission lines like Hα or  OII  . However, we do not detect any significant excess of emission line flux over what can be explained by star formation occurring within the host galaxy itself. This result suggests either that there are no TDGs associated with our sample of ULIRGs or that they are too faint and/or too red to be detected using current facilities.",
        "watermark_text": "We present the conclusion of an optical spectroscopic study aiming at finding tidal dwarf stars ( TDGs ) candidates among a sample of ultraluminous infrared galaxies ( ULIRG ) . We have achieved spectra with FORS2 @ VLT and GMOS - N @ Gemini telescopes , covering the frequency range between 3600 Å and 9200 Å , for a total of 16 ULIRGs chosen on the basis of their high far - infrared luminosity ( L FIR > 10 12 L [UNK] ) and low redshift ( z < 0 . 1 ) .The main goal is to find TDGs that are expected to be found around interacting components such as ULIRGs . The appearance of young stars in these objects would create them detectable through strong emission lines like Hα or OII .However , we do not detect any considerable accumulation of emission point flux over what can be described by galaxy formation happening within the target star itself . This result suggests either that there are no TDGs associated with our sample of ULIRGs or that they are too bright and / or too blue to be identified using current technologies .",
        "rewrite_text": "We present the findings of an optical spectroscopic study aimed at identifying candidates for tidal dwarf galaxies (TDGs) within a sample of ultraluminous infrared galaxies (ULIRGs). We obtained spectra using FORS2 at the VLT and GMOS-N at the Gemini telescopes, covering a wavelength range from 3600 Å to 9200 Å, for a total of 16 ULIRGs selected based on their high far-infrared luminosity (L_FIR > 10^12 L☉) and low redshift (z < 0.1). The primary objective of this research is to locate TDGs, which are anticipated to exist around interacting components like ULIRGs. The emergence of young stars in these regions would make them detectable through prominent emission lines such as Hα or OII. However, our observations did not reveal any significant accumulation of emission point flux beyond what can be attributed to galaxy formation within the target star itself. This outcome implies that either no TDGs are associated with our sample of ULIRGs or that they are too luminous and/or too blue to be detected using current technology.",
        "ori-fast-z-score": 0.3779644730092272,
        "water-fast-z-score": 6.0,
        "rewrite-fast-z-score": 1.61245154965971
    },
    {
        "original_text": "In this article, we study the equivariant cohomology groups of twisted generalized complex manifolds with respect to compact Lie group actions. We show that these equivariant cohomology groups are isomorphic to those of ordinary generalized complex manifolds equipped with an invariant Hermitian metric and a compatible connection whose torsion is equal to the twisting form. As applications, we compute some examples in detail. In particular, for any closed oriented Riemann surface M , we give explicit formulas for all equivariant Betti numbers of the moduli space of stable vector bundles over M . \nIntroduction\n\nLet G be a compact connected Lie group acting on a smooth manifold X. The equivariant cohomology H*G(X) was introduced by Atiyah-Bott  1  as the cohomology ring of the Borel construction EG×_G X where EG denotes the universal bundle over BG = K(G, 1). It has been studied extensively since then (see e.g.,  2  ). For example, if X is a symplectic manifold acted upon by a torus T, then H*G(X), which can also be viewed as the equivariant cohomology of the corresponding Hamiltonian T-space, plays an important role in mirror symmetry  3  .\nThe notion of generalized complex geometry  4  provides us with another class of interesting geometric objects -the so-called generalized complex manifolds-which include both symplectic and complex manifolds as special cases. Generalized complex structures were first defined by Hitchin  5  using Courant algebroids  6  . Later Gualtieri  7  gave a more intrinsic definition via a pair of almost complex structures satisfying certain compatibility conditions. Recently, it was shown  8  that there exists a one-to-one correspondence between generalized complex structures and pairs consisting of a holomorphic Poisson structure and its associated Nijenhuis tensor field. This result allows us to define generalized complex structures intrinsically without referring to Courant algebroids; see  9  for details. \nGeneralized complex manifolds have attracted much attention recently due to their close connections with string theories  10  . Moreover, they provide new insights into many classical problems such as integr",
        "watermark_text": "In this article , we study the equivariant cohomology groups of distorted generalized complex manifolds with regard to compact Lie group actions . We see that these equivariant cohomology groups are isomorphic to those of simple generalized complex manifolds equipped with an invariant Hermitian metric and a compatible link whose torsion is equal to the twisting structure .As applications , we compute some examples in detail . In particular , for any closed oriented Riemann covering M , we give explicit formulas for all equivariant Betti numbers of the moduli space of stable vector bundles over M .Introduction Let G be a compact connected Lie ring acting on a smooth manifold X . The equivariant cohomology H * G ( X ) was introduced by Atiyah - Bott 1 as the cohomology ring of the Borel construction EG× _ G X where EG indicates the universal bundle over BG = K ( G , 1 ) .It has been studied frequently since then ( saw e . g . , 2 ) . For instance , if X is a symplectic bundle acting upon by a torus T , then H * G ( X ) , which can also be viewed as the equivariant cohomology of the associated Hamiltonian T - set , takes an important role in mirror symmetry 3 .The idea of generalized complex geometry 4 provides us with another class of interesting geometric objects - the so - called generalized complex manifolds - which contain both symplectic and complex manifolds as special cases . Generalized complex systems were first defined by Hitchin 5 utilizing Courant algebroids 6 .Later Gualtieri 7 gave a more intrinsic definition via a pair of almost complex objects satisfying particular compatibility constraints . Recently , it was shown 8 that there exists a one - to - one correspondence between generalized complex objects and pairs consisting of a holomorphic Poisson form and its associated Nijenhuis tensor field .This result allows us to define generalized complex relationships intrinsically without referring to Courant algebroids ; look 9 for information . Generalized complex manifolds have garnered considerable scrutiny lately owing to their deep ties with string structures 10 .Moreover , they give modern perspectives into numerous ancient problems such as integr",
        "rewrite_text": "This article examines the equivariant cohomology groups of distorted generalized complex manifolds in relation to actions of compact Lie groups. We demonstrate that these equivariant cohomology groups are isomorphic to those of simple generalized complex manifolds that feature an invariant Hermitian metric and a compatible structure whose torsion matches the twisting structure. As applications, we provide detailed computations of several examples. Notably, for any closed oriented Riemann surface \\( M \\), we present explicit formulas for all equivariant Betti numbers of the moduli space of stable vector bundles over \\( M \\).\n\n**Introduction**: Let \\( G \\) denote a compact connected Lie group acting on a smooth manifold \\( X \\). The equivariant cohomology \\( H^*_G(X) \\) was first introduced by Atiyah-Bott as the cohomology ring of the Borel construction \\( EG \\times_G X \\), where \\( EG \\) represents the universal bundle over \\( BG = K(G, 1) \\). This topic has attracted significant scholarly attention since its inception. For instance, if \\( X \\) is a symplectic bundle acted upon by a torus \\( T \\), the equivariant cohomology \\( H^*_G(X) \\) also serves as the equivariant cohomology of the associated Hamiltonian \\( T \\)-set, which plays a crucial role in mirror symmetry.\n\nThe concept of generalized complex geometry introduces a fascinating class of geometric structures known as generalized complex manifolds, which encompass both symplectic and complex manifolds as special cases. Hitchin originally defined generalized complex systems using Courant algebroids, while Gualtieri later provided a more intrinsic definition involving pairs of almost complex structures with specific compatibility conditions. Recent findings have established a one-to-one correspondence between generalized complex structures and pairs comprising a holomorphic Poisson form and its corresponding Nijenhuis tensor field. This discovery permits the intrinsic definition of generalized complex structures without invoking Courant algebroids. In recent years, generalized complex manifolds have attracted considerable attention due to their profound connections with string structures and their ability to offer fresh insights into numerous classical problems, such as integrability.",
        "ori-fast-z-score": 0.25819888974716115,
        "water-fast-z-score": 6.688444820557844,
        "rewrite-fast-z-score": 0.6713450866373513
    },
    {
        "original_text": "We present an analytical model for the longitudinal impedance and wakefield generated by a single period of an XFEL undulator, including effects due to electron beam emittance and energy spread. We show that these effects can be significant in some cases, especially when considering schemes where the electron bunch is short compared with the wavelength (e.g., self-amplified spontaneous emission). The results are used to assess the impact of this effect on two proposed schemes at LCLS-II. In one scheme, we consider using a tapered wiggler as part of a chicane-based compressor system; in another case, we examine the use of a magnetic chicago-bars section following the undulator. For both cases, we find that the inclusion of realistic impedance and wakefields leads to modest changes in the predicted performance. \n \n Keywords: Undulator, Wakefield, Impedance, Self-Amplified Spontaneous Emission",
        "watermark_text": "We present an analytical theory for the longitudinal impedance and wakefield generated by a single period of an XFEL undulator , covering effects due to ion beam emittance and energy spread . We suggest that these consequences can be large in some cases , particularly when using techniques where the electron bunch is short compared with the frequency ( e . g . , self - amplified spontaneous emission ) .The results are using to examine the impact of this effect on two proposed methods at LCLS - II . In one scheme , we imagine employing a tapered wiggler as part of a chicane - based compressor mechanism ; in another case , we investigate the using of a magnetic chicago - bars area following the undulator .For both cases , we find that the introduction of realistic impedance and wakefields contributes to modest changes in the expected performance . Keywords : Undulator , Wakefield , Impedance , Self - Amplified Spontaneous Emission",
        "rewrite_text": "We introduce an analytical theory that addresses the longitudinal impedance and wakefield generated by a single period of an XFEL undulator, taking into account the effects of ion beam emittance and energy spread. We note that these effects can be significant, particularly in situations involving techniques where the electron bunch length is short relative to the frequency (e.g., self-amplified spontaneous emission). Our findings are applied to evaluate the impact of these effects on two proposed methods at LCLS-II. In one approach, we consider using a tapered wiggler as part of a chicane-based compression mechanism; in another, we explore the use of a magnetic Chicago-bar architecture following the undulator. In both scenarios, we observe that the inclusion of realistic impedance and wakefields leads to modest alterations in the anticipated performance. Keywords: Undulator, Wakefield, Impedance, Self-Amplified Spontaneous Emission.",
        "ori-fast-z-score": -0.13018891098082389,
        "water-fast-z-score": 5.514870180108347,
        "rewrite-fast-z-score": 1.4084056792618558
    },
    {
        "original_text": "We study the effects of noise on spatially extended systems by using an extension of the concept of nonequilibrium potential (NEP). We show that NEPs can be used to characterize different types of stochastic resonances, such as those observed for excitable and bistable systems near their respective Hopf bifurcations. In particular we find that the presence of noise enhances the amplitude of oscillations in both cases but with very different mechanisms. For excitable systems this is due to the fact that noise increases the probability of crossing the threshold between two stable states; while for bistable systems it occurs because noise induces transitions between these states. Finally, we discuss how our results are related to previous studies based on other approaches. Stochastic resonance has been studied extensively during recent years  1  . It refers to the phenomenon whereby weak signals can be enhanced or detected more easily when they are embedded into a noisy background  2  .\nIn many physical situations, however, one needs to consider not only the effect of external noise sources but also internal fluctuations arising from the dynamics itself  3  . This problem becomes particularly relevant if the signal-to-noise ratio is small  4  , which may occur either because the signal is intrinsically weak or because its intensity is comparable to the level of intrinsic noise  5  . Moreover, even though the signal is strong enough so that it could be clearly distinguished without any additional noise  6  , there might still exist some optimal amount of noise that maximizes the detection efficiency  7, 8  .",
        "watermark_text": "We research the effects of noise on spatially extended systems by using an extension of the idea of nonequilibrium potential ( NEP ) . We see that NEPs can be used to characterize many kinds of stochastic resonances , such as those observed for excitable and bistable systems near their different Hopf bifurcations .In particular we find that the presence of noise enhances the frequency of oscillations in both cases but with very different mechanisms . For excitable systems this is due to the fact that noise changes the probability of reaching the threshold between two stable states ; while for bistable systems it appears because sound induces transitions between these states .Finally , we talk how our findings are related to previous research based on other methods . Stochastic resonance has been studied significantly during recent seasons 1 .It refers to the situation whereby soft signals can be enhanced or detected more easily when they are lodged into a loud background 2 . In many physical conditions , however , one needs to consider not only the impact of external sound sources but also internal fluctuations originating from the dynamics itself 3 .This problem appears particularly relevant if the signal - to - noise proportion is tiny 4 , which may happen either because the signal is intrinsically weak or because its brightness is equal to the level of intrinsic noise 5 . Moreover , even though the signal is strong enough so that it could be obviously differentiated without any additional noise 6 , there might nevertheless exist some optimal level of noise that maximizes the detection efficiency 7 , 8 .",
        "rewrite_text": "We investigate how noise affects spatially extended systems by extending the concept of nonequilibrium potential (NEP). Our findings demonstrate that NEPs can effectively characterize various forms of stochastic resonance, particularly in excitable and bistable systems near their different Hopf bifurcations. Notably, we discover that noise increases the frequency of oscillations in both types of systems, albeit through distinct mechanisms. In excitable systems, this enhancement arises because noise alters the likelihood of reaching the threshold between two stable states, while in bistable systems, it results from noise facilitating transitions between these states. Additionally, we discuss how our results relate to previous research methods. Stochastic resonance has been a significant area of study in recent years, referring to the phenomenon where weak signals are more easily detected against a loud background. However, in many physical scenarios, it is crucial to account for not just external noise sources but also the internal fluctuations that stem from the system's dynamics. This issue is especially pertinent when the signal-to-noise ratio is low, which can occur if the signal is inherently weak or if its strength is comparable to the intrinsic noise level. Furthermore, even when the signal is robust enough to be easily distinguished without added noise, there may still be an optimal level of noise that enhances detection efficiency.",
        "ori-fast-z-score": 0.38138503569823695,
        "water-fast-z-score": 6.928853368993243,
        "rewrite-fast-z-score": 1.0
    },
    {
        "original_text": "We present the results of numerical simulations of magnetohydrostatic equilibrium for solar prominences embedded into non-potential, sheared and twisted coronal fields. The model is based on solving numerically the Grad-Shafranov equation with boundary conditions at both ends of the computational domain that are derived using an approximate analytical solution to this problem. We find that the resulting equilibria have shapes similar to those observed in white-light coronagraph images. In particular, we show how the shape of the prominence changes as its position relative to the underlying photospheric magnetic flux distribution varies. Our results also demonstrate that the presence of shear and/or twist leads to significant deviations from potential-field models commonly used in theoretical studies of prominences. These findings may be useful for interpreting observations of prominences made by space-based instruments such as SDO/AIA. \n \n Keywords: Solar prominence, Magnetohydrostatics",
        "watermark_text": "We present the conclusion of computational simulations of magnetohydrostatic equilibrium for solar prominences localized into non - potential , sheared and spun coronal fields . The model is based on solving numerically the Grad - Shafranov equation with boundary conditions at both sides of the theoretical domain that are derived using an approximate mathematical solution to this question .We see that the resulting equilibria have shapes parallel to those observed in white - light coronagraph images . In particular , we find how the form of the prominence changes as its position relative to the underlying photospheric magnetic flux flow varies .Our results also demonstrate that the presence of shear and / or twist contributes to significant deviations from potential - field methods commonly used in theoretical analyses of prominences . These conclusions could be suitable for interpreting observations of prominences made by space - based instruments such as SDO / AIA .Keywords : Solar prominence , Magnetohydrostatics",
        "rewrite_text": "We present the results of computational simulations exploring magnetohydrostatic equilibrium in solar prominences situated within non-potential, sheared, and twisted coronal magnetic fields. Our model is developed by numerically solving the Grad-Shafranov equation, using boundary conditions on both ends of the theoretical domain derived from an approximate mathematical solution. The equilibria we obtain exhibit shapes that closely resemble those seen in white-light coronagraph images. Notably, we observe that the structure of the prominence changes depending on its position relative to the underlying photospheric magnetic flux flow. Our findings also highlight that the presence of shear and/or twist leads to considerable deviations from the potential-field models typically employed in theoretical analyses of prominences. These results may prove useful for interpreting observations of prominences captured by space-based instruments like SDO/AIA. \n\nKeywords: Solar prominence, Magnetohydrostatics",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.541868715470696,
        "rewrite-fast-z-score": -0.23570226039551587
    },
    {
        "original_text": "The multifractal nature of the human heartbeat has been studied by many authors, but most studies have focused on short time series (typically less than one hour). In this work we study the scaling properties of long-term recordings of the electrocardiograms (ECG) of healthy subjects during sleep using wavelet transforms to calculate the singularity spectrum f(α), which characterizes the degree of multifractality present in each signal.  We find that all signals are characterized by a broad range of exponents α indicating strong multifractality. The width Δα of these spectra decreases with increasing recording length T as Δα~T-1/2 for T<10 hours and Δα~T-3/4 for T>10 hours. This indicates that the ECGs become more monofractal-like when longer recordings are considered. Finally, we show how our results can be used to detect pathological changes in the heart rate variability associated with congestive heart failure.",
        "watermark_text": "The multifractal nature of the human heartbeat has been studied by many writers , but most studies have concentrated on short period series ( generally less than one minute ) . In this project we study the scaling effects of long - term recordings of the electrocardiograms ( ECG ) of healthy participants during sleep use wavelet transforms to estimate the singularity spectrum f ( α ) , which characterizes the degree of multifractality observed in each signal .We see that all signals are marked by a broad variety of exponents α indicating strong multifractality . The width Δα of these spectra decreases with increasing recording length T as Δα ~ T - 1 / 2 for T < 10 hours and Δα ~ T - 3 / 4 for T > 10 hours .This shows that the ECGs grow more monofractal - like when longer recordings are considered . Finally , we show how our findings can be used to identify pathological alterations in the chest rate variability associated with congestive heart failure .",
        "rewrite_text": "Numerous researchers have explored the multifractal characteristics of the human heartbeat, with the majority of studies focusing on short-duration series, typically lasting less than one minute. In this project, we examine the scaling effects of long-term electrocardiogram (ECG) recordings from healthy participants during sleep, utilizing wavelet transforms to estimate the singularity spectrum f(α), which reflects the level of multifractality present in each signal. Our analysis reveals a wide range of exponents α across all signals, indicating pronounced multifractality. We observe that the width Δα of these spectra decreases as the recording length T increases, following Δα ~ T^(-1/2) for T < 10 hours and Δα ~ T^(-3/4) for T > 10 hours. This suggests that ECGs exhibit more monofractal characteristics with longer recordings. Finally, we discuss how our results can aid in identifying pathological changes in heart rate variability associated with congestive heart failure.",
        "ori-fast-z-score": -0.508000508000762,
        "water-fast-z-score": 5.08000508000762,
        "rewrite-fast-z-score": 0.7385489458759964
    },
    {
        "original_text": "The aim of this study was to investigate the effect of novel antimicrobial cyclic peptides, named microbe-derived cationic ring structures (MCRs), on cell proliferation and apoptosis induction in A549 non-small-cell lung carcinoma cells. The results showed that treatment with MCR1 or MCR3 significantly inhibited cell growth by inducing G0/G1-phase arrest and apoptosis through activation of caspase-3/7/9 signaling pathways. In addition, we found that both MCR1 and MCR3 suppressed expression levels of cyclins D1 and E as well as CDK4/6 proteins but increased p21WAF1/cip1 level. Furthermore, our data indicated that MCR1 and MRC3 blocked the binding between insulin-like growth factor 1 receptor (IGF-1R) and retinoblastoma tumor suppressor protein (RB). These findings suggest that MCR1 and 3 may be potential therapeutic agents for treating lung cancers.",
        "watermark_text": "The goal of this study was to examine the impact of new antimicrobial cyclic peptides , designated microbe - derived cationic ring structures ( MCRs ) , on cell development and apoptosis activation in A549 non - large - cell lung carcinoma cells . The results suggested that treatment with MCR1 or MCR3 significantly inhibited cell development by inducing G0 / G1 - phase arrest and apoptosis through activation of caspase - 3 / 7 / 9 signaling pathways .In addition , we reported that both MCR1 and MCR3 reduced transcription rates of cyclins D1 and E as well as CDK4 / 6 factors but improved p21WAF1 / cip1 level . Furthermore , our information shown that MCR1 and MRC3 blocked the interaction between insulin - like growth factor 1 receptor ( IGF - 1R ) and retinoblastoma tumor suppressor protein ( RB ) .These data suggest that MCR1 and 3 might be possible therapeutic agents for controlling lung cancers .",
        "rewrite_text": "This study aimed to investigate the effects of novel antimicrobial cyclic peptides, termed microbe-derived cationic ring structures (MCRs), on cell growth and apoptosis in A549 non-small cell lung carcinoma cells. The findings indicated that treatment with MCR1 or MCR3 significantly suppressed cell growth by causing G0/G1 phase arrest and triggering apoptosis through the activation of the caspase-3/7/9 signaling pathways. Additionally, we observed that both MCR1 and MCR3 decreased the transcription levels of cyclins D1 and E, as well as CDK4/6, while enhancing the expression of p21WAF1/cip1. Moreover, our data demonstrated that MCR1 and MCR3 inhibited the interaction between the insulin-like growth factor 1 receptor (IGF-1R) and the retinoblastoma tumor suppressor protein (RB). These results suggest that MCR1 and MCR3 could serve as potential therapeutic agents in the treatment of lung cancer.",
        "ori-fast-z-score": -0.674199862463242,
        "water-fast-z-score": 5.715476066494082,
        "rewrite-fast-z-score": -0.40451991747794525
    },
    {
        "original_text": "We propose that the dark matter in our universe is composed of milli-charged particles, which are neutral under electromagnetism but carry an electric charge on the order of 10^(-6)e (electrons). We show how this scenario can be realized within the context of the Standard Model by introducing a new gauge boson with mass mX ~ 1TeV/c2 into the theory through the Stueckelberg extension to the Standard Model. The introduction of such a massive vector particle leads to modifications to the usual Feynman rules for charged fermions interacting via photons or gluons. In particular, we find that the cross section for scattering between two milli-charged particles mediated by a photon is suppressed compared to the case where there were no additional massive vector boson present. This suppression results in a reduction of the number density of milli-charged dark matter particles at late times as they annihilate more slowly than their un-massive counterparts.",
        "watermark_text": "We suggest that the dark matter in our universe is composed of milli - charged particles , which are stable under electromagnetism but hold an electric current on the order of 10 ^ ( - 6 ) e ( electrons ) . We see how this situation can be realized within the context of the Standard Model by bringing a new gauge boson with mass mX ~ 1TeV / c2 into the theory through the Stueckelberg extension to the Standard Model .The advent of such a huge vector particle leads to modifications to the usual Feynman conditions for charged fermions interacting via photons or gluons . In particular , we find that the cross section for absorption between two milli - charged particles mediated by a photon is suppressed compared to the case where there were no additional massive vector boson involved .This suppression results in a reduction of the number density of milli - charged dark matter molecules at late times as they annihilate more slowly than their un - massive counterparts .",
        "rewrite_text": "We propose that dark matter in our universe is made up of milli-charged particles, which are stable under electromagnetic interactions and carry an electric charge on the order of 10^(-6) times that of an electron. We demonstrate how this scenario can be realized within the framework of the Standard Model by incorporating a new gauge boson with a mass of approximately 1 TeV/c² through the Stueckelberg extension. The introduction of such a heavy vector particle necessitates adjustments to the conventional Feynman rules for charged fermions interacting via photons or gluons. Specifically, we discover that the cross-section for the absorption of two milli-charged particles mediated by a photon is diminished compared to the scenario where no additional massive vector boson is present. This reduction leads to a lower number density of milli-charged dark matter particles over time, as they annihilate more slowly than their massless counterparts.",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 4.25,
        "rewrite-fast-z-score": 1.016001016001524
    },
    {
        "original_text": "We present results for the evolution of magnetized protostellar accretion discs in which we have included both Ohmic and ambipolar diffusion, as well as radiative transfer effects using flux-limited diffusion (FLD). We find that the inclusion of these additional physical processes has important consequences for disc structure and evolution.  In particular, we show that the presence of an initial magnetic field can significantly affect the mass distribution within the disc at early times by suppressing fragmentation near the central star. This leads to more massive discs than those found previously with purely hydrodynamic simulations. The resulting discs are also less flared due to the increased pressure support provided by the magnetic field. As time progresses, however, the magnetic field is dissipated through ohmic dissipation and turbulence driven by gravitational instabilities. Once this happens, the disc becomes thinner and more flared compared to non-magnetic models.",
        "watermark_text": "We see results for the evolution of magnetized protostellar accretion balls in which we have incorporated both Ohmic and ambipolar diffusion , as well as radiative transfer effects utilizing flux - limited absorption ( FLD ) . We see that the introduction of these additional material processes has crucial consequences for disc composition and evolution .In particular , we find that the presence of an initial magnetic force can significantly affect the mass distribution within the disc at early periods by suppressing fragmentation near the main star . This leads to more massive discs than those identified previously with solely hydrodynamic simulations .The produced discs are also less flared due to the increased pressure support offered by the magnetic force . As time progresses , however , the magnetic force is dissipated through ohmic dissipation and turbulence driven by gravitational instabilities .Once this happens , the disc becomes thinner and more flared relative to non - magnetic models .",
        "rewrite_text": "We present findings on the evolution of magnetized protostellar accretion disks, incorporating both Ohmic and ambipolar diffusion, along with radiative transfer effects using flux-limited absorption (FLD). The inclusion of these additional material processes has significant implications for the composition and evolution of the disks. Notably, we discover that an initial magnetic force can have a profound impact on the mass distribution in the early stages, suppressing fragmentation near the central star. As a result, the disks formed are more massive than those produced in previous hydrodynamic simulations. Moreover, these disks exhibit less flaring due to the enhanced pressure support provided by the magnetic force. However, as time goes on, the magnetic force dissipates through ohmic dissipation and turbulence driven by gravitational instabilities. Once this dissipation occurs, the disk becomes thinner and more flared compared to non-magnetic models.",
        "ori-fast-z-score": 0.3511234415883917,
        "water-fast-z-score": 5.500933918218137,
        "rewrite-fast-z-score": 2.852798895551795
    },
    {
        "original_text": "We study the critical Casimir effect (CCE) between two parallel plates immersed into a liquid helium film at its superfluid transition temperature T_sf = 2.17 K, using Monte Carlo simulations based on the density functional theory for quantum fluids. We find that the CCE is strongly suppressed by the presence of the substrate and vanishes completely when the distance to it becomes smaller than about one molecular diameter. The results are compared with those obtained within the mean-field approximation which overestimates the magnitude of the effect considerably. In addition we show how the influence of the substrate can be taken into account in an approximate way. \nPACS numbers: 67.85.-j, 68.45.-k, 71.10.Fd \nI. INTRODUCTORY REMARK\nThe critical Casimir effect  1  , i.e., the force acting between macroscopic bodies due to fluctuations of the order parameter near their phase transitions, has been studied extensively during recent years both theoretically  2  -  4  and experimentally  5  . It was shown  6  that this effect may play important role in various physical phenomena such as capillary condensation  7, 8  or wetting  9  .\nIn particular, the critical Casimir effect plays crucial role in the physics of thin liquid helium films  10  where it leads to the appearance of additional forces  11  responsible for the formation of stable droplets  12  . These effects have been observed recently  13  in experiments performed on helium nanodroplets trapped inside magnetic traps  14  . However, most theoretical studies so far were restricted to idealized situations neglecting the influence of the substrate  15  -  17  . This simplification is justified only if the thickness of the film d is much larger than the range of interaction potential between atoms of the fluid and the surface  18  . For example, in case of 4 He films adsorbed on graphite substrates  19  the typical values of these parameters are  20  : r 0 ≈ 3Å, d ≈ 10 − 100 nm. Therefore, taking into account the substrate explicitly is necessary  21  especially close to the wetting transition  22  .",
        "watermark_text": "We research the critical Casimir effect ( CCE ) between two connected sheets immersed into a liquid helium movie at its superfluid transition rate T _ sf = 2 . 17 K , using Monte Carlo simulations based on the density functional theory for quantum fluids . We see that the CCE is strongly restrained by the presence of the substrate and vanishes totally when the distance to it becomes lower than about one molecular size .The results are compared with those achieved within the mean - field approximation which overestimates the severity of the impact considerably . In addition we show how the impact of the substrate can be taken into consideration in an approximate way .PACS codes : 67 . 85 . - j , 68 . 45 . - k , 71 . 10 . Fd I . INTRODUCTORY REMARK The essential Casimir effect 1 , i . e . , the force acting between macroscopic bodies owing to fluctuations of the order parameter near their phase transitions , has been studied thoroughly during recent months both theoretically 2 - 4 and experimentally 5 .It was shown 6 that this effect could play crucial role in different mechanical phenomena such as capillary condensation 7 , 8 or wetting 9 . In particular , the critical Casimir effect serves crucial role in the physics of dense liquid helium films 10 where it gives to the emergence of added forces 11 contributing for the formation of stable droplets 12 .These effects have been observed recently 13 in experiments conducted on helium nanodroplets caught inside magnetic traps 14 . However , most theoretical researchers so far were restricted to idealized scenarios neglecting the impact of the substrate 15 - 17 .This simplification is justified only if the length of the film d is much larger than the range of interaction potential between molecules of the liquid and the surface 18 . For instance , in case of 4 He films adsorbed on graphite substrates 19 the typical values of these parameters are 20 : l 0 ≈ 3Å , d ≈ 10 − 100 nm .Therefore , giving into consideration the substrate explicitly is required 21 especially close to the wetting transition 22 .",
        "rewrite_text": "We investigate the critical Casimir effect (CCE) that occurs between two connected sheets immersed in a liquid helium film at its superfluid transition temperature, T_sf = 2.17 K, through Monte Carlo simulations informed by density functional theory for quantum fluids. Our findings indicate that the presence of the substrate significantly restricts the CCE, which completely disappears when the separation from the substrate is reduced to approximately one molecular size. These results are contrasted with those obtained from mean-field approximations, which tend to greatly exaggerate the influence of the substrate. Additionally, we propose a method for approximately accounting for the substrate's effects. \n\n**PACS codes:** 67.85.-j, 68.45.-k, 71.10.Fd \n\n**I. INTRODUCTORY REMARKS** \n\nThe fundamental Casimir effect, which refers to the force acting between macroscopic bodies due to fluctuations in the order parameter near phase transitions, has been extensively studied both theoretically and experimentally in recent months. It has been demonstrated that this effect can significantly influence various mechanical phenomena, such as capillary condensation and wetting. In particular, the critical Casimir effect plays an important role in the behavior of dense liquid helium films, contributing to the emergence of additional forces that facilitate the formation of stable droplets. These effects have recently been observed in experiments involving helium nanodroplets captured in magnetic traps. However, most theoretical investigations have thus far focused on idealized models that disregard the influence of the substrate. This assumption is only valid when the film thickness (d) is substantially greater than the interaction potential range between the liquid molecules and the substrate. For example, in the case of 4 He films adsorbed on graphite substrates, the typical values are approximately l_0 ≈ 3 Å and d ≈ 10-100 nm. Therefore, it becomes essential to explicitly consider the substrate, particularly near the wetting transition.",
        "ori-fast-z-score": -0.6024640760767093,
        "water-fast-z-score": 7.20294057598537,
        "rewrite-fast-z-score": 2.0732842213952645
    },
    {
        "original_text": "We present high-order coupled cluster (CC) results for the ground state energy and magnetic susceptibility of several one-dimensional spin-1/2 Heisenberg models with nearest-neighbor interactions, including the isotropic chain, the anisotropic XXZ model, and the two-leg ladder system. We show that CC provides accurate results even at low temperatures where standard mean-field approaches fail to describe correctly the physics of these systems. In particular we find that the magnetization curve of the isotropic chain displays an unexpected non-monotonic behavior which can be explained by the presence of two competing phases characterized by different values of the staggered magnetization. Finally, we discuss how our results could be used as benchmark data for future numerical studies on more complicated two-dimensional or three-dimensional quantum magnets. The study of strongly correlated electron systems has been a central topic in condensed matter theory over many decades  1  . One important class of such materials are so-called quantum magnets  2  , i.e., compounds whose low-energy excitations are described by collective spin degrees of freedom. These systems have attracted considerable interest because they often display exotic phenomena like unconventional superconductivity  3  , fractionalized excitations  4  , or topological order  5  .\nIn recent years there has also been growing interest in studying artificially engineered quantum magnets  6  using ultracold atoms  7  or trapped ions  8  . This new field of research offers unprecedented possibilities to explore novel physical regimes  9  and it may lead to the development of new technologies  10  . However, despite their fundamental importance, theoretical investigations into quantum magnets remain challenging due to the strong correlations between the spins  11  . Therefore, finding reliable methods to calculate properties of these systems remains an active area of research  12  .\nOne particularly interesting example of a quantum magnet is given by the one-dimensional (1D) Heisenberg model  13  \nwhere J > 0 denotes the strength of the exchange interaction between neighboring sites j = 1, ..., L along the chain direction x, while S j ≡ c † j σc j describes the local spin operator acting on site j with Pauli matrices {σ}. Here {c † j } and {c",
        "watermark_text": "We present high - order correlated cluster ( CC ) results for the ground state energy and magnetic susceptibility of several one - dimensional spin - 1 / 2 Heisenberg configurations with nearest - neighbor interactions , notably the isotropic chain , the anisotropic XXZ model , and the two - leg ladder system . We see that CC provides reliable results even at low temperatures where standard mean - field methods fail to explain correctly the physics of these systems .In particular we find that the magnetization path of the isotropic chain exhibits an unexpected non - monotonic activity which can be described by the presence of two rival phases characterized by various values of the staggered magnetization . Finally , we talk how our findings may be used as benchmark data for future numerical studies on more complicated two - dimensional or three - dimensional quantum magnets .The investigation of highly correlated electron complexes has been a central topic in condensed matter theory over much generations 1 . One important group of such substances are so - called quantum magnets 2 , i . e . , compounds whose low - energy excitations are explained by collective spin degrees of liberty .These systems have garnered considerable interest because they frequently exhibit exotic processes like unconventional superconductivity 3 , fractionalized excitations 4 , or topological order 5 . In recent years there has also been growing interest in investigating artificially engineered quantum magnets 6 using ultracold atoms 7 or trapped ions 8 .This new area of research provides remarkable possibilities to examine novel physical regimes 9 and it could lead to the development of new concepts 10 . However , despite their vital importance , theoretical investigations into quantum magnets remain challenging due to the strong correlations between the spins 11 .Therefore , finding useful techniques to estimate features of these systems still an active area of research 12 . One especially interesting example of a quantum magnet is given by the one - dimensional ( 1D ) Heisenberg study 13 where J > 0 denotes the strength of the transfer coupling between neighboring sites j = 1 , . . . , L along the chain direction x , while S j ≡ c † j σc j describes the local spin operator acting on site j with Pauli matrices { σ } .Here { c † j } and { c",
        "rewrite_text": "We report high-order correlated cluster (CC) calculations for the ground state energy and magnetic susceptibility of various one-dimensional spin-1/2 Heisenberg systems featuring nearest-neighbor interactions. This includes the isotropic chain, the anisotropic XXZ model, and the two-leg ladder configuration. Our findings indicate that CC methods yield reliable results even at low temperatures, where traditional mean-field approaches often fall short in accurately capturing the physics of these systems. Notably, we observe that the magnetization curve of the isotropic chain displays an unexpected non-monotonic behavior, which we can attribute to the existence of two competing phases, each characterized by different levels of staggered magnetization. Furthermore, we discuss how our results could serve as benchmark data for future numerical investigations into more complex two-dimensional or three-dimensional quantum magnets.\n\nThe study of highly correlated electron systems has long been a key focus in condensed matter theory. A prominent subset of these systems includes quantum magnets, which are materials where the low-energy excitations can be understood through collective spin dynamics. These materials have attracted significant attention due to their potential to exhibit exotic phenomena such as unconventional superconductivity, fractionalized excitations, and topological order. Recently, there has been a surge of interest in exploring artificially engineered quantum magnets using ultracold atoms or trapped ions. This emerging research field offers exciting opportunities to investigate new physical regimes and could lead to the development of innovative concepts. However, despite their significance, theoretical studies of quantum magnets remain difficult due to the strong spin correlations involved, making the search for effective techniques to analyze these systems an ongoing area of research. A particularly interesting case of a quantum magnet is represented by the one-dimensional Heisenberg model, where J > 0 denotes the strength of the coupling between neighboring sites along the x-direction, and the local spin operator at site j is described as S_j ≡ c†_j σ c_j, with Pauli matrices {σ}.",
        "ori-fast-z-score": 1.5609177071190494,
        "water-fast-z-score": 8.845200340341279,
        "rewrite-fast-z-score": 2.204829171682146
    },
    {
        "original_text": "We study the charm quark fragmentation into hadrons in perturbative QCD by using an effective coupling constant, which is determined so as to reproduce the experimental data on the total cross section for e+e-annihilation into hadrons at high energies.  We find that our results are consistent with those obtained within the framework of the conventional parton model and also with recent measurements performed by CLEO collaboration. The present analysis suggests that the charm quark fragmentation function can be well described by the Peterson form factor multiplied by a simple exponential function. \nPACS numbers: 11.10.Kk, 12.38.Qk, 13 .60.Hb \nI. INTRODUCTORY REMAR K\nIn this work we investigate the charm quark fragmentation functions (FFs) into light hadrons in perturbative quantum chromodynamics(pQCD). In particular, we use an effective coupling constant, αeff , which is determined so as t o reproduce the experimental data on thetotal cross section for e + e-annihilation into hadronsthat have been measured recentlybyCLEOcollaboration  1  .\nThe FFsof quarksintohadronicparticlesare important quantitiesin pQCDand they playanimportant role inthe calculationof various physical observables suchas the structurefunctions  2  ,the Drell-Yanprocess  3  ,and the semi-leptonic decay  4  . It hasbeen shownthat the FFsof quarksintohadronscan be calculatedperturbatively  5  -  8  . However, it shouldbe notedthatthe calculationsrequire veryhighenergy scales  9  . Therefore,it would be usefulto determineαefffromexperimentaldataat relativelylowenergies  10  .",
        "watermark_text": "We research the charm quark fragmentation into hadrons in perturbative QCD by using an efficient coupling constant , which is calculated so as to reproduce the empirical data on the total cross section for r + e - annihilation into hadrons at high energies . We see that our findings are compatible with those achieved within the framework of the usual parton theory and also with recent observations performed by CLEO collaboration .The present research suggests that the charm quark fragmentation distribution can be well described by the Peterson form value multiplied by a simple exponential function . PACS codes : 11 . 10 . Kk , 12 . 38 . Qk , 13 . 60 . Hb I .INTRODUCTORY REMAR K In this research we investigate the charm quark fragmentation functions ( FFs ) into light hadrons in perturbative quantum chromodynamics ( pQCD ) . In particular , we utilize an efficient coupling constant , αeff , which is calculated so as t o reproduce the empirical data on thetotal cross section for e + e - annihilation into hadronsthat have been measured recentlybyCLEOcollaboration 1 .The FFsof quarksintohadronicparticlesare crucial quantitiesin pQCDand they playanimportant importance inthe calculationof various physical observables suchas the structurefunctions 2 , the Drell - Yanprocess 3 , and the semi - leptonic decay 4 . It hasbeen shownthat the FFsof quarksintohadronscan be calculatedperturbatively 5 - 8 .However, it shouldbe notedthatthe calculationsrequire veryhighenergy scales  9  .Therefore,it would be usefulto determineαefffromexperimentaldataat relativelylowenergies  10  .",
        "rewrite_text": "In this study, we explore the fragmentation of charm quarks into hadrons within the framework of perturbative quantum chromodynamics (pQCD). We employ an efficient coupling constant, α_eff, which is determined to reproduce empirical measurements of the total cross section for e⁺ e⁻ annihilation into hadrons at high energies, as obtained by the CLEO collaboration. Our results align with findings from traditional parton theory as well as recent experimental observations. We propose that the charm quark fragmentation distribution can be effectively described by a Peterson-type function scaled by a simple exponential factor. \n\nPACS codes: 11.10.Kk, 12.38.Qk, 13.60.Hb\n\n**I. INTRODUCTION**  \nThis research focuses on the charm quark fragmentation functions (FFs) into light hadrons in the context of pQCD. We specifically analyze an efficient coupling constant, α_eff, which is calculated to match the empirical total cross section data for e⁺ e⁻ annihilation into hadrons recently reported by the CLEO collaboration. The fragmentation functions of quarks into hadronic particles are fundamental in pQCD, contributing significantly to the calculation of various physical observables, including structure functions, the Drell-Yan process, and semi-leptonic decays. While it has been established that quark fragmentation functions can be computed perturbatively, these calculations typically necessitate very high-energy scales. Thus, determining α_eff from experimental data at relatively lower energies presents a valuable approach.",
        "ori-fast-z-score": -1.212678125181665,
        "water-fast-z-score": 5.898906801202691,
        "rewrite-fast-z-score": 0.7337993857053429
    },
    {
        "original_text": "We present new constructions for locally decodable codes (LDCs) based on nice subsets of finite fields, prime factors of Mersenne numbers, and the Chinese remainder theorem. Our first construction is an explicit family of LDCs with optimal query complexity that are derived from nice subsets of finite fields. We then show how to use these results in conjunction with the Chinese remainder theorem to obtain families of LDCs whose parameters can be tuned by varying the number of primes used in their construction. Finally we give a lower bound on the length of any LDC over a binary alphabet which uses only one-sided queries. The proofs of our main theorems appear at the end of this extended abstract. \nIntroduction\n\nLocally decodable codes (abbreviated as LCDs)\nare error correcting codes where each codeword has associated with it some decoding algorithm that allows efficient recovery of individual bits or symbols when queried about them. In particular, if the codeword is corrupted by up to t errors, then there exists a deterministic polynomial time algorithm that recovers the original uncorrupted word using O(t) queries per symbol. This property makes such codes useful in applications like data storage systems, peer-to-peer networks, and streaming media distribution services. \n \n A large body of work has been devoted towards understanding the trade-off between the rate of the code, its distance, and the query complexity of the decoder. For example, Guruswami et al. (2005), Chan et al. (2006) , and Kopparty & Saraf (2007)  studied the problem of constructing codes with low query complexity while maintaining high rates and distances. Recently, several works have focused on improving the known bounds on the minimum possible query complexity required to decode a single bit given a certain amount of corruption. These include the recent breakthrough result of Dvir et al. (2010a) (which improved upon the previous best-known upper bound due to Sudan et al., 2005 ) and the subsequent improvements made by Dvir et al. (2011 ), Feldman et al. (2012 , and Kopparty et al. (2013) . \n \n Another important",
        "watermark_text": "We introduce novel constructions for locally decodable codes ( LDCs ) based on pleasant subsets of finite fields , prime elements of Mersenne numbers , and the Chinese remainder theorem . Our first build is an explicit class of LDCs with optimal query complexity that are derived from good subsets of finite fields .We then show how to use these results in partnership with the Chinese remainder theorem to obtain families of LDCs whose parameters can be tuned by varying the number of primes used in their design . Finally we give a smaller bound on the length of any LDC over a binary alphabet which uses only one - sided queries .The proofs of our major theorems emerge at the end of this enlarged abstract . Introduction Locally decodable codes ( denoted as LCDs ) are mistake correcting codes where each codeword has associated with it some decoding algorithm that enables efficient returning of individual characters or characters when queried about them .In particular , if the codeword is corrupted by up to t errors , then there exists a deterministic polynomial period algorithm that recovers the actual uncorrupted phrase using O ( t ) queries per symbol . This property gives such codes helpful in applications like data storage systems , peer - to - peer systems , and streaming media distribution services .A vast body of research has been focused towards studying the trade - off between the frequency of the code , its location , and the query complexity of the decoder . For instance , Guruswami et al .( 2005 ) , Chan et al . ( 2006 ) , and Kopparty & Saraf ( 2007 ) studied the question of constructing coding with little query complexity while maintaining high frequencies and distances .Recently , various efforts have concentrated on improving the known bounds on the minimum possible query complexity required to decode a single bit given a certain quantity of corruption . These include the recent breakthrough result of Dvir et al .( 2010a ) ( which updated upon the previous good - used upper bound due to Sudan et al . , 2005 ) and the subsequent improvements done by Dvir et al . ( 2011 ) , Feldman et al .( 2012 , and Kopparty et al . ( 2013 ) .Another important",
        "rewrite_text": "We present novel constructions for locally decodable codes (LDCs) utilizing pleasant subsets of finite fields, prime elements of Mersenne numbers, and the Chinese remainder theorem. Our first construction is an explicit class of LDCs with optimal query complexity, which is based on good subsets of finite fields. We then demonstrate how these findings, combined with the Chinese remainder theorem, result in families of LDCs with adjustable parameters determined by the number of primes used in their construction. Additionally, we establish a tighter bound on the length of any LDC utilizing a binary alphabet that only employs one-sided queries. The proofs for our key theorems are included at the conclusion of this extended abstract. \n\nIntroduction: Locally decodable codes (LDCs) are error-correcting codes that associate each codeword with a decoding algorithm, allowing for the efficient retrieval of individual symbols upon request. Specifically, if a codeword is subject to up to t errors, there exists a deterministic polynomial-time algorithm that can recover the original, uncorrupted sequence using O(t) queries per symbol. This characteristic makes LDCs advantageous for applications in data storage, peer-to-peer systems, and streaming media distribution. Significant research has focused on understanding the trade-offs between code frequency, location, and decoder query complexity. For example, Guruswami et al. (2005), Chan et al. (2006), and Kopparty & Saraf (2007) explored methods for constructing codes with low query complexity while preserving high frequency and distance. Recently, various studies have aimed at tightening the known bounds on the minimum query complexity required to decode a single bit given a certain level of corruption, including a breakthrough by Dvir et al. (2010a) that improved upon earlier upper bounds established by Sudan et al. (2005), followed by enhancements from Dvir et al. (2011), Feldman et al. (2012), and Kopparty et al. (2013). Another significant aspect of this research is...",
        "ori-fast-z-score": -0.40689422938557973,
        "water-fast-z-score": 7.021870595978444,
        "rewrite-fast-z-score": -0.1690308509457033
    },
    {
        "original_text": "We study the dynamics of glassy states formed by particles interacting via short-range repulsion or attraction, using molecular-dynamics simulations at constant volume. We find that both types of systems exhibit non-Arrhenius relaxation with Vogel-Fulcher-Tammann (VFT) temperature dependence. The VFT temperatures are found to be higher for attractive than for repulsive interactions. In addition we show that the diffusion coefficients follow the Stokes-Einstein relation only when plotted as functions of the structural relaxation time. This is explained by considering the role played by elastic stresses on particle mobility. Finally, we discuss how our results can be used to understand recent experiments performed on colloids confined between two plates. Glass-forming liquids have been studied extensively over many decades  1  . Despite this effort there remain open questions about their properties  2  , including whether they obey the StokesEinstein relation  3  .\nIn particular it has recently become possible to prepare colloidal suspensions which form amorphous solids  4  . These materials provide an ideal opportunity to investigate the relationship between structure and dynamics  5  . However, despite considerable experimental  6  and theoretical  7  efforts, the nature of the slow dynamics observed in these systems remains controversial  8  .",
        "watermark_text": "We research the dynamics of glassy states formed by particles bonding via low - range repulsion or attraction , using cell - mechanics simulations at constant volume . We see that both types of solutions undergo anti - Arrhenius relaxation with Vogel - Fulcher - Tammann ( VFT ) thermal dependence .The VFT altitudes are found to be higher for attractive than for repulsive molecules . In addition we find that the diffusion coefficients observe the Stokes - Einstein function only when plotted as functions of the structural relaxation time .This is understood by examining the part played by elastic forces on particle mobility . Finally , we talk how our findings can be used to explain latest studies performed on colloids confined between two plates .Glass - creating liquids have been studied thoroughly over numerous years 1 . Despite this progress there remain open questions about their characteristics 2 , particularly whether they obey the StokesEinstein connection 3 .In particular it has recently become able to make colloidal suspensions which create amorphous solids 4 . These substances give an excellent chance to examine the relationship between form and dynamics 5 .However , despite considerable experimental 6 and theoretical 7 attempts , the nature of the slow behavior observed in these systems still controversial 8 .",
        "rewrite_text": "We investigate the dynamics of glassy states formed by particles that connect through weak-range repulsive or attractive interactions, utilizing cell-mechanics simulations at constant volume. Our findings reveal that both types of interactions exhibit anti-Arrhenius relaxation characterized by Vogel-Fulcher-Tammann (VFT) thermal dependence. Notably, we observe that the VFT parameters are higher for attractive molecules compared to repulsive ones. Furthermore, we discover that diffusion coefficients align with the Stokes-Einstein relation only when plotted against structural relaxation time, which we attribute to the role of elastic forces in particle mobility. Finally, we discuss how our results can shed light on recent studies involving colloids confined between two plates. The study of glass-forming liquids has advanced significantly over the years. Nevertheless, questions regarding their properties remain, particularly concerning compliance with the Stokes-Einstein relationship. Recently, the ability to create colloidal suspensions that form amorphous solids has emerged, providing a valuable opportunity to explore the link between structural composition and dynamics. However, despite extensive experimental and theoretical research, the nature of the slow dynamics observed in these systems continues to be a topic of debate.",
        "ori-fast-z-score": 0.3110855084191276,
        "water-fast-z-score": 8.399308727316445,
        "rewrite-fast-z-score": 1.5389675281277313
    },
    {
        "original_text": "We have studied the thick brane model in which our universe is embedded into an extra dimension and found that it can explain some recent observations such as cosmic microwave background anisotropy, supernovae Ia data and baryon acoustic oscillations without introducing any new physics beyond standard model. \n \n In this model, we assume that there exists a scalar field whose potential has two degenerate minima at different values of the vacuum expectation value (VEV). The VEVs are determined by the parameters of the potential. We find that if the difference between these VEVs is large enough to satisfy the condition for the existence of stable domain walls then the thickness of the wall becomes larger than the Hubble radius today. This means that the domain walls cannot be produced during inflationary epoch. On the other hand, if the difference between these vacua is small compared to the Hubble scale, the domain walls will be created after inflation but they decay before nucleosynthesis era due to their extremely high tension.",
        "watermark_text": "We have researched the deep brane model in which our universe is anchored into an additional dimension and found that it can describe some latest measurements such as cosmic microwave background anisotropy , supernovae Ia data and baryon acoustic oscillations without exploring any new science beyond standard model . In this description , we suppose that there exists a scalar field whose potential has two degenerate minima at different values of the vacuum expectation value ( VEV ) .The VEVs are decided by the variables of the potential . We see that if the difference between these VEVs is huge enough to meet the requirement for the existence of stable domain barriers then the length of the wall grows larger than the Hubble diameter today .This implies that the domain barriers cannot be formed during inflationary epoch . On the other hand , if the difference between these vacua is tiny relative to the Hubble scale , the domain barriers will be formed after inflation but they decay before nucleosynthesis era due to their extremely raised tension .",
        "rewrite_text": "We have investigated the deep brane model, which posits that our universe is anchored to an additional dimension, and found that it effectively explains recent measurements, including cosmic microwave background anisotropy, Type Ia supernova data, and baryon acoustic oscillations, without introducing any new physics beyond the standard model. In this framework, we propose the existence of a scalar field with a potential that features two degenerate minima at different vacuum expectation values (VEVs). The values of these VEVs are determined by the parameters of the potential. If the difference between these VEVs is sufficiently large to allow for stable domain barriers, the size of the wall could exceed the current Hubble diameter. This suggests that domain barriers could not form during the inflationary period. Conversely, if the difference between the vacua is small compared to the Hubble scale, domain barriers may form after inflation but would subsequently decay before the nucleosynthesis era due to their significantly high tension.",
        "ori-fast-z-score": -2.629502940535666,
        "water-fast-z-score": 4.063777271736939,
        "rewrite-fast-z-score": 0.46499055497527714
    },
    {
        "original_text": "In this work, we study the problem of clustering co-occurrences of maximal frequent patterns (MFP) in streams. We propose an algorithm that clusters MFPs based on their occurrences and then uses these clusters to build a compact representation for each pattern. The proposed approach is efficient both in terms of space consumption as well as time required to process new data points. Our experimental results show that our method outperforms state-of-the-art algorithms by up to two orders of magnitude while achieving high accuracy. In addition, it can be easily parallelized using existing frameworks such as MapReduce or Spark. Keywords: Data stream mining, Cluster analysis, Frequent itemset mining, Association rule learning, Time series prediction. 1 Introduction Mining large volumes of streaming data has become increasingly important over recent years due to its wide range of applications including sensor networks  20, 21  , social media analytics  22  , fraud detection  23  , network intrusion detection  24  , etc.. However, processing massive amounts of streaming data poses several challenges since traditional batch-based approaches are not applicable anymore  25  . For example, if one wants to detect anomalies in a continuous flow of tweets, he needs to continuously monitor all incoming messages and identify those which deviate significantly from normal behavior  26  .\nTo address these issues, researchers have developed various techniques for analyzing data streams  7, 8, 27  . An emerging area within data stream mining focuses on discovering interesting patterns from data streams  28  . A common task in this context is finding frequent items/patterns in data streams  29  . Another popular research direction involves identifying correlations between different attributes  30  . These tasks are often performed jointly with classification  31  and/or regression  32  problems.",
        "watermark_text": "In this research , we study the question of clustering co - occurrences of maximal frequent patterns ( MFP ) in streams . We suggest an algorithm that clusters MFPs based on their occurrences and then uses these clusters to build a compact form for each pattern .The proposed approach is efficient both in terms of space requirements as well as space required to collect new data sets . Our research results show that our technique outperforms state - of - the - art algorithms by up to two orders of magnitude while reaching large accuracy .In addition , it can be easily parallelized using existing frameworks such as MapReduce or Spark . Keywords : Data stream analysis , Cluster processing , Frequent itemset searching , Association control learning , Time series modeling .1 Introduction Mining huge volumes of streaming information has become rapidly interesting over recent years owing to its large variety of applications notably sensor networks 20 , 21 , social media analytics 22 , fraud detection 23 , network intrusion detection 24 , etc . . However , processing massive sums of streaming information poses various challenges since traditional batch - based methods are not applicable today 25 .For instance , if one wants to identify anomalies in a rapid stream of tweets , he requires to constantly watch all outgoing messages and locate those which deviate substantially from normal behavior 26 . To address these problems , researchers have developed various methods for studying data loops 7 , 8 , 27 .An developing region within information stream mined focuses on discovering interesting trends from information streams 28 . A prevalent problem in this environment is identifying significant items / patterns in data streams 29 .Another common study trend includes identifying correlations between various qualities 30 . These tasks are often worked collectively with classification 31 and / or regression 32 questions .",
        "rewrite_text": "In this study, we explore the clustering of co-occurrences of maximal frequent patterns (MFP) in data streams. We propose an algorithm that groups MFPs according to their occurrences and utilizes these clusters to create a compact representation for each pattern. Our approach is efficient in terms of both space requirements and the resources needed to collect new datasets. Our findings demonstrate that our technique significantly outperforms state-of-the-art algorithms, achieving improvements of up to two orders of magnitude while maintaining a high level of accuracy. Furthermore, it can be easily parallelized using established frameworks like MapReduce or Spark. \n\nKeywords: Data stream analysis, Cluster processing, Frequent itemset searching, Association rule learning, Time series modeling.\n\n1. Introduction\n\nRecent years have seen a surge in interest in mining large volumes of streaming information, driven by a wide range of applications, including sensor networks, social media analytics, fraud detection, and network intrusion detection. However, processing vast amounts of streaming data presents significant challenges, as traditional batch-based methods are no longer suitable. For example, to detect anomalies in a fast-paced stream of tweets, it is essential to continuously monitor all outgoing messages and identify those that significantly deviate from normal behavior. In response to these challenges, researchers have developed various techniques for analyzing data streams. A burgeoning area within this field focuses on uncovering intriguing trends from streaming data. A major issue in this context is the identification of significant items or patterns within the data streams. Additionally, a common research trend involves uncovering correlations among various attributes. These tasks are frequently addressed in conjunction with classification or regression problems.",
        "ori-fast-z-score": -1.655211777204736,
        "water-fast-z-score": 9.26918595234652,
        "rewrite-fast-z-score": 0.50709255283711
    },
    {
        "original_text": "We study isospin-breaking effects on the production rate for heavy-light mesons (D, D*) and light-heavy mesons (D0, D0bar). We use an effective field theory approach to calculate these rates at leading order in perturbation theory. The results are compared with experimental data obtained by CLEO-c. \n \n Isospin symmetry plays an important role in hadronic physics. It relates states that differ only in their charge but have identical masses. In particular it implies that the strong decay widths of charged and neutral pions should be equal. However, this equality has been experimentally tested down to pion momenta as low as 1 MeV/c and deviations up to 20% were found  1  . These deviations can be explained within Chiral Perturbation Theory  2  , which predicts corrections proportional to powers of the momentum transfer between initial and final state particles. At higher energies, where the typical momentum transfers become larger than the chiral scale, one expects such corrections to vanish rapidly  3  .\n \nIn contrast, we consider here processes involving two heavy quarks close to threshold. Here, the typical momentum transfers are small enough so that non-perturbative contributions cannot be neglected anymore. As a consequence, even though the mass difference between charm and anti-charm quarks is tiny, there will still be significant differences between the corresponding cross sections  4  . \n \n This effect was first observed more than 20 years ago  5  when studying the production of charmed mesons in electron-positron collisions. Since then many experiments  6  -  8  have measured the ratio of the production rates for different combinations of heavy-meson pairs. While some of them find good agreement with theoretical predictions  9  based on Heavy Quark Effective Theory  10  , others disagree significantly  11  .",
        "watermark_text": "We research isospin - breaking effects on the production frequency for heavy - heavy mesons ( D , D * ) and light - heavy mesons ( D0 , D0bar ) . We use an efficient field model approach to estimate these rates at leading order in perturbation theory .The results are compared with experimental evidence derived by CLEO - c . Isospin symmetry serves an important role in hadronic physics . It relates states that differ only in their charge but have equal masses .In particular it assumes that the strong decay widths of charged and neutral pions should be equal . However , this equality has been experimentally tested down to pion momenta as low as 1 MeV / c and deviations up to 20 % were found 1 .These deviations can be described within Chiral Perturbation Theory 2 , which predicts corrections proportional to powers of the velocity transfer between initial and final state particles . At higher energies , where the typical velocity transfers become bigger than the chiral scale , one expects such corrections to vanish swiftly 3 .In comparison , we treat here reactions involving two heavy quarks close to threshold . Here , the typical velocity transfers are small enough so that non - perturbative contributions never be forgotten anymore .As a consequence , even though the mass gap between charm and pro - charm quarks is tiny , there will still be considerable changes between the associated cross sections 4 . This phenomenon was first observed more than 20 centuries earlier 5 when examining the production of charmed mesons in electron - positron collisions .Since then many tests 6 - 8 have tested the proportion of the production rates for different combinations of heavy - meson pairs . While some of them find good agreement with theoretical estimates 9 based on Heavy Quark Effective Theory 10 , others disagree significantly 11 .",
        "rewrite_text": "We investigate isospin-breaking effects on the production rates of heavy-heavy mesons (D, D*) and light-heavy mesons (D0, D0-bar). Utilizing an efficient field model approach, we estimate these rates at leading order in perturbation theory. Our findings are compared with experimental data from CLEO-c. Isospin symmetry plays a crucial role in hadronic physics, connecting states that differ only in charge while maintaining equal masses. Specifically, it postulates that the strong decay widths of charged and neutral pions should be identical. However, experimental tests down to pion momenta of 1 MeV/c have revealed deviations of up to 20%. These discrepancies can be explained using Chiral Perturbation Theory, which predicts corrections proportional to the velocity transfer between initial and final state particles. At higher energies, where typical velocity transfers exceed the chiral scale, these corrections are expected to diminish quickly. In contrast, our analysis focuses on reactions involving two heavy quarks near threshold, where the velocity transfers are sufficiently small that non-perturbative contributions cannot be ignored. Consequently, despite the minimal mass gap between charm and anti-charm quarks, significant variations in the associated cross sections can occur. This phenomenon was first noted over 20 years ago when studying charmed meson production in electron-positron collisions. Since then, multiple studies have investigated the production rates for various heavy-meson pairs. While some findings align well with theoretical predictions based on Heavy Quark Effective Theory, others show notable discrepancies.",
        "ori-fast-z-score": -0.08873565094161139,
        "water-fast-z-score": 6.529318494299385,
        "rewrite-fast-z-score": 2.70426394389691
    },
    {
        "original_text": "The cosmological constant is one of the most important parameters in modern physics, and its value has been determined by observations to be extremely small but nonzero.  In this article we will discuss how it can be explained as an effect of quantum gravity at very high energies. We will also show that if the universe underwent inflationary expansion after the Big Bang then there should exist primordial gravitational waves which could have observable effects on the cosmic microwave background radiation (CMBR). Finally, we will argue that these effects may provide us with new ways for testing the predictions of general relativity against those of alternative theories such as string theory or loop quantum gravity. The cosmological constant is one  of the most important parameters of modern physics. Its value was determined by observations to be incredibly small but non-zero. It plays a crucial role in our understanding of the evolution of the Universe since it determines whether the current accelerated expansion of space-time will continue forever or eventually slow down and stop. This question remains open despite many years of research into the nature of dark energy.",
        "watermark_text": "The cosmological coefficient is one of the most important components in modern physics , and its value has been determined by observations to be extremely tiny but nonzero . In this page we will explore how it can be described as an influence of quantum gravitational at very high energies .We will also demonstrate that if the universe underwent inflationary inflation after the Big Bang then there should exist primordial gravitational waves which could have observable effects on the cosmic microwave background radiation ( CMBR ) . Finally , we will argue that these consequences may provide us with novel ways for testing the assumptions of general relativity against those of alternative theories such as string theory or loop quantum gravitational .The cosmological coefficient is one of the most important characteristics of modern physics . Its value was calculated by observations to be incredibly small but un - zero .It holds a crucial role in our understanding of the evolution of the Universe since it determines whether the present rapid expansion of space - time will continue forever or eventually halt down and stop . This question stays open despite many years of research into the nature of dark energy .",
        "rewrite_text": "The cosmological constant is a fundamental aspect of contemporary physics, with observational data indicating that its value is exceedingly small yet distinctly nonzero. In this section, we will examine how it can be interpreted as an effect of quantum gravity at extremely high energies. We will also illustrate that if the universe experienced inflation after the Big Bang, primordial gravitational waves should exist, potentially impacting the cosmic microwave background radiation (CMBR). Additionally, we will propose that these effects might offer new avenues for testing the principles of general relativity against alternative theories, such as string theory or loop quantum gravity. The cosmological constant plays a vital role in our comprehension of the universe's evolution, influencing whether the current swift expansion of spacetime will persist indefinitely or eventually cease. Despite extensive research into dark energy, this question remains unresolved.",
        "ori-fast-z-score": 1.8225913092242512,
        "water-fast-z-score": 6.038635299392551,
        "rewrite-fast-z-score": 0.7276068751089989
    },
    {
        "original_text": "We present an algorithm that efficiently creates and propagates order in spin chains with the help of geodesic paths on graphs representing the spins. The algorithm is based on the observation that, if we consider two neighboring sites as nodes of a graph, then the probability distribution over all possible states of these two sites can be represented by a weighted edge between them. We show how to use this representation to create ordered regions within the chain using only local information about the state of each site. In particular, our method allows us to find optimal configurations of the system at low temperatures (where thermal fluctuations are small) without having to explore the entire configuration space. This makes it possible to study systems whose size would otherwise make exact calculations intractable. Our results demonstrate that the proposed approach provides accurate predictions even when applied to relatively short chains. Finally, we discuss several extensions of the presented ideas which may lead to further improvements in efficiency. \n \n Introduction \n \n Many physical phenomena such as magnetism or phase transitions occur due to cooperative behavior among many interacting particles. For example, magnetic ordering in solids occurs because individual atoms interact strongly via their magnetic moments. Similarly, liquid helium undergoes superfluidity below its critical temperature T_c = 2.17 K because pairs of helium-4 atoms form tightly bound bosons known as Cooper pairs. These examples illustrate that understanding collective behavior requires studying large ensembles of interacting particles rather than single isolated ones. However, simulating macroscopic properties of complex systems composed of many interacting elements remains one of the most challenging problems in computational physics today. Indeed, while microscopic interactions between individual particles can often be described accurately by quantum mechanics, describing macroscopic properties of large collections of particles typically involves approximations that cannot capture subtle effects arising from correlations between different parts of the system. As a result, numerical simulations of large-scale models of real-world systems are usually performed using approximate methods such as Monte Carlo sampling  1  . Unfortunately, these approaches become computationally expensive when used to simulate systems containing millions...",
        "watermark_text": "We create an algorithm that efficiently creates and propagates order in spinning chains with the aid of geodesic tracks on graphs representing the spins . The algorithm is based on the observation that , if we treat two adjacent sites as nodes of a graph , then the probability distribution over all possible states of these two locations can be represented by a weighted edge between them .We see how to use this representation to create ordered regions within the chain using only local information about the state of each site . In particular , our technique permits us to find optimal configurations of the system at low temperatures ( where thermal fluctuations are small ) without having to examine the entire configuration room .This gives it able to study systems whose size would normally leave accurate calculations intractable . Our results show that the suggested approach offers easy forecast even when applied to relatively short chains .Finally , we explain several extensions of the offered concepts which would result to further developments in efficiency . Introduction Many mechanical phenomena such as magnetism or phase transitions occur due to cooperative behavior among various interacting particles .For instance , magnetic ordering in solids occurs because individual molecules interact heavily via their magnetic moments . Similarly , fluid helium undergoes superfluidity below its critical temperature T _ c = 2 . 17 K because pairs of helium - 4 molecules form tightly bound bosons called as Cooper pairs .These examples indicate that understanding collective behavior needs investigating big ensembles of interacting interactions instead than single isolated ones . However , simulating macroscopic properties of complex systems composed of several interacting elements becomes one of the most challenging difficulties in computational physics today .Indeed , while microscopic interactions between individual objects can often be described properly by quantum mechanics , exploring macroscopic properties of large collections of particles usually includes approximations that cannot reproduce subtle effects resulting from correlations between various parts of the system . As a result , numerical simulations of large - scale models of real - time systems are typically performed using approximate methods such as Monte Carlo sampling 1 .Unfortunately , these perspectives prove computationally expensive when utilized to simulate systems containing millions . . .",
        "rewrite_text": "We have developed an efficient algorithm for establishing and managing order in spinning chains by utilizing geodesic paths on graphs that depict the spins. This algorithm is grounded in the insight that when we regard two neighboring sites as nodes in a graph, the probability distribution of all possible states at these two locations can be represented as a weighted edge connecting them. We demonstrate how this representation can be leveraged to create ordered regions within the chain using only localized information about each site's state. Specifically, our method enables the identification of optimal system configurations at low temperatures, where thermal fluctuations are minimal, without the need to assess the entire configuration space. This capability facilitates the examination of systems that would typically render precise calculations impractical due to their size. Our findings indicate that this approach provides reliable predictions, even when applied to relatively short chains. Additionally, we discuss various extensions of these concepts that could further enhance computational efficiency. \n\nIntroduction: Numerous mechanical phenomena, such as magnetism and phase transitions, arise from collective behavior among interacting particles. For example, magnetic ordering in solids results from strong interactions among individual molecules via their magnetic moments. Similarly, fluid helium demonstrates superfluidity at temperatures below its critical threshold of T_c = 2.17 K, as pairs of helium-4 molecules form tightly bound bosons known as Cooper pairs. These instances highlight the necessity of studying collective behavior in large ensembles of interacting particles rather than focusing on isolated entities. However, simulating the macroscopic properties of complex systems with numerous interacting components poses significant challenges in computational physics today. While quantum mechanics often adequately describes microscopic interactions among individual objects, investigating the macroscopic properties of large particle collections generally involves approximations that may fail to capture the subtle effects resulting from correlations within the system. Consequently, numerical simulations of large-scale real-time models typically rely on approximate techniques such as Monte Carlo sampling. Unfortunately, these approaches can be computationally burdensome when applied to systems containing millions of particles.",
        "ori-fast-z-score": -0.43301270189221935,
        "water-fast-z-score": 8.235321051453479,
        "rewrite-fast-z-score": 2.1879748724684185
    },
    {
        "original_text": "We consider the problem of successive refinement coding for layered broadcast systems, where each receiver is interested only in one out of several layers and has access to all previous layers. We propose an optimal scheme that minimizes expected distortion at any given receiver by using rate-distortion optimized quantizers. The proposed scheme can be implemented efficiently as it requires no feedback between receivers or encoders. Our results are illustrated through numerical examples. Index Terms-Broadcasting, Data compression, Quantization, Rate-distortion theory, Successive refinement coding. I. INTRODUCTIO N In this work we study the problem of successive refinem ent coding (SRC)  1  , which consists on transmitting information over multiple stages such that the quality of reconstruction improves progressively. SRC is used extensively in video broadcasting applications  2  -  4  . For example, in digital television transmission, the base station sends a coarse description of the video sequence to mobile users via satellite links. Then, when these users get closer to their destination they request additional descriptions of higher resolution. This process continues until the user receives enough data to reconstruct the original signal without error  5  .\nIn general, there exist two different approaches to solve the SRC problem: 1) Joint source-channel coding: Here, the encoder jointly optimizes both source coding and channel coding  6 -  8  ; 2) Separate source-channel coding: Here, separate source coders and channel codes are employed  9  -  11  . In this case, the source code must provide some form of side-information so that the decoder can perform successive decoding  12  .",
        "watermark_text": "We consider the issue of successive refinement compression for layered broadcast systems , where each receiver is interested only in one out of several layers and has access to all previous layers . We suggest an appropriate plan that minimizes expected distortion at any certain receiver by using frequency - noise optimized quantizers .The proposed system can be executed easily as it requires no feedback between receivers or encoders . Our results are shown through numerical examples .Index Terms - Broadcasting , Data coding , Quantization , Rate - noise theory , Successive refinement compression . I . INTRODUCTIO N In this research we study the question of successive refinem ent codes ( SRC ) 1 , which consists on distributing data over successive phases such that the quality of recovery improves progressively .SRC is utilized frequently in digital broadcasting environments 2 - 4 . For instance , in digital television broadcast , the base station provides a coarse summary of the television scene to mobile users via satellite connections .Then , when these users draw closer to their target they seek alternative descriptions of greater resolution . This process proceeds until the user receives enough data to reconstruct the previous signal without error 5 .In general , there follow two different methods to solve the SRC problem : 1 ) Joint source - channel code : Here , the encoder jointly optimizes both source coding and channel code 6 - 8 ; 2 ) Separate source - channel code : Here , distinct source coders and channel codes are applied 9 - 11 . In this instance , the source coding need provide some kind of side - information so that the decoder can conduct consecutive decoding 12 .",
        "rewrite_text": "We address the challenge of successive refinement compression in layered broadcast systems, where each receiver is interested only in one specific layer while having access to all preceding layers. Our proposed strategy aims to minimize expected distortion for each receiver by employing frequency-noise optimized quantizers. The system is designed for straightforward implementation, requiring no feedback between receivers or encoders. We present our findings through numerical examples. \n\n**Index Terms:** Broadcasting, Data Coding, Quantization, Rate-Noise Theory, Successive Refinement Compression.\n\n**I. INTRODUCTION**  \nThis study explores successive refinement codes (SRC), which distribute data over multiple phases, progressively enhancing recovery quality. SRC is commonly used in digital broadcasting scenarios. For example, in digital television broadcasts, a base station transmits a basic summary of the television content to mobile users via satellite. As users approach their destination, they seek higher resolution alternatives, continuing this process until they have received sufficient data to accurately reconstruct the original signal. There are generally two approaches to tackle the SRC problem: 1) Joint source-channel coding, where the encoder simultaneously optimizes source and channel coding; 2) Separate source-channel coding, where distinct source coders and channel codes are utilized. In this latter case, the source coding must provide some form of side information to allow the decoder to perform sequential decoding.",
        "ori-fast-z-score": -2.057182539299806,
        "water-fast-z-score": 6.770618128448084,
        "rewrite-fast-z-score": -0.2847473987257497
    },
    {
        "original_text": "We present the results of our investigation into accretion disk continuum emission in black hole candidates (BHCs). We have developed an analytical model for calculating the spectrum emitted by a thin, optically thick accretion disk around a Schwarzschild black hole and applied it to several BHCs with known mass functions. The observed spectra are well reproduced when we assume that the inner edge of the disk is located at 6 gravitational radii. This result suggests that the standard thin disk model can be used as a good approximation for modeling the X-ray continuum emission of these objects. \n \n Keywords: Black holes -- Spectroscopy -- X-rays -- Modeling -- Accretion disks -- Emission lines -- Broad-band spectral energy distribution -- Luminosity function -- Mass measurement -- Stellar-mass black holes -- Supermassive black holes -- Active galactic nuclei -- Quasars -- Cosmic evolution \n \n \n \n 1 Introduction \n \n In recent years there has been considerable progress made towards understanding the physical processes occurring near supermassive black holes (SMBH) in active galactic nuclei (AGN), quasars, and other similar systems. These studies rely on observations of the broad-band spectral energy distributions (SEDs) of SMBHs over many decades in frequency space. However, because of their enormous distances, direct measurements of the intrinsic luminosities of most AGNs are not possible. Instead, one must use indirect methods such as reverberation mapping or statistical correlations between various properties of AGNs to determine their luminosities. For example, if one knows how much light passes through some region of interest within an AGN then one may calculate its luminosity using simple geometric arguments. Alternatively, if one knows the distance to an AGN then one could measure its absolute magnitude directly. Unfortunately, both of these approaches require detailed knowledge about the structure of the emitting regions which cannot currently be obtained observationally. Therefore, in order to make accurate estimates of the luminosities of distant AGNs, one needs to develop models capable of reproducing the observed SEDs of nearby AGNs.",
        "watermark_text": "We present the conclusion of our inquiry into accretion disk continuum emission in black hole candidates ( BHCs ) . We have developed an analytical theory for determining the spectrum emitted by a thin , optically dense accretion disk around a Schwarzschild red hole and applied it to several BHCs with reported mass distributions .The observed spectra are better illustrated when we suppose that the inner corner of the disk is situated at 6 gravitational radii . This result suggests that the standard narrow disk model can be used as a better approximation for modeling the X - ray continuum emission of these objects .Keywords : Black holes - - Spectroscopy - - X - rays - - Modeling - - Accretion disks - - Emission lines - - Broad - band spectral energy distribution - - Luminosity function - - Mass measurement - - Stellar - mass black holes - - Supermassive black holes - - Active galactic nuclei - - Quasars - - Cosmic evolution 1 Introduction In recent years there has been increased progress conducted towards exploring the physical processes occurring near supermassive black holes ( SMBH ) in active galactic nuclei ( AGN ) , quasars , and other similar systems . These studies rely on observations of the broad - band spectral energy distributions ( SEDs ) of SMBHs over many decades in frequency space .However , because of their huge altitudes , direct measurements of the intrinsic luminosities of most AGNs are not required . Rather , one must use indirect tools such as reverberation projection or statistical correlations between various properties of AGNs to obtain their luminosities .For instance , if one remembers how many light passes through some region of interest within an AGN then one may calculate its luminosity taking simple geometric arguments . Alternatively , if one understands the distance to an AGN then one might estimate its absolute magnitude directly .Unfortunately , both of these perspectives need rigorous knowledge about the composition of the emitting regions which lacks already be obtained observationally . Therefore , in order to make accurate calculations of the luminosities of distant AGNs , one needs to develop models capable of reproducing the known SEDs of neighbouring AGNs .",
        "rewrite_text": "We conclude our investigation into the continuum emission from accretion disks surrounding black hole candidates (BHCs). Our research has led to the creation of an analytical framework to calculate the spectrum emitted by a thin, optically dense accretion disk around a Schwarzschild black hole. We applied this model to various BHCs with documented mass distributions. Our findings suggest that positioning the inner edge of the disk at 6 gravitational radii provides a more accurate representation of the observed spectra. This implies that the conventional narrow disk model is a more effective approximation for simulating the X-ray continuum emission of these objects.\n\nKeywords: Black holes - Spectroscopy - X-rays - Modeling - Accretion disks - Emission lines - Broad-band spectral energy distribution - Luminosity function - Mass measurement - Stellar-mass black holes - Supermassive black holes - Active galactic nuclei - Quasars - Cosmic evolution.\n\n1. Introduction  \nRecent years have seen significant advancements in understanding the physical processes occurring near supermassive black holes (SMBHs) in active galactic nuclei (AGNs), quasars, and similar systems. These investigations utilize observations of the broad-band spectral energy distributions (SEDs) of SMBHs over a wide range of frequencies. However, due to their vast distances, direct measurements of the intrinsic luminosities of most AGNs are not feasible. Instead, researchers rely on indirect methods such as reverberation mapping or statistical correlations between various AGN properties to infer their luminosities. For example, by tracking how many times light traverses a particular area within an AGN, one can estimate its luminosity using simple geometric principles. Alternatively, if the distance to an AGN is known, one can directly estimate its absolute magnitude. Unfortunately, both approaches require a comprehensive understanding of the composition of the emitting regions, which has not been fully achieved through observational data. Therefore, to accurately calculate the luminosities of distant AGNs, it is essential to develop models that can replicate the known SEDs of nearby AGNs.",
        "ori-fast-z-score": -0.9733285267845753,
        "water-fast-z-score": 5.028864055053639,
        "rewrite-fast-z-score": -0.16783627165933782
    },
    {
        "original_text": "We present an approach to extract the underlying physics from large sets of experimental data by using machine learning techniques and statistical analysis. The method is applied on two different examples, namely the measurement of the electrical conductivity in doped semiconductors as well as the determination of the critical temperature Tc for superconductivity in cuprates. In both cases we find that our results are consistent with theoretical predictions. We show how this new technique can be used to identify unknown parameters or even completely new phenomena which cannot be predicted theoretically at all. This work was supported by the German Science Foundation (DFG) under grant number SFB/TRR 191. A central goal of modern science is to understand complex systems such as materials or living organisms through their fundamental building blocks. To achieve this aim it is necessary to develop methods which allow us to analyze huge amounts of experimental data efficiently. Here we propose a novel approach based on machine learning algorithms combined with advanced statistical tools. Our method is demonstrated on two examples: First, we study the dependence of the electrical conductivity on doping concentration in semiconductor compounds. Second, we determine the critical temperature T c for superconductivity in high-temperature cuprate oxides. For both problems we obtain results which agree very well with existing theories. Moreover, we demonstrate how our method allows one to discover previously unforeseen features in the data.",
        "watermark_text": "We present an way to extract the fundamental theory from huge sets of experimental evidence by using computer learning techniques and statistical analysis . The method is applied on two different examples , notably the determination of the electrical conductivity in doped semiconductors as well as the determination of the significant heat Tc for superconductivity in cuprates .In both cases we find that our findings are compatible with theoretical expectations . We see how this new technique can be used to identify unseen conditions or even completely new events which cannot be described theoretically at all .This project was supported by the German Science Foundation ( DFG ) under grant number SFB / TRR 191 . A central goal of modern science is to explain complex systems such as materials or living organisms through their major building frames .To achieve this aim it is required to develop techniques which allow us to analyze huge amounts of research data easily . Here we undertake a innovative method built on machine computing methods coupled with sophisticated statistical tools .Our method is demonstrated on two examples : First , we study the relationship of the electrical conductivity on doping concentration in semiconductor compounds . Second , we determine the significant heat T c for superconductivity in high - temperature cuprate oxides .For both difficulties we obtain results which agree very best with existing ideas . Moreover , we prove how our technique permits one to identify formerly unforeseen features in the information .",
        "rewrite_text": "We introduce a novel approach for extracting fundamental theories from extensive sets of experimental data using machine learning techniques and statistical analysis. This method has been applied to two distinct cases: the identification of electrical conductivity in doped semiconductors and the determination of the critical temperature, Tc, for superconductivity in cuprate materials. In both instances, our results align well with established theoretical predictions. Furthermore, we demonstrate how this innovative technique can uncover previously unrecognized conditions or entirely new phenomena that cannot currently be described by existing theory. This research was funded by the German Science Foundation (DFG) under grant number SFB/TRR 191. A primary objective of contemporary science is to comprehend complex systems, like materials or living organisms, through their fundamental components. To attain this goal, it is crucial to develop methods that facilitate the analysis of large datasets with ease. In this study, we employ an advanced methodology that integrates machine learning with sophisticated statistical tools. Our approach is illustrated through two examples: first, we explore the relationship between electrical conductivity and doping concentration in semiconductor compounds; second, we investigate the critical temperature, Tc, for superconductivity in high-temperature cuprate oxides. For both challenges, we present results that closely match existing theories, and we highlight how our method allows for the identification of previously unnoticed features in the data.",
        "ori-fast-z-score": -0.3682298471593294,
        "water-fast-z-score": 7.98489954161323,
        "rewrite-fast-z-score": 0.19069251784911848
    },
    {
        "original_text": "Organic materials have been widely used for optoelectronic devices, such as organic light-emitting diodes (OLEDs), photovoltaics and sensors due to their unique properties including low cost, flexibility, large area coverage and solution processability. In this review we focus on the recent progresses made by our group in developing new types of organic materials with high performance for OLED applications. We first introduce some basic concepts about luminescent mechanisms in OLEDs. Then we discuss several important issues related to the development of novel emissive layers based on small molecules or polymers. Finally, we summarize the current challenges and future trends in designing highly efficient OLEDs. The research work presented here is supported by National Natural Science Foundation of China under Grants No. 21471063, 21621062, 21573189, 21390563 , 21133005 . Keywords: Light emitting diode; Emissive layer; Small molecule",
        "watermark_text": "Organic materials have been widely useful for optoelectronic products , such as organic light - emitting diodes ( OLEDs ) , photovoltaics and sensors due to their distinct characteristics including low cost , functionality , large area coverage and application processability . In this review we focus on the recent progresses done by our team in identifying new types of organic materials with high efficiency for OLED applications .We first introduce some fundamental concepts about luminescent mechanisms in OLEDs . Then we explain several important problems related to the development of new emissive layers modeled on small particles or polymers .Finally , we summarize the present problems and future developments in building highly efficient OLEDs . The research effort displayed here is backed by National Natural Science Foundation of China under Grants No .21471063, 21621062, 21573189, 21390563 , 21133005 .Keywords: Light emitting diode; Emissive layer; Small molecule",
        "rewrite_text": "Organic materials have proven to be highly valuable in the realm of optoelectronic products, including organic light-emitting diodes (OLEDs), photovoltaics, and sensors. Their unique characteristics, such as cost-effectiveness, functional versatility, extensive coverage, and ease of application, contribute to their widespread adoption. In this review, we highlight the recent advancements made by our team in discovering new organic materials with high efficiency for OLED applications. We begin by introducing some fundamental concepts regarding the luminescent mechanisms in OLEDs. Next, we address several key challenges associated with developing new emissive layers based on small particles or polymers. Finally, we summarize current issues and prospective developments aimed at creating highly efficient OLEDs. This research is supported by the National Natural Science Foundation of China under Grants No. 21471063, 21621062, 21573189, 21390563, and 21133005. \n\nKeywords: Light-emitting diode; Emissive layer; Small molecule",
        "ori-fast-z-score": 0.3841106397986879,
        "water-fast-z-score": 6.529880876577695,
        "rewrite-fast-z-score": 2.6457513110645903
    },
    {
        "original_text": "We study stability properties of steady-state solutions to the compressible Navier-Stokes equations with large Mach numbers, and prove that they are stable under small perturbations if their pressure satisfies certain conditions.  We consider two types of steady states: (i) traveling waves which connect different constant states; and (ii) stationary shocks connecting different constant states. For both cases we show that these steady-states are stable for all sufficiently large Mach numbers M > 1 provided that the pressure p(ρ) has at most one inflection point on its graph. In particular, this implies that any smooth solution starting close enough to such a steady state converges exponentially fast towards it as time goes to infinity. \nThe proof relies on an energy estimate combined with suitable weighted Sobolev estimates. The main difficulty lies in dealing with the nonlinear term arising from the convection part of the equation. This problem can be overcome by using appropriate weight functions together with some delicate analysis based on the maximum principle.",
        "watermark_text": "We explore equilibrium properties of stable - state solutions to the compressible Navier - Stokes equations with large Mach numbers , and prove that they are stable under small perturbations if their pressure satisfies certain conditions . We consider two forms of stable states : ( i ) moving flows which link different constant states ; and ( ii ) continuous shocks connecting different constant states .For both cases we prove that these steady - states are stable for all reasonably large Mach numbers M > 1 given that the pressure p ( ρ ) has at most one inflection point on its graph . In particular , this implies that any smooth equation beginning close enough to such a steady state converges exponentially rapidly towards it as time went to infinity .The proof involves on an energy estimate combined with suitable weighted Sobolev estimates . The main problems lies in concerned with the nonlinear term arising from the convection part of the equation .This problem can be overcome by using appropriate weight functions combined with some delicate investigation depending on the maximum law .",
        "rewrite_text": "We investigate the equilibrium characteristics of stable steady-state solutions to the compressible Navier-Stokes equations at high Mach numbers, demonstrating that these solutions remain stable under small perturbations, provided their pressure meets specific criteria. Our analysis focuses on two types of stable states: (i) moving flows that connect different constant states, and (ii) continuous shocks that link various constant states. In both scenarios, we establish that these steady-states are stable for all sufficiently large Mach numbers (M > 1), given that the pressure function p(ρ) exhibits at most one inflection point. This finding indicates that any smooth solution starting near such a steady state converges exponentially fast to it as time progresses. Our proof relies on an energy estimate coupled with appropriate weighted Sobolev estimates. The main challenge arises from the nonlinear terms associated with the convection component of the equations. We address this challenge by employing suitable weight functions and conducting a careful analysis based on the maximum principle.",
        "ori-fast-z-score": 1.0660035817780522,
        "water-fast-z-score": 5.9696200579570915,
        "rewrite-fast-z-score": 1.4757295747452437
    },
    {
        "original_text": "We present the canonical quantization of topologically massive gauge theories in any dimension, including the case of non-abelian gauge fields coupled to fermions. We show that these models are equivalent to gauge-invariant factorised formalisms which have been used previously for studying such systems. In particular we demonstrate how this equivalence can be exploited to obtain exact results for correlation functions at finite temperature using functional methods. This formalism is also applicable to other quantum field theories with massless particles and an associated topological term. It may therefore prove useful as a general tool for investigating strongly interacting systems where conventional perturbative techniques fail. Introduction:-The study of quantum field theory has led to many important insights into fundamental physics over recent decades. However it remains difficult to solve exactly even simple problems involving interactions between elementary particles due to their nonperturbative nature. One approach to tackling this problem involves exploiting symmetries inherent within certain classes of model systems; in particular supersymmetry (SUSY) provides powerful constraints on the possible forms of particle interaction and leads to significant simplifications when applied to specific physical situations  1  . Another promising technique exploits the fact that some quantum field theories possess additional global or local symmetries which allow them to be expressed in terms of simpler effective descriptions known as  gauge-invariant factorisations   2  , see e.g.  3  -  6  .\nIn this work we consider a class of quantum field theories whose Lagrangians contain both a standard kinetic energy term and a so-called  topological  contribution arising from the coupling of the gauge field to itself  7, 8  . These theories include Yang-Mills-Higgs models  9  , Chern-Simons-matter theories  10  , and more recently proposed extensions  11  -  13  . They play an important role in condensed matter physics  14  , string theory  15  , and cosmology  16  . Despite being relatively simple they exhibit rich behaviour; for example they support excitations with fractional statistics  17  and provide examples of parity-violating phases  18  . Furthermore there exist interesting connections...",
        "watermark_text": "We introduce the canonical quantization of topologically heavy gauge fields in any dimension , particularly the case of non - abelian gauge fields coupled to fermions . We see that these models are comparable to gauge - invariant factorised formalisms which have been used earlier for studying such schemes .In particular we prove how this equivalence can be exploited to obtain exact findings for correlation functions at finite temperature using functional principles . This formalism is also useful to other quantum field theories with massless objects and an associated topological term .It might hence become useful as a general tool for investigating strongly interacting networks where conventional perturbative tools fail . Introduction : - The investigation of quantum field theory has led to many important insights into fundamental theory over recent generations .However it remains harder to solve exactly even basic difficulties involving interactions between elementary particles due to their nonperturbative nature . One approach to tackling this question involves exploiting symmetries inherent within particular categories of model structures ; in instance supersymmetry ( SUSY ) presents powerful restrictions on the possible kinds of particle interaction and results to significant simplifications when applied to specific physical conditions 1 .Another promising theory exploits the fact that some quantum field schemes contain extra international or local symmetries which allow them to be described in terms of simpler effective models termed as gauge - invariant factorisations 2 , see e . g . 3 - 6 .In this research we treat a class of quantum field theories whose Lagrangians contain both a basic kinetic power term and a so - called topological contribution arising from the interaction of the gauge field to itself 7 , 8 . These fields include Yang - Mills - Higgs theories 9 , Chern - Simons - matter experiments 10 , and more recently suggested extended 11 - 13 .They play an important role in condensed matter science 14 , string theory 15 , and cosmology 16 . Despite being largely simple they exhibit rich behaviour ; for example they support excitations with fractional numbers 17 and provide examples of parity - violating phases 18 .Furthermore there remain curious connections . . .",
        "rewrite_text": "We present the canonical quantization of topologically heavy gauge fields across any dimension, focusing specifically on non-abelian gauge fields coupled to fermions. Our findings indicate that these models align closely with gauge-invariant factorized formalisms previously utilized in similar studies. Notably, we demonstrate how this equivalence can be leveraged to achieve exact results for correlation functions at finite temperature using functional methods. This framework is also applicable to other quantum field theories involving massless entities and corresponding topological terms, potentially serving as a general tool for exploring strongly interacting networks where traditional perturbative methods fall short.\n\n**Introduction:** The exploration of quantum field theory has yielded significant insights into fundamental concepts over the past several generations. However, even basic problems concerning interactions between elementary particles remain challenging to solve exactly, primarily due to their nonperturbative nature. One strategy for addressing these issues involves leveraging symmetries inherent in specific model categories; for instance, supersymmetry (SUSY) imposes strong constraints on types of particle interactions, leading to major simplifications under certain physical conditions. Another promising approach recognizes that some quantum field theories possess additional global or local symmetries that enable their representation through simpler effective models known as gauge-invariant factorizations. In this investigation, we examine a category of quantum field theories characterized by Lagrangians that include both a fundamental kinetic term and a topological contribution stemming from self-interaction of the gauge fields. These theories encompass Yang-Mills-Higgs models, Chern-Simons-matter systems, and newer extensions. They are significant in various domains, including condensed matter physics, string theory, and cosmology. Despite their apparent simplicity, these theories exhibit complex behaviors, such as supporting fractional excitations and showcasing parity-violating phases, alongside intriguing connections in the field.",
        "ori-fast-z-score": -1.5966004346663816,
        "water-fast-z-score": 6.727767619564244,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We study numerically and analytically the dynamics of an elastic interface in two dimensions driven by thermal fluctuations, starting far away from equilibrium. We find that the system relaxes to its steady state via coarsening with power law growth of characteristic length scales. The exponents are determined both for the case where the initial condition is random noise as well as for the case when it has a regular pattern. In particular we show how the exponent depends on the strength of disorder present in the initial conditions. This work was supported by NSF grant DMR-0704520 (M.S.) and by DFG grant SFB-TR6 (A.K.). \nI. INTRODUCTORY REMARkS\n\nThe motion of interfaces between different phases or states plays an important role in many physical systems ranging from crystal growth  1  , fluid flow  2  , magnetic domain wall motion  3  , fracture  4  , wetting  5  , etc.. A common feature shared by all these phenomena is that they involve some kind of competition between surface tension which tries to smooth out any roughness at the interface and other driving forces such as gravity  6  , electric field  7  , chemical potential  8  , etc., which tend to make the interface roughen. It turns out that this competition leads to interesting nonequilibrium behavior  9  . For example, if one starts with flat surfaces then the presence of quenched disorder can lead to the formation of fractal structures  10  .\nIn recent years there have been several studies  11  -  16  devoted to understanding the statistical properties of growing interfaces near their critical dimension d c = 2  17  . These investigations were motivated primarily by experiments  18  -  20  performed on various types of thin films grown under controlled experimental conditions  21  . One of the main goals of these studies is to understand whether the scaling laws observed experimentally  22  -  24  are universal  25  or depend crucially on microscopic details  26  . Another motivation comes from theoretical interest in studying the interplay between nonlinearity and disorder  27  -  29  . Finally, another reason for investigating the problem theoretically is due to possible applications  30  -  32  in data storage devices  33  and optical",
        "watermark_text": "We research numerically and analytically the dynamics of an elastic interface in two dimensions accelerated by temperature fluctuations , beginning far back from equilibrium . We see that the system relaxes to its steady state via coarsening with power law expansion of typical depth scales .The exponents are decided both for the case where the initial situation is random noise as well as for the case when it has a regular rhythm . In particular we determine how the exponent depends on the strength of disorder present in the first situations .This project was supported by NSF grant DMR - 0704520 ( M . S . ) and by DFG funding SFB - TR6 ( A . K . ) .I . INTRODUCTORY REMARkS The movement of interfaces between various phases or states takes an important role in different mechanical models ranging from crystal growth 1 , fluid flow 2 , magnetic domain wall motion 3 , fracture 4 , wetting 5 , etc . . A common characteristic shared by all these phenomena is that they represent some kind of battle between surface friction which tries to rough out any roughness at the interface and other driving forces such as gravity 6 , electric field 7 , chemical current 8 , etc . , which prefer to make the interface roughen .It turns out that this competition leads to attractive nonequilibrium behavior 9 . For instance , if one starts with smooth surfaces then the presence of quenched instability can lead to the formation of fractal structures 10 .In recent years there have been numerous research 11 - 16 devoted to study the statistical characteristics of growing interfaces near their critical parameter d c = 2 17 . These studies were driven mainly by research 18 - 20 performed on various types of thin sheets grown under controlled research situations 21 .One of the main goals of these research is to study whether the scaling forces observed experimentally 22 - 24 are fundamental 25 or rely crucially on microscopic information 26 . Another motivation arises from theoretical interest in examining the interplay between nonlinearity and disorder 27 - 29 .Finally , another reason for investigating the issue theoretically is due to possible users 30 - 32 in data storage devices 33 and optical",
        "rewrite_text": "We investigate both numerically and analytically the dynamics of an elastic interface in two dimensions, driven by temperature fluctuations starting well away from equilibrium. Our findings indicate that the system relaxes to a steady state through coarsening, characterized by a power-law expansion of typical depth scales. We identify the exponents for scenarios involving random noise and those with a regular rhythm. Notably, we explore how the exponent varies with the strength of disorder in the initial conditions. This research received support from NSF grant DMR-0704520 (M. S.) and DFG funding SFB-TR6 (A. K.). \n\n**I. INTRODUCTORY REMARKS**  \nThe movement of interfaces across various phases or states plays a crucial role in multiple mechanical models, including crystal growth, fluid dynamics, magnetic domain wall motion, fracture mechanics, and wetting phenomena. A key feature common to these processes is the interplay between surface friction, which tends to smooth out interface roughness, and external forces such as gravity, electric fields, and chemical currents, which encourage roughness to develop. This competition results in distinctive nonequilibrium behaviors. For example, starting with smooth surfaces and introducing quenched instability can lead to the emergence of fractal structures. Recent research has focused on analyzing the statistical properties of growing interfaces as they approach their critical parameter, \\(d_c = 2\\). These studies have primarily been inspired by experiments conducted on various types of thin sheets in controlled settings. One of the primary aims of this research is to determine whether the observed scaling behaviors are fundamental properties or significantly influenced by microscopic details. Additionally, there is a theoretical interest in understanding the interaction between nonlinearity and disorder. Lastly, exploring these issues theoretically is important for potential applications in data storage technologies and optical systems.",
        "ori-fast-z-score": -0.48989794855663565,
        "water-fast-z-score": 8.382021125342941,
        "rewrite-fast-z-score": 2.3333333333333335
    },
    {
        "original_text": "The detection and characterization of planets orbiting stars other than the Sun is one of the most exciting areas of modern astronomy, with important implications for our understanding of planet formation and evolution.  The majority of known exoplanet systems are found around single main-sequence (MS) stars; however, it has been suggested that many more planets may be present in binary star systems.   In this review we discuss observational techniques used to detect planets in binaries, including radial velocity measurements, transit photometry, direct imaging, astrometric wobble, microlensing, pulsar timing, and gravitational wave observations. We also briefly describe some of the challenges associated with detecting planets in these systems. Finally, we summarize current results on planetary companions to MS+MS, MS+WD, WD+MS, and WD+WD binaries. Keywords: Planetary systems; Binaries; Exoplanets; Direct imaging; Astrometry",
        "watermark_text": "The observation and identification of stars orbiting planets other than the Sun is one of the most exciting areas of modern astronomy , with important implications for our studying of planet development and evolution . The majority of known exoplanet systems are found around single major - sequence ( MS ) stars ; however , it has been proposed that several more planets might be found in binary star systems .In this review we explain observational techniques employed to identify planets in binaries , notably radial speed measurements , transit photometry , direct scanning , astrometric wobble , microlensing , pulsar timing , and gravity wave surveys . We additionally momentarily describe some of the challenges associated with detecting planets in these systems .Finally , we summarize current data on asteroid companions to MS + MS , MS + WD , WD + MS , and WD + WD binaries . Keywords : Planetary systems ; Binaries ; Exoplanets ; Direct imaging ; Astrometry",
        "rewrite_text": "The detection and analysis of stars orbiting planets beyond our solar system is one of the most thrilling fields in contemporary astronomy, carrying significant implications for our understanding of planetary formation and evolution. While most known exoplanet systems exist around solitary main-sequence (MS) stars, there is a suggestion that additional planets may reside in binary star systems. In this review, we discuss the various observational techniques used to identify planets in binary systems, including radial velocity measurements, transit photometry, direct imaging, astrometric wobble, microlensing, pulsar timing, and gravitational wave surveys. We also briefly outline some of the challenges involved in detecting planets within these systems. Lastly, we provide a summary of the current data concerning asteroid companions in MS + MS, MS + white dwarf (WD), WD + MS, and WD + WD binary systems. Keywords: Planetary systems; Binaries; Exoplanets; Direct imaging; Astrometry.",
        "ori-fast-z-score": -0.3841106397986879,
        "water-fast-z-score": 6.096006096009144,
        "rewrite-fast-z-score": 0.8307471607356973
    },
    {
        "original_text": "The main result is the following theorem. \nTHEOREM 1 Let  be an arbitrary real number and let  be any positive integer.  Then, there exists a constant , depending only on , , such that \nfor all matrices . The proof of this theorem will be given in Section 2 below. In particular, if we take  then (1) becomes \nwhich was proved by Yakubovich  J. Math. Anal. Appl., vol. 16, pp. 719-726, (1964) . If we choose  then (1) reduces to \nwhich was established by Popov  Publ. Math. Inst. Steklov, vol. A, no. 3, p. 225-230, (1963)  . We remark here that our results are not new but they can be obtained as corollaries of these two papers. However, it seems worthwhile to give proofs which do not depend upon those earlier works.",
        "watermark_text": "The main consequence is the following theorem . THEOREM 1 Let be an arbitrary real number and consider be any positive integer .Then , there exists a constant , depending only on , , such that for all matrices . The confirmation of this theorem will be provided in Section 2 below .In particular , if we took then ( 1 ) becomes which was confirmed by Yakubovich J . Math .Anal.Appl., vol.16 , pp . 719 - 726 , ( 1964 ) .If we choose  then (1) reduces to \nwhich was established by Popov  Publ.Math.Inst.Steklov, vol.A , no . 3 , p . 225 - 230 , ( 1963 ) .We comment here that our findings are not original but they can be obtained as corollaries of these two papers . However , it appears worthwhile to give proofs which do not depend upon those earlier works .",
        "rewrite_text": "The primary result is encapsulated in the following theorem: \n\n**THEOREM 1**: Let \\( x \\) be any real number and \\( n \\) be any positive integer. Then, there exists a constant \\( C \\), which depends solely on \\( x \\) and \\( n \\), such that the theorem holds for all matrices. A detailed proof of this theorem will be presented in Section 2. Specifically, if we take \\( x = 1 \\), the expression (1) simplifies, a result that was verified by Yakubovich in *J. Math. Anal. Appl.*, vol. 16, pp. 719-726, (1964). If we select \\( x = 0 \\), equation (1) further reduces to another form, which was established by Popov in *Publ. Math. Inst. Steklov*, vol. A, no. 3, p. 225-230, (1963). It is important to note that while our results are not novel, as they can be derived as corollaries from these two earlier papers, we find it valuable to provide proofs that are independent of those previous works.",
        "ori-fast-z-score": -0.16012815380508713,
        "water-fast-z-score": 2.846049894151541,
        "rewrite-fast-z-score": -0.13736056394868904
    },
    {
        "original_text": "We present an efficient numerical scheme to detect the existence of periodic orbits in chaotically behaving dynamical systems, such as chaotic maps or chaotic flows. The proposed algorithm is based on the concept of shadowing trajectories which are close approximations of unstable periodic orbits embedded within the attractor. We show that our approach can be used to efficiently compute the topological entropy of chaotic maps with non-integer slopes. Finally we demonstrate how this new technique can be applied to study the dynamics of a model system describing the interaction between two coupled semiconductor lasers. Periodic orbits play an important role in understanding the behavior of many nonlinear dynamical systems. In particular they provide valuable information about the underlying structure of the attractors associated with these systems. However, it has been shown that finding all periodic orbits of a given periodicity may not always be possible due to their complicated nature  1  . This problem becomes even more challenging when dealing with chaotic systems where the number of periodic orbits increases exponentially with increasing period  2  .\nIn recent years there have been several attempts to develop techniques to find periodic orbits numerically  3, 4, 5, 6, 7, 8  , but most of them suffer from one or both of the following drawbacks: (i) They require very high computational resources. (ii) They do not guarantee convergence towards the desired orbit. Here we propose a novel numerical scheme to overcome these difficulties by using the concept of shadowing  9  . Shadowing refers to the property of some trajectories being close approximations of unstable orbits embedded inside the attractor. It was first introduced by Anosov  10  who showed that every trajectory starting sufficiently close to any unstable periodic orbit will remain close to it for at least a certain amount of time. Since then various authors  11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44",
        "watermark_text": "We present an efficient numerical system to identify the existence of periodic orbits in chaotically behaving dynamical systems , such as chaotic maps or turbulent flows . The proposed algorithm is based on the idea of shadowing trajectories which are close approximations of unstable periodic orbits embedded within the attractor .We see that our approach can be used to easily compute the topological entropy of turbulent maps with non - integer peaks . Finally we prove how this new technique can be applied to study the dynamics of a prototype system describing the interaction between two coupled semiconductor lasers .Periodic orbits take an important role in understanding the dynamics of several nonlinear dynamical systems . In particular they give valuable info about the fundamental structure of the attractors associated with these systems .However , it has been shown that finding all periodic orbits of a given periodicity might not always be possible due to their complicated nature 1 . This problem arises even more challenging when dealing with turbulent systems where the number of periodic orbits changes exponentially with expanding period 2 .In past decades there have been numerous attempts to develop techniques to find periodic orbits numerically 3 , 4 , 5 , 6 , 7 , 8 , but most of them suffer from one or both of the following drawbacks : ( i ) They require very high computational resources . ( ii ) They do not guarantee convergence towards the desired orbit .Here we develop a new numerical system to overcome these problems by using the idea of shadowing 9 . Shadowing refers to the property of some trajectories being close approximations of unstable orbits embedded inside the attractor .It was first developed by Anosov 10 who demonstrated that every orbital beginning sufficiently next to any weak periodic orbit will remain close to it for at least a certain quantity of time . Since then various authors 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44",
        "rewrite_text": "We introduce an effective numerical method to detect the presence of periodic orbits in chaotic dynamical systems, such as chaotic maps and turbulent flows. Our algorithm is grounded in the concept of shadowing trajectories, which serve as close approximations to unstable periodic orbits situated within the attractor. Our findings indicate that this method allows for the straightforward calculation of the topological entropy of turbulent maps that exhibit non-integer peaks. Furthermore, we demonstrate how this technique can be applied to analyze the dynamics of a model system that represents the interaction between two coupled semiconductor lasers. Periodic orbits are crucial for understanding the dynamics of various nonlinear dynamical systems, as they provide significant insights into the fundamental structure of the corresponding attractors. However, identifying all periodic orbits of a specific periodicity can be exceedingly challenging due to their complex nature. This difficulty is amplified in turbulent systems, where the number of periodic orbits increases exponentially as the period expands. Over the past few decades, there have been numerous efforts to create numerical techniques for identifying periodic orbits, but most of these approaches face one or both of the following challenges: (i) they demand substantial computational resources, and (ii) they lack guarantees of convergence to the intended orbit. In this work, we propose a new numerical framework that addresses these issues by leveraging the principle of shadowing. Shadowing describes the phenomenon where certain trajectories closely follow unstable orbits within the attractor. This concept was initially introduced by Anosov, who showed that any orbit starting sufficiently near to a weak periodic orbit will remain closely aligned with it for a certain duration. Since then, the idea has been explored and expanded by various authors.",
        "ori-fast-z-score": -0.43033148291193524,
        "water-fast-z-score": 6.688444820557844,
        "rewrite-fast-z-score": 0.25819888974716115
    },
    {
        "original_text": "We report the detection of an infrared dark cloud (IRDC) in the vicinity of the open cluster NGC 6334, using data obtained with Spitzer Space Telescope s Infrared Array Camera (IRAC). The IRDC is associated with the molecular cloud complex G327.3+0.6 and has been identified as Bok globule CB190 by Clemens & Barvainis (1988) . We find that this object exhibits a prominent 24 micron shadow which may be caused by absorption against bright mid-infrared emission from nearby protostars or young stellar objects. This feature suggests that the cloud contains dense cores at different evolutionary stages. Using near-infrared extinction mapping we identify two candidate starless cores within the cloud. These are located near the center of the cloud where the 24 micron shadow is most pronounced. Our analysis shows that these cores have masses between 0.5 Msun to 1 Msun and radii ranging from 1000 AU to 3000 AU .",
        "watermark_text": "We report the observation of an infrared shadow cloud ( IRDC ) in the vicinity of the open cluster NGC 6334 , using data acquired with Spitzer Space Telescope s Infrared Array Camera ( IRAC ) . The IRDC is associated with the molecular cloud complex G327 . 3 + 0 . 6 and has been described as Bok globule CB190 by Clemens & Barvainis ( 1988 ) .We see that this body features a distinct 24 micron shadow which may be caused by absorption against bright mid - infrared absorption from nearby protostars or young stellar bodies . This characteristic suggests that the cloud contains thick cores at different evolutionary stages .Using near - infrared extinction mapping we identify two proposed starless cores within the cloud . These are situated near the center of the cloud where the 24 micron shadow is most pronounced .Our study shows that these cores have masses between 0 . 5 Msun to 1 Msun and radii ranging from 1000 AU to 3000 AU .",
        "rewrite_text": "We present our findings on an infrared dark cloud (IRDC) located near the open cluster NGC 6334, utilizing data from the Infrared Array Camera (IRAC) on the Spitzer Space Telescope. This IRDC is linked to the molecular cloud complex G327.3 + 0.6 and has been previously identified as Bok globule CB190 by Clemens & Barvainis (1988). Our observations reveal a prominent 24-micron shadow, likely resulting from absorption against bright mid-infrared emissions from nearby protostars or young stellar objects. This feature suggests that the cloud harbors dense cores at various evolutionary stages. Through near-infrared extinction mapping, we have identified two potential starless cores within the cloud, located at its center where the 24-micron shadow is most pronounced. Our analysis indicates that these cores have masses ranging from 0.5 to 1 solar mass and radii between 1000 AU and 3000 AU.",
        "ori-fast-z-score": 1.0886621079036347,
        "water-fast-z-score": 4.9890789822279915,
        "rewrite-fast-z-score": 1.2362450755382013
    },
    {
        "original_text": "We present new results on mass loss in carbon rich asymptotic giant branch (AGB) stars based on infrared photometry obtained with ISO-SWS, IRAS, MSX and Spitzer-IRS. We find that there is no correlation between the total luminosity or effective temperature of these objects and their mass-loss rates. The observed scatter may be explained by differences in chemical composition and/or pulsation properties among individual sources. In addition to this we show that the dust-to-gas ratio decreases towards higher temperatures for oxygen-rich as well as carbon-rich AGB stars. This indicates that the physical conditions at which dust forms are different in both types of evolved stars. Finally, we discuss how our findings can be used to improve current models describing the evolution of red giants. Keywords: Asymptotic Giant Branch Stars; Dust formation; Red Giants; Mass loss. 1 Introduction Carbon-rich asymptotic giant branch (AGB; hereafter Crich AGB) stars have been studied extensively over the past decades because they represent an important source class of interstellar matter. They lose large amounts of material through stellar winds driven by radiation pressure on dust grains formed in the outflowing gas. These winds play an essential role in shaping circumstellar envelopes around evolved stars and thus influence the appearance of planetary nebulae and proto-stellar disks surrounding young stellar objects. However, despite numerous observational studies it remains unclear what determines the amount of mass lost by Crich AGB stars. It has been suggested that the total luminosity L * , the effective temperature T eff , the surface gravity g, the metallicity Z, the pulsation period P, and the initial mass M ini might all affectṀ . For example, Wood et al. (1992) , van Loon et al. (1999), Olofsson et al. (2002a) , Knapp & Morris (1985) , and Winters et al. (1994) found evidence thatṀ increases with decreasing T eff .\nIn contrast, Groenewegen et al. (1998 ), De Beck et al. (2010 , and Ramstedt et al",
        "watermark_text": "We report new data on mass loss in carbon rich asymptotic giant line ( AGB ) galaxy based on infrared photometry obtained with ISO - SWS , IRAS , MSX and Spitzer - IRS . We see that there is no difference between the total luminosity or effective heat of these objects and their mass - loss rates .The observed scatter could be reason by differences in chemical composition and / or pulsation properties among different sources . In addition to this we find that the dust - to - gas ratio falls towards higher temperatures for oxygen - rich as well as carbon - rich AGB stars .This implies that the physical conditions at which dust occurs are distinct in both types of evolved stars . Finally , we talk how our findings can be used to improve current theories describing the evolution of red giants .Keywords : Asymptotic Giant Branch Stars ; Dust formation ; Red Giants ; Mass death . 1 Introduction Carbon - rich asymptotic giant line ( AGB ; hereafter Crich AGB ) stars have been studied frequently over the previous decades because they represent an important source type of interstellar matter .They lose enormous amounts of debris through stellar winds driven by radiation stress on dust grains created in the outflowing gas . These winds play an essential part in shaping circumstellar envelopes around evolved planets and therefore influence the appearance of planetary nebulae and proto - stellar disks surrounding young stellar bodies .However , despite several observational research it remains unsure what determines the quantity of mass losing by Crich AGB stars . It has been proposed that the total luminosity L * , the effective heat T eff , the surface gravity g , the metallicity Z , the pulsation period P , and the first weight M ini may all [UNK] .For instance , Wood et al . ( 1992 ) , van Loon et al .( 1999 ) , Olofsson et al . ( 2002a ) , Knapp & Morris ( 1985 ) , and Winters et al .( 1994 ) found evidence [UNK] increases with decreasing T eff . In contrast , Groenewegen et al .( 1998 ) , De Beck et al . ( 2010 , and Ramstedt et al",
        "rewrite_text": "We present new findings on mass loss in carbon-rich asymptotic giant branch (AGB) galaxies, utilizing infrared photometry from ISO-SWS, IRAS, MSX, and Spitzer-IRS. Our analysis reveals no significant differences in total luminosity or effective temperature among these objects in relation to their mass-loss rates. The variability observed may be attributed to differences in chemical composition and/or pulsation characteristics across different sources. Additionally, we find that the dust-to-gas ratio decreases at higher temperatures for both oxygen-rich and carbon-rich AGB stars, suggesting that the physical conditions for dust formation differ between these two types of evolved stars. Finally, we discuss how these findings can enhance current theories regarding the evolution of red giants. \n\nKeywords: Asymptotic Giant Branch Stars; Dust Formation; Red Giants; Mass Loss.\n\n1. Introduction  \nCarbon-rich asymptotic giant branch (hereafter C-rich AGB) stars have been the subject of extensive study over the past few decades, as they are a significant source of interstellar material. These stars expel substantial amounts of material through stellar winds driven by radiation pressure on dust particles formed in the outflowing gas. Such winds are crucial for shaping the circumstellar envelopes surrounding evolved stars, thereby influencing the characteristics of planetary nebulae and prostellar disks around young stellar objects. Nonetheless, despite numerous observational studies, the factors determining the mass loss rates of C-rich AGB stars remain uncertain. It has been suggested that various parameters, including total luminosity (L*), effective temperature (T_eff), surface gravity (g), metallicity (Z), pulsation period (P), and initial mass (M_ini) may all play a role. For instance, studies by Wood et al. (1992), van Loon et al. (1999), Olofsson et al. (2002a), Knapp & Morris (1985), and Winters et al. (1994) indicated a correlation between mass loss and decreasing T_eff. Conversely, Groenewegen et al. (1998), De Beck et al. (2010), and Ramstedt et al. (201…",
        "ori-fast-z-score": -0.9135002783911397,
        "water-fast-z-score": 6.124283575657523,
        "rewrite-fast-z-score": -2.813860021248051
    },
    {
        "original_text": "We show that, in addition to gravitational waves and neutrinos, there is an additional source of energy loss during the final stages of stellar evolution which has been largely ignored by previous authors. This arises because the universe becomes transparent to photons at redshifts z ~ 1100 (the time when matter-radiation equality occurs), allowing them to stream freely outwards into space. The resulting decrease in pressure causes the universe to expand faster than it would otherwise do, thereby accelerating its expansion rate. We estimate this effect for different types of stars and find that it can be significant - up to 10% of the total luminosity output of massive stars may be lost due to this process. In particular we predict that Type Ia supernovae should exhibit systematically lower peak luminosities compared with their observed values if they are not corrected for this effect. Finally, we discuss how our results could be tested observationally using current data on distant supernovae.",
        "watermark_text": "We suggest that , in addition to gravitational waves and neutrinos , there is an additional source of power transfer during the last phases of stars evolution which has been mostly overlooked by earlier authors . This arises because the universe makes transparent to photons at redshifts z ~ 1100 ( the period when matter - radiation equality happens ) , allowing them to leak independently outwards into space .The resulting shift in pressure creates the universe to expand faster than it would normally do , thereby accelerating its expansion speed . We estimate this effect for different kinds of stars and find that it can be considerable - up to 10 % of the total luminosity production of large galaxies must be lost due to this process .In particular we estimate that Type Ia supernovae should exhibit systematically lower peak luminosities contrasted with their observed values if they are not corrected for this effect . Finally , we explain how our findings may be evaluated observationally using current data on remote supernovae .",
        "rewrite_text": "We propose that, alongside gravitational waves and neutrinos, there exists another significant mechanism for power transfer during the final stages of stellar evolution, which has largely been overlooked by previous researchers. This mechanism results from the universe becoming transparent to photons at redshifts of approximately z ~ 1100, coinciding with the era of matter-radiation equality. This transparency enables photons to escape freely into space, leading to a shift in pressure that accelerates the expansion of the universe beyond its normal rate. Our estimates indicate that this effect, which varies among different types of stars, can be substantial—potentially accounting for up to 10% of the total luminosity produced by large galaxies that is lost due to this phenomenon. Notably, we predict that Type Ia supernovae may exhibit systematically lower peak luminosities than their observed values if this effect is not taken into consideration. Lastly, we discuss how our results can be assessed through current observations of distant supernovae.",
        "ori-fast-z-score": 0.22941573387056174,
        "water-fast-z-score": 6.653056282246291,
        "rewrite-fast-z-score": 1.2874526191574363
    },
    {
        "original_text": "The low-energy parameters of neutron-proton scattering are determined by using modern experimental data obtained in partial-wave analyses (PWAs). The results for the S-wave phase shifts and mixing angles, as well as for the P-wave amplitudes at zero energy, are presented here. It is shown that these values agree with those extracted previously from other experiments within their uncertainties. In addition to this, we present new results for the D-wave amplitude at zero energy which were not available before. \nI. INTRODUCTIO N\nNeutron-proton elastic scattering has been studied extensively over many decades  1  . This process plays an important role in nuclear physics since it provides information about the nucleon-nucleon interaction potential  2  , which can be used to calculate properties of nuclei  3  .\nIn recent years there have been significant advances in our understanding of the structure of the nucleon-nucleus system  4  . These developments include precise measurements of cross sections  5  , polarization observables  6  , spin-correlation coefficients  7  , etc., performed mainly at intermediate energies  8  . However, despite all efforts made so far, some questions remain open  9  . For example, one still needs more accurate determinations of the lowenergy parameters of the nucleonnucleon interaction  10  .",
        "watermark_text": "The lowest - energy parameters of neutron - proton diffusion are decided by using contemporary experimental evidence derived in partial - wave assessments ( PWAs ) . The results for the S - wave phase change and mixing angles , as well as for the P - wave amplitudes at zero energy , are presented here .It is demonstrated that these parameters agree with those retrieved previously from other experiments within their uncertainties . In addition to this , we present new data for the D - wave amplitude at zero energy which were not accessible before .I . INTRODUCTIO N Neutron - proton elastic scattering has been studied extensively over numerous years 1 . This process holds an important role in nuclear science since it gives information about the nucleon - nucleon collision potential 2 , which can be used to estimate features of nuclei 3 .In recent years there have been significant advances in our knowing of the structure of the nucleon - nucleus system 4 . These advances require precise observations of cross sections 5 , polarization observables 6 , spin - correlation coefficients 7 , etc . , conducted predominantly at intermediate energies 8 .However , despite all efforts made so far , some questions remain open 9 . For instance , one currently needs more accurate determinations of the lowenergy variables of the nucleonnucleon interaction 10 .",
        "rewrite_text": "The low-energy parameters of neutron-proton diffusion are determined using current experimental data obtained from partial-wave analyses (PWAs). This report presents findings on the S-wave phase shift, mixing angles, and P-wave amplitudes at zero energy. It is shown that these parameters are consistent with previously obtained results from other experiments, within their respective uncertainties. Additionally, we provide new data on the D-wave amplitude at zero energy, which has not been available before. \n\n**I. INTRODUCTION** \n\nNeutron-proton elastic scattering has been the subject of extensive research over many years. This process is crucial in nuclear science as it reveals information about the nucleon-nucleon collision potential, which aids in estimating nuclear properties. Recent advancements have significantly enhanced our understanding of the nucleon-nucleus system, necessitating precise measurements of cross sections, polarization observables, and spin-correlation coefficients, primarily conducted at intermediate energies. Nevertheless, despite these efforts, several questions remain unresolved. For example, there is still a need for more accurate determinations of the low-energy parameters of the nucleon-nucleon interaction.",
        "ori-fast-z-score": -0.21081851067789195,
        "water-fast-z-score": 6.81385143869247,
        "rewrite-fast-z-score": 0.8626621856275073
    },
    {
        "original_text": "We present new high resolution observations of the interstellar medium in the direction of the North Ecliptic Pole, made with the Westerbork Synthesis Radio Telescope at 1.4 GHz. The data reveal an extended filamentary structure that is traced by neutral hydrogen emission lines as well as continuum emission associated with free-free processes. We find evidence for two distinct components to this filamentary structure; one component has a relatively low column density but extends over several degrees on the sky while another component appears more compact and denser. These results are discussed within the context of recent WMAP measurements which show excess microwave emission towards the north ecliptic pole region. This work was supported by NASA grant NAG5-10842. Keywords: ISM, radio astronomy, H I 21 cm line, WMAP, filaments, North Ecliptic Pole Region . \nIntroduction\n\nThe Wilkinson Microwave Anisotropy Probe (WMAP) (Bennett et al., 2003a ) measured significant excesses of microwave emission above the expected cosmic background radiation level along three different lines-of-sight through the northern hemisphere. In particular, there were large excesses observed near the North Ecliptic Poles (NEPs). Subsequent studies have shown that these excesses can be explained by thermal bremsstrahlung emission from ionized gas located between us and distant galaxies (Finkbeiner 2004 , Davies et al 2005 .\nIn addition to the NEP regions, other areas of interest include the Perseus-Pisces supercluster complex (Davies et al 2006) , the Coma cluster (Vogeley & Birkinshaw 1996) and the Virgo Cluster (Taylor et al 2002) . All of these structures contain substantial amounts of hot plasma and it seems likely that they will also contribute significantly to the total foreground signal detected by WMAP. \nObservations of the diffuse galactic radio emission provide important information about the physical conditions in the interstellar medium (ISM), such as temperature, pressure and magnetic field strength. However, due to its faintness relative to point sources, only recently have we",
        "watermark_text": "We report new high resolution measurements of the interstellar material in the direction of the North Ecliptic Pole , made with the Westerbork Synthesis Radio Telescope at 1 . 4 GHz . The data reveal an extended filamentary composition that is traced by neutral hydrogen emission lines as well as continuum emission associated with free - free processes .We get data for two separate constituents to this filamentary composition ; one part has a fairly lowest column thickness but spreads over numerous degrees on the sky while another component appears more compact and denser . These conclusions are discussed within the context of recent WMAP measurements which show additional microwave emission towards the north ecliptic pole region .This project was supported by NASA loan NAG5 - 10842 . Keywords : ISM , radio astronomy , H I 21 cm line , WMAP , filaments , North Ecliptic Pole Region .Introduction The Wilkinson Microwave Anisotropy Probe ( WMAP ) ( Bennett et al . , 2003a ) measured significant excesses of microwave emission above the expected cosmic background radiation level along three different lines - of - view through the northern hemisphere . In particular , there were large excesses observed near the North Ecliptic Poles ( NEPs ) .Subsequent researchers have shown that these excesses can be explained by thermal bremsstrahlung emission from ionized gas located between us and distant galaxies ( Finkbeiner 2004 , Davies et al 2005 . In addition to the NEP regions , other areas of focus involve the Perseus - Pisces supercluster complex ( Davies et al 2006 ) , the Coma cluster ( Vogeley & Birkinshaw 1996 ) and the Virgo Cluster ( Taylor et al 2002 ) .All of these structures hold substantial deposits of hard gas and it appears probably that they will also contribute considerably to the total foreground light detected by WMAP . Observations of the diffuse galactic radio emission reveal important information about the physical conditions in the interstellar medium ( ISM ) , such as temperature , pressure and magnetic field intensity .However , owing to its faintness relative to point sources , only lately have we",
        "rewrite_text": "We present new high-resolution observations of interstellar material toward the North Ecliptic Pole, conducted using the Westerbork Synthesis Radio Telescope at 1.4 GHz. Our findings indicate a complex, extended filamentary structure, characterized by neutral hydrogen emission lines and continuum emission linked to free-free processes. We identify two distinct components within this filamentary structure: one that exhibits a relatively low column density but spans several degrees across the sky, and another that is more compact and denser. These results are discussed in the context of recent measurements from the Wilkinson Microwave Anisotropy Probe (WMAP), which illustrated additional microwave emissions in the North Ecliptic Pole region. This research was supported by NASA loan NAG5-10842. \n\n**Keywords:** Interstellar Medium (ISM), radio astronomy, HI 21 cm line, WMAP, filaments, North Ecliptic Pole region.\n\n**Introduction:** The Wilkinson Microwave Anisotropy Probe (WMAP) (Bennett et al., 2003a) detected notable excesses in microwave radiation above the expected cosmic background in three different lines of sight through the northern hemisphere, particularly near the North Ecliptic Poles (NEPs). Subsequent studies have attributed these excesses to thermal bremsstrahlung emissions from ionized gas situated between us and distant galaxies (Finkbeiner 2004, Davies et al. 2005). Aside from the NEP regions, other key areas include the Perseus-Pisces supercluster complex (Davies et al. 2006), the Coma cluster (Vogeley & Birkinshaw 1996), and the Virgo Cluster (Taylor et al. 2002). These structures contain significant amounts of hot gas, which likely contribute substantially to the overall foreground light observed by WMAP. Investigations of diffuse galactic radio emissions provide crucial insights into the physical conditions of the interstellar medium (ISM), such as temperature, pressure, and the intensity of magnetic fields. However, due to its faintness compared to point sources, significant progress in this area has only recently been made.",
        "ori-fast-z-score": 1.4852968963237645,
        "water-fast-z-score": 6.850168759240548,
        "rewrite-fast-z-score": 1.414213562373095
    },
    {
        "original_text": "We report on the fabrication and characterization of a novel floating gate (FG) HEMT with an AlGaN/GaN/AlN heterostructure grown by metal-organic chemical vapor deposition (MOCVD). The device is fabricated using standard photolithography techniques, followed by dry etching to define mesa structures. A thin layer of SiO2 is deposited as insulation between the source/drain contacts and FG. Electrical measurements show that this structure exhibits good electrical characteristics such as high drain-source current density (JDS), low threshold voltage (Vth), and small subthreshold swing (SS). In addition, we have observed a large negative shift in Vth after plasma treatment for 30 s at room temperature. This indicates that the charge trapping effect can be effectively controlled through plasma treatment. \n \n Keywords: GaN-based transistors; Plasma effects; Floating gate devices; High electron mobility transistors",
        "watermark_text": "We report on the fabrication and identification of a new floating gate ( FG ) HEMT with an AlGaN / GaN / AlN heterostructure grown by metal - organic chemical vapor deposition ( MOCVD ) . The system is manufactured using traditional photolithography method , followed by cold etching to define mesa forms .A narrow coating of SiO2 is accumulated as insulation between the supply / drain contacts and FG . Electrical measurements show that this formation displays good electrical qualities such as long drain - source current density ( JDS ) , low threshold voltage ( Vth ) , and tiny subthreshold swing ( SS ) .In addition , we have noted a large negative shift in Vth after plasma treatment for 30 s at room temperature . This implies that the charge trapping phenomenon can be effectively controlled through plasma treatment .Keywords : GaN - based transistors ; Plasma elements ; Floating gate devices ; High electron mobility transistors",
        "rewrite_text": "We present the development and characterization of a novel floating gate (FG) high electron mobility transistor (HEMT) featuring an AlGaN/GaN/AlN heterostructure, which was fabricated using metal-organic chemical vapor deposition (MOCVD). The device was created utilizing standard photolithography techniques, followed by cold etching to shape the mesa structures. A thin layer of SiO2 was applied as an insulating material between the supply/drain contacts and the floating gate. Electrical testing indicates that this configuration exhibits excellent performance characteristics, including a high drain-source current density (JDS), a low threshold voltage (Vth), and a minimal subthreshold swing (SS). Furthermore, we observed a significant negative shift in Vth following a 30-second room temperature plasma treatment, suggesting that plasma treatment can effectively manipulate the charge trapping phenomenon. Keywords: GaN-based transistors; Plasma elements; Floating gate devices; High electron mobility transistors.",
        "ori-fast-z-score": 0.12216944435630522,
        "water-fast-z-score": 5.662208585049306,
        "rewrite-fast-z-score": -0.6793662204867574
    },
    {
        "original_text": "The main goal of this research is the study and analysis of how different users can contribute in an open source software project, by sharing their knowledge through comments on issues or pull requests (PRs). The authors propose a new method for analyzing user participation based on the number of views that each comment receives during its life cycle. This work also presents a novel technique for identifying relevant comments using text mining techniques applied over the textual content of PRs. Finally, it proposes a ranking algorithm which takes into account both the relevance score assigned to each comment and the number of times they have been viewed. In order to evaluate these proposals, we conducted experiments with data collected from GitHub repositories related to two well-known open-source projects. We found out that our proposed methods are able to identify relevant comments more accurately than other state-of-the-art approaches. Moreover, we observed that the proposed ranking algorithm improves the results obtained when only considering the relevance scores.",
        "watermark_text": "The main goal of this research is the study and assessment of how various users can participation in an free source software work , by sharing their understanding through comments on problems or pull requests ( PRs ) . The authors propose a new method for evaluating customer membership based on the quantity of views that each comment receives during its life cycle .This research also provides a new technique for finding relevant remarks utilizing text searching methods applied over the textual content of PRs . Finally , it presents a ranking method which gives into consideration both the credibility score given to each comment and the quantity of years they have been viewed .In order to analyze these proposals , we conducted experiments with data taken from GitHub repositories linked to two good - famous open - source projects . We showed out that our proposed methods are able to identify relevant comments more accurately than other state - of - the - art methods .Moreover , we concluded that the suggested ranking method improves the results derived when only considering the relevance ratings .",
        "rewrite_text": "The primary aim of this research is to examine and evaluate how different users can contribute to open-source software projects by sharing their insights through comments on issues or pull requests (PRs). The authors introduce a novel method for assessing user engagement based on the number of views each comment receives throughout its lifecycle. Additionally, the study presents a technique for identifying relevant comments by applying text search methods to the content of PRs. It also introduces a ranking system that takes into account both the credibility score assigned to each comment and the total number of views they have received. To validate these proposals, experiments were conducted using data from GitHub repositories associated with two well-known open-source projects. The results demonstrated that the proposed methods are more effective in identifying relevant comments compared to existing state-of-the-art approaches. Furthermore, we found that the suggested ranking method enhances the outcomes when considering relevance ratings alone.",
        "ori-fast-z-score": -1.0425720702853738,
        "water-fast-z-score": 6.672461249826393,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "In this work, we study the renormalization group equations (RGEs) for extra U(1) supersymmetric string inspired model with heavy Z  prime and its effects on gauge coupling unification at one-loop level. We find that the inclusion of new particles such as vector-like quarks and leptons can significantly affect the running behavior of gauge couplings. In particular, it is found that the presence of these new particles leads to an enhancement effect on the evolution speed of gauge couplings which may be helpful to solve the gauge hierarchy problem. Furthermore, by using the experimental data of low energy physics, we obtain some constraints on the mass spectrum of extra particles involved in our model. Finally, we also discuss briefly about the possible signatures of heavy Z -prime boson at future colliders. The results are summarized below. \nI. INTRODUCTORY REMARK\nThe Standard Model (SM), based on SU(3) C ×SU(2) L ×U(1) Y gauge symmetry, has been very successful in describing all known phenomena upto TeV scale energies  1  . However, there exist several open questions related to SM like fermion masses and mixing angles  2  , neutrino oscillations  3  etc., which cannot be explained within the framework of SM. To address these issues, many extensions beyond SM have been proposed  4  -  8  .\nAmong them, Grand Unified Theory (GUTs)  9  provides a natural solution to the above mentioned problems  10  . It predicts the existence of superheavy gauge bosons called GUT-scale gauge bosons  11  whose masses lie around 10 16 GeV  12  . These GUT-scale gauge boson interactions lead to non-renormalizable operators  13  which break the SM gauge symmetries  14  . Therefore, they should not appear in any physical process  15  . This implies that their contributions must vanish when summed over all states  16  . Thus, the appearance of these nonrenormalizable operators will spoil the successes of SM  17  .",
        "watermark_text": "In this research , we study the renormalization group equations ( RGEs ) for extra U ( 1 ) supersymmetric string inspired system with heavy Z prime and its impact on gauge correlation unification at one - loop level . We see that the introduction of new ions such as vector - like quarks and leptons can significantly affect the running response of gauge couplings .In particular , it is found that the presence of these new objects gives to an enhancement impact on the evolution speed of gauge couplings which would be beneficial to solve the gauge ranking problem . Furthermore , by using the empirical data of low power physics , we obtain some restrictions on the mass spectrum of added particles involved in our model .Finally , we also discuss briefly about the possible signatures of large Z - prime boson at possible colliders . The results are presented below .I . INTRODUCTORY REMARK The Standard Model ( SM ) , built on SU ( 3 ) C ×SU ( 2 ) L ×U ( 1 ) Y gauge symmetry , has been very successful in representing all known phenomena upto TeV scale energies 1 .However , there remain many open questions related to SM like fermion masses and mixing angles 2 , neutrino oscillations 3 etc . , which impossible be described within the framework of SM . To address these problems , various extensions beyond SM have been proposed 4 - 8 .Among them , Grand Unified Theory ( GUTs ) 9 offers a natural solution to the above mentioned difficulties 10 . It predicts the existence of superheavy gauge bosons called GUT - scale gauge bosons 11 whose masses sit around 10 16 GeV 12 .These GUT - scale gauge boson interactions result to non - renormalizable expressions 13 which break the SM gauge symmetries 14 . Therefore , they should not appear in any physical process 15 .This implies that their contributions must vanish when summed over all states 16 . Thus , the appearance of these nonrenormalizable functions will spoil the achievements of SM 17 .",
        "rewrite_text": "In this study, we investigate the renormalization group equations (RGEs) for an extended U(1) supersymmetric string-inspired framework featuring a heavy Z' boson and its influence on gauge coupling unification at the one-loop level. Our findings indicate that the introduction of new particles, such as vector-like quarks and leptons, can have a substantial effect on the running behavior of gauge couplings. Notably, the presence of these additional particles accelerates the evolution of gauge couplings, providing a potential resolution to the gauge hierarchy problem. Additionally, by analyzing empirical data from low-energy physics, we derive constraints on the mass spectrum of the newly introduced particles in our model. Lastly, we briefly discuss the potential signatures of a large Z' boson at future colliders. The results of our research are outlined below.\n\nI. INTRODUCTORY REMARKS\n\nThe Standard Model (SM), founded on the gauge symmetry SU(3)C × SU(2)L × U(1)Y, has been remarkably successful in accounting for all known phenomena up to TeV-scale energies. However, numerous unresolved questions persist regarding aspects such as SM fermion masses and mixing angles, as well as neutrino oscillations, which cannot be addressed within the confines of the SM. To tackle these issues, various extensions beyond the SM have been proposed. Among these, Grand Unified Theories (GUTs) provide a natural solution to the aforementioned challenges. GUTs predict the existence of superheavy gauge bosons, termed GUT-scale gauge bosons, with masses on the order of 10^16 GeV. The interactions of these GUT-scale gauge bosons lead to non-renormalizable expressions that break the SM gauge symmetries. Consequently, such contributions should not manifest in any physical processes, implying their total contributions must vanish when summed across all states. Therefore, the emergence of these non-renormalizable functions could undermine the successes of the SM.",
        "ori-fast-z-score": 0.3563483225498992,
        "water-fast-z-score": 6.887089370699352,
        "rewrite-fast-z-score": 1.7960530202677492
    },
    {
        "original_text": "We study the effect of Coulomb gauge fixing on the gluon propagator in Landau gauge, using lattice simulations with two different actions for SU(2) Yang-Mills theory. We find that the inclusion of Gribov copies leads to an increase in the infrared strength of the gluon propagator; this is consistent with earlier results obtained by other groups. \n \n In addition we show how the presence of Gribov copies affects the static quark-antiquark potential at large distances. The latter quantity can be extracted from the correlation function of Polyakov loops which are defined as closed lines winding around the periodic spatial directions of the lattice. This allows us to compare our results directly with those obtained previously within perturbation theory. Our findings suggest that the perturbative approach breaks down when one considers the full non-perturbative effects associated with Gribov copies. Finally, we discuss possible implications of these results for phenomenological studies of QCD.",
        "watermark_text": "We research the impact of Coulomb gauge fixing on the gluon propagator in Landau gauge , using crystal simulations with two different actions for SU ( 2 ) Yang - Mills theory . We see that the introduction of Gribov copies results to an increase in the infrared thickness of the gluon propagator ; this is compatible with previous findings obtained by other groups .In addition we study how the presence of Gribov copies impacts the static quark - antiquark potential at large distances . The latter quantity can be extracted from the relationship function of Polyakov loops which are defined as closed lines wound around the periodic spatial directions of the crystal .This enables us to relate our findings directly with those achieved previously within perturbation theory . Our findings show that the perturbative methodology cracks down when one considers the full non - perturbative properties associated with Gribov copies .Finally , we explain possible possibilities of these results for phenomenological investigations of QCD .",
        "rewrite_text": "We investigate the effects of Coulomb gauge fixing on the gluon propagator in Landau gauge through crystal simulations utilizing two different actions for SU(2) Yang-Mills theory. Our results indicate that the introduction of Gribov copies leads to an increase in the infrared thickness of the gluon propagator, which aligns with findings from other research groups. Additionally, we analyze how Gribov copies influence the static quark-antiquark potential at large distances. This potential can be derived from the relationship involving Polyakov loops, which are defined as closed loops wrapping around the periodic spatial directions of the crystal. This approach allows us to directly connect our results to those obtained previously through perturbation theory. Our findings reveal that the perturbative approach becomes inadequate when considering the full non-perturbative properties linked to Gribov copies. Finally, we discuss the potential implications of these results for phenomenological studies of QCD.",
        "ori-fast-z-score": -1.3438638879193574,
        "water-fast-z-score": 5.0089472186085136,
        "rewrite-fast-z-score": 0.3721042037676254
    },
    {
        "original_text": "We present new near-infrared (NIR) photometry for more than 1000 stars in the central region of the Carina Nebulae, obtained with the WFCAM camera on UKIRT. The data are used to construct an energy budget for this complex star forming region. We find that the total luminosity is dominated by red supergiants at K-band (2 microns), but there is also significant contribution from hotter O-type stars. Using these NIR observations we have constructed a model of the global properties of the nebulosity surrounding the open clusters Trumpler 14 & 16. This model shows good agreement with existing optical images of the region. In particular it reproduces well the observed distribution of dust emission as traced by Spitzer mid-infrared imaging. \n \n Keywords: Open cluster; Near-Infrared; Star formation; Supernova remnant; Stellar population synthesis; Galactic structure",
        "watermark_text": "We report new near - infrared ( NIR ) photometry for more than 1000 stars in the central region of the Carina Nebulae , obtained with the WFCAM sensor on UKIRT . The data are using to build an energy budget for this complex star producing zone .We see that the total luminosity is dominated by red supergiants at K - band ( 2 microns ) , but there is also important contribution from hotter O - class stars . Using these NIR observations we have constructed a description of the global properties of the nebulosity surrounding the open complexes Trumpler 14 & 16 .This theory demonstrates good agreement with existing imaging photographs of the region . In particular it reproduces well the seen patterns of dust radiation as dated by Spitzer mid - infrared imaging .Keywords : Open cluster ; Near - Infrared ; Star formation ; Supernova remnant ; Stellar population production ; Galactic structure",
        "rewrite_text": "We present new near-infrared (NIR) photometry for over 1,000 stars in the central region of the Carina Nebula, acquired using the WFCAM sensor on UKIRT. This data is utilized to create an energy budget for this intricate star-forming area. Our analysis reveals that red supergiants dominate the total luminosity at the K-band (2 microns), while hotter O-class stars also make significant contributions. With these NIR observations, we have developed a comprehensive understanding of the global properties of the nebulosity surrounding the open clusters Trumpler 14 and 16. Our findings align closely with existing imaging of the region, accurately reproducing the observed patterns of dust radiation as indicated by Spitzer's mid-infrared imaging. \n\nKeywords: Open cluster; Near-Infrared; Star formation; Supernova remnant; Stellar population production; Galactic structure.",
        "ori-fast-z-score": 1.2909944487358056,
        "water-fast-z-score": 6.37925663806037,
        "rewrite-fast-z-score": 3.3565855667130946
    },
    {
        "original_text": "We have analyzed the statistical properties of giant pulses (GPs) detected in radio observations at 1.4 GHz with the Arecibo Observatory and compared them to those observed for GPs at other frequencies.  We find that the distribution of pulse widths is consistent with a log-normal function, as found previously by Cordes et al. (2004), but we also find evidence for an additional component which may be due to interstellar scattering or intrinsic effects within the source itself. The mean flux density of GPs decreases rapidly with increasing frequency above about 400 MHz; this decrease can be described well using a power law model with index -1.5 ± 0.1. This result suggests that there are two populations of GPs: one population whose emission mechanism has a low-frequency cutoff near 400 MHz, and another population whose emission mechanism extends up to at least 2 GHz. Finally, we show that the number of GPs per unit time increases linearly with observing bandwidth over most of our data set, indicating that the majority of these events occur independently of each other.",
        "watermark_text": "We have analyzed the statistical characteristics of giant pulses ( GPs ) detected in radio observations at 1 . 4 GHz with the Arecibo Observatory and compared them to those observed for GPs at other frequencies . We see that the spread of wave widths is compatible with a log - normal function , as found prior by Cordes et al .( 2004 ) , but we also find proof for an additional element which may be due to interstellar scattering or intrinsic effects within the source itself . The mean flux concentration of GPs changes swiftly with increasing amplitude above about 400 MHz ; this decline can be described good using a power law description with index - 1 . 5 ± 0 . 1 .This result suggests that there are two communities of GPs : one community whose emission mechanism has a small - frequency cutoff near 400 MHz , and another population whose emission mechanism stretches up to at least 2 GHz . Finally , we find that the proportion of GPs per unit time changes linearly with observing bandwidth over most of our information pool , showing that the majority of these changes occur independently of each other .",
        "rewrite_text": "We examined the statistical properties of giant pulses (GPs) detected at 1.4 GHz using the Arecibo Observatory, comparing them to those observed at different frequencies. Our analysis reveals that the distribution of pulse widths aligns with a log-normal function, consistent with previous findings by Cordes et al. (2004). However, we also identify evidence for an additional factor that may result from interstellar scattering or intrinsic characteristics of the source itself. The mean flux density of GPs rapidly declines as the amplitude increases beyond approximately 400 MHz; this trend can be effectively modeled with a power law featuring an index of -1.5 ± 0.1. This indicates the existence of two distinct groups of GPs: one group with an emission mechanism that has a low-frequency cutoff around 400 MHz, and another that extends up to at least 2 GHz. Lastly, we observe that the rate of GPs per unit time varies linearly with the observing bandwidth across most of our dataset, suggesting that these variations occur largely independently of one another.",
        "ori-fast-z-score": -0.22941573387056174,
        "water-fast-z-score": 5.9648090806346055,
        "rewrite-fast-z-score": -0.7071067811865476
    },
    {
        "original_text": "We present an exact expression for the energy density functional in terms of the local electronic charge and spin densities, which is valid for any number N of electrons on a two-dimensional jellium surface with arbitrary spin-orbit interaction strength. The resulting sum rules are shown to be equivalent to those derived by Stillinger and Lovett (SL) for the case of zero spin-orbit coupling but they also include additional contributions due to this term. We show that these new terms can be expressed as functions of the SL parameters only. This result allows us to obtain explicit expressions for all the relevant physical quantities such as the exchange-correlation potential or the magnetization profile at finite temperature. Finally we discuss how our results could be used to improve existing approximations within Density Functional Theory. PACS: 71.10.Pq - Energy-densities; 72.20.Fd - Energy-density functionals; 73.40.Gk - Spin-polarized systems",
        "watermark_text": "We present an precise representation for the power density functional in terms of the local electronic charge and spin densities , which is valid for any number N of electrons on a two - dimensional jellium surface with arbitrary spin - orbit interaction strength . The resulting sum rules are shown to be analogous to those developed by Stillinger and Lovett ( SL ) for the case of zero spin - orbit bonding but they still provide additional contributions due to this term .We see that these new terms can be described as functions of the SL parameters only . This result allows us to obtain precise expressions for all the appropriate physical components such as the transfer - correlation potential or the magnetization profile at finite temperature .Finally we talk how our findings may be used to improve established approximations within Density Functional Theory . PACS : 71 . 10 . Pq - Energy - densities ; 72 . 20 . Fd - Energy - density functionals ; 73 . 40 . Gk - Spin - polarized systems",
        "rewrite_text": "We provide an accurate representation of the power density functional in terms of local electronic charge and spin densities, applicable to any number \\( N \\) of electrons on a two-dimensional jellium surface with arbitrary strength of spin-orbit interaction. The resulting sum rules resemble those formulated by Stillinger and Lovett (SL) in the context of zero spin-orbit coupling, but they also incorporate additional contributions arising from this interaction. Notably, these new terms can be expressed solely in terms of the SL parameters. This finding enables us to derive precise expressions for key physical quantities, such as the transfer-correlation potential and the magnetization profile at finite temperatures. Finally, we discuss how our results may enhance established approximations within Density Functional Theory. PACS: 71.10.Pq - Energy densities; 72.20.Fd - Energy-density functionals; 73.40.Gk - Spin-polarized systems.",
        "ori-fast-z-score": -0.3721042037676254,
        "water-fast-z-score": 3.6927447293799815,
        "rewrite-fast-z-score": 1.0
    },
    {
        "original_text": "In this work, we consider the problem of multiuser detection (MUD) for code division multiple access systems with time-varying channels. We propose an algorithm that jointly performs user identification and data detection by using a maximum likelihood criterion. The proposed method is based on the expectation-maximization (EM) algorithm which iteratively estimates both the channel coefficients and transmitted symbols. In order to reduce computational complexity, we also develop a low-complexity suboptimal MUD scheme. Numerical results show that our proposed algorithms outperform existing schemes under various scenarios. Index Terms-Data detection, EM algorithm, Multiuser detection, Time varying channels. 1 Introduction Code-division-multiple-access (CDMA) has been widely used as one of the most promising technologies for next-generation wireless communications due to its high spectral efficiency  1  . However, CDMA suffers from severe interference between users caused by multipath propagation  2  , especially when the number of active users increases  3  .\nTo mitigate inter-user interference, multiuser detectors have been developed  4  -  6  . Among them, linear multiuser detectors are attractive because they can be implemented easily at low cost  7  . Unfortunately, these detectors suffer from performance loss compared to optimal multiuser detectors  8  . To improve their performance, nonlinear multiuser detectors such as successive interference cancellation  9  or parallel interference cancellation  10  were introduced. These detectors require accurate knowledge about the received signals  11  . Therefore, blind multiuser detectors  12  -  14  were proposed to estimate unknown parameters without any training sequence  15  . Although blind multiuser detectors do not need prior information about the received signal, they usually perform worse than conventional multiuser detectors  16  .\nRecently, there has been growing interest in developing multiuser detectors for time-varying channels  17  -  20  . Since the channel varies over time, it becomes more difficult to detect the transmitted symbol accurately  21  . Moreover, if the channel changes rapidly, then the detector may fail completely  22  . Thus, it is important to design robust multiuser detectors against rapid channel variations  23  .",
        "watermark_text": "In this research , we investigate the question of multiuser tracking ( MUD ) for code division multiple entry systems with time - differing channels . We suggest an algorithm that together manages user identification and information detection by using a maximum likelihood threshold .The proposed approach is based on the expectation - maximization ( EM ) algorithm which iteratively generates both the channel coefficients and transmitted symbols . In order to reduce numerical complexity , we also build a small - complexity suboptimal MUD scheme .Numerical results show that our proposed methods outperform established algorithms under various circumstances . Index Terms - Data tracking , EM algorithm , Multiuser tracking , Time varying channels .1 Introduction Code - division - multiple - access ( CDMA ) has been widely adopted as one of the most attractive devices for next - class wireless communications thanks to its high spectral power 1 . However , CDMA suffers from severe interference between clients caused by multipath propagation 2 , particularly when the proportion of active consumers increases 3 .To mitigate inter - customer interference , multiuser detectors have been created 4 - 6 . Among them , continuous multiuser detectors are interesting because they can be deployed easily at low cost 7 .Unfortunately , these detectors suffer from performance loss compared to optimal multiuser detectors 8 . To increase their performance , nonlinear multiuser detectors such as consecutive interference cancellation 9 or parallel interference cancellation 10 were introduced .These detectors need accurate knowledge about the received messages 11 . Therefore , blind multiuser detectors 12 - 14 were developed to estimate unknown parameters without any testing sequence 15 .Although blind multiuser detectors do not require prior information about the received signal , they generally work worse than conventional multiuser detectors 16 . Recently , there has been growing interest in building multiuser detectors for time - differing channels 17 - 20 .Since the channel varies over time , it becomes more impossible to locate the transmitted expression accurately 21 . Moreover , if the channel shifts rapidly , then the sensor may fail entirely 22 .Thus , it is important to build robust multiuser detectors against sudden channel variations 23 .",
        "rewrite_text": "In this study, we explore the issue of multiuser tracking (MUD) within code division multiple access (CDMA) systems characterized by time-varying channels. We propose an algorithm that effectively handles user identification and information detection by employing a maximum likelihood threshold. This approach is grounded in the expectation-maximization (EM) algorithm, which iteratively estimates both the channel coefficients and the transmitted symbols. To minimize numerical complexity, we also develop a low-complexity suboptimal MUD scheme. Our numerical results indicate that the methods we propose outperform existing algorithms across a range of scenarios. \n\n**Index Terms:** Data Tracking, EM Algorithm, Multiuser Tracking, Time-Varying Channels.\n\n**1 Introduction**  \nCode-division multiple access (CDMA) has become one of the most promising technologies for next-generation wireless communications due to its high spectral efficiency. However, CDMA systems face significant interference among users caused by multipath propagation, which becomes particularly problematic as the number of active users increases. To alleviate inter-user interference, various multiuser detectors have been developed. Continuous multiuser detectors are particularly appealing due to their ease of deployment and low cost. Unfortunately, these detectors often experience performance degradation compared to optimal multiuser detectors. To enhance their performance, nonlinear multiuser detectors, such as successive interference cancellation and parallel interference cancellation, have been introduced. These nonlinear approaches require precise knowledge of the received signals. As a solution, blind multiuser detectors have emerged to estimate unknown parameters without relying on any pre-testing sequences. However, despite their independence from prior signal information, blind multiuser detectors generally perform worse than traditional multiuser detectors. Recent research has increasingly focused on developing multiuser detectors for time-varying channels. The variability of the channel introduces challenges in accurately determining the transmitted signal, particularly in rapidly changing conditions, which can lead to detector failures. Therefore, it is crucial to create robust multiuser detectors that can effectively handle sudden variations in the channel.",
        "ori-fast-z-score": -1.0309670614335873,
        "water-fast-z-score": 8.751130125933031,
        "rewrite-fast-z-score": 2.114803214967485
    },
    {
        "original_text": "We study the relationship between network structure, dynamics, and function using an example system that is both complex and experimentally accessible -- the brain s neuronal circuitry. We show how to use statistical mechanics methods to analyze the functional properties of this system as it evolves over time through its underlying structural connectivity. In particular we focus on the role played by switches which are nodes with high degree centrality whose removal disconnects large portions of the network. Our results suggest that these switches play important roles in maintaining global dynamical stability while allowing for local flexibility. The manuscript is organized into four sections. Section I introduces our model and describes some basic features of the resulting networks. Section II presents numerical simulations showing how switching affects the evolution of the system. Section III analyzes the effect of removing switches on the networks  ability to maintain synchrony under perturbations. Finally section IV discusses possible extensions of our work. This article has been published in final form at http://arxiv.org/abs/1306.5995",
        "watermark_text": "We research the relationship between network structure , dynamics , and function using an instance structure that is both complex and experimentally visible - - the brain s neuronal circuitry . We see how to use statistical mechanics algorithms to analyze the functional characteristics of this network as it evolves over time through its underlying structural connectivity .In particular we focus on the part played by switches which are networks with high degree centrality whose removal disconnects huge segments of the organization . Our results show that these switches act key roles in maintaining global dynamical stability while providing for central autonomy .The manuscript is organized into four components . Section I outlines our model and explains some fundamental characteristics of the resulting connections .Section II offers numerical simulations demonstrating how switching influence the evolution of the organization . Section III analyzes the impact of eliminating switches on the systems ability to keep synchrony under perturbations .Finally section IV examines possible extensions of our work . This section has been publication in finished form at http : / / arxiv . org / abs / 1306 . 5995",
        "rewrite_text": "We investigate the interplay between network structure, dynamics, and functionality through a complex and experimentally observable system—the neuronal circuitry of the brain. Our approach utilizes statistical mechanics algorithms to examine the functional traits of this network as it evolves over time, driven by its inherent structural connectivity. Specifically, we concentrate on the role of switches—networks characterized by high degree centrality—whose removal leads to the disconnection of significant portions of the organization. Our findings indicate that these switches are critical for maintaining global dynamical stability while allowing for central autonomy. The manuscript is divided into four sections. Section I presents our model and describes some essential characteristics of the resulting connections. Section II provides numerical simulations that illustrate how switches influence the evolution of the network. Section III assesses the effects of switch removal on the system's ability to maintain synchrony in the face of perturbations. Finally, Section IV explores potential extensions of our research. This section has been published in its final form at http://arxiv.org/abs/1306.5995.",
        "ori-fast-z-score": -0.9761870601839528,
        "water-fast-z-score": 7.637626158259733,
        "rewrite-fast-z-score": 2.5555555555555554
    },
    {
        "original_text": "The main goal of this thesis is to experiment with the use of recursion as an alternative way for querying databases, using Prolog (a declarative language) and SQL (the standard query language). The first part presents some background on how databases are structured and queried today; it also introduces the concept of recursion and its application in computer science. In the second section we present our experiments with recursion in Prolog, where we show that recursion can be used to express complex queries without having to resort to procedural code or other languages such as Java. Finally, in the third section we discuss the results obtained by applying recursion in SQL systems. We conclude that although there have been many attempts at implementing recursion in SQL systems, none has succeeded so far due to technical difficulties inherent in these systems. This work shows that recursion could be useful if implemented correctly in SQL systems. Keywords: Database, Recursion, Query",
        "watermark_text": "The main goal of this dissertation is to study with the using of recursion as an additional means for querying data , using Prolog ( a declarative language ) and SQL ( the standard query language ) . The first part offers some details on how databases are structured and queried today ; it also explains the idea of recursion and its use in computer science .In the second chapter we present our experiments with recursion in Prolog , where we explain that recursion can be used to express complex queries without having to resort to procedural code or other languages such as Java . Finally , in the third chapter we explain the results derived by using recursion in SQL systems .We follow that although there have been many efforts at executing recursion in SQL systems , none has successful so far owing to technical problems inherent in these systems . This research shows that recursion could be usable if implemented correctly in SQL systems .Keywords: Database, Recursion, Query",
        "rewrite_text": "The primary objective of this dissertation is to explore the use of recursion as a supplementary method for querying data, utilizing Prolog, a declarative programming language, alongside SQL, the standard query language. The first chapter provides an overview of contemporary database structures and querying techniques, while also introducing the concept of recursion and its relevance in computer science. In the second chapter, we detail our experiments with recursion in Prolog, demonstrating how it can be employed to formulate complex queries without the need for procedural code or other programming languages such as Java. Finally, the third chapter discusses the outcomes of applying recursion in SQL systems. We note that despite various attempts to implement recursion in SQL, none have been successful due to inherent technical challenges within these systems. Our research indicates that recursion could be effectively utilized if it is correctly integrated into SQL systems. \n\nKeywords: Database, Recursion, Query",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.425396041156863,
        "rewrite-fast-z-score": 1.25
    },
    {
        "original_text": "We present the results of an analysis searching for supersymmetric particles in events with jets and missing transverse energy using data collected by the D0 experiment at Fermilab during Run II, corresponding to 1 fb-1 . We consider models where squarks decay into quarks and gluinos which then decay via intermediate sleptons or neutralinos into final states containing two light-flavored leptons (electrons and/or muons) and large E T / .\nThe search is performed over a wide range of masses for all sparticles involved in these cascade decays , including those that are not directly produced but can be exchanged in t-channel processes . No significant excess above background expectations has been observed . Limits on the production cross sections times branching fractions have been set as functions of the mass parameters of the model considered . These limits are compared to theoretical predictions obtained within the framework of minimal supergravity grand unification .",
        "watermark_text": "We present the conclusion of an assessment searching for supersymmetric particles in events with jets and lost radial energy using data acquired by the D0 study at Fermilab during Run II , corresponding to 1 fb - 1 . We consider scenarios where squarks decay into quarks and gluinos which then decay via elementary sleptons or neutralinos into last states featuring two light - flavored leptons ( atoms and / or muons ) and large E T / .The search is conducted over a broad variety of masses for all sparticles involved in these cascade decays , particularly those that are not directly produced but can be exchanged in t - channel pathways . No much excess above background expectations has been observed .Limits on the production cross sections times branching fractions have been set as functions of the mass parameters of the model discussed . These restrictions are compared to theoretical estimates obtained within the framework of minimal supergravity grand unification .",
        "rewrite_text": "We present the findings of an assessment aimed at identifying supersymmetric particles in events characterized by jets and missing transverse energy. This analysis utilizes data collected by the D0 experiment at Fermilab during Run II, amounting to 1 fb^-1. We explore scenarios in which squarks decay into quarks and gluinos, which subsequently decay through light sleptons or neutralinos, resulting in final states that include two light-flavor leptons (such as electrons and/or muons) and significant missing transverse energy. The investigation covers a wide range of masses for all sparticles involved in these cascade decays, particularly focusing on those not directly produced but exchanged in t-channel processes. No significant excess above background expectations has been detected. Consequently, we have established limits on the production cross sections multiplied by branching fractions as functions of the model's mass parameters. These limits are then compared with theoretical predictions derived from the framework of minimal supergravity grand unification.",
        "ori-fast-z-score": -1.1338934190276817,
        "water-fast-z-score": 4.6615618337804685,
        "rewrite-fast-z-score": -0.23570226039551587
    },
    {
        "original_text": "We report on observations made with Chandra and XMM-Newton that reveal an X-ray flare from the magnetar CXOU J16 47 10 . 2-45 52 16 (hereafter, J1647) located within the open cluster Westerlund 1. The flare was detected by both observatories during their respective slews to point at another target; it lasted for about one hour before fading below detectability. We find no evidence for any significant change in the spin-down rate or period derivative of this source following its outburst. \n \n This is the first time such a large event has been observed from a magnetar; we estimate that the total energy released in the flare was ~3 x 10^44 erg. Our analysis shows that the flare occurred when the star s magnetic field lines were nearly perpendicular to our line-of-sight. In addition, we detect pulsations from J1647 during the flare which are consistent with those seen prior to the flare. These results suggest that the flaring activity may be due to reconnection events occurring along the closed loops of the stellar magnetic field.",
        "watermark_text": "We report on observations made with Chandra and XMM - Newton that indicate an X - ray flare from the magnetar CXOU J16 47 10 . 2 - 45 52 16 ( hereafter , J1647 ) located within the open cluster Westerlund 1 .The flare was noticed by both observatories during their separate slews to point at another target ; it persisted for about one evening before faded below detectability . We see no evidence for any considerable shift in the spin - down frequency or duration derivative of this source following its outburst .This is the first time such a large incident has been observed from a magnetar ; we estimate that the total energy released in the flare was ~ 3 x 10 ^ 44 erg . Our study shows that the flare originated when the star s magnetic field lines were roughly perpendicular to our line - of - view .In addition , we find pulsations from J1647 during the flare which are compatible with those observed earlier to the flare . These data suggest that the flaring activity may be due to reconnection events resulting along the shut rings of the stars magnetic force .",
        "rewrite_text": "We present observations from Chandra and XMM-Newton, which indicate that the magnetar CXOU J164710.2-455216 (referred to as J1647), located within the open cluster Westerlund 1, experienced an X-ray flare. This flare was detected by both observatories during their separate observations of another target and lasted for approximately one evening before fading below detectable levels. We found no significant changes in the spin-down frequency or duration derivative of this source following the outburst. This marks the first observation of such a significant event from a magnetar, with an estimated total energy release of ~3 x 10^44 erg. Our analysis reveals that the flare occurred when the star's magnetic field lines were nearly perpendicular to our line of sight. Additionally, we detected pulsations from J1647 during the flare, which align with previously observed pulsations. These findings suggest that the flaring activity may be attributed to reconnection events occurring along the star's magnetic field lines.",
        "ori-fast-z-score": -0.7171371656006361,
        "water-fast-z-score": 5.259005881071332,
        "rewrite-fast-z-score": -1.2309149097933272
    },
    {
        "original_text": "We study the properties of strong peak points in Banach spaces, which are defined as follows.  Let X be a real or complex normed space with dual space X*. A point x # X is called a strong peak point if there exists an f # S(X) such that |f (x)| = sup{|f (y)| : y # X}. We prove that every separable reflexive Banach space has a dense set of strong peak points. As applications we show that every separable reflexivizable Banach space contains a copy of c 0 , and that every separable superreflexive Banach space contains a subspace isomorphic to l p for some 1 < p < + . In this note we study the properties of strong peaks points in Banach spaces. The concept was introduced by J. Lindenstrauss  L  who proved that every separable reflexible Banach space has a nonempty set of strong peak points; see also  JL1  .\nIn Section 2 we give several equivalent characterizations of strong peak points. In particular, it turns out that a point x # X is a strong peak point if and only if there exist two sequences (a n ) and (b n ) in R satisfying lim n Ä a n = lim n Ä b n = 1 and lim n Ä a n &1Â2 b n = 0 such that the sequence (a n b n ) converges weakly to zero but not strongly. This characterization enables us to prove our first main result on the density of strong peak points in separable reflexive BanACH spaces. \nTheorem 3. Every separable reflexive BanACH space has a dense set SP(X) of strong peak points.\n\nAs immediate consequences of Theorem 3 we obtain the following results. (i) Every separable reflexivizable space contains a copy of c0.\n(ii) Every separable superreflexive space contains a subspace isomorphic",
        "watermark_text": "We research the properties of stable peak points in Banach spaces , which are given as follows . Let X be a real or complex normed space with dual collection X * .A point x # X is dubbed a strong peak point if there exists an f # S ( X ) such that | f ( x ) | = sup { | f ( y ) | : y # X } . We say that every separable reflexive Banach space has a dense setting of strengthened peak points .As applications we prove that every separable reflexivizable Banach space includes a copy of c 0 , and that every separable superreflexive Banach space includes a subspace isomorphic to l p for some 1 < p < + . In this note we study the properties of strong peaks points in Banach spaces .The concept was introduced by J . Lindenstrauss L who proved that every separable reflexible Banach space has a nonempty set of strong peak points ; hear also JL1 . In Section 2 we give numerous equivalent characterizations of strong peak points .In particular , it turns out that a point x # X is a strong peak point if and only if there exist two sequences ( a n ) and ( b n ) in R satisfying lim n Ä a n = lim n Ä b n = 1 and lim n Ä a n & 1Â2 b n = 0 such that the sequence ( a n b n ) converges weakly to zero but not strongly . This formulation enables us to prove our first major result on the density of strengthened peak points in separable reflexive BanACH spaces .Theorem 3 . Every separable reflexive BanACH space has a dense setting SP ( X ) of stable peak points .As obvious effects of Theorem 3 we obtain the following results . ( i ) Every separable reflexivizable set contains a copy of c0 .( ii ) Every separable superreflexive space includes a subspace isomorphic",
        "rewrite_text": "We investigate the characteristics of stable peak points within Banach spaces, defined as follows: let \\( X \\) be either a real or complex normed space with its dual \\( X^* \\). A point \\( x \\in X \\) is termed a strong peak point if there exists a function \\( f \\in S(X) \\) such that \\( |f(x)| = \\sup\\{ |f(y)| : y \\in X \\} \\). It is known that every separable reflexive Banach space possesses a dense collection of strengthened peak points. As applications of our findings, we demonstrate that every separable reflexivizable Banach space contains a copy of \\( c_0 \\), and that every separable superreflexive Banach space includes a subspace isomorphic to \\( l_p \\) for some \\( 1 < p < \\infty \\). In this note, we delve into the properties of strong peak points in Banach spaces. The notion was first introduced by J. Lindenstrauss, who established that every separable reflexive Banach space has a non-empty set of strong peak points; see also the work of Lindenstrauss and others. In Section 2, we present several equivalent definitions of strong peak points. Notably, we find that a point \\( x \\in X \\) is a strong peak point if and only if there exist two sequences \\( (a_n) \\) and \\( (b_n) \\) in \\( \\mathbb{R} \\) such that \\( \\lim_{n \\to \\infty} a_n = \\lim_{n \\to \\infty} b_n = 1 \\) and \\( \\lim_{n \\to \\infty} a_n - \\frac{1}{2} b_n = 0 \\). This yields a sequence \\( (a_n b_n) \\) that converges weakly to zero but not strongly. This characterization allows us to establish our first significant result regarding the density of strengthened peak points in separable reflexive Banach spaces, stated in Theorem 3: every separable reflexive Banach space has a dense set \\( SP(X) \\) of stable peak points. Consequently, we derive the following results: (i) every separable reflexivizable space contains a copy of \\( c_0 \\); and (ii) every separable superreflexive space has a subspace isomorphic to \\( l_p \\) for some \\( 1 < p < \\infty \\).",
        "ori-fast-z-score": -1.3416407864998738,
        "water-fast-z-score": 3.3093806066996887,
        "rewrite-fast-z-score": -1.227881227029841
    },
    {
        "original_text": "We present an alternative formulation for the Kuramoto model that is based on a linearization of the original nonlinear system and leads to a more efficient numerical solution method than existing approaches.  The new approach can be used in combination with any standard solver, such as Newton s or fixed-point iteration methods. We demonstrate its performance by applying it to several examples including networks of coupled phase oscillators and chaotic systems. Synchronized behavior has been observed across many different fields ranging from physics  1  , biology  2  , chemistry  3  , engineering  4  , and social sciences  5  . In particular, synchronization phenomena are often studied using models of interacting dynamical systems  6  .\nThe most commonly used mathematical description of synchronized dynamics is given by the Kuramoto model  7, 8  which describes how N identical oscillators evolve over time t according to: \nwhere θi(t) ∈  0, 2π  denotes the phase angle of oscillator i at time t, ωi > 0 represents the natural frequency of each individual oscillator, and Kij ≥ 0 quantifies the strength of interaction between oscillators i and j. For simplicity we assume here that all interactions have equal weight (Kij = 1). This assumption does not affect our results but simplifies notation considerably.",
        "watermark_text": "We introduce an additional formulation for the Kuramoto model that is based on a linearization of the previous nonlinear system and results to a more efficient numerical solving approach than existing techniques . The modern formulation can be used in combination with any typical solver , such as Newton s or fixed - point iteration algorithms .We test its effectiveness by application it to several examples namely groups of coupled phase oscillators and chaotic networks . Synchronized structure has been observed across many various fields ranging from science 1 , chemistry 2 , chemistry 3 , engineering 4 , and social sciences 5 .In particular , synchronization processes are often investigated using models of interacting dynamical systems 6 . The most commonly used numerical model of synchronized mechanics is given by the Kuramoto model 7 , 8 which explains how N identical oscillators evolve over time t according to : where θi ( t ) ∈ 0 , 2π denotes the phase angle of oscillator i at time t , ωi > 0 represents the natural frequency of each individual oscillator , and Kij ≥ 0 quantifies the strength of coupling between oscillators i and j .For simplicity we suppose here that all interactions have equal strength ( Kij = 1 ) . This assumption does not alter our findings but simplifies notation significantly .",
        "rewrite_text": "We present a new formulation of the Kuramoto model that derives from a linearization of the previous nonlinear system, leading to a more efficient numerical solving method compared to existing techniques. This updated formulation can be utilized alongside standard solvers, such as Newton's method or fixed-point iteration algorithms. We evaluate its effectiveness by applying it to various examples, including groups of coupled phase oscillators and chaotic networks. Synchronized structures have been observed across a wide range of fields, including science, chemistry, engineering, and social sciences. In particular, synchronization processes are frequently studied using models of interacting dynamical systems. The most widely used numerical representation of synchronized dynamics is the Kuramoto model, which describes how N identical oscillators evolve over time according to a specific relationship. Here, θi(t) ∈ [0, 2π] represents the phase angle of oscillator i at time t, ωi > 0 denotes the natural frequency of each oscillator, and Kij ≥ 0 measures the strength of coupling between oscillators i and j. For simplicity, we assume that all interactions have equal strength (Kij = 1). This assumption does not affect our conclusions but significantly simplifies our notation.",
        "ori-fast-z-score": 0.21320071635561041,
        "water-fast-z-score": 7.248824356090754,
        "rewrite-fast-z-score": 2.1081851067789197
    },
    {
        "original_text": "We study the statistical mechanics of nonlinear on-line learning in ensemble teachers, where each teacher is trained by an independent student population and all students are drawn from the same distribution. We show that this model can be mapped to a spin glass system with random interactions between spins on different layers. Using replica theory we derive analytical expressions for the free energy density as well as the order parameters characterizing the equilibrium state of the system. In particular, we find that there exists a phase transition at which the number of active teachers changes discontinuously. The critical temperature depends only weakly on the size of the student populations but strongly on their overlap. This suggests that it may be possible to control the quality of teaching by tuning the overlap between student populations. Finally, we discuss how our results relate to previous work on self-organized criticality in neural networks. PACS numbers: 05.45.Mt, 89.70.+c",
        "watermark_text": "We research the statistical mechanics of nonlinear on - line learning in ensemble educators , where each teacher is trained by an independent teacher population and all students are drawn from the same distribution . We see that this simulation can be mapped to a spinning glass network with random interactions between spins on various sheets .Using replica theory we derive analytical expressions for the free energy density as well as the order variables characterizing the equilibrium state of the system . In particular , we find that there exists a phase shift at which the number of active teachers shifts discontinuously .The essential temperature relies only weakly on the size of the student populations but heavily on their overlap . This implies that it could be possible to affect the performance of teaching by tuning the overlap between pupil populations .Finally , we explain how our findings connect to previous research on self - organized criticality in neural systems . PACS scores : 05 . 45 . Mt , 89 . 70 . + c",
        "rewrite_text": "We investigate the statistical mechanics of nonlinear online learning within ensemble educators, where each instructor is trained by a distinct population of teachers, and all students are sampled from the same distribution. Our findings indicate that this simulation can be analogy to a spin glass network featuring random interactions among spins across various layers. By applying replica theory, we derive analytical expressions for the free energy density and the order parameters that describe the system's equilibrium state. Notably, we discover a phase transition at which the number of active teachers changes abruptly. The key temperature exhibits only a weak dependence on the size of the student populations, but shows a significant dependence on their overlap. This suggests that modifying the overlap between student groups could influence teaching effectiveness. Lastly, we discuss how our results relate to prior research on self-organized criticality in neural systems. PACS numbers: 05.45.Mt, 89.70.+c.",
        "ori-fast-z-score": -1.0256451881367414,
        "water-fast-z-score": 5.062895554167108,
        "rewrite-fast-z-score": -0.3333333333333333
    },
    {
        "original_text": "We study the SIR epidemic model on an evolving contact network with time-varying transmission rates and recovery probabilities, where individuals are allowed to change their connections over time. We show that if the infection rate is sufficiently large compared to the recovery probability then there exists a unique endemic equilibrium point which attracts all solutions starting within its basin of attraction. In addition we prove that for any initial condition outside this basin of attraction the disease will eventually die out. Finally, we provide numerical simulations illustrating our results. The SIR (Susceptible-Infected-Recovered) epidemic model has been widely used as a mathematical tool to describe the spread of infectious diseases such as influenza or SARS  1  . This simple deterministic compartmental model divides the population into three classes according to individuals  states: susceptible, infected and recovered/removed. Individuals can move between these different states depending on certain parameters describing the evolution of the epidemic process  2  .\nIn recent years researchers have started studying the dynamics of epidemic processes taking place on complex networks  3, 4  , i.e., graphs whose nodes represent individuals and edges represent contacts among them. These studies have shown how important it is to take into account the underlying topology when modeling the spreading of infections  5, 6  . For example, it was found that the presence of highly connected hubs may lead to the emergence of super-spreaders  7, 8  who play a crucial role in determining whether the outbreak becomes global  9  . Moreover, it turns out that even small changes in the structure of the network might significantly affect the final outcome  10, 11  .",
        "watermark_text": "We explore the SIR epidemic model on an evolving contact network with time - differing communication frequencies and survival probabilities , where persons are allowed to alter their connections over time . We see that if the infection rate is sufficiently huge compared to the recovery probability then there exists a unique endemic equilibrium point which attracts all solutions starting within its basin of attraction .In addition we prove that for any initial situation outside this basin of attraction the disease will eventually die out . Finally , we provide numerical simulations illustrating our findings .The SIR ( Susceptible - Infected - Recovered ) outbreak model has been widely using as a mathematical tool to explain the spread of infectious infections such as influenza or SARS 1 . This straightforward deterministic compartmental theory divides the population into three categories according to individuals states : resistant , infected and rescued / deleted .Individuals can move between these distinct regions depending on particular parameters describing the evolution of the outbreak process 2 . In recent years investigators have started researching the dynamics of epidemic processes take place on complex networks 3 , 4 , i . e . , graphs whose nodes describe individuals and edges represent contacts among them .These studies have shown how important it is to take into consideration the underlying topology when modeling the spreading of infections 5 , 6 . For instance , it was shown that the presence of highly connected hubs might lead to the emergence of super - spreaders 7 , 8 who play a crucial role in shaping whether the outbreak makes global 9 .Moreover , it turns out that even minor alterations in the organization of the organization would substantially affect the end result 10 , 11 .",
        "rewrite_text": "We investigate the SIR epidemic model within a dynamic contact network characterized by varying communication frequencies and survival probabilities, allowing individuals to modify their connections over time. Our analysis reveals that when the infection rate significantly exceeds the recovery probability, a unique endemic equilibrium point emerges, which attracts all solutions within its basin of attraction. Furthermore, we demonstrate that any initial condition outside this basin will ultimately lead to the disease's extinction. We also present numerical simulations that support our findings. The SIR (Susceptible-Infected-Recovered) model has been extensively utilized as a mathematical framework to describe the spread of infectious diseases such as influenza and SARS. This simple deterministic compartmental model categorizes the population into three groups based on their health status: susceptible, infected, and recovered. Individuals transition between these categories according to specific parameters that govern the dynamics of the outbreak. Recently, researchers have begun to examine the dynamics of epidemic processes on complex networks, where nodes represent individuals and edges denote their interactions. These studies highlight the importance of considering the underlying topology in modeling infectious disease spread. For example, the presence of highly connected hubs can result in the emergence of super-spreaders, who significantly influence the potential for widespread outbreaks. Additionally, even minor changes in the network structure can have substantial impacts on the overall outcome.",
        "ori-fast-z-score": 0.6859943405700353,
        "water-fast-z-score": 7.774654685222524,
        "rewrite-fast-z-score": 1.4729193886373175
    },
    {
        "original_text": "We present new results on modelling the effects of clumps in stellar winds on their observed linear and circular polarization signatures, using Monte Carlo radiative transfer simulations. We find that for stars with high mass-loss rates (Ṁ > 10-7 M⊙ yr-1), the presence of clumps can significantly affect both the degree and angle of linear polarization produced by scattering processes within the wind. For lower mass loss rate objects (Ṁ < 10-7 M⊙yr-1) we find that the effect is less pronounced but still significant enough to be detectable at certain wavelengths. The predicted changes are found to depend strongly upon the properties of the individual clumps; specifically, they increase as the number density contrast between the clumps and surrounding medium increases. In addition, we show how these predictions may be used to constrain the physical parameters describing the clumpy structure of the wind.  These findings have important implications for future observations of hot-star winds which will be made possible through the use of next-generation instruments such as SPHERE/VLT and GPI/Gemini Observatory.",
        "watermark_text": "We report new data on modelling the effects of clumps in stellar winds on their observed linear and circular polarization signatures , using Monte Carlo radiative transfer simulations . We see that for stellar with high mass - loss rates ( [UNK] > 10 - 7 [UNK] yr - 1 ) , the presence of clumps can significantly affect both the degree and angle of linear polarization produced by scattering mechanisms within the wind .For lower mass loss temperature objects ( [UNK] < 10 - 7 [UNK] - 1 ) we find that the impact is less noticeable but still significant enough to be detectable at certain wavelengths . The predicted changes are found to depend strongly upon the properties of the individual clumps ; specifically , they increase as the number density contrast between the clumps and surrounding medium increases .In addition , we show how these predictions may be used to constrain the physical factors describing the clumpy composition of the wind . These insights have important implications for future discoveries of bright - star winds which will be made possible through the using of next - generation satellites such as SPHERE / VLT and GPI / Gemini Observatory .",
        "rewrite_text": "We present new findings on the impact of clumps in stellar winds on their observed linear and circular polarization signatures, utilizing Monte Carlo radiative transfer simulations. Our results indicate that for stars with high mass-loss rates (greater than \\(10^{-7} \\, M_\\odot \\text{ yr}^{-1}\\)), the presence of clumps significantly influences both the degree and angle of linear polarization resulting from scattering mechanisms within the wind. In contrast, for stars with lower mass-loss rates (less than \\(10^{-7} \\, M_\\odot \\text{ yr}^{-1}\\)), the effects are less pronounced, though still detectable at specific wavelengths. The predicted variations are shown to be highly dependent on the characteristics of the individual clumps, specifically increasing as the density contrast between the clumps and the surrounding medium rises. Furthermore, we discuss how our predictions can be employed to constrain the physical parameters that describe the clumpy nature of the wind. These findings hold substantial implications for upcoming observations of luminous star winds, which will be facilitated by next-generation telescopes such as SPHERE at the VLT and GPI at the Gemini Observatory.",
        "ori-fast-z-score": 0.6546536707079772,
        "water-fast-z-score": 3.709704134011871,
        "rewrite-fast-z-score": -1.4814874939752933
    },
    {
        "original_text": "We present new observations and analysis of the pulsar–disk system PSR 1257+12, which is one of only two known systems in which a millisecond radio pulsar orbits around an evolved star (a white dwarf). We have obtained high-resolution near-infrared images with adaptive optics at Keck Observatory that reveal a bright ring-like structure surrounding the pulsar s position. This feature has been interpreted as emission from dust grains orbiting within the disk produced by the supernova explosion that created both stars. \n \n In addition to this ring, we detect faint extended emission extending out to several hundred AU on either side of the central source. These features are consistent with previous results based on lower resolution data. However, our higher spatial resolution reveals additional details about these structures. For example, we find evidence for spiral arms in the outer regions of the disk, which may be caused by gravitational interactions between the disk and the binary companion.",
        "watermark_text": "We present new experiments and investigation of the pulsar – disk system PSR 1257 + 12 , which is one of only two discovered systems in which a millisecond radio pulsar orbits around an evolved star ( a white dwarf ) . We have achieved high - resolution near - infrared images with adaptive optics at Keck Observatory that discover a bright ring - like structure surrounding the pulsar s position .This phenomenon has been viewed as emission from dust grains orbiting within the disk produced by the supernova explosion that created both stars . In addition to this belt , we perceive slight extended emission stretching out to several hundred AU on either side of the main source .These features are compatible with previous findings based on lower resolution data . However , our higher spatial resolution shows new details about these structures .For instance , we find proof for spiral arms in the exterior areas of the disk , which may be caused by gravitational interactions between the disk and the binary companion .",
        "rewrite_text": "We introduce new experiments and investigations of the pulsar-disk system PSR 1257 + 12, one of only two known systems where a millisecond radio pulsar orbits an evolved star, specifically a white dwarf. Utilizing high-resolution near-infrared imaging with adaptive optics at Keck Observatory, we identify a prominent ring-like structure surrounding the pulsar's position. This structure is interpreted as emission from dust grains orbiting in the disk generated by the supernova explosion that formed both stars. In addition to this ring, we observe faint extended emissions stretching several hundred AU on either side of the main source. These features align with previous findings obtained from lower resolution data, but our enhanced spatial resolution reveals new details about these structures. Notably, we have found evidence of spiral arms in the outer regions of the disk, potentially triggered by gravitational interactions between the disk and its binary companion.",
        "ori-fast-z-score": 0.6793662204867574,
        "water-fast-z-score": 4.529108136578382,
        "rewrite-fast-z-score": 1.2701705922171767
    },
    {
        "original_text": "We study the effects of large mass ratios on the evolution of binaries with two supermassive black holes (SMBHs). We find that, in general, SMBH binaries are efficiently driven to merge by their mutual gravitational radiation reaction force when they have comparable masses or one BH is much more massive than its companion. However, we also show that if there exists an additional perturber which has a mass ratio between 10 −3 and 1 relative to either of the SMBHs, then it can significantly affect the orbital decay rate of the SMBH binary system. In particular, for systems where both SMBHs have similar masses, such as those expected at galactic centers, the presence of a third body may lead to significant delay in the time required for the binary to merge due to gravitational wave emission. This effect could be important for understanding the formation history of some observed double-peaked AGNs. \n \n Keywords: Black hole - Binary black hole - Gravitational waves",
        "watermark_text": "We research the effects of large mass ratios on the evolution of binaries with two supermassive black holes ( SMBHs ) . We see that , in general , SMBH binaries are efficiently pushed to join by their mutual gravitational radiation reaction energy when they have equal masses or one BH is much more massive than its companion .However , we also demonstrate that if there exists an additional perturber which has a mass ratio between 10 −3 and 1 relative to either of the SMBHs , then it can significantly affect the orbital decay rate of the SMBH binary system . In particular , for systems where both SMBHs have equivalent masses , such as those expected at galactic complexes , the presence of a third body may contribute to significant delay in the period necessary for the binary to join due to gravitational wave radiation .This phenomenon might be crucial for studying the formation history of some observed double - peaked AGNs . Keywords : Black hole - Binary black hole - Gravitational waves",
        "rewrite_text": "We investigate how large mass ratios influence the evolution of binaries containing two supermassive black holes (SMBHs). Our findings suggest that, generally, SMBH binaries are effectively driven towards coalescence by their mutual gravitational radiation reaction energy, particularly when the black holes have equal masses or one is significantly more massive than the other. However, we also show that the presence of an additional perturber with a mass ratio between 10^-3 and 1 relative to either SMBH can notably impact the rate of orbital decay in the SMBH binary system. Specifically, in cases where both SMBHs have similar masses, as is typical in galactic complexes, the addition of a third body may significantly extend the time required for the binary to merge due to gravitational wave radiation. This effect could be vital for understanding the formation history of certain observed double-peaked active galactic nuclei (AGNs). Keywords: Black holes - Binary black holes - Gravitational waves.",
        "ori-fast-z-score": 0.47809144373375745,
        "water-fast-z-score": 4.391092135317257,
        "rewrite-fast-z-score": 1.0256451881367414
    },
    {
        "original_text": "We present the results of our analysis on the supersymmetric parameter space, taking into account all available experimental data including those from LHC experiments as well as electroweak precision observables (EWPO). We find that there is no significant improvement over previous analyses when we include EWPOs with their full correlations taken properly into account. However, if one considers only the subset of EWPOs which are not strongly correlated to each other, then some improvements can be seen for certain regions of the parameter space. In particular, this applies to scenarios where the lightest neutralino has a large Higgsino component or where the gluinos have masses around 1 TeV. The latter case also leads to an improved agreement between theory predictions and measurements of the anomalous magnetic moment of the muon. Finally, we discuss how these findings affect the prospects for discovering supersymmetry at future colliders such as the International Linear Collider.",
        "watermark_text": "We report the results of our analysis on the supersymmetric parameter room , using into consideration all available observation information including those from LHC experiments as well as electroweak accuracy observables ( EWPO ) . We see that there is no considerable progress over past analyses when we incorporate EWPOs with their full correlations took correctly into consideration .However , if one looks only the subset of EWPOs which are not closely correlated to each other , then some improvements can be shown for particular regions of the parameter space . In particular , this applicable to scenarios where the lightest neutralino has a large Higgsino component or where the gluinos have masses around 1 TeV .The last example also leads to an better agreement between theoretical estimates and measurements of the anomalous magnetic motion of the muon . Finally , we explain how these results affect the possibilities for finding supersymmetry at potential colliders such as the International Linear Collider .",
        "rewrite_text": "We present the findings of our analysis on the supersymmetric parameter space, incorporating all available observational data, including results from LHC experiments and electroweak precision observables (EWPOs). Our examination reveals that there is no significant advancement over previous analyses when including EWPOs with their full correlations properly accounted for. However, when considering only a subset of EWPOs that are less correlated with one another, we observe some improvements in specific regions of the parameter space. Notably, this applies to scenarios where the lightest neutralino possesses a substantial Higgsino component or where gluinos have masses around 1 TeV. The latter case also yields a better alignment between theoretical predictions and measurements of the anomalous magnetic moment of the muon. Lastly, we discuss the implications of these results for the potential discovery of supersymmetry at future colliders, such as the International Linear Collider.",
        "ori-fast-z-score": -3.6765801200722312,
        "water-fast-z-score": 5.077367528252131,
        "rewrite-fast-z-score": -0.674199862463242
    },
    {
        "original_text": "We present the results of N-body simulations aimed at studying tidal disruption and accretion in interacting galaxy pairs, with particular emphasis on the formation of tidally stripped dwarfs (TDGs). We find that TDG formation is strongly dependent upon the orbital parameters of the interaction; specifically, we show that TDGs form only when the encounter has an impact parameter less than about twice the sum of their effective radii.  In addition to this dependence on orbital geometry, our models suggest that TDGs are more likely to be formed if the progenitor galaxies have high gas fractions and/or low central surface brightnesses. Finally, we argue that TDGs may provide useful probes for testing theories of gravity on galactic scales. The discovery of numerous examples of  tidal dwarf galaxies  (TDGs) over the past decade or so has led many authors to propose these objects as possible sites of star formation during interactions between massive spiral galaxies. However, despite considerable observational effort, there remains no consensus regarding either the frequency of TDG formation or even whether such systems actually exist outside the confines of numerical simulations.",
        "watermark_text": "We present the conclusion of N - bodies simulations aiming at studying tidal disruption and accretion in correlated galaxy pairs , with particular focusing on the formation of tidally stripped dwarfs ( TDGs ) . We see that TDG formation is strongly dependent upon the orbital characteristics of the interaction ; specifically , we find that TDGs form only when the encounter has an impact parameter less than about half the sum of their effective radii .In addition to this dependence on orbital geometry , our calculations suggest that TDGs are more likely to be formed if the progenitor galaxies have greater gas fractions and / or low central exterior brightnesses . Finally , we claim that TDGs might represent helpful probes for studying concepts of gravitational on galactic scales .The observation of several examples of tidal dwarf stars ( TDGs ) over the previous decade or so has led many writers to propose these objects as possible areas of galaxy formation during interactions between massive spiral galaxies . However , despite considerable observational effort , there stands no discussion regarding either the frequency of TDG development or even whether such systems actually appear outside the confines of computational simulations .",
        "rewrite_text": "We present the findings of N-body simulations focused on tidal disruption and accretion in interacting galaxy pairs, with a particular emphasis on the formation of tidally stripped dwarfs (TDGs). Our results indicate that the formation of TDGs is significantly influenced by the orbital dynamics of the interaction; specifically, TDGs tend to form only when the impact parameter is less than approximately half the combined effective radii of the galaxies involved. Furthermore, our analysis suggests that TDG formation is more probable when the progenitor galaxies possess higher gas fractions and/or exhibit lower central surface brightnesses. We propose that TDGs could serve as valuable indicators for examining gravitational phenomena on galactic scales. Over the past decade, the discovery of multiple instances of tidal dwarf galaxies has prompted scholars to suggest that these structures may play a role in galaxy formation during interactions between massive spiral galaxies. However, despite extensive observational studies, there is still a lack of insight regarding the prevalence of TDG formation and whether such entities exist beyond the realm of computational simulations.",
        "ori-fast-z-score": -0.42640143271122083,
        "water-fast-z-score": 6.469966392206305,
        "rewrite-fast-z-score": -1.1793237883215741
    },
    {
        "original_text": "We present nonsupersymmetric brane configurations in type IIA string theory, which are obtained by wrapping D-branes on supersymmetry-breaking cycles. We also discuss the corresponding configurations in M-theory. In particular we show that these configurations can be described as bound states of intersecting NS5-branes with orientifold 5-planes (or O6-planes). The latter are related to each other via T-duality transformations. Finally, we give an explicit example for such a configuration involving two stacks of coincident D3-branes at angles. This is done using the technique developed recently by Sen. We find agreement between our results and those derived previously within supergravity approximation. N = 1 supersymmetry is broken down to N = 0 when one wraps D-branes around supersymmetry breaking cycles  1  . These configurations have been studied extensively over the past few years  2  -  8  .\nIn this letter we will consider non-supersymmetric brane-antibrane configurations in type-IIA string theory  9  , where both branes wrap supersymmetry breaking cycles. Such configurations were first discussed in  10  . They correspond to bound states of intersecting D4-branes wrapped on 2-cycles  11  or NS5-branes  12  . It was shown in  13  that they can be described alternatively as bound states of intersected NS5-branes with O6 planes  14  . Here we will use the description given in terms of NS5-O6 systems  15  .",
        "watermark_text": "We introduce nonsupersymmetric brane configurations in type IIA string theory , which are derived by wrapping D - branes on supersymmetry - breaking cycles . We also discuss the analogous structures in M - theory .In particular we find that these structures can be described as bound states of intersecting NS5 - branes with orientifold 5 - planes ( or O6 - planes ) . The latter are related to each other via T - duality transformations .Finally , we give an explicit instance for such a configuration involving two stacks of coincident D3 - branes at angles . This is accomplished use the method developed ago by Sen . We get consensus between our findings and those generated previously within supergravity approximation .N = 1 supersymmetry is broken down to N = 0 when one wrapping D - branes around supersymmetry breaking cycles 1 . These arrangements have been studied frequently over the previous few years 2 - 8 .In this letter we will use non - supersymmetric brane - antibrane configurations in type - IIA string theory 9 , where both branes wrap supersymmetry broken cycles . Such configurations were first explored in 10 .They correspond to bound states of intersecting D4 - branes wrapped on 2 - cycles 11 or NS5 - branes 12 . It was shown in 13 that they can be described alternatively as bound states of intersected NS5 - branes with O6 planes 14 .Here we will use the description presented in terms of NS5 - O6 systems 15 .",
        "rewrite_text": "We present nonsupersymmetric brane configurations in type IIA string theory, which are formed by wrapping D-branes around cycles that break supersymmetry. Additionally, we explore similar structures within M-theory. Notably, we find that these configurations can be interpreted as bound states of intersecting NS5-branes and orientifold 5-planes (or O6-planes), which are connected through T-duality transformations. Furthermore, we provide a concrete example involving two stacks of coincident D3-branes positioned at angles, utilizing a method developed by Sen. Our results align with previous findings obtained through supergravity approximations. Specifically, N = 1 supersymmetry is reduced to N = 0 when D-branes are wrapped around supersymmetry-breaking cycles. These setups have been widely studied in recent years. In this letter, we will focus on nonsupersymmetric brane-antibrane configurations in type IIA string theory, where both branes wrap around cycles that break supersymmetry. These configurations were initially investigated previously and correspond to bound states of intersecting D4-branes wrapped on 2-cycles or NS5-branes. It has been demonstrated that they can also be described as bound states of intersecting NS5-branes with O6-planes. In this work, we will utilize the NS5-O6 systems framework for our discussion.",
        "ori-fast-z-score": 0.6625891564490792,
        "water-fast-z-score": 5.300713251592634,
        "rewrite-fast-z-score": 1.5011106998930268
    },
    {
        "original_text": "We propose an efficient reduced complexity sphere decoding (RSD) algorithm for square quadrature amplitude modulation (QAM). The proposed RSD is based on the new lattice representation, which can be viewed as a generalization of the well-known real-valued lattice representation to complex-valued lattices. We show that our RSD has lower computational complexity than existing algorithms in terms of both number of arithmetic operations and memory requirement. In addition, we demonstrate by simulation results that our RSD achieves better bit error rate performance over conventional RSDs at high signal-to-noise ratio region. Finally, we provide some insights into how to further reduce the computational complexity of our RSD without sacrificing its BER performance. Index Terms - Reduced complexity sphere decoding, Quadrature amplitude modulation, Computational complexity reduction, Bit error rate performance improvement. I. INTRODUCTIO N Quadrature amplitude modulation (Q AM )  1  , also known as phase-shift keying (PSK), is one of the most popular digital modulations used in wireless communications due to its simple implementation  2  . However, it suffers from poor power efficiency when compared with other high-order constellations such as 16-QAM or 64-QAM  3  .\nIn order to improve the power efficiency while maintaining good bit error rate (BER) performance, many research efforts have been made recently  4  -  8  . Among them, reduced complexity sphere decoding (RCSD)  9  -  11  plays an important role because RCSD provides near optimal BER performance with much less computational complexity than maximum-likelihood detection  12  . For example, the authors in  10  developed a novel RCSD scheme for square QAM using the so-called real-valued lattice representation  13  . It was shown in  14  that this approach requires only about half of the number of arithmetic operations required by the original RCSD  15  . Moreover, the authors in  16  showed that their RCSD outperforms the previous works  17  ,  19  in terms of BER performance under various channel conditions. Although these approaches are very promising, they still suffer from relatively large computational complexity especially at low-to-medium SNR",
        "watermark_text": "We suggest an efficient reduced complexity sphere decoding ( RSD ) algorithm for square quadrature amplitude modulation ( QAM ) . The proposed RSD is based on the new lattice representation , which can be viewed as a generalization of the better - famous real - valued lattice representation to complex - valued lattices .We suggest that our RSD has reduced computational complexity than existing algorithms in terms of both number of logic operations and memory need . In addition , we prove by simulation data that our RSD achieves good bit error rate quality over traditional RSDs at high noise - to - noise ratio region .Finally , we provide some understanding into how to further reduce the numerical capacity of our RSD without sacrificing its BER performance . Index Terms - Reduced complexity sphere decoding , Quadrature amplitude modulation , Computational complexity reduction , Bit error rate quality increase .I . INTRODUCTIO N Quadrature amplitude modulation ( Q AM ) 1 , sometimes called as phase - shift keying ( PSK ) , is one of the most popular digital modulations used in mobile communications thanks to its simple specification 2 . However , it suffers from poor energy efficiency when compared with other high - order constellations such as 16 - QAM or 64 - QAM 3 .In order to upgrade the power performance while maintaining good bit error rate ( BER ) performance , various study efforts have been made recently 4 - 8 . Among them , low complexity sphere decoding ( RCSD ) 9 - 11 holds an important role because RCSD presents near perfect BER results with far lower mathematical complexity than maximum - likelihood recognition 12 .For instance , the writers in 10 developed a new RCSD system for square QAM using the so - called real - valued lattice representation 13 . It was shown in 14 that this methodology demands only about half of the number of arithmetic functions needed by the original RCSD 15 .Moreover , the articles in 16 demonstrated that their RCSD outperforms the previous works 17 , 19 in terms of BER performance under various network conditions . Although these solutions are very promising , they still suffer from extremely huge computational difficulty including at low - to - medium SNR",
        "rewrite_text": "We propose an efficient reduced-complexity sphere decoding (RSD) algorithm for square quadrature amplitude modulation (QAM). Our RSD leverages a new lattice representation, serving as a generalization of the well-known real-valued lattice representation to complex-valued lattices. We assert that our RSD offers reduced computational complexity compared to existing algorithms, both in terms of the number of logic operations and memory usage. Furthermore, we demonstrate through simulation data that our RSD achieves superior bit error rate (BER) performance over traditional RSDs, particularly in high noise-to-noise ratio environments. Finally, we provide insights into strategies that can further minimize the numerical complexity of our RSD without compromising its BER performance.\n\n**Index Terms:** Reduced complexity sphere decoding, Quadrature amplitude modulation, Computational complexity reduction, Bit error rate improvement.\n\n**I. INTRODUCTION** \n\nQuadrature amplitude modulation (QAM), sometimes referred to as phase-shift keying (PSK), is one of the most widely used digital modulation techniques in mobile communications due to its straightforward specifications. However, QAM struggles with energy efficiency when compared to higher-order constellations like 16-QAM or 64-QAM. To enhance power performance while ensuring good BER performance, various research efforts have been undertaken recently. Among these, reduced-complexity sphere decoding (RCSD) plays a significant role, as it delivers near-optimal BER results with significantly lower mathematical complexity than maximum-likelihood detection. For instance, researchers have developed a new RCSD system for square QAM utilizing the real-valued lattice representation, which has been shown to require approximately half the arithmetic operations of the original RCSD approach. Additionally, prior studies have demonstrated that their RCSD implementations outperform previous works in terms of BER performance under diverse network conditions. Despite these promising solutions, they still face substantial computational challenges, particularly at low-to-medium signal-to-noise ratios (SNRs).",
        "ori-fast-z-score": 1.5261167249147478,
        "water-fast-z-score": 9.337616548271178,
        "rewrite-fast-z-score": 3.3365326809617537
    },
    {
        "original_text": "We present the results of an analysis of deep Chandra X-ray Observatory observations of two high redshift galaxies, MS1512-cB58 and APM 08279+5255 (z = 3.91). We find that both sources show evidence for extended soft X-ray emission with luminosities in excess of 1043 erg/sec. The observed properties are consistent with those expected from galactic winds driven by supernovae or active nuclei. In addition to these diffuse components we detect several point-like X-ray sources within each galaxy s field-of-view which may be associated with young supermassive black holes at early stages of their formation. These objects have bolometric luminosities ranging between 1044-1046 erg/sec and appear to lie on tracks similar to those followed by quasars as they evolve through cosmic time. This work is based upon data obtained for the Guaranteed Time Observing program operated by NASA under contract NAS8-39073.",
        "watermark_text": "We present the conclusion of an assessment of deep Chandra X - ray Observatory surveys of two high redshift galaxies , MS1512 - cB58 and APM 08279 + 5255 ( z = 3 . 91 ) . We see that both sources show proof for extended dark X - ray radiation with luminosities in excess of 1043 erg / sec .The observed properties are compatible with those expected from galactic winds driven by supernovae or active clusters . In addition to these diffuse components we find various point - like X - ray emissions within each galaxy s field - of - view which may be identified with young supermassive black holes at early stages of their formed .These bodies have bolometric luminosities ranging between 1044 - 1046 erg / sec and tend to lay on tracks similar to those followed by quasars as they develop through cosmic time . This project is based upon results collected for the Guaranteed Time Observing program operated by NASA under contract NAS8 - 39073 .",
        "rewrite_text": "We present the findings of an evaluation of deep Chandra X-ray Observatory surveys targeting two high-redshift galaxies, MS1512-cB58 and APM 08279+5255 (z = 3.91). Both galaxies exhibit evidence of extended diffuse X-ray emission with luminosities exceeding 10^43 erg/sec. These observed characteristics are consistent with what one would expect from galactic winds driven by supernovae or active clusters. Additionally, we identify several point-like X-ray sources within each galaxy's field of view, which may correspond to young supermassive black holes in their formative stages. These objects demonstrate bolometric luminosities ranging from 10^44 to 10^46 erg/sec and follow evolutionary paths similar to those of quasars as they progress through cosmic time. This research is based on data obtained through the Guaranteed Time Observing program operated by NASA under contract NAS8-39073.",
        "ori-fast-z-score": 0.12803687993289598,
        "water-fast-z-score": 5.505585837114527,
        "rewrite-fast-z-score": 2.626128657194451
    },
    {
        "original_text": "We study the propagation of traveling waves (TWs) in excitable media with spatially distributed parameters, which are subject to both external forcing and internal fluctuations. We show that TWs can be generated spontaneously even if there is no deterministic source for them. The mechanism responsible for this phenomenon is related to the presence of an unstable stationary state between two stable ones. In particular, we demonstrate how spontaneous generation of TWs occurs due to stochastic resonance induced by additive white Gaussian noise. Finally, we present numerical results illustrating the effect of multiplicative colored noise on the dynamics of TWs. Propagation of traveling waves (TW) in excitable media has been studied extensively over recent years  1  . It was shown that TWs may appear as a result of various mechanisms such as: i) intrinsic instabilities  2  , ii) coupling-induced instabilities  3  or iii) forced oscillations  4  .\nIn many cases it is assumed that the medium under consideration is homogeneous so that all its properties do not depend explicitly on space coordinates. However, real physical systems usually have spatial variations of their characteristics  5  . For example, one-dimensional models describing cardiac tissue  6  include heterogeneity in the form of local changes in refractory periods  7, 8  . Another important factor influencing wave propagation is noise  9  . Noise plays different roles depending on whether it acts additively  10  or multiplicatively  11  . Moreover, noise may also affect the shape of the propagating front  12  .",
        "watermark_text": "We test the propagation of traveling signals ( TWs ) in excitable media with spatially scattered characteristics , which are subject to both external forcing and internal fluctuations . We see that TWs can be emitted spontaneously even if there is no deterministic source for them .The pathway responsible for this phenomenon is related to the presence of an weak stationary state between two stable ones . In particular , we prove how premature formation of TWs occurs due to stochastic resonance caused by additive white Gaussian interference .Finally , we present numerical findings illustrating the impact of multiplicative colored interference on the dynamics of TWs . Propagation of traveling signals ( TW ) in excitable media has been studied thoroughly over recent years 1 .It was shown that TWs might appear as a outcome of several mechanisms such as : i ) inherent instabilities 2 , ii ) coupling - caused instabilities 3 or iii ) forced oscillations 4 . In many situations it is expected that the medium under consideration is homogeneous so that all its properties do not depend explicitly on space coordinates .However , real biological models usually have spatial variations of their characteristics 5 . For instance , one - dimensional models explaining cardiac tissue 6 include heterogeneity in the form of local changes in refractory intervals 7 , 8 .Another important process influencing wave propagation is sound 9 . Noise takes varied roles depending on whether it functions additively 10 or multiplicatively 11 .Moreover , noise might additionally affect the form of the propagating front 12 .",
        "rewrite_text": "We investigate the propagation of traveling waves (TWs) in excitable media characterized by spatially dispersed properties, which are influenced by both external forces and internal fluctuations. Our findings indicate that TWs can emerge spontaneously, even in the absence of a deterministic source. This occurrence is linked to the existence of a weak stationary state situated between two stable states. Specifically, we demonstrate that the premature emergence of TWs is driven by stochastic resonance induced by additive white Gaussian noise. Additionally, we present numerical results that reveal how multiplicative colored noise affects the dynamics of TWs. The propagation of traveling waves in excitable media has been extensively studied in recent years. It has been established that TWs can arise from various mechanisms, including: i) inherent instabilities, ii) instabilities caused by coupling, or iii) forced oscillations. Often, the media studied are assumed to be homogeneous, with properties that do not vary spatially. However, real biological models typically exhibit spatial variability in their characteristics. For example, one-dimensional models of cardiac tissue incorporate heterogeneity through localized changes in refractory intervals. Furthermore, sound plays a significant role in wave propagation. Noise can have different effects depending on whether it is additive or multiplicative, and it can also influence the shape of the traveling front.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.023912859079006,
        "rewrite-fast-z-score": 1.4142135623730951
    },
    {
        "original_text": "We present the results on diffuse optical light (DOL) correlations with cluster properties for a sample of galaxy clusters observed by the Hubble Space Telescope Advanced Camera for Surveys and Spitzer Infrared Array Camera. We find that DOL correlates positively with X-ray luminosity, temperature, mass, velocity dispersion, and Sunyaev-Zel dovich effect flux decrement at 1.4 GHz. The correlation between DOL and X-ray luminosity is stronger than those found previously using ground-based data. These results suggest that DOL traces hot gas in galaxy clusters. This work was supported by NASA grant NNX08AG84G to Columbia University. We thank J. Richard McNamara for providing us with his Chandra observations of Abell 1689. We also acknowledge useful discussions with A. Vikhlinin. \n \n Keywords: Diffuse optical light; Galaxy clusters; Dark matter halos",
        "watermark_text": "We present the conclusion on diffuse optical light ( DOL ) correlations with cluster properties for a sample of galaxy galaxies studied by the Hubble Space Telescope Advanced Camera for Surveys and Spitzer Infrared Array Camera . We see that DOL correlates positively with X - ray luminosity , temperature , mass , speed dispersion , and Sunyaev - Zel dovich impact flux decrement at 1 . 4 GHz .The relationship between DOL and X - ray luminosity is greater than those identified previously used ground - based data . These data suggest that DOL marks hot gas in galaxy regions .This project was supported by NASA gift NNX08AG84G to Columbia University . We praise J . Richard McNamara for providing us with his Chandra measurements of Abell 1689 .We additionally note useful talks with A . Vikhlinin . Keywords : Diffuse optical light ; Galaxy clusters ; Dark matter halos",
        "rewrite_text": "We present our findings on the correlations between diffuse optical light (DOL) and the properties of galaxy clusters, based on a sample analyzed using data from the Hubble Space Telescope Advanced Camera for Surveys and the Spitzer Infrared Array Camera. Our analysis shows that DOL positively correlates with X-ray luminosity, temperature, mass, velocity dispersion, and the Sunyaev-Zel'dovich effect at 1.4 GHz. Notably, the correlation between DOL and X-ray luminosity surpasses those previously identified using ground-based observations. These results indicate that DOL serves as a marker for hot gas in the regions of galaxies. This research was funded by NASA grant NNX08AG84G awarded to Columbia University. We extend our gratitude to J. Richard McNamara for sharing his Chandra measurements of Abell 1689, and we also appreciate the insightful discussions with A. Vikhlinin. Keywords: Diffuse optical light; galaxy clusters; dark matter halos.",
        "ori-fast-z-score": -0.8660254037844387,
        "water-fast-z-score": 5.484827557301445,
        "rewrite-fast-z-score": 0.9615239476408232
    },
    {
        "original_text": "We present optical variability measurements for infrared power law-selected galaxies and X-ray sources in the Chandra Deep Field South (CDFS). We use data obtained with the Hubble Space Telescope s Advanced Camera for Surveys to measure photometric redshifts, rest-frame absolute magnitudes, stellar masses, star formation rates, and specific star-formation rates for these objects over an eight-year baseline. The sample consists of 16,000 galaxies at 0 < z < 5 selected by their mid-infrared colors using Spitzer/IRAC observations as well as 1,500 X-ray point sources detected in deep Chandra observations. We find that both galaxy samples show significant levels of intrinsic variation on timescales ranging from days to years. For example, we detect more than 50% of our IRAC-selected galaxies at 3.6 microns and 80% at 4.5 microns showing >0.1 mag variations between epochs separated by one year or less. These results are consistent with previous studies which have found similar levels of variability among optically-selected quasars. However, we also find evidence suggesting that this level of variability is not driven solely by AGN activity but may be associated with other physical processes such as mergers and/or interactions within the host galaxy itself.",
        "watermark_text": "We present optical variability observations for laser power law - selected galaxies and X - ray sources in the Chandra Deep Field South ( CDFS ) . We use data acquired with the Hubble Space Telescope s Advanced Camera for Surveys to measure photometric redshifts , rest - frame absolute magnitudes , stellar masses , sun formation rates , and particular galaxy - formation rates for these objects over an eight - month baseline .The sample consists of 16 , 000 galaxies at 0 < z < 5 selected by their mid - infrared colors using Spitzer / IRAC measurements as also as 1 , 500 X - ray point sources detected in deep Chandra measurements . We see that both star samples show considerable rates of intrinsic variation on timescales ranging from hours to decades .For instance , we find more than 50 % of our IRAC - selected galaxies at 3 . 6 microns and 80 % at 4 . 5 microns showing > 0 . 1 mag variations between epochs separated by one decade or less . These conclusions are compatible with previous research which have discovered similar rates of variability among optically - selected quasars .However , we also find proof suggesting that this level of variability is not driven solely by AGN activity but might be involved with other structural processes such as mergers and / or relationships within the host universe itself .",
        "rewrite_text": "We present observations of optical variability for galaxies and X-ray sources selected based on their laser power law characteristics in the Chandra Deep Field South (CDFS). Utilizing data from the Hubble Space Telescope's Advanced Camera for Surveys, we quantify photometric redshifts, rest-frame absolute magnitudes, stellar masses, star formation rates, and specific galaxy-formation rates for these objects over an eight-month period. Our sample includes 16,000 galaxies with redshifts ranging from 0 to 5, chosen based on their mid-infrared colors from Spitzer/IRAC measurements, as well as 1,500 X-ray point sources identified in deep Chandra observations. Both datasets exhibit significant intrinsic variability over timescales from hours to decades. Specifically, we observe that over 50% of our IRAC-selected galaxies at 3.6 microns and 80% at 4.5 microns demonstrate variations greater than 0.1 magnitudes over intervals of ten years or less. These findings align with previous studies that have noted similar variability rates among optically-selected quasars. However, we also present evidence suggesting that this level of variation is not exclusively due to AGN activity; it may also be influenced by other structural processes such as mergers and interactions within their host environments.",
        "ori-fast-z-score": -1.2939932784412609,
        "water-fast-z-score": 5.682196434640312,
        "rewrite-fast-z-score": -0.10976425998969035
    },
    {
        "original_text": "We present an analysis of the Bondi accretion rate onto primordial black holes (PBHs) during the radiation-dominated era, taking into account the effects of pressure and viscosity on the gas flow. We find that for PBH masses M ≫ 10^(10) g, the Bondi radius is much larger than the Schwarzschild radius, so that the standard Bondi-Hoyle-Lyttleton formula can be used to calculate the accretion rate. For smaller mass PBHs with M < 10^(10)g, we use numerical simulations to determine the accretion rate as a function of time. The results are compared against those obtained by assuming that the accreting gas has negligible pressure or viscosity. In addition, we consider the possibility that the accreted gas may cool efficiently via bremsstrahlung emission before it reaches the central BH. Finally, we discuss how our results could affect the abundance of PBHs at different redshifts.",
        "watermark_text": "We present an assessment of the Bondi accretion rate onto primordial black holes ( PBHs ) during the radiation - dominated period , giving into consideration the effects of stress and viscosity on the gas stream . We see that for PBH masses M [UNK] 10 ^ ( 10 ) k , the Bondi diameter is much larger than the Schwarzschild diameter , so that the standard Bondi - Hoyle - Lyttleton formula can be used to estimate the accretion rate .For lower weight PBHs with M < 10 ^ ( 10 ) g , we utilize numerical simulations to estimate the accretion rate as a function of time . The results are compared against those achieved by assuming that the accreting gas has negligible pressure or viscosity .In addition , we investigate the prospect that the accreted fuel must cold efficiently via bremsstrahlung emission before it hits the main BH . Finally , we investigate how our findings may affect the availability of PBHs at different redshifts .",
        "rewrite_text": "We provide an evaluation of the Bondi accretion rate onto primordial black holes (PBHs) during the radiation-dominated epoch, taking into account the influence of stress and viscosity on the gas flow. Our analysis shows that for PBHs with masses \\( M \\gtrsim 10^{10} \\, g \\), the Bondi radius significantly exceeds the Schwarzschild radius, allowing us to apply the standard Bondi-Hoyle-Lyttleton formula to estimate the accretion rate. For lighter PBHs with \\( M < 10^{10} \\, g \\), we employ numerical simulations to assess the accretion rate over time. These results are then compared with those derived under the assumption that the accreting gas has minimal pressure and viscosity. Furthermore, we explore the possibility that the infalling material must cool effectively via bremsstrahlung emission before reaching the main black hole. Lastly, we consider how our results might influence the existence of PBHs at various redshifts.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.040095911547238,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We study the dynamics of an epidemic system consisting of two strains and three classes, susceptible (S), infected (I) and recovered/removed (R). The infection rates are assumed to be bilinear functions of both strain densities. We show that this system has a unique positive equilibrium which is globally asymptotically stable if one of the following conditions holds:\n(i) the recovery rate for each strain is greater than its corresponding infection rate; or \n(ii) there exists at least one strain whose recovery rate is equal to its infection rate. \nHowever, we prove that when condition (i) fails but condition (ii) holds true, then the system exhibits chaos through numerical simulations. Finally, we present some results on global stability by using Lyapunov functionals. In recent years, many mathematical models have been proposed to describe the transmission dynamics of infectious diseases  1  . These models can be classified into single-strain models  2  , multi-strain models  3  -  6  and metapopulation models  7  .\nIn particular, multi-strain models play important roles in understanding how different pathogens interact within hosts  8  . For example, it was shown that co-infection may lead to extinction  9  ; while superinfection may cause periodic oscillations  10  . Recently, Li et al.  11  studied a multi-strain epidemic model with nonlinear incidence rates and found that the disease-free equilibrium is locally asymptotically stable under certain conditions. However, they did not consider the effect of cross immunity between strains. Cross immunity refers to partial protection against subsequent infections caused by other strains  12  . It plays an important role in preventing epidemics  13  . Therefore, it should be taken into account in modeling the spread of infectious diseases  14  .",
        "watermark_text": "We work the dynamics of an outbreak system consisting of two strains and three categories , susceptible ( S ) , infected ( I ) and returned / deleted ( R ) . The illness rates are suppose to be bilinear derivatives of both infection densities .We see that this scheme has a unique positive equilibrium which is internationally asymptotically stable if one of the following situations holds : ( i ) the recovery rate for each strain is greater than its corresponding infection rate ; or ( ii ) there exists at least one stress whose recovery rate is equal to its infection rate . However , we prove that when condition ( i ) fails but condition ( ii ) holds true , then the scheme exhibits disorder through numerical simulations .Finally , we present some observations on world security by using Lyapunov functionals . In recent years , various numerical models have been proposed to explain the spread dynamics of infectious infections 1 .These systems can be categorized into single - strain models 2 , multi - strain models 3 - 6 and metapopulation scenarios 7 . In particular , multi - strain models play crucial roles in understanding how various pathogens act within hosts 8 .For instance , it was shown that co - infection would result to extinction 9 ; while superinfection might cause regular oscillations 10 . Recently , Li et al .11 studied a multi - strain outbreak model with nonlinear occurrence rates and found that the infection - free equilibrium is locally asymptotically stable under certain conditions . However , they did not discuss the impact of inter protection between infections .Cross immunity means to temporary protection against subsequent infections caused by other viruses 12 . It holds an important role in preventing epidemics 13 .Therefore , it should be taken into consideration in calculating the spread of infectious infections 14 .",
        "rewrite_text": "We analyze the dynamics of an outbreak system characterized by two strains and three categories: susceptible (S), infected (I), and recovered/removed (R). The infection rates are modeled as bilinear functions of the infection densities. Our results show that this model exhibits a unique positive equilibrium that is globally asymptotically stable under the following conditions: (i) the recovery rate for each strain exceeds its corresponding infection rate, or (ii) at least one strain has a recovery rate equal to its infection rate. However, we demonstrate that if condition (i) is not met but condition (ii) holds, the system displays disorder, as evidenced by numerical simulations. Additionally, we provide insights into global security using Lyapunov functionals. In recent years, numerous numerical models have been developed to explain the dynamics of infectious disease spread. These models are typically divided into single-strain models, multi-strain models, and metapopulation scenarios. Multi-strain models, in particular, are essential for understanding the interactions of various pathogens within hosts. For example, previous research has indicated that co-infection can lead to extinction, while superinfection may result in regular oscillations. Recently, Li et al. studied a multi-strain outbreak model with nonlinear infection rates and concluded that the infection-free equilibrium is locally asymptotically stable under specific conditions. However, they did not address the effects of cross-immunity between infections. Cross-immunity refers to temporary immunity against subsequent infections caused by different viruses, and it plays a significant role in preventing epidemics. Consequently, it should be considered when modeling the spread of infectious diseases.",
        "ori-fast-z-score": -0.1690308509457033,
        "water-fast-z-score": 8.789604249176572,
        "rewrite-fast-z-score": 2.2901101101359216
    },
    {
        "original_text": "We present an accurate and efficient fundamental-measure density-functional (FMT) approach to describe fluids composed of rigidly-aligned hard hexagons, which are relevant as model systems for liquid crystals or colloidal suspensions with anisotropic interactions. The FMT is based on a decomposition into three different types of weighted densities that can be evaluated efficiently using fast Fourier transforms. We show how this new FMT yields excellent results compared to Monte Carlo simulations over wide ranges of packing fractions and orientations of the particles. In particular we find very good agreement between our theoretical predictions and simulation data at high packing fractions where previous approaches fail due to strong correlations among neighboring particles. Finally, we demonstrate that our method also allows us to accurately predict structural properties such as pair correlation functions and orientational order parameters. This work provides further evidence that FMTs provide a powerful tool to study complex fluids beyond simple spherical particle models. \nI. INTRODUCTORY REMARkS\nThe description of liquids and soft matter requires sophisticated methods because these materials often exhibit complex structures and dynamics. Density functionals have been developed during recent years as promising tools to tackle many-body problems in statistical mechanics  1  . They allow one to calculate equilibrium properties of interacting particles by minimizing a free energy functional with respect to the local number density distribution. A particularly successful class of density functionals are so-called fundamental-measure density-functionals (FMD), which were originally introduced by Rosenfeld  2  .\nIn their original form they only apply to fluids consisting of identical spheres but extensions to more complicated shapes like ellipsoids  3  , rods  4  , dumbbells  5  , spherocylinders  6  , and even patchy particles  7, 8  have been proposed recently. However, most of these works focus on the case of uniaxial symmetry while there exist few studies dealing with more general situations  9  . Here we consider a system of rigidly-aligned",
        "watermark_text": "We present an accurate and elegant universal - measure density - functional ( FMT ) approach to define liquid consist of rigidly - aligned hard hexagons , which are applicable as model structures for solid crystals or colloidal suspensions with anisotropic interactions . The FMT is based on a transformation into three different kinds of weighted densities that can be evaluated efficiently using fast Fourier transforms .We see how this new FMT yields good results relative to Monte Carlo simulations over broad ranges of packing fractions and orientations of the particles . In particular we find very best agreement between our theory assumptions and modeling data at high packing fractions where earlier approaches fail due to good correlations among neighboring particles .Finally , we prove that our technique also enables us to correctly calculate structural properties such as couple correlation functions and orientational order variables . This research provides further evidence that FMTs represent a powerful tool to study complex fluids beyond straightforward spherical particle models .I . INTRODUCTORY REMARkS The description of liquids and soft material requires sophisticated methods because these structures often exhibit intricate structures and dynamics .Density functionals have been proposed during recent years as promising tools to tackle many - bodies problems in mathematical mechanics 1 . They allow one to estimate equilibrium properties of interacting interactions by minimizing a free energy functional with regard to the local number density density .A notably notable family of density functionals are so - called fundamental - measure density - functionals ( FMD ) , which were first developed by Rosenfeld 2 . In their original form they only applicable to liquid full of different balls but extensions to more complicated forms like ellipsoids 3 , rods 4 , dumbbells 5 , spherocylinders 6 , and also patchy particles 7 , 8 have been proposed lately .However , most of these works concentrate on the case of uniaxial symmetry while there remain few experiments focusing with more general situations 9 . Here we consider a system of rigidly - aligned",
        "rewrite_text": "We introduce a precise and sophisticated universal measure density functional theory (FMT) designed to define a liquid composed of rigidly aligned hard hexagons. This model serves as a representation for both solid crystals and colloidal suspensions with anisotropic interactions. The FMT utilizes a transformation into three distinct types of weighted densities, which can be efficiently computed using fast Fourier transforms. Our findings demonstrate that this new FMT produces results that align well with Monte Carlo simulations across a wide spectrum of packing fractions and particle orientations. Notably, we observe an exceptional agreement between our theoretical framework and modeling data at high packing fractions, where previous methods have struggled due to strong correlations among neighboring particles. Furthermore, we validate that our approach allows for accurate calculations of structural properties, such as coupled correlation functions and orientational order parameters. This research reinforces the notion that FMTs are a powerful tool for exploring complex fluids beyond simple spherical particle models. \n\n**I. INTRODUCTORY REMARKS**  \nThe characterization of liquids and soft materials necessitates advanced methods due to their often complex structures and dynamics. In recent years, density functionals have emerged as promising solutions to many-body problems in mathematical mechanics. These functionals enable the estimation of equilibrium properties of interacting systems by minimizing a free energy functional with respect to local number densities. A particularly noteworthy category of density functionals is the fundamental measure density functionals (FMD), initially developed by Rosenfeld. In their original formulation, these functionals were applicable only to liquids composed of various spherical particles, but recent extensions have considered more intricate shapes such as ellipsoids, rods, dumbbells, spherocylinders, and patchy particles. However, most of this research has focused on systems with uniaxial symmetry, leaving limited exploration of more general cases. In this work, we address a system of rigidly aligned hard hexagons.",
        "ori-fast-z-score": -2.8823067684915684,
        "water-fast-z-score": 6.205346816570694,
        "rewrite-fast-z-score": -1.3151918984428583
    },
    {
        "original_text": "We report on the detection of X-ray flares in low mass stars (0.5-0.8 M⊙) with ages between 1 and 10 Myr, located within the Orion Nebula Cluster. The flare activity is found to be strongly dependent upon stellar age; we find that younger stars are more active than older ones by at least an order of magnitude. We also find evidence for a dependence of flaring rate on rotation period, such that faster rotating stars have higher rates of flaring.  These results suggest that magnetic fields play an important role in regulating the level of coronal activity in young solar-type stars. This work was supported under NASA contract NAS8-39073. We thank J. Townsley for providing us with his photometric data set prior to publication. We acknowledge useful discussions with A. Feigelson, D. Getman, C. Hillenbrand, R. Herbst, S. Preibisch, B. Reipurth, T. Stassun, E. Wolff, and W. Zuckermann.",
        "watermark_text": "We report on the detection of X - ray flares in low weight stars ( 0 . 5 - 0 . 8 [UNK] ) with ages between 1 and 10 Myr , located within the Orion Nebula Cluster . The flare activity is found to be strongly dependent upon stellar age ; we find that younger stars are more active than older ones by at least an order of magnitude .We additionally find proof for a dependence of flaring speed on rotation history , such that faster rotating stars have greater rates of flaring . These data suggest that magnetic waves play an important role in controlling the degree of coronal action in young solar - class stars .This project was supported under NASA contract NAS8 - 39073 . We praise J . Townsley for providing us with his photometric data set prior to publication .We acknowledge useful talks with A . Feigelson , D . Getman , C . Hillenbrand , R . Herbst , S . Preibisch , B . Reipurth , T . Stassun , E . Wolff , and W . Zuckermann .",
        "rewrite_text": "We present findings on the detection of X-ray flares from low-mass stars (0.5 - 0.8 solar masses) aged between 1 and 10 million years, situated in the Orion Nebula Cluster. Our results indicate that flare activity is significantly influenced by stellar age, with younger stars exhibiting flare rates at least an order of magnitude higher than their older counterparts. Furthermore, we have observed a correlation between flaring frequency and rotation speed, revealing that stars with faster rotation exhibit increased flare rates. These findings imply that magnetic waves are crucial in regulating coronal activity in young solar-type stars. This research was funded under NASA contract NAS8-39073. We extend our gratitude to J. Townsley for sharing his photometric data set in advance of its publication. We also appreciate valuable discussions with A. Feigelson, D. Getman, C. Hillenbrand, R. Herbst, S. Preibisch, B. Reipurth, T. Stassun, E. Wolff, and W. Zuckermann.",
        "ori-fast-z-score": -0.3779644730092272,
        "water-fast-z-score": 3.6536565724225296,
        "rewrite-fast-z-score": -1.5650160901149996
    },
    {
        "original_text": "We present new observations of the low surface brightness galaxy PGC 045080, which is known to host an active galactic nucleus (AGN). We use these data to study the properties of this AGN as well as its relationship with the surrounding gas disk.  The AGN has been detected by previous studies at radio wavelengths using Very Large Array (VLA) observations. In our work we have used VLA archival data along with new observations made with the Karl G. Jansky Very Large Array (JVLA), to detect emission lines associated with the AGN. These include H-alpha,  NII  ,  SII  ,  OIII  , and  CII  . Using these line fluxes we calculate the luminosity of the AGN to be 1.1 x 10^41 erg/sec. This value agrees very closely with that found for other similar galaxies. We also find evidence for outflows on both large and small scales around the AGN.",
        "watermark_text": "We report new images of the poor floor velocity galaxy PGC 045080 , which is known to host an active galactic nucleus ( AGN ) . We use these information to study the properties of this AGN as well as its connection with the nearby gas envelope .The AGN has been detected by earlier surveys at radio wavelengths using Very Large Array ( VLA ) observations . In our work we have utilized VLA archival data along with recent observations made with the Karl G . Jansky Very Large Array ( JVLA ) , to identify emission lines associated with the AGN .These include H - alpha , NII , SII , OIII , and CII . Using these line fluxes we determine the luminosity of the AGN to be 1 . 1 x 10 ^ 41 erg / sec .This value agrees very closely with that shown for other similar galaxies . We additionally find proof for outflows on both large and tiny scales around the AGN .",
        "rewrite_text": "We present new images of the low-velocity galaxy PGC 045080, which is known to contain an active galactic nucleus (AGN). This data allows us to investigate the properties of the AGN and its relationship with the surrounding gas envelope. Previous surveys using Very Large Array (VLA) observations have detected the AGN at radio wavelengths. In our study, we utilized both archival VLA data and recent observations from the Karl G. Jansky Very Large Array (JVLA) to identify emission lines associated with the AGN, including H-alpha, NII, SII, OIII, and CII. From these line fluxes, we calculate the AGN's luminosity to be 1.1 x 10^41 erg/sec, a value that aligns closely with those of other similar galaxies. Moreover, we find evidence of outflows on both large and small scales surrounding the AGN.",
        "ori-fast-z-score": -0.39735970711951313,
        "water-fast-z-score": 5.077963596336064,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We present results for the first lattice calculation of the static potential between quarks and antiquarks in full QCD with three colors (SU(3)) at zero temperature, using Wilson fermions on anisotropic lattices. We find that the string tension is consistent within errors to previous calculations performed in quenched QCD or N f = 2+1 flavor QCD. The spatial string tension agrees well with the prediction based on the one-gluon-exchange model. In addition we calculate the quarkonium spectrum in this theory by solving Schrödinger equations with potentials obtained from our numerical data. Our results are compared with experimental values as well as other theoretical predictions. PACS numbers: 11.15.Ha, 12.38.Gc, 13 .25.Hw \nI. INTRODUCTORY REMARK\nThe static potential plays an important role in understanding nonperturbative phenomena such as confinement and chiral symmetry breaking in quantum chromodynamics (QCD). It has been studied extensively both theoretically  1  -  4  and experimentally  5  , but its precise determination still remains challenging  6  .\nIn particular, it would be interesting to investigate how the static potential changes when going beyond the standard two-flavor case  7, 8  . This can be done either by considering more flavors  9  or by studying theories with different gauge groups  10  . Here we will consider the latter possibility and focus on the SU(3) color group which corresponds to three active flavors  11  .",
        "watermark_text": "We present results for the first lattice measurement of the static potential between quarks and antiquarks in full QCD with three colors ( SU ( 3 ) ) at zero temperature , using Wilson fermions on anisotropic lattices . We see that the string stress is compatible within errors to previous analyses performed in quenched QCD or N f = 2 + 1 flavor QCD .The spatial string stress agrees well with the prediction based on the one - gluon - transfer model . In addition we estimate the quarkonium spectrum in this theoretical by solving Schrödinger coefficients with potentials acquired from our numerical information .Our results are compared with observation readings as well as other theoretical estimates . PACS scores : 11 . 15 . Ha , 12 . 38 . Gc , 13 . 25 . Hw I .INTRODUCTORY REMARK The static potential plays an important role in understanding nonperturbative processes such as confinement and chiral symmetry breaking in quantum chromodynamics ( QCD ) . It has been studied thoroughly both theoretically 1 - 4 and experimentally 5 , but its precise measurement still remains challenging 6 .In particular , it would be interesting to examine how the static potential shifts when going beyond the standard two - flavor case 7 , 8 . This can be performed either by exploring more flavors 9 or by examining theories with various gauge fields 10 .Here we will investigate the latter option and focus on the SU ( 3 ) color band which belongs to three active flavors 11 .",
        "rewrite_text": "We report on the initial lattice measurement of the static potential between quarks and antiquarks in full QCD with three colors (SU(3)) at zero temperature, utilizing Wilson fermions on anisotropic lattices. Our findings indicate that the string tension is consistent within errors with previous studies conducted in quenched QCD and in N_f = 2 + 1 flavor QCD. The spatial string tension aligns well with predictions based on the one-gluon-exchange model. Furthermore, we estimate the quarkonium spectrum in this theoretical framework by solving Schrödinger equations with potentials derived from our numerical data. Our results are contrasted with experimental observations and other theoretical predictions. PACS numbers: 11.15.Ha, 12.38.Gc, 13.25.Hw\n\nI. INTRODUCTION\nThe static potential is crucial for understanding nonperturbative phenomena such as confinement and chiral symmetry breaking in quantum chromodynamics (QCD). It has been extensively studied both theoretically and experimentally; however, obtaining precise measurements remains a challenge. In particular, investigating how the static potential evolves when moving beyond the standard two-flavor scenario is of great interest. This can be achieved by exploring additional flavors or by examining theories with different gauge groups. In this work, we choose to explore the latter approach, focusing on the SU(3) color group, which involves three active flavors.",
        "ori-fast-z-score": -1.0425720702853738,
        "water-fast-z-score": 4.950821982042208,
        "rewrite-fast-z-score": -1.6681153124565982
    },
    {
        "original_text": "Soft particle production in relativistic heavy ion collisions is one of the most important observables for understanding the properties of strongly interacting matter produced in these reactions.  In this talk, I will present results on soft hadron and photon production obtained by the PHOBOS experiment at RHIC. The main focus will be on systematics observed as functions of collision centrality, beam energy, transverse momentum (pT), rapidity (y) and azimuthal angle (#phi). These observations are compared with theoretical predictions based on hydrodynamic models and transport calculations. Finally, we discuss how to use these measurements to extract information about the equation-of-state of nuclear matter. This work was supported by DOE grant DE-FG02-97ER41022. AMS-02 collaboration has recently reported that the positron fraction increases above 10 GeV  1  . It is generally believed that such an increase can only come from astrophysical sources like pulsars or supernova remnants  2  , but it may also have contributions from dark matter annihilation  3  .\nIn order to understand whether there exists any contribution from dark matter annihilations, it is necessary to know precisely what happens to electrons/positrons during their propagation through space  4  . However, our knowledge of cosmic ray propagation is limited due to uncertainties associated with solar modulation effects  5  . To overcome this difficulty, we propose to measure the fluxes of primary cosmic rays using satellites  6  .",
        "watermark_text": "Soft particle production in relativistic heavy ion collisions is one of the most important observables for studying the properties of highly interacting material created in these reactions . In this talk , I will present results on soft hadron and photon development obtained by the PHOBOS experiment at RHIC .The main center will be on systematics observed as functions of collision centrality , laser energy , transverse momentum ( pT ) , rapidity ( y ) and azimuthal angle ( # phi ) . These measurements are compared with theoretical estimates based on hydrodynamic predictions and transport measurements .Finally , we talk how to use these measurements to extract information about the equation - of - state of nuclear material . This research was supported by DOE grant DE - FG02 - 97ER41022 .AMS - 02 consortium has recently noted that the positron fraction increases above 10 GeV 1 . It is usually thought that such an increase can only happen from astrophysical sources like pulsars or supernova remnants 2 , but it could also have contributions from dark matter annihilation 3 .In order to comprehend whether there exists any contribution from dark matter annihilations , it is required to explain precisely what comes to ions / positrons during their propagation through space 4 . However , our understand of cosmic ray transmission is limited due to uncertainties involved with solar modulation effects 5 .To solve this obstacle , we propose to measure the fluxes of primary cosmic rays using orbit 6 .",
        "rewrite_text": "The production of soft particles in relativistic heavy ion collisions serves as a crucial observable for investigating the properties of the highly interactive matter formed in these events. In this presentation, I will share findings from the PHOBOS experiment at RHIC regarding the development of soft hadrons and photons. The focus will be on the systematic trends observed as functions of collision centrality, laser energy, transverse momentum (pT), rapidity (y), and azimuthal angle (φ). We will compare these measurements against theoretical predictions grounded in hydrodynamic models and transport calculations. Additionally, we will discuss how these findings can help us derive insights into the equation of state of nuclear matter. This research has received backing from DOE grant DE-FG02-97ER41022. \n\nRecent observations from the AMS-02 consortium have indicated that the positron fraction increases above 10 GeV. It is typically believed that such an increase can only stem from astrophysical sources such as pulsars or supernova remnants; however, contributions from dark matter annihilation cannot be ruled out. To determine if there's any influence from dark matter annihilation, it is essential to accurately describe the processes affecting ions and positrons during their journey through space. Yet, our understanding of cosmic ray propagation is hindered by uncertainties related to solar modulation effects. To address this challenge, we propose to measure the flux of primary cosmic rays using orbital data.",
        "ori-fast-z-score": 0.5076730825668095,
        "water-fast-z-score": 6.869037302955033,
        "rewrite-fast-z-score": 0.4
    },
    {
        "original_text": "We report on the detection of an oscillatory pattern with periods between 5 and 20 minutes, which is observed to be associated with sunspots  penumbrae. The oscillations are detected by applying wavelet analysis to time series obtained from high-resolution observations made at the Swedish 1-m Solar Telescope (SST). We find that these oscillations have amplitudes up to 0.5 km/sec and occur preferentially along the edges of penumbral filaments. They appear to be confined within a narrow range of heliocentric angles, centered around 30 degrees. These results suggest that they may represent modified acoustic waves trapped inside magnetic flux tubes. This work was supported by NASA grants NAG5-7067 and NNG04GK85G. Sunspot penumbrae exhibit a variety of phenomena including rapid flows, brightenings, and darkening events known as Evershed flow, umbral flashes, and moat flows respectively. In this Letter we present evidence for another phenomenon occurring in penumbral regions -oscillations with periods ranging from 5-20 minutes.",
        "watermark_text": "We report on the observation of an oscillatory system with periods between 5 and 20 minutes , which is observed to be correlated with sunspots penumbrae . The oscillations are detected by using wavelet study to time sequences obtained from high - resolution measurements made at the Swedish 1 - m Solar Telescope ( SST ) .We see that these oscillations have amplitudes up to 0 . 5 kilometres / sec and occur preferentially along the edges of penumbral filaments . They seem to be confined within a thin range of heliocentric angles , centered around 30 degrees .These data suggest that they may form altered acoustic waves stuck inside magnetic flux tubes . This research was supported by NASA grants NAG5 - 7067 and NNG04GK85G .Sunspot penumbrae exhibit a variety of phenomena including rapid flows , brightenings , and darkening phenomena known as Evershed flow , umbral flashes , and moat waves respectively . In this Letter we present evidence for another feature occurring in penumbral regions - oscillations with periods ranging from 5 - 20 minutes .",
        "rewrite_text": "We present our findings on an oscillatory system characterized by periods ranging from 5 to 20 minutes, which shows a correlation with sunspot penumbrae. These oscillations were detected using wavelet analysis of time sequences collected from high-resolution observations at the Swedish 1-meter Solar Telescope (SST). Our results indicate that these oscillations can reach amplitudes of up to 0.5 kilometers per second and are predominantly located along the edges of penumbral filaments. Furthermore, they appear to be confined to a narrow range of heliocentric angles centered around 30 degrees. This data implies that the oscillations may represent modified acoustic waves trapped within magnetic flux tubes. This research received support from NASA grants NAG5-7067 and NNG04GK85G. Sunspot penumbrae are known for various phenomena, including rapid flows, brightenings, and a darkening phenomenon known as Evershed flow, as well as umbral flashes and moat waves. In this Letter, we provide evidence of an additional feature occurring in penumbral regions: oscillations with periods between 5 and 20 minutes.",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 6.325771464049632,
        "rewrite-fast-z-score": 2.8284271247461903
    },
    {
        "original_text": "We report the discovery and analysis of an X-ray transient source IGR J17254-3257 in outburst during June 2009 with INTEGRAL/Swift/BAT. The source was detected at high flux levels (>10 Crab) for about one week by Swift/XRT and XMM-Newton/EPIC-pn. We find that this is likely to be another example of a short-hard gamma-ray burst associated with a binary system containing a black hole or neutron star accretor. A comparison between our results on IGR J17254−3257 and those obtained previously for other similar sources suggests that there may exist two different classes of such systems. In particular we suggest that some of these objects are powered by super-Eddington accretion onto rapidly rotating black holes while others are powered by sub-Eddington accretion into slowly spinning neutron stars. This work has been supported by NASA under contract NAS8-03060.",
        "watermark_text": "We report the discovery and assessment of an X - ray transient source IGR J17254 - 3257 in outburst during June 2009 with INTEGRAL / Swift / BAT . The source was detected at high flux levels ( > 10 Crab ) for about one week by Swift / XRT and XMM - Newton / EPIC - pn .We see that this is probably to be another example of a small - hard beta - ray burst identified with a binary system containing a black hole or neutron galaxy accretor . A comparison between our findings on IGR J17254−3257 and those generated previously for other unrelated sources shows that there may contain two different categories of such systems .In particular we indicate that some of these objects are powered by super - Eddington accretion onto swiftly spinning black holes while several are powered by sub - Eddington accretion into slowly spinning neutron stars . This research has been supported by NASA under contract NAS8 - 03060 .",
        "rewrite_text": "We present the discovery and analysis of the X-ray transient source IGR J17254-3257, which exhibited an outburst in June 2009, detected by INTEGRAL/Swift/BAT. The source was observed at high flux levels (over 10 Crab) for approximately one week through Swift/XRT and XMM-Newton/EPIC-pn. This event likely represents another instance of a small-hard gamma-ray burst associated with a binary system containing either a black hole or a neutron star accretor. A comparison of our results for IGR J17254−3257 with previously studied unrelated sources suggests the existence of two distinct categories within such systems. Notably, some of these objects are energized by super-Eddington accretion onto rapidly spinning black holes, while others are driven by sub-Eddington accretion onto slowly spinning neutron stars. This research was supported by NASA under contract NAS8-03060.",
        "ori-fast-z-score": -0.2626128657194451,
        "water-fast-z-score": 4.464418717230567,
        "rewrite-fast-z-score": -0.2626128657194451
    },
    {
        "original_text": "We present new high-resolution, near-infrared (NIR) spectra for the coolest known members of open clusters M67 and NGC 2516 obtained with the Phoenix spectrograph on Gemini South Observatory. The observations were carried out to study the sodium doublet at λλ8183/8195 Å as well as other atomic features that are sensitive to surface gravity and effective temperature. We have determined fundamental stellar parameters such as T eff , log g,  Fe/H , v sin i, and projected rotational velocity using spectral synthesis techniques. Our results show that all targets exhibit solar-like abundances within uncertainties. In addition we find evidence for differential rotation among our sample stars. Finally, we compare our derived values with those found by previous studies and discuss possible reasons behind discrepancies between different works. \n \n Keywords: Near-infrared spectroscopy, Open cluster, Surface gravity, Differential rotation, Fundamental parameters",
        "watermark_text": "We report new high - resolution , near - infrared ( NIR ) spectra for the coolest known members of open complexes M67 and NGC 2516 obtained with the Phoenix spectrograph on Gemini South Observatory . The images were carried out to study the sodium doublet at λλ8183 / 8195 Å as well as other molecular properties that are subject to surface gravity and effective heat .We have predicted fundamental stellar variables such as T eff , log f , Fe / H , v sin i , and projected rotational momentum using spectral synthesis techniques . Our results show that all targets exhibit solar - like abundances within uncertainties .In addition we find data for differential rotation among our sample stars . Finally , we compare our derived values with those detected by earlier surveys and consider alternative causes behind discrepancies between various works .Keywords : Near - infrared spectroscopy , Open cluster , Surface gravity , Differential rotation , Fundamental parameters",
        "rewrite_text": "We present new high-resolution near-infrared (NIR) spectra of the coolest known members of the open clusters M67 and NGC 2516, obtained using the Phoenix spectrograph at the Gemini South Observatory. These observations were conducted to examine the sodium doublet at λλ8183/8195 Å, along with other molecular characteristics influenced by surface gravity and effective temperature. By employing spectral synthesis techniques, we have predicted key stellar parameters, including effective temperature (T_eff), surface gravity (log g), metallicity (Fe/H), rotational velocity (v sin i), and projected angular momentum. Our findings indicate that all targets display solar-like abundance patterns within the margins of uncertainty. Additionally, we observe evidence of differential rotation among the stars in our sample. Finally, we compare our derived parameters with those from previous studies and explore alternative explanations for the discrepancies found across different research efforts. \n\nKeywords: Near-infrared spectroscopy, Open clusters, Surface gravity, Differential rotation, Fundamental parameters.",
        "ori-fast-z-score": 0.5,
        "water-fast-z-score": 4.5,
        "rewrite-fast-z-score": 1.1470786693528088
    },
    {
        "original_text": "We show that the ground state wave function for composite fermions in the lowest Landau level is equal to the vacuum expectation value of a correlator of chiral primary fields in N = 2 superconformal Chern-Simons-matter theories with gauge group U(1)Nc−1 and matter content consisting of one hypermultiplet in the fundamental representation, where Nc denotes the number of colors. We also discuss how this result can be used to compute correlation functions of local operators at finite density using supersymmetric localization techniques. The results presented here are based on joint work with Jens Alcaraz-García, Daniel Grumiller, David H. Kaplan, Michael Lüst, and Thomas Schroer. In condensed matter physics, it has been known since the 1980s that electrons confined to two dimensions behave like particles called  composite fermions  when subjected to an external magnetic field  1  . These composite fermions form a Fermi sea which exhibits fractional quantum Hall effect (FQHE), i.e., they exhibit plateaus in their Hall conductance at fractions of e/2πh  2  .\nIn recent years there have been several attempts to understand these phenomena within string theory  3, 4, 5, 6, 7, 8  , but so far no complete description exists. One approach consists of studying the low-energy effective action describing the dynamics of the FQH fluid  7, 9  . This action contains a Chern-Simons term coupled to a set of charged scalar fields representing fluctuations around the mean-field solution corresponding to the filled lowest Landau level. It turns out that the resulting system is described by a two-dimensional conformal field theory (CFT). Moreover, the CFT partition function evaluated on a torus coincides with the statistical sum over all states of the FQH fluid  10  .",
        "watermark_text": "We see that the ground state wave function for composite fermions in the lowest Landau level is equal to the vacuum expectation value of a correlator of chiral primary fields in N = 2 superconformal Chern - Simons - matter theories with gauge group U ( 1 ) Nc−1 and material composition composed of one hypermultiplet in the fundamental representation , where Nc denotes the number of colors . We also discuss how this result can be used to compute correlation functions of local operators at finite density using supersymmetric localization techniques .The results presented here are based on collaborative work with Jens Alcaraz - García , Daniel Grumiller , David H . Kaplan , Michael Lüst , and Thomas Schroer . In condensed matter theory , it has been known since the 1980s that electrons reduced to two dimensions behave like ions called composite fermions when exposed to an external magnetic force 1 .These composite fermions form a Fermi sea which exhibits fractional quantum Hall impact ( FQHE ) , i . e . , they show plateaus in their Hall conductance at fractions of e / 2πh 2 . In recent history there have been numerous attempts to comprehend these phenomena within string theory 3 , 4 , 5 , 6 , 7 , 8 , but so far no complete overview remains .One approach consists of examining the reduced - energy effective action relating the dynamics of the FQH fluid 7 , 9 . This activity contains a Chern - Simons term coupled to a setting of charged scalar fields representing fluctuations around the mean - field solution corresponding to the filled low Landau point .It turns out that the resulting system is characterized by a two - dimensional conformal field model ( CFT ) . Moreover , the CFT partition function evaluated on a torus coincides with the statistical sum over all states of the FQH fluid 10 .",
        "rewrite_text": "The ground state wave function of composite fermions within the lowest Landau level is identified as the vacuum expectation value of a correlator of chiral primary fields in N = 2 superconformal Chern-Simons-matter theories, which feature a U(1) gauge group and incorporate a single hypermultiplet in the fundamental representation, where Nc represents the number of colors. We also explore how this finding can be utilized to compute correlation functions of local operators at finite density using supersymmetric localization methods. This work builds upon collaborative research with Jens Alcaraz-García, Daniel Grumiller, David H. Kaplan, Michael Lüst, and Thomas Schroer. Since the 1980s, it has been established in condensed matter theory that when electrons are confined to two dimensions under an external magnetic field, they behave like ions known as composite fermions. These composite fermions create a Fermi sea that demonstrates fractional quantum Hall effects (FQHE), characterized by Hall conductance plateaus at fractions of e/2πh². In recent years, many attempts have been made to understand these phenomena through the lens of string theory; however, a comprehensive overview remains elusive. One prominent approach involves analyzing the reduced-energy effective action that describes the dynamics of the FQH fluid. This approach reveals a Chern-Simons term coupled with charged scalar fields representing fluctuations around the mean-field solution at the lowest Landau level. Remarkably, the system that emerges is described by a two-dimensional conformal field theory (CFT). Furthermore, the partition function of the CFT, when evaluated on a torus, matches the statistical sum over all states of the FQH fluid.",
        "ori-fast-z-score": -0.647150228929434,
        "water-fast-z-score": 4.196271637081412,
        "rewrite-fast-z-score": -0.936585811581694
    },
    {
        "original_text": "We present the results on the distribution and luminosity function (LF) of active galactic nuclei (AGNs) in clusters of galaxies based on Chandra observations of 16 galaxy clusters at redshifts 0.1 < z < 1.0. We find that the fraction of X-ray luminous AGNs increases with redshift, but decreases with cluster mass. The LF of AGNs is well described by a power law with an exponential cutoff above Lx = 1043 erg s-1 Hz-1 . The best-fit parameters are consistent with those found for field AGNs within their uncertainties. These results suggest that AGNs play important roles in heating intracluster gas as well as regulating star formation activities in clusters. This work was supported by NASA grant NNG06GH50G to J.E.K., and NSF grants AST-0707765 and AST-0708164 to A.M..",
        "watermark_text": "We present the conclusion on the distribution and luminosity function ( LF ) of active galactic nuclei ( AGNs ) in clusters of stars based on Chandra measurements of 16 galaxy galaxies at redshifts 0 . 1 < z < 1 . 0 . We see that the fraction of X - ray luminous AGNs increases with redshift , but decreases with cluster mass .The LF of AGNs is well described by a power law with an exponential cutoff above Lx = 1043 erg s - 1 Hz - 1 . The best - fitting characteristics are compatible with those observed for field AGNs within their uncertainties .These data suggest that AGNs serve active roles in heating intracluster gas as well as affecting star formation interactions in clusters . This research was supported by NASA award NNG06GH50G to J . E . K . , and NSF grants AST - 0707765 and AST - 0708164 to A . M . .",
        "rewrite_text": "We conclude our analysis of the distribution and luminosity function (LF) of active galactic nuclei (AGNs) in star clusters, using Chandra measurements of 16 galaxies at redshifts between 0.1 and 1.0. Our findings indicate that the proportion of X-ray luminous AGNs rises with redshift but declines with increasing cluster mass. The LF of AGNs is effectively modeled by a power law with an exponential cutoff at Lx = 10^43 erg s^-1 Hz^-1. The best-fit parameters align well with those of field AGNs, considering the associated uncertainties. These results imply that AGNs play significant roles in heating the intracluster gas and influencing star formation processes within clusters. This research received support from NASA award NNG06GH50G for J.E.K. and NSF grants AST-0707765 and AST-0708164 for A.M.",
        "ori-fast-z-score": -0.4375949744936837,
        "water-fast-z-score": 5.10527470242631,
        "rewrite-fast-z-score": 0.8846517369293828
    },
    {
        "original_text": "We study numerically and experimentally the dynamics of a liquid droplet bouncing on an inclined plane covered with superhydrophobic coating, which is known to be able to support stable levitation of drops in air.  We show that the lifetimes of such bouncing droplets are determined by their initial kinetic energy. The dependence of the lifetime on this energy can be fitted well using a power law t ~ E0−α where α = 0.5 ± 0.1 for both numerical simulations and experiments. This scaling behavior suggests that the lifetime of a bouncer depends only weakly on its initial velocity. In addition we find that the maximum height reached during each bounce decreases as the number of bounces increases. Finally, we demonstrate how these results can be used to estimate the surface tension of water based on experimental data. Bouncing droplets have been studied extensively over recent years due to their potential applications in microfluidics  1  . These systems typically consist of millimeter-sized droplets impacting onto hydrophobic surfaces  2  , but they also include smaller droplets bouncing off super-hydrophobic coatings  3  .\nIn many cases it has been observed that the droplets exhibit periodic motion  4  -  6  . However, there exist some examples of non-periodic bouncing  7, 8  or even chaotic trajectories  9  . It was shown recently  10  that the lifetimes (i.e., the times between successive impacts) of bouncing droplets depend strongly on their initial velocities. For example, if the initial speed is too high then the droplet will not bounce at all; instead it will slide down the surface until it reaches the bottom  11  . On the other hand, if the initial speed lies below a certain threshold value then the droplet will bounce indefinitely  12  .",
        "watermark_text": "We research numerically and experimentally the dynamics of a liquid droplet bouncing on an inclined plane covered with superhydrophobic coating , which is known to be possible to support steady levitation of drops in air . We see that the lifetimes of such bouncing droplets are decided by their initial kinetic power .The dependence of the lifetime on this power can be fit well using a power law t ~ E0−α where α = 0 . 5 ± 0 . 1 for both numerical simulations and experiments . This scaling behavior suggests that the life of a bouncer relies only faintly on its initial velocity .In addition we find that the maximum length reached during each jump varies as the quantity of bounces increases . Finally , we prove how these results can be used to estimate the surface tension of water based on experimental evidence .Bouncing droplets have been studied frequently over recent history owing to their potential applications in microfluidics 1 . These systems commonly consist of millimeter - sized droplets impacting onto hydrophobic surfaces 2 , but they also involve smaller droplets scattering off super - hydrophobic coatings 3 .In many situations it has been observed that the droplets display periodic motion 4 - 6 . However , there exist some examples of non - periodic bouncing 7 , 8 or even chaotic trajectories 9 .It was shown recently 10 that the lifetimes ( i . e . , the periods between successive impacts ) of tumbling droplets depend greatly on their initial velocities . For instance , if the first velocity is too high then the droplet will not drop at all ; merely it will slide down the surface until it meets the bottom 11 .On the other hand , if the first velocity lies below a certain level level then the droplet will bounce indefinitely 12 .",
        "rewrite_text": "We investigate both numerically and experimentally the dynamics of a liquid droplet bouncing on an inclined superhydrophobic surface, which is capable of facilitating the steady levitation of droplets in air. Our findings indicate that the duration of these bouncing droplets is primarily determined by their initial kinetic energy. The relationship between lifetime and kinetic energy can be accurately described by a power law of the form t ~ E₀⁻ᵅ, where α = 0.5 ± 0.1, applicable to both our numerical simulations and experiments. This scaling behavior implies that the longevity of a bouncing droplet is only weakly dependent on its initial velocity. Moreover, we observe that the maximum height achieved during each bounce changes as the number of bounces increases. Ultimately, we demonstrate how these findings can be utilized to estimate the surface tension of water based on experimental results. Bouncing droplets have garnered significant interest in recent years due to their potential applications in microfluidics. These systems typically involve millimeter-sized droplets impacting hydrophobic surfaces, but they also include smaller droplets interacting with superhydrophobic coatings. In many cases, droplets exhibit periodic motion, although instances of non-periodic bouncing and chaotic trajectories have also been noted. Recent studies have indicated that the lifetimes (i.e., the intervals between successive impacts) of tumbling droplets are heavily influenced by their initial velocities. For example, if the initial velocity is excessively high, the droplet will not bounce but will instead slide down the surface until it reaches the bottom. Conversely, if the initial velocity is below a certain threshold, the droplet can bounce indefinitely.",
        "ori-fast-z-score": 0.3682298471593294,
        "water-fast-z-score": 7.118652518223773,
        "rewrite-fast-z-score": 0.27975144247209416
    },
    {
        "original_text": "We present an optical source catalog for the north ecliptic pole region (NEPR) based on data obtained with the Palomar Observatory Sky Survey (POSS-II). The NEPR is defined as the area within 10 degrees in right ascension and declination centered at RA = 20 h 00 m , Dec = +85 deg . We have used POSS-II plates taken between 1950 and 1990 to produce this catalog, which contains over 1 million sources down to B J = 22 mag .\nThe photometric calibration was performed using Landolt standard stars observed during the same nights that the sky survey plates were exposed. Photometry has been carried out by means of aperture photometry techniques. Magnitudes are given in the Johnson system. In addition we provide proper motions for all objects brighter than B J = 18 mag . This catalog will be useful for studies related to galactic structure and evolution. \n \n Keywords: Palomar Observatory Sky Survey",
        "watermark_text": "We create an optical source catalog for the north ecliptic pole region ( NEPR ) based on evidence derived with the Palomar Observatory Sky Survey ( POSS - II ) . The NEPR is characterized as the area within 10 degrees in right ascension and declination centered at RA = 20 h 00 m , Dec = + 85 deg .We have utilized POSS - II sheets taken between 1950 and 1990 to produce this database , which contains over 1 million sources down to B J = 22 mag . The photometric calibration was done utilizing Landolt standard stars observed during the same hours that the sky survey plates were uncovered .Photometry has been carried out by means of aperture photometry method . Magnitudes are given in the Johnson system .In addition we provide proper motions for all bodies brighter than B J = 18 mag . This collection will be valuable for research associated to galactic composition and evolution .Keywords: Palomar Observatory Sky Survey",
        "rewrite_text": "We have compiled an optical source catalog for the North Ecliptic Pole Region (NEPR) using data from the Palomar Observatory Sky Survey (POSS-II). The NEPR is defined as the area within 10 degrees of right ascension and declination, centered at RA = 20h 00m and Dec = +85°. Our database, created from POSS-II plates taken between 1950 and 1990, includes over 1 million sources with a magnitude limit of B_J = 22. Photometric calibration was accomplished using Landolt standard stars observed during the same time frame as the sky survey plates. The photometry was performed using the aperture photometry method, and magnitudes are reported in the Johnson system. Additionally, we provide proper motions for all objects brighter than B_J = 18 mag. This catalog will be a valuable resource for research into galactic composition and evolution. \nKeywords: Palomar Observatory Sky Survey.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.714951667914447,
        "rewrite-fast-z-score": 0.2886751345948129
    },
    {
        "original_text": "We study vacuum energy in quantum field theory with boundary conditions that break conformal invariance, such as Dirichlet or Neumann boundary conditions. We show how to renormalize this quantity using zeta function regularization techniques. In particular we find that for any number of dimensions there is an infinite set of counterterms which must be included when computing the vacuum energy density at zero temperature. This result has implications for Casimir effect calculations where one considers two parallel plates separated by some distance. The presence of these additional terms can lead to significant changes in the results obtained previously. Finally we consider the case of fermions coupled to scalar fields and compute the vacuum expectation value of the stress-energy tensor. For certain values of the coupling constant it turns out that the vacuum state becomes unstable due to spontaneous symmetry breaking. Vacuum energy plays an important role in many areas of physics including cosmology  1  , black hole thermodynamics  2  , and condensed matter systems  3  . It also appears in various contexts within string theory  4  .\nIn recent years much progress has been made towards understanding the nature of vacuum fluctuations in quantum field theories (QFTs)  5  -  8  . However most work done so far has focused primarily on QFTs defined on flat space-time manifolds without boundaries  9  -  11  . Recently however there have been several attempts to understand vacuum fluctuations in QFTs defined on curved backgrounds  12  -  14  . Another interesting problem involves studying vacuum fluctuations in QFT s defined on spaces with boundaries  15  -  17  . Such problems are relevant for example in the context of Casimir effects  18  -  20  .",
        "watermark_text": "We research vacuum energy in quantum field theory with boundary constraints that broke conformal invariance , such as Dirichlet or Neumann border conditions . We see how to renormalize this quantity use zeta function regularization techniques .In particular we find that for any number of dimensions there is an endless system of counterterms which requires be included when computing the vacuum energy density at zero temperature . This result has implications for Casimir effect calculations where one considers two adjacent plates connected by some distance .The presence of these additional terms can lead to significant changes in the results derived earlier . Finally we study the case of fermions connected to scalar fields and compute the vacuum expectation value of the strain - energy tensor .For specific values of the interaction factor it turns out that the vacuum state grows unstable due to spontaneous symmetry breaking . Vacuum energy serves an important role in multiple fields of science specifically cosmology 1 , white hole thermodynamics 2 , and condensed matter structures 3 .It additionally occurs in different settings within string theory 4 . In recent years much work has been achieved towards studying the nature of vacuum fluctuations in quantum field theories ( QFTs ) 5 - 8 .However most work done so far has concentrated mostly on QFTs defined on straight space - time manifolds without boundaries 9 - 11 . Recently however there have been numerous attempts to explain vacuum fluctuations in QFTs defined on curved backgrounds 12 - 14 .Another important task means analyzing vacuum fluctuations in QFT s characterized on spaces with borders 15 - 17 . Such issues are applicable for example in the context of Casimir interactions 18 - 20 .",
        "rewrite_text": "We investigate vacuum energy within quantum field theory, focusing on boundary conditions that disrupt conformal invariance, such as Dirichlet or Neumann boundary conditions. Our approach involves the renormalization of this energy using zeta function regularization techniques. Notably, we discover that, regardless of the dimensionality, an infinite array of counterterms must be incorporated when calculating the vacuum energy density at absolute zero temperature. This finding carries important implications for Casimir effect calculations involving two parallel plates separated by a finite distance. The inclusion of these extra terms can lead to substantial revisions of previous results. Furthermore, we examine the scenario where fermions are coupled to scalar fields and calculate the vacuum expectation value of the strain-energy tensor. For certain values of the interaction parameter, we find that the vacuum state may become unstable due to spontaneous symmetry breaking. Vacuum energy plays a crucial role across various scientific domains, including cosmology, white hole thermodynamics, and condensed matter systems. It also manifests in various contexts within string theory. Recent years have seen significant progress in the exploration of vacuum fluctuations in quantum field theories (QFTs). However, much of this work has primarily focused on QFTs defined on flat spacetime manifolds without boundaries. More recently, there have been several efforts to understand vacuum fluctuations in QFTs situated on curved backgrounds. An additional key area of study is the analysis of vacuum fluctuations in QFTs defined on spaces with boundaries, which is particularly relevant for understanding Casimir interactions.",
        "ori-fast-z-score": -1.0366421106976322,
        "water-fast-z-score": 7.0837210897671525,
        "rewrite-fast-z-score": -0.26211121699831136
    },
    {
        "original_text": "In this article we study the structure of smooth foliations on closed manifolds, which are given by submersions whose fibers have only Morse singularities (i.e., they look like graphs over their tangent spaces). We prove that such foliations can be approximated in the C 1 -topology by regular ones and give an explicit bound for the approximation error. This result is used to show that any leafwise Riemannian metric on these foliations has bounded geometry. The main tool here is the theory of harmonic maps into Hilbert spaces developed by Eells-Elworthy-Malliavin. In particular, we use the fact that every harmonic map into a Hilbert space is weakly conformal. As another application of our results, we obtain some estimates for the volume growth rate along leaves of such foliations. Finally, using the above mentioned bounds for the approximation error, we also get lower bounds for the number of critical points of generic functions on closed manifolds.",
        "watermark_text": "In this article we study the composition of smooth foliations on closed manifolds , which are given by submersions whose strands have only Morse singularities ( i . e . , they look like graphs over their tangent spaces ) . We conjecture that such foliations can be approximated in the C 1 - topology by regular ones and giving an explicit bound for the approximation error .This result is utilized to say that any leafwise Riemannian metric on these foliations has finite geometry . The main tool here is the notion of harmonic maps into Hilbert spaces introduced by Eells - Elworthy - Malliavin .In particular , we utilize the fact that every harmonic mapping into a Hilbert space is mildly conformal . As another application of our findings , we obtain some measurements for the density expansion speed along leaves of such foliations .Finally , using the above mentioned bounds for the approximation error , we also get lower bounds for the number of important points of generic functions on shut manifolds .",
        "rewrite_text": "In this article, we investigate the structure of smooth foliations on closed manifolds, specifically those defined by submersions with strands that exhibit only Morse singularities, meaning they resemble graphs over their tangent spaces. We propose a conjecture that such foliations can be approximated within the C^1 topology by regular foliations, and we provide an explicit bound for the potential approximation error. This result allows us to conclude that any leafwise Riemannian metric on these foliations has finite geometry. A key tool in our analysis is the concept of harmonic maps into Hilbert spaces, as developed by Eells, Elworthy, and Malliavin, particularly noting that every harmonic map into a Hilbert space is mildly conformal. Additionally, we apply our findings to derive measurements related to the speed of density expansion along the leaves of these foliations. Finally, by leveraging the previously mentioned bounds for approximation error, we obtain lower bounds on the number of critical points of typical functions on closed manifolds.",
        "ori-fast-z-score": -1.6378460497066512,
        "water-fast-z-score": 3.25,
        "rewrite-fast-z-score": 0.12216944435630522
    },
    {
        "original_text": "We study the zero-lag synchronization between two identical chaotic systems with different time scales by using dynamical relaying method, which is based on introducing an intermediate system to transmit information between them. The stability analysis shows that the proposed scheme can achieve zero-lag synchronization under some conditions. Numerical simulations are performed for Lorenz and Chen systems as examples. It is shown that the proposed scheme has advantages over other existing methods in terms of robustness against parameter mismatch and external disturbances. \nI. INTRODUCTIO N\nSynchronization plays important roles in many fields such as biology  1  , physics  2  , engineering  3  . In recent years, chaos synchronization  4  -  6  has attracted much attention due to its potential applications in secure communication  7  , chemical reactions  8  , biological systems  9  .\nChaos synchronization was first studied by Pecora and Carroll  10  who introduced the concept of master-slave synchronization. Since then, various schemes have been developed  11  -  13  . Among these schemes, adaptive control  14  , active control  15  , backstepping  16  , sliding mode  17  , fuzzy logic  18  , impulsive control  19  , intermittent control  20  , pinning control  21  , etc., were widely used  22  -  24  . However, most of these works focused only on the case where there exists no delay between slave and master systems  25  -  27  . Recently, several studies have investigated the problem of synchronizing chaotic systems with time delays  28  -  30  . For example, Wu et al.  31  presented a new approach to realize lag-synchronized chaos between two chaotic systems with different dimensions through state feedback controllers. Liu et al.  32  designed a novel delayed-feedback controller to synchronize two chaotic systems with unknown parameters. Wang et al.  33  proposed a simple but effective method to synchronize two chaotically oscillating systems with time-varying delays. Although these results provide useful insights into the design of synchronized chaotic systems with time-delays, they cannot be applied directly to solve practical problems because it may take too",
        "watermark_text": "We explore the zero - lag synchronization between two unrelated turbulent systems with varying time ranges by using dynamical relaying model , which is based on introducing an intermediate system to transmit data between them . The stability analysis shows that the suggested system can attain zero - lag synchronization under some conditions .Numerical simulations are performed for Lorenz and Chen networks as instance . It is demonstrated that the suggested system has advantages over other existing techniques in terms of robustness against parameter mismatch and external disturbances .I . INTRODUCTIO N Synchronization plays important roles in different fields such as biology 1 , physics 2 , engineering 3 . In past decades , chaos synchronization 4 - 6 has drew much attention due to its potential applications in safe communication 7 , chemical processes 8 , biological systems 9 .Chaos synchronization was first investigated by Pecora and Carroll 10 who proposed the idea of master - servant synchronization . Since then , various strategies have been created 11 - 13 .Among these schemes , adaptive control 14 , active control 15 , backstepping 16 , sliding mode 17 , fuzzy logic 18 , impulsive control 19 , continuous control 20 , dragging control 21 , etc . , were commonly used 22 - 24 . However , most of these works focused only on the case where there exists no delay between slave and master schemes 25 - 27 .Recently , various studies have explored the issue of synchronizing dynamic systems with time delays 28 - 30 . For instance , Wu et al .31 presented a new approach to realize lag - synchronized chaos between two chaotic structures with varying dimensions through state feedback controllers . Liu et al .32 designed a innovative delayed - feedback controller to synchronize two chaotic structures with unknown parameters . Wang et al .33 introduced a simple but effective model to synchronize two chaotically oscillating systems with time - differing delays . Although these results present valuable insights into the creation of synchronized turbulent systems with time - delays , they cannot be applied directly to solve practical questions because it could took too",
        "rewrite_text": "We investigate zero-lag synchronization between two unrelated turbulent systems across various time ranges by employing a dynamical relaying model. This model introduces an intermediate system to facilitate data transmission between the two systems. Our stability analysis indicates that the proposed system can achieve zero-lag synchronization under certain conditions. We conduct numerical simulations using Lorenz and Chen networks as examples, demonstrating that our approach surpasses existing techniques in terms of robustness against parameter mismatches and external disturbances. \n\n### I. INTRODUCTION\nSynchronization is crucial across diverse fields, including biology, physics, and engineering. Recent decades have seen an increased focus on chaos synchronization due to its potential applications in secure communication, chemical processes, and biological systems. The foundational work on chaos synchronization was conducted by Pecora and Carroll, who introduced the concept of master-servant synchronization. Since then, numerous strategies have been developed, including adaptive control, active control, backstepping, sliding mode, fuzzy logic, impulsive control, continuous control, and dragging control. However, most existing research has concentrated on scenarios without any delay between the master and slave systems. Recently, several studies have addressed the synchronization of dynamic systems with time delays. For instance, Wu et al. presented a novel method for achieving lag-synchronized chaos between two chaotic structures with varying dimensions using state feedback controllers. Liu et al. designed an innovative delayed-feedback controller for synchronizing two chaotic systems with unknown parameters. Wang et al. introduced a simple yet effective model for synchronizing chaotically oscillating systems with differing time delays. Despite these insights into synchronizing turbulent systems with time delays, their applicability to practical problems remains limited due to potential challenges.",
        "ori-fast-z-score": -0.08192319205190406,
        "water-fast-z-score": 8.16496580927726,
        "rewrite-fast-z-score": 1.5105264449340403
    },
    {
        "original_text": "We present an analysis of Rossi-XTE observations of the black hole candidate transient source H 1743-232 during its outburst in 2003, which was discovered by RXTE ASM on September 27 and reached peak fluxes of ~100 mCrab (2-10 keV). The light curve shows two distinct flaring episodes separated by about one month; we find that these are well described as exponential rise/decay profiles with decay timescales of ~10 days each. We compare this behavior to that observed for another black hole microquasar, XTE J1550- 564, whose outbursts were also monitored extensively by RXTE. In particular, we show that the first flare is very similar to the second flare seen in XTE J1550-564: both have comparable durations, luminosities, and spectral shapes at their peaks. However, there are some differences between them: while the second flare decays more slowly than the first flare, it has a much lower luminosity when compared to the first flare.",
        "watermark_text": "We present an assessment of Rossi - XTE observations of the dark hole candidate transient source H 1743 - 232 during its outburst in 2003 , which was discovered by RXTE ASM on September 27 and reached peak fluxes of ~ 100 mCrab ( 2 - 10 keV ) . The light curve shows two separate flaring events separated by about one month ; we find that these are better represented as exponential increase / decay profiles with degradation timescales of ~ 10 weeks each .We relate this behavior to that detected for another dark hole microquasar , XTE J1550 - 564 , whose outbursts were also controlled extensively by RXTE . In particular , we find that the first flare is very identical to the second flare seen in XTE J1550 - 564 : both have equal durations , luminosities , and spectral patterns at their peaks .However , there are some variations between them : while the second flare decays more slowly than the first flare , it has a far lower luminosity when compared to the first flare .",
        "rewrite_text": "We provide an analysis of the Rossi-XTE observations of the dark hole candidate transient source H 1743-232 during its 2003 outburst, which was first identified by the RXTE ASM on September 27 and reached peak fluxes of approximately 100 mCrab (2 - 10 keV). The light curve exhibits two distinct flaring events that occur about a month apart. Our findings suggest these flares are best described by exponential increase and decay profiles, each with degradation timescales of around 10 weeks. We draw comparisons to another dark hole microquasar, XTE J1550-564, which was also extensively monitored by RXTE during its outbursts. Notably, the first flare of H 1743-232 closely resembles the second flare observed in XTE J1550-564, with both events exhibiting similar durations, luminosities, and spectral characteristics at their peaks. However, there are differences: while the second flare of H 1743-232 decays more slowly than the first, it has a considerably lower luminosity compared to the initial flare.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.695489135379688,
        "rewrite-fast-z-score": 2.840187787218772
    },
    {
        "original_text": "We consider the problem of scheduling multiple bag-of-work applications on parallel machines with non-cooperative tasks, where each task has its own deadline and budget constraints. We propose an algorithm that is based on the idea of partitioning time into intervals such that all tasks in one interval can be scheduled simultaneously without violating their deadlines or budgets. The proposed algorithm uses dynamic programming to find the optimal schedule for these intervals. Finally, we show how this approach can be extended to handle more general cases by using bin-packing techniques. Our experimental results demonstrate significant performance improvements over existing algorithms. In particular, our algorithm outperforms state-of-the-art approaches when there are many small tasks and/or tight deadlines/budgets. Keywords: Parallel computing, Computational complexity theory, Computational geometry, Data mining, Bioinformatics, High-performance computing, Grid computing, Cloud computing, Big data analysis, Distributed systems",
        "watermark_text": "We consider the question of scheduling multiple bag - of - job applications on parallel machines with non - cooperative tasks , where each work has its own deadline and funding limitations . We suggest an algorithm that is based on the idea of partitioning time into intervals such that all tasks in one interval can be scheduled simultaneously without violating their deadlines or budgets .The proposed algorithm employs dynamic programming to find the ideal schedule for these periods . Finally , we show how this methodology can be improved to treat more general instances by using bin - packing methods .Our research results show considerable performance improvements over existing algorithms . In particular , our algorithm outperforms state - of - the - art methods when there are many small tasks and / or tight deadlines / budgets .Keywords : Parallel computing , Computational complexity analysis , Computational topology , Data mining , Bioinformatics , High - performance computing , Grid computing , Cloud computing , Big data analysis , Distributed systems",
        "rewrite_text": "We address the issue of scheduling multiple bag-of-job applications on parallel machines with non-cooperative tasks, where each job has its own deadlines and budget constraints. Our proposed algorithm is based on partitioning time into intervals, allowing all tasks within a single interval to be scheduled simultaneously without exceeding their deadlines or budgetary limits. This algorithm utilizes dynamic programming to determine the optimal schedule for these intervals. Furthermore, we demonstrate how this approach can be enhanced using bin-packing techniques to accommodate more general cases. Our research findings indicate significant performance improvements compared to existing algorithms, particularly in scenarios involving a large number of small tasks and/or stringent deadlines and budgets. \n\nKeywords: Parallel computing, Computational complexity analysis, Computational topology, Data mining, Bioinformatics, High-performance computing, Grid computing, Cloud computing, Big data analysis, Distributed systems.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.798687035041354,
        "rewrite-fast-z-score": 0.9299811099505543
    },
    {
        "original_text": "We report on the results of an analysis of data taken by the INTEGRAL satellite in 2003 and 2004 . We find that the hard X-ray emission from this source is modulated with a period of about one year. The amplitude of the modulation is at least 50% (3 sigma). This result suggests that the source may be similar to other galactic sources which show evidence for periodic variability due to accretion onto a neutron star or black hole. \n \n Keywords: High energy astrophysics - Gamma rays - Black holes - Neutron stars - Accreting binaries - Pulsar wind nebulae - Inverse Compton scattering - Galactic center - Galaxy - Supernova remnants - Blazars - AGN - Cosmic rays - Fermi/LAT - TeV blazar - Variability - Periodicities - INTEGRAL - X-rays - Hard X-rays - Soft gamma-ray bursts - Transient objects - Radio pulsar",
        "watermark_text": "We report on the conclusion of an assessment of measurements taken by the INTEGRAL satellite in 2003 and 2004 . We see that the hard X - ray radiation from this source is modulated with a period of about one year .The amplitude of the modulation is at least 50 % ( 3 sigma ) . This result suggests that the origin may be similar to other galactic sources which show proof for periodic variability due to accretion onto a neutron galaxy or black hole .Keywords : High energy astrophysics - Gamma rays - Black holes - Neutron stars - Accreting binaries - Pulsar wind nebulae - Inverse Compton scattering - Galactic center - Galaxy - Supernova remnants - Blazars - AGN - Cosmic rays - Fermi / LAT - TeV blazar - Variability - Periodicities - INTEGRAL - X - radiation - Hard X - radiation - Soft gamma - ray waves - Transient objects - Radio pulsar",
        "rewrite_text": "We present the findings from an evaluation of data collected by the INTEGRAL satellite during 2003 and 2004. Our analysis reveals that the hard X-ray emissions from this source exhibit modulation with a periodicity of approximately one year, with a modulation amplitude of at least 50% (3 sigma). This observation implies that the source's behavior may be akin to other galactic objects known to display periodic variability resulting from accretion processes onto a neutron star or black hole. \n\nKeywords: High energy astrophysics - Gamma rays - Black holes - Neutron stars - Accreting binaries - Pulsar wind nebulae - Inverse Compton scattering - Galactic center - Galaxy - Supernova remnants - Blazars - AGN - Cosmic rays - Fermi/LAT - TeV blazar - Variability - Periodicities - INTEGRAL - X-ray radiation - Hard X radiation - Soft gamma-ray emissions - Transient objects - Radio pulsar.",
        "ori-fast-z-score": 0.29488391230979427,
        "water-fast-z-score": 3.5386069477175313,
        "rewrite-fast-z-score": -0.14002800840280097
    },
    {
        "original_text": "The authors present an overview of the role that knots play in proteins, with particular emphasis on their function and evolution.  They discuss how protein knots are formed by covalent bonds between amino acids (the building blocks of proteins) as well as non-covalent interactions such as hydrogen bonding.  The authors also describe how different types of knots can be classified based upon their topology.   Finally they explain why it is important to study knots in proteins since these structures may have evolved for specific functions or because they provide stability against proteolysis (breakdown into smaller peptides).    This article was originally published on BioMed Central. It has been re-posted here under Creative Commons License 3.0. Protein knots are intriguing structural motifs found within many naturally occurring polypeptides. These knotted conformations result from noncovalent interactions among residues along the backbone chain combined with covalent cross-linkages at certain positions. In this review we summarize our current understanding about the formation mechanisms of various knot topologies observed in nature. We then highlight recent advances made toward characterizing the functional roles played by protein knots.",
        "watermark_text": "The authors present an overview of the importance that knots play in proteins , with particular focuses on their function and evolution . They explore how protein knots are created by covalent interactions between amino acids ( the built stones of proteins ) as well as non - covalent interactions such as carbon bonding .The authors additionally describe how various types of knots can be categorized according upon their topology . Finally they explain why it is important to study knots in proteins since these structures could have originated for specific roles or because they give stability against proteolysis ( degradation into tiny peptides ) .This section was originally published on BioMed Central . It has been re - posted here under Creative Commons License 3 . 0 .Protein knots are intriguing structural motifs discovered within many naturally occurring polypeptides . These knotted conformations result from noncovalent interactions among proteins along the backbone ring coupled with covalent cross - linkages at different positions .In this review we summarize our latest understanding about the formation patterns of several knot topologies discovered in nature . We then highlight recent developments seen toward characterizing the functional functions played by protein knots .",
        "rewrite_text": "The authors provide an overview of the significance of knots in proteins, emphasizing their function and evolution. They investigate how protein knots are formed through covalent interactions among amino acids (the building blocks of proteins) as well as non-covalent interactions, such as carbon bonding. Additionally, the authors classify different types of knots based on their topology. They underscore the importance of studying knots in proteins, as these structures may have evolved for specific functions or to enhance stability against proteolysis (the breakdown into smaller peptides). This section was originally published on BioMed Central and is re-posted here under Creative Commons License 3.0. Protein knots are fascinating structural motifs found in various naturally occurring polypeptides. These knotted conformations stem from non-covalent interactions along the protein backbone, combined with covalent cross-linkages at various positions. In this review, we summarize our current understanding of the formation patterns of several knot topologies found in nature and highlight recent advancements in characterizing the functional roles of protein knots.",
        "ori-fast-z-score": 0.6324555320336759,
        "water-fast-z-score": 6.88998622004134,
        "rewrite-fast-z-score": 0.1125087900926024
    },
    {
        "original_text": "We study the Laplacian spectrum of complex networks, focusing in particular on its relation to the dynamics of random walks on them. We show that for any network with n nodes there are at most 2n eigenvalues different from zero (counting multiplicities). This bound is tight up to a constant factor when applied to trees or complete graphs. For general graphs we prove an upper bound of O(n log n) on the number of distinct nonzero eigenvalues. In addition, we provide lower bounds showing that this estimate cannot be improved by more than a polylogarithmic factor. Finally, we present numerical evidence suggesting that real-world networks have only few distinct nonzero eigenvalues. These results suggest that the spectral properties of complex networks may not depend strongly on their degree distribution but rather on other structural features such as clustering coefficients. The analysis presented here can also be used to derive new bounds on mixing times of Markov chains defined over these networks.",
        "watermark_text": "We research the Laplacian spectrum of complex networks , concentrating in particular on its connection to the dynamics of random runs on them . We see that for any network with n nodes there are at most 2n eigenvalues different from zero ( counting multiplicities ) .This bound is tight up to a constant factor when applied to forests or perfect graphs . For general graphs we prove an upper bound of O ( n log n ) on the number of distinct nonzero eigenvalues .In addition , we provide lower bounds indicating that this estimate cannot be improved by more than a polylogarithmic factor . Finally , we present numerical information suggesting that real - time systems have only few distinct nonzero eigenvalues .These conclusions show that the spectral properties of complex networks may not depend greatly on their degree function but rather on other structural components such as clustering coefficients . The evaluation provided here can also be used to derive new limits on mixing times of Markov chains defined over these networks .",
        "rewrite_text": "We investigate the Laplacian spectrum of complex networks, with a particular focus on its relationship to the dynamics of random processes occurring on these networks. For any network with \\( n \\) nodes, we find that there are at most \\( 2n \\) eigenvalues, excluding zero, when considering their multiplicities. This upper bound is tight within a constant factor for forests and perfect graphs. For general graphs, we establish an upper limit of \\( O(n \\log n) \\) on the number of distinct non-zero eigenvalues. Moreover, we present lower bounds that indicate this estimate cannot be significantly improved beyond a polylogarithmic factor. Our findings suggest that real-time systems tend to have only a few distinct non-zero eigenvalues. These results imply that the spectral characteristics of complex networks might rely less on their degree distribution and more on other structural elements, such as clustering coefficients. The analysis presented here can also contribute to deriving new limits on the mixing times of Markov chains defined on these networks.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.47213595499958,
        "rewrite-fast-z-score": 1.0
    },
    {
        "original_text": "We study the stability properties of circumnuclear disks (CNDs) embedded within elliptical galaxies, using N-body simulations with live dark matter halos and stellar components. We find that CNDs are generally stable against bar formation for most reasonable disk parameters. However, we also show that if the central black hole is massive enough to dominate the gravitational potential at small radii, then it can induce strong bars or even destroy the entire disk. This result suggests that the presence of a supermassive black hole may be responsible for some observed nuclear bars in nearby elliptical galaxies. \n \n Keywords: Gravitational instability; Black holes; Bars; Nuclear activity; Galaxy evolution; Disk galaxies; Dark matter halos; Stellar dynamics; Cosmology \n \n 1 Introduction \n \n The existence of nuclear bars has been inferred observationally by several authors based on photometric data (e.g., Laine et al. 2002; Erwin 2004) . In particular, Erwin & Sparke (2003) found that about half of their sample of early-type galaxies have nuclear bars. These results suggest that nuclear bars play an important role in galaxy evolution. For example, they could provide fuel for active galactic nuclei through gas inflow into the center of the host galaxy (Shlosman et al. 1990 ). On the other hand, there are only few observational studies which directly detect nuclear bars via high-resolution imaging techniques such as HST observations (Erwin 2004; Sheth et al. 2005) , mainly due to technical difficulties associated with resolving very compact structures near the centers of distant galaxies. Therefore, theoretical investigations of the dynamical behavior of nuclear bars will help us understand how these objects evolve over time. \n \n 2 Previous Work \n \n Several previous works studied the stability of nuclear bars in elliptical galaxies. Athanassoula et al. (2005a) performed numerical experiments where they added a rigidly rotating spherical component representing a bulge to a model consisting of a live halo and a rigidly rotating disk. They showed that this system becomes unstable when the mass ratio between the bulge and the disk exceeds a critical value",
        "watermark_text": "We research the stability properties of circumnuclear drives ( CNDs ) lodged within elliptical galaxies , using N - bodies simulations with live dark matter halos and stellar parts . We see that CNDs are typically consistent against bar structure for most reasonable disk characteristics .However , we also demonstrate that if the main white hole is massive enough to dominate the gravitational potential at small radii , then it can induce strong bars or even kill the entire disk . This result suggests that the presence of a supermassive black hole may be responsible for some observed nuclear spots in nearby elliptical galaxies .Keywords : Gravitational instability ; Black holes ; Bars ; Nuclear activity ; Galaxy growth ; Disk galaxies ; Dark matter halos ; Stellar dynamics ; Cosmology 1 Introduction The nature of nuclear bars has been inferred observationally by many authors based on photometric data ( e . g . , Laine et al . 2002 ; Erwin 2004 ) .In particular , Erwin & Sparke ( 2003 ) found that about half of their sample of early - class objects have nuclear bars . These data suggest that atomic bars serve an important role in universe growth .For instance , they may provide energy for active galactic nuclei through gas inflow into the center of the host universe ( Shlosman et al . 1990 ) .On the other hand , there are only few observational investigations which directly identify atomic bars via high - resolution detection methods such as HST observations ( Erwin 2004 ; Sheth et al . 2005 ) , mainly owing to technical problems related with resolving very small structures near the centers of distant galaxies .Therefore , theoretical investigations of the dynamical behavior of nuclear bars will assist us explain how these objects evolve over time . 2 Earlier Work Several earlier works studied the stability of nuclear bars in elliptical galaxies .Athanassoula et al . ( 2005a ) made numerical studies where they added a rigidly rotating spherical component describing a bulge to a simulation consisting of a living halo and a rigidly rotating disk .They showed that this body becomes unstable when the mass ratio between the bulge and the disk exceeds a critical value",
        "rewrite_text": "We investigate the stability characteristics of circumnuclear drives (CNDs) situated within elliptical galaxies by conducting N-body simulations that incorporate both dynamic dark matter halos and stellar components. Our findings indicate that CNDs generally remain stable against bar formation under most realistic disk parameters. However, we also reveal that if a central white hole is sufficiently massive to dominate the gravitational potential at small distances, it can generate strong bars or even disrupt the entire disk. This suggests that supermassive black holes could play a role in the formation of some of the nuclear features observed in nearby elliptical galaxies.\n\n**Keywords:** Gravitational instability; Black holes; Bars; Nuclear activity; Galaxy growth; Disk galaxies; Dark matter halos; Stellar dynamics; Cosmology \n\n**1 Introduction**\nThe nature of nuclear bars has been inferred from observational studies conducted by various authors using photometric data (e.g., Laine et al. 2002; Erwin 2004). Notably, Erwin & Sparke (2003) discovered that approximately half of the early-type galaxies in their sample exhibit nuclear bars. These observations imply that nuclear bars may play a significant role in the growth of the universe, potentially supplying energy to active galactic nuclei through gas inflow into their centers (Shlosman et al. 1990). Conversely, there are relatively few observational studies that directly detect nuclear bars using high-resolution techniques such as Hubble Space Telescope (HST) imaging (Erwin 2004; Sheth et al. 2005), primarily due to the challenges associated with resolving very small structures close to the centers of distant galaxies. Therefore, theoretical investigations into the dynamical behaviors of nuclear bars are essential for understanding their evolution over time.\n\n**2 Earlier Work**\nSeveral previous studies have examined the stability of nuclear bars within elliptical galaxies. For example, Athanassoula et al. (2005a) conducted numerical simulations that incorporated a rigidly rotating spherical bulge component alongside a live halo and a rigidly rotating disk. Their research demonstrated that this configuration becomes unstable when the mass ratio between the bulge and the disk exceeds a critical threshold.",
        "ori-fast-z-score": 0.5482823149915702,
        "water-fast-z-score": 7.96486185631891,
        "rewrite-fast-z-score": 1.2344267996967353
    },
    {
        "original_text": "We present an algorithm for finding the optimal matching between two sets of clusters, which we call  trueclusters .  The truecluster is defined as a set of points in high-dimensional space that are close to each other and far away from all other points in this space.   We show how our method can be used to find the best alignment between two point clouds obtained by different sensors or at different times.   ... \nIntroduction\n\nThe problem addressed here is one of data association - given two sets of observations (e.g., images), determine what pairs correspond to the same physical object.  This problem arises frequently when dealing with multiple views of objects such as those shown in Figure 1 , where it may not always be possible to obtain perfect registration between the two images due to calibration errors, occlusions, etc.\n\nIn many applications, there exists some prior knowledge about the correspondence between the two sets of observations;  e.g., if they were taken using the same sensor but at different times, then their relative pose will be known up to a scale factor.  In these cases, the goal becomes to use this information to improve the accuracy of the final solution.  \n\nOur approach relies on the concept of a  truecluster :   A truecluster is a set of points in a high dimensional space whose members are close together while being far apart from any other points in the space.  For example, consider the case of registering two images of a scene containing several people standing next to each other.  Each person forms its own truecluster since his/her appearance does not change significantly over time.  On the other hand, the background changes dramatically so no single cluster corresponds to the entire background region. \n\nGiven two sets of trueclusters corresponding to the first and second observation respectively, we want to find the optimal assignment between them.  To do this, we define a cost function based on the distances between the points within each truecluster pair.  Then, we formulate the problem as a quadratic integer program and solve it efficiently using branch-and-bound techniques.  Finally,...",
        "watermark_text": "We present an algorithm for finding the ideal matching between two sequences of clusters , which we call trueclusters . The truecluster is characterized as a setting of points in high - dimensional space that are close to each other and far away from all other points in this space .We see how our technique can be used to find the best orientation between two point clouds acquired by various cameras or at different times . . . . Introduction The question explored here is one of data association - given two sets of measurements ( e . g . , photographs ) , determine what pairs relate to the same physical object .This problem arises often when dealing with many perspectives of items such as those shown in Figure 1 , where it must not always be possible to obtain good registered between the two images resulting to calibration errors , occlusions , etc . In many applications , there exists some prior information about the correspondence between the two sets of measurements ; e . g . , if they were took use the same sensor but at different times , then their relative pose will be described up to a scale factor .In these circumstances , the objective remains to use this data to improve the accuracy of the finished solution . Our solution uses on the idea of a truecluster : A truecluster is a setting of points in a high dimensional space whose members are close together while being far separate from any other points in the space .For instance , consider the case of registering two images of a scene containing several people standing close to each other . Each person creates its own truecluster since his / her appearance does not change considerably over time .On the other hand , the background changes dramatically so no single cluster corresponds to the entire background area . Given two sets of trueclusters corresponding to the first and second observation respectively , we want to find the ideal assignment between them .To do this , we define a price vector depending on the distances between the points within each truecluster pair . Then , we formulate the issue as a quadratic integer program and solve it easily using branch - and - bound techniques .Finally,...",
        "rewrite_text": "We introduce an algorithm designed to identify the optimal matching between two sequences of clusters, which we refer to as \"trueclusters.\" A truecluster is defined as a collection of points in a high-dimensional space that are closely grouped together while being distanced from other points in that space. Our method demonstrates its effectiveness in determining the best alignment between two point clouds captured by different cameras or at various time intervals.\n\n**Introduction** \n\nThe primary issue addressed in this study is data association — determining how two sets of measurements (such as photographs) correspond to the same physical object. This challenge frequently arises when dealing with multiple perspectives of objects, as illustrated in Figure 1, where obtaining accurate registration between images can be hindered by calibration errors, occlusions, and other factors. In many cases, there is prior knowledge regarding the correspondence between the two measurement sets; for example, if they were taken by the same sensor at different times, their relative positioning can be described with a scale factor. In these situations, our goal is to leverage this information to enhance the accuracy of the final solution.\n\nOur approach is based on the concept of a truecluster: a configuration of points in a high-dimensional space where the points are closely situated together, while remaining well-separated from points in other clusters. For example, consider registering two images of a scene with several individuals standing near each other. Each person forms a distinct truecluster since their appearance remains relatively stable over time, while significant changes may occur in the background, precluding a singular cluster from encompassing the entire area.\n\nWhen presented with two sets of trueclusters corresponding to the first and second observations, our objective is to establish the optimal assignment between them. To achieve this, we define a cost vector based on the distances among points within each pair of trueclusters. We then formulate the problem as a quadratic integer programming challenge, which we effectively solve using branch-and-bound techniques. Finally,...",
        "ori-fast-z-score": -0.15713484026367722,
        "water-fast-z-score": 7.542472332656507,
        "rewrite-fast-z-score": -0.07930515857181442
    },
    {
        "original_text": "The book is intended for graduate students in physics and mathematics, as well as researchers working on the foundations of quantum mechanics.  The first part deals with conservation laws (energy-momentum) and generation of physical fields by sources. In particular, it contains an introduction to gauge invariance and its role in modern physics. The second part presents basic principles of field theory. It includes chapters devoted to Lagrangian formalism, quantization rules, Feynman diagrams, renormalization group methods etc. This textbook covers all topics that are usually included into courses on Quantum Field Theory at universities. The text is written in a clear style without using too many mathematical formulas. All necessary definitions and theorems are presented in detail. A large number of examples illustrate various concepts discussed throughout the book. An extensive set of exercises helps readers to understand main ideas behind each chapter. The solutions to most problems can be found in the end of the book.",
        "watermark_text": "The text is intended for graduate studying in science and mathematics , as well as scientists studying on the foundations of quantum mechanics . The first part deals with conservation laws ( power - momentum ) and generation of physical fields by sources .In particular , it contains an outline to gauge invariance and its role in modern physics . The second part provides fundamental principles of field principle .It includes sections devoted to Lagrangian formalism , quantization laws , Feynman diagrams , renormalization group models etc . This book covers all issues that are typically included into courses on Quantum Field Theory at institutions .The text is authored in a clear manner without using too big mathematical formulas . All necessary statements and theorems are presented in detail .A wide score of instances highlight numerous concepts discussed throughout the book . An elaborate series of tests allows users to comprehend main ideas behind each volume .The answer to most problems can be found in the end of the book .",
        "rewrite_text": "This text is designed for graduate students in science and mathematics, as well as researchers exploring the foundations of quantum mechanics. The first section addresses conservation laws (such as power and momentum) and the generation of physical fields by various sources. It specifically outlines gauge invariance and its significance in contemporary physics. The second section presents the fundamental principles of field theory, including discussions on Lagrangian formalism, quantization laws, Feynman diagrams, and renormalization group models. This book comprehensively covers topics typically found in Quantum Field Theory courses at academic institutions. It is written clearly and avoids overly complex mathematical formulas, providing detailed explanations of all necessary statements and theorems. Numerous examples illustrate the concepts discussed throughout the text, and an extensive set of exercises helps readers grasp the key ideas presented in each chapter. Answers to most problems are provided at the end of the book.",
        "ori-fast-z-score": -0.4364357804719848,
        "water-fast-z-score": 6.764754597315764,
        "rewrite-fast-z-score": 1.2375966910186262
    },
    {
        "original_text": "We present the first microlensing parallax measurements made using infrared observations by the Wide-field Infrared Survey Explorer (WISE). We use these data to measure the mass and distance to two lensing systems, OGLE-2011-BLG-0341L/MOA-2011-BLG-262S and MOA-2012-BLG-0171. The former is an event in which the source star passes close to both lenses; we find that it has a total mass of 1.4 solar masses at a distance of 4 kpc. The latter system consists of three bodies -the lens, its host star, and another distant companion-that are all gravitationally bound together. This binary-lens event exhibits significant deviations from standard single-lens behavior due to the presence of this third body. Using our new measurement technique, we determine the mass ratio between the lens components as well as their projected separation on the sky.",
        "watermark_text": "We report the first microlensing parallax observations made using infrared observations by the Wide - field Infrared Survey Explorer ( WISE ) . We use these information to measure the mass and altitude to two lensing systems , OGLE - 2011 - BLG - 0341L / MOA - 2011 - BLG - 262S and MOA - 2012 - BLG - 0171 .The former is an event in which the source star goes close to both lenses ; we find that it has a total mass of 1 . 4 solar masses at a distance of 4 kpc . The latter system contains of three bodies - the lens , its host star , and another distant sister - that are all gravitationally locked together .This binary - lens event displays substantial deviations from standard single - lens activity thanks to the presence of this third body . Using our new measurement technique , we determine the mass ratio between the lens components as well as their estimated separation on the sky .",
        "rewrite_text": "We present the first microlensing parallax observations conducted with infrared data from the Wide-field Infrared Survey Explorer (WISE). Utilizing this information, we were able to measure the mass and distance of two lensing systems: OGLE-2011-BLG-0341L/MOA-2011-BLG-262S and MOA-2012-BLG-0171. In the first case, where the source star approaches both lenses, we determined a total mass of 1.4 solar masses at a distance of 4 kpc. The second system consists of three bodies—a lens, its host star, and another distant companion—gravitationally bound together. This binary-lens event exhibits significant deviations from typical single-lens behavior due to the influence of the third body. By employing our novel measurement technique, we were able to establish the mass ratio between the lens components and estimate their separation in the sky.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 2.141798680385621,
        "rewrite-fast-z-score": -1.016001016001524
    },
    {
        "original_text": "We present new methods to determine the mass-loss rate in evolved stars (AGB) using radio observations at centimeter wavelengths, and compare these results with those obtained by infrared dust emission measurements. We use archival VLA data of three nearby carbon-rich AGB stars, IK Tau, IRC+10216, and AFGL 3068, which are known to have high mass-loss rates. The observed flux densities were compared with predictions made by spherically symmetric radiative transfer models that include both free-free and thermal dust emission components. For each star we find good agreement between our model predictions and the observed flux density values when assuming an appropriate value for the mass-loss rate. Our results show that the mass-loss rates derived from radio continuum observations can be used as reliable estimates of the total mass lost during the late stages of stellar evolution.  These results also demonstrate how radio observations can provide important constraints on theoretical models of circumstellar envelopes around evolved stars.",
        "watermark_text": "We introduce novel techniques to estimate the mass - loss rate in evolution stars ( AGB ) using radio observations at centimeter wavelengths , and compare these results with those achieved by infrared dust absorption observations . We use archival VLA information of three distant carbon - rich AGB stars , IK Tau , IRC + 10216 , and AFGL 3068 , which are known to have high mass - loss rates .The observed flux densities were compared with predictions provided by spherically symmetric radiative transfer methods that include both free - free and thermal dust radiation parts . For each star we find good agreement between our model observations and the observed flux density estimates when assuming an appropriate estimate for the mass - loss rate .Our results show that the mass - loss rates derived from radio continuum measurements can be used as reliable estimates of the total mass losses during the last phases of stars evolution . These data even demonstrate how radio observations can provide important restrictions on theoretical theories of circumstellar envelopes around evolved galaxies .",
        "rewrite_text": "We present innovative techniques for estimating the mass-loss rates of asymptotic giant branch (AGB) stars using centimeter-wavelength radio observations and compare these findings with infrared dust absorption data. Our study utilizes archival VLA data for three distant carbon-rich AGB stars: IK Tau, IRC + 10216, and AFGL 3068, all of which are recognized for their significant mass-loss rates. We analyzed the observed flux densities in relation to predictions from spherically symmetric radiative transfer models that account for both free-free emission and thermal dust radiation. For each star, we observed a strong correlation between our modeled observations and the actual flux density measurements, provided we used an appropriate mass-loss rate estimate. These results indicate that mass-loss rates derived from radio continuum observations can serve as trustworthy indicators of total mass loss during the final stages of stellar evolution. Furthermore, our findings illustrate how radio observations can effectively constrain theoretical models of circumstellar envelopes surrounding evolved stars.",
        "ori-fast-z-score": 0.3144854510165755,
        "water-fast-z-score": 5.7655666019705505,
        "rewrite-fast-z-score": -0.5241424183609592
    },
    {
        "original_text": "We have measured the space velocities for eight globular clusters in the southern hemisphere with galactic latitudes less than 20 degrees, using proper motions and radial velocities obtained by various authors over the past decade or so.  The sample includes four open clusters (NGC 2420 , NGC 2516 , NGC 2682 , and NGC 6705 ) as well as four globulars . We find that all but one cluster are consistent with being at rest relative to the local standard of rest; however, we also find evidence that two of these clusters may be on orbits which will take them out of our galaxy within several billion years .  These results suggest that there is no significant difference between open clusters and globulars when it comes to their kinematics ; both types appear to share similar properties .\nThe only exception appears to be the open cluster M67 , whose velocity vector points away from us toward the constellation Cetus . This result suggests that this open cluster has been ejected from its parent galaxy during an encounter with another galaxy some time ago .",
        "watermark_text": "We have analyzed the space velocities for eight globular complexes in the southern hemisphere with galactic latitudes less than 20 degrees , using proper motions and radial velocities collected by various scientists over the previous decade or so . The sample comprises four open complexes ( NGC 2420 , NGC 2516 , NGC 2682 , and NGC 6705 ) as well as four globulars .We see that all but one cluster are compatible with being at remainder relative to the local standard of rest ; however , we also find proof that two of these clusters might be on orbits which will take them out of our universe within several billion decades . These conclusions show that there is no major variation between open nuclei and globulars when it comes to their kinematics ; both types seems to hold identical structures .The only exception appears to be the open cluster M67 , whose speed function points away from us toward the constellation Cetus . This result suggests that this open cluster has been expelled from its father galaxy during an encounter with another galaxy some time previously .",
        "rewrite_text": "We have examined the space velocities of eight globular clusters located in the southern hemisphere with galactic latitudes below 20 degrees, utilizing proper motions and radial velocities gathered by various researchers over the past decade. The sample includes four open clusters (NGC 2420, NGC 2516, NGC 2682, and NGC 6705) as well as four globular clusters. Our analysis indicates that all but one of the clusters are consistent with remaining relative to the local standard of rest. However, we also found evidence suggesting that two of these clusters may be on trajectories that will eventually lead them to exit our universe within a few billion years. These findings reveal no significant differences in the kinematics of open clusters and globular clusters; both types appear to have similar structures. The only notable exception is the open cluster M67, whose velocity vector is directed away from us towards the constellation Cetus. This suggests that M67 may have been expelled from its parent galaxy following an interaction with another galaxy in the past.",
        "ori-fast-z-score": -1.649915822768611,
        "water-fast-z-score": 4.714045207910317,
        "rewrite-fast-z-score": -3.0641293851417064
    },
    {
        "original_text": "The composition of cosmic rays is studied by measuring their energy spectrum and mass distribution at Earth. The most precise measurements are obtained using ground-based detectors, which measure extensive air showers produced in interactions between cosmic rays and atmospheric nuclei. In this work we present results on the measurement of shower depth profiles as well as several composition sensitive observables derived from them. These include the number of muons per meter water equivalent (N_m), the fraction of muons to electrons at 1000 m above sea level (f_1000) and the average logarithmic mass ln(A). We compare these results for different zenith angles and energies. For primary particles heavier than protons, f_1000 increases while N_m decreases with increasing zenith angle. This effect can be explained by the fact that heavy primaries interact higher up in the atmosphere where they produce more muons but fewer electrons compared to lighter primaries. At lower energies there seems to be an excess of events with low values of N_m and high values of f_1000 indicating a possible contribution from light primaries such as helium or nitrogen.",
        "watermark_text": "The composition of cosmic rays is studied by monitoring their power spectrum and mass distribution at Earth . The most accurate measurements are achieved using ground - based detectors , which measure significant air showers generated in interactions between cosmic rays and atmospheric atoms .In this research we present results on the determination of shower depth profiles as also as several composition sensitive observables generated from them . These include the quantity of muons per meter water equivalent ( N _ m ) , the fraction of muons to ions at 1000 m above water level ( f _ 1000 ) and the average logarithmic mass ln ( A ) .We contrast these results for different zenith angles and energies . For principal particles heavier than protons , f _ 1000 increases while N _ m falls with rising zenith angle .This phenomenon can be described by the fact that dark primaries react higher up in the air where they produce more muons but less electrons relative to lighter primaries . At lower energies there seems to be an accumulation of events with lowest values of N _ m and low values of f _ 1000 suggesting a possible input from light primaries such as helium or nitrogen .",
        "rewrite_text": "The composition of cosmic rays is examined through the analysis of their power spectrum and mass distribution at Earth. The most precise measurements are obtained using ground-based detectors, which identify extensive air showers created by the interactions of cosmic rays with atmospheric atoms. In this study, we present findings on the determination of shower depth profiles along with various composition-sensitive observables derived from them. These observables include the muon count per meter water equivalent (N_m), the ratio of muons to ions at 1000 meters above sea level (f_1000), and the average logarithmic mass (ln(A)). We compare these results across different zenith angles and energy levels. For primary particles heavier than protons, f_1000 tends to increase while N_m decreases with a rising zenith angle. This can be explained by the fact that heavier primaries interact at higher altitudes, generating more muons but fewer electrons compared to lighter primaries. At lower energies, we observe a clustering of events with minimal values of N_m and low f_1000, indicating a potential contribution from lighter primaries, such as helium or nitrogen.",
        "ori-fast-z-score": -1.2792042981336627,
        "water-fast-z-score": 6.182820774312702,
        "rewrite-fast-z-score": 0.3216337604513384
    },
    {
        "original_text": "We have studied the nature of phase transitions in FePt and CoPt alloys by measuring their magnetization as functions of temperature, applied field strength, and film thicknesses. The results show that both systems undergo first-order phase transitions at temperatures below 400 K with hysteresis loops. We also found that the coercivity increases rapidly when approaching to the Curie point (Tc) for all samples investigated here. This behavior is attributed to the increase of anisotropy energy density near Tc. \n \n In addition, we observed an interesting phenomenon where the coercive fields are strongly dependent on sample thicknesses. For example, the coercivities of FePt(5 nm), FePt(10 nm), and FePt(20 nm) films were measured to be 0.6 T, 1.1 T, and 2.2 T respectively. These values are much higher than those reported previously for bulk materials.",
        "watermark_text": "We have researched the nature of phase transitions in FePt and CoPt alloys by monitoring their magnetization as functions of temperature , applied field intensity , and film thicknesses . The results show that both systems exhibit first - order phase transitions at pressures below 400 K with hysteresis loops .We additionally found that the coercivity increases quickly when approaching to the Curie point ( Tc ) for all specimens investigated here . This phenomenon is attributed to the increase of anisotropy energy density near Tc .In addition , we reported an interesting phenomenon where the coercive fields are strongly dependent on sample thicknesses . For instance , the coercivities of FePt ( 5 nm ) , FePt ( 10 nm ) , and FePt ( 20 nm ) films were calculated to be 0 . 6 T , 1 . 1 T , and 2 . 2 T respectively .These measurements are greatly higher than those noted earlier for bulk products .",
        "rewrite_text": "We conducted a study on phase transitions in FePt and CoPt alloys by examining their magnetization in relation to temperature, applied field intensity, and film thickness. Our findings indicate that both alloy systems undergo first-order phase transitions at pressures below 400 K, characterized by hysteresis loops. Furthermore, we observed that coercivity increases rapidly as the samples approach the Curie point (Tc) across all specimens tested. This behavior is linked to the rise in anisotropy energy density near Tc. Additionally, we discovered a significant dependence of coercive fields on the thickness of the samples. For example, the coercivities measured for FePt films of thicknesses 5 nm, 10 nm, and 20 nm were found to be 0.6 T, 1.1 T, and 2.2 T, respectively. These values are significantly higher than those previously reported for bulk materials.",
        "ori-fast-z-score": -0.5345224838248488,
        "water-fast-z-score": 4.27617987059879,
        "rewrite-fast-z-score": -0.5252257314388902
    },
    {
        "original_text": "The standard model is the most successful theory in particle physics, but it fails to explain gravity. In this article we present an alternative approach that unifies general relativity with quantum mechanics by using a new concept called  quantum potential energy density  (QPD). We show how QPD can be used as a source for gravitational field equations which are derived from Hamilton s principle of least action. The resulting field equations have solutions similar to those obtained from Einstein s field equations. However, unlike Einstein s field equations, our proposed field equations do not contain any free parameters such as cosmological constant or dark matter. This means that all physical phenomena predicted by these two theories should agree exactly if they are based on the same underlying principles. Finally, we discuss some possible experimental tests of our proposal. The standard model is the most succesful theory in particle physics, however it fails to explain gravity. \n \n In this article we present another approach that unifies general relavity with quantum mechanics by introducing a new concept called “quantum potental energy density”(QPD). \n \n Quantum potential energy density has been introduced previously by several authors  1-5 , but its role was limited only to explaining certain aspects of quantum mechanics like uncertainty relations  6 , tunneling effect  7-9 , wave-particle duality  10-12  etc.. \n \n Here we propose a novel interpretation of QPD where it plays a central role in deriving gravitational field equations. These field equations are then derived from Hamilton’s principle of least action. \n \n Our results suggest that QPD may play a fundamental role in understanding both gravity and quantum mechanics at their deepest level.",
        "watermark_text": "The classic description is the most popular concept in particle theory , but it fails to explain gravity . In this page we present an additional method that unifies general relativity with classical mechanics by using a new definition called quantum potential energy density ( QPD ) .We see how QPD can be used as a source for gravitational field equations which are derived from Hamilton s principle of least action . The resulting field equations have solutions comparable to those generated from Einstein s field equations .However , unlike Einstein s field equations , our proposed field equations do not include any free parameters such as cosmological factor or black material . This implies that all physical phenomena predicted by these two explanations should agree precisely if they are based on the same underlying principles .Finally , we talk some possible experimental tests of our proposal . The conventional hypothesis is the most succesful model in particle theory , however it fails to explain gravity .In this article we present another methodology that unifies general relavity with quantum mechanics by offering a new notion called “ quantum potental energy density ” ( QPD ) . Quantum potential electricity density has been proposed earlier by various literature 1 - 5 , but its significance was confined only to describing particular aspects of quantum mechanics like uncertainty relations 6 , tunneling effect 7 - 9 , wave - particle duality 10 - 12 etc . .Here we develop a new definition of QPD where it takes a central role in deriving gravitational field equations . These field equations are then constructed from Hamilton ’ s principle of least action .Our results propose that QPD would play a basic part in understanding both gravity and quantum mechanics at their deepest level .",
        "rewrite_text": "The traditional framework is the most widely accepted concept in particle theory, yet it falls short in addressing gravity. In this document, we introduce an alternative approach that merges general relativity with classical mechanics through a new concept known as quantum potential energy density (QPD). We demonstrate how QPD can serve as a foundation for gravitational field equations derived from Hamilton's principle of least action. The resulting equations present solutions that are comparable to those of Einstein's field equations. However, unlike Einstein's formulations, our proposed equations do not contain any free parameters, such as a cosmological constant or dark matter. This implies that any physical phenomena predicted by both approaches should align perfectly if they stem from the same foundational principles. Additionally, we explore potential experimental tests to validate our proposal. While the conventional hypothesis is a successful model in particle theory, it does not account for gravity. In this article, we propose a novel methodology that integrates general relativity with quantum mechanics by introducing the concept of quantum potential energy density (QPD). Although QPD has been mentioned in previous literature—primarily in relation to specific aspects of quantum mechanics such as uncertainty relations and the tunneling effect—it has not been fully utilized in the context of gravity. Here, we redefine QPD to play a pivotal role in formulating gravitational field equations based on Hamilton's principle of least action. Our findings suggest that QPD is essential for a deeper understanding of both gravity and quantum mechanics.",
        "ori-fast-z-score": 2.2132669799727465,
        "water-fast-z-score": 8.842595171198449,
        "rewrite-fast-z-score": 1.1818181818181819
    },
    {
        "original_text": "We present new near-infrared (NIR) observations of the young stellar cluster IC 1396 N, located in the Orion Nebula Cluster region. The data were obtained with the adaptive optics system NAOS-CONICA on the VLT telescope and cover an area of 0.5 arcmin2 around the central star HD 37022. We detect more than 100 point sources down to Ks = 18 mag within this field-of-view. Using these data we have constructed colour-magnitude diagrams for different areas inside our field-of-view. From these CMDs we find that there are two populations of stars which can be separated by their position in the diagrams: one population is redder and fainter while another has bluer colours and brighter magnitudes. These results suggest that the first group consists mainly of low mass pre-main sequence stars surrounded by circumstellar disks, whereas the second group contains mostly high mass main-sequence stars without any surrounding material.",
        "watermark_text": "We report new near - infrared ( NIR ) observations of the small stellar cluster IC 1396 N , located in the Orion Nebula Cluster region . The data were obtained with the adaptive optics network NAOS - CONICA on the VLT telescope and cover an area of 0 . 5 arcmin2 around the primary star HD 37022 .We detect more than 100 point sources down to Ks = 18 mag within this field - of - view . Using these information we have created colour - magnitude diagrams for different areas inside our field - of - view .From these CMDs we find that there are two communities of stars which can be apart by their placement in the diagrams : one community is redder and fainter while another has bluer colours and darker magnitudes . These data suggest that the first group contains primarily of high mass pre - principal sequence stars surrounded by circumstellar disks , whereas the second set contains primarily low mass primary - sequence stars without any surrounding media .",
        "rewrite_text": "We present new near-infrared (NIR) observations of the small stellar cluster IC 1396 N, situated within the Orion Nebula Cluster region. These data were collected using the adaptive optics system NAOS-CONICA on the VLT telescope, covering an area of 0.5 arcmin² around the primary star HD 37022. Within this field of view, we identified over 100 point sources down to Ks = 18 mag. Using this information, we constructed color-magnitude diagrams for various regions within our field. Analysis of these diagrams reveals two distinct groups of stars based on their positions: one group is characterized by redder and fainter stars, while the other is composed of stars with bluer colors and brighter magnitudes. Our findings suggest that the first group mainly consists of high-mass pre-main-sequence stars that are surrounded by circumstellar disks, whereas the second group is primarily made up of low-mass main-sequence stars devoid of surrounding material.",
        "ori-fast-z-score": 0.12403473458920847,
        "water-fast-z-score": 5.417490779798923,
        "rewrite-fast-z-score": 0.8307471607356973
    },
    {
        "original_text": "We study the ground state properties of an interacting electron gas confined to a onedimensional (1D) quantum dot with parabolic confinement potential and repulsive Coulomb interaction between electrons. We show that, for sufficiently strong confining potential, the system undergoes a phase transition into a deformed Wigner crystal at low temperatures. The results are obtained by using density functional theory within the local spin-density approximation combined with exact diagonalization method. In this regime, we find that the charge distribution is characterized by alternating peaks separated by valleys which become more pronounced as temperature decreases. This behavior can be understood in terms of formation of a periodic structure due to inter-particle correlations. Our results suggest that such structures may exist experimentally in semiconductor nanowires or carbon nanotubes. Introduction:-In recent years there has been considerable interest in studying the electronic properties of nanostructures  1  . One dimensional systems have attracted particular attention because they provide a unique opportunity to investigate fundamental physical phenomena like Luttinger liquid  2  , fractional statistics  3  , and Wigner crystallization  4  .\nTheoretical studies of 1D quantum dots (QDs), i.e., QDs with only one dimension much smaller than other two dimensions, were first carried out by Lieb et al  5  who showed that these systems exhibit interesting features including shell filling effects  6  . Subsequently, several authors studied various aspects of QD physics  7, 8  . For example, it was shown that the energy spectrum of a QD depends strongly on its shape  9  . It also turns out that the single particle wave functions of a QD depend sensitively on the boundary conditions  10  . Recently, some experimental progress has been made towards realizing 1D QDs  11  -  13  . However, most experiments so far have focused mainly on transport measurements  14  -  16  rather than direct imaging  17  . Therefore, theoretical investigations play an important role in understanding the underlying physics of these systems  18  -  20  .\nIn this work, we consider a model consisting of N non-interacting fermions confined to a 1D QD with parabolic confinement potential V(x). The total energy E tot = ∑ i=1...N",
        "watermark_text": "We explore the ground state properties of an interacting electron gas restricted to a onedimensional ( 1D ) quantum dot with parabolic confinement potential and repulsive Coulomb interaction between electrons . We see that , for enough strong confining potential , the system undergoes a phase shift into a deformed Wigner crystal at low temperatures .The results are derived by using density functional theory within the local spin - density algorithm coupled with exact diagonalization technique . In this regime , we find that the charge distribution is characterized by alternating ridges separated by regions which turn more pronounced as temperature falls .This phenomenon can be understood in terms of formation of a periodic pattern leading to inter - particle correlations . Our results propose that such structures could occur experimentally in semiconductor nanowires or carbon nanotubes .Introduction : - In recent years there has been substantial interest in examining the electronic properties of nanostructures 1 . One dimensional complexes have garnered especially attention because they give a unique opportunity to examine fundamental physical phenomena like Luttinger vacuum 2 , fractional statistics 3 , and Wigner crystallization 4 .Theoretical experiments of 1D quantum dots ( QDs ) , i . e . , QDs with only one dimension much smaller than other two dimensions , were first conducted out by Lieb et al 5 who demonstrated that these systems exhibit unusual characteristics notably barrel filling effects 6 . Subsequently , various scientists researched several elements of QD physics 7 , 8 .For instance , it was shown that the energy spectrum of a QD depends strongly on its shape 9 . It also turns out that the single molecule wave systems of a QD depend sensitively on the boundary parameters 10 .Recently , some experimental development has been achieved towards realizing 1D QDs 11 - 13 . However , most studies so far have concentrated mostly on transport measurements 14 - 16 rather than direct scanning 17 .Therefore , theoretical investigations play an important role in understanding the fundamental theory of these systems 18 - 20 . In this research , we study a theory consisting of N non - interacting fermions localized to a 1D QD with parabolic confinement potential V ( x ) .The total energy E tot = ∑ i=1...N",
        "rewrite_text": "We investigate the ground state characteristics of an interacting electron gas confined to a one-dimensional (1D) quantum dot that features a parabolic potential and repulsive Coulomb interactions among electrons. Our findings indicate that when the confining potential is sufficiently strong, the system experiences a phase transition to a deformed Wigner crystal at low temperatures. These results are obtained using density functional theory via the local spin-density algorithm in conjunction with exact diagonalization techniques. In this regime, we observe that the charge distribution is defined by alternating ridges separated by increasingly prominent regions as the temperature decreases. This behavior can be interpreted as the emergence of a periodic pattern that enhances inter-particle correlations. We propose that such structures could be experimentally observed in semiconductor nanowires or carbon nanotubes.\n\n**Introduction:** Recent years have seen significant interest in exploring the electronic properties of nanostructures. One-dimensional complexes have attracted particular attention due to their unique ability to probe fundamental physical phenomena such as the Luttinger vacuum, fractional statistics, and Wigner crystallization. Theoretical studies on 1D quantum dots (QDs), wherein one dimension is significantly smaller than the other two, were initially conducted by Lieb et al., who revealed that these systems exhibit extraordinary characteristics, including barrel filling effects. Following this, various researchers have investigated different aspects of QD physics. Notably, it was discovered that a QD's energy spectrum is highly dependent on its shape, and that the wave functions of individual molecules within a QD are sensitive to boundary parameters. Recently, advances have been made towards the realization of 1D QDs; however, most existing studies have primarily focused on transport measurements rather than direct scanning. Hence, theoretical investigations remain crucial for uncovering the fundamental theories governing these systems. In this study, we examine a theoretical model comprised of N non-interacting fermions localized within a 1D QD characterized by a parabolic confinement potential V(x). The total energy is expressed as E_tot = ∑_{i=1}^N.",
        "ori-fast-z-score": -0.9370425713316364,
        "water-fast-z-score": 6.9853547313569955,
        "rewrite-fast-z-score": 0.39405520311955033
    },
    {
        "original_text": "We present high-resolution (R = λ/Δλ ~ 10000) near-infrared and mid-infrared spectroscopic observations for two ULIRGs, Mrk 231 and Arp 220. The data were obtained with the Subaru Telescope using the Cooled Mid-Infrared Camera and Spectrograph (COMICS). We detect several emission lines in both objects including H I Brγ at 2.16 μm, Paα at 1.87 μm,  Fe II  at 1.64 μm, He I at 1.70 μm,  S III  at 0.95 μm, and  C IV  at 0.15 μm. In addition to these lines, we also find that there are many absorption features such as CO bandheads near 4.7 μm and 6.2 μm. These results show that the observed spectra have complex line profiles which can be explained by multiple components along our line-of-sight and/or different physical conditions within each component.",
        "watermark_text": "We present high - resolution ( R = λ / Δλ ~ 10000 ) near - infrared and mid - infrared spectroscopic observations for two ULIRGs , Mrk 231 and Arp 220 . The data were obtained with the Subaru Telescope using the Cooled Mid - Infrared Camera and Spectrograph ( COMICS ) .We detect many emission lines in both objects including H I Brγ at 2 . 16 μm , Paα at 1 . 87 μm , Fe II at 1 . 64 μm , He I at 1 . 70 μm , S III at 0 . 95 μm , and C IV at 0 . 15 μm . In addition to these lines , we also find that there are many absorption properties such as CO bandheads near 4 . 7 μm and 6 . 2 μm .These data reveal that the seen spectra have complex line profiles which can be described by various components along our line - of - view and / or varying material conditions within each portion .",
        "rewrite_text": "We present high-resolution near-infrared and mid-infrared spectroscopic observations (R = λ / Δλ ~ 10,000) of two ULIRGs, Mrk 231 and Arp 220. These observations were conducted using the Subaru Telescope and the Cooled Mid-Infrared Camera and Spectrograph (COMICS). Our analysis reveals numerous emission lines in both galaxies, including H I Brγ at 2.16 μm, Paα at 1.87 μm, Fe II at 1.64 μm, He I at 1.70 μm, S III at 0.95 μm, and C IV at 0.15 μm. Additionally, we identified several absorption features, such as CO bandheads at approximately 4.7 μm and 6.2 μm. The data indicate that the observed spectra exhibit complex line profiles, which may result from multiple components along our line of sight and/or the varying physical conditions in different regions of each galaxy.",
        "ori-fast-z-score": 1.2977713690461004,
        "water-fast-z-score": 4.8666426339228765,
        "rewrite-fast-z-score": 0.3086066999241838
    },
    {
        "original_text": "We present an evolutionary algorithm for the problem of mesh numbering, which is to assign integers in the range  0, ..., n-1  to all vertices of a given graph G = (V, E) such that adjacent vertices have consecutive numbers and no two edges share the same pair of endpoints with the same order.  The proposed method uses a population-based approach where each individual represents a valid solution by means of a permutation vector. We show how this representation can be used to efficiently compute fitness values using only local information. In addition we propose several genetic operators to explore the search space. Finally, we report on preliminary results obtained by applying our method to some well-known benchmark instances. Keywords: Graphs, Optimization problems, Evolutionary algorithms, Genetic algorithms. 1 Introduction A common task when working with graphs is to label their nodes or edges with unique identifiers. This process is known as node or edge numbering respectively. For example, it may be required to number the nodes of a road network so that every path between any two points has a unique sequence of labels. Another application arises in circuit design, where one needs to assign unique addresses to components of electronic circuits.",
        "watermark_text": "We present an evolutionary algorithm for the question of mesh numbering , which is to assign integers in the range 0 , . . . , k - 1 to all edges of a given graph G = ( V , E ) such that adjacent vertices have consecutive numbers and no two edges occupy the same pair of endpoints with the same order . The proposed approach utilizes a population - based approach where each individual represents a valid answer by means of a permutation matrix .We see how this representation can be used to easily compute fitness values utilizing only local information . In addition we propose several genetic functions to examine the search space .Finally , we publish on preliminary results acquired by using our technique to some well - famous benchmark instances . Keywords : Graphs , Optimization problems , Evolutionary algorithms , Genetic algorithms .1 Introduction A typical task when dealing with graphs is to label their edges or edges with special identifiers . This process is known as node or edge numbering respectively .For instance , it could be required to count the nodes of a street system so that every path between any two points has a unique string of tags . Another application exists in circuit design , where one needs to give unique addresses to components of electronic circuits .",
        "rewrite_text": "We introduce an evolutionary algorithm aimed at solving the mesh numbering problem. This entails assigning integers from the range 0 to k - 1 to all edges of a graph G = (V, E) in such a way that adjacent vertices are labeled with consecutive numbers, and no two edges share the same pair of endpoints in the same order. Our approach employs a population-based strategy in which each individual signifies a valid solution through a permutation matrix. This representation allows for the straightforward calculation of fitness values using only local information. Additionally, we propose various genetic functions to explore the search space. Finally, we present preliminary results obtained from applying our technique to several well-known benchmark instances. Keywords: Graphs, Optimization Problems, Evolutionary Algorithms, Genetic Algorithms.\n\n1 Introduction\nA common task in graph theory involves labeling edges or nodes with specific identifiers, a process referred to as node or edge numbering, respectively. For example, one might need to assign numbers to the nodes in a street network to ensure that every route between any two locations has a distinct set of tags. Another application can be found in circuit design, where it is essential to assign unique addresses to the components of electronic circuits.",
        "ori-fast-z-score": -1.0,
        "water-fast-z-score": 5.273697108112943,
        "rewrite-fast-z-score": 0.10050378152592121
    },
    {
        "original_text": "We report the detection of periodic bursts of coherent radio emission at 1.4 GHz and 8.5 GHz, with periods ranging between 0.3 s to 3.6 s, from the ultracool dwarf TVLM 513-46546 (M8V). The source is located in the southern hemisphere near the Galactic plane, where it was discovered by its optical variability. \n \n We have detected these bursts using the Karl G. Jansky Very Large Array (VLA) and the Australia Telescope Compact Array (ATCA), as well as archival data obtained with the Westerbork Synthesis Radio Telescope (WSRT). \n \n These bursts are characterized by their high brightness temperatures (Tb > 1011 K), rapid rise times (< 10 ms), flat or inverted spectral indices (-0.2 < α < +0.7), and lack of circular polarization. They also appear to be highly polarized (~50% linear polarization fraction) on short time scales (< 100 ms). Their properties suggest that they may originate from gyrosynchrotron radiation produced within magnetic loops anchored to the surface of this star. \n \n This discovery opens up new avenues for studying the magnetospheres of low-mass stars through direct imaging techniques.",
        "watermark_text": "We report the observation of periodic pulses of coherent radio emission at 1 . 4 GHz and 8 . 5 GHz , with periods ranging between 0 . 3 s to 3 . 6 s , from the ultracool dwarf TVLM 513 - 46546 ( M8V ) . The source is situated in the southern hemisphere near the Galactic jet , where it was known by its optical variability .We have discovered these bursts using the Karl G . Jansky Very Large Array ( VLA ) and the Australia Telescope Compact Array ( ATCA ) , as well as archival info collected with the Westerbork Synthesis Radio Telescope ( WSRT ) . These bursts are marked by their high brightness temperatures ( Tb > 1011 K ) , quick rising periods ( < 10 ms ) , flat or inverted spectral indices ( - 0 . 2 < α < + 0 . 7 ) , and lack of circular polarization .They even seem to be highly polarized ( ~ 50 % linear polarization fraction ) on short time ranges ( < 100 ms ) . Their properties suggest that they may originate from gyrosynchrotron rays produced within magnetic loops anchored to the surface of this star .This find starts up new avenues for studying the magnetospheres of lowest - density stars through direct imaging technology .",
        "rewrite_text": "We present our findings of periodic coherent radio emission pulses at frequencies of 1.4 GHz and 8.5 GHz from the ultracool dwarf TVLM 513-46546 (M8V), with periods ranging from 0.3 to 3.6 seconds. Located in the southern hemisphere near the Galactic jet, this source has previously been noted for its optical variability. Our discovery of these bursts was made using the Karl G. Jansky Very Large Array (VLA) and the Australia Telescope Compact Array (ATCA), along with archival data from the Westerbork Synthesis Radio Telescope (WSRT). The bursts exhibit exceptionally high brightness temperatures (Tb > 10^11 K), rapid rise times (less than 10 ms), flat to inverted spectral indices (-0.2 < α < +0.7), and no observable circular polarization. Remarkably, they also show significant linear polarization (around 50%) over short durations (under 100 ms). These characteristics imply that the emissions could be produced by gyrosynchrotron radiation arising from magnetic loops anchored to the star's surface. This discovery opens up new possibilities for investigating the magnetospheres of low-density stars using direct imaging techniques.",
        "ori-fast-z-score": 0.6201736729460423,
        "water-fast-z-score": 5.333493587335964,
        "rewrite-fast-z-score": -1.9402850002906638
    },
    {
        "original_text": "We present new constraints on the acceleration mechanisms responsible for quasar outflows, using data obtained with the Chandra X-ray Observatory (CXO) to study the Fe K emission line profiles observed in two quasars at redshifts z = 1.7 and 2.3. The Fe K lines are found to be broadened by Doppler motions associated with an outflowing wind that is launched close to the central black hole. We find evidence for both thermal broadening and bulk motion of the emitting gas, but we cannot rule out other possible explanations such as relativistic effects or multiple components. In addition, we use these observations to place limits on the mass loss rateṀout and kinetic luminosity L kin of this outflow. For one object, PG 1211+143, we also compare our results with those derived from optical/UV absorption-line studies. Our analysis suggests that the winds may have different properties depending upon their location within the host galaxy. \n \n Keywords: Accretion disk - Black holes - Emission lines - Winds",
        "watermark_text": "We introduce novel constraints on the acceleration mechanisms involved for quasar outflows , using data acquired with the Chandra X - ray Observatory ( CXO ) to study the Fe K emission line profiles observed in two quasars at redshifts z = 1 . 7 and 2 . 3 . The Fe K bands are found to be broadened by Doppler movements involved with an outflowing breeze that is launched close to the main white hole .We see evidence for both thermal broadening and bulk movement of the emitting gas , but we lack judge out other possible explanations such as relativistic effects or multiple components . In addition , we utilize these observations to place limits on the mass loss [UNK] and kinetic luminosity L kin of this outflow .For one object , PG 1211 + 143 , we also compare our findings with those generated from optical / UV absorption - line surveys . Our study implies that the winds may have different properties depending upon their orientation within the target galaxy .Keywords : Accretion disk - Black holes - Emission lines - Winds",
        "rewrite_text": "We present new constraints on the acceleration mechanisms driving quasar outflows, utilizing data from the Chandra X-ray Observatory (CXO) to analyze the Fe K emission line profiles in two quasars at redshifts z = 1.7 and 2.3. Our findings indicate that the Fe K bands are broadened due to Doppler shifts associated with an outflowing wind emanating near the central white hole. We detect evidence of both thermal broadening and bulk motion of the emitting gas; however, we are unable to assess other potential factors such as relativistic effects or the presence of multiple components. Additionally, we use these observations to establish limits on mass loss and the kinetic luminosity (L_kin) of the outflow. For one quasar, PG 1211 + 143, we also compare our results with data from optical/UV absorption-line surveys. Our research suggests that the properties of these winds may vary depending on their orientation within the host galaxy. Keywords: Accretion disk, Black holes, Emission lines, Winds.",
        "ori-fast-z-score": 0.8307471607356973,
        "water-fast-z-score": 6.289942788427422,
        "rewrite-fast-z-score": 1.2309149097933272
    },
    {
        "original_text": "We present an analysis of the kinematics and dynamics of galaxies within galaxy clusters, using data obtained with the Hubble Space Telescope (HST). We use this information to measure the degree of radial bias in the distribution of cluster member velocities as well as their spatial correlation function. The results are compared against predictions made by cosmological N-body simulations that include both baryonic gas and collisionless dark matter particles. Our main conclusions are:  1) Galaxy clusters exhibit significant deviations from isotropic dynamical equilibrium; 2) These deviations can be explained if we assume that the dark matter component has a radially biased velocity dispersion tensor; 3) This result implies that the dark matter halos surrounding individual galaxies have similar shapes but different orientations relative to each other. In addition, our measurements provide new constraints on the mass-to-light ratio for galaxy clusters. Using HST observations of four nearby galaxy clusters, we find evidence that the dark matter component exhibits a strong radial bias in its velocity dispersion tensor.",
        "watermark_text": "We present an assessment of the kinematics and dynamics of clusters within galaxy clusters , using data acquired with the Hubble Space Telescope ( HST ) . We use this data to measure the degree of radial bias in the distribution of cluster member velocities as well as their spatial correlation function .The results are compared against models done by cosmological N - bodies simulations that include both baryonic gas and collisionless dark matter molecules . Our main results are : 1 ) Galaxy clusters exhibit substantial deviations from isotropic dynamical balance ; 2 ) These deviations can be described if we suppose that the dark matter component has a radially biased speed dispersion matrix ; 3 ) This result suggests that the dark matter halos adjoining individual stars have related shapes but different orientations relative to each other .In addition , our measurements give novel constraints on the mass - to - light percentage for galaxy regions . Using HST observations of four nearby galaxy galaxies , we find proof that the dark matter component displays a powerful radial bias in its velocity dispersion matrix .",
        "rewrite_text": "We provide an evaluation of the kinematics and dynamics of clusters within galaxy clusters, utilizing data obtained from the Hubble Space Telescope (HST). This data allows us to assess the extent of radial bias in the velocities of cluster members as well as their spatial correlation function. Our findings are compared with models developed from cosmological N-body simulations that incorporate both baryonic gas and collisionless dark matter particles. Our key conclusions are as follows: 1) Galaxy clusters show significant deviations from isotropic dynamical equilibrium; 2) These deviations can be explained by assuming that the dark matter component has a radially biased velocity dispersion matrix; 3) This indicates that the dark matter halos surrounding individual stars share similar shapes but differ in their orientations relative to one another. Furthermore, our measurements provide new constraints on the mass-to-light ratios in galaxy regions. Analyzing HST observations of four nearby galaxies, we find evidence that the dark matter component exhibits a strong radial bias in its velocity dispersion matrix.",
        "ori-fast-z-score": -0.44172610429938614,
        "water-fast-z-score": 6.184165460191406,
        "rewrite-fast-z-score": 0.3375263702778072
    },
    {
        "original_text": "We present new observations with the Hubble Space Telescope (HST) and Chandra X-ray Observatory to study the properties of ionized gas in galaxy clusters at z ~ 0.5-0.8, where most massive clusters are found today.  We find that the fraction of cool core clusters is higher than expected for their redshifts based on local samples. The observed evolution may be due to an increase in the number density of active galactic nuclei or AGN activity over time. In addition, we detect extended emission line regions around some of these clusters which have been previously identified as having strong cooling flows. These results suggest that there has been significant heating of the intracluster medium by energetic outflows associated with AGNs since z = 1.0. This work was supported by NASA grant NAG5-9998. Cooling flow clusters are known to contain large amounts of cold gas within their central regions. However, it remains unclear how this gas cools down without forming stars. Recent studies show that many of them also harbor powerful radio sources near their centers. It is possible that such radio jets heat up the ICM through shocks and/or turbulence generated during the interaction between the jet plasma and the ambient hot gas.",
        "watermark_text": "We present new experiments with the Hubble Space Telescope ( HST ) and Chandra X - ray Observatory to study the properties of ionized gas in galaxy galaxies at z ~ 0 . 5 - 0 . 8 , where most large clusters are found today . We see that the fraction of cold core galaxies is higher than expected for their redshifts based on local samples .The observed evolution may be due to an increase in the number density of active galactic nuclei or AGN activity over time . In addition , we find extended emitted path regions around some of these clusters which have been previously noted as having strong cooling flows .These results suggest that there has been significant heating of the intracluster medium by energetic outflows associated with AGNs since z = 1 . 0 . This work was supported by NASA grant NAG5 - 9998 .Cooling circulation clusters are known to contain significant amounts of cold energy within their central regions . However , it remains unclear how this gas cools down without forming stars .Recent research reveal that several of them additionally harbor potent wireless sources near their regions . It is suggested that such radio jets heat up the ICM through shocks and / or turbulence generated during the interaction between the jet plasma and the ambient warm gas .",
        "rewrite_text": "We present new experiments conducted with the Hubble Space Telescope (HST) and the Chandra X-ray Observatory to investigate the properties of ionized gas in galaxies at redshifts approximately 0.5 to 0.8, where many large clusters are currently located. Our findings indicate that the proportion of cold core galaxies is greater than anticipated for their redshifts, based on local samples. This observed evolution could be a result of an increase in the number density of active galactic nuclei (AGN) or heightened AGN activity over time. Additionally, we have identified extended emission regions surrounding some of these clusters, which have previously been recognized for their strong cooling flows. These results imply that there has been considerable heating of the intracluster medium due to energetic outflows from AGNs since redshift z = 1.0. This research was supported by NASA grant NAG5-9998. Cooling circulation clusters are known to contain substantial amounts of cold energy in their central regions; however, it remains uncertain how this gas cools without forming stars. Recent studies indicate that several of these clusters also host powerful radio sources in their vicinity. It is proposed that such radio jets contribute to heating the intracluster medium through shocks and/or turbulence generated from the interaction between the jet plasma and the surrounding warm gas.",
        "ori-fast-z-score": 1.744163198544762,
        "water-fast-z-score": 6.123724356957946,
        "rewrite-fast-z-score": 2.2
    },
    {
        "original_text": "We present the first steps towards building a library of synthetic galaxy SEDs (spectral energy distributions) that will be used to classify and parameterize unresolved galaxies in the Gaia data stream, as part of the Data Processing and Analysis Consortium (DPAC). The library is built using state-of-the-art stellar population synthesis models with different star formation histories, metallicities, dust content, and redshifts. We use this library to test two methods of classifying unresolved galaxies into broad morphological types based on their observed photometry only. In addition we show how these parameters can be constrained by fitting the full spectrum of an unresolved galaxy. This work was performed within the framework of the ESA Gaia mission. Keywords: Galaxy evolution; Stellar populations; Spectroscopy. 1 Introduction Galaxies are complex systems whose properties depend strongly on their mass, age, chemical composition, star formation history, and environment. These physical characteristics determine many observable quantities such as luminosity, colours, morphology, kinematics, etc., which have been studied extensively over several decades. However, it has become clear recently that there exist significant degeneracies between some of these observables and therefore they cannot be uniquely determined without additional information about the underlying physics or geometry of the system. For example, the total luminosity of a galaxy depends not only on its current star formation rate but also on its past star formation activity through the integrated light of old stars. Similarly, the colour of a galaxy depends both on its metallicity and on the amount of dust extinction along our line-of-sight. Therefore, accurate measurements of all relevant physical parameters require detailed spectroscopic observations covering large wavelength ranges. Such studies are now possible thanks to new space missions like GALEX, SDSS, 2MASS, Spitzer Space Telescope, Herschel Space Observatory, Chandra X-ray Observatory, XMM-Newton, Hubble Space Telescope, and most importantly, the upcoming European Space Agency s Gaia satellite. Gaia is expected to provide astrometric positions, parallaxes, proper motions, radial velocities, and multi-colour photometry for more than one billion objects",
        "watermark_text": "We present the first steps towards constructing a library of synthetic galaxy SEDs ( spectral energy distributions ) that will be used to classify and parameterize unresolved galaxies in the Gaia data feed , as member of the Data Processing and Analysis Consortium ( DPAC ) . The library is built using state - of - the - art stellar community synthesis estimates with various galaxy formation histories , metallicities , dust content , and redshifts .We use this library to test two means of classifying unresolved galaxies into wide morphological types based on their observed photometry only . In addition we prove how these parameters can be constrained by fitting the full spectrum of an unresolved universe .This research was done within the framework of the ESA Gaia spacecraft . Keywords : Galaxy evolution ; Stellar populations ; Spectroscopy .1 Introduction Galaxies are diverse structures whose characteristics rely heavily on their mass , age , chemical composition , star formation history , and environment . These physical traits determine many observable quantities such as luminosity , colours , morphology , kinematics , etc . , which have been studied frequently over numerous years .However , it has become clear recently that there remain considerable degeneracies between some of these observables and therefore they cannot be uniquely determined without additional information about the fundamental physics or topology of the system . For instance , the total luminosity of a galaxy depends not only on its current star formation rate but also on its past star formation activity through the integrated light of young galaxies .Similarly , the colour of a galaxy depends both on its metallicity and on the extent of dust extinction along our line - of - view . Therefore , detailed observations of all relevant physical factors require comprehensive spectroscopic observations encompassing large wavelength ranges .Such investigations are now able thanks to novel space missions like GALEX , SDSS , 2MASS , Spitzer Space Telescope , Herschel Space Observatory , Chandra X - ray Observatory , XMM - Newton , Hubble Space Telescope , and most importantly , the latest European Space Agency s Gaia satellite . Gaia is expected to provide astrometric positions , parallaxes , proper motions , radial velocities , and multi - colour photometry for more than one billion objects",
        "rewrite_text": "We introduce the initial stages of developing a library of synthetic spectral energy distributions (SEDs) for galaxies, which will be utilized to classify and characterize unresolved galaxies within the Gaia data stream as part of the Data Processing and Analysis Consortium (DPAC). This library is constructed using advanced stellar population synthesis models, incorporating a range of galaxy formation histories, metallicities, dust content, and redshifts. We employ this library to evaluate two methods for classifying unresolved galaxies into broad morphological categories based solely on their observed photometry. Additionally, we demonstrate how these parameters can be refined by fitting the complete spectrum of an unresolved universe. This research has been conducted within the framework of the European Space Agency's Gaia mission. \n\nKeywords: Galaxy evolution; Stellar populations; Spectroscopy.\n\n1. Introduction \n\nGalaxies are complex structures whose properties are significantly influenced by their mass, age, chemical composition, star formation history, and environment. These physical attributes govern a variety of observable quantities such as luminosity, colors, morphology, and kinematics, which have been extensively investigated over many years. However, recent insights reveal substantial degeneracies among some of these observables, indicating that they cannot be uniquely identified without additional information regarding the underlying physics or topology of the system. For example, a galaxy's total luminosity is influenced not only by its current star formation rate but also by its historical star formation activity, as reflected in the integrated light of younger galaxies. Similarly, a galaxy's color is contingent upon its metallicity and the degree of dust extinction encountered along the line of sight. As a result, thorough observations of all pertinent physical factors necessitate comprehensive spectroscopic data across extensive wavelength ranges. Advancements in this field are now possible due to innovative space missions, including GALEX, SDSS, 2MASS, the Spitzer Space Telescope, the Herschel Space Observatory, the Chandra X-ray Observatory, XMM-Newton, the Hubble Space Telescope, and especially the latest European Space Agency satellite, Gaia. Gaia is anticipated to deliver astrometric positions, parallaxes, proper motions, radial velocities, and multi-color photometry for over one billion celestial objects.",
        "ori-fast-z-score": 1.643989873053573,
        "water-fast-z-score": 7.893748050080246,
        "rewrite-fast-z-score": 1.1281521496355325
    },
    {
        "original_text": "We report on the magnetic properties of self-assembled arrays of cobalt (Co) hollow spheres, which are prepared by an electrochemical deposition method onto carbon-coated copper grids. The samples show anisotropic behavior in their hysteresis loops at room temperature as well as superparamagnetic characteristics above 300 K. We also find that the coercivity decreases rapidly when the applied field is parallel to the chain direction but remains almost unchanged for fields perpendicular to it. This indicates that the easy axis lies along the chain direction. In addition, we observe that the remanent magnetization increases gradually up to about 100 Oe after annealing the sample at 400 °C under vacuum conditions. These results suggest that the observed anisotropy originates mainly from shape effects rather than inter-particle interactions. \n \n Keywords: Anisotropy, Cobalt, Hollow sphere, Self-assembling, Superparamagnetism",
        "watermark_text": "We report on the magnetic properties of self - assembled arrays of cobalt ( Co ) hollow spheres , which are prepared by an electrochemical deposition technology onto carbon - wrapped copper grids . The samples show anisotropic dynamics in their hysteresis loops at room temperature as well as superparamagnetic qualities above 300 K . We additionally find that the coercivity decreases quickly when the introduced field is parallel to the chain direction but remains virtually unchanged for fields perpendicular to it .This implies that the easy axis lies along the chain direction . In addition , we determine that the remanent magnetization increases slowly up to about 100 Oe after annealing the sample at 400 °C under vacuum environments .These data suggest that the seen anisotropy derives mainly from shape impacts rather than inter - particle processes . Keywords : Anisotropy , Cobalt , Hollow sphere , Self - assembling , Superparamagnetism",
        "rewrite_text": "We present our findings on the magnetic characteristics of self-assembled arrays of cobalt (Co) hollow spheres, which were fabricated using electrochemical deposition onto carbon-coated copper grids. The samples exhibit anisotropic behavior in their hysteresis loops at room temperature and demonstrate superparamagnetic properties above 300 K. Notably, we observed a rapid decrease in coercivity when the applied field is aligned with the chain direction, while coercivity remains nearly constant for fields oriented perpendicular to the chains, indicating that the easy axis is aligned with the chain direction. Furthermore, we found that the remanent magnetization gradually increases up to approximately 100 Oe after annealing the samples at 400 °C in a vacuum. These results suggest that the observed anisotropy is primarily influenced by shape rather than inter-particle interactions. Keywords: Anisotropy, Cobalt, Hollow sphere, Self-assembly, Superparamagnetism.",
        "ori-fast-z-score": 0.6401843996644799,
        "water-fast-z-score": 5.505585837114527,
        "rewrite-fast-z-score": 1.524001524002286
    },
    {
        "original_text": "In this work, we present an analysis of design process and experiments conducted in developing a generic tutoring system for intelligent tutoring applications (ITAs). The main goal is to provide insights into how such systems can be developed with minimal effort by reusing existing components. We describe our experiences in building the AnITA system that provides adaptive feedbacks based on student s actions during problem solving activities. In addition, we discuss some issues related to evaluation of ITAs using different types of students as subjects. Finally, we conclude with lessons learned throughout the development cycle. This article is available from: http://arxiv.org/abs/1207.5995. Keywords: Intelligent tutoring application; Adaptive feedbacks; Problem-solving activity; Student modeling; Evaluation experimentation. 1 Introduction Intelligent tutoring applications (ITAS) are computer-based learning environments designed to help students learn specific skills or concepts through interactive problem-solving activities  1  . They have been shown to improve students  performance when compared to traditional teaching methods  2  .\nThe development of ITA requires significant efforts due to their complexity  3  , which includes several components including domain knowledge representation  4  , student modeling  5  , pedagogical strategies  6  , user interface  7  , and adaptation  8  . To reduce these efforts, researchers have proposed frameworks  9  -  11  and tools  12  -  14  that allow developers to build new ITS without having to start from scratch. However, most of them focus only on one aspect of ITS development  15  , e.g., authoring tool  16  , content management  17  , or student modeling  18  .",
        "watermark_text": "In this research , we present an assessment of design process and experiments conducted in building a generic tutoring scheme for intelligent tutoring applications ( ITAs ) . The main goal is to provide insights into how such applications can be designed with minimal effort by reusing existing elements .We relate our events in building the AnITA process that offers intelligent feedbacks based on student s activities during task solving operations . In addition , we explain some issues related to assessment of ITAs using varying kinds of participants as subjects .Finally , we conclude with lessons learned throughout the development period . This section is accessible from : www : / / arxiv . org / abs / 1207 . 5995 .Keywords : Intelligent tutoring application ; Adaptive feedbacks ; Problem - solving exercise ; Student simulation ; Evaluation testing . 1 Introduction Intelligent tutoring applications ( ITAS ) are computer - based educational environments designed to assist children understand particular techniques or concepts through interactive problem - solving operations 1 .They have been shown to improve students performance when compared to conventional taught methods 2 . The formation of ITA demands major steps owing to their complexity 3 , which includes several elements including domain knowledge structure 4 , student modeling 5 , pedagogical strategies 6 , user interface 7 , and adaptation 8 .To reduce these attempts , researchers have proposed frameworks 9 - 11 and tools 12 - 14 that enable developers to build existing ITS without having to start from scratch . However , most of them focus only on one element of ITS development 15 , e . g . , authoring tool 16 , product management 17 , or student design 18 .",
        "rewrite_text": "In this study, we evaluate the design process and experiments involved in creating a generic tutoring scheme for intelligent tutoring applications (ITAs). Our primary objective is to offer insights on how these applications can be developed with minimal effort by leveraging existing components. We detail our experience in establishing the AnITA process, which provides intelligent feedback based on students' activities during problem-solving tasks. Additionally, we address various challenges related to the evaluation of ITAs using different types of participants. We conclude with the lessons learned during the development phase. More information can be found at: www:/arxiv.org/abs/1207.5995. Keywords: Intelligent tutoring application; Adaptive feedback; Problem-solving exercise; Student simulation; Evaluation testing.\n\n1. Introduction\n\nIntelligent tutoring applications (ITAs) are computer-based educational platforms designed to help children grasp specific techniques or concepts through interactive problem-solving activities. Research has indicated that these applications can enhance student performance compared to traditional teaching methods. Developing ITAs involves several complex steps, including establishing domain knowledge structures, student modeling, pedagogical strategies, user interfaces, and adaptation. To streamline this process, researchers have suggested various frameworks and tools that enable developers to create existing intelligent tutoring systems (ITS) without starting anew. However, many of these tools focus on a single aspect of ITS development, such as authoring, product management, or student design.",
        "ori-fast-z-score": -0.9918365981341755,
        "water-fast-z-score": 7.786074159656593,
        "rewrite-fast-z-score": 1.2675004445952593
    },
    {
        "original_text": "The present work is devoted to the study of astrophysical plasma turbulence, with particular emphasis on its statistical properties at different scales. We consider both kinetic and fluid descriptions for the dynamics of collisionless plasmas, which are relevant for many space and laboratory applications. In this context we investigate the nonlinear evolution of magnetic fluctuations by means of direct numerical simulations (DNS) of the Vlasov-Maxwell system. The main results can be summarized as follows:  1. Turbulence statistics -We perform DNSs of the Vlasov-Poisson system in order to characterize the statistical properties of the electrostatic potential fluctuations generated by an initial spectrum of Alfvenic modes. Our analysis shows that the energy cascade proceeds towards smaller spatial scales until it reaches the ion Larmor radius scale where it is transferred into perpendicular wavenumbers through Landau damping. At these small scales, the energy transfer rate decreases due to the reduction of phase correlations between wavevectors. This process leads to the formation of intermittency in the distribution function of particles.  2. Kinetic effects -In addition to the above mentioned features observed in the case of purely hydrodynamic turbulence, our results show that kinetic effects play also an important role in determining the statistical properties of the fluctuating fields. Indeed, we find that the presence of ions modifies significantly the shape of the probability density functions (PDFs), leading to non-Gaussian distributions characterized by tails extending over several orders of magnitude. Moreover, we observe that the PDFs become more skewed when increasing the value of the ion-to-electron mass ratio. Finally, we discuss how the inclusion of kinetic effects affects the scaling laws characterizing the power spectra of the fluctuating fields. \n3. Fluid description -By performing DNSs of the Euler-",
        "watermark_text": "The present work is committed to the observation of astrophysical plasma turbulence , with particular emphasis on its statistical characteristics at different scales . We consider both kinetic and fluid representations for the dynamics of collisionless plasmas , which are applicable for numerous space and lab applications .In this framework we investigate the nonlinear development of magnetic fluctuations by means of direct numerical simulations ( DNS ) of the Vlasov - Maxwell process . The main results can be summarized as follows : 1 .Turbulence statistics - We perform DNSs of the Vlasov - Poisson system in order to characterize the statistical characteristics of the electrostatic potential fluctuations formed by an initial spectrum of Alfvenic modes . Our study shows that the power cascade proceeds towards smaller spatial scales until it meets the electron Larmor radius scale where it is transferred into perpendicular wavenumbers through Landau damping .At these little scales , the power transfer frequency falls due to the reduction of phase correlations between wavevectors . This process results to the formation of intermittency in the distribution function of particles .2 . Kinetic effects - In addition to the above mentioned elements observed in the case of solely hydrodynamic turbulence , our findings show that kinetic influences play also an important role in determining the statistical characteristics of the fluctuating fields .Indeed , we find that the presence of atoms modifies substantially the morphology of the probability density functions ( PDFs ) , leading to non - Gaussian functions characterized by tails extending over numerous orders of magnitude . Moreover , we find that the PDFs get more skewed when increasing the value of the electron - to - atom weight ratio .Finally , we explain how the introduction of kinetic effects affects the scaling laws characterizing the power spectra of the fluctuating forces . 3 .Fluid description - By conducting DNSs of the Euler -",
        "rewrite_text": "This study focuses on observing astrophysical plasma turbulence, specifically its statistical properties across various scales. We explore both kinetic and fluid models for the dynamics of collisionless plasmas, applicable in numerous space and laboratory settings. Within this context, we delve into the nonlinear evolution of magnetic fluctuations through direct numerical simulations (DNS) of the Vlasov-Maxwell equations. Our key findings can be summarized as follows: \n\n1. **Turbulence Statistics**: We conduct DNS of the Vlasov-Poisson system to analyze the statistical properties of electrostatic potential fluctuations generated from an initial spectrum of Alfvenic modes. Our research reveals that the power cascade shifts toward smaller spatial scales until it reaches the electron Larmor radius scale, at which point the energy is transferred to perpendicular wavenumbers via Landau damping. At these small scales, the power transfer frequency decreases due to a reduction in phase correlations among wavevectors, leading to the emergence of intermittency in the particles’ distribution function.\n\n2. **Kinetic Effects**: Beyond the elements observed in purely hydrodynamic turbulence, we demonstrate that kinetic factors significantly influence the statistical characteristics of fluctuating fields. Notably, the presence of particles alters the shape of the probability density functions (PDFs), resulting in non-Gaussian distributions with tails extending over several orders of magnitude. Furthermore, we observe that the skewness of the PDFs increases with a rising electron-to-atom weight ratio. We also clarify how incorporating kinetic effects modifies the scaling laws defining the power spectra of the fluctuating forces.\n\n3. **Fluid Description**: Through further DNS of the Euler equations, we... [Continue with further information as needed].",
        "ori-fast-z-score": -1.2374368670764582,
        "water-fast-z-score": 6.251201434911929,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We present the results of an investigation into the shapes and orientations of molecular cloud cores in the Orion Nebula region using near-infrared polarimetry obtained with the Gemini North telescope. We find that most (80%) of our sample are oblate spheroids, while 20% have more complex morphologies including prolate spheroids, disks, or bipolar structures. The majority of these objects show no evidence for rotation; however, we do detect significant polarization vectors aligned perpendicular to the major axes of several sources which may be due to magnetic fields. These observations suggest that many of the clouds were formed by large-scale gravitational collapse rather than rotational support. This work is supported by NASA grant NNX10AC99G. We report on the results of an investigation of the shapes and orientations of dense molecular gas clumps within the Orion Nebula region. Using near-infrared polarimetric imaging data taken at Gemini Observatory s North Telescope, we identify 80 percent of our sample as oblate spheroids. Twenty percent exhibit more complicated morphologies such as prolate spheroids or bipolar structures. Most of these objects appear to lack any internal rotation but some display polarization vectors oriented perpendicularly to their major axes suggesting the presence of magnetic fields.",
        "watermark_text": "We present the conclusion of an research into the shapes and orientations of molecular dust cores in the Orion Nebula region utilizing near - infrared polarimetry obtained with the Gemini North telescope . We see that most ( 80 % ) of our sample are oblate spheroids , while 20 % have more sophisticated morphologies including prolate spheroids , cones , or bipolar forms .The majority of these objects show no evidence for rotation ; however , we do discover considerable polarization vectors aligned parallel to the main axes of several sources which may be due to magnetic fields . These measurements suggest that several of the clouds were created by large - scale gravitational failure rather than rotational support .This research is backed by NASA grant NNX10AC99G . We report on the conclusion of an research of the shapes and orientations of dense molecular gas clumps within the Orion Nebula region .Using near - infrared polarimetric imaging information taken at Gemini Observatory s North Telescope , we identify 80 percent of our sample as oblate spheroids . Twenty half display more complicated morphologies such as prolate spheroids or bipolar forms .Most of these objects may to lack any internal rotation but some display polarization axes aligned perpendicularly to their major directions indicating the presence of magnetic waves .",
        "rewrite_text": "We present the findings of our research on the shapes and orientations of molecular dust cores in the Orion Nebula, utilizing near-infrared polarimetry obtained from the Gemini North Telescope. Our analysis reveals that 80% of the sampled cores are oblate spheroids, while the remaining 20% exhibit more complex morphologies, including prolate spheroids, cones, or bipolar shapes. Although most of these objects show no signs of rotation, we do observe significant polarization vectors aligned parallel to the main axes of several cores, which may suggest the influence of magnetic fields. These results indicate that many of the clouds were formed as a result of large-scale gravitational collapse rather than being supported by rotation. This research is supported by NASA grant NNX10AC99G. In summary, we conclude that our study of dense molecular gas clumps within the Orion Nebula reveals that 80% are oblate spheroids, while 20% exhibit more intricate shapes. Most of these clumps appear to lack internal rotation, although some do show polarization axes that are perpendicular to their major axes, indicating the potential presence of magnetic waves.",
        "ori-fast-z-score": -0.329292779969071,
        "water-fast-z-score": 5.965587590013045,
        "rewrite-fast-z-score": 0.11547005383792514
    },
    {
        "original_text": "We present the results of an investigation into the physical nature of polar broad absorption line quasars (BALQSOs). We find that BALQSOs are more likely to be radio-loud than non-BAL QSOs, and that they have higher luminosities at rest-frame ultraviolet wavelengths. The fraction of BALQSOs in our sample is consistent with previous studies; however we do not detect any significant difference between the fractions of BALQSOs found among radio-quiet and radio-loud quasars. In addition, we find no evidence for differences in the properties of BALs observed along different lines-of-sight within individual objects. Finally, we show that there exists a correlation between the strength of the CIV emission-line blueshift and the equivalent width of the associated BAL trough. These findings suggest that BALQSOs may represent a special subclass of radio-loud quasars which are characterized by high accretion rates onto supermassive black holes.",
        "watermark_text": "We present the conclusion of an research into the physical nature of polar wide absorption line quasars ( BALQSOs ) . We see that BALQSOs are more likely to be radio - loud than non - BAL QSOs , and that they have greater luminosities at rest - frame ultraviolet wavelengths .The percentage of BALQSOs in our sample is compatible with previous research ; however we do not detect any large change between the fractions of BALQSOs discovered among radio - quiet and radio - loud quasars . In addition , we find no evidence for variations in the properties of BALs observed along various lines - of - view within particular objects .Finally , we prove that there exists a correlation between the strength of the CIV radiation - line blueshift and the equivalent size of the associated BAL trough . These conclusions propose that BALQSOs might represent a unique subclass of radio - loud quasars which are marked by high accretion speeds onto supermassive black holes .",
        "rewrite_text": "We present the findings of a study focused on the physical characteristics of polar broad absorption line quasars (BALQSOs). Our results indicate that BALQSOs are more likely to exhibit radio loudness compared to non-BAL QSOs and possess higher luminosities in the rest-frame ultraviolet spectra. The proportion of BALQSOs in our sample aligns with previous studies; however, we do not observe significant differences in the presence of BALQSOs between radio-quiet and radio-loud quasars. Furthermore, we find no evidence of variations in the properties of BALs when viewed from different angles within individual quasars. Lastly, we establish a correlation between the strength of the CIV emission line blueshift and the equivalent width of the corresponding BAL trough. These findings suggest that BALQSOs may represent a distinct subclass of radio-loud quasars characterized by high accretion rates onto supermassive black holes.",
        "ori-fast-z-score": 0.5,
        "water-fast-z-score": 6.573840933228048,
        "rewrite-fast-z-score": -0.3779644730092272
    },
    {
        "original_text": "The SIM PlanetQuest mission is the most promising near-term technique for detecting, finding masses, and determining three-dimensional orbits of nearby habitable planets.  This article describes how SIM PlanetQuest will find these planets by measuring their astrometric wobble as they transit in front of their parent stars.   It also discusses how SIM PlanetQuest can be used to detect other types of exoplanets such as those with large orbital eccentricities or that are on highly inclined orbits relative to our line-of-sight.    Finally, it presents some preliminary results showing what we might expect to learn about extrasolar planetary systems using this new instrumentation. Keywords: Extrasolar planet, Astrometry, SIM PlanetQuest, Transit detection, Mass measurement, Orbital determination. 1 Introduction   In recent years there has been an explosion in interest in discovering extra-solar terrestrial planets (exo-Earths) because of the possibility that one may harbor life like Earth does. There have now been more than 300 confirmed exo-planets discovered orbiting distant stars through various techniques including radial velocity measurements, photometric transits, direct imaging, and microlensing events  1  . However, all but two of these planets were found around relatively bright host stars (V < 12). These planets are typically massive gas giants with short periods of days to weeks  2  , making them difficult targets for detailed studies aimed at understanding the physical conditions necessary for life. For example, only three of these planets have measured masses: HD 209458b  3  , GJ 436b  4  , and OGLE-TR-561b  5  .  Of these, only HD 209458b has a radius determined directly  6  .\n2\n\nSIM PlanetQuest Mission Overview\nIn order to study the atmospheres and surfaces of smaller, cooler planets, which are likely candidates for hosting liquid water  7, 8  , astronomers need to find planets around fainter stars. To do so requires space-based observatories capable of obtaining high-precision astrometric data over many years. Such observations would allow us to measure the positions of thousands of faint stars simultaneously with precisions better than 0",
        "watermark_text": "The SIM PlanetQuest mission is the most exciting near - term technique for detecting , finding masses , and determining three - dimensional orbits of nearby habitable planets . This page describes how SIM PlanetQuest will locate these planets by monitoring their astrometric wobble as they travel in front of their father planets .It additionally outlines how SIM PlanetQuest can be used to locate other types of exoplanets such as those with large orbital eccentricities or that are on highly inclined planets relative to our line - of - sight . Finally , it presents some preliminary results showing what we may expect to find about extrasolar planetary structures using this new instrumentation .Keywords : Extrasolar planet , Astrometry , SIM PlanetQuest , Transit detection , Mass calculation , Orbital measurement . 1 Introduction In recent years there has been an explosion in interest in discovering extra - solar terrestrial worlds ( exo - Earths ) because of the prospect that one may harbor living like Earth does .There have now been more than 300 verified exo - planets discovered orbiting distant stars through several methods namely radial speed measurements , photometric transits , direct scanning , and microlensing events 1 . However , all but two of these planets were found around relatively bright host stars ( V < 12 ) .These worlds are typically massive gas giants with short periods of weeks to weeks 2 , making them difficult targets for detailed analyses aimed at studying the physical conditions crucial for life . For instance , only three of these planets have recorded masses : HD 209458b 3 , GJ 436b 4 , and OGLE - TR - 561b 5 .Of these , only HD 209458b has a diameter determined directly 6 . 2 SIM PlanetQuest Mission Overview In try to study the atmospheres and surfaces of tiny , cooler planets , which are likely candidates for hosting liquid water 7 , 8 , astronomers need to find planets around fainter stars .To do so requires space - based observatories capable of acquiring high - precision astrometric data over numerous years . Such observations would enable us to measure the places of thousands of distant stars simultaneously with precisions higher than 0",
        "rewrite_text": "The SIM PlanetQuest mission represents a groundbreaking approach to detecting and analyzing nearby habitable planets by measuring their masses and determining their three-dimensional orbits. This page details how SIM PlanetQuest will identify these planets by observing their astrometric wobble as they transit in front of their host stars. Additionally, it explains the mission's potential to locate different types of exoplanets, including those with significant orbital eccentricities or inclined orbits relative to our line of sight. Lastly, it shares preliminary findings that suggest what we might learn about the structure of extrasolar planetary systems using this innovative technology. \n\n**Keywords:** Extrasolar planet, Astrometry, SIM PlanetQuest, Transit detection, Mass calculation, Orbital measurement.\n\n**1. Introduction**  \nRecent years have seen a surge of interest in the search for extrasolar terrestrial worlds (exo-Earths), driven by the possibility that some may support life as Earth does. Over 300 confirmed exoplanets have been discovered orbiting distant stars through various techniques, including radial velocity measurements, photometric transits, direct imaging, and gravitational microlensing events. However, nearly all of these planets (with the exception of two) orbit relatively bright host stars (with magnitudes less than 12). Most of these bodies are massive gas giants with short orbital periods, posing challenges for detailed studies needed to assess conditions conducive to life. For example, only three of these exoplanets have measured masses: HD 209458b, GJ 436b, and OGLE-TR-561b. Of these, only HD 209458b has a directly measured diameter.\n\n**2. SIM PlanetQuest Mission Overview**  \nTo study the atmospheres and surfaces of smaller, cooler planets that are likely candidates for harboring liquid water, astronomers need to identify planets orbiting fainter stars. Achieving this requires space-based observatories capable of gathering high-precision astrometric data over many years. Such observations would allow us to simultaneously measure the positions of thousands of distant stars with precision surpassing 0.",
        "ori-fast-z-score": 0.7373087284671365,
        "water-fast-z-score": 7.505553499465135,
        "rewrite-fast-z-score": 0.16666666666666666
    },
    {
        "original_text": "We study the dynamics of particles suspended in an idealized, two-dimensional turbulent jet using direct numerical simulations (DNS). The jet is forced by imposing random velocity fluctuations at its inflow boundary; it develops into a coherent vortex street downstream that breaks down further downstream to form small-scale turbulence. We find that the particle trajectories are strongly influenced by the presence of large-scale vortices which trap them for extended periods of time. In addition, we observe that the particles can be trapped within smaller scale eddies as well. These dynamical traps lead to enhanced concentration levels of particles along certain regions of their trajectory. Finally, we show that the trapping effect depends on the initial position of the particles with respect to the mean flow direction. Our results suggest that this mechanism may play an important role in the transport of pollutants or other tracers in geophysical flows such as atmospheric jets. Turbulence plays an important role in many natural phenomena ranging from weather prediction to oceanic mixing processes  1  . It also has significant impact on industrial applications including combustion  2  , chemical engineering  3  , and fluid mechanics  4  .\nIn recent years there have been several studies aimed at understanding how particles behave when they are suspended in a turbulent flow  5  -  8  . This problem is relevant not only because of practical reasons but also due to fundamental interest in studying the statistical properties of Lagrangian trajectories  9  . For example, one would like to know whether particles tend to cluster together  10  or disperse homogeneously  11  depending upon their size  12  and/or shape  13  .",
        "watermark_text": "We research the dynamics of molecules held in an idealized , two - dimensional turbulent jet using direct numerical simulations ( DNS ) . The plane is displaced by imposing random momentum fluctuations at its inflow boundary ; it develops into a coherent vortex road downstream that broke down further downstream to form small - scale turbulence .We see that the particle trajectories are strongly altered by the presence of large - scale vortices which trapping them for extended times of time . In addition , we find that the molecules can be trapped within large scale eddies as well .These dynamical trapping result to heightened density levels of molecules along particular regions of their path . Finally , we find that the capturing phenomenon depends on the first configuration of the particles with regard to the mean flow path .Our results show that this mechanism may play an important role in the movement of pollutants or other tracers in geophysical flows such as atmospheric jets . Turbulence holds an important role in many natural observations ranging from weather prediction to oceanic mixing mechanisms 1 .It additionally has significant effect on industrial applications notably combustion 2 , chemical engineering 3 , and fluid engineering 4 . In recent years there have been numerous research targeted at studying how molecules react when they are suspended in a turbulent flow 5 - 8 .This problem is relevant not only because of practical reasons but also owing to essential interest in examining the statistical characteristics of Lagrangian trajectories 9 . For instance , one would like to see whether particles tend to group together 10 or disperse homogeneously 11 varying upon their shape 12 and / or shape 13 .",
        "rewrite_text": "We investigate the behavior of molecules in an idealized two-dimensional turbulent jet through direct numerical simulations (DNS). By introducing random momentum fluctuations at the inflow boundary, the system develops a coherent vortex structure downstream, which eventually transitions into small-scale turbulence. Our findings indicate that particle trajectories are significantly influenced by the presence of large-scale vortices, which can trap the particles for extended periods. Additionally, we observe that molecules can also become trapped within large-scale eddies, leading to increased density levels in certain areas along their paths. Moreover, the trapping phenomenon appears to be influenced by the initial arrangement of the particles in relation to the mean flow path. These results suggest that such mechanisms could be crucial in understanding the transport of pollutants and other tracers within geophysical flows, like atmospheric jets. Turbulence is a vital factor in various natural phenomena, from weather forecasting to ocean mixing processes. It also has considerable implications for industrial applications, particularly in combustion, chemical engineering, and fluid dynamics. Recent research has focused on how molecules behave when suspended in turbulent flows, which is important not only for practical reasons but also for examining the statistical properties of Lagrangian trajectories. For example, researchers are interested in whether particles tend to cluster together or disperse uniformly, influenced by their shape and characteristics.",
        "ori-fast-z-score": -1.227881227029841,
        "water-fast-z-score": 7.7181105699018575,
        "rewrite-fast-z-score": 0.09407208683835973
    },
    {
        "original_text": "Quantum zero-knowledge proofs are quantum protocols that allow one party to prove knowledge of some secret information without revealing any other information about it.  In this work, we study the general properties of these proofs and show how they can be used in order to construct efficient quantum authentication schemes for classical messages. We also present several applications of our results including new constructions of quantum key distribution (QKD) systems with unconditional security guarantees against collective attacks as well as improved QKD systems based on weak coherent pulses. Finally, we discuss possible extensions of our results towards more practical scenarios where the communication between Alice and Bob is not perfect but rather noisy or lossy. Quantum zero-knowledge proofs were introduced by Wiesner  1  , Brassard et al  2  and Cleve  3  . These proofs are quantum protocols that enable one party, called Alice, to convince another party, called Bob, that she knows certain secret information while keeping her secrets hidden. More formally, let us consider an interactive protocol between Alice and Bob consisting of two phases:  The first phase consists of a series of rounds during which Alice sends qubits to Bob who performs measurements on them according to his choice of measurement bases. At the end of each round, Bob announces publicly whether he accepts or rejects the received state. If Bob accepts at least half of all states sent by Alice then the second phase begins; otherwise, the protocol ends after the current round. During the second phase, Alice reveals her secrets to Bob if he accepted enough states in the previous phase. Otherwise, both parties abort the protocol. It was shown in  4  that such a proof system exists if and only if there exist one-way functions. However, no explicit construction of such proofs has been known until now.",
        "watermark_text": "Quantum zero - knowledge proofs are quantum mechanisms that enable one party to confirm knowledge of some secret information without revealing any other information about it . In this research , we study the general properties of these proofs and know how they can be used in order to build efficient quantum authentication schemes for classical messages .We also discuss various uses of our findings including novel constructions of quantum key distribution ( QKD ) networks with unconditional security assurance against collective assaults as well as improved QKD schemes using on weak coherent pulses . Finally , we explain possible extend of our findings towards more feasible situations where the interaction between Alice and Bob is not good but rather noisy or lossy .Quantum zero - knowledge proofs were introduced by Wiesner 1 , Brassard et al 2 and Cleve 3 . These proofs are quantum mechanisms that enable one party , called Alice , to reassure another party , called Bob , that she knows particular hidden information while maintaining her knowledge hidden .More technically , let us consider an interactive procedure between Alice and Bob composed of two phases : The first phase involves of a sequence of rounds during which Alice releases qubits to Bob who takes measurements on them based to his choice of measurement bases . At the end of each round , Bob declares publicly whether he agrees or accepts the received state .If Bob accepts at least half of all states sent by Alice then the second phase begins ; otherwise , the protocol ends after the present round . During the second phase , Alice reveals her secrets to Bob if he accepted sufficient states in the previous phase .Otherwise , both parties abort the method . It was shown in 4 that such a proof method exists if and only if there exist one - way functions .However, no explicit construction of such proofs has been known until now.",
        "rewrite_text": "Quantum zero-knowledge proofs are quantum techniques that allow one party, known as Alice, to demonstrate to another party, Bob, that she possesses specific confidential information without disclosing any additional details about it. In this research, we examine the fundamental characteristics of these proofs and explore their application in creating efficient quantum authentication systems for classical messages. We also highlight various implications of our findings, including innovative designs for quantum key distribution (QKD) networks that offer unconditional security against collective attacks, as well as enhancements to QKD schemes that utilize weak coherent pulses. Furthermore, we discuss how our insights can extend to scenarios where the interaction between Alice and Bob is suboptimal, such as in noisy or lossy environments. Quantum zero-knowledge proofs were originally introduced by Wiesner, Brassard et al., and Cleve. These proofs enable Alice to assure Bob of her knowledge of certain hidden information while keeping that knowledge concealed. More specifically, an interactive process occurs between Alice and Bob, consisting of two phases: In the first phase, Alice sends qubits to Bob, who measures them according to his chosen measurement bases. After each round, Bob publicly indicates whether he accepts the state he received. If Bob accepts at least half of the states sent by Alice, the second phase proceeds; otherwise, the protocol concludes after the current round. In the second phase, Alice discloses her secrets to Bob if he accepted a sufficient number of states in the previous phase; if not, both parties terminate the procedure. It has been established that such a proof method exists if and only if one-way functions are available; however, no explicit constructions of these proofs have been identified until now.",
        "ori-fast-z-score": -0.5937322507759797,
        "water-fast-z-score": 6.484569792212196,
        "rewrite-fast-z-score": 1.153563462240948
    },
    {
        "original_text": "We present an analytical model for high-order harmonic generation (HHG) in diatomic molecules, which is based on the concept of molecular orbitals and their associated electronic wavefunctions. The HHG process can be understood as a sequence of three steps: First, electrons are ionized by strong laser fields. Second, they propagate through the continuum until rescattering with parent ions occurs. Third, these returning electrons emit high harmonics when interacting again with the driving field. We show that this picture leads to a simple expression for the emitted harmonic intensity, which depends only on two parameters characterizing the molecule s orbital structure. This result allows us to explain the observed interference patterns between different harmonics in terms of destructive or constructive interferences between contributions from different molecular orbits. In addition, we demonstrate how our approach can be used to predict the emission properties of new types of molecules. High-order harmonic generation (HHG), i.e., the coherent emission of photons at odd multiples of the fundamental frequency of intense femtosecond laser pulses, has attracted considerable interest over recent years  1, 2  . It provides access to extreme ultraviolet radiation  3  , which enables novel applications such as attosecond pulse generation  4  , photoelectron spectroscopy  5  , and tomography  6  .\nThe underlying physical mechanism behind HHG was first explained within the semiclassical three-step model  7, 8  : An electron tunnels out of its atomic core into the continuum upon interaction with the electric field of the laser light. Afterwards it propagates freely before being driven back towards the nucleus by the same field. Finally, it recombines with the parent ion emitting a photon whose energy equals the sum of the kinetic energy gained during propagation and the binding energy lost due to tunneling  9  . Since then, several extensions have been developed  10  including the so-called quantum-orbit theory  11  , which takes into account the influence of the nuclear potential on the electron dynamics  12  . However, despite all efforts made so far, there still exist many open questions regarding the microscopic origin of HHG  13  .",
        "watermark_text": "We present an analytical theory for high - order harmonic production ( HHG ) in diatomic molecules , which is based on the idea of molecular orbitals and their accompanying electronic wavefunctions . The HHG process can be understood as a sequence of three stages : First , electrons are ionized by intense laser fields .Second , they propagate through the continuum until rescattering with mother ions happens . Third , these returning electrons emit large harmonics when interacting again with the driving field .We see that this picture leads to a simple expression for the emitted harmonic intensity , which depends only on two parameters characterizing the molecule s orbital structure . This result allows us to explain the seen interference patterns between various harmonics in terms of destructive or constructive interferences between contributions from different molecular orbits .In addition , we prove how our approach can be used to predict the emission behavior of new types of molecules . High - order harmonic production ( HHG ) , i . e . , the coherent emission of photons at odd multiples of the fundamental frequency of active femtosecond infrared signals , has garnered considerable interest over recent periods 1 , 2 .It provides entry to extreme ultraviolet radiation 3 , which enables novel applications such as attosecond pulse production 4 , photoelectron spectroscopy 5 , and tomography 6 . The fundamental physical process behind HHG was first explained within the semiclassical three - stepping model 7 , 8 : An electron tunnels out of its atomic backbone into the continuum upon interference with the electric field of the laser light .Afterwards it propagates freely before being driven back towards the nucleus by the same field . Finally , it recombines with the parent ion emitting a photon whose power equals the sum of the kinetic power gained during propagation and the binding energy gain due to tunneling 9 .Since then , various extensions have been created 10 including the so - called quantum - orbit concept 11 , which gives into consideration the impact of the atomic potential on the electron mechanics 12 . However , despite all efforts made so far , there still appear many open questions regarding the microscopic ancestry of HHG 13 .",
        "rewrite_text": "We introduce an analytical theory for high-order harmonic generation (HHG) in diatomic molecules, which is grounded in the concept of molecular orbitals and their corresponding electronic wavefunctions. The HHG process can be delineated into three phases: Initially, electrons are ionized by intense laser fields; subsequently, they travel through the continuum until they undergo rescattering with the parent ions; finally, these returning electrons emit high-frequency harmonics upon interacting again with the driving field. This framework leads to a straightforward expression for the emitted harmonic intensity, which relies solely on two parameters reflecting the molecular orbital structure. Consequently, we can interpret the observed interference patterns among different harmonics as resulting from either constructive or destructive interference originating from contributions of various molecular orbits. Additionally, we demonstrate that our approach can forecast the emission characteristics of new types of molecules. High-order harmonic generation (HHG), characterized by the coherent emission of photons at odd multiples of the fundamental frequency of active femtosecond infrared signals, has recently attracted significant attention. This phenomenon serves as a gateway to extreme ultraviolet radiation, facilitating innovative applications such as the generation of attosecond pulses, photoelectron spectroscopy, and tomography. The fundamental mechanism underlying HHG was initially described through the semiclassical three-step model: an electron tunnels from its atomic core into the continuum due to the influence of the laser's electric field. It then propagates freely before being driven back to the nucleus by the same field. Finally, upon recombination with the parent ion, it emits a photon, the energy of which corresponds to the sum of the kinetic energy gained during its propagation and the binding energy lost during tunneling. Since then, various extensions have emerged, including the quantum-orbit concept, which accounts for the effects of atomic potential on electron dynamics. Nevertheless, despite these advancements, many fundamental questions remain concerning the microscopic origins of HHG.",
        "ori-fast-z-score": 0.8111071056538127,
        "water-fast-z-score": 7.786628214276602,
        "rewrite-fast-z-score": 2.301585822275002
    },
    {
        "original_text": "We study noise-induced phase transitions in systems with multiplicative white Gaussian, Poissonian or Lévy noise. We show that for all these three types of noise there is an optimal noise intensity at which the system undergoes a transition to a state where it performs better than without noise. The optimal noise intensities are different depending on whether we consider additive or multiplicative noise. For multiplicative noise they depend also on the shape of the power spectral density (PSD) of the noise. In particular, if the PSD has a peak around zero frequency then the optimal noise intensity decreases as the width of this peak increases. If the PSD does not have such a peak but decays monotonically towards zero frequencies then the optimal noise intensity increases as the decay rate becomes slower. Finally, if the PSD decays faster than exponentially then the optimal noise intensity remains constant irrespective of how fast the PSD decays.",
        "watermark_text": "We work noise - caused phase transitions in networks with multiplicative white Gaussian , Poissonian or Lévy noise . We see that for all these three sorts of noise there is an appropriate sound amplitude at which the system undergoes a shift to a state where it performs better than without noise .The appropriate sound intensities are different depending on whether we choose additive or multiplicative sound . For multiplicative sound they rely also on the shape of the power spectral coefficient ( PSD ) of the signal .In particular , if the PSD has a peak around zero frequency then the ideal noise amplitude decreases as the length of this peak rises . If the PSD does not have such a peak but decays monotonically nearer zero amplitude then the ideal noise amplitude rises as the decay rate gets smaller .Finally , if the PSD decays faster than exponentially then the ideal noise amplitude remains constant irrespective of how far the PSD decays .",
        "rewrite_text": "We investigate noise-induced phase transitions in networks influenced by multiplicative white Gaussian, Poissonian, and Lévy noise. Our findings indicate that for each of these noise types, there exists an optimal sound amplitude at which the system transitions to a more efficient state compared to when no noise is present. The specific sound intensities required vary based on whether the sound is additive or multiplicative. In the case of multiplicative noise, they are also influenced by the characteristics of the power spectral density (PSD) of the signal. Notably, if the PSD exhibits a peak near zero frequency, the ideal noise amplitude decreases with an increase in the length of this peak. Conversely, if the PSD lacks such a peak and instead decreases monotonically as it approaches zero frequency, the optimal noise amplitude increases as the decay rate becomes slower. Lastly, if the PSD decays at a rate faster than exponentially, the ideal noise amplitude remains constant regardless of the extent of the PSD's decay.",
        "ori-fast-z-score": -1.778001778002667,
        "water-fast-z-score": 5.669467095138408,
        "rewrite-fast-z-score": 2.6558112382722783
    },
    {
        "original_text": "We compare the magnetic flux distribution in coronal holes (CHs) with that in quiet regions using vector magnetograms observed by Hinode/SOT/SP. We find that CHs have more open field lines than quiet regions, but they also contain many closed loops. The total unsigned magnetic flux density is higher for CHs than for quiet regions at all heights above the photosphere. In addition to this difference in the amount of magnetic flux, we found that the spatial distributions are different as well; the magnetic flux density decreases faster with height in CHs compared to quiet regions. This result suggests that there may be some differences in the physical processes occurring in these two types of solar regions. Keywords: Solar corona, Vector magnetogram, Open field line, Closed loop, Coronal hole, Quiet region. 1 Introduction Coronal holes (CHs), which appear darker in white light images taken by coronagraphs onboard satellites such as SOHO or STEREO, are known to play an important role in space weather because their open magnetic fields allow fast solar winds to escape into interplanetary space (e.g., Wang et al. (1998) , Cranmer & van Ballegooijen (2005) ).\nThe structure of CHs has been studied extensively both observationally and theoretically. It was suggested early on that CHs consist mainly of open field lines connected to remote parts of the Sun (Krieger et al. (1971) ), while closed loops were rarely seen inside them (Wiegelmann et al. (2010a) ). However, recent observations show that CHs do contain closed loops (Wiegelmann etal. (2010b) , Parnell et al. (2011 ), DeForest et al. (2013 , Brooks et al. (2014) ). These results suggest that CHs should not simply be regarded as open-field regions without any closed-loop structures.",
        "watermark_text": "We relate the magnetic flux spread in coronal holes ( CHs ) with that in quiet regions using vector magnetograms observed by Hinode / SOT / SP . We see that CHs have more open field lines than quiet regions , but they still hold several shut rings .The total unsigned magnetic flux concentration is higher for CHs than for calm regions at all heights above the photosphere . In addition to this contrast in the quantity of magnetic flux , we reported that the spatial distributions are distinct as well ; the magnetic flux concentration drops quicker with depth in CHs compared to quiet regions .This result suggests that there may be some variations in the physical processes arising in these two kind of sun areas . Keywords : Solar corona , Vector magnetogram , Open field system , Closed loop , Coronal hole , Quiet region .1 Introduction Coronal holes ( CHs ) , which appear darker in white light pictures taken by coronagraphs onboard satellites such as SOHO or STEREO , are known to play an important role in space weather because their open magnetic fields allow strong sun winds to escape into interplanetary space ( e . g . , Wang et al . ( 1998 ) , Cranmer & van Ballegooijen ( 2005 ) ) .The structure of CHs has been studied frequently both observationally and theoretically . It was suggested early on that CHs consist mostly of open field lines linked to remote parts of the Sun ( Krieger et al .( 1971 ) ) , while closed loops were seldom visible inside them ( Wiegelmann et al . ( 2010a ) ) .However , recent observations show that CHs do contain shut loops ( Wiegelmann etal . ( 2010b ) , Parnell et al .( 2011 ) , DeForest et al . ( 2013 , Brooks et al .( 2014 ) ) . These conclusions show that CHs should not simply be regarded as open - field regions without any closed - loop fields .",
        "rewrite_text": "We examine the distribution of magnetic flux in coronal holes (CHs) compared to quiet regions using vector magnetograms from Hinode/SOT/SP. Our analysis reveals that CHs have a greater number of open magnetic field lines than quiet regions, yet they still contain several closed magnetic loops. Across all heights above the photosphere, the total unsigned magnetic flux concentration is consistently higher in CHs than in tranquil areas. Additionally, we note distinct differences in the spatial distributions: the concentration of magnetic flux decreases more rapidly with depth in CHs than in quiet regions. This finding implies that there may be variations in the underlying physical processes occurring in these two types of solar areas. \n\n**Keywords**: Solar corona, Vector magnetogram, Open field system, Closed loop, Coronal hole, Quiet region.\n\n**1 Introduction**: Coronal holes (CHs), which appear darker in white light images captured by coronagraphs on satellites such as SOHO and STEREO, play a significant role in space weather due to their open magnetic fields that facilitate strong solar winds escaping into interplanetary space (e.g., Wang et al. 1998; Cranmer & van Ballegooijen 2005). Both observational and theoretical studies have frequently explored the structure of CHs. Early hypotheses suggested that CHs predominantly consist of open field lines connected to distant regions of the Sun (Krieger et al. 1971), with closed loops rarely observed within them (Wiegelmann et al. 2010a). However, recent studies have indicated that closed loops do exist within CHs (Wiegelmann et al. 2010b; Parnell et al. 2011; DeForest et al. 2013; Brooks et al. 2014). These findings suggest that CHs should not merely be classified as open-field regions devoid of closed-loop structures.",
        "ori-fast-z-score": -0.44367825470805694,
        "water-fast-z-score": 5.833630944789017,
        "rewrite-fast-z-score": -0.25819888974716115
    },
    {
        "original_text": "The metal-insulator phase diagram of the quasi-one dimensional organic conductor (TMTSF2)2SO3 has been investigated using infrared spectroscopy and scanning tunneling microscopy at temperatures down to 20 mK. The temperature dependence of the optical conductivity shows that the charge gap opens below TMI = 135 K, which is consistent with previous results obtained on single crystals grown under different conditions. In addition we find evidence for an additional energy scale associated with the formation of excitons near 50 meV. We show that this feature can be explained within a simple model based on electron-phonon interaction between molecular orbitals. Finally, our data reveal that the electronic structure changes significantly across the metal-insulator transition. This finding suggests that the insulating state may not simply result from localization effects but rather involves strong correlations among electrons. The metal-insulator phase diagram was studied in detail by infrared spectroscopy and scanning tunnel microscopy experiments performed on high-quality single crystals of (TMTSF)2SO3. Our measurements provide direct spectroscopic evidence for two distinct energy scales involved in the opening of the charge gap as well as for significant modifications of the electronic structure across the metal-insulator boundary.",
        "watermark_text": "The metal - insulator phase diagram of the quasi - one dimensional organic conductor ( TMTSF2 ) 2SO3 has been investigated using infrared spectroscopy and scanning tunneling microscopy at conditions down to 20 mK . The temperature dependence of the optical conductivity reveals that the charge gap opens below TMI = 135 K , which is compatible with previous findings obtained on double particles grown under various circumstances .In addition we find proof for an additional power range involved with the formation of excitons near 50 meV . We see that this phenomenon can be described within a simple model based on electron - phonon interaction between molecular orbitals .Finally , our evidence reveal that the electronic configuration changes significantly across the metal - insulator transition . This conclusion suggests that the insulating state may not simply result from localization effects but rather includes weak correlations among electrons .The metal - insulator phase diagram was studied in detail by infrared spectroscopy and scanning tunnel microscopy experiments conducted on well - grade single crystals of ( TMTSF ) 2SO3 . Our measurements give direct spectroscopic evidence for two separate power scales implicated in the opening of the charge gap as well as for significant modifications of the electronic configuration across the metal - insulator boundary .",
        "rewrite_text": "The metal-insulator phase diagram of the quasi-one-dimensional organic conductor (TMTSF)2SO3 has been examined using infrared spectroscopy and scanning tunneling microscopy at temperatures as low as 20 mK. Our investigation reveals that the optical conductivity shows a temperature dependence indicating that the charge gap emerges below TMI = 135 K, which aligns with prior studies on double particles grown under various conditions. Additionally, we identify evidence of another energy scale involved in the formation of excitons near 50 meV. This phenomenon can be effectively explained by a straightforward model that considers electron-phonon interactions among molecular orbitals. Furthermore, our findings indicate significant changes in the electronic configuration during the metal-insulator transition, suggesting that the insulating state may not merely arise from localization effects, but also includes weak electron correlations. Overall, our detailed studies using infrared spectroscopy and scanning tunneling microscopy on high-quality single crystals of (TMTSF)2SO3 provide direct spectroscopic evidence for two distinct energy scales related to the opening of the charge gap, as well as notable alterations in the electronic configuration across the metal-insulator boundary.",
        "ori-fast-z-score": 0.8164965809277261,
        "water-fast-z-score": 6.193611607315077,
        "rewrite-fast-z-score": 1.1659976680069961
    },
    {
        "original_text": "We study the evaporation process of black holes (BHs) in an expanding universe by using the tunneling method and the WKB approximation. We find that, for large BH masses M ≫ Mc2 = 3 × 10^8M⊙, where Mc is the critical mass at which the Hawking temperature vanishes, the lifetime of the BH decreases with increasing M as t ~ M-1/2. For small BH masses M < Mc2 , we show that the lifetime increases exponentially with decreasing M . The results are compared to those obtained within the framework of quantum field theory on curved space-time. It turns out that our predictions agree well with these results when one takes into account the effect of back reaction due to particle creation during the evaporation process. \nPACS numbers: 04.20.-q; 98.80.Cq \nI. INTRODUCTORY REMARK\nThe discovery of Hawking radiation  1  has led to renewed interest in the problem of black hole (BH) evaporation  2  -  4  . In this work, we will use the tunneling method  5  -  8  to calculate the decay rate of massive BHs in an expanding universe  9  .\nII. BLACK HOLE EVAPORATION IN AN EXPANDING UNIVERSE\n\nA. Tunneling Method\nIn order to apply the tunneling method to the case of evaporating BHs, it is convenient to introduce new coordinates (t′, r′), related to the original ones (t,r) through the following transformations  10  :",
        "watermark_text": "We explore the evaporation process of brown holes ( BHs ) in an evolving galaxy by using the tunneling procedure and the WKB approximation . We see that , for large BH masses M [UNK] Mc2 = 3 × 10 ^ [UNK] , where Mc is the critical mass at which the Hawking temperature vanishes , the life of the BH decreases with expanding M as t ~ M - 1 / 2 .For small BH masses M < Mc2 , we find that the life grows exponentially with varying M . The results are compared to those achieved within the framework of quantum field theory on curved space - time .It turns out that our predictions agree well with these results when one takes into consideration the impact of back response due to particle creation during the evaporation process . PACS codes : 04 . 20 . - q ; 98 . 80 . Cq I .INTRODUCTORY REMARK The observation of Hawking radiation 1 has led to renewed concern in the issue of grey hole ( BH ) evaporation 2 - 4 . In this research , we will use the tunneling method 5 - 8 to estimate the decay rate of large BHs in an evolving galaxy 9 .II . BLACK HOLE EVAPORATION IN AN EXPANDING UNIVERSE A . Tunneling Method In order to apply the tunneling procedure to the case of evaporating BHs , it is convenient to introduce different coordinates ( t ′ , r ′ ) , related to the previous ones ( t , r ) through the following transformations 10 :",
        "rewrite_text": "We investigate the evaporation process of black holes (BHs) within a dynamic galaxy using the tunneling method and the WKB approximation. Our findings indicate that for large BH masses \\( M \\) (where \\( M c^2 = 3 \\times 10 \\)), the lifespan of the BH decreases with increasing mass, following the relationship \\( t \\sim M^{-1/2} \\). Conversely, for smaller BH masses (\\( M < Mc^2 \\)), we observe that the lifespan increases exponentially with changes in mass. We compare our results to those obtained from quantum field theory in curved spacetime, discovering that our predictions align well with those findings, particularly when considering the effects of backreaction from particle creation during the evaporation. The observation of Hawking radiation has reignited interest in the topic of BH evaporation. In this study, we apply the tunneling method to estimate the decay rate of massive BHs in an expanding galaxy. \n\nTo implement the tunneling approach for evaporating BHs, we find it convenient to employ a different set of coordinates \\((t', r')\\), which are related to the original coordinates \\((t, r)\\) through specific transformations.",
        "ori-fast-z-score": 0.6546536707079772,
        "water-fast-z-score": 6.546536707079771,
        "rewrite-fast-z-score": -1.1952286093343936
    },
    {
        "original_text": "We present new observations of the outflow driven by the young star cluster NGC 1333 IRAS 4A, located at the center of the Perseus molecular cloud (d = 235 pc). The data were obtained with the Submillimeter Array and include continuum emission at 1.3 mm as well as CO(2-1) line emission. We find that the outflow is highly collimated along an axis oriented NNE-SSW, which coincides with the direction to the nearby Herbig-Haro objects HH 7-11. The total mass of the outflowing gas is estimated to be ~0.1 Msun, while its kinetic energy amounts to ~10^50 ergs. These values are comparable to those found for other low-mass protostellar systems. However, we also detect significant differences between this system and others previously studied. In particular, our results suggest that the outflow may have been triggered recently due to the interaction of the central source with another object or structure within the dense core surrounding it.",
        "watermark_text": "We report new images of the outflow generated by the young star cluster NGC 1333 IRAS 4A , located at the center of the Perseus molecular storm ( d = 235 pc ) . The data were obtained with the Submillimeter Array and include continuum emission at 1 . 3 cm as well as CO ( 2 - 1 ) line emission .We see that the outflow is heavily collimated along an axis oriented NNE - SSW , which coincides with the direction to the nearby Herbig - Haro objects HH 7 - 11 . The total mass of the outflowing gas is expected to be ~ 0 . 1 Msun , while its kinetic power amounts to ~ 10 ^ 50 ergs .These measurements are comparable to those shown for other low - weight protostellar systems . However , we also observe significant variations between this scheme and others earlier studied .In particular , our findings show that the outflow could have been caused recently result to the interaction of the main source with another object or system within the dense core covering it .",
        "rewrite_text": "We present new images of the outflow produced by the young star cluster NGC 1333 IRAS 4A, which is situated at the heart of the Perseus molecular cloud (distance = 235 pc). These observations were acquired using the Submillimeter Array and include both continuum emission at 1.3 cm and CO (2-1) line emission. Our results indicate that the outflow is highly collimated along a NNE-SSW axis, aligning with the nearby Herbig-Haro objects HH 7-11. The total mass of the outflowing gas is estimated to be around 0.1 Msun, and its kinetic power is approximately 10^50 ergs. These findings are comparable to those reported for other low-mass protostellar systems. However, we also note substantial differences compared to previously studied outflows. Notably, our results suggest that the outflow may have recently originated from the interaction of the main source with another object or system within the dense core surrounding it.",
        "ori-fast-z-score": -1.1338934190276817,
        "water-fast-z-score": 5.165514464459439,
        "rewrite-fast-z-score": 0.8962581595302719
    },
    {
        "original_text": "We present new near-infrared (NIR) spectra for red supergiants and giants, obtained at the European Southern Observatory in La Silla, Chile.  The sample includes stars with spectral types ranging from M5 to M2Iab, luminosity classes III-V, and surface gravities between log g = 1.0 and 3.8 dex. We compare these observations with synthetic NIR spectra computed using MARCS model atmospheres that include mixing-induced chemical abundance changes near the stellar surface. Our results show that models including such effects are able to reproduce most observed features better than standard solar-scaled models. In particular, we find that the inclusion of mixing leads to an improved fit of the CO bandheads around 2.3 microns as well as of several atomic lines. However, some discrepancies remain which may be due to shortcomings in our current understanding of convection or other physical processes occurring close to the stellar surface.",
        "watermark_text": "We present new near - infrared ( NIR ) spectra for red supergiants and giants , obtained at the European Southern Observatory in La Silla , Chile . The sample comprises stars with spectral classes ranging from M5 to M2Iab , luminosity classes III - V , and surface gravities between log f = 1 . 0 and 3 . 8 dex .We link these observations with artificial NIR spectra computed using MARCS model atmospheres that include mixing - caused chemical abundance changes near the stars surface . Our results show that estimates including such effects are able to depict most observed features good than conventional solar - scaled models .In particular , we find that the introduction of mixing gives to an better match of the CO bandheads around 2 . 3 microns as well as of several atomic lines . However , some discrepancies remain which perhaps be due to shortcomings in our future interpretation of convection or other material processes resulting close to the stars interior .",
        "rewrite_text": "We present new near-infrared (NIR) spectra of red supergiants and giants, collected at the European Southern Observatory in La Silla, Chile. The sample includes stars with spectral classifications ranging from M5 to M2Iab, luminosity classes III to V, and surface gravities between log g = 1.0 and 3.8 dex. We compare these observations with artificially generated NIR spectra, created using MARCS model atmospheres that account for chemical abundance variations due to mixing near the stellar surface. Our findings indicate that models incorporating these effects more accurately represent most observed features compared to conventional solar-scaled models. Notably, the inclusion of mixing leads to a better match for the CO bandheads around 2.3 microns and several atomic lines. However, some discrepancies persist, which may be attributed to limitations in our current understanding of convection or other material processes occurring near the stars' interiors.",
        "ori-fast-z-score": 0.36650833306891567,
        "water-fast-z-score": 5.41602560309064,
        "rewrite-fast-z-score": 0.3779644730092272
    },
    {
        "original_text": "The performance evaluation of object-oriented databases (OODBs) is an important issue in database research and development, but it has been difficult because there are many factors that affect their performances. In this study we propose VOODB as a generic discrete-event random simulation model for evaluating the performances of OODBs. The proposed model can be used with any OODB system by simply changing its configuration parameters. We have implemented our model using Visual Basic 6.0 on Windows NT 4.0 platform. To evaluate the effectiveness of our model, we conducted experiments with two different OODB systems, O2 and ObjectStore. Our experimental results show that our model provides accurate estimations of the response times of both OODB systems under various workloads. Keywords: Performance Evaluation, Database System, Object-Oriented Database Systems, Discrete Event Simulations, Response Time Prediction. 1 Introduction Object-oriented databases (OODBSs), which provide powerful data modeling capabilities such as inheritance, encapsulation, polymorphism, etc., have become increasingly popular recently  l  . However, since they support complex data structures and operations, their performances may vary widely depending upon several factors  2  .\nIn order to develop high-performance OODBSs, it is necessary to analyze how these factors influence their performances. Therefore, researchers have studied the performance evaluations of OODBSs extensively  3  , 4 , 5 , 6 , 7 , 8 , 9 , lo , 11 , 12 , 13 , 14 , 15 , 16 ,  17  , 18 , 19 ,  20  , 21 ,  22  , 23 ,  24  , 25 ,  26  , 27 ,  28  , 29 ,  30  , 31 ,  32  , 33 ,  34  , 35 ,  36  ,  37J,  38  ,  39J,  40  ,  411,  42  ,  43J,  44  ,  45J,  46  ,  47J,  48  ,  49J,  50  ,  51J,  52J,  53J,  54J,  55J,  56J,",
        "watermark_text": "The behavior evaluation of object - based databases ( OODBs ) is an important issue in database study and development , but it has been difficult because there are many factors that affect their performances . In this study we propose VOODB as a generic discrete - event random simulation system for evaluating the performances of OODBs .The proposed approach can be used with any OODB network by simply changing its setup elements . We have developed our model utilizing Visual Basic 6 . 0 on Windows NT 4 . 0 platform .To assess the performance of our model , we conducted experiments with two different OODB systems , O2 and ObjectStore . Our research results show that our model provides reliable estimations of the response periods of both OODB systems under various workloads .Keywords : Performance Evaluation , Database System , Object - Oriented Database Systems , Discrete Event Simulations , Response Time Prediction . 1 Introduction Object - oriented libraries ( OODBSs ) , which provide potent data modeling skills such as inheritance , encapsulation , polymorphism , etc . , have become increasingly popular recently f .However , since they support difficult information structures and functions , their performances may differ widely depending upon several variables 2 . In order to develop large - performance OODBSs , it is required to analyze how these considerations influence their performances .Therefore , researchers have researched the performance evaluations of OODBSs extensively 3 , 4 , 5 , 6 , 7 , 8 , 9 , lo , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37J , 38 , 39J , 40 , 411 , 42 , 43J , 44 , 45J , 46 , 47J , 48 , 49J , 50 , 51J , 52J , 53J , 54J , 55J , 56J ,",
        "rewrite_text": "The evaluation of the behavior of object-oriented databases (OODBs) is a crucial aspect of database research and development. However, this task can be challenging due to the numerous factors influencing their performance. In this study, we introduce VOODB, a flexible discrete-event random simulation system designed for assessing the performance of OODBs. This method can be adapted to any OODB network by simply modifying its configuration elements. Our model has been developed using Visual Basic 6.0 on the Windows NT 4.0 platform. To validate our model's performance, we conducted experiments with two distinct OODB systems: O2 and ObjectStore. The findings demonstrate that our model delivers accurate estimations of response times for both OODB systems across various workloads. \n\n**Keywords:** Performance Evaluation, Database System, Object-Oriented Database Systems, Discrete Event Simulations, Response Time Prediction. \n\n**1 Introduction**  \nObject-oriented databases (OODBs) have gained popularity in recent years due to their powerful data modeling capabilities, which include features like inheritance, encapsulation, and polymorphism. However, their ability to support complex data structures and functions results in performance variability influenced by several factors. To create high-performance OODBs, it is essential to analyze the impact of these factors on their performance. Consequently, extensive research has been conducted on the performance evaluation of OODBs.",
        "ori-fast-z-score": -0.7258661863112977,
        "water-fast-z-score": 5.848076606885379,
        "rewrite-fast-z-score": -0.3110855084191276
    },
    {
        "original_text": "The authors present an experimental method for determining the probability that two photons simultaneously hit pixels in a detector, as well as its spatial resolution. The method is based on measuring correlations between pairs of photons emitted by a source with known angular distribution. It can be used to characterize any type of photon-counting detector (CCD cameras, photomultipliers etc.) without requiring knowledge about their internal structure or electronics. This information may then be used to improve the performance of imaging systems such as telescopes. The results are presented for a silicon-strip detector. They show good agreement with Monte Carlo simulations. DOI: 10.1088/1742-6596/aa5e20\nSpatial resolution and coincidence resolving time measurement of Si strip detectors using single-photon counting technique \nI. INTRODUCTIO N\nIn many applications it is important to know how accurately one can determine the position where a photon hits a detector. For example this information is needed when designing optical instruments like telescopes  1  . In order to measure the spatial resolution of a detector we need to have some reference point against which we compare our measured data  2  .\nOne way to obtain this reference point is to use a light source emitting photons at a well-defined angle relative to the normal direction  3  , see Fig.  1(a) . If the detector has no intrinsic spatial resolution, all detected photons will come from a small area around the center of the detector surface. By scanning the detector over different angles θ, we can find out what fraction of the total number of counts comes from each part of the detector  4  . We call these fractions the response function R(θ) of the detector  5  . Knowing the shape of the response function allows us to calculate the spatial resolution of the detector  6  . However, if there is more than one pixel per unit solid angle, the situation becomes complicated because now several pixels could detect a given photon  7, 8  . To solve this problem we introduce here a new concept -the joint probability P ij that i-th and j-th pixels detect a photon simultaneously  9  . Using this concept together with the response function we",
        "watermark_text": "The authors present an research technique for determining the probability that two photons simultaneously struck pixels in a detector , as well as its spatial resolution . The method is based on measuring correlations between pairs of photons generated by a source with known angular distribution .It can be used to characterize any type of photon - tracking detector ( CCD cameras , photomultipliers etc . ) without using knowledge about their internal structure or electronics .This knowledge might then be used to upgrade the performance of optical applications such as telescopes . The results are presented for a silicon - strip detector .They show good agreement with Monte Carlo simulations . DOI : 10 . 1088 / 1742 - 6596 / aa5e20 Spatial resolution and coincidence resolving time measurement of Si strip detectors using single - photon counting technique I . INTRODUCTIO N In many applications it is important to consider how accurately one can determine the position where a photon hits a detector .For instance this data is required when designing optical equipment like telescopes 1 . In order to measure the spatial resolution of a detector we require to have some reference location against which we compare our measured data 2 .One method to obtain this reference location is to use a light source emitting photons at a better - defined angle relative to the normal direction 3 , see Fig . 1 ( a ) .If the sensor has no intrinsic temporal resolution , all detected photons will coming from a small area around the center of the sensor surface . By scanning the sensor over different angles θ , we can find out what fraction of the total number of counts coming from each portion of the detector 4 .We call these fractions the response function R ( θ ) of the sensor 5 . Understanding the shape of the response function allows us to estimate the spatial resolution of the sensor 6 .However , if there is more than one pixel per unit solid angle , the situation grows difficult because now multiple pixels might detect a given photon 7 , 8 . To solve this situation we approach here a new notion - the joint probability P ij that i - th and j - th pixels detect a photon simultaneously 9 .Using this concept together with the response function we",
        "rewrite_text": "The authors introduce a research methodology aimed at determining the probability that two photons concurrently hit pixels in a detector, as well as evaluating its spatial resolution. This technique relies on analyzing correlations between pairs of photons emitted by a source with a known angular distribution. It is applicable to various photon-tracking detectors, including CCD cameras and photomultipliers, without requiring insights into their internal architecture or electronics. This understanding could be leveraged to enhance the performance of optical instruments such as telescopes. Results are provided for a silicon-strip detector and demonstrate good concordance with Monte Carlo simulations (DOI: 10.1088/1742-6596/aa5e20). \n\n**Spatial resolution and coincidence resolving time measurement of Si strip detectors using single-photon counting technique: Introduction**\n\nIn many applications, accurately determining the position at which a photon impacts a detector is crucial, particularly in the design of optical instruments like telescopes. To ascertain the spatial resolution of a detector, a reference location must be established for comparison with the measured data. One approach to obtaining this reference is through a light source that emits photons at a precisely defined angle relative to the normal. If the detector lacks intrinsic temporal resolution, all detected photons will originate from a small area near the center of the sensor surface. By varying the scanning angle θ of the sensor, we can quantify the proportion of total counts attributed to each section of the detector. We refer to these proportions as the response function R(θ) of the sensor. Understanding the characteristics of this response function enables us to estimate the spatial resolution of the sensor. However, complications arise when multiple pixels occupy a unit solid angle, as more than one pixel may detect the same photon. To address this complexity, we introduce a new concept—joint probability P_ij—representing the likelihood that the i-th and j-th pixels register a photon simultaneously. By integrating this concept with the response function, we can further our analysis.",
        "ori-fast-z-score": 2.2998495985826177,
        "water-fast-z-score": 8.380035799446205,
        "rewrite-fast-z-score": 2.8295822920905516
    },
    {
        "original_text": "Circinus X-1 is an X-ray binary system with a neutron star and its companion, which has been observed in many wavelengths ranging from radio to gamma-ray bands. The source shows periodic dipping activity at X-ray energies that are caused by obscuration of the central X-ray emitting region due to matter falling onto the accretion disk around the compact object. In this work we present results obtained using data collected during two different observational campaigns carried out with Suzaku satellite (from 2005 to 2007) and INTEGRAL/IBIS telescope (from 2003 to 2009). We have analyzed the spectral properties of the source for both observations separately as well as combined together. Our analysis reveals that the spectrum can be described by a combination of several components such as: blackbody emission from the neutron star surface; Comptonized component produced by hot plasma surrounding the neutron star; reflection component originating from reprocessing of hard radiation emitted by the central X-ray source into softer photons; iron line feature arising from fluorescence of cold material located close to the neutron star.",
        "watermark_text": "Circinus X - 1 is an X - ray binary system with a neutron star and its companion , which has been observed in multiple wavelengths ranging from radio to gamma - ray bands . The source shows irregular dipping activity at X - ray energies that are created by obscuration of the main X - ray emitting area owing to matter falling onto the accretion disk around the compact body .In this project we present results collected using data taken during two different observational campaigns carried out with Suzaku spacecraft ( from 2005 to 2007 ) and INTEGRAL / IBIS telescope ( from 2003 to 2009 ) . We have analyzed the spectral properties of the origin for both surveys independently as well as combined together .Our study reveals that the spectrum can be described by a combination of several parts such as : blackbody emission from the neutron star surface ; Comptonized component produced by hot plasma surrounding the neutron star ; reflection portion arising from reprocessing of hard radiation emitted by the main X - ray source into stronger photons ; iron line feature arising from fluorescence of cold matter located close to the neutron star .",
        "rewrite_text": "Circinus X-1 is an X-ray binary system that includes a neutron star and its companion. It has been observed across various wavelengths, from radio to gamma rays. The system exhibits irregular dipping activity at X-ray energies, which is caused by the obscuration of the primary X-ray emission region due to matter falling onto the accretion disk surrounding the compact object. In this project, we present results obtained from data collected during two distinct observational campaigns using the Suzaku spacecraft (from 2005 to 2007) and the INTEGRAL/IBIS telescope (from 2003 to 2009). We analyzed the spectral characteristics of both surveys individually as well as in combination. Our findings indicate that the spectrum can be described by a combination of several components, including: blackbody emission from the surface of the neutron star, a Comptonized component generated by hot plasma surrounding the neutron star, a reflection component resulting from the reprocessing of hard radiation emitted by the primary X-ray source into higher-energy photons, and an iron line feature arising from the fluorescence of cold matter situated near the neutron star.",
        "ori-fast-z-score": 1.801996396010812,
        "water-fast-z-score": 6.041987916036252,
        "rewrite-fast-z-score": 2.225995548013356
    },
    {
        "original_text": "We propose that the dark matter (DM) and supersymmetric particles are generated by an emergent gauge symmetry at high energy scales, which is broken down to Standard Model symmetries below TeV scale. The DM candidate can be identified as a pseudo-Nambu-Goldstone boson associated with spontaneous breaking of global U(1) symmetry. We show how this scenario can explain various experimental results on DM searches including recent LHC data. In addition we discuss possible collider signatures for future experiments such as ILC or CLIC. Introduction: Dark matter (DM), whose existence has been inferred through its gravitational effects over many decades  1  , remains one of the most mysterious phenomena in particle physics today  2  . Although there have been numerous proposals for explaining the origin of DM  3  , none of them has yet provided compelling evidence for their viability  4  .\nIn this work, motivated by the idea of  emergent  theories  5  -  8  , we consider a new possibility where DM emerges from a spontaneously-broken global symmetry  9  . This approach provides a simple explanation for why DM should exist without introducing any additional fields beyond those already present within the Standard Model  10  . Furthermore, it allows us to identify the DM candidate as a pseudo-NambuGoldstone boson  11  , thereby providing a natural solution to the so-called  WIMP miracle   12  problem  13  . Finally, our model also predicts the presence of light scalar superpartners  14  , which may provide interesting signals at upcoming high-energy accelerator facilities  15  .\nThe rest of this article is organised as follows. In Sec. 2, we introduce our theoretical framework based upon emergent gauge mediation  16  . Then, in Secs. 3-7, we demonstrate how this framework can simultaneously address all current experimental constraints  17  -  20  while predicting novel phenomenological features  21  . Finally, in Sec. 8, we conclude with some remarks about further directions of research.",
        "watermark_text": "We suggest that the dark matter ( DM ) and supersymmetric particles are produced by an emergent gauge symmetry at high energy scales , which is broken down to Standard Model symmetries below TeV scale . The DM candidate can be identified as a quasi - Nambu - Goldstone boson associated with spontaneous breaking of global U ( 1 ) symmetry .We see how this situation can describe several experimental outcome on DM searches notably recent LHC evidence . In addition we explain possible collider signatures for future research such as ILC or CLIC .Introduction : Dark matter ( DM ) , whose existence has been inferred through its gravitational influences over much centuries 1 , seems one of the most obscure events in particle science today 2 . Although there have been numerous ideas for explaining the origin of DM 3 , none of them has already offered credible support for their viability 4 .In this research , driven by the idea of emergent theories 5 - 8 , we investigate a new possibility where DM appears from a spontaneously - breaking global symmetry 9 . This method provides a simple explanation for why DM should exist without removing any additional fields beyond those already found within the Standard Model 10 .Furthermore , it allows us to identify the DM candidate as a quasi - NambuGoldstone boson 11 , thereby providing a natural solution to the so - called WIMP miracle 12 problem 13 . Finally , our model also predicts the presence of light scalar superpartners 14 , which would offer useful signals at upcoming high - energy accelerator facilities 15 .The rest of this article is grouped as follows . In Sec .2 , we provide our theory framework based upon emergent gauge mediation 16 . Then , in Secs .3 - 7 , we prove how this framework can independently solve all present observation constraints 17 - 20 while predicting novel phenomenological characteristics 21 . Finally , in Sec .8 , we conclude with some remarks about further directions of research .",
        "rewrite_text": "We propose that dark matter (DM) and supersymmetric particles arise from an emergent gauge symmetry at high energy scales, which subsequently breaks down to the symmetries of the Standard Model below the TeV scale. The DM candidate can be characterized as a quasi-Nambu-Goldstone boson associated with the spontaneous breaking of a global U(1) symmetry. This framework is able to account for various experimental results from DM searches, including recent evidence from the LHC. Additionally, we discuss potential collider signatures for future experiments, such as those at the International Linear Collider (ILC) or Compact Linear Collider (CLIC).\n\nIntroduction: Dark matter (DM) has long been inferred from its gravitational effects, presenting one of the most enigmatic challenges in contemporary particle physics. Though many theories have been proposed to explain the nature of DM, none have garnered substantial validation. In this work, inspired by emergent theories, we explore a novel approach in which DM emerges from the spontaneous breaking of a global symmetry. This framework elegantly accounts for the existence of DM without necessitating the introduction of any new fields beyond those already recognized in the Standard Model. Moreover, it allows us to identify the DM candidate as a quasi-Nambu-Goldstone boson, thus offering a natural resolution to the so-called WIMP miracle problem. Our model also predicts the existence of light scalar superpartners, which could generate valuable signals at forthcoming high-energy accelerator facilities.\n\nThe remainder of this article is structured as follows: In Section 2, we present our theoretical framework based on emergent gauge mediation. Sections 3 through 7 demonstrate how this framework can independently address all current observational constraints while predicting new phenomenological features. Finally, in Section 8, we summarize our findings and discuss potential avenues for further research.",
        "ori-fast-z-score": 0.7986208584745025,
        "water-fast-z-score": 7.954951288348659,
        "rewrite-fast-z-score": 1.9414506867883017
    },
    {
        "original_text": "The production of light elements in the early universe is one of the most important unsolved problems in astrophysics, cosmology, nuclear physics and particle physics. The standard model (SM) of elementary particles cannot explain how these elements were created during the first few minutes after the Big Bang. In this talk I will present an overview on our current understanding about the origin of light nuclei with A=1-3 produced by photonuclear reactions at high temperatures and densities in the early universe. This includes theoretical predictions for the abundances as well as experimental results obtained using radioactive beams at GSI Darmstadt. Finally, I will discuss possible future experiments to test some of the key predictions made within the SM. Keywords: Photonuclear reaction, Light element synthesis, Big Bang nucleosynthesis, Astrophysical SNe Ia explosion mechanism, Nuclear structure theory. 1 Introduction.\nLight element synthesis in the early universe is among the most challenging open questions in modern science  1  . It has been known since the 1960s that photons can induce nuclear fusion processes leading to the creation of light elements like D, 3 He, 4 He, 7 Li or 9 Be  2  , but it was not until recently when we have gained sufficient knowledge about the physical conditions prevailing in the early universe  3  .\nIn particular, the temperature T and density ρ reached values up to 10 12 K and 10 15 g/cm 3 respectively  4  . These extreme conditions are only accessible today in laboratory experiments using relativistic heavy-ion collisions  5  . However, due to the extremely short time scales involved  6  , such experiments do not allow us to study the formation of light elements directly  7, 8  . Instead they provide information about the properties of hot dense matter which may be relevant for the description of the initial stages of supernova explosions  9  . On the other hand, the abundance pattern observed in primordial objects like white dwarfs  10  or metal-poor stars  11  provides valuable constraints on the models describing the evolution of the chemical composition of the universe  12  .",
        "watermark_text": "The production of light elements in the early universe is one of the most important unsolved issues in astrophysics , cosmology , nuclear science and particle science . The typical model ( SM ) of primary atoms cannot explain how these objects were created during the first few hours after the Big Bang .In this talk I will present an overview on our new understanding about the origin of light nuclei with A = 1 - 3 created by photonuclear reactions at high temperatures and densities in the early universe . This contains theoretical estimates for the abundances as well as research results derived using nuclear beams at GSI Darmstadt .Finally , I will explore possible future research to test some of the key predictions produced within the SM . Keywords : Photonuclear reaction , Light element synthesis , Big Bang nucleosynthesis , Astrophysical SNe Ia explosion mechanism , Nuclear structure hypothesis .1 Introduction . Light factor synthesis in the early universe is among the most challenging open questions in modern science 1 .It has been known since the 1960s that photons can induce nuclear fusion mechanisms leading to the creation of light elements like D , 3 He , 4 He , 7 Li or 9 Be 2 , but it was not until recently when we have achieved sufficient knowledge about the physical conditions prevailing in the early universe 3 . In particular , the temperature T and density ρ reached values up to 10 12 K and 10 15 g / cm 3 respectively 4 .These severe environments are only accessible today in laboratory experiments using relativistic heavy - ion collisions 5 . However , owing to the exceptionally short period scales involved 6 , such studies do not enable us to study the formation of light elements directly 7 , 8 .Instead they give information about the properties of bright heavy material which may be crucial for the description of the first phase of supernova explosions 9 . On the other hand , the density trend detected in primordial objects like white dwarfs 10 or metal - poor stars 11 provides valuable constraints on the models explaining the evolution of the chemical composition of the universe 12 .",
        "rewrite_text": "The synthesis of light elements in the early universe remains one of the most significant unresolved challenges in the fields of astrophysics, cosmology, nuclear science, and particle physics. Current standard models (SM) of primary atom formation fail to adequately explain how these elements were formed in the first few hours following the Big Bang. In this presentation, I will provide an overview of our newly developed understanding of the origins of light nuclei with mass numbers A = 1 to 3, which are produced through photonuclear reactions under the extreme temperatures and densities characteristic of the early universe. This includes theoretical predictions regarding their abundances, as well as experimental findings acquired through the use of nuclear beams at GSI Darmstadt. Additionally, I will discuss potential avenues for future research aimed at testing some of the critical predictions derived from the standard model. \n\nKeywords: Photonuclear reaction, light element synthesis, Big Bang nucleosynthesis, astrophysical SNe Ia explosion mechanism, nuclear structure hypothesis.\n\n1. Introduction\n\nThe synthesis of light elements in the early universe stands out as one of the most formidable open questions in contemporary science. Since the 1960s, it has been established that photon-induced nuclear fusion can lead to the formation of light elements, such as deuterium (D), helium-3 (3He), helium-4 (4He), lithium-7 (7Li), and beryllium-9 (9Be). However, only recently have we gained sufficient insight into the physical conditions that existed in the early universe. Specifically, temperatures (T) and densities (ρ) reached levels as high as 10^12 K and 10^15 g/cm³, respectively. Such extreme conditions can currently only be replicated in laboratory settings through relativistic heavy-ion collisions. Nevertheless, due to the exceptionally brief timescales involved, these experiments do not allow for the direct observation of light element formation. Instead, they provide insights into the behaviors of dense heavy materials, which may be critical for understanding the initial phases of supernova explosions. Conversely, the density trends observed in primordial objects, such as white dwarfs and metal-poor stars, offer valuable constraints on models that seek to explain the evolution of the universe's chemical composition.",
        "ori-fast-z-score": 1.8842334171937931,
        "water-fast-z-score": 8.818163074019441,
        "rewrite-fast-z-score": 0.5482823149915702
    },
    {
        "original_text": "We present an experimental investigation into complementarity and quantum nonlocality using a photonic implementation of the Einstein-Bohr photon box thought experiment. We demonstrate that our system exhibits both classical correlations, which are consistent with local hidden variable theories, as well as quantum correlations, which cannot be explained by any such theory. Our results show that this system is capable of exhibiting all three types of Bell inequalities simultaneously. The Einstein-Bohr (EB) photon-box  1  , also known as the EPRB  2  or the two-slit experiment  3  , has been used to investigate many aspects of quantum mechanics including entanglement  4  , Bell s theorem  5  , and quantum teleportation  6  . In its original form it consists of a source emitting pairs of photons at random times; one photon passes through a beam splitter while the other travels directly towards a detector. If we measure whether each photon arrives at either output port of the beam splitter then there will always be exactly one photon arriving at each detector. This measurement can be performed locally on each side without disturbing the state of the other particle. However if instead we perform measurements on both particles jointly then they must arrive together at the same detector  7, 8  .\nIn order for these experiments to exhibit genuine quantum effects, the detectors need to have high efficiency so that the probability of detecting more than one photon per pair is negligible  9  . Previous implementations of EB boxes have relied upon inefficient single-photon counting detectors  10  or inefficient avalanche photo diodes  11  . These devices do not allow us to distinguish between different numbers of detected photons and therefore prevent us from observing truly quantum behaviour  12  .",
        "watermark_text": "We present an experimental inquiry into complementarity and quantum nonlocality utilizing a photonic implementation of the Einstein - Bohr photon box thought experiment . We suggest that our system displays both classical correlations , which are compatible with local hidden variable theories , as well as particle correlations , which cannot be described by any such theory .Our results show that this scheme is capable of displaying all three sorts of Bell inequalities simultaneously . The Einstein - Bohr ( EB ) photon - box 1 , sometimes called as the EPRB 2 or the two - slit experiment 3 , has been used to examine multiple matters of quantum mechanics including entanglement 4 , Bell s theorem 5 , and quantum teleportation 6 .In its initial structure it consists of a source emitting sets of photons at random times ; one photon passes through a beam splitter while the other travels immediately towards a detector . If we measure whether each photon arrives at either output port of the beam splitter then there will always be exactly one photon entering at each sensor .This measurement can be performed locally on each side without disturbing the state of the other particle . However if instead we perform observations on both particles jointly then they must appear together at the same detector 7 , 8 .In order for these experiments to produce genuine quantum effects , the detectors need to have high efficiency so that the probability of detecting more than one photon per couple is negligible 9 . Earlier implementations of EB Box have relied upon inefficient single - photon counting detectors 10 or inefficient avalanche photographic diodes 11 .These machines do not enable us to distinguish between multiple numbers of identified photons and therefore prevent us from observing truly quantum behaviour 12 .",
        "rewrite_text": "We present an experimental investigation into complementarity and quantum nonlocality using a photonic version of the Einstein-Bohr photon box thought experiment. Our findings indicate that our system exhibits both classical correlations, consistent with local hidden variable theories, and particle correlations that cannot be explained by any such theories. Our results demonstrate that this setup can simultaneously showcase all three types of Bell inequalities. The Einstein-Bohr (EB) photon box, also known as the EPRB or the two-slit experiment, has been utilized to explore various aspects of quantum mechanics, including entanglement, Bell's theorem, and quantum teleportation. In its original design, the experiment features a source that emits pairs of photons at random intervals; one photon goes through a beam splitter while the other heads directly to a detector. By measuring which output port each photon reaches, we ensure that exactly one photon arrives at each detector. This local measurement can be conducted on each side without affecting the counterpart's state. However, if we observe both particles together, they must appear at the same detector. For these experiments to reveal genuine quantum phenomena, the detectors must operate with high efficiency to keep the likelihood of detecting more than one photon per pair to a minimum. Previous implementations of the EB Box have depended on inefficient single-photon counting detectors or subpar avalanche photodiodes, which fail to distinguish between multiple photons and hinder the observation of authentic quantum behavior.",
        "ori-fast-z-score": 0.0949157995752499,
        "water-fast-z-score": 5.651175082804793,
        "rewrite-fast-z-score": 0.7921180343813395
    },
    {
        "original_text": "We study the scattering amplitudes for gluons and gravitons at strong coupling using classical string solutions in Anti-de Sitter space (AdS). We show that these amplitudes can be obtained by evaluating certain correlation functions on the worldsheet boundary, which are related to tree-level gauge theory amplitudes via holography. The results agree with those found previously using integrability techniques. In addition we find new contributions to the graviton-graviton amplitude involving an infinite tower of massive states. These arise because our solution is not invariant under global Poincare transformations; they correspond to corrections to the supergravity action induced by higher derivative terms in the bulk effective field theory. \nIntroduction\n\nThe AdS/CFT correspondence  1  relates type IIB superstrings propagating in ten-dimensional anti-de Sitter space-time (AdS) to conformal field theories living on its four-dimensional boundary. This duality has been used extensively over recent years as a tool to explore non-perturbative phenomena in quantum gravity  2  . It also provides a novel approach to studying strongly-coupled gauge theories such as QCD  3  .\nIn this talk we will consider the simplest example of the AdS/CFT correspondence -the maximally supersymmetric Yang-Mills (N=4 SYM) theory  4  , whose dual description involves type IIA strings moving in AdS 5 × S 5  5  . At weak  t Hooft coupling λ = g 2 Y M N ≪ 1, where g Y M denotes the Yang-Mills coupling constant, perturbative calculations have shown that the two descriptions match exactly  6  . However, it remains unclear how to calculate quantities like scattering amplitudes directly within the gauge theory at large values of λ  7, 8  . On the other hand, one may use the AdS/CFT dictionary  9  to translate between observables calculated in either side of the duality. For instance, the expectation value of Wilson loops in the gauge theory corresponds to the area of minimal surfaces embedded into AdS  10  ; while n-point correlators of local operators in the gauge theory are given by functional integrals over n-punctured Riemann surfaces  11  .",
        "watermark_text": "We research the scattering amplitudes for gluons and gravitons at strong coupling using traditional string solutions in Anti - de Sitter space ( AdS ) . We see that these amplitudes can be obtained by evaluating several coupling functions on the worldsheet border , which are related to tree - level gauge theory amplitudes via holography .The results agree with those shown previously used integrability methods . In addition we find new contributions to the graviton - graviton amplitude involving an endless tower of large states .These occur because our solution is not invariant under universal Poincare shifts ; they relate to corrections to the supergravity act caused by higher derivative conditions in the bulk effective field theory . Introduction The AdS / CFT relationship 1 relates class IIB superstrings propagating in ten - dimensional anti - de Sitter space - time ( AdS ) to conformal field schemes residing on its four - dimensional boundary .This duality has been used heavily over recent years as a platform to examine anti - perturbative processes in particle gravity 2 . It additionally offers a new approach to investigating strongly - coupled gauge fields such as QCD 3 .In this talk we will take the simplest example of the AdS / CFT relationship - the maximally supersymmetric Yang - Mills ( N = 4 SYM ) theory 4 , whose dual description requires type IIA strings moving in AdS 5 × S 5 5 . At weak t Hooft coupling λ = g 2 Y M N [UNK] 1 , where h Y M denotes the Yang - Mills coupling constant , perturbative calculations have shown that the two explanations match exactly 6 .However , it remains unclear how to estimate quantities like absorption amplitudes directly within the gauge theory at large values of λ 7 , 8 . On the other hand , one may use the AdS / CFT dictionary 9 to translate between observables calculated in either face of the duality .For instance , the expectation value of Wilson loops in the gauge theory corresponds to the area of minimal surfaces embedded into AdS 10 ; while n - point correlators of local operators in the gauge theory are given by functional integrals over n - punctured Riemann spheres 11 .",
        "rewrite_text": "We investigate the scattering amplitudes for gluons and gravitons at strong coupling, utilizing conventional string solutions in Anti-de Sitter space (AdS). Our analysis reveals that these amplitudes can be derived by evaluating several coupling functions on the boundary of the worldsheet, which are connected to tree-level gauge theory amplitudes through holography. Our findings are consistent with earlier results obtained using integrability methods. Furthermore, we uncover new contributions to the graviton-graviton amplitude that involve an infinite tower of large states. These arise due to the lack of invariance of our solution under universal Poincaré shifts and are linked to corrections in the supergravity action caused by higher derivative terms in the bulk effective field theory. \n\nIn the introduction, the AdS/CFT correspondence relates type IIB superstrings propagating in ten-dimensional Anti-de Sitter space-time (AdS) to conformal field theories located on its four-dimensional boundary. This duality has been extensively employed in recent years to explore non-perturbative processes in particle gravity. Moreover, it provides a novel framework for investigating strongly-coupled gauge theories, including QCD. In this discussion, we focus on the simplest case of the AdS/CFT correspondence: the maximally supersymmetric Yang-Mills (N = 4 SYM) theory, whose dual description involves type IIA strings in AdS5 × S5. At weak 't Hooft coupling (λ = g²YM N << 1), perturbative calculations have demonstrated an exact match between the two representations. However, it remains challenging to directly estimate quantities such as absorption amplitudes within the gauge theory at large values of λ. Alternatively, one can leverage the AdS/CFT dictionary to relate observables calculated on either side of the duality. For example, the expectation value of Wilson loops in the gauge theory corresponds to the area of minimal surfaces embedded in AdS, while n-point correlators of local operators in the gauge theory are represented by functional integrals over n-punctured Riemann spheres.",
        "ori-fast-z-score": -1.643989873053573,
        "water-fast-z-score": 5.488853867477571,
        "rewrite-fast-z-score": 1.4216114170120542
    },
    {
        "original_text": "The present work is concerned with efficient methods to calculate molecular properties, such as vibrational frequencies or electronic excitation energies, using ab initio quantum chemical techniques. The main focus lies on the calculation of these quantities for large systems containing many atoms (e.g., proteins). In this context we have developed an approach which allows us to reduce computational costs significantly by combining two different approximations. First, we use split-valence Gaussian basis functions instead of conventional Cartesian Gaussians. Second, we apply the so-called  heterolevel  approximation within restricted Hartree-Fock theory and second-order Moller-Plesset perturbation theory. This combination leads to very accurate results at low computational cost even if applied to relatively large molecules like polypeptides. We demonstrate that our method can be used successfully to study the influence of solvent effects on the structure and stability of small peptides. Finally, we show how it may also be employed to investigate excited-state processes occurring during photochemical reactions.",
        "watermark_text": "The present work is concerned with able methods to estimate chemical properties , such as vibrational speeds or electronic excitation energies , using ab initio quantum chemical techniques . The main interest lies on the determination of these quantities for large systems containing many atoms ( e . g . , proteins ) .In this situation we have developed an solution which allows us to reduce mathematical expenses significantly by combining two different approximations . First , we using split - valence Gaussian basis variables instead of standard Cartesian Gaussians .Second , we apply the so - called heterolevel algorithm within limit Hartree - Fock theory and second - order Moller - Plesset perturbation theory . This pairing allows to very accurate outcomes at low theoretical cost especially if applied to relatively huge compounds like polypeptides .We showed that our technique can be used successfully to study the impact of solvent effects on the composition and strength of tiny peptides . Finally , we indicate how it could also be employed to examine excited - state mechanisms occurring during photochemical reactions .",
        "rewrite_text": "This study focuses on effective methods for estimating chemical properties, such as vibrational frequencies and electronic excitation energies, using ab initio quantum chemical techniques. The primary goal is to accurately determine these properties for large systems with many atoms, such as proteins. To address the computational challenges, we have developed a solution that significantly reduces mathematical expenses by combining two different approximations. First, we utilize split-valence Gaussian basis functions instead of conventional Cartesian Gaussians. Second, we implement the heterolevel algorithm within the framework of limited Hartree-Fock theory and second-order Møller-Plesset perturbation theory. This combination allows for highly accurate results at a relatively low theoretical cost, particularly when applied to large compounds like polypeptides. We have demonstrated that our technique effectively studies the influence of solvent effects on the composition and stability of small peptides. Additionally, we suggest its potential application in investigating excited-state mechanisms that occur during photochemical reactions.",
        "ori-fast-z-score": -0.32539568672798425,
        "water-fast-z-score": 6.915148379350492,
        "rewrite-fast-z-score": 1.7888543819998317
    },
    {
        "original_text": "We present the results of our study on the evolution and nucleosynthesis in super-asymptotic giant branch (super-AGB) stars, which are evolved massive AGB stars with initial masses between 8 to 12 M⊙. We have performed detailed stellar evolutionary calculations for these stars using the latest version of the FRANEC code. The calculated models show that super-AGB stars experience strong mass loss during their late stages of evolution due to pulsation driven winds. These stars lose about 0.5 M⊙ before they enter into the white dwarf cooling phase. During this stage, we find that the surface abundances of CNO elements change significantly as compared to those at the end of the previous red giant phase. In particular, the surface abundance of nitrogen increases by more than one order of magnitude while carbon decreases by almost an order of magnitude. This is mainly because of the dredge-up episodes experienced by these stars when they cross the HR diagram towards higher luminosities.",
        "watermark_text": "We present the conclusion of our study on the evolution and nucleosynthesis in super - asymptotic giant branch ( super - AGB ) stars , which are evolved massive AGB stars with initial masses between 8 to 12 [UNK] . We have performed detailed stellar evolutionary calculations for these stars using the latest version of the FRANEC code .The adjusted models show that super - AGB stars experience heavy mass loss during their late stages of evolved due to pulsation driven winds . These galaxies lose about 0 . 5 [UNK] before they enter into the white dwarf cooling phase .During this phase , we find that the surface abundances of CNO groups change considerably as compared to those at the end of the previous red giant stage . In particular , the surface abundance of nitrogen changes by more than one order of magnitude while carbon decreases by almost an order of magnitude .This is mainly because of the dredge - up episodes experienced by these stars when they cross the HR diagram towards higher luminosities .",
        "rewrite_text": "We present the findings of our research on the evolution and nucleosynthesis of super-asymptotic giant branch (super-AGB) stars, which are evolved massive AGB stars with initial masses ranging from 8 to 12 solar masses. We conducted thorough stellar evolutionary calculations for these stars using the latest version of the FRANEC code. Our refined models indicate that super-AGB stars undergo significant mass loss during their later evolutionary stages due to pulsation-driven winds. These stars lose approximately 0.5 solar masses before entering the white dwarf cooling phase. During this phase, we observe substantial changes in the surface abundances of the carbon-nitrogen-oxygen (CNO) elements compared to their levels at the conclusion of the previous red giant phase. Notably, the nitrogen abundance increases by over an order of magnitude, while the carbon abundance decreases by nearly an order of magnitude. These changes primarily result from the dredge-up events that occur as these stars move across the Hertzsprung-Russell diagram towards higher luminosities.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 2.9068883707497264,
        "rewrite-fast-z-score": -0.6396021490668313
    },
    {
        "original_text": "We present the results of an unbiased survey toward starless cores using the HCN hyperfine transitions at 1.42 GHz and 2.12 GHz with the Nobeyama 45 m telescope to probe inward motions within these objects. We detected emission lines from all targets, except for L1521F (Taurus), which is known as one of the coldest prestellar cores. From our observations we found that the line widths are narrower than those observed by single-dish telescopes. This suggests that there may be unresolved substructure or turbulence on small scales inside the cores. For most sources, the peak intensities of both frequencies agree well with each other; however, for some cases they show significant differences between them. These discrepancies can be explained if the core has a temperature gradient along its radius and/or if it contains multiple velocity components. Our analysis shows that the kinetic temperatures derived from the two different frequency data sets range from 10 K to 30 K.",
        "watermark_text": "We present the results of an unbiased survey toward starless cores using the HCN hyperfine transitions at 1 . 42 GHz and 2 . 12 GHz with the Nobeyama 45 m telescope to probe inward motions within these objects . We detected emission lines from all targets , except for L1521F ( Taurus ) , which is known as one of the coldest prestellar cores .From our observations we concluded that the line widths are smaller than those observed by single - dish telescopes . This implies that there may be unresolved substructure or turbulence on small scales inside the cores .For most sources , the peak intensities of both frequencies agree well with each other ; however , for some cases they show considerable variations between them . These discrepancies can be understood if the core has a temperature gradient along its radius and / or if it contains multiple velocity components .Our study shows that the kinetic concentrations generated from the two different frequency information sets range from 10 K to 30 K .",
        "rewrite_text": "We present the findings of an unbiased survey of starless cores using the HCN hyperfine transitions observed at 1.42 GHz and 2.12 GHz with the Nobeyama 45 m telescope, aimed at investigating inward motions within these objects. Emission lines were detected from all targets, except for L1521F (Taurus), which is recognized as one of the coldest prestellar cores. Our observations indicated that the line widths are narrower than those recorded by single-dish telescopes, suggesting the presence of unresolved substructure or small-scale turbulence within the cores. For most sources, the peak intensities at both frequencies align closely; however, some cases exhibited significant variations between the two. These discrepancies may be explained by a temperature gradient along the core's radius and/or the presence of multiple velocity components. Our study reveals that the kinetic temperatures inferred from the data at the two frequencies range between 10 K and 30 K.",
        "ori-fast-z-score": 0.9438798074485389,
        "water-fast-z-score": 3.3709993123162105,
        "rewrite-fast-z-score": 0.13736056394868904
    },
    {
        "original_text": "We present an analysis of dislocation structures in icosahedral approximant phases based on a new approach to describing dislocation networks, which is applicable both to periodic crystals and aperiodic solids with any kind of local order. The method relies on projecting the Burgers vectors onto a set of basis vectors that are determined by the underlying lattice structure. We show how this can be used to describe the dislocation network in the decagonal phase of the AlPdMn system as well as its parent cubic phase. In particular we find that the dislocation network in these two phases has very similar characteristics despite the fact that they have different symmetries. This suggests that the dislocation network may play an important role in determining the physical properties of these materials. \n \n Introduction \n \n Dislocations are line defects in crystalline materials where there is a discontinuity in the atomic arrangement along some direction. They occur naturally during plastic deformation processes such as bending or stretching but also arise spontaneously when certain conditions are satisfied  1  . For example, it was recently shown that dislocations form at grain boundaries between grains of differing orientations  2  , and that they can even appear within single grains  3  .\n \nDislocations are classified according to their Burgers vector b = mu + nv (where u and v are primitive lattice vectors) into edge dislocations if m+n=0, screw dislocations if n=m=1, mixed dislocations otherwise  4  . Edge dislocations correspond to a displacement field perpendicular to the slip plane while screw dislocations give rise to a displacement parallel to the slip plane  5  . Mixed dislocations combine features of both types  6  . \n \nThe presence of dislocations leads to elastic strain fields around them  7, 8  . These strains can be calculated using the Peach-Koehler force acting on each individual dislocation  9  . If all dislocations were isolated then the total energy would simply be given by the sum over all contributions from individual dislocations  10  . However, in real systems dislocations interact strongly with one another through elastic interactions  11  . As a result, the total energy depends not only on the number density",
        "watermark_text": "We present an assessment of dislocation arrangements in icosahedral approximant layers using on a new approach to describing dislocation networks , which is applicable both to periodic crystals and aperiodic solids with any sort of local order . The method relies on translating the Burgers vectors onto a setting of basis vectors that are decided by the underlying lattice structure .We see how this can be used to explain the dislocation system in the decagonal phase of the AlPdMn system as also as its parent cubic cycle . In particular we find that the dislocation system in these two phases has very related characteristics despite the fact that they have different symmetries .This implies that the dislocation channel may play an important role in determining the physical properties of these structures . Introduction Dislocations are line failures in crystalline structures where there is a discontinuity in the atomic arrangement along some direction .They happen naturally during plastic deformation processes such as stretching or extension but also arise spontaneously when particular conditions are fulfilled 1 . For instance , it was recently shown that dislocations form at grain boundaries between particles of differing orientations 2 , and that they can even exist within double particles 3 .Dislocations are classified according to their Burgers vector b = mu + nv ( where u and v are basic lattice vectors ) into edge dislocations if m + n = 0 , screw dislocations if n = m = 1 , blended dislocations otherwise 4 . Edge dislocations relate to a displacement field perpendicular to the slip plane while screw dislocations make rise to a displacement adjacent to the slip plane 5 .Mixed dislocations mix qualities of both types 6 . The presence of dislocations causes to elastic strain fields around them 7 , 8 .These strains can be determined using the Peach - Koehler stress acted on each individual dislocation 9 . If all dislocations were isolated then the total energy may simply be taken by the sum over all contributions from individual dislocations 10 .However , in real systems dislocations behave closely with one another through elastic interactions 11 . As a result , the total energy relies not only on the number density",
        "rewrite_text": "We present an analysis of dislocation arrangements in icosahedral approximant layers, utilizing a novel method for characterizing dislocation networks that is applicable to both periodic crystals and aperiodic solids exhibiting various types of local order. This approach involves translating Burgers vectors into a framework of basis vectors defined by the underlying lattice structure. We demonstrate how this technique can elucidate the dislocation system in the decagonal phase of the AlPdMn alloy and its cubic parent structure. Notably, we observe that the dislocation configurations in these two phases share significant similarities, despite their differing symmetries. This suggests that dislocation channels may critically influence the physical properties of these materials.\n\nIntroduction: Dislocations represent linear defects in crystalline structures characterized by a disruption in the atomic arrangement along a given direction. They naturally occur during plastic deformation processes, such as stretching or extension, but can also form spontaneously under certain conditions. For example, recent studies have shown that dislocations can arise at grain boundaries between particles with differing orientations, and even within double particles. Dislocations are categorized based on their Burgers vector \\( b = mu + nv \\) (where \\( u \\) and \\( v \\) are fundamental lattice vectors): they are classified as edge dislocations when \\( m + n = 0 \\), screw dislocations when \\( n = m = 1 \\), and mixed dislocations in other cases. Edge dislocations are associated with a displacement field that is perpendicular to the slip plane, while screw dislocations generate a displacement parallel to the slip plane. Mixed dislocations exhibit characteristics of both types. The presence of dislocations leads to elastic strain fields in their vicinity. These strains can be quantified using the Peach-Koehler stress acting on each dislocation. If all dislocations were isolated, the total energy could be computed as the sum of the contributions from each dislocation. However, in practical scenarios, dislocations interact with one another through elastic forces, meaning that the total energy is influenced not just by the dislocation density, but also by these interactions.",
        "ori-fast-z-score": 0.2491364395612199,
        "water-fast-z-score": 7.505553499465135,
        "rewrite-fast-z-score": 1.3522468075656264
    },
    {
        "original_text": "We present an algorithm for checking consistency in quantified constraints, which is based on the concept of generalized quantifiers. We show that our approach can be used to check several constraint properties such as satisfiability or equivalence between two sets of quantified constraints. Finally we discuss how this method could be applied to solve problems related to software testing. In computer science, many problems are formulated using constraints. For example, in Software Testing (ST), test cases are often represented by means of logical formulas called Test Cases Specifications (TCS). These TCSs contain some variables whose values have to satisfy certain conditions expressed with Boolean expressions. The problem consists then in finding all possible assignments of these variables satisfying the given conditions. This kind of problems has been studied extensively during last years but most works focus only on unquantified constraints. However, there exist situations where it may be useful to express some restrictions over the set of solutions using quantifiers.",
        "watermark_text": "We present an algorithm for checking consistency in quantified constraints , which is based on the idea of generalized quantifiers . We see that our approach can be used to test several constraint features such as satisfiability or equivalence between two sets of quantified constraints .Finally we talk how this technology could be applied to solve difficulties related to programming testing . In computer science , many difficulties are formulated using restrictions .For instance , in Software Testing ( ST ) , test situations are often represented by means of logical formulas called Test Cases Specifications ( TCS ) . These TCSs comprise some parameters whose values have to meet particular conditions stated with Boolean expressions .The question involves then in seeking all possible assignments of these parameters satisfying the particular conditions . This kind of problems has been studied thoroughly during last decades but most works concentrate only on unquantified constraints .However , there exist situations where it could be beneficial to define some restrictions over the group of solutions use quantifiers .",
        "rewrite_text": "We introduce an algorithm designed to evaluate the consistency of quantified constraints, grounded in the concept of generalized quantifiers. Our method can assess various features of constraints, including their satisfiability and the equivalence between different sets of quantified constraints. Additionally, we explore the potential applications of this technology in addressing challenges related to software testing. In the field of computer science, many issues are framed in terms of restrictions. For example, in Software Testing (ST), test scenarios are often represented using logical formulas known as Test Case Specifications (TCS). These TCS include parameters whose values must satisfy specific conditions expressed as Boolean expressions. The primary challenge lies in identifying all possible assignments for these parameters that meet the established conditions. While this type of problem has been extensively studied over the past few decades, most research has focused solely on unquantified constraints. However, there are scenarios where incorporating quantifiers to define restrictions on the solution set could prove advantageous.",
        "ori-fast-z-score": -0.5773502691896257,
        "water-fast-z-score": 5.584068246522259,
        "rewrite-fast-z-score": 2.1376670117594454
    },
    {
        "original_text": "We report on observations made with Suzaku and Swift during the 2006 eruption of the recurrent nova RS Ophiucchi (RS Oph). The X-ray light curve shows that the source was brightest at around day 50 after the optical peak, when it reached an apparent luminosity of ~10^38 erg s-1. We find evidence for nonthermal emission up to 100 keV by fitting the observed spectrum with a power-law model modified by photoelectric absorption. This is consistent with previous results obtained using data taken with other satellites such as Chandra and XMM-Newton. In addition we found that the photon index changed significantly between days 40-50 and 60-70; this may be due to changes in the physical conditions near the central engine or in the geometry of the emitting region. \n \n We also detected significant hard X-ray emission above 10 keV which can not be explained solely by thermal bremsstrahlung radiation. A possible explanation would be inverse Compton scattering of soft photons off relativistic electrons accelerated in shocks driven into the surrounding medium. If so, then these particles should have been accelerated to energies greater than 1 PeV.",
        "watermark_text": "We report on observations made with Suzaku and Swift during the 2006 eruption of the recurrent nova RS Ophiucchi ( RS Oph ) . The X - ray light curve shows that the source was brightest at around week 50 after the optical peak , when it attained an apparent luminosity of ~ 10 ^ 38 erg s - 1 .We get data for nonthermal emission up to 100 keV by fitting the seen spectrum with a power - law description altered by photoelectric absorbed . This is compatible with previous findings obtained using data taken with other satellites such as Chandra and XMM - Newton .In addition we reported that the photon index changed significantly between days 40 - 50 and 60 - 70 ; this might be due to changes in the physical conditions near the main motor or in the topology of the emitting area . We additionally observed significant hard X - ray radiation above 10 keV which can not be described solely by magnetic bremsstrahlung rays .A possible reason would be inverse Compton absorption of soft photons off relativistic electrons accelerated in shocks driven into the nearby medium . If so , then these ions should have been accelerated to energies higher than 1 PeV .",
        "rewrite_text": "We present observations from Suzaku and Swift concerning the 2006 eruption of the recurrent nova RS Ophiuchi (RS Oph). The X-ray light curve indicates that the source reached its peak brightness approximately 50 weeks after the optical maximum, achieving an apparent luminosity of around 10^38 erg s^-1. By fitting the observed spectrum with a photoelectron-absorbed power-law model, we obtained data for nonthermal emission extending up to 100 keV. These results are consistent with earlier findings from other satellites, including Chandra and XMM-Newton. Furthermore, we noted a significant change in the photon index between days 40-50 and days 60-70, which may reflect variations in the physical conditions near the primary engine or alterations in the emitting region's structure. We also detected considerable hard X-ray radiation above 10 keV that cannot be solely attributed to magnetic bremsstrahlung. One potential explanation involves inverse Compton scattering of soft photons off relativistic electrons accelerated by shocks in the surrounding medium. If this theory holds true, it suggests that these particles would have been accelerated to energies exceeding 1 PeV.",
        "ori-fast-z-score": -1.0533703247651751,
        "water-fast-z-score": 5.500933918218137,
        "rewrite-fast-z-score": -0.6708203932499369
    },
    {
        "original_text": "The Compact Muon Solenoid (CMS) experiment at the Large Hadron Collider has recently reported evidence for a new particle with mass around 125 GeV, consistent with Standard Model expectations for the Higgs boson.  The D0 collaboration at Fermilab is also searching for this signal in its data set and has presented results on the search for single top quarks produced via t-channel exchange of a virtual W-boson as well as s-channel production through gluon fusion.   In both cases we find no significant excess over background predictions. We present our results here along with those from other experiments that have searched for similar signals. The CMS experiment at the LHC has recently reported evidence for an unexpectedly light scalar resonance decaying to pairs of photons or leptons  1  . This observation is compatible with the Standard Model expectation for the Higgs boson  2  , which would be expected to weigh about 126 GeV  3  .\nIn addition to the standard model Higgs boson searches performed by ATLAS  4  and CMS  5  , there are many extensions of the SM  6  that predict additional scalars  7, 8  . These models can lead to deviations from the SM prediction for the Higgs boson properties  9  such as spin  10  , parity  11  , CP  12  , coupling strengths  13  , branching ratios  14  , etc.. Many of these scenarios involve heavy particles that may be pair-produced at hadron colliders  15  . However, some theories  16  suggest that the Higgs-like state could be singlet under SU(2), U(1). Such states cannot be directly produced in pairs but only appear in association with another quark  17  . For example, in supersymmetric models  18  , the Higgs-like state appears in association with b-quarks  19  . Other examples include composite  20  and Little-Higgs  21  models where the Higgs-like state couples preferentially to third generation fermions  22  .",
        "watermark_text": "The Compact Muon Solenoid ( CMS ) experiment at the Large Hadron Collider has recently published evidence for a new particle with mass around 125 GeV , compatible with Standard Model expectations for the Higgs boson . The D0 consortium at Fermilab is also searching for this signal in its data set and has presented data on the hunt for single bottom quarks produced via t - channel exchange of a virtual W - boson as well as s - channel production through gluon fusion .In both cases we find no considerable excess over background predictions . We present our findings here along with those from other experiments that have searched for related systems .The CMS experiment at the LHC has recently published evidence for an unexpectedly light scalar resonance decaying to pairs of photons or leptons 1 . This measurement is compatible with the Standard Model estimate for the Higgs boson 2 , which would be anticipated to weigh about 126 GeV 3 .In addition to the standard model Higgs boson searches performed by ATLAS 4 and CMS 5 , there are many extensions of the SM 6 that forecast additional scalars 7 , 8 . These models can lead to deviations from the SM estimate for the Higgs boson properties 9 such as spin 10 , parity 11 , CP 12 , coupling strengths 13 , branching factors 14 , etc . .Many of these scenarios involve heavy nuclei that might be pair - produced at hadron colliders 15 . However , some theories 16 suggest that the Higgs - like state possible be singlet under SU ( 2 ) , U ( 1 ) .Such states cannot be directly produced in couples but only appear in association with another quark 17 . For instance , in supersymmetric theories 18 , the Higgs - like state occurs in association with b - quarks 19 .Other examples include composite 20 and Little - Higgs 21 models where the Higgs - like state couples preferentially to third generation fermions 22 .",
        "rewrite_text": "The Compact Muon Solenoid (CMS) experiment at the Large Hadron Collider has recently released evidence indicating the existence of a new particle with a mass of approximately 125 GeV, which aligns with the Standard Model predictions for the Higgs boson. Meanwhile, the D0 collaboration at Fermilab is also examining its dataset for this signal, focusing on the production of single bottom quarks via t-channel processes involving a virtual W-boson and s-channel production through gluon fusion. So far, they have observed no significant excess over expected background levels. In this article, we present our findings alongside those from other experiments investigating similar phenomena. The CMS experiment has also reported evidence for an unexpectedly light scalar resonance that decays into pairs of photons or leptons, consistent with the Standard Model's prediction for the Higgs boson, which should have a mass of around 126 GeV. Beyond the searches for the standard model Higgs boson conducted by ATLAS and CMS, numerous extensions of the Standard Model predict the existence of additional scalar particles. These models may show variations from the Standard Model predictions regarding Higgs boson properties, including spin, parity, CP violation, coupling strengths, and branching ratios. Many of these scenarios involve heavy nuclei that could be pair-produced at hadron colliders. However, certain theories propose the possibility of a Higgs-like state that is a singlet under SU(2) and U(1), which cannot be produced in pairs but can appear in association with another quark. For example, in supersymmetric models, this Higgs-like state is produced alongside b-quarks. Other theories, such as composite and Little Higgs models, suggest that the Higgs-like state preferentially couples to third-generation fermions.",
        "ori-fast-z-score": 0.9805806756909202,
        "water-fast-z-score": 5.439200829200679,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We consider the problem of energy-efficient resource allocation for wireless networks under qualityof-service (QoS) constraints, where each user has an individual QoS requirement and is equipped with multiple radios to communicate simultaneously over different channels. We propose a novel framework that jointly optimizes power control, channel assignment, scheduling, and routing by formulating it as a mixed integer linear program (MILP). The proposed MILP formulation takes into account both intra-cell interference among users within one cell and inter-cell interference between neighboring cells. To solve this large-scale optimization problem efficiently, we develop two efficient algorithms based on Lagrangian relaxation techniques. Our simulation results show that our proposed algorithm can significantly improve network performance compared to existing schemes. In particular, when there are only a few active links per cell at any time instant, our scheme achieves up to 4 times higher throughput than the baseline scheme without increasing transmit powers or bandwidths. \n \n Keywords: Energy efficiency, Power control, Channel assignment, Scheduling",
        "watermark_text": "We consider the issue of power - efficient resource allocation for wireless networks under qualityof - service ( QoS ) restrictions , where each consumer has an individual QoS requirement and is equipped with many radios to connect simultaneously over distinct networks . We suggest a new framework that collectively optimizes power control , network assignment , planning , and routing by formulating it as a mixed integer linear program ( MILP ) .The proposed MILP formulation uses into consideration both intra - cell interference among consumers within one cell and inter - cell interference between neighboring cells . To solve this big - scale optimization problem efficiently , we develop two efficient methods using on Lagrangian relaxation techniques .Our modelling findings show that our proposed algorithm can significantly improve network quality relative to existing algorithms . In particular , when there are only a few active connections per cell at any time instant , our scheme achieves up to 4 times higher throughput than the baseline scheme without increasing receive powers or bandwidths .Keywords : Energy efficiency , Power control , Channel assignment , Scheduling",
        "rewrite_text": "We address the challenge of power-efficient resource allocation in wireless networks while adhering to quality-of-service (QoS) constraints, where each user has specific QoS needs and is equipped with multiple radios that allow simultaneous connections to various networks. Our proposed framework aims to optimize power control, network assignment, planning, and routing collectively, and we achieve this by modeling the problem as a mixed-integer linear program (MILP). The MILP formulation takes into account both intra-cell interference among users within a single cell and inter-cell interference between adjacent cells. To solve this large-scale optimization problem effectively, we introduce two efficient methods based on Lagrangian relaxation techniques. Our modeling results indicate that our algorithm significantly enhances network quality compared to existing solutions. Notably, when the number of active connections per cell is low at a given time, our approach can achieve up to four times the throughput of the baseline scheme, without necessitating increases in receive power or bandwidth. Keywords: Energy efficiency, Power control, Channel assignment, Scheduling.",
        "ori-fast-z-score": 0.7504787743864564,
        "water-fast-z-score": 6.11104144857543,
        "rewrite-fast-z-score": -0.20851441405707477
    },
    {
        "original_text": "We present new mid-IR photometry and spectroscopy of the HUDF-JD2 galaxy at redshift 2.081, which is one of the most luminous infrared galaxies known to date. The SED shows that it has an extremely red continuum with strong PAH emission features in its rest frame optical spectrum. We find evidence for both star formation activity (from the UV-optical) as well as obscured AGN activity (from X-ray observations). This object may be representative of a population of dusty star-forming galaxies undergoing rapid evolution during this critical epoch when massive black holes are growing rapidly along with their host galaxies. Keywords: Infrared, Redshift, Spectroscopy, Photometry, Black Hole Growth, Star Formation Rate Density, Ultraviolet Background Radiation, Cosmic Evolution, Cosmology, Extragalactic Astronomy, High Energy Astrophysics, Space Science, Nearby Galaxies",
        "watermark_text": "We present new mid - IR photometry and spectroscopy of the HUDF - JD2 galaxy at redshift 2 . 081 , which is one of the most luminous infrared galaxies known to date . The SED shows that it has an extremely red continuum with strong PAH emission features in its rest frame optical spectrum .We get data for both star formation activity ( from the UV - optical ) as well as obscured AGN activity ( from X - ray observations ) . This object may be representative of a population of dusty star - creating stars undergoing fast evolution during this critical epoch when massive brown holes are growing faster along with their host galaxies .Keywords: Infrared, Redshift, Spectroscopy, Photometry, Black Hole Growth, Star Formation Rate Density, Ultraviolet Background Radiation, Cosmic Evolution, Cosmology, Extragalactic Astronomy, High Energy Astrophysics, Space Science, Nearby Galaxies",
        "rewrite_text": "We present new mid-infrared photometry and spectroscopy for the HUDF-JD2 galaxy, which has a redshift of 2.081 and is among the most luminous infrared galaxies identified to date. The spectral energy distribution (SED) indicates a remarkably red continuum accompanied by pronounced PAH emission features in its rest-frame optical spectrum. Our data encompasses assessments of both star formation activity, derived from UV-optical observations, and obscured AGN activity, based on X-ray data. This galaxy may exemplify a population of dust-rich, star-forming systems experiencing rapid evolution during a critical period marked by the accelerated growth of massive black holes alongside their host galaxies. \n\nKeywords: Infrared, Redshift, Spectroscopy, Photometry, Black Hole Growth, Star Formation Rate Density, Ultraviolet Background Radiation, Cosmic Evolution, Cosmology, Extragalactic Astronomy, High Energy Astrophysics, Space Science, Nearby Galaxies.",
        "ori-fast-z-score": 0.2886751345948129,
        "water-fast-z-score": 2.3094010767585034,
        "rewrite-fast-z-score": 0.13245323570650439
    },
    {
        "original_text": "We study the stability properties of longitudinal flows in straight and curved magnetic flux tubes using linearized ideal MHD equations. We find that for sufficiently large values of plasma beta, there is always an unstable mode with zero frequency (i.e., static) which grows exponentially fast at small wavenumbers. The growth rate increases monotonically as we increase the value of plasma beta. \n \n For smaller values of plasma beta, however, this instability disappears completely. In fact, we show analytically that if the plasma beta is less than some critical value then all modes are stable irrespective of their frequencies or wavelengths. This result agrees well with our numerical simulations. Finally, we also present results on the effect of curvature on the stability properties of longitudinal flow. It turns out that the presence of curvature has no significant effect on the stability properties of these flows. However, it does affect the nature of the eigenfunctions associated with different eigenvalues.",
        "watermark_text": "We research the stability properties of longitudinal streams in straight and curved magnetic flux tubes using linearized ideal MHD equations . We see that for enough large values of plasma beta , there is usually an weak mode with zero frequency ( i . e . , static ) which increases exponentially rapidly at small wavenumbers .The growth speed increases monotonically as we increase the value of plasma beta . For lower values of plasma beta , however , this instability disappears entirely .In fact , we prove analytically that if the plasma beta is less than some essential value then all modes are stable irrespective of their frequencies or wavelengths . This result agrees well with our numerical simulations .Finally , we also present results on the impact of curvature on the stability properties of longitudinal stream . It turns out that the presence of curvature has no considerable impact on the stability properties of these flows .However , it does affect the nature of the eigenfunctions associated with various eigenvalues .",
        "rewrite_text": "We investigate the stability characteristics of longitudinal streams within both straight and curved magnetic flux tubes using linearized ideal magnetohydrodynamics (MHD) equations. Our findings reveal that for sufficiently large values of plasma beta, there exists typically a weak mode with zero frequency (i.e., static) that grows exponentially at small wavenumbers. The growth rate of this mode increases monotonically with rising plasma beta values. Conversely, at lower plasma beta values, this instability is completely suppressed. We provide analytical proof that if plasma beta is below a certain critical threshold, all modes remain stable, regardless of their frequencies or wavelengths. This analytical result is in strong agreement with our numerical simulations. Additionally, we explore the effects of curvature on the stability of longitudinal streams, discovering that while curvature does not significantly alter the stability characteristics of these flows, it does influence the nature of the eigenfunctions corresponding to various eigenvalues.",
        "ori-fast-z-score": 1.0256451881367414,
        "water-fast-z-score": 5.887840577551898,
        "rewrite-fast-z-score": 2.3626845919446504
    },
    {
        "original_text": "We study the effects on electroweak precision observables (EWPO) due to new physics at the TeV scale, which is motivated by recent LHC results and theoretical arguments for naturalness. We consider two classes of models with extra dimensions: Randall-Sundrum (RS) warped space model and holographic technicolor (HTC). In RS model we find that the corrections are too large compared to EWPOs if the mass scales involved satisfy MPlanck ~ 5TeV. However, this problem can be solved by introducing an additional bulk scalar field whose VEV breaks custodial symmetry softly. The resulting correction to T parameter is found to be small enough even when MPlanck = 5TeV. On the other hand, in HTC model there exists no such difficulty because the Higgs boson is composite particle made up of techni-dilaton and techni-sigma mesons.",
        "watermark_text": "We research the effects on electroweak accuracy observables ( EWPO ) related to recent science at the TeV scale , which is prompted by recent LHC results and theoretical evidence for naturalness . We consider two groups of models with extra dimensions : Randall - Sundrum ( RS ) warped space model and holographic technicolor ( HTC ) .In RS model we find that the corrections are too huge compared to EWPOs if the mass scales concerned meet MPlanck ~ 5TeV . However , this situation can be answered by using an additional bulk scalar field whose VEV cuts custodial symmetry quietly .The resulting correction to T parameter is found to be small enough even when MPlanck = 5TeV . On the other hand , in HTC system there exists no such difficulty because the Higgs boson is composite particle making up of techni - dilaton and techni - sigma mesons .",
        "rewrite_text": "We investigate the impact of electroweak precision observables (EWPO) in light of recent discoveries at the TeV scale, motivated by findings from the LHC and theoretical considerations regarding naturalness. Our study focuses on two categories of models that incorporate extra dimensions: the Randall-Sundrum (RS) warped space model and holographic technicolor (HTC). In the RS model, we determine that the corrections to EWPO are excessively large if the relevant mass scales approach MPlanck ~ 5 TeV. However, this issue can be mitigated by introducing an additional bulk scalar field with a vacuum expectation value that subtly breaks custodial symmetry. As a result, the correction to the T parameter is found to be sufficiently small, even with MPlanck set at 5 TeV. In contrast, the HTC framework does not encounter this problem since the Higgs boson is a composite particle formed from techni-dilaton and techni-sigma mesons.",
        "ori-fast-z-score": -1.2602520756252087,
        "water-fast-z-score": 3.959797974644666,
        "rewrite-fast-z-score": -0.816496580927726
    },
    {
        "original_text": "We study the orbital magnetization (OM) induced by spin-orbit coupling on a kagome lattice with chiral magnetic order, which is realized as an emergent property of the system at low temperatures. We show that the OM can be expressed in terms of the Berry curvature associated with the band structure near the Fermi level. The magnitude of the OM depends strongly on the strength of the spin-orbit interaction and the direction of the applied field. In particular, we find that when the external field points along one of the three equivalent <111> directions, there are two peaks in the temperature dependence of the OM. These results suggest that the OM may provide useful information about the nature of the ordered state in this material. \n \n Introduction \n \n Orbital magnetization (OM), also known as orbital polarization or orbital moment density, has been studied extensively for many years both theoretically  1 - 3  and experimentally  4 - 6  . It arises due to the presence of spin-orbit interactions  7  8  9  , and it plays important roles in various physical phenomena such as topological insulators  10  -  12  , quantum Hall effect  13  , and superconductivity  14  . Recently, the OM was observed in several materials including SrRuO3  15  , La0.7Sr0.3MnO3  16  , YbMgGaO4  17  , and FeSe  18  .\n \nIn this work, we consider the case where the OM appears in a frustrated antiferromagnetically coupled spin-1/2 Heisenberg model on a kagome lattice  19  20  21   22  . This type of magnetic ordering occurs naturally in some compounds like Herbertsmithite  23  , ZnCu3(OH)6Cl2  24  , and CuFeO2  25  . However, these systems have relatively weak spin-orbit couplings compared to other transition metal oxides  26  . Therefore, they do not exhibit large values of the OM  27  . On the other hand, recently discovered iron-based pnictide/chalcogenide compounds  28  -  30  possess strong spin-orbit interactions  31  , but their magnetic structures remain controversial  32  -  35  . Thus, our theoretical investigation provides valuable insight into possible experimental realiz",
        "watermark_text": "We explore the orbital magnetization ( OM ) induced by spin - orbit interaction on a kagome lattice with chiral magnetic order , which is realized as an emergent property of the system at low temperatures . We see that the OM can be described in terms of the Berry curvature associated with the band structure near the Fermi level .The magnitude of the OM depends strongly on the strength of the spin - orbit interaction and the direction of the applied field . In particular , we find that when the external field points along one of the three analogous < 111 > directions , there are two peaks in the temperature dependence of the OM .These data suggest that the OM may provide useful info about the nature of the ordered state in this material . Introduction Orbital magnetization ( OM ) , sometimes called as orbital polarization or orbital moment density , has been studied thoroughly for numerous years both theoretically 1 - 3 and experimentally 4 - 6 .It arises due to the presence of spin - orbit interactions 7 8 9 , and it serves crucial roles in different physical phenomena such as topological insulators 10 - 12 , quantum Hall impact 13 , and superconductivity 14 . Recently , the OM was seen in multiple materials namely SrRuO3 15 , La0 . 7Sr0 . 3MnO3 16 , YbMgGaO4 17 , and FeSe 18 .In this research , we define the case where the OM appears in a frustrated antiferromagnetically linked spin - 1 / 2 Heisenberg model on a kagome lattice 19 20 21 22 . This kind of magnetic ordering occurs commonly in some molecules like Herbertsmithite 23 , ZnCu3 ( OH ) 6Cl2 24 , and CuFeO2 25 .However , these systems have fairly weak spin - orbit couplings compared to other transition metal oxides 26 . Therefore , they do not show many values of the OM 27 .On the other hand , recently discovered iron - based pnictide / chalcogenide compounds 28 - 30 contain powerful spin - orbit bonding 31 , but their magnetic structures remain disputed 32 - 35 . Thus , our theoretical investigation gives valuable inquiry into possible experimental realiz",
        "rewrite_text": "We investigate the orbital magnetization (OM) arising from spin-orbit interactions in a kagome lattice exhibiting chiral magnetic order, a phenomenon that emerges at low temperatures. Our findings reveal that the OM can be characterized by the Berry curvature linked to the band structure near the Fermi level. The magnitude of the OM is highly sensitive to both the strength of the spin-orbit interaction and the orientation of the applied magnetic field. Notably, when the external field is directed along one of the three equivalent <111> axes, we observe two peaks in the temperature dependence of the OM. This data indicates that the OM may offer valuable insights into the nature of the ordered state in this material. \n\nIntroduction: Orbital magnetization (OM), also referred to as orbital polarization or orbital moment density, has been extensively studied both theoretically [1-3] and experimentally [4-6]. It arises due to spin-orbit interactions [7-9] and plays a significant role in various physical phenomena, including topological insulators [10-12], the quantum Hall effect [13], and superconductivity [14]. Recently, OM has been observed in several materials, such as SrRuO3 [15], La0.7Sr0.3MnO3 [16], YbMgGaO4 [17], and FeSe [18]. In this work, we focus on the OM in a frustrated antiferromagnetically coupled spin-1/2 Heisenberg model on a kagome lattice [19-22]. Such magnetic ordering is commonly found in materials like Herbertsmithite [23], ZnCu3(OH)6Cl2 [24], and CuFeO2 [25]. However, these compounds typically exhibit relatively weak spin-orbit coupling compared to other transition metal oxides [26], resulting in low OM values [27]. Conversely, newly discovered iron-based pnictide and chalcogenide compounds [28-30] possess strong spin-orbit interactions [31], although their magnetic structures remain under debate [32-35]. Therefore, our theoretical examination provides important perspectives for potential experimental realizations.",
        "ori-fast-z-score": 0.0873704056661038,
        "water-fast-z-score": 5.722930891116555,
        "rewrite-fast-z-score": -1.5085060660073935
    },
    {
        "original_text": "The Relativistic Heavy Ion Collider (RHIC) is an accelerator complex located in Brookhaven National Laboratory, New York. The main goal of this facility is to study nuclear matter under extreme conditions by colliding heavy ions with high energies and studying their properties after the collision. In addition, it also provides opportunities for other experiments using different beams such as protons or photons. This talk will present recent results on the measurement of spin structure functions g_1(x) and g1p(x), longitudinal double-spin asymmetries A_L, transverse single-spin asymmetry A_T, and transversity distributions h_1/T(x). These measurements are performed by the Solenoidal Tracker At RHIC experiment (STAR) which uses two large Time Projection Chambers (TPCs) filled with a gas mixture consisting of 90% helium-4 and 10% isobutane-1.",
        "watermark_text": "The Relativistic Heavy Ion Collider ( RHIC ) is an accelerator complex located in Brookhaven National Laboratory , New York . The main goal of this lab is to study nuclear material under extreme circumstances by colliding heavy ions with high energies and studying their properties after the interaction .In addition , it also provides opportunities for other experiments using separate beams such as protons or photons . This discussion will present recent results on the determination of spin structure parameters h _ 1 ( x ) and g1p ( x ) , longitudinal single - spinning asymmetries A _ L , transverse single - spin asymmetry A _ T , and transversity distributions x _ 1 / T ( x ) .These measurements are performed by the Solenoidal Tracker At RHIC observation ( STAR ) which uses two huge Time Projection Chambers ( TPCs ) filled with a gas mixture consisting of 90 % helium - 4 and 10 % isobutane - 1 .",
        "rewrite_text": "The Relativistic Heavy Ion Collider (RHIC) is a high-energy accelerator facility situated at Brookhaven National Laboratory in New York. This laboratory's primary objective is to investigate nuclear matter under extreme conditions by colliding heavy ions at high energies and analyzing their properties post-collision. Additionally, RHIC facilitates other experiments using distinct beams, including protons or photons. This presentation will detail recent findings regarding the determination of spin structure parameters \\( h_1(x) \\) and \\( g_1^p(x) \\), as well as longitudinal single-spin asymmetries \\( A_L \\), transverse single-spin asymmetry \\( A_T \\), and transversity distributions \\( x_1^T(x) \\). These measurements are conducted by the Solenoidal Tracker at RHIC (STAR), which employs two large Time Projection Chambers (TPCs) filled with a gas mixture of 90% helium-4 and 10% isobutane-1.",
        "ori-fast-z-score": 1.386750490563073,
        "water-fast-z-score": 4.9923017660270625,
        "rewrite-fast-z-score": 0.5443310539518174
    },
    {
        "original_text": "We propose an optical scheme for implementing the Gaussian valence bond (GVB) state, which is one of the most important classes of quantum states in condensed matter physics. The GVB state can be used to describe many-body systems with strong correlations such as spin liquids or Mott insulators. We show that our proposed scheme allows us to distribute entanglement between two distant parties by using only linear optics elements and single-photon sources. Our results may have potential applications in quantum information processing. \n \n Introduction \n \n Quantum entanglement plays a crucial role in various fields ranging from quantum communication  1  , quantum metrology  2  , quantum sensing  3  , and quantum computing  4  . In particular, it has been shown that quantum entangled states are useful resources for quantum teleportation  5  , superdense coding  6  , remote state preparation  7  , and quantum key distribution  8  .\n \nIn recent years, there has been growing interest in studying quantum entanglement in many-body systems  9  -  11  . For example, the ground-state wavefunction of strongly correlated fermions on lattices can be written as a product of local singlet pairs known as valence bonds  12  . This class of states is called valence-bond solid (VBS) states  13  . It was later found that VBS states can also be represented by so-called valence bond basis  14  . These states include the famous Néel state  15  describing antiferromagnetic order  16  , the Haldane phase  17  corresponding to integer-spin chains  18  , and the Affleck-Kennedy-Lieb-Tasaki (AKLT) model  19  representing gapped spin-1/2 chain  20  . \n \n Recently, several schemes  21 -  23  were proposed to generate these types of quantum states experimentally. However, all existing proposals require nonlinear interactions among photons  24  and/or complicated setups  25  . Therefore, they cannot be implemented easily in practice. On the other hand, some experimental demonstrations  26  -  28  have been performed recently to produce photonic qubits  29  . Thus, it would be interesting if we could find ways to implement these quantum states without requiring any nonlinear interaction  30  .",
        "watermark_text": "We suggest an optical scheme for incorporating the Gaussian valence bond ( GVB ) state , which is one of the most important classes of quantum states in condensed matter science . The GVB state can be used to define multiple - bodies systems with powerful correlations such as spin liquids or Mott insulators .We see that our proposed system enables us to distribute entanglement between two distant participants by using only linear optics components and single - photon sources . Our results may have potential applications in quantum information processing .Introduction Quantum entanglement plays a crucial role in different fields ranging from particle communication 1 , quantum metrology 2 , quantum sensing 3 , and quantum computing 4 . In particular , it has been shown that quantum entangled states are valuable resources for quantum teleportation 5 , superdense coding 6 , remote state formation 7 , and quantum key distribution 8 .In past decades , there has been growing interest in investigating quantum entanglement in large - bodies systems 9 - 11 . For instance , the ground - state wavefunction of highly correlated fermions on lattices can be written as a product of local singlet sets known as valence bonds 12 .This family of states is called valence - bond solid ( VBS ) states 13 . It was later known that VBS states can also be described by so - called valence bond basis 14 .These states contain the famous Néel state 15 describing antiferromagnetic order 16 , the Haldane phase 17 corresponding to integer - spin rings 18 , and the Affleck - Kennedy - Lieb - Tasaki ( AKLT ) model 19 representing gapped spin - 1 / 2 chain 20 . Recently , various strategies 21 - 23 were developed to produce these kinds of quantum states experimentally .However , all previous designs require nonlinear interactions among photons 24 and / or complicated setups 25 . Therefore , they cannot be deployed easily in practice .On the other hand , some experimental tests 26 - 28 have been performed recently to produce photonic qubits 29 . Thus , it would be exciting if we could discover ways to execute these quantum states without using any nonlinear interaction 30 .",
        "rewrite_text": "We propose an optical framework for integrating the Gaussian valence bond (GVB) state, a crucial category of quantum states within condensed matter physics. The GVB state is instrumental in characterizing complex many-body systems with strong correlations, such as spin liquids and Mott insulators. Our system allows for the distribution of entanglement between two remote parties using only linear optical components and single-photon sources. The implications of our findings could be significant for quantum information processing. \n\nIntroduction: Quantum entanglement is fundamental across various domains, including particle communication, quantum metrology, quantum sensing, and quantum computing. It has been demonstrated that entangled quantum states serve as valuable resources for numerous applications, such as quantum teleportation, superdense coding, remote state formation, and quantum key distribution. In recent years, there has been increasing interest in exploring quantum entanglement within large-body systems. For instance, the ground-state wavefunction of highly correlated fermions on lattices can be expressed as a product of local singlet sets, known as valence bonds. This collection of states is referred to as valence-bond solid (VBS) states. It has also been recognized that VBS states can be characterized using a valence bond basis. This category includes notable states, such as the Néel state, which illustrates antiferromagnetic order, the Haldane phase for integer-spin rings, and the Affleck-Kennedy-Lieb-Tasaki (AKLT) model that depicts a gapped spin-1/2 chain. Recently, various methods have been developed to experimentally generate these quantum states. However, prior designs typically necessitate nonlinear interactions among photons and involve complex arrangements, hindering practical implementation. Conversely, some recent experimental efforts have successfully produced photonic qubits. Consequently, discovering approaches to realize these quantum states without reliance on nonlinear interactions would be highly promising.",
        "ori-fast-z-score": 0.4931969619160719,
        "water-fast-z-score": 7.6705107192336,
        "rewrite-fast-z-score": 0.42107596053325946
    },
    {
        "original_text": "We report the discovery of two new faint Milky Way open clusters, which we call Palomar 1 and 2 (Palomar 1: RA = 17 h 55 m 00 s , Dec = -28°45 00  ;  Palomar 2: RA = 18 h 04 m 30 s , Dec = -29°00 30 ). They are located in the southern hemisphere at galactocentric distances between 20 kpc and 25 kpc. The total integrated V-band magnitudes for these objects are about 23 mag arcsec-2 . We have obtained deep photometry with the Hubble Space Telescope Advanced Camera for Surveys Wide Field Channel to study their stellar populations. Both clusters show very similar color-magnitude diagrams dominated by old red giant branch stars. Their ages are estimated as 12 Gyrs using isochrone fitting techniques. These results suggest that both clusters may be among the oldest open clusters known in our Galaxy.",
        "watermark_text": "We report the discovery of two new faint Milky Way open complexes , which we call Palomar 1 and 2 ( Palomar 1 : RA = 17 h 55 m 00 s , Dec = - 28°45 00 ; Palomar 2 : RA = 18 h 04 m 30 s , Dec = - 29°00 30 ) . They are situated in the southern hemisphere at galactocentric speeds between 20 kpc and 25 kpc .The total integrated V - band magnitudes for these objects are about 23 mag arcsec - 2 . We have achieved dark photometry with the Hubble Space Telescope Advanced Camera for Surveys Wide Field Channel to study their stellar populations .Both clusters show very identical color - magnitude diagrams dominated by ancient red giant line stars . Their ages are estimated as 12 Gyrs using isochrone fit techniques .These data suggest that both clusters might be among the earliest open regions known in our Galaxy .",
        "rewrite_text": "We announce the discovery of two new faint open star clusters in the Milky Way, designated Palomar 1 and Palomar 2. Palomar 1 is located at coordinates RA = 17h 55m 00s, Dec = -28° 45' 00\", while Palomar 2 is found at RA = 18h 04m 30s, Dec = -29° 00' 30\". Both clusters are positioned in the southern hemisphere and have galactocentric velocities ranging from 20 kpc to 25 kpc. The integrated V-band magnitudes for these clusters are approximately 23 mag arcsec^-2. Utilizing the Hubble Space Telescope’s Advanced Camera for Surveys Wide Field Channel, we performed dark photometry to analyze their stellar populations. The color-magnitude diagrams of both clusters exhibit striking similarities, with a predominance of ancient red giant stars. Isochrone fitting techniques indicate their ages to be around 12 billion years, suggesting that these clusters may represent some of the earliest open regions identified in our Galaxy.",
        "ori-fast-z-score": -0.8846517369293828,
        "water-fast-z-score": 3.8334908600273256,
        "rewrite-fast-z-score": 0.14285714285714285
    },
    {
        "original_text": "The dynamical discrete web is an extension to the concept of the discrete web, which was introduced by Markose and Sukumar in 1998 as a tool for studying the dynamics of nonlinear systems. The main idea behind this approach is that one can use the information contained within the trajectories of the system under consideration to construct a network whose nodes are given by these trajectories themselves. This network has been shown to be useful in identifying important features such as attractors or periodic orbits embedded in the phase space of the system.  In this work we present some new results on the properties of the dynamical discrete web associated with dissipative chaotic maps. We show how it is possible to obtain accurate estimates of the fractal dimension of strange attractors using only a small number of initial conditions (typically less than 100). Furthermore, we demonstrate how the dynamical discrete web can also be used to identify unstable periodic orbits embedded in the strange attractor.",
        "watermark_text": "The dynamical discrete web is an addition to the idea of the discrete web , which was introduced by Markose and Sukumar in 1998 as a technique for studying the dynamics of nonlinear processes . The main idea behind this methodology is that one can using the information stored within the trajectories of the system under consideration to build a network whose nodes are given by these trajectories themselves .This system has been shown to be valuable in identifying important features such as attractors or periodic orbits embedded in the phase space of the system . In this research we present some new data on the properties of the dynamical discrete web linked with dissipative chaotic functions .We see how it is easy to obtain precise estimates of the fractal dimension of odd attractors using only a small number of initial conditions ( generally less than 100 ) . Furthermore , we prove how the dynamical discrete web can also be used to identify unstable periodic orbits embedded in the weird attractor .",
        "rewrite_text": "The dynamical discrete web builds upon the concept of the discrete web, first proposed by Markose and Sukumar in 1998 as a method for analyzing the dynamics of nonlinear processes. The core principle of this approach involves utilizing the information contained in the system's trajectories to construct a network, where the nodes represent these trajectories. This methodology has proven effective in uncovering significant features within the system's phase space, such as attractors and periodic orbits. In this study, we present new findings related to the properties of the dynamical discrete web in connection with dissipative chaotic functions. Our results demonstrate that it is feasible to obtain accurate estimates of the fractal dimension of odd attractors using a limited number of initial conditions, typically fewer than 100. Additionally, we establish that the dynamical discrete web can be employed to identify unstable periodic orbits situated within the peculiar attractor.",
        "ori-fast-z-score": 0.5933908290969266,
        "water-fast-z-score": 6.052586456788652,
        "rewrite-fast-z-score": -0.35603449745815596
    },
    {
        "original_text": "The free energy of activation (ΔG*) is calculated for the comorosan effect, which describes the formation of an intermediate state in the reaction between carbon dioxide and water to form carbonate ions.  The ΔG* value obtained by this method is compared with that determined by other methods such as calorimetry or electrochemistry. It was found that these values are not consistent among themselves; however, they agree well within experimental error when the temperature dependence of the equilibrium constant is taken into account. This suggests that the discrepancy may be due to differences in the conditions under which each experiment was performed. In addition, it has been shown that the ΔG* value depends on the nature of the solvent used in the experiments. Finally, we have proposed a mechanism for the comorosan process based on our results. The free energy of activation (∆G*) is calculated using the Arrhenius equation for the comorosan reaction, which describes the formation",
        "watermark_text": "The free energy of activation ( ΔG * ) is calculated for the comorosan effect , which explains the formation of an intermediate state in the process between carbon dioxide and water to form carbonate compounds . The ΔG * value obtained by this process is compared with that determined by other methods such as calorimetry or electrochemistry .It was shown that these estimates are not consistent among themselves ; however , they accord well within experimental error when the temperature dependence of the equilibrium coefficient is taken into consideration . This implies that the discrepancy may be due to differences in the conditions under which each experiment was done .In addition , it has been shown that the ΔG * value depends on the nature of the solvent used in the experiments . Finally , we have proposed a system for the comorosan process depending on our findings .The free energy of activation ( [UNK] * ) is calculated using the Arrhenius equation for the comorosan reaction , which describes the formation",
        "rewrite_text": "The free energy of activation (ΔG*) is calculated for the comorosan effect, which elucidates the formation of an intermediate state during the reaction between carbon dioxide and water to produce carbonate compounds. The ΔG* value derived from this process is compared to values obtained through other techniques, such as calorimetry and electrochemistry. While these estimates show inconsistencies, they are generally in agreement within experimental error when the temperature dependence of the equilibrium constant is considered. This suggests that the observed discrepancies may stem from variations in the experimental conditions. Furthermore, it has been demonstrated that the ΔG* value is influenced by the type of solvent employed in the experiments. Based on our findings, we have proposed a system for the comorosan process. The free energy of activation (ΔG*) for the comorosan reaction is calculated using the Arrhenius equation to describe the formation.",
        "ori-fast-z-score": 2.25,
        "water-fast-z-score": 5.75,
        "rewrite-fast-z-score": 1.0327955589886444
    },
    {
        "original_text": "We present new results on the evolution of the dust content in Lyman break galaxies (LBGs) using deep near-infrared data obtained by the UltraVISTA survey, which is part of the Sloan Digital Sky Survey III program. We use these observations to study the rest-frame UV-optical properties of LBGs at redshifts 1<z<3.5. The main goal of this work was to investigate how the dust extinction evolves as a function of galaxy mass and star formation rate density over cosmic time. Our analysis shows that there are two different populations of LBGs: one population has low stellar masses (M*=10^10-10^11 Msun), high specific star formation rates (SSFR>100Gyr-1), and relatively small amounts of dust; while another population consists of more massive systems (M*>10^11Msun), lower SSFR values (SSFR<30Gyr-1), and higher levels of dust extinction. These findings suggest that the amount of dust increases with increasing galaxy mass for both local and distant galaxies.",
        "watermark_text": "We report new data on the evolution of the dust content in Lyman break galaxies ( LBGs ) using deep near - infrared results collected by the UltraVISTA survey , which is part of the Sloan Digital Sky Survey III program . We use these observations to study the rest - frame UV - optical properties of LBGs at redshifts 1 < z < 3 . 5 .The main goal of this research was to examine how the dust extinction evolves as a function of galaxy mass and star formation rate concentration over cosmic time . Our study shows that there are two different populations of LBGs : one community has low stellar masses ( M * = 10 ^ 10 - 10 ^ 11 Msun ) , low specific star formation rates ( SSFR > 100Gyr - 1 ) , and fairly large quantities of dust ; while another population contains of more massive complexes ( M * > 10 ^ 11Msun ) , lesser SSFR values ( SSFR < 30Gyr - 1 ) , and larger levels of dust extinction .These studies imply that the quantity of dust increases with higher galaxy mass for both local and distant galaxies .",
        "rewrite_text": "We present new findings on the evolution of dust content in Lyman break galaxies (LBGs), utilizing deep near-infrared data from the UltraVISTA survey, which is part of the Sloan Digital Sky Survey III program. These observations allow us to investigate the rest-frame UV-optical characteristics of LBGs at redshifts ranging from 1 to 3.5. The primary objective of our research was to analyze how dust extinction varies in relation to galaxy mass and concentrations of star formation rate over cosmic time. Our results reveal the existence of two distinct populations of LBGs: one group features low stellar masses (M* = 10^10 - 10^11 M☉), elevated specific star formation rates (SSFR > 100 Gyr^-1), and significant amounts of dust, while the other group comprises more massive galaxies (M* > 10^11 M☉) with lower SSFR values (SSFR < 30 Gyr^-1) and greater levels of dust extinction. These findings suggest that the amount of dust increases with higher galaxy mass, applicable to both local and distant galaxies.",
        "ori-fast-z-score": 1.1470786693528088,
        "water-fast-z-score": 5.735393346764043,
        "rewrite-fast-z-score": 1.6876318513890358
    },
    {
        "original_text": "We consider the energy conditions in cosmology, which are necessary for the existence of matter with positive pressure. We show that these conditions can be violated by quantum effects at high energies. In particular, we find that the universe is accelerating now because of such violations. The results obtained agree well with observations. \n \n Keywords: Energy condition, Quantum gravity, Acceleration of the universe \n \n 1 Introduction \n \n It has been known since the work of Einstein  1  , that the gravitational field equations admit solutions describing an accelerated expansion of space-time (see e.g.,  2  ). This fact was confirmed later on by numerous observational data  3  . However, it remains unclear what causes this phenomenon. One possible explanation could be related to some new physics beyond general relativity  4  .\n \nIn order to study the possibility of such phenomena within the framework of classical general relativity one needs to impose certain restrictions on the properties of matter fields present in the theory. These restrictions are usually called  energy conditions   5  . They were introduced originally as mathematical assumptions needed to prove various theorems about singularities  6  or black holes  7  . Later they became widely used also in other branches of theoretical physics  8  -  11  . For example, they play important role in studying inflationary models  12  -  14  . \n \n 2 Energy Conditions in Cosmology \n \n Let us start our discussion with the following set of four basic energy conditions  15  :",
        "watermark_text": "We consider the energy conditions in cosmology , which are necessary for the existence of matter with positive pressure . We see that these conditions can be violated by quantum effects at high energies .In particular , we find that the universe is accelerating now because of such defects . The results collected accord well with observations .Keywords : Energy condition , Quantum gravity , Acceleration of the universe 1 Introduction It has been known since the work of Einstein 1 , that the gravitational field equations imply solutions describing an accelerated expansion of space - time ( saw e . g . , 2 ) . This fact was confirmed later on by various observational data 3 .However , it remains unsure what causes this phenomenon . One potential explanation could be connected to some new science beyond general relativity 4 .In order to study the possibility of such interactions within the framework of classical general relativity one needs to introduce certain constraints on the properties of matter fields encountered in the theory . These restrictions are typically called energy conditions 5 .They were introduced originally as mathematical statements needed to prove several theorems about singularities 6 or black holes 7 . Afterwards they becoming widely useful also in other branches of theoretical physics 8 - 11 .For instance , they serve useful character in understanding inflationary theories 12 - 14 . 2 Energy Conditions in Cosmology Let us begin our debate with the following setting of four fundamental energy conditions 15 :",
        "rewrite_text": "We examine the energy conditions in cosmology that are essential for the presence of matter with positive pressure. Our findings suggest that these conditions can be breached due to quantum effects at high energies. Specifically, we observe that the current acceleration of the universe can be attributed to such anomalies, and our results align closely with empirical observations. \n\nKeywords: Energy condition, Quantum gravity, Acceleration of the universe \n\n1. Introduction\n\nSince Einstein's original work, it has been recognized that the gravitational field equations can yield solutions indicative of an accelerated expansion of spacetime (refer to e.g., 2). This phenomenon was later corroborated by several observational studies (3). However, the underlying cause of this acceleration remains uncertain. A possible explanation may lie in new scientific frameworks that extend beyond general relativity (4). To explore potential interactions within the classical general relativity framework, certain constraints on the properties of matter fields must be introduced. These constraints are commonly referred to as energy conditions (5). Initially, they were formulated as mathematical propositions necessary for proving several theorems regarding singularities (6) and black holes (7). Subsequently, these energy conditions have proven to be immensely valuable in various other areas of theoretical physics (8-11), including their role in elucidating inflationary theories (12-14). \n\n2. Energy Conditions in Cosmology\n\nWe will initiate our discussion with an overview of the four fundamental energy conditions (15):",
        "ori-fast-z-score": 0.944911182523068,
        "water-fast-z-score": 6.614378277661476,
        "rewrite-fast-z-score": -0.09759000729485333
    },
    {
        "original_text": "The DualHeap selection algorithm is an efficient method for selecting the kth smallest element in a set S of n elements.  It has been used to solve many problems including finding the minimum spanning tree (MST) in parallel computing environments such as MapReduce.   In this article we present some new results on the DualHeap algorithm that shed light on its efficiency and inherent parallelism.    We show how it can be implemented using only O(logn) bits per element while still maintaining its efficiency guarantees.   This implementation requires no extra space beyond what is needed by the input data itself and thus fits well with modern storage devices like flash memory or hard disks where storing large amounts of data is cheap but accessing individual items may be expensive.   Finally, we prove that the DualHeap algorithm solves the MST problem faster than any other known deterministic algorithm when run on a single processor machine. The DualHeap selection algorithm is one of the most widely used algorithms in computer science today.",
        "watermark_text": "The DualHeap selection method is an efficient algorithm for determining the kth smallest element in a set S of n elements . It has been used to solve many difficulties especially seeking the minimum spanning path ( MST ) in concurrent processing applications such as MapReduce .In this page we present some different results on the DualHeap algorithm that shed light on its reliability and inherent parallelism . We see how it can be executed using only O ( logn ) characters per element while nevertheless maintaining its productivity guarantees .This architecture requires no additional room beyond what is required by the input data itself and therefore fitted well with modern storage devices like flash memory or hard disks where storing huge amounts of data is cheap but accessing individual items might be expensive . Finally , we prove that the DualHeap algorithm solves the MST problem faster than any other known deterministic procedure when run on a single CPU machine .The DualHeap selection method is one of the most commonly used algorithms in computer science today .",
        "rewrite_text": "The DualHeap selection method is an effective algorithm for finding the kth smallest element in a set S with n elements. It has been widely applied to tackle various challenges, particularly in determining the minimum spanning tree (MST) in concurrent processing contexts like MapReduce. This page presents various findings regarding the DualHeap algorithm, emphasizing its reliability and inherent parallelism. Remarkably, it can be executed with only O(log n) characters per element while still ensuring productivity guarantees. This architecture requires no extra space beyond the input data itself, making it well-suited for modern storage devices such as flash memory or hard drives, where it's economical to store large datasets but costly to access individual items. Finally, we demonstrate that the DualHeap algorithm outperforms all known deterministic methods for solving the MST problem when executed on a single CPU machine. Consequently, the DualHeap selection method remains one of the most widely utilized algorithms in computer science today.",
        "ori-fast-z-score": -1.4100479758212652,
        "water-fast-z-score": 5.673665146135802,
        "rewrite-fast-z-score": 1.865992419824736
    },
    {
        "original_text": "The effect of cooling rate on martensitic transformation temperature (Mf) was investigated for Ni$_{50}$ Mn$_{34}$ In$_{16}$ alloy using differential scanning calorimetry (DSC). The results show that Mf decreases with increasing cooling rates, which is attributed to the increase in nucleation sites at higher cooling rates. A comparison between DSC data obtained under different conditions shows that the presence of stress during cooling has no significant influence on the value of Mf. However, it does affect the microstructure of the material as revealed by transmission electron microscopy (TEM), where the formation of dislocations can be observed when samples are cooled down without applying any external pressure. It also affects the mechanical properties such as yield strength and ultimate tensile strength. \n \n © 2014 Elsevier B.V. \nKeywords: Magnetic shape memory alloys; Cooling rate; Martensitic transformation",
        "watermark_text": "The impact of cooling rate on martensitic transformation temperature ( Mf ) was investigated for Ni $ _ { 50 } $ Mn $ _ { 34 } $ In $ _ { 16 } $ alloy utilizing differential scanning calorimetry ( DSC ) . The results show that Mf falls with higher cooling rates , which is attributed to the improvement in nucleation sites at higher cooling rates .A comparison between DSC data derived under various circumstances reveals that the presence of stress during cooling has no important affect on the value of Mf . However , it does affect the microstructure of the material as revealed by transmission electron microscopy ( TEM ) , where the formation of dislocations can be observed when samples are heated down without applying any external stress .It additionally impacts the structural properties such as yield strength and absolute tensile strength . © 2014 Elsevier B . V . Keywords : Magnetic shape memory alloys ; Cooling rate ; Martensitic transformation",
        "rewrite_text": "The influence of cooling rate on the martensitic transformation temperature (Mf) for the Ni$_{50}$Mn$_{34}$In$_{16}$ alloy was examined using differential scanning calorimetry (DSC). The findings indicate that Mf decreases with increasing cooling rates, a phenomenon attributed to the enhancement of nucleation sites at these higher rates. A comparison of DSC data obtained under various conditions suggests that the presence of stress during cooling does not significantly affect the value of Mf. However, it does influence the microstructure of the material, as demonstrated by transmission electron microscopy (TEM), which reveals the formation of dislocations in samples cooled without any external stress. This also impacts structural properties, including yield strength and absolute tensile strength. © 2014 Elsevier B.V. Keywords: Magnetic shape memory alloys; Cooling rate; Martensitic transformation.",
        "ori-fast-z-score": -0.13018891098082389,
        "water-fast-z-score": 3.6765801200722312,
        "rewrite-fast-z-score": 0.13018891098082389
    },
    {
        "original_text": "We present an alternative approach to reconstructing the scalar-field Lagrangian in scalar-tensor theories, based on the assumption that the background cosmology is described by standard ΛCDM (Lambda Cold Dark Matter) model with negligible tensor perturbations. We show how this method can be used to derive constraints on the parameters of the theory using current data sets such as WMAP7+BAO+H0. The resulting parameter space for some representative models are shown to agree well with those obtained previously through other methods. \n \n In particular we consider two classes of models - quintessence-like models where the field potential has a minimum at finite value of the field, and k-essence-like models which have no minima but instead feature a kinetic term with non-canonical dependence on the field velocity. For both cases we find that the allowed range of values for the coupling constant between matter and the scalar field agrees very well with previous results derived from different approaches.",
        "watermark_text": "We present an alternative approach to reconstructing the scalar - field Lagrangian in scalar - vector models , using on the assumption that the background cosmology is modeled by traditional ΛCDM ( Lambda Cold Dark Matter ) model with negligible vector perturbations . We see how this method can be used to derive restrictions on the variables of the model utilizing current data sets such as WMAP7 + BAO + H0 .The resulting parameter space for some representative models are shown to agree well with those generated previously through other methods . In particular we define two groups of models - quintessence - like models where the field potential has a minimum at finite value of the field , and k - essence - like systems which have no minima but instead feature a kinetic term with non - canonical dependence on the field momentum .For both cases we find that the allowed range of values for the interaction constant between matter and the scalar field agrees very best with previous findings obtained from different methods .",
        "rewrite_text": "We introduce a novel approach for reconstructing the scalar-field Lagrangian within scalar-vector models, based on the premise that the background cosmology is described by the traditional ΛCDM (Lambda Cold Dark Matter) model with minimal vector perturbations. This method allows us to derive constraints on the model's variables using current datasets, including WMAP7, BAO, and H0. The resulting parameter space for several representative models aligns closely with results obtained through other techniques. Specifically, we categorize the models into two groups: quintessence-like models, which have a potential that reaches a minimum at a finite field value, and k-essence-like systems, which lack minima and instead exhibit a kinetic term that depends non-canonically on field momentum. In both cases, our findings indicate that the permissible range for the interaction constant between matter and the scalar field is in strong agreement with results from different methodologies.",
        "ori-fast-z-score": 0.11704114719613057,
        "water-fast-z-score": 4.564604740649092,
        "rewrite-fast-z-score": -0.7385489458759964
    },
    {
        "original_text": "We present new results on the properties and evolution of early-type galaxies (ETGs) in the Coma cluster, based on deep HST/ACS imaging data obtained as part of our ongoing survey for faint globular clusters associated with ETGs.  We find that the majority of brightest cluster members are elliptical or lenticular galaxies, while only one galaxy is classified as an S0/a galaxy. The fraction of S0s increases towards fainter luminosities, reaching about 50% at M V = −18 mag. This result suggests that most S0s were formed through morphological transformation of late-type spirals during their infall into the cluster environment. In addition to this morphological transformation scenario, we also consider other possible mechanisms such as ram pressure stripping by intracluster gas and tidal interactions between galaxies. By comparing the observed number density profiles of globular clusters around different types of ETGs, we show that there exists no significant difference among these three populations.",
        "watermark_text": "We report new data on the properties and evolution of early - class objects ( ETGs ) in the Coma cluster , using on deep HST / ACS scanning data acquired as part of our ongoing search for faint globular galaxies involved with ETGs . We see that the majority of brightest cluster elements are elliptical or lenticular galaxies , while only one galaxy is categorized as an S0 / a galaxy .The percentage of S0s increases towards fainter luminosities , increasing about 50 % at M V = −18 mag . This result suggests that most S0s were created through morphological transformation of late - class spirals during their infall into the cluster environment .In addition to this morphological transformation situation , we also consider other possible processes such as ram temperature stripping by intracluster gas and tidal interactions between galaxies . By matching the reported number density characteristics of globular complexes around different kinds of ETGs , we prove that there exists no major variation among these three communities .",
        "rewrite_text": "We present new findings on the characteristics and development of early-type objects (ETGs) in the Coma cluster, utilizing deep HST/ACS imaging data obtained during our ongoing investigation into faint globular galaxies associated with ETGs. Our analysis reveals that the majority of the brightest cluster members are elliptical or lenticular galaxies, with only one being classified as an S0/a galaxy. Interestingly, the proportion of S0 galaxies increases as we look at fainter luminosities, rising by approximately 50% at M_V = −18 mag. This trend suggests that many S0 galaxies likely formed through the morphological transformation of late-type spirals as they fell into the cluster environment. In addition to this morphological evolution, we also explore other potential processes, including ram-pressure stripping by intracluster gas and tidal interactions between galaxies. By comparing the reported number density of globular complexes surrounding various types of ETGs, we find no significant variation among these three groups.",
        "ori-fast-z-score": -1.4770978917519928,
        "water-fast-z-score": 5.662208585049306,
        "rewrite-fast-z-score": -0.3611575592573076
    },
    {
        "original_text": "We report on observations made by the High Energy Stereoscopic System (H.E.S. S.) telescope array in Namibia, which detected very-high-energy (VHE) gamma rays from the distant blazar  1ES1102-232 at redshift z = 0.186. The source was observed for more than 50 hours between September 2005 and March 2006 using data taken simultaneously with four telescopes. A total excess of 12 events above background were found within an energy range of 400 GeV to 20 TeV. No significant variability is seen during this period. We present results from spectral analysis performed over different time intervals as well as broadband modelling of the multi-wavelength spectrum including radio through X-ray measurements. This work demonstrates that H.E.S.  S. can detect sources beyond redshifts previously accessible only to ground-based Cherenkov telescopes. It also shows how such observations are important for understanding the physics of these extreme objects.",
        "watermark_text": "We report on observations made by the High Energy Stereoscopic System ( H . E . S . S . ) telescope array in Namibia , which detected very - large - energy ( VHE ) gamma radiation from the distant blazar 1ES1102 - 232 at redshift z = 0 . 186 .The source was seen for more than 50 hours between September 2005 and March 2006 using data taken concurrently with four telescopes . A total excess of 12 events above background were found within an energy range of 400 GeV to 20 TeV .No considerable variability is seen during this time . We see results from spectral study performed over different time periods as well as broadband analysis of the multi - wavelength spectrum including radio through X - ray observations .This research proves that H . E . S . S . can identify sources beyond redshifts previously accessible only to surface - based Cherenkov telescopes .It additionally shows how such observations are important for studying the physics of these extreme objects .",
        "rewrite_text": "We present findings from the High Energy Stereoscopic System (H.E.S.S.) telescope array in Namibia, which successfully detected very high-energy (VHE) gamma radiation from the distant blazar 1ES1102-232 at a redshift of z = 0.186. The observations spanned over 50 hours from September 2005 to March 2006 and were conducted using data from four telescopes simultaneously. We identified a total of 12 excess events above the background within an energy range of 400 GeV to 20 TeV, with no significant variability observed during the observation period. Our analysis includes results from spectral studies conducted over various time intervals, along with a broadband analysis of the multi-wavelength spectrum, covering radio to X-ray observations. This research demonstrates that H.E.S.S. is capable of identifying sources at redshifts that were previously unreachable by ground-based Cherenkov telescopes, highlighting the importance of such observations for advancing our understanding of the physics of these extreme cosmic objects.",
        "ori-fast-z-score": 1.016001016001524,
        "water-fast-z-score": 5.505585837114527,
        "rewrite-fast-z-score": 1.3643820804812932
    },
    {
        "original_text": "We report on the discovery and analysis of an extended, bright radio source at z = 1.55 associated with the galaxy cluster Abell S1063 (z = 0.33). The source is detected by both the VLA and ATCA as two lobes separated by ~1 arcmin. It has a total flux density of 2.2 Jy at 5 GHz and shows no evidence for variability over more than 20 years. We find that this object is similar to other distant FR-II sources but it also exhibits some unusual properties. In particular, its luminosity is higher than expected based on the correlation between jet power and lobe luminosity observed locally. This may be due to either relativistic beaming effects and/or a high accretion rate onto the central black hole. Using deep Chandra observations we detect diffuse soft X-rays extending out to several hundred kiloparsecs around the core of the cluster which are likely produced via thermal bremsstrahlung radiation. However, there appears to be a compact region of hard X-ray emission located within 30 kpc of the center of the cluster coincident with the location of the radio source.",
        "watermark_text": "We report on the discovery and evaluation of an extended , faint radio signal at z = 1 . 55 associated with the galaxy community Abell S1063 ( z = 0 . 33 ) . The source is detected by both the VLA and ATCA as two lobes divided by ~ 1 arcmin .It has a total flux concentration of 2 . 2 Jy at 5 GHz and shows no evidence for variability over more than 20 decades . We see that this particle is related to other nearby FR - II sources but it also exhibits some unusual characteristics .In particular , its luminosity is higher than expected based on the relationship between jet speed and lobe luminosity observed locally . This might be due to either relativistic beaming effects and / or a high accretion rate onto the main dark hole .Using deep Chandra measurements we perceive diffuse soft X - radiation stretching out to several hundred kiloparsecs around the core of the cluster which are likely generated via thermal bremsstrahlung rays . However , there seems to be a compact region of hard X - ray radiation located within 30 kpc of the center of the cluster coincident with the location of the radio source .",
        "rewrite_text": "We present the discovery and assessment of a faint, extended radio signal at a redshift of z = 1.55, associated with the galaxy cluster Abell S1063 (z = 0.33). The source has been identified by both the VLA and ATCA, appearing as two lobes separated by approximately 1 arcminute. It has a total flux density of 2.2 Jy at 5 GHz and shows no signs of variability over a span of more than 20 decades. This source is linked to other nearby FR-II sources, but it also displays some atypical traits. Notably, its luminosity is higher than what is typically expected from the correlation between jet speed and lobe luminosity observed locally. This discrepancy may be attributed to relativistic beaming effects and/or a high accretion rate onto the central supermassive black hole. Through deep Chandra observations, we observe diffuse soft X-ray emissions extending several hundred kiloparsecs from the cluster's core, likely produced by thermal bremsstrahlung. Additionally, there appears to be a compact region of hard X-ray emission located within 30 kpc of the cluster center, coinciding with the position of the radio source.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.888972745734182,
        "rewrite-fast-z-score": 0.3511234415883917
    },
    {
        "original_text": "We study the disordering transitions in polydisperse particle systems with repulsive interactions by means of Monte Carlo simulations. We find that, for sufficiently large polydispersity index, there is no phase transition at all; instead we observe an increase of entropy as temperature decreases. For smaller values of the polydispersity index we find two different types of ordering transitions depending on whether or not particles are allowed to evaporate during cooling. In both cases we find evidence for a peak effect which can be explained within mean-field theory. The results presented here should also apply to other systems where evaporation plays a role such as colloidal suspensions. \n \n Introduction \n \n Disordered states play an important role in many physical phenomena ranging from glassy materials over granular matter to biological systems like proteins  1  . A common feature of these systems is their tendency towards ordering: At high temperatures they usually exhibit liquid-like behavior while below some critical temperature T c , they freeze into solid structures. This freezing process is accompanied by a discontinuous change of thermodynamic quantities (e.g., specific heat) signaling a first-order phase transition  2  .\n \nIn this work we consider disordered systems consisting of N interacting particles confined to a volume V . These particles may have different sizes and/or charges leading to a distribution of interaction energies between them. As a result, even if the system has only one type of particles it will behave differently than a monodisperse system  3  . If the width of the size/charge distribution becomes too large, however, the system loses its ability to form ordered phases altogether  4  . It then behaves more like a gas rather than a liquid  5  . \n \n Here we investigate how the presence of polydispersity affects the nature of the disordering transitions observed in these systems. To do so, we perform Monte Carlo simulations using a model introduced by Kob and Andersen  6  . Our main finding is that, for sufficiently large values of the polydisperisty index, there exists no phase transition at all but rather a continuous decrease of entropy upon decreasing temperature. On the other hand, for small enough polydispers",
        "watermark_text": "We explore the disordering transitions in polydisperse particle structures with repulsive interactions by means of Monte Carlo simulations . We see that , for enough large polydispersity index , there is no phase shift at all ; instead we study an increase of entropy as temperature falls .For lower values of the polydispersity index we find two different kinds of ordering changes varying on whether or not atoms are allowed to evaporate during cooling . In both cases we find proof for a peak influence which can be described within mean - field model .The results presented here should additionally apply to other processes where evaporation plays a role such as colloidal suspensions . Introduction Disordered states play an important role in many natural phenomena ranging from glassy materials over granular material to biological systems like genes 1 .A characteristic characteristic of these systems is their tendency towards ordering : At high temperatures they generally exhibit water - like behavior while below some significant heat T c , they freeze into solid structures . This freezing process is preceded by a discontinuous change of thermodynamic quantities ( e . g . , basic heat ) signaling a first - order phase change 2 .In this research we study disordered systems composed of N interacting interactions enclosed to a volume V . These particles may have different shapes and / or charges leading to a distribution of coupling energies between them .As a result , even if the scheme has only one sort of particles it will react differently than a monodisperse scheme 3 . If the length of the size / charge distribution gets too huge , however , the scheme drops its capacity to form ordered phases entirely 4 .It then behaves more like a gas instead than a liquid 5 . Here we investigate how the presence of polydispersity affects the nature of the disordering transitions observed in these systems .To do so , we perform Monte Carlo simulations using a theory introduced by Kob and Andersen 6 . Our main discovery is that , for sufficiently high values of the polydisperisty index , there exists no phase shift at all but rather a periodic drop of entropy upon decreasing temperature .On the other hand , for low enough polydispers",
        "rewrite_text": "We investigate the disordering transitions in structures comprised of polydisperse particles with repulsive interactions through Monte Carlo simulations. Our findings indicate that at sufficiently high polydispersity indices, no phase transition occurs; instead, we observe an increase in entropy as the temperature decreases. In contrast, at lower polydispersity indices, we identify two distinct types of ordering changes, which differ depending on whether particle evaporation is permitted during the cooling process. In both scenarios, we provide evidence for a peak influence that aligns with a mean-field model description. The results presented are expected to be applicable to other contexts where evaporation is a factor, such as in colloidal suspensions.\n\n**Introduction**  \nDisordered states are crucial to various natural phenomena, including glassy materials, granular matter, and biological systems like genes. A notable characteristic of these systems is their propensity to order: at elevated temperatures, they typically exhibit liquid-like behavior, while below a certain critical temperature (T_c), they transition into solid structures. This freezing process is marked by a discontinuous change in thermodynamic properties (e.g., specific heat), indicating a first-order phase transition. In this study, we focus on disordered systems composed of N interacting particles confined in a volume V. These particles can possess varying shapes and/or charges, resulting in a distribution of coupling energies. Consequently, a system with a single particle type behaves differently than a monodisperse system. However, if the range of size or charge variation becomes sufficiently large, the system loses its ability to form ordered phases entirely and behaves more like a gas than a liquid. Here, we examine how polydispersity influences the nature of disordering transitions in these systems. To achieve this, we utilize Monte Carlo simulations grounded in a theory formulated by Kob and Andersen. Our primary finding reveals that at high polydispersity indices, no phase transition occurs, which is instead characterized by a regular decrease in entropy as the temperature drops. Conversely, for lower polydispersity indices, we observe a different behavior in the ordering transitions.",
        "ori-fast-z-score": -1.2649110640673518,
        "water-fast-z-score": 7.58946638440411,
        "rewrite-fast-z-score": -0.159111456835146
    },
    {
        "original_text": "We present new results on the detection rate, mass distribution, and orbital properties of hypervelocity stars (HVSs) in the Galactic halo based on spectroscopic observations with Keck II/DEIMOS over three years. We find that HVSs are detected at a rate of 0.5 +/- 0.2 per year within 100 pc of the Galactic center. The observed number density profile is consistent with an exponential fall-off with distance from the Galactic center. Our sample contains two HVSs with velocities greater than 1000 km/s; one has a heliocentric radial velocity of 1240 km/s and another has 1420 km/s. These high velocities suggest that these objects were ejected by gravitational slingshots during close encounters between massive black holes or neutron stars. In addition to the known population of HVSs near the Sun, we also detect a large number of high-velocity stars located farther away from the Galactic center which may be associated with other nearby supermassive black holes.",
        "watermark_text": "We report new data on the detection rate , mass distribution , and orbital properties of hypervelocity stars ( HVSs ) in the Galactic halo based on spectroscopic observations with Keck II / DEIMOS over three years . We see that HVSs are detected at a rate of 0 . 5 + / - 0 . 2 per month within 100 pc of the Galactic center .The observed number density profile is compatible with an exponential fall - off with distance from the Galactic center . Our specimen contains two HVSs with velocities greater than 1000 kilometers / s ; one has a heliocentric radial speed of 1240 km / s and another has 1420 km / s .These high velocities indicate that these objects were ejected by gravitational slingshots during close contacts between massive brown holes or neutron galaxies . In addition to the known community of HVSs near the Sun , we also observe a large number of high - speed stars situated closer back from the Galactic center which may be involved with other nearby supermassive black holes .",
        "rewrite_text": "We present new findings on the detection rate, mass distribution, and orbital characteristics of hypervelocity stars (HVSs) in the Galactic halo, derived from three years of spectroscopic observations using Keck II / DEIMOS. Our results indicate a detection rate of 0.5 ± 0.2 HVSs per month within 100 parsecs of the Galactic center. The observed number density profile aligns with an exponential decline as the distance from the Galactic center increases. Among our sample, we identified two HVSs with velocities exceeding 1000 kilometers per second; one has a heliocentric radial speed of 1240 km/s, while the other measures 1420 km/s. These remarkable speeds suggest that these stars were ejected through gravitational slingshot events caused by close encounters with massive black holes or neutron stars. Besides the established population of HVSs near the Sun, we have also detected a considerable number of high-speed stars residing further back from the Galactic center, which may be associated with other nearby supermassive black holes.",
        "ori-fast-z-score": 0.8682431421244593,
        "water-fast-z-score": 5.581563056514381,
        "rewrite-fast-z-score": 0.7171371656006361
    },
    {
        "original_text": "We present an equation-of-state (EOS) model for solar matter that is based on the path integral formalism and includes quantum nuclear effects in the form of shell corrections, which are calculated using realistic nuclear interactions. The EOS covers densities ranging from 0 to 1.5 times normal density at temperatures between 10^6 K and 5×10^8 K. We compare our results against those obtained by other authors who used different methods or approximations. Our new EOS agrees well with previous calculations within their respective domains of validity but extends these into previously unexplored regions. In particular we find that the pressure increases more rapidly than predicted by standard models when approaching the center of the Sun. This leads to higher central temperatures and lower radii compared to standard models. These differences may be important for understanding the structure of stars like the Sun as well as for modeling stellar evolution. \n \n Keywords: Solar interior",
        "watermark_text": "We create an equation - of - state ( EOS ) model for solar material that is based on the path integral formalism and incorporates quantum nuclear effects in the form of shell corrections , which are measured using realistic nuclear interactions . The EOS includes densities extending from 0 to 1 . 5 times normal density at levels between 10 ^ 6 K and 5×10 ^ 8 K . We match our findings against those achieved by other researchers who used various methods or approximations .Our current EOS follows well with previous analyses within their different domains of validity but extends these into formerly unexplored regions . In particular we find that the pressure changes more fast than expected by traditional models when approaching the center of the Sun .This leads to higher central temperatures and less radii compared to standard models . These changes may be crucial for knowledge the composition of stars like the Sun as also as for modeling stellar evolution .Keywords: Solar interior",
        "rewrite_text": "We have developed an equation-of-state (EOS) model for solar material that utilizes the path integral formalism and accounts for quantum nuclear effects through shell corrections, which are determined using realistic nuclear interactions. This EOS encompasses densities ranging from 0 to 1.5 times the normal density at temperatures between 10^6 K and 5×10^8 K. We compare our results with those obtained by other researchers who employed various methods and approximations. Our current EOS aligns well with previous analyses within their respective domains of validity, while also extending into previously uncharted territories. Notably, we observe that pressure increases more rapidly than predicted by traditional models as we move towards the Sun's core. This results in elevated central temperatures and smaller radii compared to conventional models. These insights could be significant for understanding the composition of stars like the Sun and for modeling stellar evolution. Keywords: Solar interior.",
        "ori-fast-z-score": -0.5852057359806528,
        "water-fast-z-score": 5.7350162126103985,
        "rewrite-fast-z-score": 0.11867816581938533
    },
    {
        "original_text": "We consider the probability distribution of the number of times that a simple random walk on an infinite graph visits some fixed vertex in finite time, and show how this can be approximated by a Poisson distribution with mean equal to the expected value of the number of visits.  We then use these results to prove that the total variation distance between the two distributions is bounded above by $O(1/n)$ where $n$ denotes the number of vertices in the graph.   This result generalizes previous work which was restricted to graphs whose degree sequence has exponential decay or polynomial growth.    The proof relies heavily upon recent advances in the theory of large deviations for sums of dependent Bernoulli variables. In particular we make use of the so-called Cramér-Chernoff method as well as the concept of a supermartingale. Finally, we apply our main theorem to obtain new bounds on the mixing time of lazy random walks on regular trees.",
        "watermark_text": "We consider the probability distribution of the number of twice that a simple random walk on an endless graph visits some fixed vertex in finite time , and know how this can be approximated by a Poisson distribution with mean equivalent to the expected value of the number of visits . We then use these results to obtain that the total variation length between the two distributions is bounded above by $ O ( 1 / n ) $ where $ n $ represents the number of vertices in the graph .This result generalizes earlier papers which was restricted to graphs whose degree sequence has exponential decay or polynomial growth . The proof draws highly upon recent developments in the notion of large deviations for sums of dependent Bernoulli variables .In particular we make using of the so - called Cramér - Chernoff procedure as well as the idea of a supermartingale . Finally , we apply our major principle to obtain new limits on the mix speed of lazy random tours on regular trees .",
        "rewrite_text": "We investigate the probability distribution of the number of times a simple random walk on an infinite graph visits a fixed vertex in finite time. It is established that this distribution can be approximated by a Poisson distribution, where the mean corresponds to the expected number of visits. Utilizing these findings, we demonstrate that the total variation distance between the two distributions is bounded above by \\( O(1/n) \\), with \\( n \\) denoting the number of vertices in the graph. This result extends previous studies that were limited to graphs with either exponentially decaying degree sequences or polynomial growth. The proof leverages recent advancements in the theory of large deviations for sums of dependent Bernoulli variables, specifically employing the Cramér-Chernoff method and concepts from supermartingales. Lastly, we apply our main results to establish new bounds on the mixing speed of lazy random walks on regular trees.",
        "ori-fast-z-score": -0.7875615306482168,
        "water-fast-z-score": 4.162825233426289,
        "rewrite-fast-z-score": -2.0465595024580763
    },
    {
        "original_text": "We have studied the scaling behavior of two different types of surfaces, one made out of pyrex glass (a transparent material) and another made out of silicon dioxide (SiO2), which is an opaque material. The SiO2 surface was prepared by etching in hydrofluoric acid to remove all traces of metal contamination that could be present on its surface after being cut from a wafer. Both surfaces were then cleaned using standard cleaning procedures before they were subjected to particle bombardment at room temperature under ultra-high vacuum conditions.  We found that both surfaces exhibit similar scaling behaviors when we plot their respective roughness as a function of the number of deposited atoms per unit area for various incident angles ranging between 0°and 60°. However, there are some differences observed in the scaling exponents obtained for these two surfaces. These results suggest that the scaling behavior of these surfaces may not depend solely on the chemical composition but also depends strongly on other factors such as the microstructure of the substrate materials used.",
        "watermark_text": "We have researched the scaling behavior of two different kinds of structures , one made out of pyrex glass ( a transparent material ) and another created out of silicon dioxide ( SiO2 ) , which is an opaque material . The SiO2 surface was prepared by etching in hydrofluoric acid to remove all traces of steel pollution that might be found on its surface after being cut from a wafer .Both bodies were then cleaned using traditional cleaning procedures before they were subjected to particle bombardment at room temperature under ultra - large vacuum environments . We showed that both surfaces display analogous scaling actions when we calculated their respective roughness as a function of the quantity of deposited atoms per unit area for various incident angles ranging between 0°and 60° .However , there are some variations found in the scaling exponents found for these two materials . These data suggest that the scaling behavior of these surfaces may not depend purely on the chemical composition but also relies highly on other parameters such as the microstructure of the substrate surfaces used .",
        "rewrite_text": "We conducted a study on the scaling behavior of two different types of materials: one composed of Pyrex glass, a transparent substance, and the other made from silicon dioxide (SiO2), which is opaque. The SiO2 surface was prepared by etching it with hydrofluoric acid to eliminate any steel contaminants that may have remained from its cutting process. Both materials were then thoroughly cleaned using standard procedures before undergoing particle bombardment at room temperature in an ultra-high vacuum environment. Our findings revealed that both surfaces exhibited similar scaling behavior when we analyzed their roughness in relation to the amount of deposited atoms per unit area at various incident angles ranging from 0° to 60°. However, we observed some differences in the scaling exponents for the two materials. This data indicates that the scaling behavior of these surfaces may not solely depend on their chemical composition, but could also be significantly influenced by other factors, such as the microstructure of the substrate surfaces.",
        "ori-fast-z-score": 0.917662935482247,
        "water-fast-z-score": 7.4074374698764665,
        "rewrite-fast-z-score": 2.6919463855110033
    },
    {
        "original_text": "We have analyzed nine years (1991â€“1998) of data on blazars observed by the Energetic Gamma Ray Experiment Telescope (EGRET). We find that there is no significant correlation between gamma-ray flux and photon index for individual sources, but we do see evidence for an anti-correlation when all sources are combined into one sample. This result suggests that the spectrum hardens as the source brightens. The lack of such a trend in single-source analysis may be due to insufficient statistics or intrinsic spectral variability within each source. Our results also suggest that the average luminosity of blazars increases faster than linearly with increasing redshift. These findings can help us understand how relativistic jets work in active galactic nuclei. Relativistic jets play important roles in many astrophysical phenomena including active galactic nuclei (AGNs), microquasars, pulsar winds, and gamma ray bursts (GRBs). In AGNs, they are believed to carry away most of the energy produced at the central engine. However, it remains unclear what physical processes drive these energetic outflows.",
        "watermark_text": "We have analyzed nine years ( 1991â€ “ 1998 ) of statistics on blazars observed by the Energetic Gamma Ray Experiment Telescope ( EGRET ) . We see that there is no considerable relationship between beta - ray density and photon index for individual sources , but we do hear proof for an counter - correlation when all sources are combined into one sample .This result suggests that the spectrum hardens as the source brightens . The lack of such a tendency in single - source studies might be due to lacking statistics or intrinsic spectral variability within each source .Our results also suggest that the average luminosity of blazars increases faster than linearly with increasing redshift . These studies can help us explain how relativistic jets act in active galactic nuclei .Relativistic jets serve active roles in many astrophysical processes including active galactic nuclei ( AGNs ) , microquasars , pulsar winds , and gamma ray bursts ( GRBs ) . In AGNs , they are said to carry away most of the power emitted at the main engine .However , it remains unsure what physical processes drive these active outflows .",
        "rewrite_text": "We have examined nine years of blazar statistics (from 1991 to 1998) collected by the Energetic Gamma Ray Experiment Telescope (EGRET). Our analysis reveals no significant correlation between beta-ray density and photon index for individual sources. However, when aggregating all sources into a single sample, we observe evidence of a counter-correlation, suggesting that the spectrum becomes harder as the source brightens. The absence of a similar trend in individual source studies may be attributed to insufficient statistics or inherent spectral variability within each source. Additionally, our findings indicate that the average luminosity of blazars increases at a rate faster than linear as redshift rises. These insights contribute to our understanding of the behavior of relativistic jets in active galactic nuclei (AGNs). Relativistic jets play crucial roles in various astrophysical phenomena, including AGNs, microquasars, pulsar winds, and gamma-ray bursts (GRBs). In the context of AGNs, these jets are believed to carry away a significant portion of the energy produced by the central engine. Nonetheless, the underlying physical processes that drive these active outflows remain uncertain.",
        "ori-fast-z-score": -0.22941573387056174,
        "water-fast-z-score": 4.672383634845156,
        "rewrite-fast-z-score": 0.1111111111111111
    },
    {
        "original_text": "In this work, we revisit some issues on netflow sample and export performance in terms of packet loss rate (PLR) and flow sampling accuracy (FSA). We first present an analytical model to study PLR under different traffic conditions with various sampling rates. Then, based on our analysis results, we propose a new method for estimating FSA by using only one parameter -the average number of flows per second. Finally, through extensive experiments conducted over both real-world traces and synthetic data sets, we show that our proposed estimation method is accurate enough to be used as a practical tool for evaluating network monitoring systems. The rest of this paper is organized as follows. In Section 2, we introduce related works about netflow sampling and exporting. In Section 3, we describe our experimental environment. In Section 4, we analyze the relationship between PLR and sampling rate. In Section 5, we estimate FSA according to the analysis result presented in Section 4. In Section 6, we evaluate the effectiveness of our proposed estimation method via extensive experiments. Finally, conclusions are drawn in Section 7.",
        "watermark_text": "In this research , we revisit some issues on netflow sample and export quality in terms of packet loss rate ( PLR ) and flow sampling accuracy ( FSA ) . We first offer an analytical method to study PLR under various traffic conditions with various sampling rates .Then , using on our analysis results , we propose a new method for estimating FSA by using only one parameter - the average number of flows per second . Finally , through numerous experiments conducted over both real - time traces and synthetic information sets , we prove that our proposed estimation method is accurate sufficient to be used as a practical tool for evaluating network monitoring systems .The rest of this paper is organized as follows . In Section 2 , we provide similar papers about netflow sampling and exporting .In Section 3 , we explain our experimental environment . In Section 4 , we assess the relationship between PLR and sampling rate .In Section 5 , we estimate FSA according to the evaluation result provided in Section 4 . In Section 6 , we assess the performance of our proposed estimation method via extensive experiments .Finally , findings are drawn in Section 7 .",
        "rewrite_text": "In this research, we examine key issues related to netflow sampling and export quality with a focus on packet loss rate (PLR) and flow sampling accuracy (FSA). We begin by introducing an analytical approach to investigate PLR under varying traffic conditions and sampling rates. Building on our analytical findings, we propose a novel method to estimate FSA using a single parameter: the average number of flows per second. Through a series of experiments conducted on both real-time trace data and synthetic datasets, we demonstrate that our proposed estimation method is sufficiently accurate for practical application in evaluating network monitoring systems. The structure of this paper is as follows: Section 2 reviews related work on netflow sampling and export. Section 3 describes our experimental setup. Section 4 analyzes the correlation between PLR and sampling rate. In Section 5, we estimate FSA based on the evaluations from Section 4. Section 6 examines the performance of our estimation method through comprehensive experiments. Finally, we present our conclusions in Section 7.",
        "ori-fast-z-score": 1.8973665961010275,
        "water-fast-z-score": 5.9752235693149345,
        "rewrite-fast-z-score": 1.5096588248481377
    },
    {
        "original_text": "We report on the detection and analysis of radio emission associated with an impulsive solar flare that occurred in active region NOAA 10486 (SOL2010-07-20T17:48) at 17:48 UT on July 20, 2010 using the Nançay Decameter Array (NDA). The event was accompanied by a fast halo coronal mass ejection (CME), which reached Earth at 18:20 UT on July 21. We find that the radio source is located near the center of the CME front as seen in white light images taken by STEREO-Ahead/EUVI 195 Å . The radio flux density shows rapid evolution during the first hour after the onset of the flare, followed by gradual decay over several hours. The radio spectrum has a power-law shape between 1 MHz to 5 GHz. The spectral index decreases rapidly below 100 MHz but remains nearly constant above this frequency.",
        "watermark_text": "We report on the detection and assessment of radio emission associated with an impulsive solar flare that occurred in active region NOAA 10486 ( SOL2010 - 07 - 20T17 : 48 ) at 17 : 48 UT on July 20 , 2010 using the Nançay Decameter Array ( NDA ) . The event was accompanied by a rapid halo coronal mass ejection ( CME ) , which reached Earth at 18 : 20 UT on July 21 .We see that the radio source is situated near the center of the CME front as shown in white light pictures taken by STEREO - Ahead / EUVI 195 Å . The radio flux concentration displays rapid change during the first hour after the outbreak of the flare , followed by rapid fading over numerous weeks .The radio signal has a power - law shape between 1 MHz to 5 GHz . The spectral index drops rapidly below 100 MHz but maintains fairly constant above this signal .",
        "rewrite_text": "We present our findings on the detection and analysis of radio emissions linked to an impulsive solar flare that took place in active region NOAA 10486 (SOL2010-07-20T17:48) at 17:48 UT on July 20, 2010, utilizing the Nançay Decameter Array (NDA). This event was accompanied by a swift halo coronal mass ejection (CME) that reached Earth by 18:20 UT on July 21. Observations reveal that the radio source is located near the center of the CME front, as evidenced by white light images captured by STEREO-Ahead/EUVI at 195 Å. The concentration of radio flux exhibits rapid changes during the first hour following the flare, followed by a gradual decline over several weeks. The radio signal displays a power-law distribution within the frequency range of 1 MHz to 5 GHz, with the spectral index decreasing quickly below 100 MHz while remaining relatively stable at higher frequencies.",
        "ori-fast-z-score": -1.1920791213585393,
        "water-fast-z-score": 3.841143835488627,
        "rewrite-fast-z-score": -0.629940788348712
    },
    {
        "original_text": "The authors present an overview of the current state-of-the-art in understanding how lipids form membranes and what determines their physical properties.  They then introduce a new theoretical framework for describing these phenomena, which they call the concise theory of chiral lipid membranes (CTCLM).  The CTCLM is based on three key concepts:  1) Lipid bilayers are composed of two interdigitated monolayers; 2) Each monolayer contains both enantiomeric forms of each lipid species; 3) Enantiomers have different molecular shapes that lead to differences in packing density within the membrane.  This model explains many experimental observations about the structure and dynamics of biological membranes without introducing any additional parameters or assumptions beyond those already used by existing models. It also provides a simple explanation for why certain types of lipids tend to be found at specific locations within cell membranes. Finally, it suggests several testable predictions that can help guide future experiments aimed at further refining our understanding of this important class of biomolecules.",
        "watermark_text": "The authors present an overview of the present state - of - the - art in understanding how lipids form membranes and what determines their physical properties . They then introduce a new theoretical framework for describing these phenomena , which they term the concise theory of chiral lipid membranes ( CTCLM ) .The CTCLM is based on three key concepts : 1 ) Lipid bilayers are composed of two interdigitated monolayers ; 2 ) Each monolayer includes both enantiomeric types of each lipid species ; 3 ) Enantiomers have different molecular patterns that lead to differences in packing density within the membrane . This theory presents many experimental studies about the composition and dynamics of biological membranes without removing any additional parameters or assumptions beyond those already applied by existing models .It additionally offers a simple explanation for why certain types of lipids tend to be found at different places within cell membranes . Finally , it presents several testable assumptions that can help guide upcoming experiments intended at further refining our grasp of this vital class of biomolecules .",
        "rewrite_text": "The authors provide a comprehensive overview of the current understanding of how lipids assemble into membranes and the factors influencing their physical properties. They introduce a novel theoretical framework they call the Concise Theory of Chiral Lipid Membranes (CTCLM). This theory is grounded in three fundamental principles: (1) Lipid bilayers consist of two interdigitated monolayers; (2) Each monolayer contains both enantiomeric forms of each lipid type; and (3) The different molecular arrangements of enantiomers result in variations in packing density within the membrane. The CTCLM accounts for many experimental findings related to the composition and dynamics of biological membranes without introducing any additional parameters or assumptions beyond those used in existing models. It also provides a straightforward explanation for the preferential distribution of certain lipid types within cell membranes. Lastly, the theory outlines several testable hypotheses that can inform future experiments aimed at deepening our understanding of this critical category of biomolecules.",
        "ori-fast-z-score": 2.457864091118742,
        "water-fast-z-score": 7.373592273356226,
        "rewrite-fast-z-score": 1.5
    },
    {
        "original_text": "We present results on polarized radio emission in the field surrounding the galaxy cluster Abell 2218, observed with the Australia Telescope Compact Array (ATCA) at 1.4 GHz and 4.8 GHz. We detect 16 compact sources above 5 mJy beam-1 at both frequencies; all but one are unresolved or marginally resolved by our observations. The majority have fractional linear polarization between 10% and 20%, while two objects show higher values up to 40%. All detected sources appear to be associated with galaxies within the central region of Abell 2218. In addition we find evidence for diffuse polarized emission around the brightest member of this galaxy cluster. This is likely due to synchrotron radiation produced by relativistic electrons accelerated in shocks driven into the intracluster medium during multiple mergers that occurred over time scales ranging from 10 Myr to several Gyrs ago. Our data also reveal an extended halo-like structure which surrounds the entire galaxy cluster.",
        "watermark_text": "We report findings on polarized radio emission in the field surrounding the galaxy cluster Abell 2218 , detected with the Australia Telescope Compact Array ( ATCA ) at 1 . 4 GHz and 4 . 8 GHz . We detect 16 compact sources above 5 mJy beam - 1 at both frequencies ; all but one are unresolved or marginally resolved by our observations .The majority have fractional linear polarization between 10 % and 20 % , while two bodies display larger ratings up to 40 % . All detected sources appear to be identified with galaxies within the inner region of Abell 2218 .In addition we find data for diffuse polarized emission around the brightest part of this galaxy cluster . This is probably due to synchrotron emission generated by relativistic electrons accelerated in shocks driven into the intracluster medium during various mergers that occurred over time ranges ranging from 10 Myr to several Gyrs ago .Our data also suggest an extended halo - like structure which covers the entire galaxy cluster .",
        "rewrite_text": "We present our findings on polarized radio emission in the vicinity of the galaxy cluster Abell 2218, which we detected using the Australia Telescope Compact Array (ATCA) at frequencies of 1.4 GHz and 4.8 GHz. Our observations revealed 16 compact sources with flux densities exceeding 5 mJy beam^-1 at both frequencies; nearly all of these sources are either unresolved or only marginally resolved. The majority exhibit fractional linear polarization levels between 10% and 20%, while two sources show higher polarization rates of up to 40%. All detected sources are associated with galaxies located in the inner region of Abell 2218. Additionally, we observed diffuse polarized emission surrounding the brightest part of the galaxy cluster, likely resulting from synchrotron radiation produced by relativistic electrons that have been accelerated in shocks within the intracluster medium during various mergers that have occurred over timescales ranging from 10 million to several billion years ago. Our data also indicate the presence of an extended halo-like structure that encompasses the entire galaxy cluster.",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 4.6475800154489,
        "rewrite-fast-z-score": -0.6201736729460423
    },
    {
        "original_text": "We present the results of our analysis on two gamma-ray bursts (GRBs) detected by Swift satellite, GRB 050410 and its afterglow at optical wavelengths, and GRB 050412; we find that both events have very low luminosities in their prompt emission phase as well as in their X-ray afterglows; this is consistent with them being  dark  GRBs.  We also report the detection of an unusual radio flare associated to GRB 050410 which may be related to the central engine activity or to late-time energy injection into the relativistic jet. The first event was discovered by Swift/BAT on April 10th 2006 at 07:41:06 UT  1  . It triggered BAT again at 08:47:12 UT  2  , but no further triggers were recorded until 09:55:43 UT  3  when it re-triggered BAT for one more time  4  .\nThe second event was discovered by Swift /BAT on April 12th 2006 at 06:52:53 UT  5  . No other triggers were recorded until 07:30:00 UT  6  when it re-triggered; however, there was another trigger at 07:45:20 UT  7  . Both events had durations longer than 2 s  8  ; therefore, they could not be classified as short-duration GRBs  9  .  They did not show any evidence of extended emission  10  nor multiple peaks  11  during their prompt phases  12  .",
        "watermark_text": "We present the conclusion of our analysis on two gamma - ray clusters ( GRBs ) detected by Swift satellite , GRB 050410 and its afterglow at optical wavelengths , and GRB 050412 ; we find that both events have very low luminosities in their prompt emission period as well as in their X - ray afterglows ; this is consistent with them being black GRBs . We additionally report the observation of an strange television flare associated to GRB 050410 which may be connected to the main motor behavior or to late - time energy conversion into the relativistic jet .The first phenomenon was discovered by Swift / BAT on April 10th 2006 at 07 : 41 : 06 UT 1 . It suppressed BAT again at 08 : 47 : 12 UT 2 , but no further triggers were registered until 09 : 55 : 43 UT 3 when it re - triggered BAT for one more time 4 .The second phenomenon was discovered by Swift / BAT on April 12th 2006 at 06 : 52 : 53 UT 5 . No other triggers were documented until 07 : 30 : 00 UT 6 when it re - triggered ; however , there was another trigger at 07 : 45 : 20 UT 7 .Both episodes had durations greater than 2 s 8 ; therefore , they cannot not be categorized as short - duration GRBs 9 . They did not show any evidence of extended emission 10 nor multiple levels 11 during their prompt stages 12 .",
        "rewrite_text": "We present the findings from our analysis of two gamma-ray bursts (GRBs) detected by the Swift satellite: GRB 050410, along with its optical afterglow, and GRB 050412. Our results indicate that both events exhibit significantly low luminosities during their prompt emission phases and in their X-ray afterglows, suggesting that they might be classified as black GRBs. Additionally, we report the observation of an unusual television flare associated with GRB 050410, which may relate to the primary engine activity or the late-time energy conversion into the relativistic jet. The first phenomenon was detected by Swift/BAT on April 10, 2006, at 07:41:06 UT and suppressed at 08:47:12 UT, with no further triggers until it re-activated at 09:55:43 UT. The second phenomenon was also picked up by Swift/BAT on April 12, 2006, at 06:52:53 UT, with no other triggers recorded until 07:30:00 UT, followed by an additional trigger at 07:45:20 UT. Both episodes had durations exceeding 2 seconds, thus they cannot be categorized as short-duration GRBs. There was no evidence of extended emission or multiple levels during their prompt phases.",
        "ori-fast-z-score": -0.75,
        "water-fast-z-score": 5.0,
        "rewrite-fast-z-score": 1.61245154965971
    },
    {
        "original_text": "We present the first measurement of the gamma-ray emission associated with the hot gas in galaxy clusters using data collected by Fermi Large Area Telescope (LAT). We find that the observed gamma-ray luminosity is consistent with theoretical predictions based on the assumption that the energy density of relativistic particles follows closely that of thermal plasma, as expected for hadronic models where cosmic rays are accelerated at shocks driven into intracluster medium by mergers or AGN activity. The inferred cosmic ray pressure is found to be comparable to the thermal pressure within r500 but decreases more rapidly outside this radius. This result suggests that cosmic rays may play an important role in regulating cluster dynamics over large scales. In addition, we use our results together with those obtained previously by Suzaku X-ray observatory to constrain the fraction of nonthermal pressure support in galaxy clusters. Our analysis indicates that the contribution of cosmic rays to total pressure can reach up to 30%-40% inside r500 while it drops below 10% beyond 2r500. Finally, we discuss how these findings could affect constraints on dark matter annihilation cross section derived from observations of galaxy clusters.",
        "watermark_text": "We present the first measurement of the gamma - ray radiation attributed with the hot gas in galaxy regions using data provided by Fermi Large Area Telescope ( LAT ) . We see that the seen γ - ray luminosity is compatible with theoretical expectations based on the assumption that the power concentration of relativistic objects resembles closely that of thermal plasma , as anticipated for hadronic models where cosmic rays are accelerated at shocks driven into intracluster medium by mergers or AGN activity .The inferred cosmic ray tension is found to be analogous to the thermal tension within r500 but decreases more swiftly outside this radius . This result suggests that cosmic rays may play an important role in controlling cluster structure over large scales .In addition , we using our findings together with those acquired previously by Suzaku X - ray observatory to constrain the fraction of nonthermal stress support in galaxy regions . Our study implies that the impact of cosmic rays to maximum pressure can reach up to 30 % - 40 % inside r500 while it rises below 10 % beyond 2r500 .Finally , we explain how these results could affect constraints on dark matter annihilation cross section obtained from measurements of galaxy clusters .",
        "rewrite_text": "We present the inaugural measurement of gamma-ray radiation linked to hot gas in galactic regions, utilizing data from the Fermi Large Area Telescope (LAT). Our findings indicate that the observed gamma-ray luminosity aligns with theoretical expectations based on the premise that the distribution of power among relativistic objects closely mirrors that of thermal plasma. This correlation is anticipated in hadronic models, where cosmic rays are accelerated by shocks within the intracluster medium due to mergers or AGN activity. The inferred cosmic ray pressure is found to be similar to the thermal pressure within r500, but it decreases more rapidly beyond this radius. This suggests that cosmic rays might significantly influence cluster structure on large scales. Furthermore, we combine our results with previously obtained data from the Suzaku X-ray Observatory to estimate the fraction of nonthermal pressure support in galactic regions. Our analysis indicates that the contribution of cosmic rays to the maximum pressure can reach 30% to 40% within r500, while this contribution drops below 10% beyond 2r500. Finally, we discuss how these findings may impact the constraints on dark matter annihilation cross-section derived from observations of galaxy clusters.",
        "ori-fast-z-score": 0.8164965809277261,
        "water-fast-z-score": 6.736096792653741,
        "rewrite-fast-z-score": 0.41256849850351734
    },
    {
        "original_text": "We present the first calculation of quark-quark scattering at next-to-leading order (NLO) accuracy within the framework of multiple parton scattering (MPI). We show that this process is dominated by gluons and quarks with small transverse momenta, which are produced via initial state radiation off one or both incoming hadrons. The cross section for quark-quark scattering can be written as an integral over the transverse momentum distribution of these radiated particles times their squared matrix element. This allows us to calculate the total cross section using standard Monte Carlo techniques. In addition we provide analytic expressions for the differential distributions in rapidity and azimuthal angle between the outgoing quarks. Our results agree well with those obtained numerically. Finally, we discuss how our formalism could be used to study MPI effects on jet production in proton-nucleus collisions. PACS numbers: 12.38.Qk, 13 .60.Le",
        "watermark_text": "We present the first measurement of quark - quark diffusion at next - to - leading order ( NLO ) accuracy within the framework of multiple parton absorption ( MPI ) . We suggest that this process is dominated by gluons and quarks with little transverse momenta , which are produced via initial state radiation off one or both incoming hadrons .The cross section for quark - quark waves can be written as an integral over the transverse energy density of these emitted particles times their squared matrix element . This enables us to estimate the total cross section using conventional Monte Carlo methods .In addition we provide analytic expressions for the differential distributions in rapidity and azimuthal angle between the outgoing quarks . Our results agree well with those achieved numerically .Finally , we talk how our formalism may be used to study MPI impacts on jet production in proton - nucleus collisions . PACS codes : 12 . 38 . Qk , 13 . 60 . Le",
        "rewrite_text": "We present the inaugural measurement of quark-quark diffusion at next-to-leading order (NLO) accuracy within the context of multiple parton interactions (MPI). Our findings indicate that this process is primarily influenced by gluons and quarks with minimal transverse momenta, which are generated through initial state radiation from one or both of the incoming hadrons. The cross section for quark-quark interactions can be expressed as an integral of the transverse energy density of these emitted particles multiplied by their squared matrix element. This approach allows us to estimate the total cross section using standard Monte Carlo techniques. Moreover, we provide analytical expressions for the differential distributions in rapidity and the azimuthal angle between the outgoing quarks, which align well with our numerical results. Finally, we discuss how our framework can be applied to analyze the impact of MPI on jet production in proton-nucleus collisions. PACS codes: 12.38.Qk, 13.60.Le.",
        "ori-fast-z-score": 0.3779644730092272,
        "water-fast-z-score": 5.5,
        "rewrite-fast-z-score": 2.3566599571949607
    },
    {
        "original_text": "We present the results for two different models of galaxy formation, one stable model with no dark matter halos merging or growing in mass (the standard CDM scenario), and an unstable model where dark matter halos merge continuously to form larger structures.  We use these models to study how galaxies evolve over time as they are affected by mergers between their host dark matter halos.   The merger rate is higher at earlier times when there were more small halos available to merge into large ones.  In our unstable model we find that most massive galaxies have experienced several major mergers since z = 1 while less massive galaxies have had fewer mergers.    Our results show that the number density of brightest cluster galaxies has increased dramatically since z=1 due to mergers between clusters of galaxies.  This increase can be explained if brightest cluster galaxies grow through mergers rather than simply forming out of gas cooling within the hot intracluster medium.",
        "watermark_text": "We present the results for two different models of galaxy formation , one stable model with no bright matter halos merging or developing in mass ( the standard CDM scenario ) , and an unstable scenario where bright matter halos merge consistently to form bigger structures . We use these models to study how clusters evolve over time as they are influenced by mergers between their host dark matter halos .The merger speed is higher at earlier times when there were more little halos accessible to unite into huge ones . In our unstable scenario we find that most large galaxies have experienced several main mergers since h = 1 while less massive galaxies have had fewer mergers .Our results show that the number density of brightest cluster clusters has increased significantly since z = 1 due to mergers between clusters of clusters . This increase can be described if brightest cluster clusters grow through mergers rather than merely creating out of gas melt within the hotter intracluster medium .",
        "rewrite_text": "We present findings from two distinct models of galaxy formation: a stable model where bright matter halos neither merge nor gain mass (the standard CDM scenario), and an unstable model in which bright matter halos consistently merge to form larger structures. We utilize these models to examine the evolution of clusters over time, particularly influenced by mergers involving their host dark matter halos. The merger rate is higher in the earlier epochs when numerous smaller halos were available to merge into larger ones. In our unstable scenario, we observe that most large galaxies have undergone multiple significant mergers since the time when h = 1, whereas less massive galaxies have experienced fewer mergers. Our results indicate that the number density of brightest cluster galaxies has significantly increased since z = 1, driven by mergers among clusters. This growth in number density can be explained by the notion that brightest cluster galaxies predominantly arise through mergers rather than merely forming from gas condensation within the hotter intracluster medium.",
        "ori-fast-z-score": 0.3333333333333333,
        "water-fast-z-score": 5.888888888888889,
        "rewrite-fast-z-score": 1.7056057308448833
    },
    {
        "original_text": "We report on the detection and characterization of microwave continuum emission from air shower plasmas using data collected by the LOPES experiment in Germany during 2004-2006. The observed signal is consistent with that expected for coherent Cherenkov radiation emitted by relativistic electrons accelerated to energies up to 100 MeV within the showers, as predicted by theory. We find no evidence for any significant contribution from incoherent synchrotron or bremsstrahlung processes. These results provide new insights into the physics of cosmic ray interactions at high energy. They also demonstrate the potential utility of radio techniques for studying atmospheric phenomena such as thunderstorms. \n \n Keywords: Cosmic rays, Radio waves, Air showers, Coherence, Synchrotron radiation \n \n \n \n 1 Introduction \n \n In recent years there has been growing interest in developing novel methods for detecting ultra-high-energy (UHE) cosmic rays based upon their interaction with Earth s atmosphere  1  . One promising technique involves measuring the radio-frequency (RF) emission produced when UHE particles interact with molecules in the upper atmosphere  2  , which can be detected remotely over large areas  3  .\n \nThe most prominent feature of this RF emission is an intense broadband pulse lasting several microseconds  4  . This pulse arises because the charged particle cascade generated by each primary cosmic ray interacts strongly with the geomagnetic field, causing it to emit coherently across a wide range of frequencies  5  . However, other mechanisms may contribute significantly to the total RF emission  6  . \n \n Here we present observations made with the Low-Frequency Array (LOFAR), one component of the International LOFAR Telescope  7  . Our analysis focuses primarily on measurements taken between 2004 and 2006 with the Long Wavelength Array (LWA)  8  , a phased array consisting of 144 dual-polarized dipole antennas operating at wavelengths ranging from 10 m to 80 m  9  . During these three years, LWA was deployed near Karthaus Township, Germany  10  , where it recorded signals from more than 20 million cosmic-ray-induced air showers  11  .",
        "watermark_text": "We report on the characterization and description of microwave continuum emission from air spray plasmas using data taken by the LOPES experiment in Germany during 2004 - 2006 . The observed light is compatible with that expected for coherent Cherenkov radiation emitted by relativistic electrons accelerated to energies up to 100 MeV within the showers , as predicted by theory .We see no evidence for any large contribution from incoherent synchrotron or bremsstrahlung interactions . These data provide fresh insights into the physics of cosmic ray interactions at high energy .They especially demonstrate the possibilities utility of radio methods for studying air events such as thunderstorms . Keywords : Cosmic rays , Radio beams , Air showers , Coherence , Synchrotron emission 1 Introduction In recent years there has been growing interest in establishing novel techniques for detecting ultra - large - energy ( UHE ) cosmic rays based upon their association with Earth s atmosphere 1 .One promising hypothesis includes monitoring the television - frequency ( RF ) emission generated when UHE ions contact with compounds in the higher atmosphere 2 , which can be identified remotely over large areas 3 . The most notable feature of this RF absorption is an intense broadband wave lasting several microseconds 4 .This wave exists because the charged particle cascade generated by each main cosmic ray interacts heavily with the geomagnetic field , forcing it to emit coherently across a broad variety of rates 5 . However , other mechanisms may contribute greatly to the total RF radiation 6 .Here we present observations made with the Low - Frequency Array ( LOFAR ) , one element of the International LOFAR Telescope 7 . Our study consists primarily on observations made between 2004 and 2006 with the Long Wavelength Array ( LWA ) 8 , a phased array consisting of 144 multiple - polarized dipole antennas active at wavelengths ranging from 10 m to 80 m 9 .During these three years , LWA was deployed near Karthaus Township , Germany 10 , where it recorded transmissions from more than 20 million cosmic - ray - caused air showers 11 .",
        "rewrite_text": "We present the characterization and analysis of microwave continuum emission resulting from air spray plasmas, utilizing data collected by the LOPES experiment in Germany from 2004 to 2006. The observed emissions align with theoretical predictions for coherent Cherenkov radiation produced by relativistic electrons accelerated to energies of up to 100 MeV within the cosmic ray showers. No significant evidence of contributions from incoherent synchrotron or bremsstrahlung interactions was found. This data offers new insights into the physics of high-energy cosmic ray interactions and highlights the potential of radio methods in studying atmospheric phenomena, such as thunderstorms. \n\nKeywords: Cosmic rays, Radio emissions, Air showers, Coherence, Synchrotron radiation\n\n1. Introduction\n\nRecent years have seen an increasing interest in innovative techniques for detecting ultra-high-energy (UHE) cosmic rays, particularly their interactions with Earth’s atmosphere. One promising approach involves monitoring the radio-frequency (RF) emissions generated when UHE ions interact with atmospheric compounds, which can be remotely identified across extensive areas. A key characteristic of this RF emission is a strong broadband signal that lasts several microseconds. This signal arises because the charged particle cascade produced by each primary cosmic ray interacts significantly with the geomagnetic field, leading to coherent emission over a wide frequency range. However, other mechanisms may also significantly contribute to the overall RF radiation. \n\nIn this context, we present observations conducted with the Low-Frequency Array (LOFAR), a component of the International LOFAR Telescope. Our analysis is primarily based on data collected between 2004 and 2006 using the Long Wavelength Array (LWA), a phased array consisting of 144 multi-polarized dipole antennas operating at wavelengths from 10 m to 80 m. Over these three years, the LWA was situated near Karthaus Township, Germany, where it recorded signals from more than 20 million air showers caused by cosmic rays.",
        "ori-fast-z-score": -1.4631270419005797,
        "water-fast-z-score": 8.060433501697915,
        "rewrite-fast-z-score": -0.08606629658238704
    },
    {
        "original_text": "We present an analysis of the stability of planetary systems in which protoplanetary embryos evolve under oligarchy, i.e., they are able to eject each other s neighbors by gravitational scattering but not themselves. We find that this process leads to rapid growth of the largest embryo until it reaches its isolation mass (the minimum mass required for runaway accretion). The system then evolves into either a single planet or two planets with comparable masses depending on how close the initial conditions were to instability. This evolution is very different than what happens when all bodies grow simultaneously; in particular, we show that there can be multiple stable outcomes even if the initial conditions are identical. Our results suggest that the formation of terrestrial planets may have proceeded through several stages including oligarchy before reaching their final state as observed today. In addition, our work provides new insights about the origin of Mercury-like planets. Protoplanetary embryos form in circumstellar disks around young stars and undergo mutual gravitational interactions during their growth phase. These interactions lead to orbital migration and dynamical instabilities such as collisions between neighboring embryos. If these processes occur frequently enough, only one body will survive at the end of the growth stage leaving behind a planetary system consisting of just one planet. However, recent studies indicate that many planetary systems contain more than one planet suggesting that some mechanism must exist to prevent complete destruction of the system. Here we study the possibility that protoplanetary embryos follow a hierarchical evolutionary path where they first grow hierarchically via gravitational scattering followed by runaway accretion once the largest embryo has reached its isolation mass. Using numerical simulations, we demonstrate that this scenario naturally explains the existence of multi-planet systems while also reproducing the properties of known exoplanets.",
        "watermark_text": "We present an assessment of the stability of planetary networks in which protoplanetary embryos grow under oligarchy , i . e . , they are able to eject each other s neighbors by gravitational scattering but not themselves . We see that this process results to rapid growth of the greatest embryo until it hits its isolation volume ( the minimum mass needed for runaway accretion ) .The system then evolves into either a single planet or two planets with similar masses depending on how close the early conditions were to instability . This evolution is very different than what happens when all bodies grow simultaneously ; in particular , we prove that there can be several stable outcomes even if the first conditions are matched .Our results show that the formation of terrestrial worlds may have continued through several stages including oligarchy before reaching their final condition as found today . In addition , our work offer additional information about the origin of Mercury - like planets .Protoplanetary embryos form in circumstellar disks around new stars and undergo mutual gravitational interactions during their development period . These interactions result to orbital movement and dynamical instabilities such as collisions between neighboring embryos .If these mechanisms occur frequently enough , only one body will survive at the end of the development period leaving behind a planetary system consisting of just one planet . However , recent studies demonstrate that several planetary complexes include more than one planet suggesting that some method may arise to resist total destruction of the system .Here we study the prospect that protoplanetary embryos continue a hierarchical evolutionary course where they originally grow hierarchically via gravitational waves followed by runaway accretion once the greatest embryo has reached its isolation volume . Using numerical simulations , we prove that this situation naturally explains the existence of dual - planet systems while actually reproducing the properties of known exoplanets .",
        "rewrite_text": "We provide an evaluation of the stability of planetary networks in which protoplanetary embryos develop under oligarchic conditions. In this scenario, they can gravitationally scatter and eject their neighboring embryos but cannot be ejected themselves. This interaction leads to the rapid growth of the largest embryo until it reaches its isolation volume, the minimum mass required for runaway accretion. Following this, the system tends to evolve into either a single planet or a pair of planets with similar masses, contingent on how close the initial conditions were to an instability threshold. This evolutionary path contrasts sharply with situations where all bodies grow simultaneously; notably, we demonstrate that multiple stable outcomes can arise even with the same initial conditions. Our findings indicate that the formation of terrestrial planets may have progressed through several phases, including oligarchy, before achieving their current state. Moreover, our research provides insights into the origins of Mercury-like planets. Protoplanetary embryos form in circumstellar disks around new stars and engage in gravitational interactions throughout their development. These interactions can lead to orbital movements and dynamic instabilities, such as collisions between neighboring embryos. If these processes occur frequently enough, typically only one body survives by the end of this developmental stage, resulting in a planetary system with just one planet. However, recent research suggests that many planetary systems consist of multiple planets, implying that some mechanism allows for the preservation of the system rather than its total destruction. In this study, we explore the idea that protoplanetary embryos may follow a hierarchical evolutionary trajectory, initially growing through gravitational interactions and then undergoing runaway accretion once the largest embryo attains its isolation volume. Through numerical simulations, we demonstrate that this scenario naturally accounts for the existence of dual-planet systems while accurately replicating the characteristics of known exoplanets.",
        "ori-fast-z-score": -0.8333333333333334,
        "water-fast-z-score": 7.166666666666667,
        "rewrite-fast-z-score": 0.2491364395612199
    },
    {
        "original_text": "We report on an analysis of archival Chandra data for the central region of the nearby starburst galaxy M82 (NGC 3034). We find that there are two bright, point-like sources in this field which have been previously identified as ULXs (Ultra-Luminous X-Ray Sources) by Swartz et al. (2004) . The first source is located at RA = 12 h 54 m 55 s .6 and Dec = 69°59 45   with a count rate of 1.1 x 10^-3 counts sec-1. This source has a luminosity of 2 x 10^39 erg/sec assuming it lies at 8 kpc distance. The second source is located at RA=12h54m55s.7 and Dec=69°59 46   with a count rate 0.9 x 10^-3 countssec-1. It also has a luminosity of about 2 x 10^39erg/sec if it lies at 8kpc. Both these sources appear to be variable over timescales ranging between hours and days.  These results suggest that both sources may contain black holes accreting close to their Eddington limit.",
        "watermark_text": "We report on an assessment of archival Chandra data for the central region of the nearby starburst galaxy M82 ( NGC 3034 ) . We see that there are two faint , point - like sources in this field which have been previously described as ULXs ( Ultra - Luminous X - Ray Sources ) by Swartz et al .( 2004 ) . The first reference is found at RA = 12 h 54 m 55 s . 6 and Dec = 69°59 45 with a count rate of 1 . 1 x 10 ^ - 3 counts sec - 1 .This source has a luminosity of 2 x 10 ^ 39 erg / sec assuming it lies at 8 kpc distance . The second source is situated at RA = 12h54m55s . 7 and Dec = 69°59 46 with a count rate 0 . 9 x 10 ^ - 3 countssec - 1 .It additionally has a luminosity of about 2 x 10 ^ 39erg / sec if it lies at 8kpc . Both these sources appear to be varying over timescales ranging between hours and days .These data suggest that both sources might represent dark holes accreting close to their Eddington limit .",
        "rewrite_text": "We present an analysis of archival Chandra data for the central region of the nearby starburst galaxy M82 (NGC 3034). Our findings reveal two faint, point-like sources in the field, previously identified as Ultra-Luminous X-Ray Sources (ULXs) by Swartz et al. (2004). The first source is located at RA = 12h 54m 55s.6 and Dec = 69°59' 45\", exhibiting a count rate of 1.1 x 10^-3 counts sec^-1. Assuming a distance of 8 kpc, this source has a luminosity of 2 x 10^39 erg/sec. The second source is found at RA = 12h 54m 55s.7 and Dec = 69°59' 46\", with a count rate of 0.9 x 10^-3 counts sec^-1, and it also has a luminosity of approximately 2 x 10^39 erg/sec if at the same distance of 8 kpc. Both sources appear to exhibit variability on timescales of hours to days, indicating that they may be black holes accreting matter close to their Eddington limit.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.328201177351375,
        "rewrite-fast-z-score": 1.131370849898476
    },
    {
        "original_text": "We present an algorithm for clustering graphs based on their patterns, which are represented as lattices. The proposed method is applied to analyze the similarity between chemical compounds and protein structures. We show that our approach can be used to identify similar substructures within large databases efficiently. In addition, we demonstrate how it can be utilized to detect structural changes caused by mutations or modifications. Our experiments reveal that the presented technique outperforms state-of-the-art methods significantly both in terms of accuracy and efficiency. Clustering algorithms have been widely studied in many fields such as data mining  1  , bioinformatics  2  , computer vision  3  , etc., due to its importance in discovering hidden information  4  . However, most existing approaches focus only on finding clusters without considering any additional information about them  5  .\nIn this work, we propose a novel graph clustering algorithm called CLUSTERING WITH LATTERS (CLL)  6  , which takes advantage of lattice representation  7, 8  to capture the pattern of each cluster. As shown in Figure 1 , CLL first transforms all input graphs into their corresponding lattices using a set of predefined rules  9  . Then, it performs hierarchical agglomerative clustering  10  over these lattices to find groups of similar graphs. Finally, it assigns each group to one cluster according to the majority vote among all members belonging to the same group  11  .",
        "watermark_text": "We present an algorithm for clustering graphs based on their patterns , which are represented as lattices . The proposed approach is applied to analyze the similarity between chemical molecules and protein compounds .We suggest that our approach can be used to identify similar substructures within large databases accurately . In addition , we prove how it can be employed to identify structural modifications affected by genes or modifications .Our experiments indicate that the offered technique outperforms state - of - the - art methods significantly both in terms of precision and efficiency . Clustering methods have been widely explored in multiple fields such as data extraction 1 , bioinformatics 2 , computer vision 3 , etc . , owing to its significance in discovering secret information 4 .However , most existing techniques concentrate only on discovering clusters without examining any additional information about them 5 . In this research , we propose a new graph clustering procedure entitled CLUSTERING WITH LATTERS ( CLL ) 6 , which uses advantage of lattice representation 7 , 8 to capture the rhythm of each cluster .As seen in Figure 1 , CLL initially transforms all input graphs into their appropriate lattices using a setting of predefined rules 9 . Then , it performs hierarchical agglomerative clustering 10 over these lattices to find groups of related graphs .Finally , it gives each group to one grouping due to the majority vote among all members belonging to the same group 11 .",
        "rewrite_text": "We introduce a novel algorithm for clustering graphs by utilizing their patterns, which are expressed as lattices. This method is designed to assess the similarity between chemical molecules and protein compounds. We propose that our approach can effectively identify similar substructures within extensive databases. Furthermore, we demonstrate its capability to detect structural changes driven by genetic variations or other modifications. Our experimental results show that this technique significantly surpasses existing state-of-the-art methods in both precision and efficiency. Clustering techniques have been extensively studied across various domains, including data extraction, bioinformatics, and computer vision, due to their crucial role in uncovering hidden information. However, most current methods focus solely on identifying clusters without analyzing any additional relevant information. In this study, we introduce a new graph clustering method called CLUSTERING WITH LATTICES (CLL), which leverages lattice representation to capture the characteristics of each cluster. As illustrated in Figure 1, CLL starts by converting all input graphs into their corresponding lattices based on a set of predefined rules. It then applies hierarchical agglomerative clustering to these lattices to identify groups of related graphs. Finally, it assigns each group based on a majority vote among the members within the same cluster.",
        "ori-fast-z-score": -0.9901475429766744,
        "water-fast-z-score": 6.798772019333623,
        "rewrite-fast-z-score": 0.8
    },
    {
        "original_text": "We present the results of an analysis of microlensing events detected by the Optical Gravitational Lensing Experiment (OGLE) and its follow-up network, including the Microlensing Observations in Astrophysics collaboration (MOA). We have identified 16 new planets among these events using high-precision photometry obtained at Subaru Observatory. The masses of all but one planet are determined to be less than 1 M⊕ . Fourteen of them are found to orbit stars more massive than 0.5 M⊙ , while two others are around low-mass dwarfs. These planets are located between 0.1 AU and 4 AU away from their host stars. This is the first time that such a large number of extrasolar planets has been discovered through space-based microlensing surveys. Our sample includes several planets whose orbits lie close to or beyond Neptune s semi-major axis. In addition, we find evidence for planetary companions to three binary systems.",
        "watermark_text": "We present the conclusion of an assessment of microlensing events discovered by the Optical Gravitational Lensing Experiment ( OGLE ) and its follow - up network , notably the Microlensing Observations in Astrophysics collaboration ( MOA ) . We have discovered 16 new objects among these phenomena using high - precision photometry obtained at Subaru Observatory .The masses of all but one planet are decided to be less than 1 M⊕ . Fourteen of them are found to orbit stars more massive than 0 . 5 [UNK] , while two others are around low - weight dwarfs .These planets are situated between 0 . 1 AU and 4 AU away from their home stars . This is the first time that such a large number of extrasolar stars has been detected through space - based microlensing observations .Our specimen includes several planets whose orbits lie close to or beyond Neptune s semi - major axis . In addition , we find proof for planetary companions to three binary systems .",
        "rewrite_text": "We present the findings from our assessment of microlensing events identified by the Optical Gravitational Lensing Experiment (OGLE) and its follow-up network, particularly the Microlensing Observations in Astrophysics collaboration (MOA). Utilizing high-precision photometry from Subaru Observatory, we have identified 16 new objects among these microlensing phenomena. With the exception of one planet, all have masses less than 1 M⊕. Fourteen of these planets orbit stars with masses greater than 0.5 solar masses, while two are located around lower-mass dwarf stars. These planets are positioned between 0.1 AU and 4 AU from their respective stars. This discovery marks the first instance of such a significant number of extrasolar planets being detected through space-based microlensing observations. Additionally, our study includes several planets whose orbits are close to or exceed the semi-major axis of Neptune, and we also provide evidence of planetary companions in three binary systems.",
        "ori-fast-z-score": 0.2581988897471611,
        "water-fast-z-score": 4.6475800154489,
        "rewrite-fast-z-score": -1.1338934190276817
    },
    {
        "original_text": "In this work, we study the throughput capacity region for multi-hop wireless networks with multiple transmitters and one receiver (MISO-MHWN). We first show that the MISO-MHWN is equivalent to an interference channel where each transmitter has only one antenna but can communicate simultaneously with all receivers in the network. Then, by using the concept of degrees-of-freedom (DoF), which characterizes how many parallel data streams are supported at high signal-to-noise ratio (SNR) regime, we derive outer bounds on the DoF region of the MISO-MHWNS. Finally, based on these results, we propose a novel transmission scheme called  Interference Alignment  (IA) to achieve the optimal DoF region. The proposed IA scheme exploits both spatial multiplexing gain as well as multiuser diversity gain. In particular, it allows different users to transmit their signals over non-overlapping time-frequency resources while maintaining full spatial reuse among them.",
        "watermark_text": "In this research , we study the throughput capacity area for single - hop wireless networks with many transmitters and one antenna ( MISO - MHWN ) . We first see that the MISO - MHWN is analogous to an interference channel where each antenna has only one antenna but can communicate simultaneously with all receivers in the channel .Then , by using the notion of degrees - of - independence ( DoF ) , which characterizes how many concurrent data feeds are implemented at high signal - to - noise ratio ( SNR ) regime , we derive upper limits on the DoF area of the MISO - MHWNS . Finally , based on these results , we undertake a new transmission strategy titled Interference Alignment ( IA ) to achieve the ideal DoF area .The proposed IA plan involves both temporal multiplexing gain as well as multiuser diversity gain . In particular , it allows different users to transmit their messages over non - overlapping period - frequency resources while maintaining full temporal reuse among them .",
        "rewrite_text": "In this research, we investigate the throughput capacity region for single-hop wireless networks characterized by multiple transmitters and a single antenna (MISO-MHWN). Initially, we observe that the MISO-MHWN resembles an interference channel, where each transmitter has only one antenna yet can communicate simultaneously with all receivers. We then utilize the concept of degrees of freedom (DoF), which indicates the number of concurrent data streams that can be supported in a high signal-to-noise ratio (SNR) setting, to establish upper bounds on the DoF region of the MISO-MHWN. Building on these findings, we propose a novel transmission strategy called Interference Alignment (IA) to optimize the DoF region. This IA approach leverages both temporal multiplexing gain and multiuser diversity gain, enabling different users to transmit their messages over distinct, non-overlapping period-frequency resources while fully reusing the temporal spectrum among them.",
        "ori-fast-z-score": -0.8307471607356973,
        "water-fast-z-score": 5.421151989096865,
        "rewrite-fast-z-score": -0.3611575592573076
    },
    {
        "original_text": "We study how classical and quantum uncertainty affect the price dynamics in an incomplete information setting, where agents have access to different sources of information about the underlying state variable. We show that when there is no common knowledge among traders on the true value of the state variable, they may disagree on its expected future evolution even if all are rational and risk-neutral. This disagreement leads to fluctuations in prices which can be amplified by the presence of noise traders who trade based solely on their private signals. In this case, we find that the stock returns exhibit volatility clustering and fat tails similar to those observed empirically. Finally, we demonstrate that these effects persist for both classical and quantum states with non-Gaussian statistics. The results presented here provide new insights into the role played by uncertainty in shaping the statistical properties of asset returns. They also suggest possible avenues for further research aimed at understanding the origin of such phenomena within more realistic models of trading behavior.",
        "watermark_text": "We research how classical and quantum uncertainty influence the price dynamics in an incomplete information context , where agents have access to different sources of information about the underlying state variable . We see that when there is no shared information among traders on the true value of the state variable , they may differ on its expected past development even if all are realistic and chance - neutral .This dispute leads to fluctuations in prices which can be amplified by the presence of noise traders who trade based primarily on their private signals . In this instance , we find that the stock returns display volatility clustering and lean tails identical to those observed empirically .Finally , we prove that these consequences persist for both classical and quantum states with non - Gaussian statistics . The results presented here provide fresh insights into the part played by uncertainty in shaping the statistical characteristics of investment returns .They also suggest possible avenues for further studies aimed at studying the origin of such patterns within more realistic descriptions of market behavior .",
        "rewrite_text": "We investigate the impact of classical and quantum uncertainty on price dynamics within a context of incomplete information, where agents have access to varying sources of information regarding the underlying state variable. Our findings indicate that in the absence of shared knowledge among traders about the true value of this state variable, they may hold differing perceptions of its expected historical progression, even if all parties are rational and neutral toward chance. This divergence can trigger price fluctuations, which are further exacerbated by noise traders who primarily base their trades on personal signals. In such cases, we observe that stock returns exhibit volatility clustering and heavy tails similar to those documented in empirical studies. Additionally, we demonstrate that these effects persist for both classical and quantum states characterized by non-Gaussian statistics. The insights derived from our research shed light on the role of uncertainty in influencing the statistical properties of investment returns and suggest potential pathways for future research aimed at exploring the origins of these patterns in more realistic market models.",
        "ori-fast-z-score": -0.7504787743864564,
        "water-fast-z-score": 5.9696200579570915,
        "rewrite-fast-z-score": 0.9434563530497265
    },
    {
        "original_text": "We present observations of the Mg II k line asymmetry during flares, which are compared with results obtained by numerical simulations using the RH code (Uitenbroek 2001). The observed profiles show that the blue wing is enhanced relative to the red one at all heights above the limb where we can see the flare emission. This effect is more pronounced for higher altitudes. We find that this behavior cannot be explained solely by Doppler shifts due to bulk plasma motions along the LOS. In addition, our modeling shows that the observed profile shapes cannot be reproduced without including nonthermal electron beams as an additional heating source. \n \n Keywords: Solar flare, chromospheric lines, nonthermal electrons, radiative hydrodynamics model, RH code, Mg II k line, line asymmetry. 1 Introduction \n \n During solar flares, intense energy release leads to rapid changes in physical conditions throughout the atmosphere of the Sun. These include temperature increases up to several million degrees Kelvin, strong magnetic fields, high densities, and large velocities. All these factors affect the shape of spectral lines emitted by different atmospheric layers. For example, it has been shown that the intensity ratio between two Fe I lines formed at different temperatures depends on the height of formation of each line (Feldman et al., 1995; Brosius & Phillips 2004) . Also, the presence of nonthermal electrons causes significant deviations from Maxwellian velocity distributions leading to asymmetric line profiles (e.g., Canfield et al. (1990) ; Doschek et al. (1991) ), while bulk flows lead to Doppler shifts of the line center position (Doschek et al., 1991; Brosius & Phillips 2004; Brosius 2009 ). Therefore, studying the temporal evolution of the line profiles provides important information about the dynamics of the flaring region. However, interpreting such data requires detailed knowledge of the underlying physics involved in the processes responsible for the observed phenomena. \n \n In particular, the study of the Mg II h&k lines offers unique opportunities to investigate various aspects of solar flares because they form over a wide range",
        "watermark_text": "We present observations of the Mg II k line asymmetry during flares , which are compared with data derived by numerical simulations using the RH code ( Uitenbroek 2001 ) . The observed profiles indicate that the blue wing is enhanced compared to the red one at all heights above the limb where we can see the flare emission .This phenomenon is more pronounced for greater altitudes . We see that this behavior cannot be described solely by Doppler variations owing to bulk plasma dynamics along the LOS .In addition , our modeling demonstrates that the seen profile patterns cannot be altered without using nonthermal electron beams as an additional thermal source . Keywords : Solar flare , chromospheric lines , nonthermal atoms , radiative hydrodynamics theory , RH code , Mg II h line , edge asymmetry .1 Introduction During solar flares , intense heat release leads to rapid alterations in physical conditions throughout the atmosphere of the Sun . These include temperature increases up to several million degrees Kelvin , intense magnetic fields , large densities , and large velocities .All these influences influence the morphology of spectral lines emitted by various atmospheric elements . For instance , it has been shown that the frequency proportion between two Fe I lines formed at different temperatures depends on the height of formation of each line ( Feldman et al . , 1995 ; Brosius & Phillips 2004 ) .Also , the presence of nonthermal atoms causes significant deviations from Maxwellian velocity distributions leading to asymmetric line profiles ( e . g . , Canfield et al . ( 1990 ) ; Doschek et al .( 1991 ) ) , while bulk flows result to Doppler movements of the line center position ( Doschek et al . , 1991 ; Brosius & Phillips 2004 ; Brosius 2009 ) . Therefore , studying the temporal evolution of the line profiles provides crucial data about the dynamics of the flaring zone .However , interpreting such information requires deep knowledge of the fundamental physics involved in the mechanisms involved for the seen phenomena . In particular , the knowledge of the Mg II h & k lines provides unique possibilities to examine different components of sun flares because they shape over a broad range",
        "rewrite_text": "We report our observations of the asymmetry of the Mg II k line during solar flares, comparing them to data obtained from numerical simulations using the RH code (Uitenbroek 2001). The observed profiles reveal that the blue wing is consistently enhanced relative to the red wing at all altitudes above the limb where flare emissions are detectable. This effect becomes increasingly pronounced at higher elevations. Our analysis indicates that this pattern cannot be solely explained by Doppler shifts resulting from bulk plasma dynamics along the line of sight. Furthermore, our models demonstrate that altering these profile patterns necessitates the inclusion of nonthermal electron beams as an additional thermal source. \n\nKeywords: Solar flares, chromospheric lines, nonthermal atoms, radiative hydrodynamics theory, RH code, Mg II h line, edge asymmetry. \n\n1 Introduction \n\nDuring solar flares, the release of intense heat leads to rapid changes in the Sun's atmospheric conditions, including temperature spikes up to several million degrees Kelvin, strong magnetic fields, increased densities, and high velocities. These factors significantly affect the spectral line morphology of various atmospheric elements. For example, earlier research has shown that the relative intensity of two Fe I lines formed at different temperatures varies with the height of their formation (Feldman et al., 1995; Brosius & Phillips, 2004). Additionally, the presence of nonthermal atoms introduces notable deviations from Maxwellian velocity distributions, resulting in asymmetric line profiles (e.g., Canfield et al. 1990; Doschek et al. 1991). Meanwhile, bulk plasma flows cause Doppler shifts in the line center positions (Doschek et al., 1991; Brosius & Phillips, 2004; Brosius, 2009). Consequently, analyzing the temporal evolution of these line profiles is essential for understanding the dynamics of the flaring zone. However, a thorough interpretation of this data requires an in-depth understanding of the fundamental physics associated with the observed phenomena. Specifically, the knowledge of the Mg II h and k lines offers unique opportunities to investigate various aspects of solar flares due to their formation across a wide range.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.485281374238571,
        "rewrite-fast-z-score": -0.4685212856658182
    },
    {
        "original_text": "We consider the problem of broadcasting in wireless networks with random access, where nodes can transmit at any time they choose to do so. We propose an algorithm that achieves stability by using a simple backoff mechanism based on local information only. The proposed scheme is shown to be throughput optimal under certain conditions. In addition, we show how our results are related to existing work on this topic. Finally, simulation experiments demonstrate the performance gains achieved by our approach over other schemes. Wireless broadcast has been studied extensively for many years due to its wide range of applications such as data dissemination, file transfer, video streaming, etc.. However, most previous works assume that all transmissions occur synchronously or within some fixed schedule. This assumption does not hold true when there exist multiple transmitters competing for channel resources simultaneously. Random access (RA) protocols have recently received much attention because they allow users to send packets whenever it is convenient without requiring tight synchronization among them  1  . Unfortunately, RA introduces additional challenges compared to traditional synchronous transmission models since collisions may happen frequently if no coordination exists between different transmitters  2  .\nIn this paper, we study the problem of broadcasting in multi-hop wireless networks with random access. Specifically, each node maintains one packet which needs to be transmitted to every other node in the network eventually. Each node chooses independently and uniformly at random a starting time slot to begin transmitting its packet. If two or more nodes start their transmissions at the same time slot, then these transmissions collide and none of them will reach the intended receivers successfully. Our goal is to design distributed algorithms that achieve both stability and high throughput while minimizing the number of retransmissions required to deliver messages reliably.",
        "watermark_text": "We consider the issue of transmitting in mobile networks with random access , where nodes can distribute at any time they select to do so . We suggest an algorithm that achieves independence by using a simple backoff mechanism based on local information only .The proposed system is demonstrated to be throughput efficient under certain conditions . In addition , we tell how our findings are related to existing work on this topic .Finally , simulation studies demonstrate the performance increases attained by our approach over other schemes . Wireless broadcast has been studied extensively for numerous years owing to its large variety of applications such as data dissemination , file transfer , media streaming , etc . .However , most prior authors assumption that all transmissions happen synchronously or within some fixed schedule . This assumption does not stand true when there exist several transmitters battling for channel supplies concurrently .Random entry ( RA ) technologies have recently garnered many notice because they allow users to send messages whenever it is convenient without allowing close synchronization among them 1 . Unfortunately , RA creates additional challenges compared to conventional synchronous transmission approaches since collisions might come frequently if no coordination occurs between different transmitters 2 .In this paper , we study the issue of transmitting in multi - hop wireless networks with random access . Specifically , each node maintains one packet which needs to be delivered to every other node in the network subsequently .Each node decides separately and uniformly at random a starting date slot to starting sending its message . If two or more nodes start their broadcasts at the same time slot , then these transmissions collide and nobody of them will achieve the intended receivers correctly .Our goal is to create distributed methods that attain both stability and good throughput while minimizing the quantity of retransmissions needed to deliver communications reliably .",
        "rewrite_text": "In this paper, we address the challenge of transmission in mobile networks utilizing random access, where nodes can choose their own times to send data. We propose a novel algorithm that leverages a straightforward backoff mechanism based solely on local information to achieve independence among nodes. Our system demonstrates efficient throughput under specific conditions, and we discuss how our findings relate to existing literature on the subject. Additionally, simulation results illustrate the performance improvements of our approach compared to other strategies. \n\nWireless broadcasting has been extensively researched over the years due to its wide range of applications, including data dissemination, file transfers, and media streaming. However, most previous studies have assumed that transmissions occur synchronously or adhere to a fixed schedule, a premise that falters in scenarios where multiple transmitters compete for channel access simultaneously. Recent developments in random access (RA) technologies have drawn attention as they allow users to transmit messages at their convenience, thus eliminating the need for tight synchronization. Unfortunately, RA introduces new challenges compared to traditional synchronous transmission methods, primarily because collisions can occur frequently in the absence of coordination among transmitters.\n\nIn this study, we focus on transmission in multi-hop wireless networks using random access. Specifically, each node holds a single packet that must be sent to every other node within the network. To initiate message transmission, each node randomly selects a starting time slot. If multiple nodes broadcast simultaneously in the same time slot, their transmissions collide, preventing any of them from reaching their intended receivers effectively. Our objective is to develop distributed strategies that ensure both stability and high throughput while minimizing the number of retransmissions required for reliable communication.",
        "ori-fast-z-score": -0.5734623443633283,
        "water-fast-z-score": 9.14476170639053,
        "rewrite-fast-z-score": 0.727606875108999
    },
    {
        "original_text": "We present the results of our analysis of the photometric data obtained by the Advanced Camera for Surveys (ACS) on board HST in the F606W and F814W bands during Cycle 12 as part of program GO-10775. The survey consists of deep imaging observations of 16 globular clusters with metallicities ranging between  Fe/H  = -2.2 to -0.7. We have used these data along with archival WFPC-2 images taken under programs GO-5269 and GO-6366 to study the properties of horizontal branch stars in each cluster. \n \n In this work we use theoretical stellar evolution tracks, isochrones, luminosity functions, and synthetic HB models to determine ages, reddenings, distances, helium abundances, and mass loss rates for all sixteen clusters studied here. Our main conclusions are summarized below: \n \n \n \n 1. Ages - We find that most of the clusters analyzed here appear younger than previously thought based upon their location relative to the fiducial ridge line defined by the Milky Way s old open clusters. This result suggests that either the age scale derived using open clusters may be systematically too young or that there has been significant dynamical evolution within many of the clusters since they formed. \n \n 2. Reddening - We find evidence for differential reddening across several of the clusters studied here. However, it appears that the majority of the clusters do not suffer from large amounts of differential reddening. For those clusters where we can measure individual reddenings for different populations of stars, we find no systematic differences between the values determined for blue stragglers versus normal giants. These results suggest that any differential reddening affecting these clusters must occur over scales smaller than the typical size of an open cluster. \n \n 3. Distances - Using the absolute magnitudes of RR Lyrae variables observed in each cluster, we derive distance moduli which agree well with previous estimates made using other methods such as main sequence fitting. We also compare the mean magnitude of the RGB bump in each cluster to predictions made using synthetic HB models. While some",
        "watermark_text": "We present the conclusion of our analysis of the photometric data received by the Advanced Camera for Surveys ( ACS ) on board HST in the F606W and F814W bands during Cycle 12 as part of program GO - 10775 . The survey consists of deep optical images of 16 globular complexes with metallicities ranging between Fe / H = - 2 . 2 to - 0 . 7 .We have utilized these information along with archival WFPC - 2 images took under programs GO - 5269 and GO - 6366 to study the properties of horizontal branch stars in each cluster . In this research we utilize theoretical stellar evolution tracks , isochrones , luminosity functions , and synthetic HB models to estimate ages , reddenings , distances , helium abundances , and mass loss patterns for all sixteen clusters explored here .Our main results are presented below : 1 . Ages - We see that most of the clusters evaluated here appear newer than previously thought based upon their placement relative to the fiducial crest line defined by the Milky Way s ancient open objects .This result suggests that either the age level obtained using open groups may be systematically too young or that there has been significant dynamical development within many of the clusters since they formed . 2 .Reddening - We get data for differential reddening across many of the clusters explored here . However , it appears that the majority of the clusters do not suffer from huge amounts of differential reddening .For those clusters where we can measure individual reddenings for different populations of stars , we find no comprehensive differences between the values determined for blue stragglers versus regular giants . These data suggest that any differential reddening affecting these clusters must exist over sizes less than the typical size of an open cluster .3 . Distances - Using the absolute magnitudes of RR Lyrae variables seen in each cluster , we derive distance moduli which agree well with previous estimates made using other methods such as main sequence fitting .We additionally compare the mean magnitude of the RGB bump in each cluster to calculations made using synthetic HB models . While some",
        "rewrite_text": "We present the conclusions of our analysis of photometric data obtained by the Advanced Camera for Surveys (ACS) on the Hubble Space Telescope (HST) in the F606W and F814W bands during Cycle 12, as part of program GO-10775. This survey includes deep optical images of 16 globular clusters with metallicities ranging from [Fe/H] = -2.2 to -0.7. We have combined this data with archival WFPC-2 images captured under programs GO-5269 and GO-6366 to examine the properties of horizontal branch stars within each cluster. Our research employs theoretical stellar evolution tracks, isochrones, luminosity functions, and synthetic horizontal branch models to estimate the ages, reddenings, distances, helium abundances, and mass loss patterns for all sixteen clusters studied. Our main findings are summarized as follows: \n\n1. **Ages**: Most of the clusters we analyzed appear to be younger than previously believed, based on their positions relative to the fiducial crest line defined by the older open clusters of the Milky Way. This suggests that the age estimates derived from open clusters may be systematically too young, or that significant dynamical evolution has occurred within many of the clusters since their formation.\n\n2. **Reddening**: We have gathered data on differential reddening across numerous analyzed clusters. However, it seems that most clusters do not experience substantial differential reddening. In cases where we can measure individual reddenings for different stellar populations, we find no significant differences between the reddening values determined for blue stragglers and regular giants. This indicates that any differential reddening present is likely smaller than the typical size of an open cluster.\n\n3. **Distances**: By using the absolute magnitudes of RR Lyrae variables in each cluster, we calculated distance moduli that align well with previous estimates derived from other methods such as main sequence fitting. Additionally, we compared the mean magnitude of the RGB bump in each cluster with predictions from synthetic horizontal branch models. While some...",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.021870595978444,
        "rewrite-fast-z-score": 0.50709255283711
    },
    {
        "original_text": "We have carried out multi-wavelength observations for a sample of infrared (IR) selected galaxies with AKARI and other telescopes to investigate their physical properties, such as dust temperature T d , luminosity L IR , star formation rate SFR, stellar mass M * . The main results are summarized below.  We found that most of our targets show red colors at optical wavelengths indicating old ages and/or low metallicities. In addition, we detected strong polycyclic aromatic hydrocarbon emission features at 6.2, 7.7, 8.6, 11.3 um which indicate active star-formation activities. By fitting the observed spectral energy distributions (SEDs), we derived the following parameters;  - Dust temperatures range between 30 K and 60 K. - Luminosities range between 10^10 and 10^12 Lsun. - Star formation rates range between 0.1 and 100 Msun yr-1. - Stellar masses range between 10^9 and 10^11 Msun.",
        "watermark_text": "We have carried out multi - wavelength experiments for a sample of infrared ( IR ) selected galaxies with AKARI and other telescopes to examine their physical properties , such as cloud temperature T d , luminosity L IR , sun formation rate SFR , planetary weight M * . The main results are presented below .We showed that most of our sources show red colors at visual wavelengths suggesting old ages and / or low metallicities . In addition , we spotted intense polycyclic aromatic hydrocarbon emission events at 6 . 2 , 7 . 7 , 8 . 6 , 11 . 3 um which demonstrate active galaxy - formation behaviors .By fitting the known spectral power distributions ( SEDs ) , we derived the following variables ; - Dust temperatures range between 30 K and 60 K . - Luminosities range between 10 ^ 10 and 10 ^ 12 Lsun . - Star formation rates range between 0 . 1 and 100 Msun yr - 1 .- Stellar masses range between 10 ^ 9 and 10 ^ 11 Msun .",
        "rewrite_text": "We conducted multi-wavelength observations of a sample of infrared (IR) selected galaxies using AKARI and various other telescopes to investigate their physical properties, including dust temperature (T_d), infrared luminosity (L_IR), star formation rate (SFR), and stellar mass (M*). The main findings are summarized below. Our analysis indicates that most of the galaxies exhibit red colors in the visible spectrum, suggesting they are either ancient or have low metallicities. Furthermore, we detected strong emission lines from polycyclic aromatic hydrocarbons at wavelengths of 6.2, 7.7, 8.6, and 11.3 µm, signifying active galaxy formation processes. By fitting the known spectral energy distributions (SEDs), we determined the following parameters: dust temperatures range from 30 K to 60 K; luminosities span from 10^10 to 10^12 L_sun; star formation rates vary between 0.1 and 100 M_sun per year; and stellar masses lie between 10^9 and 10^11 M_sun.",
        "ori-fast-z-score": 0.39056673294247163,
        "water-fast-z-score": 5.337745350213779,
        "rewrite-fast-z-score": -0.7385489458759964
    },
    {
        "original_text": "The GRI (Gamma Ray Imager) is an astrophysics space observatory proposed by the French Space Agency CNES and NASA to study gamma-ray bursts, active galactic nuclei and other phenomena in high-energy astronomy.  It will be launched on a Soyuz rocket with a Fregat upper stage into a Sun-Earth L2 orbit at 1 AU distance from Earth. Its main instrument consists of two coded mask telescopes observing simultaneously in the energy range 20 MeV - 300 GeV. Each telescope has a large field-of-view of 2 steradians and a spatial resolution better than 0.1 degrees. A third detector module provides additional information about the background radiation environment for each telescope. This article describes the design concept of this innovative instrument. Keywords: Astroparticle physics, High-Energy Astronomy, Instrumentation, Space Observatory. Introduction:  The GRI (Gamma Ray...  more ",
        "watermark_text": "The GRI ( Gamma Ray Imager ) is an astrophysics space observatory proposed by the French Space Agency CNES and NASA to study alpha - ray clusters , active galactic nuclei and other processes in high - energy astronomy . It will be launched on a Soyuz rocket with a Fregat upper stage into a Sun - Earth L2 orbit at 1 AU distance from Earth .Its main object consists of two coded mask telescopes observing simultaneously in the power range 20 MeV - 300 GeV . Each observatory has a large field - of - view of 2 steradians and a spatial resolution best than 0 . 1 degrees .A third detector module presents additional information about the background radiation conditions for each telescope . This page describes the design concept of this innovative instrument .Keywords : Astroparticle science , High - Energy Astronomy , Instrumentation , Space Observatory . Introduction : The GRI ( Gamma Ray . . . more",
        "rewrite_text": "The Gamma Ray Imager (GRI) is a space observatory proposed by the French Space Agency CNES in collaboration with NASA, aiming to investigate alpha-ray clusters, active galactic nuclei, and various phenomena in high-energy astronomy. The observatory will be launched aboard a Soyuz rocket with a Fregat upper stage, targeting a Sun-Earth L2 orbit, located 1 AU from Earth. It features two coded mask telescopes that will operate simultaneously across an energy range of 20 MeV to 300 GeV. Each telescope offers a broad field of view of 2 steradians and boasts a spatial resolution of better than 0.1 degrees. Additionally, a third detector module will provide supplementary data on the background radiation conditions for each of the telescopes. This page outlines the design concept for this groundbreaking instrument. Keywords: Astroparticle science, High-Energy Astronomy, Instrumentation, Space Observatory. Introduction: The GRI (Gamma Ray... more",
        "ori-fast-z-score": 1.3363062095621219,
        "water-fast-z-score": 4.008918628686366,
        "rewrite-fast-z-score": 2.213211486674006
    },
    {
        "original_text": "In this thesis, we propose an energy-efficient power control scheme for large code division multiple access (CDMA) systems with variable traffic loads and channel conditions. The proposed approach is based on the concept that all users should be allocated their required data rates at minimum total transmit power consumption while maintaining acceptable quality-of-service (QoS). We first develop a new analytical model which can accurately predict the average received signal-to-interference-plus-noise ratio (SINR) under different system configurations. Based on our analysis results, we then formulate the problem as a convex optimization problem subject to SINR constraints. Finally, by applying Lagrange multiplier method, we obtain closed-form solutions for both uplink and downlink transmissions. Our simulation results show that compared with conventional schemes such as water-filling algorithm, the proposed approach achieves significant performance gains in terms of power efficiency without sacrificing QoS requirements. In addition, it also outperforms other existing approaches in terms of computational complexity. \n \n Keywords: Code Division Multiple Access, Power Control",
        "watermark_text": "In this dissertation , we propose an energy - efficient energy management scheme for large code division multiple entry ( CDMA ) networks with variable traffic loads and channel conditions . The proposed approach is based on the idea that all users should be allocated their required information rates at minimum total broadcast power consumption while maintaining acceptable reliability - of - service ( QoS ) .We first develop a new analytical theory which can accurately forecast the average received signal - to - interference - plus - noise proportion ( SINR ) under various system systems . Based on our analysis results , we then formulate the question as a convex optimization problem subject to SINR restrictions .Finally , by using Lagrange multiplier method , we obtain closed - form methods for both uplink and downlink transmissions . Our modelling findings show that compared with typical strategies such as water - filling algorithm , the suggested approach achieves significant efficiency increases in terms of power performance without sacrificing QoS specifications .In addition , it also outperforms other existing techniques in terms of computational complexity . Keywords : Code Division Multiple Access , Power Control",
        "rewrite_text": "In this dissertation, we present an energy-efficient energy management scheme tailored for large code division multiple access (CDMA) networks facing variable traffic loads and channel conditions. Our approach centers on the principle that each user should receive their required information rates while minimizing total broadcast power consumption and ensuring acceptable quality of service (QoS) levels. We begin by developing a novel analytical theory that accurately predicts the average signal-to-interference-plus-noise ratio (SINR) across different system configurations. Building on our analytical findings, we recast the issue as a convex optimization problem constrained by SINR requirements. By employing the Lagrange multiplier method, we derive closed-form solutions for both uplink and downlink transmissions. Our modeling results demonstrate that, when compared to conventional strategies like the water-filling algorithm, our proposed method significantly enhances power efficiency without compromising QoS standards. Moreover, it also surpasses other existing methods in terms of computational complexity. Keywords: Code Division Multiple Access, Power Control.",
        "ori-fast-z-score": 0.9332565252573828,
        "water-fast-z-score": 7.154966693639935,
        "rewrite-fast-z-score": 1.6081688022566922
    },
    {
        "original_text": "The Stochastic Loewner Evolution (SLE) is an important tool in the study of random curves and fractals, especially those arising as scaling limits of discrete models such as lattice paths or self-avoiding walks.  The SLE trace can be thought of as a continuous version of Brownian motion with drift; it has been shown to have connections to many other fields including quantum gravity, string theory, statistical mechanics, probability theory, mathematical physics, number theory, and computer science.   In this article we will give a brief introduction to the basic concepts behind the SLE process, along with some examples that illustrate its use. We also provide references for further reading on the subject. For more information about the SLE process see the following articles:  http://arxiv.org/abs/math/9906028 http://arxiv.org/sabs/0909.0366 http://arxiv.org/10.1103/PhysRevE.71.026110",
        "watermark_text": "The Stochastic Loewner Evolution ( SLE ) is an important tool in the study of random curves and fractals , particularly those arose as scaling limits of linear models such as lattice trails or self - escaping tours . The SLE trace can be thought of as a continuous version of Brownian movement with drift ; it has been shown to have link to many other fields including quantum gravitational , string theory , statistical mechanics , probability theory , mathematical science , number theory , and computer science .In this article we will provide a brief introduction to the fundamental concepts behind the SLE method , along with some examples that highlight its use . We additionally offer references for further reading on the subject .For more information about the SLE method see the following articles : www : / / arxiv . org / abs / math / 9906028 http : / / arxiv . org / sabs / 0909 . 0366 www : / / arxiv . org / 10 . 1103 / PhysRevE . 71 . 026110",
        "rewrite_text": "The Stochastic Loewner Evolution (SLE) is a crucial framework for examining random curves and fractals, particularly those that emerge as scaling limits of linear models such as lattice paths or self-avoiding walks. The SLE trace can be regarded as a continuous analog of Brownian motion with a drift component. This methodology has been linked to various domains, including quantum gravity, string theory, statistical mechanics, probability theory, mathematics, number theory, and computer science. In this article, we will present a concise introduction to the key principles underlying the SLE approach, along with examples that showcase its applications. Additionally, we will provide references for those interested in exploring the topic further. For more detailed information on the SLE method, please refer to the following articles: www:/ / arxiv.org/abs/math/9906028, http://arxiv.org/abs/0909.0366, www:/ / arxiv.org/10.1103/PhysRevE.71.026110.",
        "ori-fast-z-score": 0.24618298195866545,
        "water-fast-z-score": 5.25,
        "rewrite-fast-z-score": 1.697749375254331
    },
    {
        "original_text": "We present an algorithm to solve the half-space depth problem, which is one of the most fundamental problems in computational geometry. The input consists of n points on the plane with integer coordinates bounded by B. We want to find a point that minimizes its distance to all other points. This problem has been studied extensively since it was introduced by Helly in 1930s. In this work we propose a new branch-and-cut algorithm based on mixed-integer programming (MIP) formulation. Our MIP model uses O(nB) variables and constraints. Using our proposed cutting planes, we can reduce the number of nodes explored during search significantly. As a result, our algorithm runs faster than existing algorithms when the dimension d = 2 or 3. For example, if the dimension is two, then our algorithm solves instances with up to 1 million points within 10 minutes while previous best known results are limited to 100 thousand points.",
        "watermark_text": "We introduce an algorithm to solve the half - space depth problem , which is one of the most important problems in computational geometry . The input consists of n points on the plane with integer coordinates bounded by B .We want to find a spot that minimizes its distance to all other points . This problem has been studied frequently since it was introduced by Helly in 1930s .In this research we propose a new branch - and - cut algorithm based on mixing - integer programming ( MIP ) implementation . Our MIP approach utilizes O ( nB ) parameters and constraints .Using our proposed cutting planes , we can restrict the number of vertices explored during search significantly . As a result , our scheme ran quicker than existing algorithms when the dimension d = 2 or 3 .For instance , if the dimension is two , then our technique solves situations with up to 1 million points within 10 minutes while prior best known data are limited to 100 thousand points .",
        "rewrite_text": "We present a new algorithm designed to tackle the half-space depth problem, a crucial challenge in computational geometry. The input consists of n points in the plane, each with integer coordinates constrained by B. Our goal is to identify a location that minimizes the distance to all other points. This issue has been the focus of considerable study since its introduction by Helly in the 1930s. In this work, we introduce an innovative branch-and-cut algorithm leveraging a mixed-integer programming (MIP) framework. Our MIP implementation employs O(nB) parameters and constraints. By utilizing our proposed cutting planes, we significantly limit the number of vertices explored during the search process. Consequently, our method outperforms existing algorithms when operating in two or three dimensions. For example, in two dimensions, our approach can efficiently handle up to 1 million points within 10 minutes, whereas previous best-known methods were restricted to 100,000 points.",
        "ori-fast-z-score": -0.5933908290969266,
        "water-fast-z-score": 4.00693842672377,
        "rewrite-fast-z-score": 0.11547005383792514
    },
    {
        "original_text": "We report on the search for a K-nuclear bound state in 4 He using the reaction $^4$He (K - , n). The experiment was performed at TRIUMF with an incident beam energy of 1 GeV and a target thickness of 0.5 cm. A total number of 2.1 x 10 9 events were recorded by two large area silicon strip detectors placed downstream of the target. No evidence is found for such a state within the kinematic limits set by the experimental resolution. Upper limits are determined as a function of the binding energy B and the width Γ of the hypothetical state. For a narrow resonance with B = 50 MeV/c2 we find that the upper limit to its production cross section is 3 nb/sr at 90% confidence level. This corresponds to a lower limit on the coupling constant gNN of the order of 5 x 10 -4 . \nThe results presented here represent one of the most stringent constraints yet obtained on this type of exotic nuclear structure. \n \n Keywords: Kaon nucleus interaction",
        "watermark_text": "We report on the search for a K - atomic bound position in 4 He using the reaction $ ^ 4 $ He ( K - , n ) . The project was done at TRIUMF with an incident beam energy of 1 GeV and a target thickness of 0 . 5 centimetres .A total number of 2 . 1 x 10 9 episodes were produced by two huge area silicon strip detectors placed downstream of the target . No information is found for such a state within the kinematic limits established by the experimental resolution .Upper levels are decided as a function of the binding energy B and the length Γ of the hypothetical state . For a small resonance with B = 50 MeV / c2 we find that the higher limit to its production cross area is 3 nb / sr at 90 % confidence rate .This corresponds to a smaller restriction on the interaction factor gNN of the order of 5 x 10 - 4 . The results presented here represent one of the most stringent constraints ever achieved on this class of exotic nuclear configuration .Keywords: Kaon nucleus interaction",
        "rewrite_text": "We present our findings from the investigation of a K- atomic bound state in 4He through the reaction ^4He(K-, n). This experiment was conducted at TRIUMF, utilizing an incident beam energy of 1 GeV and a target thickness of 0.5 centimeters. A total of 2.1 x 10^9 events were recorded by two large-area silicon strip detectors positioned downstream from the target. However, we did not identify any evidence for such a state within the kinematic limits imposed by the experimental resolution. The upper limits were determined based on the binding energy (B) and the width (Γ) of the proposed state. For a small resonance with B = 50 MeV/c², we established an upper limit of 3 nb/sr for its production cross-section with a 90% confidence level. This corresponds to a constraint on the interaction factor gNN, estimated to be around 5 x 10^-4. The results reported here provide one of the most stringent limits achieved to date on this category of exotic nuclear configurations. Keywords: Kaon-nucleus interaction.",
        "ori-fast-z-score": -1.1952286093343936,
        "water-fast-z-score": 4.541868715470696,
        "rewrite-fast-z-score": 0.5852057359806528
    },
    {
        "original_text": "We study the torsional oscillations of an inhomogeneous magnetic flux tube with longitudinal density variation and uniform twist, which is embedded into a gravitationally stratified atmosphere. The governing equations are derived by using the thin-tube approximation for both equilibrium state and linear perturbations. We find that there exist two types of eigenmodes corresponding to different wave numbers along the field line. One type has its maximum amplitude at the footpoint while another one has it near the apex. For each mode we calculate the frequency as well as the damping time due to radiative loss. It turns out that the frequencies of these modes depend on the density contrast between the base and top of the loop. In addition, they also depend on the ratio of the Alfvén speed inside the loop to that outside. Finally, we discuss how our results can be applied to observations. Keywords: Torsional oscillation, Inhomogeneity",
        "watermark_text": "We test the torsional oscillations of an inhomogeneous magnetic flux tube with longitudinal density variation and uniform twist , which is anchored into a gravitationally stratified atmosphere . The governing equations are derived by using the narrow - tunnel equation for both equilibrium state and linear perturbations .We see that there exist two forms of eigenmodes relating to different wave numbers along the field edge . One sort has its highest amplitude at the footpoint while another one has it near the apex .For each mode we estimate the frequency as well as the damping period caused to radiative loss . It turns out that the frequencies of these frequencies rely on the density contrast between the base and top of the loop .In addition , they also rely on the proportion of the Alfvén speed inside the loop to that outside . Finally , we talk how our findings can be applied to observations .Keywords: Torsional oscillation, Inhomogeneity",
        "rewrite_text": "We investigate the torsional oscillations of an inhomogeneous magnetic flux tube characterized by longitudinal density variations and a uniform twist, which is anchored in a gravitationally stratified atmosphere. The governing equations are derived using the narrow-tunnel equation for both the equilibrium state and linear perturbations. Our analysis reveals two distinct forms of eigenmodes associated with different wave numbers along the field boundary. One type of mode exhibits its maximum amplitude at the footpoint, while the other peaks near the apex. For each mode, we determine the frequency and the damping period resulting from radiative losses. Interestingly, these frequencies are influenced by the density contrast between the base and the top of the loop, as well as the ratio of the Alfvén speed inside the loop to that outside. Finally, we discuss the implications of our findings for observational studies. Keywords: Torsional oscillation, Inhomogeneity.",
        "ori-fast-z-score": -0.629940788348712,
        "water-fast-z-score": 4.318004318006477,
        "rewrite-fast-z-score": 1.4084056792618558
    },
    {
        "original_text": "We study the generalized Dicke model with an arbitrary number N of two-level atoms interacting with one-mode radiation field, and show that it can be mapped to a spin-1/2 system by using the Holstein-Primakoff transformation. We then use the exact diagonalization method to calculate its ground state energy spectrum for different values of the coupling constant g and the number N . The results are compared with those obtained by other methods such as perturbation theory and numerical integration. It is found that our results agree well with previous ones when the coupling strength is small but deviate significantly from them if the coupling becomes strong. Finally we discuss some possible applications of this work. PACS: 03.65.Ud, 05.45.Mt, 11.10.Gh, 12.20.Dc, 13.25.Gv \nI. INTRODUCTIO N\nThe Dicke model  1  describes how many identical two-level atoms interact collectively with a single mode of electromagnetic field. In recent years there has been renewed interest in studying this model because of its potential application in quantum information processing  2  , quantum optics  3  , condensed matter physics  4  , etc.. For example, the collective spontaneous emission rate of the atomic ensemble depends on the total angular momentum J = N /2 (N being the number of atoms)  5  .\nIn fact, the Dicke model was originally proposed more than half century ago  6  . Since then various theoretical approaches have been developed to solve it  7 -10  . Among these approaches, the most successful one is probably the so-called HolsteinPrimakoff transformation  11  which maps the original problem into a spin-1/2 system  12  . This approach works very well at weak-coupling regime where the interaction between atom-field is relatively small. However, it fails completely at large-coupling limit since the mapping procedure breaks down due to the appearance of unphysical states  13  . Recently, several authors  14 -19  have tried to overcome this difficulty by introducing new transformations or approximations. Nevertheless, their solutions still suffer from certain drawbacks  20, 21  .",
        "watermark_text": "We explore the generalized Dicke model with an arbitrary number N of two - level atoms interacting with one - mode radiation field , and find that it can be mapped to a spin - 1 / 2 system by using the Holstein - Primakoff transformation . We then use the exact diagonalization technique to estimate its ground state energy spectrum for different values of the interaction factor g and the number N .The results are compared with those achieved by other methods such as perturbation theory and numerical integration . It is found that our findings agree well with previous ones when the interaction strength is tiny but deviate drastically from them if the interaction becomes strong .Finally we explain some possible use of this study . PACS : 03 . 65 . Ud , 05 . 45 . Mt , 11 . 10 . Gh , 12 . 20 . Dc , 13 . 25 . Gv I . INTRODUCTIO N The Dicke model 1 explains how many identical two - level atoms behave collectively with a single mode of electromagnetic field .In recent years there has been continued interest in investigating this model because of its potential application in quantum information processing 2 , quantum optics 3 , condensed matter science 4 , etc . . For instance , the collective spontaneous emission speed of the atomic ensemble depends on the total angular velocity J = N / 2 ( N being the number of atoms ) 5 . In reality , the Dicke concept was originally proposed more than quarter century ago 6 .Since then various theoretical methods have been constructed to solve it 7 - 10 . Among these method , the most popular one is probably the so - called HolsteinPrimakoff transformation 11 which maps the original problem into a spin - 1 / 2 system 12 .This method works very best at weak - interaction regime where the interaction between electron - field is fairly little . However , it fails totally at large - interaction range since the mapping method splits down due to the appearance of unphysical states 13 .Recently , various literature 14 - 19 have tried to overcome this challenge by using new transformations or approximations . Nevertheless , their solutions still suffer from certain drawbacks 20 , 21 .",
        "rewrite_text": "We investigate the generalized Dicke model, which encompasses an arbitrary number N of two-level atoms interacting with a one-mode radiation field. Utilizing the Holstein-Primakoff transformation, we demonstrate that this model can be effectively mapped to a spin-1/2 system. We apply exact diagonalization techniques to estimate the ground state energy spectrum for various interaction strengths (g) and atom counts (N). Our results are compared with those obtained from alternative methods, including perturbation theory and numerical integration. We discover that our findings align well with previous studies in the weak interaction regime but significantly diverge when interactions strengthen. Finally, we discuss potential applications stemming from this research. \n\nPACS: 03.65.Ud, 05.45.Mt, 11.10.Gh, 12.20.Dc, 13.25.Gv\n\nI. INTRODUCTION\n\nThe Dicke model explains the collective behavior of multiple identical two-level atoms interacting with a single electromagnetic mode. Recent years have seen renewed interest in this model due to its applications in quantum information processing, quantum optics, and condensed matter science. For example, the rate of collective spontaneous emission in an atomic ensemble is influenced by the total angular momentum J = N/2, where N is the number of atoms. Originally proposed over a quarter-century ago, the Dicke model has inspired various theoretical approaches for its solution. Among these, the Holstein-Primakoff transformation is particularly prominent, mapping the problem onto a spin-1/2 framework. This method proves effective in the weak interaction regime; however, it encounters challenges in strong interaction scenarios due to the emergence of unphysical states. Recent literature has sought to address these issues through alternative transformations or approximations, yet these solutions still face certain limitations.",
        "ori-fast-z-score": -0.16222142113076254,
        "water-fast-z-score": 6.8132996874920275,
        "rewrite-fast-z-score": -0.42107596053325946
    },
    {
        "original_text": "We study the weighted complexity function W(G) for graphs G with n vertices, which is defined as the minimum number of edges in any n-vertex subgraph H such that H contains all cycles of length at most k (k = 3, ...,n). We prove upper bounds on this function by using the concept of the determinant of an adjacency matrix A associated to G. In particular we show that if A has no zero rows or columns then W(G) <= 2n-1. This bound can be improved when A satisfies some additional conditions. Finally, we give examples showing how our results are sharp. The weighted complexity function W(G;k) (k=3,...,n), introduced by Chartrand et al., measures the minimum number of edges needed to make every cycle of length up to k in a given graph G. It was shown recently that W(G;3)=n-2 for any connected triangle-free planar graph G. In this note we improve these results by proving that W(G;3))<=n-1 for any connected triangle-free plane graph G.",
        "watermark_text": "We test the weighted complexity map W ( G ) for graphs G with n edges , which is characterized as the minimum amount of vertices in any k - vertex subgraph H such that H contains all cycles of width at most h ( h = 3 , . . . , k ) . We establish upper limits on this function by using the idea of the determinant of an adjacency matrix A associated to G . In particular we prove that if A has no zero columns or rows then W ( G ) < = 2n - 1 .This bound can be improved when A satisfies some additional conditions . Finally , we give examples demonstrating how our findings are sharp .The weighted complexity map W ( G ; h ) ( h = 3 , . . . , k ) , invented by Chartrand et al . , estimates the minimum amount of vertices necessary to make every cycle of width up to n in a given graph G . It was shown lately that W ( G ; 3 ) = n - 2 for any connected triangle - free planar graph G . In this note we enhance these results by proving that W ( G ; 3 ) ) < = n - 1 for any connected triangle - free plane graph G .",
        "rewrite_text": "We investigate the weighted complexity map \\( W(G) \\) for graphs \\( G \\) with \\( n \\) edges, defined as the minimum number of vertices in any \\( k \\)-vertex subgraph \\( H \\) that includes all cycles with widths of at most \\( h \\) (where \\( h = 3, \\ldots, k \\)). We set upper bounds for this function using the determinant of the adjacency matrix \\( A \\) associated with \\( G \\). Specifically, we demonstrate that if \\( A \\) has no zero rows or columns, then \\( W(G) \\leq 2n - 1 \\). This bound can be further refined under certain additional conditions on \\( A \\). Furthermore, we present examples illustrating the sharpness of our results. The weighted complexity map \\( W(G; h) \\) (for \\( h = 3, \\ldots, k \\)), introduced by Chartrand et al., estimates the minimum number of vertices required to encompass every cycle of width up to \\( n \\) in a given graph \\( G \\). Recent findings showed that \\( W(G; 3) = n - 2 \\) for any connected triangle-free planar graph \\( G \\). In this note, we build upon these results by proving that \\( W(G; 3) \\leq n - 1 \\) for any connected triangle-free planar graph \\( G \\).",
        "ori-fast-z-score": -1.937329799813845,
        "water-fast-z-score": 5.047146145152358,
        "rewrite-fast-z-score": 0.7276068751089989
    },
    {
        "original_text": "We propose that galactic dark matter is an effective four-dimensional manifestation of extra dimensions, and we show how this can be realized in a simple model with one extra dimension compactified on S 1 /Z 2 . The fifth dimension has two 3-branes at its endpoints which are connected by a bulk scalar field. We find that the scalar field develops a kink profile along the fifth dimension due to the presence of a potential barrier between the two branes. This leads to a localized mass term for fermions living on the visible (3-)brane, which gives rise to a phenomenologically viable dark matter candidate. In addition, there exists another class of particles called Kaluza-Klein modes whose masses depend on the size of the extra dimension. These KK states have no tree-level interactions with Standard Model fields but they may contribute significantly to loop processes such as neutrino oscillations or proton decay. Finally, we discuss possible experimental signatures of our scenario.",
        "watermark_text": "We suggest that galactic dark matter is an efficient four - dimensional manifestation of extra dimensions , and we prove how this can be realized in a simple model with one extra dimension compactified on S 1 / Z 2 . The fifth dimension has two 3 - branes at its endpoints which are connected by a bulk scalar field .We see that the scalar field becomes a kink profile along the fifth dimension owing to the presence of a potential barrier between the two branes . This leads to a localized mass term for fermions residing on the visible ( 3 - ) brane , which gives rise to a phenomenologically viable dark matter candidate .In addition , there exists another class of nuclei termed Kaluza - Klein modes whose masses vary on the size of the extra dimension . These KK states have no tree - level interactions with Standard Model fields but they may contribute greatly to loop processes such as neutrino oscillations or proton emission .Finally , we explain possible experimental signatures of our scenario .",
        "rewrite_text": "We propose that galactic dark matter serves as an effective four-dimensional representation of additional dimensions, and we demonstrate how this can be achieved through a straightforward model featuring one extra dimension compactified on S1/Z2. This fifth dimension contains two three-branes at either end, connected by a bulk scalar field. Due to the presence of a potential barrier between the two branes, the scalar field adopts a kink profile along the fifth dimension. As a result, this configuration generates a localized mass term for fermions existing on the visible (3-) brane, potentially providing a viable candidate for dark matter. Furthermore, there is a distinct class of particles known as Kaluza-Klein modes, whose masses fluctuate with the size of the extra dimension. While these Kaluza-Klein states don’t interact at tree level with Standard Model fields, they could significantly influence loop processes, such as neutrino oscillations or proton decay. Lastly, we discuss potential experimental signatures that could emerge from our proposed scenario.",
        "ori-fast-z-score": 0.6108472217815261,
        "water-fast-z-score": 3.8805700005813275,
        "rewrite-fast-z-score": -0.23570226039551587
    },
    {
        "original_text": "We study the nonlinear evolution of large-scale magnetic fields (LSMFs) in two dimensions by using direct numerical simulations of incompressible magnetohydrodynamics with periodic boundary conditions. We find that LSMFs are generated spontaneously through inverse cascade processes, which is similar to three-dimensional MHD turbulence. However, we also observe some differences between 2D and 3D cases. In particular, the energy spectrum of LSMF has an exponential tail at large wave numbers instead of power-law behavior as observed for 3D case. The origin of this difference can be understood by considering the effect of magnetic helicity conservation on the dynamics of LSMF. Furthermore, we show that the effective drift velocity of LSMF depends strongly on its initial configuration. Finally, we discuss possible applications of our results to solar physics. PACS number(s): 47.27.Gs, 47.27.Gk, 52.35.Jm",
        "watermark_text": "We research the nonlinear development of large - scale magnetic fields ( LSMFs ) in two dimensions by using direct numerical simulations of incompressible magnetohydrodynamics with periodic boundary constraints . We see that LSMFs are produced spontaneously through inverse cascade processes , which is analogous to three - dimensional MHD turbulence .However , we also observe some variations between 2D and 3D cases . In particular , the electricity spectrum of LSMF has an exponential tail at large wave numbers instead of power - law behavior as found for 3D case .The origin of this distinction can be understood by examining the impact of magnetic helicity conservation on the dynamics of LSMF . Furthermore , we find that the effective drift speed of LSMF varies strongly on its initial configuration .Finally , we review possible applied of our findings to solar theory . PACS number ( s ) : 47 . 27 . Gs , 47 . 27 . Gk , 52 . 35 . Jm",
        "rewrite_text": "We investigate the nonlinear evolution of large-scale magnetic fields (LSMFs) in two dimensions through direct numerical simulations of incompressible magnetohydrodynamics with periodic boundary conditions. Our results indicate that LSMFs emerge spontaneously via inverse cascade processes, similar to what is observed in three-dimensional MHD turbulence. However, we note some distinctions between the two-dimensional and three-dimensional scenarios. Notably, the energy spectrum of LSMFs exhibits an exponential decay at high wave numbers, contrasting with the power-law behavior seen in the 3D case. This difference can be explained by analyzing the role of magnetic helicity conservation in the dynamics of LSMFs. Additionally, we discover that the effective drift speed of LSMFs is highly dependent on its initial conditions. Lastly, we explore potential applications of our findings in solar theory. PACS numbers: 47.27.Gs, 47.27.Gk, 52.35.Jm.",
        "ori-fast-z-score": 0.2581988897471611,
        "water-fast-z-score": 5.334005334008001,
        "rewrite-fast-z-score": 1.5491933384829668
    },
    {
        "original_text": "The article presents new data on the paleogeography and geodynamics of the Russian Arctic in the late Quaternary period, based on the results of field studies conducted by the authors over the past decade. The study area is located between the Lena River to the west and the Kolyma River to the east (Fig.  1) . It includes the northern part of Yakutia, the southern part of Chukotka Autonomous Okrug, and the western part of Magadan Oblast. In this region, the authors studied more than 100 sites with deposits of loess-like sediments that accumulated during the last glacial cycle. These are mainly sandy silts with an admixture of gravel particles up to 5 mm in diameter; they contain numerous mollusk shells, bones of terrestrial mammals, and other remains of biota. Based on these materials, we reconstructed the history of climatic fluctuations in the study area since the Last Glacial Maximum (LGM) until today.",
        "watermark_text": "The section offers latest data on the paleogeography and geodynamics of the Russian Arctic in the last Quaternary period , based on the results of field analyses conducted by the writers over the previous decade . The survey area is situated between the Lena River to the west and the Kolyma River to the west ( Fig .1 ) . It includes the northern part of Yakutia , the southern portion of Chukotka Autonomous Okrug , and the western part of Magadan Oblast .In this area , the authors studied more than 100 sites with formations of loess - like sediments that eroded during the last ice cycle . These are chiefly sandy silts with an admixture of sandy fragments up to 5 mm in width ; they contain many mollusk shells , fossils of terrestrial birds , and other remains of biota .Based on these resources , we analyzed the history of climatic fluctuations in the program field since the Last Glacial Maximum ( LGM ) until today .",
        "rewrite_text": "This section provides updated information on the paleogeography and geodynamics of the Russian Arctic during the last Quaternary period, drawing on field analyses conducted by the authors over the past decade. The survey area is located between the Lena River to the west and the Kolyma River to the east (see Fig. 1). It encompasses the northern region of Yakutia, the southern part of the Chukotka Autonomous Okrug, and the western section of Magadan Oblast. Within this area, the authors investigated over 100 sites featuring loess-like sediment formations that were eroded during the last ice cycle. These sediments mainly consist of sandy silts with sandy fragments up to 5 mm in size and contain numerous mollusk shells, fossils of terrestrial birds, and other biological remains. Utilizing these resources, we analyzed the history of climatic fluctuations from the Last Glacial Maximum (LGM) to the present.",
        "ori-fast-z-score": -2.516611478423583,
        "water-fast-z-score": 4.464418717230567,
        "rewrite-fast-z-score": 0.7745966692414834
    },
    {
        "original_text": "We report on electrical transport measurements through individual biphenyl dithiol molecules connected to gold electrodes by using scanning tunneling microscopy break-junction technique at room-temperature (RT) and low temperatures down to 4 K. The current–voltage characteristics show clear signatures for molecular conduction, such as Coulomb blockade peaks and negative differential resistance regions. We find that the junction conductance depends strongly on the tilt angle between the molecule backbone and the substrate normal. This is explained by an anisotropic coupling strength between the molecule and the metal contacts which leads to different transmission probabilities along the two main axes of the molecule. In addition we observe a strong temperature dependence of the junction conductance with a maximum around 50 K. These results are discussed within a model based on electron-phonon scattering processes. Biphenyl dithiol (BDT), one of the most studied organic semiconductors, has been used extensively in field-effect transistors1-5 and other electronic devices6-8 due to its high charge carrier mobility9-11. However, despite intensive research efforts12-17 only few studies have investigated the electrical properties of BDT-based single-molecule junctures18-20. Herein, we present detailed investigations of the electrical transport behavior of individual BDT molecules contacted via Au(111) surfaces by means of scanning tunneling microscopy breakjunction experiments21-23. Our data reveal pronounced features characteristic for molecular conduction24-26 including Coulomb blockade peaks27-29 and negative differential resistance30-32. Furthermore, our study reveals a strong influence of the molecular orientation relative to the substrate surface on the junction conductance33-35. Finally, we demonstrate a significant temperature dependent change of the junction conductance36-38.",
        "watermark_text": "We report on electrical travel data through individual biphenyl dithiol molecules linked to gold electrodes by using scan tunneling microscopy break - junction technique at room - temperature ( RT ) and low temperatures down to 4 K . The current – voltage parameters show visible signatures for protein conduction , such as Coulomb blockade spikes and negative integral resistance regions . We see that the junction conductance depends strongly on the tilt distance between the molecule backbone and the substrate normal .This is explained by an anisotropic interaction strength between the molecule and the metal contacts which results to different communication probabilities along the two principal axes of the molecule . In addition we study a weak thermal influence of the junction conductance with a maximum around 50 K . These data are discussed within a theory based on electron - phonon absorption processes .Biphenyl dithiol ( BDT ) , one of the most studied synthetic semiconductors , has been used heavily in field - effect transistors1 - 5 and other electronic devices6 - 8 due to its high charge carrier mobility9 - 11 . However , despite intensive study efforts12 - 17 only few researchers have researched the electrical properties of BDT - based multi - molecule junctures18 - 20 .Herein , we present detailed investigations of the electrical travel dynamics of individual BDT atoms contacted via Au ( 111 ) surfaces by means of scanning tunneling microscopy breakjunction experiments21 - 23 . Our data reveal pronounced features characteristic for molecular conduction24 - 26 including Coulomb blockade peaks27 - 29 and negative differential resistance30 - 32 .Furthermore , our research reveals a powerful impact of the molecular orientation compared to the substrate surface on the junction conductance33 - 35 . Finally , we obtain a substantial heat dependent change of the junction conductance36 - 38 .",
        "rewrite_text": "We investigate the electrical transport properties of individual biphenyl dithiol molecules connected to gold electrodes using the scanning tunneling microscopy break-junction technique at room temperature (RT) and temperatures as low as 4 K. The current-voltage characteristics exhibit distinct features indicative of molecular conduction, such as Coulomb blockade spikes and regions of negative differential resistance. Our findings demonstrate that the junction conductance is significantly influenced by the tilt distance between the molecular backbone and the normal of the substrate. This observation is attributed to the anisotropic interaction strength between the molecule and the metal contacts, leading to varying communication probabilities along the molecule's two primary axes. Additionally, we observe a subtle thermal effect on junction conductance, peaking around 50 K, which we interpret within the framework of electron-phonon absorption processes. Biphenyl dithiol (BDT), one of the most extensively studied synthetic semiconductors, has been widely utilized in field-effect transistors and other electronic devices due to its high charge carrier mobility. However, despite extensive research efforts, only a limited number of studies have focused on the electrical properties of BDT-based multi-molecule junctions. In this work, we present comprehensive examinations of the electrical transport dynamics of individual BDT molecules contacted via Au (111) surfaces through scanning tunneling microscopy break-junction experiments. Our results reveal prominent signatures of molecular conduction, including Coulomb blockade peaks and negative differential resistance. Furthermore, our research indicates that the orientation of the molecule relative to the substrate surface significantly impacts junction conductance, along with a notable temperature-dependent variation in junction conductance.",
        "ori-fast-z-score": 1.4253932901995967,
        "water-fast-z-score": 7.839663096097782,
        "rewrite-fast-z-score": 0.6963106238227914
    },
    {
        "original_text": "We propose an algorithm to select the injection point in hybrid networks, which is based on local information and can be implemented with low overheads. The proposed algorithm has two phases. First, it elects one node as the injection point by using only local information. Second, if there are multiple nodes that have been elected as the injection points, then these nodes will negotiate among themselves to determine exactly one injection point. We prove that our algorithm always selects at least one node as the injection points when all nodes are reachable from each other. Furthermore, we show through simulations that our algorithm performs well even under various network conditions such as dynamic topologies or limited communication ranges. Keywords: Distributed system, Localization, Self-organization, Wireless sensor network (WSN), Data dissemination, Energy efficiency, Routing protocol, Location-based routing, Clustering, Load balancing, Traffic engineering, Internet service provider",
        "watermark_text": "We suggest an algorithm to select the injection point in hybrid networks , which is based on local information and can be deployed with minimum overheads . The proposed algorithm has two phases .First , it elects one node as the injection center by using only local information . Second , if there are multiple nodes that have been chosen as the injection points , then these nodes will agree among themselves to select exactly one injection point .We showed that our algorithm often selects at least one node as the injection points when all nodes are reachable from each other . Furthermore , we demonstrated through simulations that our algorithm performs better even under various network conditions such as dynamic topologies or restricted transmission ranges .Keywords : Distributed system , Localization , Self - organization , Wireless sensor channel ( WSN ) , Data dissemination , Energy quality , Routing protocol , Location - based scheduling , Clustering , Load balancing , Traffic management , Internet service provider",
        "rewrite_text": "We propose an algorithm for selecting injection points in hybrid networks that utilizes local information and minimizes overhead. The algorithm consists of two phases. In the first phase, it identifies one node as the injection center based solely on local data. In the second phase, if multiple nodes are designated as injection points, those nodes will collaborate to agree on a single injection point. Our findings indicate that this algorithm frequently selects at least one injection point when all nodes can reach one another. Additionally, simulations have shown that the algorithm outperforms others under various network conditions, including dynamic topologies and limited transmission ranges. \n\nKeywords: Distributed systems, Localization, Self-organization, Wireless Sensor Networks (WSN), Data dissemination, Energy efficiency, Routing protocols, Location-based scheduling, Clustering, Load balancing, Traffic management, Internet Service Providers.",
        "ori-fast-z-score": -0.25,
        "water-fast-z-score": 4.0,
        "rewrite-fast-z-score": 0.24618298195866545
    },
    {
        "original_text": "We present an overview of our efforts to find planets around stars with high proper motions using data obtained by the TrES space telescope, which was launched on December 6, 2005. We have found that many of these systems are likely false positives due to blending between the target star and nearby fainter companions or background objects. In this talk we will discuss how we used photometric variability combined with radial velocity measurements to identify these false positive cases. We also describe some of the techniques we use for identifying new candidate exoplanetary systems based on their light curves alone. Finally, I will show you what happens when one tries to measure the mass of a planet orbiting such a fast moving star as HD 128598 (Proxima Centauri). This is part of my Ph.D thesis work at Harvard University under the supervision of Dr. Paul Butler. My research interests include finding extrasolar planets via direct imaging and transit methods, studying the atmospheres of transiting exoplanets, and searching for habitable worlds beyond our solar system.",
        "watermark_text": "We present an overview of our work to find planets around stars with high proper motions utilizing information obtained by the TrES spacecraft telescope , which was launched on December 6 , 2005 . We have discovered that several of these systems are likely false positives due to mixing between the target star and distant fainter companions or background variables .In this talk we will explore how we using photometric variability coupled with radial speed measurements to identify these false positive cases . We also describe some of the methods we using for finding new likely exoplanetary systems based on their light curves alone .Finally , I will show you what happens when one attempts to measure the mass of a planet orbiting such a rapidly motion star as HD 128598 ( Proxima Centauri ) . This is part of my Ph . D doctoral research at Harvard University under the guidance of Dr . Paul Butler .My research interests cover finding extrasolar stars via direct detection and transit methods , studying the atmospheres of transiting exoplanets , and searching for habitable worlds beyond our solar system .",
        "rewrite_text": "In this presentation, we provide an overview of our research focused on detecting planets around stars that exhibit high proper motions. This work utilizes data gathered from the TrES telescope, which was launched on December 6, 2005. Our findings indicate that many of these systems may be false positives, resulting from interference between the target star and distant, fainter companions or background variables. We will discuss our approach to identifying these false positives through the analysis of photometric variability and radial velocity measurements. Additionally, we will outline some of our methods for discovering new potential exoplanetary systems based solely on their light curves. Finally, I will share insights on the challenges encountered when measuring the mass of a planet orbiting a rapidly moving star, such as HD 128598 (Proxima Centauri). This research is part of my Ph.D. studies at Harvard University, supervised by Dr. Paul Butler. My research interests include the direct detection of extrasolar planets, the study of atmospheres of transiting exoplanets, and the search for habitable worlds beyond our solar system.",
        "ori-fast-z-score": -0.45291081365783825,
        "water-fast-z-score": 4.98201895023622,
        "rewrite-fast-z-score": 0.11547005383792514
    },
    {
        "original_text": "We study the possibility that instantons induce neutrino masses and mixings, which are compatible with current experimental data on neutrinos. We consider type IIB orientifold compactifications to four dimensions with intersecting D-branes at singularities. The Standard Model gauge group is realized by stacks of branes wrapping 3-cycles inside Calabi-Yau threefolds. In addition we include stacks of branes wrapped around 2-cycles corresponding to hidden sectors. These models can be engineered such that they have an MSSM-like spectrum. Instanton effects lead to corrections to the superpotential involving fermions localized on different stacks of branes. This leads to Majorana mass terms for right-handed neutrinos. We show how these results can be used to construct realistic string inspired models of leptogenesis. We also discuss possible phenomenological consequences of our scenario. Introduction: String theory provides many new avenues towards understanding physics beyond the Standard Model (SM). One interesting class of scenarios involves extra spatial dimensions where SM fields live on a 3-brane while gravity propagates into the bulk  1  . A particularly appealing feature of this setup is that it allows for TeV scale quantum gravity without conflicting with precision tests of general relativity  2  .\nIn recent years there has been much interest in studying supersymmetric extensions of the SM within the context of string theory  3  -  8  . Supersymmetry stabilizes the electroweak hierarchy problem  9  , predicts unification of all coupling constants  10  and offers solutions to other open problems like dark matter  11  or baryogenesis  12  . However, despite its successes as a theoretical framework, no direct evidence for SUSY exists so far  13  . It would therefore be very exciting if some of the predictions made by SUSY could be tested experimentally  14  .\nOne important question concerns the origin of neutrino masses  15  . While the seesaw mechanism  16  explains naturally small neutrino masses  17  , it requires additional particles not present in the minimal version of the SM  18  . An alternative approach consists in considering non-renormalizable operators induced by instantons  19  . Such contributions may arise when",
        "watermark_text": "We research the idea that instantons create neutrino masses and mixings , which are compatible with current experimental evidence on neutrinos . We consider kind IIB orientifold compactifications to four dimensions with intersecting D - branes at singularities .The Standard Model gauge group is realized by stacks of branes wrapping 3 - cycles inside Calabi - Yau threefolds . In addition we include stacks of branes folded around 2 - cycles corresponding to hidden sectors .These systems can be engineered such that they have an MSSM - like spectrum . Instanton effects lead to corrections to the superpotential involving fermions localized on various stacks of branes .This leads to Majorana mass words for right - handed neutrinos . We see how these results can be used to build real string inspired models of leptogenesis .We additionally discuss possible phenomenological consequences of our scenario . Introduction : String theory provides much new avenues towards studying theory beyond the Standard Model ( SM ) .One interesting class of scenarios involves extra spatial dimensions where SM fields reside on a 3 - brane while gravity propagates into the bulk 1 . A notably appealing feature of this configuration is that it allows for TeV scale quantum gravitational without conflicting with accuracy tests of general relativity 2 .In recent years there has been much interest in investigating supersymmetric extensions of the SM within the context of string theory 3 - 8 . Supersymmetry stabilizes the electroweak hierarchy problem 9 , predicts merging of all correlation constants 10 and provides solutions to other open problems like dark matter 11 or baryogenesis 12 .However , despite its successes as a conceptual framework , no formal evidence for SUSY appears so far 13 . It would therefore be very exciting if some of the assumptions produced by SUSY might be used experimentally 14 .One important question concerns the origin of neutrino masses 15 . While the seesaw mechanism 16 presents naturally tiny neutrino masses 17 , it includes added particles not present in the reduced form of the SM 18 .An alternative approach consists in considering non - renormalizable expressions induced by instantons 19 . Such contributions could occur when",
        "rewrite_text": "We investigate the concept that instantons may be responsible for generating neutrino masses and mixings that align with existing experimental data on neutrinos. Our analysis focuses on type IIB orientifold compactifications to four dimensions, featuring intersecting D-branes at singularities. The gauge group of the Standard Model is represented by stacks of branes that wrap around three-cycles within Calabi-Yau threefolds. Additionally, we incorporate stacks of branes wrapped around two-cycles that correspond to hidden sectors. These configurations can be engineered to yield a spectrum similar to that of the Minimal Supersymmetric Standard Model (MSSM). Instanton effects introduce modifications to the superpotential, which involve fermions localized on different stacks of branes, giving rise to Majorana mass terms for right-handed neutrinos. We demonstrate how these findings can be applied to construct realistic, string-inspired models of leptogenesis and also discuss the potential phenomenological implications of our scenario. \n\n**Introduction:** String theory opens up new pathways for exploring theories that extend beyond the Standard Model (SM). One intriguing class of scenarios involves extra spatial dimensions, where SM fields are confined to a 3-brane while gravity propagates in the bulk. A particularly compelling aspect of this setup is that it permits quantum gravitational effects at the TeV scale without conflicting with precision tests of general relativity. In recent years, significant interest has arisen in studying supersymmetric extensions of the SM within the framework of string theory. Supersymmetry addresses the electroweak hierarchy problem, predicts the unification of all coupling constants, and offers solutions to various unresolved issues, such as dark matter and baryogenesis. However, despite its conceptual merits, there has yet to be any empirical evidence for supersymmetry. Therefore, it would be thrilling if some predictions made by supersymmetry were to be validated experimentally. A key question in this context is the origin of neutrino masses. While the seesaw mechanism naturally yields tiny neutrino masses, it also necessitates the introduction of additional particles not present in the simplified version of the SM. An alternative approach is to explore non-renormalizable terms that arise from instantons, which could emerge under certain conditions.",
        "ori-fast-z-score": 0.08362420100070908,
        "water-fast-z-score": 7.108057085060271,
        "rewrite-fast-z-score": 0.6575959492214292
    },
    {
        "original_text": "We present an analysis of the broadband (0.5-10 keV) X-ray spectrum of the radio galaxy 3C 445, using data obtained with XMM-Newton and Chandra observatories in 2001-2002 . The observed X-ray emission is dominated by a hard power-law component which can be fitted equally well either by thermal Comptonization or non-thermal inverse Compton scattering models. We find that both models require a large amount of cold matter to produce the soft excess below 1 keV. This suggests that there are two distinct components contributing to the X-ray emission - one associated with hot plasma and another related to cool gas clouds. In addition we detect several narrow absorption lines at energies corresponding to highly ionized species such as O vii , Ne ix , Mg xi and Si xiii . These features may originate in outflows driven by nuclear activity. Finally, we report on the detection of Fe Kα line at 6.4 keV produced by reflection off distant material.",
        "watermark_text": "We present an analysis of the broadband ( 0 . 5 - 10 keV ) X - ray signal of the radio star 3C 445 , using data acquired with XMM - Newton and Chandra observatories in 2001 - 2002 . The observed X - ray radiation is dominated by a hard energy - law component which can be fit equally poorly either by thermal Comptonization or non - thermal integral Compton absorption theories .We see that both models require a large amount of cold matter to produce the soft excess below 1 keV . This implies that there are two different components contributing to the X - ray radiation - one related with hot plasma and another linked to cool gas clouds .In addition we perceive several small absorption patterns at energies corresponding to strongly ionized species such as O vii , Ne ix , Mg xi and Si xiii . These features could occur in outflows driven by nuclear activity .Finally , we publish on the observation of Fe Kα line at 6 . 4 keV generated by absorption off remote material .",
        "rewrite_text": "We present an analysis of the broadband X-ray signal (0.5 - 10 keV) from the radio source 3C 445, utilizing data gathered from the XMM-Newton and Chandra observatories during 2001-2002. The X-ray emissions we observed are primarily characterized by a hard energy-law component, which can be fitted with limited success using either thermal Comptonization or non-thermal integral Compton absorption models. Both models indicate a significant presence of cold material necessary to explain the soft excess below 1 keV, suggesting the existence of two distinct components in the X-ray emissions: one associated with hot plasma and the other with cooler gas clouds. Additionally, we identify several minor absorption features at energies that correspond to highly ionized species such as O VII, Ne IX, Mg XI, and Si XIII, which may arise from outflows driven by nuclear activity. Lastly, we report the observation of the Fe Kα line at 6.4 keV, which is produced by absorption from distant material.",
        "ori-fast-z-score": -1.8599622199011085,
        "water-fast-z-score": 4.73427220735493,
        "rewrite-fast-z-score": -1.0533703247651751
    },
    {
        "original_text": "We report the first measurement of the cross section for the process ppbar -> Zgamma + X, where X is any number of additional particles produced along with the Zgamma boson.  The data were collected by the D0 experiment during Run II of Fermilab s Tevatron Collider between 2002 and 2007 using an integrated luminosity of 5.4 fb-1 . We measure the cross section to be 0.84 +/- 0.11 (stat.) +/- 0.10 (syst.) pb, which agrees well with next-to-leading-order perturbative QCD predictions. Using this result we set upper limits on possible anomalous trilinear gauge-boson coupling parameters. These results are also used to derive constraints on models that predict new heavy neutral vector bosons decaying into pairs of photons or gluons. In addition, these measurements provide important input for future searches for Higgs bosons decaying into two photons. \nPACS numbers: 11.30.Er, 12.60.Jv",
        "watermark_text": "We report the first measurement of the cross area for the process ppbar - > Zgamma + X , where X is any number of added particles generated along with the Zgamma boson . The data were collected by the D0 study during Run II of Fermilab s Tevatron Collider between 2002 and 2007 utilizing an integrated luminosity of 5 . 4 fb - 1 .We estimate the cross area to be 0 . 84 + / - 0 . 11 ( stat . ) + / - 0 . 10 ( syst . )pb , which agrees well with next - to - leading - order perturbative QCD estimates . Using this consequence we put upper limits on potential anomalous trilinear gauge - boson correlation parameters .These data are also used to derive restrictions on estimates that forecast new heavy neutral vector bosons decaying into sets of photons or gluons . In addition , these measurements give important output for future investigations for Higgs bosons decaying into two photons .PACS codes : 11 . 30 . Er , 12 . 60 . Jv",
        "rewrite_text": "We present the first measurement of the cross section for the process \\( pp^\\text{bar} \\rightarrow Z\\gamma + X \\), where \\( X \\) represents any additional particles produced alongside the \\( Z\\gamma \\) boson. This data was collected by the D0 Collaboration during Run II of Fermilab's Tevatron Collider from 2002 to 2007, utilizing an integrated luminosity of 5.4 fb\\(^{-1}\\). We estimate the cross section to be \\( 0.84 \\pm 0.11 \\) (stat.) \\( \\pm 0.10 \\) (syst.) pb, which is in strong agreement with next-to-leading-order perturbative QCD predictions. Based on this result, we establish upper limits on potential anomalous trilinear gauge-boson couplings. Furthermore, this data allows us to place constraints on predictions regarding new heavy neutral vector bosons that decay into pairs of photons or gluons. Additionally, these measurements provide significant insights for future studies on Higgs bosons decaying into two photons. PACS codes: 11.30.Er, 12.60.Jv.",
        "ori-fast-z-score": -1.0886621079036347,
        "water-fast-z-score": 4.532898610306738,
        "rewrite-fast-z-score": -1.1920791213585393
    },
    {
        "original_text": "The electrical properties of BaTiO3 ceramics are investigated in this work by means of impedance spectroscopy (IS) at different temperatures ranging between 25 °C to 250 °C, with frequencies varying from 1 kHz to 10 MHz. The results show that the resistance decreases as the temperature increases while the capacitance remains almost constant over the entire range of measurement. This behavior is explained on the basis of the hopping conduction mechanism which dominates the transport process across grain boundaries. \n \n Keywords: Impedance Spectroscopy, Thermal conductivity, Electrical resistivity, BaTiO3 ceramic. Introduction: In recent years there has been growing interest in developing high performance materials for use in electronic devices such as sensors  1  , transducers  2  , microelectronic circuits  3  . These applications require materials having low thermal conductivities  4  , large dielectric constants  5  , small dielectric losses  6  , and high Curie temperatures  7  .\nBaTiO3 is one of these promising materials because it exhibits ferroelectricity  8  , piezoelectricity  9  , pyroelectricity  10  , and photocatalytic activity  11  . It also shows good chemical stability  12  , biocompatibility  13  , optical transparency  14  , and relatively low cost  15  . However, its poor sinterability  16  limits its application  17  . To overcome this problem, several methods have been developed including mechanical alloying  18  , spark plasma sintering  19  , microwave assisted sintering  20  , hydrothermal synthesis  21  , sol-gel processing  22  , etc  23  .",
        "watermark_text": "The electrical properties of BaTiO3 pottery are examined in this research by means of impedance spectroscopy ( IS ) at different conditions ranging between 25 °C to 250 °C , with speeds range from 1 kHz to 10 MHz . The results show that the resistance drops as the temperature increases while the capacitance remains virtually constant over the entire range of study .This activity is understood on the basis of the hopping conduction process which dominates the travel cycle across grain boundaries . Keywords : Impedance Spectroscopy , Thermal conductivity , Electrical resistivity , BaTiO3 ceramic .Introduction : In recent years there has been growing interest in building high quality devices for use in digital systems such as sensors 1 , transducers 2 , microelectronic logic 3 . These systems require devices having low heat conductivities 4 , large dielectric constants 5 , large dielectric losses 6 , and large Curie temperatures 7 .BaTiO3 is one of these promising compounds because it displays ferroelectricity 8 , piezoelectricity 9 , pyroelectricity 10 , and photocatalytic behavior 11 . It additionally shows excellent chemical integrity 12 , biocompatibility 13 , optical sensitivity 14 , and fairly lowest price 15 .However , its bad sinterability 16 limits its use 17 . To solve this situation , various methods have been constructed including magnetic alloying 18 , flash laser sintering 19 , infrared assisted sintering 20 , hydrothermal synthesis 21 , sol - gel manufacturing 22 , etc 23 .",
        "rewrite_text": "This study investigates the electrical properties of BaTiO3 ceramics using impedance spectroscopy (IS) across a temperature range of 25 °C to 250 °C and frequency ranges from 1 kHz to 10 MHz. The findings indicate that as temperature rises, the resistance decreases while the capacitance remains nearly unchanged throughout the examined range. This behavior can be attributed to the hopping conduction mechanism that influences charge transport across grain boundaries. \n\n**Keywords:** Impedance Spectroscopy, Thermal Conductivity, Electrical Resistivity, BaTiO3 Ceramic. \n\n**Introduction:** In recent years, there has been an increasing focus on developing high-quality devices for digital systems, including sensors, transducers, and microelectronic logic components. These applications necessitate devices with low thermal conductivities, high dielectric constants, significant dielectric losses, and elevated Curie temperatures. BaTiO3 is a particularly promising material due to its ferroelectric, piezoelectric, pyroelectric, and photocatalytic properties. It also boasts excellent chemical stability, biocompatibility, optical sensitivity, and is relatively inexpensive. However, its poor sinterability poses a challenge to its widespread use. Various methods have been explored to address this issue, such as magnetic alloying, flash laser sintering, infrared-assisted sintering, hydrothermal synthesis, and sol-gel processing.",
        "ori-fast-z-score": -1.8973665961010275,
        "water-fast-z-score": 7.506518906054692,
        "rewrite-fast-z-score": -0.5360562674188973
    },
    {
        "original_text": "We present VLT/VIMOS integral field spectroscopic observations for three high-z (z ~ 2.5) radio galaxies, which are known to be surrounded by extended Lyman alpha halos. The main goal is to study their kinematics and physical conditions in order to understand how these objects evolve into massive elliptical galaxies at low redshifts. We find that all three sources show complex velocity fields dominated by rotation around an axis perpendicular to the radio jets. In addition we detect several components showing blueshifted velocities up to -500 km/s relative to systemic redshift. These features may represent outflows driven by AGN feedback or galactic winds powered by star formation activity. Finally, we measure the gas density distribution using  OII  emission lines and estimate the mass of ionized hydrogen surrounding each galaxy. Our results suggest that the observed Lyman alpha halos have masses ranging between 10^10 M_sol and 10^11 M_sol .",
        "watermark_text": "We present VLT / VIMOS integral field spectroscopic observations for three high - z ( z ~ 2 . 5 ) radio objects , which are known to be accompanied by extended Lyman alpha halos . The main goal is to study their kinematics and physical conditions in order to explain how these objects evolve into huge elliptical galaxies at low redshifts .We see that all three sources show complex momentum fields dominated by rotation around an axis diagonal to the radio jets . In addition we find various components showing blueshifted velocities up to - 500 cm / s relative to systemic redshift .These features could indicate outflows driven by AGN feedback or galactic winds driven by galaxy formation activity . Finally , we measure the gas density flow use OII emission lines and estimate the mass of ionized gas covering each galaxy .Our results propose that the known Lyman alpha halos have masses ranging between 10 ^ 10 M _ sol and 10 ^ 11 M _ sol .",
        "rewrite_text": "We present integral field spectroscopic observations from VLT/VIMOS for three high-redshift (z ~ 2.5) radio sources known to possess extended Lyman-alpha halos. The primary objective of this study is to investigate their kinematics and physical conditions to understand how these objects evolve into massive elliptical galaxies at lower redshifts. Our analysis reveals that all three sources exhibit complex momentum fields, primarily dominated by rotation around an axis that is diagonal to the orientation of the radio jets. Furthermore, we observe multiple components showing blueshifted velocities of up to -500 km/s relative to the systemic redshift. These characteristics may suggest outflows driven by AGN feedback or galactic winds resulting from galaxy formation processes. Lastly, we assess the gas density flow using [O II] emission lines and estimate the mass of the ionized gas surrounding each galaxy. Our findings indicate that the known Lyman-alpha halos have masses ranging from 10^10 M_sun to 10^11 M_sun.",
        "ori-fast-z-score": 0.6974858324629157,
        "water-fast-z-score": 5.500933918218137,
        "rewrite-fast-z-score": 2.0647416048350555
    },
    {
        "original_text": "We report an observation of a large coronal mass ejection (CME) associated with a halo-type flare that occurred in active region NOAA 10486 on 2006 December 13, which was observed by Solar TErrestrial RElations Observatory (STEREO). The CME speed is estimated to be about 1450 km/s at 1 AU using STEREO observations. We find that this CME originated from a complex magnetic structure consisting of two opposite-polarity flux systems connected by a filament channel. In addition, we found that there were several small-scale brightenings around the main sunspots before the onset of the flare/CME activity. These brightenings are identified as ephemeral regions (ERs), which are known to play important roles for triggering eruptions such as flares or CMEs. By analyzing high-resolution images taken by Hinode/SOT/SP, we show that one of these ERs interacted strongly with the surrounding magnetic field lines during its rapid rotation. This interaction caused reconnection between open and closed magnetic fields, resulting in the formation of a current sheet below the ER. Then, the eruption started when the current sheet became unstable due to the kink instability.",
        "watermark_text": "We report an observation of a large coronal mass ejection ( CME ) associated with a halo - class flare that occurred in active region NOAA 10486 on 2006 December 13 , which was seen by Solar TErrestrial RElations Observatory ( STEREO ) . The CME rate is predicted to be about 1450 km / s at 1 AU using STEREO images .We see that this CME originated from a complex magnetic formation consisting of two opposite - polarity flux systems connected by a filament channel . In addition , we saw that there were several small - scale brightenings around the main sunspots before the beginning of the flare / CME activity .These brightenings are identified as ephemeral regions ( ERs ) , which are known to take key roles for triggering eruptions such as flares or CMEs . By analyzing large - resolution photos taken by Hinode / SOT / SP , we find that one of these ERs interacted heavily with the nearby magnetic field lines during its rapid rotation .This coupling resulted reconnection between open and open magnetic waves , leading in the formation of a current sheet below the ER . Then , the volcano started when the current sheet became unstable due to the kink instability .",
        "rewrite_text": "We present an observation of a significant coronal mass ejection (CME) linked to a halo-class flare that took place in active region NOAA 10486 on December 13, 2006, as captured by the Solar TErrestrial RElations Observatory (STEREO). Analysis of STEREO images suggests that the CME is expected to travel at approximately 1450 km/s at a distance of 1 astronomical unit (AU). This CME is traced back to a complex magnetic structure composed of two opposing polarity flux systems connected by a filament channel. Additionally, prior to the flare and CME onset, several small-scale brightenings were observed around the main sunspots. These brightenings are categorized as ephemeral regions (ERs), which are recognized for their crucial role in triggering eruptions like flares and CMEs. By examining high-resolution images obtained from the Hinode/SOT/SP, we discovered that one of these ERs engaged significantly with the surrounding magnetic field lines during its rapid rotation. This interaction caused reconnection between open magnetic field lines, resulting in the formation of a current sheet beneath the ER. The eruption began when this current sheet became unstable due to kink instability.",
        "ori-fast-z-score": -0.6974858324629157,
        "water-fast-z-score": 5.032769329433615,
        "rewrite-fast-z-score": -0.3375263702778072
    },
    {
        "original_text": "We study the phenomenology of string compactifications with large extra dimensions, focusing on supersymmetric particles in the mass range accessible to current experiments at the Large Hadron Collider (LHC). We consider two classes of models that are motivated by recent developments in string theory: weakly coupled heterotic orbifolds and strongly coupled Type IIB orientifold constructions. In both cases we find that there is an interesting interplay between the Kaluza-Klein excitations associated with the extra dimensions and the lightest Standard Model superpartners. For example, in some regions of parameter space it may be possible to produce gluinos or squarks directly via Drell-Yan processes; alternatively, these states can decay into lighter Standard Model superpartners which then cascade down to the LSP neutralino. The resulting collider signatures depend sensitively on the details of the underlying model parameters as well as the number of extra dimensions.",
        "watermark_text": "We research the phenomenology of string compactifications with large extra dimensions , concentrating on supersymmetric particles in the mass range available to recent experiments at the Large Hadron Collider ( LHC ) . We consider two groups of models that are motivated by recent developments in string theory : weakly connected heterotic orbifolds and strongly coupled Type IIB orientifold constructions .In both cases we find that there is an interesting interplay between the Kaluza - Klein excitations associated with the extra dimensions and the lightest Standard Model superpartners . For instance , in some regions of parameter room it could be possible to produce gluinos or squarks directly via Drell - Yan processes ; alternatively , these states can evolve into heavier Standard Model superpartners which then cascade down to the LSP neutralino .The produced collider signatures vary sensitively on the details of the underlying model variables as also as the number of added dimensions .",
        "rewrite_text": "We investigate the phenomenology of string compactifications involving large extra dimensions, focusing specifically on supersymmetric particles whose masses fall within the range accessible to recent experiments at the Large Hadron Collider (LHC). Our study examines two categories of models inspired by recent advancements in string theory: weakly coupled heterotic orbifolds and strongly coupled Type IIB orientifold frameworks. In both scenarios, we observe a notable interaction between the Kaluza-Klein excitations linked to the extra dimensions and the lightest superpartners of the Standard Model. For example, in certain parameter regions, it may be feasible to directly produce gluinos or squarks through Drell-Yan processes; alternatively, these states might transition into heavier Standard Model superpartners, which subsequently decay into the lightest stable particle, the neutralino. The collider signatures produced are highly sensitive to the specifics of the underlying model parameters, as well as the number of additional dimensions involved.",
        "ori-fast-z-score": 0.9271726499455306,
        "water-fast-z-score": 5.165676192553671,
        "rewrite-fast-z-score": -0.12403473458920847
    },
    {
        "original_text": "The Variable Star One-Shot project is an open-source software package for the analysis of astronomical data.  It was developed by members of the Harvard-Smithsonian Center for Astrophysics (CfA) in collaboration with researchers at other institutions around the world.   The goal of this project is to provide a single tool that can be used to analyze all types of astronomical data sets, including photometric time series, spectroscopic observations, images, etc., using state-of-the-art techniques such as image subtraction, cross correlation, period finding algorithms, spectral line fitting, etc.    This software has been released under the GNU General Public License v3.0 and is available on GitHub at: https://github.com/VariableStar/one-shot-astro .\nOne Shot Astro includes several tools which are useful for analyzing large amounts of astronomical data quickly and efficiently.   These include one-shot-datacleaner , which performs automated quality control checks on raw data files;   one-shot-mosaic , which creates mosaicked images from multiple dithered exposures;  one-shot-astrometry , which determines astrometric solutions for individual frames or entire mosaic images;    one-shot-photometry , which measures fluxes and/or magnitudes for stars across a field-of-view;    one-shot-pipeline , which automates the process of running these various tasks together into a pipeline;    one-shot-wikimapia , which allows users to create custom sky maps based on their own catalogs of objects.     In addition to these core packages, there are also many additional modules available through the one-shot-astro repository which allow users to perform more specialized analyses, such as:    one-shot-catalog , which provides access to a variety of different astrophysical databases via SQL queries;    one-shot-fastphot , which uses machine learning methods to measure stellar",
        "watermark_text": "The Variable Star One - Shot initiative is an free - source software tool for the analysis of astronomical data . It was developed by participants of the Harvard - Smithsonian Center for Astrophysics ( CfA ) in partnership with researchers at other institutions around the world .The goal of this project is to provide a single method that can be used to analyze all types of astronomical data sets , including photometric period series , spectroscopic observations , photographs , etc . , using state - of - the - art methods such as image subtraction , inter correlation , period finding methods , spectral line fitting , etc . This program has been released under the GNU General Public License v3 . 0 and is accessible on GitHub at : https : / / github . com / VariableStar / one - shot - astro .One Shot Astro includes several methods which are helpful for studying huge amounts of astronomical data easily and smoothly . These include one - shot - datacleaner , which performs automated quality control checks on raw data data ; one - shot - mosaic , which forms mosaicked images from multiple dithered exposures ; one - shot - astrometry , which determines astrometric solutions for individual frames or entire mosaic images ; one - shot - photometry , which estimates fluxes and / or magnitudes for planets across a field - of - view ; one - shot - pipeline , which automates the process of running these numerous tasks combined into a pipeline ; one - shot - wikimapia , which allows users to create custom skies mapping based on their own catalogs of items .In addition to these core programs , there are also many extra modules available through the one - shot - astro repository which allow users to conduct more sophisticated analyses , such as : one - shot - collection , which offers connections to a variety of different astrophysical databases via SQL queries ; one - shot - fastphot , which uses computer learning techniques to measure stellar",
        "rewrite_text": "The Variable Star One-Shot initiative is an open-source software tool designed for analyzing astronomical data. Developed by participants at the Harvard-Smithsonian Center for Astrophysics in collaboration with researchers from various institutions globally, the project aims to offer a unified method for examining a wide range of astronomical datasets, including photometric time series, spectroscopic observations, and images. It employs advanced techniques such as image subtraction, cross-correlation, period finding algorithms, and spectral line fitting. The software is released under the GNU General Public License v3.0 and is available on GitHub at: https://github.com/VariableStar/one-shot-astro. \n\nOne-Shot Astro features several methods that facilitate the easy handling of large volumes of astronomical data. These include One-Shot DataCleaner for automated quality control checks on raw data, One-Shot Mosaic for creating mosaicked images from multiple exposures, One-Shot Astrometry for determining astrometric solutions for individual frames or whole mosaics, and One-Shot Photometry for estimating fluxes and magnitudes of celestial bodies across a field of view. Additionally, One-Shot Pipeline automates the execution of these tasks as part of a workflow, while One-Shot Wikimapia enables users to develop custom sky maps based on their item catalogs.\n\nBeyond these core features, the One-Shot Astro repository also offers numerous supplementary modules that allow users to perform more complex analyses. These include One-Shot Collection, which connects to various astrophysical databases via SQL queries, and One-Shot FastPhot, which utilizes machine learning techniques to measure stellar properties.",
        "ori-fast-z-score": 1.2094157958139042,
        "water-fast-z-score": 8.465910570697329,
        "rewrite-fast-z-score": -0.9128709291752769
    },
    {
        "original_text": "We discuss the gauge invariance properties of effective actions obtained by integrating out heavy degrees of freedom, such as quarks and gluons, within supersymmetric Yang-Mills theories. We show that these actions are not generally invariant under local gauge transformations unless certain conditions on their form are satisfied. These results have important consequences for the construction of gauge-invariant observables in supersymmetric gauge theories. They also provide an explanation why it is possible to construct nontrivial superpotentials even though supersymmetry does not allow any explicit breaking terms at tree level. Finally we argue that our findings can be used to resolve some puzzling features observed recently in lattice simulations of N = 1 supersymmetric QCD with four flavors. Supersymmetric Yang-Mills theories play an important role both in particle physics and string theory. Their low-energy dynamics is described by an effective action which contains all quantum corrections due to the integration over heavy fields like quarks or gluons. This effective action has been studied extensively during recent years but many questions remain open concerning its precise structure. One particular issue concerns the question whether this action is gauge invariant. It was shown already more than twenty years ago  1  that if one integrates out only massive fermions then the resulting effective action is indeed gauge invariant. However, when including also massive bosonic degrees of freedom there exist counterexamples where the effective action fails to be gauge invariant  2  . Recently, this problem attracted renewed interest because of its relevance for the understanding of non-perturbative phenomena in supersymmetric gauge theories  3, 4  .\nIn this work we study the gauge invariance properties systematically using functional methods. Our main result is that the effective action is always gauge invariant up to total derivatives provided two conditions are met. First, the effective action must contain no higher-order time-derivatives acting on the gauge field. Second, the coefficients appearing in front of the various operators in the effective action should satisfy certain relations. For example, they cannot depend explicitly on the gauge coupling constant g. If either condition is violated then the effective action will fail to be gauge",
        "watermark_text": "We discuss the gauge invariance characteristics of effective actions obtained by combining out heavy degrees of liberty , such as quarks and gluons , within supersymmetric Yang - Mills theories . We see that these actions are not generally invariant under local gauge processes unless particular conditions on their form are fulfilled .These results have important implications for the creation of gauge - invariant observables in supersymmetric gauge fields . They especially offer an reason why it is easy to build nontrivial superpotentials even though supersymmetry does not enable any explicit breaking terms at tree level .Finally we claim that our findings can be used to explain some puzzling properties observed lately in crystal simulations of N = 1 supersymmetric QCD with four flavors . Supersymmetric Yang - Mills theories play an important role both in particle theory and string theory .Their low - energy dynamics is characterized by an efficient action which contains all quantum corrections due to the integration over heavy fields like quarks or gluons . This effective operation has been studied thoroughly during recent months but numerous concerns remain open concerning its precise shape .One particular issue concerns the question whether this action is gauge invariant . It was shown still more than twenty years previously 1 that if one integrates out only massive fermions then the resulting effective operation is indeed gauge invariant .However , when including also massive bosonic degrees of liberty there remain counterexamples where the effective operation fails to be gauge invariant 2 . Recently , this question attracted heightened interest because of its significance for the knowledge of non - perturbative processes in supersymmetric gauge physics 3 , 4 .In this study we study the gauge invariance effects systematically using functional technique . Our main consequence is that the effective act is usually gauge invariant up to maximum derivatives assuming two conditions are fulfilled .First , the effective act must include no higher - order time - derivatives acting on the gauge field . Second , the coefficients appearing in front of the various operators in the effective act should satisfy certain relations .For instance , they cannot depend explicitly on the gauge interaction function g . If either situation is violated then the effective act will fail to be gauge",
        "rewrite_text": "We examine the properties of gauge invariance in effective actions derived from integrating out heavy degrees of freedom, such as quarks and gluons, within supersymmetric Yang-Mills theories. Our findings indicate that these effective actions generally lack local gauge invariance unless specific conditions regarding their formulation are met. These results have significant implications for the development of gauge-invariant observables in supersymmetric gauge fields, particularly highlighting why constructing nontrivial superpotentials is relatively straightforward, despite the absence of explicit breaking terms at the tree level in supersymmetry. Moreover, we assert that our observations can clarify some recent puzzling phenomena noted in crystal simulations of N = 1 supersymmetric QCD with four flavors. Supersymmetric Yang-Mills theories are vital in both particle physics and string theory, with their low-energy dynamics described by an effective action that encapsulates all quantum corrections arising from the integration of heavy fields like quarks and gluons. Although this effective action has been extensively analyzed in recent months, many questions regarding its precise behavior remain unanswered. A key issue concerns the gauge invariance of this action. It was established over twenty years ago that integrating out only massive fermions results in a gauge-invariant effective action. However, when massive bosonic degrees of freedom are also considered, counterexamples exist where the effective action is not gauge invariant. Recently, this issue has garnered increased attention due to its relevance for understanding non-perturbative processes in supersymmetric gauge theory. In this study, we systematically investigate the effects of gauge invariance using functional techniques. Our primary conclusion is that the effective action is typically gauge invariant up to the highest derivatives, provided two conditions are satisfied: first, the effective action must not contain higher-order time derivatives acting on the gauge field; and second, the coefficients of the various operators in the effective action must adhere to specific relations, such as not explicitly depending on the gauge coupling function \\(g\\). If either of these conditions is violated, the effective action will lose its gauge invariance.",
        "ori-fast-z-score": -1.9487823913892397,
        "water-fast-z-score": 7.698581455344939,
        "rewrite-fast-z-score": 1.0737509843863184
    },
    {
        "original_text": "We present results of numerical simulations of the nonlinear evolution of electrostatic waves excited by a localized source in a magnetized, collisionless plasma with nonuniform density and temperature profiles. The initial conditions are chosen to be close to those observed during experiments at the Large Plasma Device (LAPD) facility at UCLA. We find that the wave spectrum is dominated by two distinct branches corresponding to different types of waves: slow modes which propagate along magnetic field lines and fast modes which have oblique propagation angles relative to B. In addition we observe a number of other interesting phenomena such as generation of coherent structures, formation of shock fronts, etc., all of which can be explained within the framework of Zakharov s theory for Langmuir turbulence. \n \n Keywords: Nonlinear dynamics; Turbulence; Wave-particle interactions; Collisionless plasmas; LAPD; Fast-slow mode coupling; Waves",
        "watermark_text": "We present results of computational simulations of the nonlinear progression of electrostatic rays accelerated by a localized source in a magnetized , collisionless plasma with nonuniform density and heat profiles . The initial conditions are chosen to be close to those observed during experiments at the Large Plasma Device ( LAPD ) laboratory at UCLA .We see that the wave spectrum is dominated by two different branches corresponding to different kinds of waves : slow modes which propagate along magnetic field lines and fast modes which have oblique propagation distances relative to B . In addition we study a number of other remarkable phenomena such as development of coherent complexes , creating of flash fronts , etc . , all of which can be described within the framework of Zakharov s concept for Langmuir turbulence .Keywords : Nonlinear dynamics ; Turbulence ; Wave - particle interactions ; Collisionless plasmas ; LAPD ; Fast - slow mode interaction ; Waves",
        "rewrite_text": "We present findings from computational simulations that explore the nonlinear evolution of electrostatic rays accelerated by a localized source in a magnetized, collisionless plasma with varying density and temperature profiles. The initial conditions are selected to closely resemble those observed in experiments conducted at the Large Plasma Device (LAPD) laboratory at UCLA. Our results reveal that the wave spectrum is primarily influenced by two distinct branches, corresponding to different types of waves: slow modes that propagate along magnetic field lines and fast modes that travel at oblique angles to the magnetic field. Additionally, we investigate several noteworthy phenomena, such as the emergence of coherent structures and the formation of flash fronts, all of which can be analyzed within the framework of Zakharov's theory of Langmuir turbulence. \n\nKeywords: Nonlinear dynamics; Turbulence; Wave-particle interactions; Collisionless plasmas; LAPD; Fast-slow mode interaction; Waves.",
        "ori-fast-z-score": -1.2909944487358056,
        "water-fast-z-score": 3.6147844564602556,
        "rewrite-fast-z-score": 0.8551861104941365
    },
    {
        "original_text": "We present the first comprehensive study of visible spectroscopy for all known Jupiter trojans (JTs). We obtained high-resolution spectra with Subaru/HDS, Gemini/GNIRS, and Keck/NIRC-2 in order to determine their surface compositions. The sample includes 49 JTs including two new discoveries by our team. Our analysis shows that most JTs are S-complex asteroids or C-type asteroids. However, we found four objects which show unusual spectral features; one is an E-type asteroid, while three others have featureless red-sloped continuum. These objects may be primitive bodies such as carbonaceous chondrites. In addition, we find that some JTs belong to dynamically cold families. This suggests that these families were formed recently through catastrophic collisions among parent bodies. Finally, we discuss possible formation scenarios for JTs based on our findings. Keywords: Asteroids",
        "watermark_text": "We present the first comprehensive investigation of visible spectroscopy for all known Jupiter trojans ( JTs ) . We obtained high - resolution spectra with Subaru / HDS , Gemini / GNIRS , and Keck / NIRC - 2 in order to obtain their surface compositions .The sample comprises 49 JTs including two latest discoveries by our team . Our study shows that most JTs are S - complex asteroids or C - class asteroids .However , we identified four bodies which show peculiar spectral features ; one is an E - class asteroid , while three rest have featureless red - sloped continuum . These bodies may be ancient bodies such as carbonaceous chondrites .In addition , we find that some JTs belong to dynamically cold families . This implies that these families were created recently through catastrophic collisions among parent bodies .Finally , we explain possible formation scenarios for JTs based on our findings . Keywords : Asteroids",
        "rewrite_text": "We present the first thorough examination of visible spectroscopy across all known Jupiter Trojans (JTs). Utilizing high-resolution spectra obtained from Subaru/HDS, Gemini/GNIRS, and Keck/NIRC-2, we analyzed their surface compositions. Our sample includes 49 JTs, including two recent discoveries made by our team. Our research indicates that the majority of JTs fall into the S-complex or C-class asteroid categories. Notably, we identified four bodies with unusual spectral characteristics: one is classified as an E-class asteroid, while the other three exhibit a featureless red-sloped continuum. These objects may represent ancient bodies akin to carbonaceous chondrites. Additionally, we discovered that some JTs are part of dynamically cold families, suggesting that these families formed relatively recently due to catastrophic collisions among their parent bodies. We conclude by discussing potential formation scenarios for the JTs based on our findings. Keywords: Asteroids.",
        "ori-fast-z-score": 0.13483997249264842,
        "water-fast-z-score": 4.900769721140662,
        "rewrite-fast-z-score": -0.629940788348712
    },
    {
        "original_text": "We consider the periodic oscillation of an adiabatic piston in contact with two ideal gases at different temperatures and pressures, separated by a rigid wall.  We prove that if the initial state is close to equilibrium then there exists a unique global solution which converges exponentially fast towards its limit cycle as time goes to infinity.  The proof relies on a combination of techniques from nonlinear analysis (Lyapunov functions) and kinetic theory (Boltzmann equation). In this work we study the dynamics of an adiabatic gas-piston system consisting of one-dimensional ideal gases confined between two walls. One of these walls is fixed while the other moves periodically according to some prescribed law. This problem has been studied extensively since the pioneering works of Maxwell  Max  , Boltzmann  Bol1  , and Sackur-Tetrode  Sac  . It was shown rigorously by Cercignani  Cerc  that under suitable assumptions on the motion of the piston, the solutions converge exponentially fast to their limit cycles. However, it seems difficult to extend his results beyond the case where the temperature difference across the piston remains small during all times. Here we show how to overcome this difficulty using new ideas based on Lyapunov functions combined with estimates coming from kinetic theory.",
        "watermark_text": "We consider the periodic oscillation of an adiabatic piston in contact with two ideal gases at different temperatures and pressures , separated by a rigid wall . We assume that if the first state is close to equilibrium then there exists a unique global solution which converges exponentially rapidly towards its limit cycle as time went to infinity .The proof uses on a combination of techniques from nonlinear analysis ( Lyapunov functions ) and kinetic theory ( Boltzmann integral ) . In this research we study the dynamics of an adiabatic gas - cylinder scheme consisting of one - dimensional ideal molecules confined between two walls .One of these barriers is fixed while the other moves periodically due to some prescribed law . This problem has been studied frequently since the pioneering works of Maxwell Max , Boltzmann Bol1 , and Sackur - Tetrode Sac .It was shown rigorously by Cercignani Cerc that under suitable assumptions on the movement of the piston , the systems converge exponentially rapidly to their limit cycles . However , it appears impossible to stretch his results beyond the case where the temperature difference across the piston remains tiny during all periods .Here we give how to overcome this trouble using new concepts relying on Lyapunov numbers coupled with projections come from kinetic theory .",
        "rewrite_text": "We analyze the periodic oscillation of an adiabatic piston in contact with two ideal gases at varying temperatures and pressures, divided by a rigid wall. We hypothesize that if the initial state is nearly in equilibrium, there exists a unique global solution that converges exponentially fast to its limit cycle as time approaches infinity. The proof employs a combination of methods from nonlinear analysis, specifically Lyapunov functions, and kinetic theory, particularly the Boltzmann integral. Our research investigates the dynamics of an adiabatic gas-cylinder system composed of one-dimensional ideal molecules confined between two walls; one wall is stationary while the other oscillates periodically according to a defined law. This problem has been frequently examined since the foundational works of Maxwell, Boltzmann, and Sackur-Tetrode. Cercignani has rigorously demonstrated that, under suitable assumptions regarding the piston's movement, the system converges exponentially to its limit cycles. However, extending these results to cases where the temperature difference across the piston is significant throughout all periods appears to be challenging. In this study, we propose a solution to this issue by introducing new concepts based on Lyapunov numbers combined with projections derived from kinetic theory.",
        "ori-fast-z-score": 0.618852747755276,
        "water-fast-z-score": 5.775958979049243,
        "rewrite-fast-z-score": 1.6865480854231356
    },
    {
        "original_text": "We present absolute calibration results on the MIPS 24, 70, and 160 m bands obtained with observations of Neptune in its southern winter hemisphere. We find that our photometric model is accurate to better than 5% over most of the field-of-view (FOV) at all three wavelengths. The uncertainty in the absolute flux scale is dominated by uncertainties in the Neptune models used as calibrators. These are estimated to be less than 10% across each bandpass. In addition we have characterized the detector response function using data taken during spacecraft testing prior to launch. This characterization has been incorporated into the final processing pipeline which will produce calibrated images for science use. Finally, we show how these results can be combined with those presented in Paper I to provide an overall estimate of the accuracy of the MIPS instrument. Keywords: Space Science Instrumentation, Infrared Space Observatory, Spitzer Space Telescope, MIPS",
        "watermark_text": "We present absolute calibration results on the MIPS 24 , 70 , and 160 m bands collected with observations of Neptune in its southern winter hemisphere . We see that our photometric model is accurate to good than 5 % over most of the field - of - view ( FOV ) at all three wavelengths .The uncertainty in the absolute flux range is dominated by uncertainties in the Neptune models used as calibrators . These are estimated to be less than 10 % across each bandpass .In addition we have characterized the detector response structure using data taken during spacecraft testing previous to launch . This description has been used into the finished processing pipeline which will generate calibrated images for research use .Finally , we show how these results can be merged with those provided in Paper I to provide an overall estimate of the accuracy of the MIPS instrument . Keywords : Space Science Instrumentation , Infrared Space Observatory , Spitzer Space Telescope , MIPS",
        "rewrite_text": "We present the results of absolute calibration for the MIPS 24, 70, and 160 µm bands, obtained from observations of Neptune during its southern winter hemisphere. Our photometric model demonstrates an accuracy greater than 5% across most of the field of view (FOV) at all three wavelengths. The primary source of uncertainty in the absolute flux measurements arises from the Neptune models utilized as calibrators, with estimated uncertainties of less than 10% for each bandpass. Furthermore, we have characterized the structure of the detector response using data gathered during the spacecraft's pre-launch testing. This characterization has been integrated into the final processing pipeline, which will produce calibrated images for research purposes. Finally, we discuss how these findings can be combined with those from Paper I to provide a comprehensive assessment of the accuracy of the MIPS instrument. Keywords: Space Science Instrumentation, Infrared Space Observatory, Spitzer Space Telescope, MIPS.",
        "ori-fast-z-score": 1.9051586888313607,
        "water-fast-z-score": 5.528438872198585,
        "rewrite-fast-z-score": 0.5345224838248488
    },
    {
        "original_text": "We study resonant spin polarization (RSP) in a two-dimensional hole gas with Rashba spin-orbit interaction by solving the Kohn-Sham equations within density functional theory. We show that RSP is strongly affected by the presence of the Luttinger parameter, which describes the strength of electron-electron interactions. In particular we find that for large values of the Luttinger parameters the magnitude of RSP decreases significantly due to an increase in the effective mass of holes. Furthermore, we demonstrate that RSP can be controlled by applying external electric fields perpendicular to the plane of the 2D hole gas. Finally, we discuss how our results are related to recent experiments on GaAs quantum wells. The effect of the Luttinger terms, structural inversion asymmetry (SIA), and Zeeman splitting on resonant spin polarization (RS P ) has been studied using density functional theory. It was found that RS P is suppressed when the Luttinger parameter increases because it leads to larger effective masses. Moreover, it was shown that RS P can be tuned by applying external electric fields normal to the plane of the two-dimensional hole gas. Our results were compared to experimental data obtained recently on GaAs quantum wells. \n \n Resonant spin polarization (R SP ), i.e., the generation of a nonequilibrium spin population at zero magnetic field via optical excitation into a heavy-hole exciton resonance, has attracted considerable interest over the past years  1–3  . This phenomenon occurs if the energy difference between the conduction band minimum and the valence band maximum lies below the photon energy of the exciting laser light  4  , as illustrated schematically in Fig. 1(a). Due to this condition, electrons excited into the conduction band have a finite probability of being scattered back into the valence band before they relax radiatively or nonradiatively  5  . If these electrons return to their original state after scattering, then they will carry away angular momentum  6  . As a result, the total angular momentum of the system becomes imbalanced  7   .\n \n \n Recently, several groups reported measurements of R SP  8 –10  .",
        "watermark_text": "We research resonant spin polarization ( RSP ) in a two - dimensional hole gas with Rashba spin - orbit interaction by solving the Kohn - Sham equations within density functional theory . We see that RSP is strongly altered by the presence of the Luttinger parameter , which explains the strength of electron - atom bonding .In particular we find that for large values of the Luttinger parameters the magnitude of RSP decreases dramatically due to an increase in the effective mass of holes . Furthermore , we prove that RSP can be regulated by using external electric forces adjacent to the plane of the 2D hole gas .Finally , we talk how our findings are related to recent experiments on GaAs quantum wells . The impact of the Luttinger terms , functional inversion asymmetry ( SIA ) , and Zeeman splitting on resonant spin polarization ( RS P ) has been studied utilizing density functional theory .It was shown that RS P is suppressed when the Luttinger parameter grows because it leads to larger effective masses . Moreover , it was shown that RS P can be tuned by using external electric forces regular to the plane of the two - dimensional hole gas .Our results were compared to experimental evidence derived recently on GaAs quantum wells . Resonant spin polarization ( R SP ) , i . e . , the generation of a nonequilibrium spin population at zero magnetic field via optical excitation into a light - hole exciton resonance , has garnered considerable interest over the previous years 1 – 3 .This phenomenon occurs if the power change between the conduction band minimum and the valence band maximum falls below the photon energy of the exciting laser light 4 , as shown schematically in Fig . 1 ( a ) .Due to this situation , electrons excited into the conduction band have a finite probability of being dispersed back into the valence band before they relax radiatively or nonradiatively 5 . If these electrons go to their previous state after scattering , then they will take aside angular velocity 6 .As a result , the total angular velocity of the system gets imbalanced 7 . Recently , various groups reported measurements of R SP 8 – 10 .",
        "rewrite_text": "We investigate resonant spin polarization (RSP) in a two-dimensional hole gas featuring Rashba spin-orbit interaction, employing the Kohn-Sham equations within density functional theory. Our findings indicate that the presence of the Luttinger parameter significantly influences RSP, which correlates with the strength of electron-atom bonding. Specifically, we observe that as the Luttinger parameters increase, the magnitude of RSP diminishes sharply due to a corresponding rise in the effective mass of holes. Additionally, we demonstrate that RSP can be adjusted through external electric fields applied perpendicular to the plane of the 2D hole gas. We also discuss how our results relate to recent experiments conducted on GaAs quantum wells. The effects of Luttinger terms, spin inversion asymmetry (SIA), and Zeeman splitting on RSP have been extensively analyzed using density functional theory. Our studies reveal that RSP is suppressed as the Luttinger parameter increases, leading to higher effective masses. Furthermore, we confirm that RSP can be manipulated with external electric forces oriented along the plane of the two-dimensional hole gas. These results have been compared to recent experimental data from GaAs quantum wells. Resonant spin polarization (RSP), defined as the generation of a nonequilibrium spin population at zero magnetic field through optical excitation into a light-hole exciton resonance, has attracted significant attention in recent years. This phenomenon occurs when the energy difference between the conduction band minimum and the valence band maximum falls below the photon energy of the excitation laser, as illustrated in Fig. 1(a). Consequently, electrons excited into the conduction band might return to the valence band before they relax either radiatively or nonradiatively. If these electrons return to their initial state post-scattering, they will carry away angular momentum, resulting in an imbalance in the total angular momentum of the system. Various research groups have recently reported measurements of RSP.",
        "ori-fast-z-score": 0.40422604172722165,
        "water-fast-z-score": 6.5916865160463916,
        "rewrite-fast-z-score": 0.9931270663228415
    },
    {
        "original_text": "We present the results of hydrodynamic simulations that show how supernova ejecta can interact with nearby protoplanetary disks and produce observable signatures in their infrared emission. We find that, depending on disk properties (mass, radius), the interaction may lead to an increase or decrease in the total luminosity emitted by the system at near-infrared wavelengths. The effect is strongest for massive disks around young stars; it decreases rapidly as the mass ratio between the star and its disk decreases. \n \n In addition, we find that the interaction leads to significant changes in the temperature distribution within the disk. These effects are most pronounced when the disk is relatively close to the supernova progenitor - less than 100 AU away. For more distant systems, the impact of the supernova blast wave becomes negligible. Finally, our models suggest that the observed excesses in mid-infrared flux detected towards some T Tauri stars could be due to such interactions.",
        "watermark_text": "We present the conclusion of hydrodynamic simulations that demonstrate how supernova ejecta can interact with nearby protoplanetary disks and produce observable signatures in their infrared emission . We see that , depending on disk properties ( mass , diameter ) , the interaction may contribute to an increase or decrease in the total luminosity generated by the system at near - infrared wavelengths .The phenomenon is greatest for huge disks around old galaxies ; it decreases quickly as the mass ratio between the star and its disk decreases . In addition , we find that the interaction results to significant variations in the temperature balance within the disk .These effects are most pronounced when the disk is fairly nearest to the supernova progenitor - less than 100 AU away . For more distant systems , the impact of the supernova blast wave gets negligible .Finally , our calculations suggest that the seen excesses in middle - infrared flux detected towards some T Tauri stars likely be due to such interactions .",
        "rewrite_text": "We present the findings from our hydrodynamic simulations, which illustrate how supernova ejecta can interact with nearby protoplanetary disks, leading to observable changes in their infrared emissions. Our results indicate that the extent of this interaction, and its impact on the system's total luminosity at near-infrared wavelengths, varies depending on the disk's properties such as mass and diameter. The effect is most pronounced in massive disks surrounding older galaxies, but diminishes rapidly as the mass ratio between the star and its disk decreases. Additionally, we observe significant variations in the temperature distribution within the disk due to this interaction, particularly when the disk is located within 100 AU of the supernova progenitor. In cases where the disk is situated further away, the influence of the supernova's blast wave becomes minimal. Ultimately, our calculations suggest that the excess middle-infrared flux observed in some T Tauri stars is likely a result of these interactions.",
        "ori-fast-z-score": 0.47140452079103173,
        "water-fast-z-score": 5.7350162126103985,
        "rewrite-fast-z-score": -0.7171371656006361
    },
    {
        "original_text": "We present an analysis of archival XMM-Newton data for the Seyfert 1 galaxy, Mkr841 (NGC 4151). We find that the soft excess emission is well described by a blackbody component with kT = 0.16 keV and luminosity LBB ~ 1043 erg s-1. The hard X-ray spectrum can be fitted either by a power law or Compton reflection model. In both cases we detect strong relativistic Fe Kα lines at 6.4-6.7 keV which are broadened to FWHM ~ 1000 km/sec. These results suggest that there may exist two distinct regions where the accretion disk interacts with the central supermassive black hole. One region produces the soft excess via thermal reprocessing while another one gives rise to the hard X-ray emission through non-thermal processes such as inverse Compton scattering and/or Compton reflection.",
        "watermark_text": "We present an assessment of archival XMM - Newton data for the Seyfert 1 galaxy , Mkr841 ( NGC 4151 ) . We see that the soft excess emission is well described by a blackbody element with kT = 0 . 16 keV and luminosity LBB ~ 1043 erg s - 1 .The hard X - ray signal can be fit either by a power law or Compton absorption theory . In both cases we find strong relativistic Fe Kα bands at 6 . 4 - 6 . 7 keV which are broadened to FWHM ~ 1000 kilometers / sec .These data suggest that there may arise two separate areas where the accretion plasma interacts with the main supermassive black hole . One region delivers the deep excess via thermal reprocessing while another one offers rise to the hard X - ray radiation through non - thermal factors such as inverse Compton absorption and / or Compton absorption .",
        "rewrite_text": "We provide an analysis of archival XMM-Newton data for the Seyfert 1 galaxy MKR 841 (NGC 4151). Our findings indicate that the soft excess emission can be accurately modeled by a black body component with a temperature of kT = 0.16 keV and a luminosity of LBB approximately 10^43 erg s^-1. The hard X-ray emissions can be described using either a power-law model or Compton absorption theory. In both scenarios, we observe prominent relativistic Fe Kα lines between 6.4 and 6.7 keV, which exhibit a broadening of FWHM approximately 1000 kilometers per second. These observations imply the existence of two distinct regions where the accretion plasma interacts with the central supermassive black hole. One region contributes to the soft excess through thermal reprocessing, while the other generates hard X-ray radiation via non-thermal processes such as inverse Compton scattering and/or Compton absorption.",
        "ori-fast-z-score": -1.8203641092364127,
        "water-fast-z-score": 4.808326112068523,
        "rewrite-fast-z-score": 0.2626128657194451
    },
    {
        "original_text": "The discovery of the first X-ray pulsar, Scorpius X1 (Sco-X1), by Giacconi et al. (1962) opened up an exciting new field for astrophysics and led to the development of many important concepts such as accretion disks around compact objects.  The study of these systems has been revolutionized with the launch of Chandra and XMM-Newton observatories which have allowed us to probe their physical properties on unprecedented spatial scales.   In this review we will discuss some recent results obtained using these satellites that shed light on how neutron stars are formed and evolve within low-mass binary systems. We will also present our current understanding of the physics behind the formation of relativistic jets observed in several classes of X-ray binaries. Finally, we will briefly describe the prospects offered by future missions like XEUS or Constellation-X for studying these fascinating sources. Keywords: Accretion disk - Compact object - Relativistic jet -X-ray binary",
        "watermark_text": "The observation of the first X - ray pulsar , Scorpius X1 ( Sco - X1 ) , by Giacconi et al . ( 1962 ) opened up an exciting new area for astrophysics and led to the development of several important concepts such as accretion disks around compact galaxies .The investigation of these systems has been revolutionized with the launch of Chandra and XMM - Newton observatories which have permitted us to probe their physical properties on unprecedented spatial scales . In this review we will explore some latest findings obtained using these satellites that shed light on how neutron galaxies are created and evolve within low - weight binary complexes .We will also discuss our latest understanding of the physics behind the formation of relativistic jets discovered in multiple types of X - ray binaries . Finally , we will briefly outline the possibilities offered by future flights like XEUS or Constellation - X for studying these fascinating sources .Keywords : Accretion wheel - Compact object - Relativistic jet - X - ray binary",
        "rewrite_text": "The discovery of the first X-ray pulsar, Scorpius X-1 (Sco-X1), by Giacconi et al. in 1962 marked the beginning of an exciting new frontier in astrophysics and led to the formulation of key concepts such as accretion disks surrounding compact objects. The launch of the Chandra and XMM-Newton observatories has transformed the study of these systems, allowing us to investigate their physical properties with unprecedented spatial resolution. In this review, we will discuss some of the recent findings from these satellites, which illuminate the formation and evolution of neutron stars within low-mass binary systems. We will also examine our current understanding of the physics underlying the creation of relativistic jets observed in various types of X-ray binaries. Finally, we will briefly highlight the potential advancements in research that future missions like XEUS and Constellation-X may offer for studying these intriguing astrophysical sources. Keywords: Accretion disk, compact object, relativistic jet, X-ray binary.",
        "ori-fast-z-score": 0.48507125007266594,
        "water-fast-z-score": 5.2532861073211246,
        "rewrite-fast-z-score": 0.7071067811865476
    },
    {
        "original_text": "We report on the detection and characterization of two new classes of radio sources in nearby star-forming regions, which we identify as candidate young stellar objects (YSOs). The first class consists of compact radio sources with flat or inverted spectral indices that are associated with infrared dark clouds (IRDCs); these may be either deeply embedded YSOs or free-free absorbed H II regions. The second class is comprised of extended radio sources with steep spectra that appear to be physically related to IRDCs; these could represent ionized outflows driven by massive protostellar jets. We also present evidence suggesting that some of our candidates are likely to be magnetically active stars. These results demonstrate how VLBI observations can be used to search for and characterize protostars at very early stages of their evolution. \n \n Keywords: Radio astronomy, Young stellar object, Infrared dark cloud, Magnetar, Coronal mass ejection",
        "watermark_text": "We report on the discovery and identification of two new classes of radio sources in nearby star - creating areas , which we identify as candidate young stellar bodies ( YSOs ) . The first class consists of compact radio sources with flat or inverted spectral indices that are identified with infrared darkness clouds ( IRDCs ) ; these may be either strongly buried YSOs or free - free absorbed H II regions .The second class is comprised of extended radio sources with steep spectra that appear to be physically connected to IRDCs ; these could indicate ionized outflows driven by massive protostellar jets . We additionally offer evidence indicating that some of our candidates are likely to be magnetically active stars .These data demonstrate how VLBI surveys can be used to search for and characterize protostars at very earliest steps of their evolved . Keywords : Radio astronomy , Young stellar object , Infrared black dust , Magnetar , Coronal weight ejection",
        "rewrite_text": "We present our findings on the discovery and identification of two new classes of radio sources in nearby star-forming regions, which we propose as candidate young stellar objects (YSOs). The first class features compact radio sources with flat or inverted spectral indices that are associated with infrared dark clouds (IRDCs); these may represent either deeply embedded YSOs or H II regions that are subject to free-free absorption. The second class consists of extended radio sources with steep spectral indices that appear to be physically linked to IRDCs, potentially indicating ionized outflows driven by massive protostellar jets. Furthermore, we provide evidence suggesting that some of our candidates are likely magnetically active stars. This research highlights the potential of VLBI surveys to search for and analyze protostars in the earliest stages of their evolution. Keywords: Radio Astronomy, Young Stellar Object, Infrared Dark Clouds, Magnetar, Coronal Mass Ejection.",
        "ori-fast-z-score": -0.11704114719613057,
        "water-fast-z-score": 4.649905549752772,
        "rewrite-fast-z-score": 0.3511234415883917
    },
    {
        "original_text": "We report on our analysis of archival Chandra data for the galaxy cluster Sersic 159-03, which shows evidence for excess X-ray emission below 1 keV (the  soft-excess ). We find that this feature is not consistent with thermal bremsstrahlung or line emission associated with any known atomic species and conclude it must be due to some other process such as inverse Compton scattering by relativistic electrons. The observed spectrum can be fitted well using an absorbed power-law model plus a blackbody component at kT = 0.2 keV; however we show that this fit is statistically unacceptable when compared against more physically motivated models including a combination of Bremsstrahlung and inverse-Compton emission. In particular, we demonstrate that the inclusion of a second blackbody component improves the quality of the fits significantly over those obtained previously.  Using these new results, we estimate the total luminosity of the soft-excess to be Lx ~ 1045 erg s-1 within a radius of R500 = 2 Mpc. This value is comparable to the bolometric luminosities inferred for several nearby radio halos detected via their synchrotron emission.",
        "watermark_text": "We report on our analysis of archival Chandra data for the galaxy region Sersic 159 - 03 , which reveals proof for excess X - ray radiation below 1 keV ( the dark - excess ) . We see that this characteristic is not consistent with thermal bremsstrahlung or line emission associated with any observed atomic species and assume it must be due to some other mechanism such as inverse Compton absorption by relativistic electrons .The observed spectrum can be fitted well using an absorbed power - law model plus a blackbody component at kT = 0 . 2 keV ; however we show that this fit is statistically unacceptable when compared against more physically motivated models including a combination of Bremsstrahlung and inverse - Compton emission . In particular , we demonstrate that the inclusion of a second blackbody component improves the quality of the fits significantly over those obtained previously .Using these new data , we estimate the total luminosity of the soft - excess to be Lx ~ 1045 erg s - 1 within a diameter of R500 = 2 Mpc . This value is analogous to the bolometric luminosities inferred for numerous nearby radio halos detected via their synchrotron emission .",
        "rewrite_text": "We present our analysis of archival Chandra data for the galaxy region Sersic 159-03, which indicates an excess of X-ray radiation below 1 keV, referred to as the dark excess. This feature does not align with thermal bremsstrahlung or line emissions from any observed atomic species, leading us to hypothesize that it arises from a different mechanism, potentially inverse Compton scattering involving relativistic electrons. The observed spectrum can be well-fitted with an absorbed power-law model along with a blackbody component at kT = 0.2 keV; however, this fitting is statistically inadequate when compared to more physically grounded models that include a mix of bremsstrahlung and inverse-Compton emission. Notably, we show that adding a second blackbody component significantly enhances the quality of the fits compared to previous models. Using this new data, we estimate the total luminosity of the soft excess to be Lx ~ 10^45 erg s^-1 within a radius of R500 = 2 Mpc, which is comparable to the bolometric luminosities derived for several nearby radio halos identified through their synchrotron emissions.",
        "ori-fast-z-score": -1.9629909152447274,
        "water-fast-z-score": 1.835325870964494,
        "rewrite-fast-z-score": -0.47140452079103173
    },
    {
        "original_text": "We present an orbital stability study for the 14 planet system discovered by HATNet and Kepler space telescopes around the star HD 10180 (HIP 108427). We use numerical integrations to show that this system is dynamically stable over timescales longer than its age, which we estimate at 4 Gyrs using gyrochronology. The planets are found in two resonant chains with period ratios close to 2:1 and 3:2 respectively. These chains are connected through a chain of mean motion resonances between adjacent pairs of planets. This structure suggests that the system has been sculpted by convergent migration followed by tidal dissipation within each planet s envelope. \n \n Keywords: Planetary systems - Stability - Mean-motion resonance - Convergent migration - Tides - Gyrochronology - HD10180 - Kepler telescope - HATNet telescope - Orbital dynamics - Dynamical evolution",
        "watermark_text": "We present an orbital stability study for the 14 planet system discovered by HATNet and Kepler space telescopes around the star HD 10180 ( HIP 108427 ) . We use numerical integrations to see that this system is dynamically stable over timescales greater than its age , which we estimate at 4 Gyrs using gyrochronology .The planets are found in two resonant chains with time proportions close to 2 : 1 and 3 : 2 respectively . These chains are connected through a network of mean motion resonances between neighboring pairs of planets .This structure implies that the system has been sculpted by convergent displacement preceded by tidal dissipation within each planet s envelope . Keywords : Planetary systems - Stability - Mean - movement resonance - Convergent migration - Tides - Gyrochronology - HD10180 - Kepler observatory - HATNet telescope - Orbital dynamics - Dynamical evolution",
        "rewrite_text": "We conduct an orbital stability analysis of the 14-planet system identified by the HATNet and Kepler space telescopes orbiting the star HD 10180 (HIP 108427). Using numerical simulations, we demonstrate that this system remains dynamically stable over timescales that exceed its estimated age of 4 billion years, as determined through gyrochronology. The planets are organized into two resonant chains with approximate ratios of 2:1 and 3:2. These chains are interconnected by a series of mean motion resonances among neighboring planet pairs. This configuration suggests that the system has been shaped by convergent migration, which was preceded by tidal dissipation within the envelopes of the planets. \n\nKeywords: Planetary systems, Stability, Mean motion resonance, Convergent migration, Tidal effects, Gyrochronology, HD 10180, Kepler Observatory, HATNet Telescope, Orbital dynamics, Dynamical evolution.",
        "ori-fast-z-score": 0.14285714285714285,
        "water-fast-z-score": 3.0,
        "rewrite-fast-z-score": 0.4375949744936837
    },
    {
        "original_text": "We present the results of our study on the possible existence and stability of terrestrial planets around the star Gliese 581, which is located at about 20 light-years away from Earth. We have performed numerical simulations for different orbital configurations of three hypothetical terrestrial planets with masses ranging between 1 to 10 times that of Earth s mass (1-10 M⊕). Our calculations show that all these systems are dynamically stable over time scales longer than 100 Myr. The most massive planet has an eccentric orbit with e=0.2 and its periastron distance ranges between 0.05 AU and 0.15 AU depending on the initial conditions used. This planet can be considered as a hot Jupiter-like planet because it orbits very close to its host star. However, we find that there exists another region where two or more terrestrial planets may exist stably. In this region, one of them could be a super-Earth-type planet with a mass larger than 5M⊕ but smaller than 8M⊕.",
        "watermark_text": "We present the conclusion of our research on the possible existence and dynamics of terrestrial worlds around the star Gliese 581 , which is situated at about 20 light - years distance from Earth . We have done mathematical simulations for different orbital arrangements of three hypothetical terrestrial worlds with masses differing between 1 to 10 twice that of Earth s mass ( 1 - 10 M⊕ ) .Our calculations show that all these systems are dynamically stable over time ranges longer than 100 Myr . The most large planet has an eccentric orbit with e = 0 . 2 and its periastron speed ranges between 0 . 05 AU and 0 . 15 AU depending on the early conditions utilized .This planet can be regarded as a bright Jupiter - like planet because it orbits very close to its host star . However , we find that there exists another region where two or more terrestrial worlds may arise stably .In this area , one of them could be a super - Earth - class planet with a mass greater than 5M⊕ but smaller than 8M⊕ .",
        "rewrite_text": "We conclude our research on the potential existence and dynamics of terrestrial planets around the star Gliese 581, located approximately 20 light-years from Earth. Our mathematical simulations explored various orbital configurations for three hypothetical terrestrial planets with masses ranging from 1 to 10 times that of Earth (1 - 10 M⊕). The results indicate that all these systems maintain dynamic stability over timescales exceeding 100 million years. The largest of these hypothetical planets features an eccentric orbit with an eccentricity of e = 0.2, and its periastron speed varies between 0.05 AU and 0.15 AU, depending on the initial conditions considered. This planet can be likened to a bright, Jupiter-like body due to its close proximity to its host star. Additionally, we identified another region where two or more terrestrial planets could coexist stably, and within this region, one of the planets could potentially be a super-Earth with a mass between 5 M⊕ and 8 M⊕.",
        "ori-fast-z-score": -1.3438638879193574,
        "water-fast-z-score": 4.185110693297313,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We report on the experimental demonstration of frequency upshift in two colliding laser pulses using a relativistically flying mirror (RFM). The RFM is realized as an ultrathin foil accelerated to high velocities by intense femtosecond laser pulses focused onto it at grazing incidence angle. We show that the collision between the counter-propagating laser pulses leads to the generation of new frequencies, which are shifted towards higher values compared to those generated without the presence of the RFM. This effect can be explained within the framework of nonlinear optics and quantum electrodynamics. Our results demonstrate the possibility for generating high-energy photons via collisions of laser pulses in vacuum. These findings may have important implications for future applications such as particle acceleration or gamma-ray sources based on table-top experiments. \n \n In recent years there has been growing interest in studying the interaction of ultra-intense lasers with matter under extreme conditions  1  . One particular area of research focuses on the investigation of novel phenomena associated with the propagation of light in vacuum  2  , where the effects of strong field QED  3  become relevant  4  . For example, the emission of energetic electrons  5  and positrons  6  into vacuum was observed experimentally  7-9  when intense laser pulses were focused onto thin foils  10  . Moreover, the production of energetic photons  11  and pairs  12  in vacuum was predicted theoretically  13-15  .\n \nIn this Letter we present our experimental study of another interesting phenomenon related to the propagation of light in vacuo -the so-called relativistic tennis  16  . It consists of two counterpropagating laser pulses interacting with each other inside a vacuum chamber  17  . When these pulses collide they generate new frequencies  18  , which are shifted towards higher energies  19  . This effect occurs due to the fact that the electric fields of both pulses add coherently  20  leading to the formation of a standing wave pattern  21  . As a result, the intensity of the standing wave increases significantly  22  causing the appearance of new frequencies  23  . \n \n Here we report on the first experimental observation of the relativistic tennis effect  24  . To achieve this goal, we used a relativistically flying mirror  25  , which",
        "watermark_text": "We report on the empirical demonstration of rate upshift in two colliding laser pulses using a relativistically flying reflection ( RFM ) . The RFM is realized as an ultrathin foil enhanced to large velocities by intense femtosecond laser pulses focused onto it at grazing incidence angle .We see that the interaction between the counter - propagating optical pulses gives to the generation of new frequencies , which are shifted towards higher values compared to those generated without the presence of the RFM . This phenomenon can be described within the framework of nonlinear optics and quantum electrodynamics .Our results show the idea for generating high - energy photons via collisions of laser pulses in vacuum . These studies might have important implications for future applications such as particle gravity or gamma - ray sources based on table - top research .In recent years there has been growing interest in investigating the interaction of ultra - intense lasers with matter under extreme circumstances 1 . One particular area of research focuses on the exploration of new events associated with the propagation of light in vacuum 2 , where the effects of bright force QED 3 become relevant 4 .For instance , the emission of active electrons 5 and positrons 6 into vacuum was seen experimentally 7 - 9 when strong laser pulses were focused onto thin foils 10 . Moreover , the production of energetic photons 11 and pairs 12 in vacuum was anticipated theoretically 13 - 15 .In this Letter we present our experimental discussion of another important process related to the propagation of light in vacuo - the so - called relativistic tennis 16 . It consists of two counterpropagating light beams interacting with each other inside a vacuum chamber 17 .When these pulses collide they generate additional frequencies 18 , which are shifted towards higher energies 19 . This phenomenon occurs due to the fact that the electric forces of both pulses add coherently 20 resulting to the formation of a standing wave pattern 21 .As a result , the strength of the running wave increases substantially 22 resulting the appearance of new frequencies 23 . Here we note on the first experimental measurement of the relativistic tennis phenomenon 24 .To achieve this goal , we using a relativistically flying reflection 25 , which",
        "rewrite_text": "We present an empirical demonstration of a rate upshift in two colliding laser pulses, utilizing a relativistically flying mirror (RFM). This RFM is created using an ultrathin foil, propelled to high velocities by intense femtosecond laser pulses that are focused onto it at a grazing incidence angle. Our observations indicate that the interaction between the counter-propagating optical pulses leads to the generation of new frequencies, which are shifted to higher values compared to those produced in the absence of the RFM. This phenomenon can be explained through the principles of nonlinear optics and quantum electrodynamics. Our findings suggest a potential method for generating high-energy photons through the collision of laser pulses in a vacuum, which could have significant implications for future applications, such as tabletop particle gravity experiments or gamma-ray sources. \n\nIn recent years, interest has surged in studying how ultra-intense lasers interact with matter under extreme conditions. One particular research area explores the new phenomena associated with light propagation in a vacuum, where the effects of quantum electrodynamics (QED) become significant. For example, the experimental observation of active electron and positron emission into a vacuum has been reported when powerful laser pulses were directed onto thin foils. Additionally, the theoretical anticipation of energetic photon and pair production in a vacuum has been well-documented. In this letter, we discuss our experimental investigation of an important process related to light propagation in vacuum known as \"relativistic tennis.\" This process involves two counter-propagating light beams interacting within a vacuum chamber. Upon colliding, these pulses generate additional frequencies that are shifted to higher energies. This occurs because the electric fields of both pulses coherently combine, leading to the formation of a standing wave pattern. Consequently, the intensity of the resultant wave increases significantly, resulting in the emergence of new frequencies. We highlight our first experimental measurement of the relativistic tennis phenomenon. To achieve this, we employ a relativistically flying reflection setup.",
        "ori-fast-z-score": 0.8563488385776753,
        "water-fast-z-score": 7.96486185631891,
        "rewrite-fast-z-score": 1.8627612616951987
    },
    {
        "original_text": "We introduce the concept of generalized conditional random fields (GCRFs) and show how they can be used to model arbitrary probability distributions over structured data sets, such as sequences or trees.  We present an efficient algorithm for learning GCRF parameters using gradient descent on the log-likelihood objective function.   Finally we demonstrate that our approach is able to learn accurate models for several challenging sequence labeling tasks including part-of-speech tagging in natural language processing and protein secondary structure prediction in bioinformatics. Conditional Random Fields (CRFs) (Lafferty et al., 2001 ) are undirected graphical models which have been successfully applied to many problems involving sequential data, e.g. (Sha & Pereira, 2003) . In this work, we propose Generalized Conditional Random Fields (GCRFs), a generalization of CRFs which allows us to represent any distribution over structured data sets like sequences or trees. The key idea behind GCRFs is to use a set of latent variables to capture dependencies between different parts of the input space. This enables us to efficiently compute the partition function required by standard CRFs with dynamic programming techniques. Furthermore, it also makes it possible to train GCRFs using gradient-based methods similar to those employed for Maximum Entropy Markov Models (MEMMs). To evaluate the performance of our method, we apply it to two important applications: part-of-speech taggin",
        "watermark_text": "We introduce the idea of generalized conditional random fields ( GCRFs ) and explain how they can be used to model arbitrary likelihood distributions over structured data sets , such as sequences or trees . We introduce an efficient algorithm for learning GCRF variables using gradient descent on the log - likelihood objective function .Finally we prove that our approach is ability to acquire precise models for numerous challenging gene labeling challenges including whole - of - voice tagging in natural language processing and protein secondary structure prediction in bioinformatics . Conditional Random Fields ( CRFs ) ( Lafferty et al . , 2001 ) are undirected numerical models which have been successfully applied to many difficulties involving sequential data , e . g .( Sha & Pereira , 2003 ) . In this research , we propose Generalized Conditional Random Fields ( GCRFs ) , a generalization of CRFs which allows us to model any distribution over structured data sets like sequences or trees .The main idea behind GCRFs is to use a setting of latent variables to capture dependencies between various parts of the input space . This enables us to easily compute the partition function required by traditional CRFs with dynamic programming tools .Furthermore , it also makes it able to train GCRFs using gradient - based methods similar to those utilized for Maximum Entropy Markov Models ( MEMMs ) . To assess the performance of our technique , we apply it to two essential applications : whole - of - voice taggin",
        "rewrite_text": "We present the concept of Generalized Conditional Random Fields (GCRFs) and demonstrate their capability to model arbitrary likelihood distributions over structured data sets, such as sequences and trees. We also introduce an efficient algorithm for learning GCRF variables employing gradient descent based on the log-likelihood objective function. In addition, we provide proof that our method effectively develops accurate models for several challenging tasks, including whole-of-voice tagging in natural language processing and protein secondary structure prediction in bioinformatics. Conditional Random Fields (CRFs), as introduced by Lafferty et al. (2001), are undirected graphical models that have proven effective for various sequential data problems, as noted by Sha and Pereira (2003). In this study, we propose GCRFs as a generalization of CRFs, enabling the modeling of any distribution over structured datasets, including sequences and trees. The core concept of GCRFs involves utilizing latent variables to capture dependencies among different components of the input space. This approach facilitates the computation of the partition function required by traditional CRFs through dynamic programming techniques. Moreover, it allows for the training of GCRFs using gradient-based methods akin to those employed for Maximum Entropy Markov Models (MEMMs). To evaluate the effectiveness of our method, we apply it to two significant applications: whole-of-voice tagging and others.",
        "ori-fast-z-score": -0.4833682445228318,
        "water-fast-z-score": 6.735753140545634,
        "rewrite-fast-z-score": 1.6915632233569815
    },
    {
        "original_text": "The purpose of this study is to investigate how privacy issues are perceived by users in Europe and what their attitude towards these issues is, when using online learning environments (OLE). The research questions are: \nWhat do students think about privacy?\nHow does student s perception change over time?\nWhich factors influence students  attitudes on privacy? How can we measure it? What are the implications for OLE developers? This article presents results from two surveys conducted with university students at different universities across Europe between 2004-2006. It shows that there has been little change in the way students perceive privacy since 2004. Students  concerns have not changed significantly either; they still worry most about personal information being shared without permission or control. However, some differences were found among countries. In addition, the findings show that gender plays a role as well as age. Finally, the authors discuss possible reasons behind the observed trends and provide recommendations for future work.",
        "watermark_text": "The purpose of this study is to examine how privacy issues are seen by users in Europe and what their attitude towards these problems is , when using internet learning habitats ( OLE ) . The survey problems are : What do students think about privacy ?How does student s perception shift over time ? Which variables influence pupils beliefs on privacy ?How can we measure it?What are the implications for OLE developers?This page presents scores from two polls conducted with university students at different schools across Europe between 2004 - 2006 . It demonstrates that there has been less shift in the way pupils understand privacy since 2004 .Students issues have not altered significantly either ; they still concern most about personal data being communicated without authorization or supervision . However , some differences were found among countries .In addition , the discoveries reveal that gender plays a role as well as aging . Finally , the articles discuss possible reasons behind the reported developments and include recommendations for future projects .",
        "rewrite_text": "This study aims to explore how users in Europe perceive privacy issues and their attitudes toward these challenges in online learning environments (OLE). The key questions addressed in the research include: What are students' views on privacy? How do perceptions of privacy evolve over time? What factors influence students' beliefs about privacy? How can these beliefs be effectively measured? What are the implications for developers of online learning environments? This report presents findings from two surveys conducted with university students across various European institutions between 2004 and 2006. The results indicate that there has been little change in students' understanding of privacy since 2004, and their concerns remain largely the same, primarily revolving around unauthorized or unmonitored sharing of personal data. However, some differences were observed between countries. Additionally, the findings suggest that both gender and age play a significant role in shaping these perceptions. Lastly, the report discusses potential reasons for the trends observed and offers recommendations for future initiatives.",
        "ori-fast-z-score": -0.22360679774997896,
        "water-fast-z-score": 7.9881240965747695,
        "rewrite-fast-z-score": -1.3251783128981585
    },
    {
        "original_text": "We study the entanglement properties of two qubits coupled by an antisymmetric anisotropic exchange interaction (AAEI) in a magnetic chain described by the Heisenberg model on the square lattice. We show that for certain values of the parameters, this system can be mapped onto a spin-1/2 XYZ chain and we calculate analytically its concurrence as well as the von Neumann entropy. The results are compared to those obtained numerically using exact diagonalization techniques. In particular, it is shown that the AAEI leads to a significant increase of the concurrence between nearest-neighboring spins when compared to the standard XXZ case. Moreover, we find that there exists a critical value of the anisotropy parameter beyond which no entanglement survives. Finally, we discuss how our findings could be tested experimentally. Introduction:-Entangled states play a crucial role in quantum information processing  1  . Therefore, understanding their generation mechanisms has been one of the main goals of many theoretical investigations  2  -  4  .\nIn recent years, much attention was paid to the investigation of entanglement in various types of spin chains  5  , including the so-called XXZ chain  6 -  8  . However, most studies were focused only on the ground state  9  or low lying excited states  10  of these systems. On the other hand, recently developed experimental techniques allow us to prepare highly excited states  11  . Thus, it becomes important to investigate also higher energy levels  12  .\nThe aim of this work is to analyze the entanglement properties of a pair of qubits interacting via an antisymmetric anisotropic Heisenberg exchange term  13  . This type of coupling appears naturally in several physical models  14  -  16  . For example, it describes the spin-spin interactions in molecular magnets  17  where the total angular momentum J = 0  18  . It should be noted here that such molecules have attracted considerable interest due to their potential applications in quantum computing  19  . Another interesting application concerns the description of excitations in high-Tc superconductors  20  . Here, the presence of the antisymmetric anisotropic exchange term may lead to new phenomena  21  .",
        "watermark_text": "We research the entanglement properties of two qubits coupled by an antisymmetric anisotropic exchange interaction ( AAEI ) in a magnetic chain described by the Heisenberg model on the square lattice . We see that for specific values of the variables , this system can be mapped onto a spin - 1 / 2 XYZ chain and we estimate analytically its concurrence as well as the von Neumann entropy .The results are compared to those achieved numerically utilizing exact diagonalization techniques . In particular , it is demonstrated that the AAEI contributes to a substantial improvement of the concurrence between nearest - neighboring spins when compared to the standard XXZ case .Moreover , we find that there exists a critical quantity of the anisotropy parameter beyond which no entanglement survives . Finally , we explain how our findings may be evaluated experimentally .Introduction : - Entangled states play a crucial role in quantum information processing 1 . Therefore , studying their generation pathways has been one of the main goals of several theoretical investigations 2 - 4 .In past decades , much attention was given to the investigation of entanglement in different kinds of spin rings 5 , notably the so - called XXZ ring 6 - 8 . However , most studies were focused only on the ground state 9 or low lying excited states 10 of these systems .On the other hand , recently advanced experimental methods able us to examine highly excited states 11 . Thus , it becomes crucial to examine also greater energy levels 12 .The goal of this research is to analyze the entanglement properties of a pair of qubits interacting via an antisymmetric anisotropic Heisenberg transfer term 13 . This kind of coupling appears naturally in different physical models 14 - 16 .For instance , it explains the spin - spinning interactions in molecular magnets 17 where the total angular velocity J = 0 18 . It should be mentioned here that such compounds have garnered considerable interest due to their potential applications in quantum computing 19 .Another important use involves the description of excitations in high - Tc superconductors 20 . Here , the presence of the antisymmetric anisotropic exchange term may contribute to novel concepts 21 .",
        "rewrite_text": "We investigate the entanglement properties of two qubits connected through an antisymmetric anisotropic exchange interaction (AAEI) within a magnetic chain modeled by the Heisenberg framework on a square lattice. Our analysis reveals that under certain conditions, this system can be effectively represented as a spin-1/2 XYZ chain, allowing us to derive analytical estimates of its concurrence and von Neumann entropy. These findings are then compared with numerical results obtained via exact diagonalization techniques. Notably, we demonstrate that the AAEI significantly enhances the concurrence among nearest-neighbor spins compared to the conventional XXZ model. Furthermore, we identify a critical value of the anisotropy parameter, beyond which entanglement is lost. We also discuss the ways in which our results could be experimentally tested.\n\n**Introduction:** Entangled states are essential for quantum information processing, making their generation pathways a key focus of numerous theoretical studies. In recent years, considerable attention has been directed toward the exploration of entanglement in various types of spin rings, particularly the XXZ ring. However, much of the previous research has concentrated on the ground state or low-lying excited states of these systems. With advancements in experimental techniques, we are now able to investigate highly excited states, which necessitates a broader examination of energy levels. This study aims to analyze the entanglement properties of a pair of qubits interacting through an antisymmetric anisotropic Heisenberg transfer term, a coupling that naturally arises in various physical models. For example, it accounts for spin-spin interactions in molecular magnets where the total angular momentum J = 0. Such compounds have drawn significant interest due to their potential applications in quantum computing. Additionally, this antisymmetric anisotropic exchange term could provide insights into excitations in high-temperature superconductors, leading to novel concepts in this field.",
        "ori-fast-z-score": 0.3223291856101521,
        "water-fast-z-score": 7.897065047448726,
        "rewrite-fast-z-score": 1.4216114170120542
    },
    {
        "original_text": "In this work, we propose the subjective information measure (SIM) to quantify the amount of information in an image or video sequence. The SIM is defined as the minimum number of bits required for lossless coding of the source data under some fidelity criterion. We show that the proposed SIM can be used to derive rate-distortion functions with high accuracy by using only one parameter. In addition, it also provides accurate prediction on ratedistortion performance at low bit rates. Finally, we demonstrate its effectiveness through experiments conducted on several test sequences. Index Terms -Information theory, Image compression, Video compression. 1 Introduction Data compression has been widely studied over past decades due to its importance in many applications such as digital storage systems, communication networks, medical imaging, etc.. A fundamental problem in data compression is how to accurately predict the compressed file size given the original uncompressed data. This problem is usually referred to as rate-distortion analysis  1  . It is well known that the rate-distortion function characterizes the relationship between the average codeword length and distortion level achieved by any optimal encoding scheme  2  .\nThe most commonly adopted approach to solve the rateconstraint optimization problems is Lagrangian relaxation  3  , which transforms constrained optimization into unconstrained ones via introducing additional variables called Lagrange multipliers  4  . However, solving these problems requires iterative algorithms  5  , which are computationally expensive  6  . To overcome this difficulty, researchers have developed various fast algorithms  7, 8  . Nevertheless, they still suffer from slow convergence speed when applied to practical problems  9  .",
        "watermark_text": "In this research , we develop the subjective information measure ( SIM ) to quantify the quantity of information in an image or image sequence . The SIM is calculated as the minimum amount of bits required for lossless coding of the input data under some fidelity criterion .We see that the suggested SIM can be used to derive rate - noise values with high clarity by using only one parameter . In addition , it also provides reliable prediction on ratedistortion behavior at low bit rates .Finally , we prove its effectiveness through experiments conducted on numerous test sequences . Index Terms - Information theory , Image compression , Video compression .1 Introduction Data compression has been widely research over past decades owing to its significance in multiple applications such as electronic storage systems , transport networks , medical imaging , etc . . A crucial problem in data encoding is how to correctly forecast the compressed file size given the actual uncompressed information . This problem is usually referred to as rate - degradation analysis 1 .It is well established that the rate - degradation relation characterizes the relationship between the average codeword height and distortion height accomplished by any optimal encoding scheme 2 . The most commonly implemented way to solve the rateconstraint optimization problems is Lagrangian relaxation 3 , which transforms constrained optimization into unconstrained ones via introducing additional parameters named Lagrange multipliers 4 .However , solving these problems demands iterative techniques 5 , which are computationally expensive 6 . To solve this challenge , researchers have developed various quick schemes 7 , 8 .Nevertheless , they still suffer from slow convergence speed when applied to practical difficulties 9 .",
        "rewrite_text": "In this study, we introduce the Subjective Information Measure (SIM) to quantify the amount of information present in an image or a sequence of images. The SIM is determined as the minimum bits necessary for lossless encoding of the input data while adhering to a specified fidelity criterion. We demonstrate that the proposed SIM allows for the derivation of rate-noise values with high precision using only one parameter. Furthermore, it provides a reliable prediction of rate-distortion behavior at low bit rates. We validate its effectiveness through experiments conducted on a variety of test sequences. \n\nIndex Terms - Information Theory, Image Compression, Video Compression.\n\n1. Introduction\n\nData compression has been extensively researched over the past few decades due to its importance in various applications, such as electronic storage systems, transport networks, and medical imaging. A significant challenge in data encoding is accurately estimating the size of the compressed file based on the actual uncompressed data. This issue is commonly referred to as rate-degradation analysis. It is well established that the rate-degradation relationship characterizes how the average codeword length corresponds to the distortion level achieved by any optimal encoding strategy. The most widely used approach to addressing rate-constrained optimization problems is Lagrangian relaxation, which transforms constrained optimization into unconstrained problems by introducing additional parameters known as Lagrange multipliers. However, solving these issues requires iterative methods, which can be computationally intensive. To tackle this challenge, researchers have proposed various fast algorithms. Nevertheless, these approaches often face challenges with slow convergence when applied to real-world problems.",
        "ori-fast-z-score": -0.17407765595569785,
        "water-fast-z-score": 7.659900395832447,
        "rewrite-fast-z-score": 1.0606601717798212
    },
    {
        "original_text": "We report on observations made in March and April 2002 at 345 GHz using the Atacama Submillimiter Telescope Experiment (ASTE). We detected no significant emission associated with the host galaxy of the gamma-ray burst GRB 980425, which was discovered by BeppoSAX on Apr. 25, 1998 . The 3 sigma upper limit to the flux density is < 0.5 Jy beam-1 , corresponding to an integrated line intensity ICO< 1 x 10^9 K km s^-1 pc^2 or Mgas < 2 x 10^8 Msun .\nThe non-detection suggests that either the molecular gas mass is much lower than previously estimated or that it has been destroyed by the intense UV radiation field produced during the burst.  These results are consistent with those obtained recently by other groups who have searched for CO emission from this source. If our result can be confirmed then it will provide important constraints on models of the formation of massive stars.",
        "watermark_text": "We report on observations made in March and April 2002 at 345 GHz use the Atacama Submillimiter Telescope Experiment ( ASTE ) . We observed no major radiation associated with the target galaxy of the gamma - ray burst GRB 980425 , which was discovered by BeppoSAX on Apr .25 , 1998 . The 3 sigma higher limit to the flux concentration is < 0 . 5 Jy beam - 1 , equivalent to an integrated line intensity ICO < 1 x 10 ^ 9 K km s ^ - 1 pc ^ 2 or Mgas < 2 x 10 ^ 8 Msun .The non - discovery suggests that either the molecular gas mass is much lower than previously predicted or that it has been destroyed by the strong UV rays field produced during the explosion . These data are compatible with those acquired previously by other groups who have searched for CO radiation from this source .If our outcome can be verified then it will provide important restrictions on estimates of the formation of large stars .",
        "rewrite_text": "We present observations conducted in March and April 2002 at a frequency of 345 GHz using the Atacama Submillimeter Telescope Experiment (ASTE). Our findings indicated no significant radiation linked to the target galaxy of the gamma-ray burst GRB 980425, which was detected by BeppoSAX on April 25, 1998. The upper limit for the flux density is < 0.5 Jy beam⁻¹, which corresponds to an integrated line intensity ICO < 1 x 10⁹ K km s⁻¹ pc² or a molecular gas mass Mgas < 2 x 10⁸ Msun. This lack of detection suggests that the molecular gas mass may be considerably lower than earlier estimates or that it has been depleted by the intense UV radiation generated during the explosion. These results align with data previously obtained by other teams that have searched for CO emissions from this source. If our findings are confirmed, they could impose significant constraints on theories regarding the formation of massive stars.",
        "ori-fast-z-score": -1.9867985355975657,
        "water-fast-z-score": 4.106050306901635,
        "rewrite-fast-z-score": -2.0
    },
    {
        "original_text": "We present results on nonleptonic two-body decays of heavy quarks into light hadrons, with an emphasis on the role played by axial vector mesons in these processes.  We use the framework of Heavy Quark Effective Theory (HQET) and its extension to include higher order corrections in inverse powers of the b-quark mass. The latter are calculated using the method developed recently for the calculation of radiative corrections within HQET. In particular we study the decay amplitudes for the following processes:  B→Dπ, Dρ, Dω; B→K*π, K*ρ, K*ω; B→Kπ, Kη′, Kη′′; B→ππ, πη, πη′. \nThe main result is that the inclusion of the effects due to the exchange of one or more soft gluons between the initial and final states leads to significant changes in the values of the decay rates as compared to those obtained previously without such contributions included.",
        "watermark_text": "We report findings on nonleptonic two - bodies decays of light quarks into light hadrons , with an emphasis on the part played by axial vector mesons in these reactions . We use the framework of Heavy Quark Effective Theory ( HQET ) and its extension to use larger order corrections in inverse powers of the b - quark mass .The latter are measured using the method developed lately for the determination of radiative corrections within HQET . In particular we study the decay amplitudes for the following processes : B→Dπ , Dρ , Dω ; B→K * π , K * ρ , K * ω ; B→Kπ , Kη ′ , Kη ′ ′ ; B→ππ , πη , πη ′ .The main consequence is that the introduction of the effects due to the transfer of one or more soft gluons between the first and final states gives to significant improvements in the values of the decay rates as compared to those acquired previously without such contributions added .",
        "rewrite_text": "We present findings on nonleptonic two-body decays of light quarks into light hadrons, focusing on the role of axial vector mesons in these processes. Our analysis is based on the framework of Heavy Quark Effective Theory (HQET) and its extensions, which account for higher-order corrections in inverse powers of the b-quark mass. These higher-order effects are assessed using a recently developed method for determining radiative corrections within HQET. Specifically, we investigate the decay amplitudes for several processes, including B→Dπ, Dρ, Dω; B→K*π, K*ρ, K*ω; B→Kπ, Kη′, Kη′′; and B→ππ, πη, πη′. A key outcome of our study is that incorporating the effects of one or more soft gluons exchanged between the initial and final states leads to significant enhancements in the decay rates compared to previous estimates that did not consider these contributions.",
        "ori-fast-z-score": 0.13736056394868904,
        "water-fast-z-score": 4.807619738204116,
        "rewrite-fast-z-score": -1.632993161855452
    },
    {
        "original_text": "We study the effect of Rashba spin-orbit interaction on the spin Hall conductivity (SHC) for an interacting two-dimensional electron system with parabolic dispersion and Zeeman splitting in presence of a uniform external magnetic field applied normal to the plane of motion. We show that SHC is independent of temperature, chemical potential and strength of disorder provided the Fermi energy lies within the Zeeman gap. The results are obtained by using the Kubo formula combined with the self-consistent Born approximation. It has been shown recently that the spin current can be generated without any net charge flow when electrons move through a nonmagnetic material under the influence of spin-orbit coupling  1  . This phenomenon known as spin Hall effect was first predicted theoretically  2  , and later observed experimentally  3  .\nThe origin of this effect is due to the fact that the spin-orbit interaction causes a transverse force which deflects the trajectories of moving particles leading to a finite spin polarization at the edges  4  . In recent years there have been several theoretical studies devoted to understand various aspects of spin Hall effect  5  -  8  . However most of these works were done either in absence or weak magnetic fields where the Landau levels do not play significant role  9  . On the other hand it is well known that the Landau level quantization plays important role in determining many physical properties such as magnetoresistance  10  , optical absorption  11  etc., especially near the quantum limit  12  . Therefore it would be interesting to investigate how the Landau levels affect the spin Hall effect.",
        "watermark_text": "We explore the impact of Rashba spin - orbit interaction on the spin Hall conductivity ( SHC ) for an interacting two - dimensional electron structure with parabolic dispersion and Zeeman splitting in presence of a consistent external magnetic current applied normal to the plane of movement . We see that SHC is independent of temperature , chemical potential and strength of disorder provided the Fermi energy rests within the Zeeman gap .The results are derived by using the Kubo formula coupled with the self - stable Born algorithm . It has been shown lately that the spin current can be formed without any gross charge flow when nuclei move through a nonmagnetic material under the effects of spin - orbit bonding 1 .This phenomenon known as spin Hall phenomenon was first expected theoretically 2 , and later observed experimentally 3 . The origin of this effect is due to the fact that the spin - orbit interaction produces a transverse force which deflects the trajectories of moving particles leading to a finite spin polarization at the edges 4 .In past decades there have been numerous conceptual research devoted to study various parts of spin Hall phenomenon 5 - 8 . However most of these works were done either in absence or strong magnetic fields where the Landau concentrations do not play substantial role 9 .On the other hand it is well established that the Landau level quantization takes key importance in establishing much mechanical parameters such as magnetoresistance 10 , optical reflection 11 etc . , particularly near the quantum limit 12 . Therefore it would be interesting to examine how the Landau concentrations influenced the spin Hall phenomenon .",
        "rewrite_text": "We investigate the influence of Rashba spin-orbit interaction on the spin Hall conductivity (SHC) within an interacting two-dimensional electron system characterized by parabolic dispersion and Zeeman splitting, under the effect of a consistent external magnetic current applied perpendicular to the plane of motion. Our findings indicate that the SHC remains unaffected by temperature, chemical potential, and disorder strength, provided the Fermi energy lies within the Zeeman gap. These results are obtained using the Kubo formula in conjunction with the self-consistent Born approximation. Recent studies have demonstrated that a spin current can be generated without significant charge flow when nuclei navigate through a nonmagnetic material under the influence of spin-orbit coupling. This phenomenon, known as the spin Hall effect, was initially predicted theoretically and later confirmed experimentally. The effect arises because spin-orbit interaction creates a transverse force that alters the paths of moving particles, resulting in a finite spin polarization at the edges. Over the past decades, numerous studies have focused on various aspects of the spin Hall effect. However, most of this research has been conducted either in the absence of magnetic fields or in conditions of strong magnetic fields, where Landau levels do not significantly contribute. Conversely, it is well recognized that Landau level quantization plays a crucial role in determining many physical properties, such as magnetoresistance and optical reflection, particularly near the quantum limit. Therefore, it would be valuable to explore how Landau levels impact the spin Hall effect.",
        "ori-fast-z-score": -0.2683281572999747,
        "water-fast-z-score": 7.723027987151322,
        "rewrite-fast-z-score": 0.3563483225498992
    },
    {
        "original_text": "We study the gravitational field equations for static spherically symmetric configurations on Randall-Sundrum type II brane-worlds with bulk cosmological constant and matter fields localized on the branes. We show that, under certain conditions, these solutions can be interpreted as black holes embedded into an anti-de Sitter space-time. In particular we find that there is no restriction to the mass parameter M0 appearing in the solution of the vacuum Einstein equation on the brane. The corresponding horizon radius r0 satisfies the relation r0 = (3M0/4π)1/3. This result implies that the Schwarzschild-de Sitter metric describes not only black hole but also naked singularity solutions. Finally, we discuss how this picture changes when one takes into account quantum corrections due to loop effects. PACS numbers: 04.20.-q; 11.10.Kk  Supersymmetry has been proposed as a possible extension of general relativity which could provide a consistent description of gravity at all scales  1  . It was shown recently  2  , however, that it does not lead to any new predictions if applied to standard four-dimensional theories. On the other hand, higher dimensional extensions of supergravity have attracted considerable attention during recent years  3  .\nIn this letter we consider five-dimensional supergravities  4  where the extra dimension is compactified on a circle  5  or orbifold  6  . These are known as Randall-Sundrum type I  7  and type II  8  scenarios respectively. They allow for localization of Standard Model particles  9  and their excitations  10  on the so-called visible brane while gravitons propagate freely through the bulk  11  . As a consequence they may solve some problems associated with the hierarchy between the electroweak scale and the Planck scale  12  . Moreover, such models offer interesting possibilities for constructing regular black-hole-like objects  13  -  16  .",
        "watermark_text": "We research the gravitational field equations for static spherically symmetric configurations on Randall - Sundrum type II brane - planets with bulk cosmological constant and material fields confined on the branes . We see that , under certain conditions , these solutions can be interpreted as black holes inserted into an anti - de Sitter space - time .In particular we find that there is no limitation to the mass vector M0 appearing in the solve of the vacuum Einstein integral on the brane . The corresponding horizon radius r0 satisfies the formula r0 = ( 3M0 / 4π ) 1 / 3 .This result suggests that the Schwarzschild - de Sitter metric encompasses not only black hole but also naked singularity solutions . Finally , we explain how this picture changes when one takes into consideration quantum corrections due to loop processes .PACS codes : 04 . 20 . - q ; 11 . 10 . Kk Supersymmetry has been proposed as a possible extension of general relativity which could give a consistent description of gravitational at all scales 1 . It was shown recently 2 , however , that it does not result to any new predictions if applied to standard four - dimensional theories .On the other hand , greater dimensional applications of supergravity have garnered considerable scrutiny during recent years 3 . In this letter we define five - dimensional supergravities 4 where the extra dimension is compactified on a ring 5 or orbifold 6 .These are known as Randall - Sundrum type I 7 and class II 8 scenarios respectively . They allow for localization of Standard Model particles 9 and their excitations 10 on the so - called visible brane while gravitons propagate continuously through the bulk 11 .As a consequence they may solve some problems identified with the ranking between the electroweak scale and the Planck scale 12 . Moreover , such theories offer useful possibilities for constructing ordinary black - hole - like structures 13 - 16 .",
        "rewrite_text": "We investigate the gravitational field equations for static, spherically symmetric configurations on Randall-Sundrum type II brane-planets, which include a bulk cosmological constant and material fields restricted to the branes. Our analysis reveals that, under specific conditions, these solutions can be regarded as black holes embedded within an anti-de Sitter spacetime. Notably, we find that there is no constraint on the mass vector \\( M_0 \\) that appears in the vacuum Einstein equations on the brane. The corresponding horizon radius \\( r_0 \\) is given by the formula \\( r_0 = \\left( \\frac{3M_0}{4\\pi} \\right)^{1/3} \\). This finding implies that the Schwarzschild-de Sitter metric encompasses both black hole and naked singularity solutions. Furthermore, we discuss how this perspective shifts when quantum corrections from loop processes are taken into account. PACS codes: 04.20.-q; 11.10.Kk. Supersymmetry has been suggested as a potential extension of general relativity that could provide a consistent framework for gravitational phenomena across all scales. However, it was recently demonstrated that applying it to standard four-dimensional theories does not yield any new predictions. Conversely, higher-dimensional implementations of supergravity have received significant attention in recent years. In this letter, we introduce five-dimensional supergravities where the extra dimension is compactified on a ring or orbifold. These scenarios, known as Randall-Sundrum type I and type II, respectively, enable the localization of Standard Model particles and their excitations on what is referred to as the visible brane, while gravitons can propagate freely through the bulk. This framework may address the discrepancies between the electroweak and Planck scales, and offers promising avenues for constructing conventional black hole-like structures.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.465790872963897,
        "rewrite-fast-z-score": 1.1141720290623112
    },
    {
        "original_text": "We present spectropolarimetric observations made with the Solar Optical Telescope (SOT) on board Hinode, which show that the magnetic field strength inferred from Stokes V profiles is systematically higher than those obtained by using the Zeeman splitting method for both the Ca II 8498 Å line and the Ca II 8542 Å line. The difference between these two methods increases as we go to smaller spatial scales. We also find that the magnetic fields are more inclined towards the solar surface at small spatial scales compared to larger ones. These results suggest that there may be some unknown physical processes affecting the formation of Stokes V profiles at small spatial scales. This work was supported by JSPS KAKENHI Grant-in-Aid for Scientific Research No. 16340040 . \nIntroduction\n\nThe solar atmosphere consists of various structures such as sunspots, pores, plages, prominences etc., where different physical phenomena occur. In order to understand how these phenomena take place, it is important to study their properties individually. However, this task has been difficult because most of them have very fine structure and they often overlap each other spatially. To overcome this difficulty, many observational studies have been carried out recently using high-resolution instruments such as the Swedish 1-m Solar Telescope (SST), the New Solar Telescope (NST), the Advanced Technology Solar Telescope (ATST), and the Solar Dynamics Observatory (SDO). Among others, the Hinode satellite launched in 2006 provides us with unprecedentedly high-quality data thanks to its sophisticated instrumentation including the Spectro-Polarimeter (SP) (Lites et al. (2001) ) and the Helioseismic and Magnetic Imager (HMI) (Schou et al. (2010) ), which enable us to investigate the solar photosphere down to subarcsecond resolution. Using these data sets, several authors studied the photospheric magnetic fields (e.g., Ichimoto et al. (2007) , Ishikawa & Tsuneta (2008) , Kitai et al. (2009 ), Orozco Suárez et al. (2010 , Sheminova et al. (2011))",
        "watermark_text": "We present spectropolarimetric experiments done with the Solar Optical Telescope ( SOT ) on board Hinode , which show that the magnetic force power inferred from Stokes V profiles is systematically greater than those achieved by using the Zeeman splitting method for both the Ca II 8498 Å line and the Ca II 8542 Å line . The difference between these two models increases as we went to smaller spatial dimensions .We additionally find that the magnetic waves are more oriented towards the sun surface at small spatial dimensions relative to larger ones . These conclusions show that there may be some undisclosed physical processes controlling the formation of Stokes V profiles at small spatial scales .This project was supported by JSPS KAKENHI Grant - in - Aid for Scientific Research No . 16340040 .Introduction The solar atmosphere includes of several buildings such as sunspots , pores , plages , prominences etc . , where various physical phenomena arise . In order to comprehend how these phenomena took place , it is important to study their characteristics individually .However , this job has been difficult because most of them have very fine structure and they frequently overlap each other spatially . To solve this obstacle , many observational research have been carried out recently utilizing large - resolution instruments such as the Swedish 1 - m Solar Telescope ( SST ) , the New Solar Telescope ( NST ) , the Advanced Technology Solar Telescope ( ATST ) , and the Solar Dynamics Observatory ( SDO ) .Among others , the Hinode satellite launched in 2006 offers us with unprecedentedly high - grade statistics courtesy to its sophisticated instrumentation including the Spectro - Polarimeter ( SP ) ( Lites et al . ( 2001 ) ) and the Helioseismic and Magnetic Imager ( HMI ) ( Schou et al .( 2010 ) ) , which enable us to examine the thermal photosphere down to subarcsecond resolution . Using these information sets , various scientists examined the photospheric magnetic fields ( e . g . , Ichimoto et al .( 2007 ) , Ishikawa & Tsuneta ( 2008 ) , Kitai et al . ( 2009 ) , Orozco Suárez et al .( 2010 , Sheminova et al . ( 2011 ) )",
        "rewrite_text": "We conducted spectropolarimetric experiments using the Solar Optical Telescope (SOT) aboard Hinode, revealing that the magnetic force power deduced from Stokes V profiles is consistently higher than that obtained through the Zeeman splitting method for both the Ca II 8498 Å and Ca II 8542 Å lines. This discrepancy between the two approaches increases as we analyze smaller spatial scales. Furthermore, we observed that at reduced spatial dimensions, the orientation of magnetic waves tends to be directed more towards the solar surface compared to larger scales. These findings suggest the presence of unrecognized physical processes influencing the formation of Stokes V profiles at small spatial scales. This research was supported by JSPS KAKENHI Grant-in-Aid for Scientific Research No. 16340040. \n\nIntroduction: The solar atmosphere comprises various structures, such as sunspots, pores, plages, and prominences, where diverse physical phenomena occur. Understanding these phenomena requires an individual examination of their characteristics. However, this task presents challenges due to their intricate structures and spatial overlaps. To address this issue, numerous observational studies have recently utilized high-resolution instruments, including the Swedish 1-m Solar Telescope (SST), the New Solar Telescope (NST), the Advanced Technology Solar Telescope (ATST), and the Solar Dynamics Observatory (SDO). Notably, the Hinode satellite, launched in 2006, provides exceptional statistical quality through its advanced instruments, such as the Spectro-Polarimeter (SP) (Lites et al. 2001) and the Helioseismic and Magnetic Imager (HMI) (Schou et al. 2010), which allow for detailed investigations of the thermal photosphere at subarcsecond resolution. Leveraging these data sets, various researchers have explored the photospheric magnetic fields (e.g., Ichimoto et al. 2007; Ishikawa & Tsuneta 2008; Kitai et al. 2009; Orozco Suárez et al. 2010; Sheminova et al. 2011).",
        "ori-fast-z-score": -1.5454545454545454,
        "water-fast-z-score": 6.454545454545454,
        "rewrite-fast-z-score": 0.19069251784911848
    },
    {
        "original_text": "We report the discovery of an extremely bright and hot (T eff = 300,000 K) blue supergiant in the open cluster NGC 6231 with a mass loss rate of 10^-6 M_sun/yr. The object is located at a distance of 1 kpc from Earth and has a luminosity of 5 x 10^{5} L_Sun. It shows strong emission lines of He II 4686 Å, N III 4641 Å, C IV 5801 Å, O V 7322 Å, and H Balmer series. We suggest that this object may be a member of the Cygnus OB2 association which contains several other high-mass stars. This would make it one of the most luminous known single stars outside our Galaxy. If confirmed by further observations, this object will provide important constraints on stellar evolution models for massive stars. Keywords: Open clusters; Blue supergiants",
        "watermark_text": "We report the discovery of an incredibly bright and hot ( T eff = 300 , 000 K ) blue supergiant in the open cluster NGC 6231 with a mass loss rate of 10 ^ - 6 M _ sun / yr . The object is situated at a distance of 1 kpc from Earth and has a luminosity of 5 x 10 ^ { 5 } L _ Sun .It displays large emission lines of He II 4686 Å , N III 4641 Å , C IV 5801 Å , O V 7322 Å , and H Balmer series . We suggest that this body may be a member of the Cygnus OB2 association which contains multiple other high - weight stars .This might making it one of the most luminous known single lights outside our Galaxy . If confirmed by further observations , this body will provide important restrictions on stellar evolution models for huge stars .Keywords : Open clusters ; Blue supergiants",
        "rewrite_text": "We announce the discovery of an exceptionally bright and hot blue supergiant in the open cluster NGC 6231, featuring an effective temperature of 300,000 K and a mass loss rate of 10^-6 M☉ per year. Located approximately 1 kpc from Earth, this star possesses a luminosity of 5 x 10^5 L☉. It exhibits prominent emission lines, including He II at 4686 Å, N III at 4641 Å, C IV at 5801 Å, O V at 7322 Å, and lines from the H Balmer series. We propose that it may belong to the Cygnus OB2 association, which hosts several other massive stars. If verified through additional observations, this star could be recognized as one of the most luminous known solitary stars outside our Galaxy, potentially providing significant insights into the stellar evolution of massive stars. \n\nKeywords: Open clusters; Blue supergiants.",
        "ori-fast-z-score": 0.14285714285714285,
        "water-fast-z-score": 3.857142857142857,
        "rewrite-fast-z-score": -1.0504514628777804
    },
    {
        "original_text": "We present results on infrared sources selected by their flux densities at 11 microns (S11) using early data taken with the InfraRed Camera (IRC) on-board AKARI, which is an infrared space telescope launched into orbit in February 2006. The survey covers about 1 deg2 area centered around the north ecliptic pole and reaches to S/N = 5 limit for point source detection. We have identified more than 1000 infrared sources down to S11 ~ 0.1 Jy over the entire field-of-view. Among them we found that most are associated with galaxies or galaxy clusters. About 20% of these objects show red colors indicative of dust-obscured star formation activity. A large fraction of the remaining 80% shows blue colors indicating active galactic nuclei and/or young stellar populations. These results suggest that our sample contains various types of infrared luminous objects including normal galaxies, interacting/merging systems, obscured AGNs as well as distant quasars.",
        "watermark_text": "We report findings on infrared sources chosen by their flux densities at 11 microns ( S11 ) using early data taken with the InfraRed Camera ( IRC ) on - board AKARI , which is an infrared space telescope launched into orbit in February 2006 . The survey encompasses about 1 deg2 region focused around the north ecliptic pole and reaches to S / N = 5 limit for point source discovery .We have discovered more than 1000 infrared sources down to S11 ~ 0 . 1 Jy over the entire field - of - view . Among them we identified that most are related with galaxies or galaxy regions .About 20 % of these objects show red colors indicative of dust - obscured star formation activity . A large fraction of the remaining 80 % indicates blue colors representing active galactic nuclei and / or young stellar groups .These data suggest that our sample comprises numerous types of infrared luminous objects including typical clusters , interacting / merging systems , obscured AGNs as well as distant quasars .",
        "rewrite_text": "We present findings on infrared sources selected based on their flux densities at 11 microns (S11), utilizing early data obtained from the InfraRed Camera (IRC) aboard the AKARI space telescope, which was launched in February 2006. The survey covers approximately 1 square degree centered around the north ecliptic pole and achieves a signal-to-noise ratio of 5 for point source detection. We have identified over 1,000 infrared sources with S11 ~ 0.1 Jy across the entire field of view. Most of these sources are associated with galaxies or galactic regions. Notably, around 20% exhibit red colors, indicating dust-obscured star formation activity, while a significant portion of the remaining 80% displays blue colors, signifying active galactic nuclei and/or young stellar populations. These findings suggest that our sample includes a diverse array of infrared luminous objects, such as typical clusters, interacting or merging systems, obscured active galactic nuclei, and distant quasars.",
        "ori-fast-z-score": 0.6882472016116852,
        "water-fast-z-score": 4.817730411281796,
        "rewrite-fast-z-score": -0.6882472016116852
    },
    {
        "original_text": "We consider the problem of estimating an unknown function f from noisy measurements y = Af + w, where A is a linear operator and w is white noise with known covariance matrix Cw.  We assume that the operator A has been discretized on some grid (e.g., by using finite differences or spectral methods) so that it can be represented as a large matrix.  The goal is to find an estimatef such that Ef − f  2 is minimized subject to certain constraints on the smoothness off . \nIn this work we propose new numerical techniques based on needlets which are able to efficiently solve these constrained optimization problems.  In particular, our approach allows us to obtain accurate estimates even when the number N of available observations is much smaller than the dimension M of the space spanned by the columns of A. \nThe proposed method relies on two main ingredients:  First, we use a sparse representation of functions in terms of needlets.  Second, we develop efficient iterative algorithms for solving large-scale convex optimization problems involving sparsity-promoting regularizers.  These algorithms combine ideas from compressed sensing theory and recent results about the convergence rate of alternating direction method of multipliers (ADMM).",
        "watermark_text": "We consider the question of estimating an unknown function f from noisy measurements y = Af + f , where A is a linear operator and f is white sound with known covariance matrix Cw . We assume that the operator A has been discretized on some grid ( e . g . , by using finite differences or spectral algorithms ) so that it can be described as a large vector .The goal is to find an estimatef such that Ef − f 2 is minimized subject to specified constraints on the smoothness off . In this study we develop new numerical tactics based on needlets which are able to easily solution these constrained optimization problems .In particular , our approach allows us to obtain precise estimates even when the number N of available observed is much smaller than the dimension M of the space spanned by the rows of A . The proposed approach consists on two principal ingredients : First , we utilize a sparse representation of functions in terms of needlets .Second , we develop optimal iterative techniques for solving large - scale convex optimization problems concerning sparsity - promoting regularizers . These methods combine developments from compressed sensing theory and recent results about the convergence speed of alternating path method of multipliers ( ADMM ) .",
        "rewrite_text": "We address the problem of estimating an unknown function \\( f \\) from noisy observations given by \\( y = Af + f \\), where \\( A \\) is a linear operator, and \\( f \\) represents white noise with a known covariance matrix \\( C_w \\). We assume that the operator \\( A \\) has been discretized on a grid (for instance, using finite differences or spectral methods), allowing it to be represented as a large vector. Our objective is to estimate \\( f \\) in such a way that \\( E[f - f^2] \\) is minimized while adhering to specific constraints on the smoothness of \\( f \\). In this work, we introduce new numerical strategies based on needlets that effectively address these constrained optimization challenges. Notably, our method enables precise estimations even when the number of observed data points \\( N \\) is significantly less than the dimensionality \\( M \\) of the space spanned by the rows of \\( A \\). The proposed approach involves two key components: firstly, we leverage a sparse representation of functions using needlets; secondly, we devise optimal iterative techniques for addressing large-scale convex optimization problems that include sparsity-promoting regularizers. These techniques draw on advances from compressed sensing theory as well as recent findings on the convergence rates of the alternating direction method of multipliers (ADMM).",
        "ori-fast-z-score": 0.9233805168766388,
        "water-fast-z-score": 6.807380225308036,
        "rewrite-fast-z-score": 1.4288690166235207
    },
    {
        "original_text": "We report on the electronic structure and magnetic properties of zigzag graphene nanoribbons (ZGNRs) with different edge structures, including hydrogenated ZGNR (H-ZGNR), fluorinated ZGNR (F-ZGNR), oxygenated ZGNR (O-ZGNR), and nitrogen-doped O-ZGNR (N-ZGNR). We find that all these ZGNRs are half-metals except for H-ZGNR which is metallic. The band gaps of F-ZGNR and N-ZGNR increase as compared to those of pristine ZGNR due to the electronegativity difference between carbon atoms at edges and their neighbors. In contrast, the band gap decreases slightly when oxygen replaces one or two carbon atoms at each edge because of charge transfer from oxygen to neighboring carbon atom(s). Our results show that the spin polarization can be enhanced by introducing oxygen into the edges of ZGNRs.",
        "watermark_text": "We report on the electronic structure and magnetic properties of zigzag graphene nanoribbons ( ZGNRs ) with various edge structures , notably hydrogenated ZGNR ( H - ZGNR ) , fluorinated ZGNR ( F - ZGNR ) , oxygenated ZGNR ( O - ZGNR ) , and nitrogen - doped O - ZGNR ( N - ZGNR ) . We see that all these ZGNRs are half - metals except for H - ZGNR which is metallic .The band holes of F - ZGNR and N - ZGNR increase as compared to those of pristine ZGNR due to the electronegativity difference between carbon atoms at corners and their relatives . In comparison , the band gap falls slightly when oxygen replaces one or two carbon atoms at each edge because of charge transfer from nitrogen to neighboring carbon molecule ( s ) .Our results show that the spin polarization can be enhanced by bringing oxygen into the edges of ZGNRs .",
        "rewrite_text": "We present our findings on the electronic structure and magnetic properties of zigzag graphene nanoribbons (ZGNRs) with various edge configurations, specifically hydrogenated ZGNRs (H-ZGNR), fluorinated ZGNRs (F-ZGNR), oxygenated ZGNRs (O-ZGNR), and nitrogen-doped O-ZGNRs (N-ZGNR). Our analysis reveals that, with the exception of H-ZGNR, which exhibits metallic behavior, all these ZGNRs display half-metallic characteristics. The band gaps of F-ZGNR and N-ZGNR are found to increase compared to that of pristine ZGNR, attributed to the difference in electronegativity between the carbon atoms located at the corners and their adjacent counterparts. Conversely, the introduction of oxygen, replacing one or two carbon atoms at each edge, leads to a slight decrease in the band gap due to charge transfer from nitrogen to the neighboring carbon atom(s). Our results indicate that incorporating oxygen into the edges of ZGNRs can effectively enhance spin polarization.",
        "ori-fast-z-score": 0.5897678246195885,
        "water-fast-z-score": 3.8334908600273256,
        "rewrite-fast-z-score": 0.2581988897471611
    },
    {
        "original_text": "We present an approach to decision tree learning that uses views over the data in order to improve efficiency and scalability. The proposed method is based on the idea of using multiple views, each one capturing different aspects or features of the same dataset. We show how this can be achieved by defining a set of views for each node in the decision tree model being learned. These views are then used as input to a modified version of the standard ID3 algorithm which learns the decision tree structure. Our experimental results demonstrate significant improvements in terms of both accuracy and execution time when compared against existing approaches. Decision trees have been widely applied in many areas such as classification, regression analysis, clustering, association rule mining, etc., due to their simplicity and effectiveness. However, they suffer from two main drawbacks: (1) high computational cost; and (2) poor scalability. In particular, the number of possible splits at any given internal node grows exponentially with respect to the size of its parent s training sample. This makes it difficult to build large decision trees efficiently. To address these problems we propose a novel approach called Relational Views-based Decision Tree Learning (RV-DTL). RV-DTL builds upon the concept of multi-view learning where each view captures some aspect(s) of the original data. More specifically, our approach defines a set of views for every internal node in the decision tree being built. Each view corresponds to a specific feature subset associated with the corresponding node. Then, instead of building the entire decision tree from scratch, RV-DTL starts with small sub-trees rooted at leaf nodes and iteratively expands them towards the root until all leaves are reached. At each expansion step, RV-DTL selects the best split among those available according to the information gain criterion. Finally, the final decision tree is constructed by merging together...",
        "watermark_text": "We suggest an approach to decision tree learning that using views over the information in attempts to promote efficiency and scalability . The proposed approach is based on the idea of using multiple views , each one capturing different components or elements of the same dataset .We see how this can be obtained by creating a setting of views for each node in the decision tree model being taught . These views are then used as input to a altered version of the standard ID3 algorithm which understands the reasoning tree structure .Our research results show considerable improvements in terms of both precision and execution time when compared against existing techniques . Decision trees have been widely applied in different areas such as classification , regression evaluation , clustering , association rule extraction , etc . , owing to their simplicity and effectiveness .However , they suffer from two principal drawbacks : ( 1 ) great computational cost ; and ( 2 ) poor scalability . In particular , the number of possible splits at any certain internal node grows exponentially with regard to the length of its parent s training sample .This creates it difficult to build large decision forests quickly . To address these problems we propose a new approach titled Relational Views - based Decision Tree Learning ( RV - DTL ) .RV - DTL relies upon the idea of multi - view testing where each vision preserves some aspect ( s ) of the original material . More specifically , our approach establishes a setting of views for every internal node in the decision tree being built .Each view belongs to a certain characteristic subset associated with the respective node . Then , rather of building the entire choice tree from scratch , RV - DTL began with little sub - forests rooted at leaf nodes and iteratively builds them towards the root until all leaves are reached .At each expansion stage , RV - DTL selects the best split among those available based to the information gain criterion . Finally , the finished choice table is built by merging together . . .",
        "rewrite_text": "We propose a novel approach to decision tree learning that leverages various views of the available information to enhance efficiency and scalability. This approach is centered around the concept of employing multiple views, each one capturing distinct aspects or features of the same dataset. We demonstrate how to implement this by establishing a set of views for each node in the decision tree model being developed. These views serve as input to a modified version of the standard ID3 algorithm, which accommodates the reasoning tree structure. Our research findings indicate significant improvements in both precision and execution time compared to current methods. Decision trees are widely utilized across various domains, including classification, regression analysis, clustering, and association rule extraction, primarily due to their simplicity and effectiveness. However, they face two major challenges: high computational cost and limited scalability. Specifically, the number of potential splits at a given internal node increases exponentially with the size of its parent’s training sample, making it challenging to quickly construct large decision forests. To tackle these issues, we introduce an approach called Relational Views-Based Decision Tree Learning (RV-DTL). RV-DTL is built on the principle of multi-view testing, where each view captures specific attributes of the original data. More precisely, our method creates a set of views for each internal node in the decision tree being built, with each view corresponding to a particular characteristic subset linked to that node. Instead of constructing the entire decision tree from the ground up, RV-DTL starts with small sub-forests at the leaf nodes and iteratively builds them up toward the root. During each expansion phase, RV-DTL selects the optimal split among available options based on information gain criteria. Ultimately, the complete decision tree is formed by merging these sub-forests together.",
        "ori-fast-z-score": -1.7905475715715027,
        "water-fast-z-score": 7.916735362204594,
        "rewrite-fast-z-score": -1.0999438818457405
    },
    {
        "original_text": "The clustering properties of light nuclei are studied within the framework of the relativistic fragmentation model (RFM). The RFM is based on the concept that nuclear matter can be considered as an ensemble of clusters which interact with each other by means of effective potentials. In this work we have used the microscopic cluster-cluster interaction potential developed recently for the description of light nuclei at low energies. We show that the RFM reproduces well the experimental data available for the production cross sections of different fragments produced in heavy ion collisions at intermediate energies. \n \n Keywords: Clusterization; Fragmentation; Light nuclei; Relativistic approach; Heavy ions; Microscopic interactions. 1 Introduction Nuclear structure studies play important role in understanding many phenomena observed in nuclear physics experiments  1  . One of these phenomena is the clustering effect  2  , i.e., the tendency to form bound states consisting of several particles or even larger systems like α-particles  3  .\nIn recent years there has been considerable interest in studying the clustering effects in light nuclei  4  -  8  . It was shown  9  that the clustering phenomenon plays significant role in describing the ground state properties of light nuclei such as binding energy, charge radius etc.. Moreover it was found  10  that the clustering effect also influences significantly the reaction dynamics of light nuclei. For example, the formation probability of compound nucleus in fusion reactions depends strongly on the number of clusters present in the entrance channel  11  . Therefore, one should take into account the clustering degrees of freedom when investigating the reaction mechanism of light nuclei  12  .",
        "watermark_text": "The clustering behavior of light nuclei are studied within the framework of the relativistic fragmentation model ( RFM ) . The RFM is based on the idea that atomic materials can be regarded as an ensemble of clusters which interact with each other by means of effective potentials .In this research we have utilized the microscopic cluster - cluster correlation potential developed lately for the description of light nuclei at low energies . We suggest that the RFM reproduces well the empirical data available for the production cross sections of different fragments produced in heavy ion collisions at intermediate energies .Keywords : Clusterization ; Fragmentation ; Light nuclei ; Relativistic approach ; Heavy electrons ; Microscopic interactions . 1 Introduction Nuclear structure researchers play essential part in understanding several phenomena observed in nuclear science studies 1 .One of these phenomena is the clustering effect 2 , i . e . , the tendency to form bound states consisting of several particles or especially bigger systems like α - particles 3 . In recent years there has been substantial interest in investigating the clustering effects in light nuclei 4 - 8 .It was shown 9 that the clustering phenomenon plays significant influence in understanding the ground state properties of light nuclei such as activation energy , charge radius etc . . Moreover it was shown 10 that the clustering effect additionally effects significantly the process chemistry of light nuclei .For instance , the formation likelihood of compound nucleus in fusion compounds depends strongly on the quantity of clusters present in the entrance channel 11 . Therefore , one should take into consideration the clustering degrees of liberty when examining the reaction mechanism of light nuclei 12 .",
        "rewrite_text": "The clustering behavior of light nuclei is investigated using the relativistic fragmentation model (RFM). This model is founded on the premise that atomic materials can be seen as a collection of clusters that interact with each other through effective potentials. In this study, we have employed the recently developed microscopic cluster-cluster correlation potential to describe light nuclei at low energies. Our findings suggest that the RFM accurately reproduces the empirical data regarding the production cross sections of various fragments that emerge from heavy ion collisions at intermediate energies. \n\nKeywords: Clusterization; Fragmentation; Light nuclei; Relativistic approach; Heavy ions; Microscopic interactions. \n\n1. Introduction\n\nResearchers in nuclear structure play a crucial role in elucidating various phenomena observed in nuclear science. One such phenomenon is the clustering effect, which involves the tendency of particles to form bound states, particularly larger systems like α-particles. In recent years, there has been considerable interest in examining clustering effects in light nuclei. It has been demonstrated that clustering significantly influences the ground state properties of light nuclei, including activation energy and charge radius. Additionally, clustering notably affects the reaction kinetics in light nuclei; for example, the likelihood of compound nucleus formation in fusion reactions is highly dependent on the number of clusters present in the entrance channel. Consequently, it is essential to consider the degrees of freedom associated with clustering when analyzing the reaction mechanisms of light nuclei.",
        "ori-fast-z-score": 2.359000952984802,
        "water-fast-z-score": 8.364283610093427,
        "rewrite-fast-z-score": 1.6296434287653334
    },
    {
        "original_text": "In this thesis, we study the problem of physical layer network coding (PLNC) in wireless networks with multiple relays and single-antenna nodes.  We first consider PLNC for two-way relay channels where each node has only one antenna.  In particular, we propose an efficient scheme to perform PLNC at both source nodes simultaneously by using linear codes over finite fields.  Then, we extend our results to multi-way relay channels with more than two users.  Finally, we investigate the performance of PLNC under imperfect channel state information (CSI). The main contributions are summarized as follows:  1. Two-way Relay Channels: We propose a novel approach to perform PLNC at the sources simultaneously based on linear codes over finite fields.   2. Multi-Way Relay Channels: By extending our previous work, we develop a new method to perform PLNC at all source nodes simultaneously.  3. Imperfect Channel State Information: We analyze the impact of imperfect CSI on the performance of PLNC schemes.",
        "watermark_text": "In this dissertation , we study the issue of physical layer network signaling ( PLNC ) in telecommunications networks with many relays and multiple - antenna nodes . We first consider PLNC for two - way relay channels where each node has only one antenna .In particular , we propose an efficient algorithm to conduct PLNC at both source nodes simultaneously by using linear codes over discrete fields . Then , we expanded our findings to multi - way transmission networks with more than two users .Finally , we investigate the performance of PLNC under imperfect channel state information ( CSI ) . The main contributions are presented as follows : 1 .Two - way Relay Channels : We suggest a new approach to conduct PLNC at the sources simultaneously based on linear codes over discrete fields . 2 .Multi - Way Relay Channels : By extending our previous research , we develop a new method to conduct PLNC at all source nodes simultaneously . 3 .Imperfect Channel State Information : We evaluate the impact of imperfect CSI on the performance of PLNC networks .",
        "rewrite_text": "In this dissertation, we examine the challenge of physical layer network coding (PLNC) within telecommunications networks that incorporate multiple relays and nodes equipped with multiple antennas. Our initial focus is on PLNC in two-way relay channels, where each node is limited to a single antenna. Specifically, we introduce an effective algorithm that enables simultaneous PLNC at both source nodes through the use of linear codes over discrete fields. We then extend our research to multi-way transmission networks involving more than two users. Lastly, we assess the performance of PLNC in scenarios with imperfect channel state information (CSI). The key contributions of our work are outlined as follows: 1. Two-Way Relay Channels: We present a novel strategy for implementing PLNC at both sources concurrently using linear codes over discrete fields. 2. Multi-Way Relay Channels: Building on our previous findings, we propose a new technique to facilitate simultaneous PLNC at all source nodes. 3. Imperfect Channel State Information: We analyze how imperfect CSI affects the performance of PLNC networks.",
        "ori-fast-z-score": 2.1652509527331207,
        "water-fast-z-score": 6.951595164037914,
        "rewrite-fast-z-score": 1.4444444444444444
    },
    {
        "original_text": "We present an analysis of the kinematics and chemical composition of stars in the outer halo (R > 20 kpc) of our Galaxy, based on data obtained with the Sloan Digital Sky Survey (SDSS). We find that these stars are consistent with being drawn from two populations: one is metal-poor and has a mean metallicity  Fe/H  = -1.7 dex, while the other population is more metal-rich with a mean metallicity   Fe / H   = -0.8 dex . The former population shows a clear rotation signature around Galactic North Pole, which we interpret as evidence for its formation by tidal disruption of dwarf galaxies; this interpretation is supported by their high orbital eccentricities. On the other hand, the latter population does not show any significant rotation or orbital anisotropy, suggesting that it was formed through dissipative processes such as gas cooling and star formation.",
        "watermark_text": "We present an assessment of the kinematics and chemical composition of stars in the outer halo ( R > 20 kpc ) of our Galaxy , using on evidence derived with the Sloan Digital Sky Survey ( SDSS ) . We see that these stars are compatible with being drawn from two communities : one is metal - weak and has a mean metallicity Fe / H = - 1 . 7 dex , while the other population is more metal - rich with a mean metallicity Fe / H = - 0 . 8 dex .The former population shows a clear rotation signature around Galactic North Pole , which we treat as proof for its formation by tidal disruption of dwarf stars ; this interpretation is backed by their high orbital eccentricities . On the other hand , the latter population does not show any considerable rotation or orbital anisotropy , showing that it was formed through dissipative processes such as gas warming and star formation .",
        "rewrite_text": "We provide an analysis of the kinematics and chemical composition of stars located in the outer halo (R > 20 kpc) of our Galaxy, based on data from the Sloan Digital Sky Survey (SDSS). Our findings indicate that these stars can be categorized into two distinct groups: one group is metal-poor, with an average metallicity of [Fe/H] = -1.7 dex, while the other group is more metal-rich, with an average metallicity of [Fe/H] = -0.8 dex. The metal-poor population exhibits a clear rotational pattern around the Galactic North Pole, which we interpret as evidence of its formation through the tidal disruption of dwarf galaxies; this idea is further supported by their high orbital eccentricities. In contrast, the metal-rich population displays little to no rotation or orbital anisotropy, suggesting that it formed through dissipative processes, such as gas heating and subsequent star formation.",
        "ori-fast-z-score": -1.386750490563073,
        "water-fast-z-score": 3.05085107923876,
        "rewrite-fast-z-score": -1.3363062095621219
    },
    {
        "original_text": "We propose an algorithm to find optimal hierarchical descriptors (OHDs) that can be used as fingerprints in complex networks, such as social and biological systems. The OHDs represent network structures at different levels of granularity by using a tree-like structure with nodes representing subnetworks or clusters. We show how these trees can be constructed efficiently based on modularity maximization algorithms. In addition, we introduce a novel concept called  clustering coefficient  which is useful when constructing OHDs. Finally, we demonstrate our method through several examples including synthetic benchmark data sets and real-world networks. Our results suggest that the proposed approach provides more accurate descriptions than existing methods. This work was supported by JSPS KAKENHI Grant Number JP26287040. Keywords: Hierarchical descriptor, Clustering coefficient, Modularity Maximization Algorithm, Tree Structure, Fingerprint, Network Description",
        "watermark_text": "We suggest an algorithm to find optimal hierarchical descriptors ( OHDs ) that can be used as fingerprints in complex networks , such as social and biological environments . The OHDs represent system structures at different levels of granularity by using a tree - like structure with vertices representing subnetworks or communities .We see how these trees can be built easily using on modularity maximization algorithms . In addition , we provide a new notion called clustering coefficient which is important when constructing OHDs .Finally , we prove our technique through several examples namely natural benchmark data sets and actual - global networks . Our results show that the suggested approach offers more accurate descriptions than existing techniques .This project was supported by JSPS KAKENHI Grant Number JP26287040 . Keywords : Hierarchical descriptor , Clustering coefficient , Modularity Maximization Algorithm , Tree Structure , Fingerprint , Network Description",
        "rewrite_text": "We propose an algorithm for identifying optimal hierarchical descriptors (OHDs) that can serve as fingerprints for complex networks, including social and biological systems. These OHDs illustrate the structural organization of a system at multiple levels of detail, utilizing a tree-like framework where the nodes correspond to subnetworks or communities. We demonstrate how these trees can be efficiently constructed through modularity maximization algorithms. Additionally, we introduce a novel concept called the clustering coefficient, which plays a crucial role in the creation of OHDs. Finally, we validate our method with various examples, including natural benchmark datasets and real-world global networks. Our findings indicate that the proposed approach yields more precise descriptions compared to existing methods. This research was funded by JSPS KAKENHI Grant Number JP26287040. Keywords: Hierarchical descriptor, Clustering coefficient, Modularity Maximization Algorithm, Tree Structure, Fingerprint, Network Description.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.37925663806037,
        "rewrite-fast-z-score": -0.12803687993289598
    },
    {
        "original_text": "The Standard Model is in excellent agreement with all current experimental data, but it leaves many questions unanswered and fails to provide an explanation for some phenomena observed experimentally.  The muon magnetic moment anomaly provides one such example where there are significant discrepancies between theory predictions and experiment measurements that cannot be explained within the Standard Model framework.   In this talk I will present the physics case for the new g-2 experiment at Fermilab which aims to measure the anomalous magnetic moment of the muon more accurately than ever before by using a novel technique based on laser cooling and trapping techniques developed over recent years.   ... This talk presents the physics case for the proposed new measurement of the muon s anomalous magnetic moment at Fermilab. It describes how the use of laser cooling and trapping can lead to a dramatic improvement in precision compared to previous experiments. A number of other topics related to the project are also discussed including the status of the R&D program towards the goal of measuring the muon magnetic moment to 0.5 parts per million accuracy.",
        "watermark_text": "The Standard Model is in good agreement with all recent experimental evidence , but it leaves many issues unanswered and fails to provide an reason for some phenomena observed experimentally . The muon magnetic point anomaly gives one such example where there are significant discrepancies between theoretical estimates and observation observations that cannot be described within the Standard Model framework .In this talk I will present the physics case for the new g - 2 study at Fermilab which aims to measure the anomalous magnetic motion of the muon more accurately than ever before by using a innovative method based on laser cooling and trapping techniques established over recent generations . . . .This discussion presents the physics case for the suggested novel measurement of the muon s anomalous magnetic force at Fermilab . It details how the using of laser cooling and trapping can lead to a dramatic improvement in precision compared to previous study .A variety of other topics related to the project are also discussed including the status of the R & D program towards the objective of calculating the muon magnetic moment to 0 . 5 parts per million accuracy .",
        "rewrite_text": "The Standard Model aligns well with recent experimental findings; however, it still leaves many questions unanswered and does not account for certain observed phenomena. One notable example is the muon magnetic moment anomaly, which reveals significant discrepancies between theoretical predictions and experimental results that the Standard Model cannot explain. In this presentation, I will outline the physics rationale behind the new g-2 experiment at Fermilab, which seeks to measure the muon's anomalous magnetic motion with unprecedented precision using innovative laser cooling and trapping techniques developed over the past few decades. I will discuss the potential for substantial improvements in measurement accuracy compared to previous studies, as well as provide updates on the R&D program aimed at achieving a calculation of the muon magnetic moment with an accuracy of 0.5 parts per million. Additionally, various related topics concerning the project will be explored.",
        "ori-fast-z-score": 1.5096588248481377,
        "water-fast-z-score": 7.701031252562294,
        "rewrite-fast-z-score": -0.23570226039551587
    },
    {
        "original_text": "The dielectric properties, phase transition behavior, and microstructure evolution were investigated for the (0.65 Pb(Ni-1/3Nb-2/3)O_3  -0.35PbTiO3) (PNT) ceramics with different sintering temperatures ranging from 850 to 1100 °C. The PNT samples exhibited high permittivity values up to ~10 4 , low loss tangent below 10 -2 , and large tunability over 30% under an electric field strength of 30 kV/cm at room temperature. With decreasing temperature down to 77 K, the permittivity increased slightly while the loss tangent decreased significantly due to the freezing out of mobile ions. At cryogenic temperatures, two relaxation processes were observed in the frequency range between 1 Hz and 100 kHz. The first process was attributed to the grain boundary effect; it shifted towards higher frequencies as the temperature decreased. The second process was associated with ferroelectric domain wall motion; its relaxation time constant remained almost unchanged when the temperature changed.",
        "watermark_text": "The dielectric characteristics , phase change response , and microstructure formation were researched for the ( 0 . 65 Pb ( Ni - 1 / 3Nb - 2 / 3 ) O _ 3 - 0 . 35PbTiO3 ) ( PNT ) ceramics with various sintering temperatures ranging from 850 to 1100 °C . The PNT specimens exhibited high permittivity values up to ~ 10 4 , low loss tangent below 10 - 2 , and large tunability over 30 % under an electric field intensity of 30 kV / cm at room temperature .With decreasing temperature down to 77 K , the permittivity increased somewhat while the loss tangent decreased significantly related to the freezing out of mobile atoms . At cryogenic temperatures , two relaxation processes were detected in the frequency region between 1 Hz and 100 kHz .The first mechanism was due to the grain boundary phenomenon ; it shifted towards higher frequencies as the temperature reduced . The second process was correlated with ferroelectric domain floor motion ; its relaxation time constant remained nearly intact when the temperature changed .",
        "rewrite_text": "The study focused on the dielectric properties, phase change behavior, and microstructural development of (0.65 Pb(Ni-1/3Nb-2/3)O3 - 0.35 PbTiO3) (PNT) ceramics, which were sintered at temperatures ranging from 850 to 1100 °C. The PNT samples demonstrated impressive permittivity values, reaching up to approximately 10^4, a low loss tangent below 10^-2, and a tunability exceeding 30% under an electric field strength of 30 kV/cm at room temperature. As the temperature decreased to 77 K, the permittivity showed a slight increase while the loss tangent significantly decreased, attributed to the immobilization of mobile atoms. At cryogenic temperatures, two distinct relaxation processes were observed within the frequency range of 1 Hz to 100 kHz. The first process was associated with grain boundary effects and shifted to higher frequencies with decreasing temperature. The second process was linked to the motion of ferroelectric domain floors, with its relaxation time constant remaining relatively stable despite changes in temperature.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.335783750799325,
        "rewrite-fast-z-score": -0.7171371656006361
    },
    {
        "original_text": "We study the ground state properties of frustrated spin-1/2 Heisenberg models on square lattices with different types of interlayer couplings, including both homogeneous and inhomogeneous ones. We show that frustration can be suppressed by introducing an additional ferromagnetic coupling between layers which leads to formation of inhomogeneous magnetic states characterized by spatially modulated magnetization profiles. The obtained results are discussed within the framework of the recently developed concept of ``inverse condensation  . Introduction: In recent years there has been growing interest in studying strongly correlated systems where competing interactions lead to complex phase diagrams exhibiting various exotic phases such as valence bond solids (VBS), charge density waves (CDW) or supersolids  1-3 . One of the most interesting examples is provided by layered quantum antiferromagnets  4  . These compounds consist of weakly coupled planes of spins arranged into a regular lattice structure. Due to strong geometrical frustration caused by competing nearest-neighbor exchange interactions J1 along the chain direction and J2 across the chains, these materials exhibit a rich variety of physical phenomena ranging from conventional Néel order at low temperatures down to disordered paramagnetic phases  5  .\nIn this work we consider two prototypical representatives of this class of materials: CuGeO3  6  , where each plane consists of edge-sharing tetrahedra forming a honeycomb-like network  7, 8  , and BaCo2As2  9  , where the planes are made up of corner-sharing triangles  10  . Both compounds have attracted considerable attention due to their unusual magnetic behavior  11, 12  . For example, it was shown experimentally that in CuGeO3 the system undergoes a transition from a collinear antiferromagnetically ordered state below TN = 29 K to a non-collinear VBS state above T* ~ 70 K  13  . On the other hand, for BaCo2As2 the situation seems more complicated since several experimental studies suggest coexistence of three different magnetic phases  14, 15  : a commensurate antiferromagnetically ordered phase below TC = 38 K; a helimagnetic",
        "watermark_text": "We research the ground state properties of frustrated spin - 1 / 2 Heisenberg machines on square lattices with various types of interlayer couplings , including both homogeneous and inhomogeneous ones . We see that frustration can be suppressed by creating an additional ferromagnetic coupling between sheets which results to formation of inhomogeneous magnetic states characterized by spatially modulated magnetization profiles .The achieved findings are discussed within the framework of the recently established concept of ` ` inverse condensation . Introduction : In recent years there has been growing interest in investigating strongly interacting systems where competing interactions result to complex phase diagrams displaying various exotic phases such as valence bond solids ( VBS ) , charge density radiation ( CDW ) or supersolids 1 - 3 .One of the most important examples is provided by layered quantum antiferromagnets 4 . These compounds comprise of mildly coupled planes of spins arranged into a regular lattice structure .Due to heavy geometrical problems caused by differing nearest - neighbor exchange interactions J1 along the chain direction and J2 across the chains , these structures exhibit a rich range of physical phenomena ranging from standard Néel order at low temperatures down to disordered paramagnetic phases 5 . In this research we consider two prototypical representatives of this class of substances : CuGeO3 6 , where each plane consists of edge - sharing tetrahedra making a honeycomb - like network 7 , 8 , and BaCo2As2 9 , where the planes are making up of spot - sharing triangles 10 .Both compounds have garnered considerable scrutiny due to their extraordinary magnetic behavior 11 , 12 . For instance , it was shown experimentally that in CuGeO3 the system undergoes a shift from a collinear antiferromagnetically ordered state below TN = 29 K to a non - collinear VBS state above T * ~ 70 K 13 .On the other hand , for BaCo2As2 the situation appears more complicated since several experimental studies confirm coexistence of three different magnetic modes 14 , 15 : a commensurate antiferromagnetically ordered phase below TC = 38 K ; a helimagnetic",
        "rewrite_text": "We investigate the ground state properties of frustrated spin-1/2 Heisenberg systems on square lattices with various interlayer coupling types, both homogeneous and inhomogeneous. Our findings indicate that frustration can be mitigated by introducing an additional ferromagnetic coupling between layers, leading to the emergence of inhomogeneous magnetic states characterized by spatially varying magnetization profiles. These results are contextualized within the recently developed concept of \"inverse condensation.\" \n\nIntroduction: Recently, there has been an increasing interest in studying strongly interacting systems where competing interactions give rise to complex phase diagrams featuring exotic phases such as valence bond solids (VBS), charge density waves (CDW), and supersolids. A significant example of this phenomenon can be seen in layered quantum antiferromagnets. These materials consist of weakly coupled spin planes arranged in a regular lattice structure. Due to the geometrical challenges posed by differing nearest-neighbor exchange interactions (J1 along the chain direction and J2 between chains), these systems exhibit a rich variety of physical phenomena, ranging from standard Néel order at low temperatures to disordered paramagnetic phases. In this study, we focus on two prototypical examples of this material class: CuGeO3, where each plane comprises edge-sharing tetrahedra forming a honeycomb-like network, and BaCo2As2, consisting of planes made up of spot-sharing triangles. Both compounds have attracted significant attention due to their remarkable magnetic properties. For instance, experiments have shown that CuGeO3 transitions from a collinear antiferromagnetically ordered state below TN = 29 K to a non-collinear VBS state above T* ~ 70 K. In contrast, BaCo2As2 presents a more complex scenario, as multiple experimental studies reveal the coexistence of three distinct magnetic phases: a commensurate antiferromagnetically ordered phase below TC = 38 K, along with a helimagnetic phase.",
        "ori-fast-z-score": 0.0854357657716761,
        "water-fast-z-score": 6.920297027505764,
        "rewrite-fast-z-score": 1.7277368511627202
    },
    {
        "original_text": "We study the concentration-mass relation for dark matter haloes in cosmological N-body simulations with different initial conditions and resolutions, focusing on the dependence on halo mass and redshift. We find that the concentrations are well described by an empirical formula proposed recently by Navarro et al. (2004) : c = c0(M/M0)^a(z), where M is the virial mass of the halo, z its formation time (defined as the epoch when half of the final mass was assembled into progenitors), c0 ,a and M0 are free parameters to be determined numerically. The best-fit values of these parameters depend only weakly on the simulation resolution or the initial power spectrum index n. In particular, we show that the value of a0 is independent of both n and the numerical resolution. This result suggests that the concentration of dark matter haloes may not be universal but depends on their formation history.",
        "watermark_text": "We research the density - mass balance for black material haloes in cosmological N - bodies simulations with various initial conditions and resolutions , concentrating on the dependence on halo weight and redshift . We see that the levels are better represented by an empirical formula proposed lately by Navarro et al .( 2004 ) : c = c0 ( M / M0 ) ^ a ( z ) , where M is the virial mass of the halo , z its formation period ( understood as the epoch when half of the finished weight was assembled into progenitors ) , c0 , a and M0 are free parameters to be determined numerically . The best - fitting values of these parameters depend only weakly on the simulation resolution or the first power spectrum value n . In particular , we prove that the value of a0 is independent of both n and the numerical resolution .This result suggests that the composition of grey matter haloes might not be universal but relies on their composition history .",
        "rewrite_text": "We examine the density-mass relationship for black material haloes in cosmological N-body simulations across various initial conditions and resolutions, focusing on how these factors affect halo mass and redshift. Our findings indicate that the density levels are more accurately depicted by an empirical formula recently introduced by Navarro et al. (2004): \\( c = c_0 (M / M_0)^{a(z)} \\), where \\( M \\) represents the virial mass of the halo, \\( z \\) denotes the formation epoch (defined as the time when half of the final mass was assembled from progenitors), and \\( c_0 \\), \\( a \\), and \\( M_0 \\) are parameters to be determined numerically. The optimal values for these parameters show only a weak dependence on simulation resolution and the initial power spectrum index \\( n \\). Notably, we demonstrate that the value of \\( a_0 \\) remains unaffected by both \\( n \\) and the numerical resolution. This finding implies that the properties of grey matter haloes may not be universal; rather, they seem to depend on their formation history.",
        "ori-fast-z-score": -0.36650833306891567,
        "water-fast-z-score": 6.230641662171566,
        "rewrite-fast-z-score": 0.819288030372914
    },
    {
        "original_text": "We report on the polarization dependent photoluminescence (PL) and Raman scattering spectra of CdSe/CdS core/shell quantum dots in solution at room temperature. The PL spectrum shows that the emission is polarized along the direction perpendicular to the excitation light, which can be explained by the selection rules for dipole transitions between electronic states with different angular momenta. In addition we observe an anisotropic broadening of the Stokes linewidths as well as a splitting into two components when exciting circularly polarized light. These effects are attributed to the presence of exciton fine structure due to spin-orbit coupling. We also find evidence for a strong electron-phonon interaction leading to phonon sidebands in both the Stokes and anti-Stokes parts of the Raman spectrum. Finally, we show how these results can be used to determine the orientation of individual QDs embedded in a polymer matrix. Polarized luminescence measurements have been performed on single QD emitters using confocal microscopy.",
        "watermark_text": "We report on the polarization dependent photoluminescence ( PL ) and Raman absorption spectra of CdSe / CdS core / shell quantum dots in solution at room temperature . The PL spectrum reveals that the emission is polarized along the direction perpendicular to the excitation light , which can be described by the selection rules for dipole changes between electronic states with various angular momenta .In addition we witness an anisotropic broadening of the Stokes linewidths as well as a dividing into two parts when exciting circularly polarized light . These effects are traced to the presence of exciton fine structure owing to spin - orbit bonding .We additionally find proof for a powerful atom - phonon interaction leading to phonon sidebands in both the Stokes and anti - Stokes parts of the Raman spectrum . Finally , we find how these results can be used to predict the orientation of different QDs integrated in a polymer matrix .Polarized luminescence measurements have been performed on single QD emitters using confocal microscopy .",
        "rewrite_text": "We present our findings on the polarization-dependent photoluminescence (PL) and Raman absorption spectra of CdSe/CdS core/shell quantum dots suspended in solution at room temperature. The PL spectrum indicates that the emission is polarized in a direction perpendicular to the excitation light, which can be explained by the selection rules governing dipole transitions between electronic states with varying angular momenta. Furthermore, we observe an anisotropic broadening of the Stokes linewidths, which divides into two components when subjected to circularly polarized light. These phenomena are attributed to the exciton fine structure resulting from spin-orbit coupling. Additionally, we provide evidence of a strong atom-phonon interaction that gives rise to phonon sidebands in both the Stokes and anti-Stokes regions of the Raman spectrum. Lastly, we demonstrate how these findings can be utilized to infer the orientation of different quantum dots incorporated into a polymer matrix. Polarized luminescence measurements have been conducted on individual quantum dot emitters using confocal microscopy.",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 5.5,
        "rewrite-fast-z-score": 0.7385489458759964
    },
    {
        "original_text": "The future neutrino factory experiments will be able to search for new physics beyond the Standard Model (SM) with unprecedented precision, and are expected to provide important information on the origin of matter-antimatter asymmetry as well as dark matter candidates.  In this talk I will present an overview of our recent studies on how to probe various types of new physics using these facilities. The results presented here were obtained by combining the analyses performed at the T2K experiment and its off-axis near detector ND280. These include searches for sterile neutrinos, lepton flavor violating processes such as neutrinoless double beta decay, CP violation effects in leptonic sector, and exotic Higgs bosons that can couple to both quarks and leptons. We also discuss possible improvements in sensitivity which may be achieved if we combine the data taken at T2K and NOvA experiments. Finally, prospects for probing new physics at future accelerator-based neutrino factories are discussed.",
        "watermark_text": "The future neutrino plant experiments will be possible to search for fresh physics beyond the Standard Model ( SM ) with incredible clarity , and are expected to provide important information on the origin of matter - antimatter asymmetry as well as dark matter candidates . In this talk I will present an overview of our latest studies on how to probe various types of new science using these facilities .The results presented here were obtained by combining the calculations performed at the T2K experiment and its off - axis near sensor ND280 . These include searches for sterile neutrinos , lepton flavor violating reactions such as neutrinoless single gamma decay , CP violation processes in leptonic sector , and rare Higgs bosons that can couple to both quarks and leptons .We also discuss possible changes in sensitivity which would be obtained if we merge the information taken at T2K and NOvA studies . Finally , prospects for probing novel physics at possible accelerator - based neutrino farms are discussed .",
        "rewrite_text": "Future experiments at neutrino facilities will enable a clear exploration of new physics beyond the Standard Model (SM), offering crucial insights into the origin of matter-antimatter asymmetry and potential dark matter candidates. In this presentation, I will provide an overview of our recent investigations into how these facilities can be utilized to explore various types of new scientific phenomena. The results I will share are derived from combining calculations conducted at the T2K experiment with data from its off-axis near detector, ND280. Our studies include searches for sterile neutrinos, lepton flavor violating processes such as neutrinoless single gamma decay, CP violation in the lepton sector, and the discovery of rare Higgs bosons that can interact with both quarks and leptons. Additionally, we will examine potential changes in sensitivity that could result from combining data from T2K and NOvA studies. Finally, prospects for investigating novel physics at potential accelerator-based neutrino facilities will also be discussed.",
        "ori-fast-z-score": -0.23570226039551587,
        "water-fast-z-score": 5.656854249492381,
        "rewrite-fast-z-score": 0.9428090415820635
    },
    {
        "original_text": "We study the phenomenological consequences of general speed of sound in brane inflationary models, where the inflaton is identified as the distance between two parallel branes moving on an extra dimension. We find that for small values of the speed of sound (cs < 0.1), there are no significant changes to the predictions made by standard slow-roll inflation. However, when cs > 0.1 we find that the tensor-to-scalar ratio r and the running of the spectral index dns/d ln k can be significantly enhanced compared to their usual values predicted within the context of single field slow roll inflation. In particular, if cs = 1 then r = 16(nT)2/5 and dns/d ln k = −8(nT)1/5, which may provide a possible explanation for recent observations of high value of nT reported by WMAP7 data combined with other CMB experiments.",
        "watermark_text": "We explore the phenomenological consequences of general velocity of noise in brane inflationary theories , where the inflaton is identified as the distance between two connected branes moving on an additional dimension . We see that for little values of the speed of noise ( cs < 0 . 1 ) , there are no major changes to the estimates made by traditional slow - roll inflation .However , when cs > 0 . 1 we find that the tensor - to - scalar ratio p and the running of the spectral index dns / d ln k can be substantially enhanced compared to their conventional estimates predicted within the context of double field fast roll inflation . In particular , if cs = 1 then r = 16 ( nT ) 2 / 5 and dns / d ln k = −8 ( nT ) 1 / 5 , which would offer a possible reason for recent observations of high value of nT reported by WMAP7 results coupled with other CMB experiments .",
        "rewrite_text": "We investigate the phenomenological implications of general noise velocity in brane inflationary theories, where the inflaton corresponds to the distance between two connected branes moving in an extra dimension. Our analysis shows that for small noise speeds (cs < 0.1), traditional slow-roll inflation estimates remain largely unaffected. However, when cs exceeds 0.1, we observe a significant enhancement in the tensor-to-scalar ratio (r) and the running of the spectral index (dns/d ln k) compared to conventional predictions from double field fast-roll inflation. Specifically, if cs = 1, we find that r = 16(nT)²/5 and dns/d ln k = -8(nT)¹/5, which may help explain the recent high values of nT reported by WMAP7 and other CMB experiments.",
        "ori-fast-z-score": -0.5163977794943222,
        "water-fast-z-score": 5.249512077248736,
        "rewrite-fast-z-score": 1.2362450755382013
    },
    {
        "original_text": "We present evidence for dark matter annihilation in the cosmic microwave background (CMB) haze, which is an excess emission at large angles with respect to the Galactic center that was first detected by Wilkinson Microwave Anisotropy Probe (WMAP). We use data from Planck and Fermi Large Area Telescope (LAT), as well as new measurements of the CMB temperature anisotropies made using the Atacama Cosmology Telescope (ACT).\nThe observed spectrum of this signal can be explained if it originates from dark matter particles with masses between 1 GeV and 10 TeV, annihilating into pairs of photons or leptons. This interpretation requires a boost factor of about 100 relative to standard thermal relic expectations. \n \n If confirmed, our results would provide strong support for models where dark matter self-annihilates into Standard Model particles. They also have important implications on the nature of dark matter itself, since they require either non-thermal production mechanisms or additional interactions beyond those predicted within the minimal supersymmetric extension of the Standard Model.",
        "watermark_text": "We present evidence for black material annihilation in the cosmic microwave background ( CMB ) fog , which is an excess emission at large angles with regard to the Galactic center that was first detected by Wilkinson Microwave Anisotropy Probe ( WMAP ) . We use data from Planck and Fermi Large Area Telescope ( LAT ) , as well as new studies of the CMB altitude anisotropies made using the Atacama Cosmology Telescope ( ACT ) .The observed spectrum of this signal can be understood if it originates from dark matter molecules with masses between 1 GeV and 10 TeV , annihilating into sets of photons or leptons . This interpretation needs a boost factor of about 100 compared to standard temperature relic estimates .If confirmed , our findings would offer strong evidence for models where bright particles self - annihilates into Standard Model particles . They especially have important implications on the nature of bright matter itself , since they demand either non - temperature generation pathways or additional interactions beyond those predicted within the minimal supersymmetric extension of the Standard Model .",
        "rewrite_text": "We provide evidence for black material annihilation in the cosmic microwave background (CMB) fog, characterized by excess emission at large angles relative to the Galactic center, first observed by the Wilkinson Microwave Anisotropy Probe (WMAP). Our analysis incorporates data from the Planck satellite and the Fermi Large Area Telescope (LAT), along with new investigations of CMB altitude anisotropies conducted with the Atacama Cosmology Telescope (ACT). The spectrum of this observed signal suggests it originates from dark matter molecules with masses ranging from 1 GeV to 10 TeV, which annihilate into pairs of photons or leptons. This interpretation requires a boost factor of approximately 100 compared to standard relic temperature estimates. If validated, our results would provide compelling support for models in which bright particles self-annihilate into Standard Model particles. Additionally, this finding could have significant implications for the nature of bright matter itself, indicating the need for non-thermal generation mechanisms or additional interactions beyond those anticipated in the minimal supersymmetric extension of the Standard Model.",
        "ori-fast-z-score": 0.7276068751089989,
        "water-fast-z-score": 5.578319375835658,
        "rewrite-fast-z-score": 0.819288030372914
    },
    {
        "original_text": "We present the results of an analysis of data on advanced potentials in hadronic collisions at high energies, obtained by the TOTEM experiment at LHC and by the UA7 collaboration at SppS collider. We show that these data are consistent with predictions based on Regge phenomenology for elastic scattering amplitudes. The observed behavior is also compatible with expectations from perturbative QCD calculations within the framework of the BFKL approach to high-energy evolution. \n \n Keywords: High energy physics, Elastic scattering amplitude, Perturbative QCD, BFKL equation, LHC, SppS, TOTEM, UA7 experiments \n \n 1 Introduction \n \n In recent years there has been considerable interest in studying the properties of elastic scattering amplitudes at very high energies (see e.g.,  1  ). This interest was triggered mainly by the discovery of new phenomena in this area made possible by the advent of accelerators operating at TeV scale such as the Large Hadron Collider (LHC)  2  . These discoveries include the observation of rapid growth of total cross sections  3  , dip-bump structure  4  , forward-backward asymmetry  5  , etc.. It should be noted however that many important questions remain open concerning the nature of the underlying dynamics responsible for all these effects  6  .\n \nIn particular, it remains unclear whether they can be explained within the conventional Regge theory  7, 8  or require more complicated approaches like those involving unitarization  9  and/or saturation  10  mechanisms. Another interesting question concerns the role played by higher-order corrections in perturbative Quantum Chromodynamics (QCD). Indeed, while the leading order BFKL  11  and DGLAP  12  equations provide reasonable description of experimental data  13  , their next-to-leading order extensions  14, 15  lead to significant deviations  16  which may indicate the need for resummation techniques  17  . \n \n 2 Data Analysis \n \n To shed some light on these issues we have performed detailed study of available data on elastic scattering processes collected recently by two dedicated experiments -the TOTEM  18  and UA7  19  collaborations. Both groups measured differential distributions dσ/d",
        "watermark_text": "We present the conclusion of an assessment of evidence on advanced potentials in hadronic collisions at high energies , obtained by the TOTEM study at LHC and by the UA7 collaboration at SppS collider . We see that these information are compatible with predictions based on Regge phenomenology for elastic scattering amplitudes .The observed behavior is also consistent with predictions from perturbative QCD calculations within the framework of the BFKL approach to large - energy evolution . Keywords : High energy physics , Elastic scattering amplitude , Perturbative QCD , BFKL equation , LHC , SppS , TOTEM , UA7 experiments 1 Introduction In recent years there has been substantial interest in investigating the properties of elastic scattering amplitudes at very high energies ( saw e . g . , 1 ) .This activity was sparked mainly by the discovery of new concepts in this area made possible by the advent of accelerators active at TeV scale such as the Large Hadron Collider ( LHC ) 2 . These finds feature the observation of rapid increase of complete cross sections 3 , dip - bump formation 4 , backwards - backward asymmetry 5 , etc . .It should be mentioned however that several important questions remain open concerning the nature of the fundamental interactions involved for all these influences 6 . In particular , it remains unsure whether they can be described within the standard Regge principle 7 , 8 or use more complicated approaches like those concerning unitarization 9 and / or saturation 10 mechanisms .Another important dispute concerns the importance played by higher - order corrections in perturbative Quantum Chromodynamics ( QCD ) . Indeed , while the led order BFKL 11 and DGLAP 12 equations offer reasonable explanation of theoretical data 13 , their next - to - leading order additions 14 , 15 lead to significant deviations 16 which would indicate the necessity for resummation methods 17 .2 Data Analysis To shed some light on these problems we have done thorough study of available data on elastic scattering systems collected lately by two dedicated studies - the TOTEM 18 and UA7 19 collaborations . Both groups recorded differential functions dσ / d",
        "rewrite_text": "We provide the conclusions from an assessment of evidence regarding the advanced potentials in hadronic collisions at high energies, as detailed in studies conducted by the TOTEM collaboration at the LHC and the UA7 collaboration at the SppS collider. Our findings indicate that these observations align with predictions derived from Regge phenomenology concerning elastic scattering amplitudes. Furthermore, the behavior observed is consistent with predictions from perturbative Quantum Chromodynamics (QCD) calculations within the BFKL framework for large-energy evolution. \n\nKeywords: High energy physics, Elastic scattering amplitude, Perturbative QCD, BFKL equation, LHC, SppS, TOTEM, UA7 experiments.\n\n1. Introduction \n\nIn recent years, there has been a growing interest in exploring the characteristics of elastic scattering amplitudes at extremely high energies. This surge in research was primarily driven by the emergence of novel concepts in the field, made possible by the operation of accelerators at the TeV scale, such as the Large Hadron Collider (LHC). Notable discoveries include the observation of rapidly increasing total cross sections, the formation of dip-bumps, and backward-backward asymmetry, among others. However, several significant questions persist concerning the fundamental interactions governing these phenomena. Specifically, it remains uncertain whether these interactions can be adequately explained by the standard Regge principle or if more complex approaches related to unitarization and saturation mechanisms should be employed. Additionally, there is ongoing debate regarding the role of higher-order corrections in perturbative Quantum Chromodynamics (QCD). While the leading-order BFKL and DGLAP equations provide a reasonable fit to theoretical data, their next-to-leading-order corrections introduce substantial discrepancies, suggesting a need for resummation techniques. \n\n2. Data Analysis \n\nTo gain further insights into these issues, we conducted an exhaustive analysis of the available data on elastic scattering systems recently gathered by the dedicated TOTEM and UA7 collaborations. Both teams recorded differential cross-sections \\( \\frac{d\\sigma}{dt} \\).",
        "ori-fast-z-score": -0.16783627165933782,
        "water-fast-z-score": 9.398831212922918,
        "rewrite-fast-z-score": 0.5107539184552492
    },
    {
        "original_text": "We present the results of first-principles calculations for structural, electronic, magnetic properties of LaMnO3 in its rhombohedral phase (R3c). We show that the local spin density approximation (LSDA) fails to reproduce correctly both the lattice constants and the band gap energy. The latter is underestimated by more than one order of magnitude as compared with experiment. In contrast, our self-consistent full-potential linearized augmented plane wave method gives good agreement between calculated and experimental values of these quantities. \n \n To understand better the origin of this discrepancy we have performed additional calculations using an effective tight-binding approach based on Wannier functions obtained within the framework of the LSDA+U formalism. Our analysis shows that the main reason why the LSDA fails to describe properly the electronic structure of LaMnO3 is due to strong hybridization effects which are not taken into account adequately within the standard LSDA scheme.",
        "watermark_text": "We present the conclusion of first - principles measurements for structural , electronic , magnetic properties of LaMnO3 in its rhombohedral phase ( R3c ) . We see that the local spin density algorithm ( LSDA ) fails to predict correctly both the crystal constants and the band gap energy .The latter is underestimated by more than one order of magnitude as compared with observation . In comparison , our self - consistent full - potential linearized augmented plane wave method gives excellent agreement between calculated and observation readings of these quantities .To understand better the origin of this discrepancy we have done additional calculations using an efficient tight - binding approach using on Wannier functions obtained within the framework of the LSDA + U formalism . Our study shows that the main explanation why the LSDA fails to explain adequately the optical composition of LaMnO3 is due to powerful hybridization factors which are not took into consideration appropriately within the standard LSDA scheme .",
        "rewrite_text": "We present the conclusions from first-principles measurements of the structural, electronic, and magnetic properties of LaMnO3 in its rhombohedral phase (R3c). Our findings indicate that the local spin density approximation (LSDA) does not accurately predict the crystal constants or the band gap energy; the latter is significantly underestimated by more than an order of magnitude compared to experimental observations. In contrast, our self-consistent full-potential linearized augmented plane wave method shows excellent agreement with these observed values. To further investigate the source of this discrepancy, we conducted additional calculations using an efficient tight-binding approach based on Wannier functions derived from the LSDA + U formalism. Our study reveals that the primary reason for the LSDA's inadequate description of the optical properties of LaMnO3 is the inadequate consideration of strong hybridization effects within the standard LSDA framework.",
        "ori-fast-z-score": -0.9299811099505543,
        "water-fast-z-score": 4.4174102722651325,
        "rewrite-fast-z-score": 0.1203858530857692
    },
    {
        "original_text": "We study gravitational interactions between two braneworlds, each with its own brane tension, by using an effective field theory approach that incorporates both Randall-Sundrum (RS) gravity and scalar-tensor theories. We show how this model can be used to describe the dynamics of binary systems such as double neutron stars or black holes. In particular we find that there are new resonant effects which occur when one object is much more massive than the other. These effects lead to large deviations from standard general relativity predictions for the orbital evolution of binaries containing compact objects. The results presented here may have important implications on our understanding of strong-field gravity phenomena like gravitational waves produced during mergers of supermassive black holes at galactic centers. Introduction: Gravitational wave observations will provide us with unprecedented information about the nature of gravity in the strongfield regime  1  . This has led to renewed interest in alternative models of gravity beyond Einstein s general relativity  2  , especially those inspired by string/M-theory  3  .\nIn recent years it was shown  4  -  8  that many interesting features of these models could be captured within the context of effective field theories where higher-dimensional fields propagate in extra dimensions  9  . One particularly successful class of models consists of so-called braneworld scenarios  10  , where Standard Model particles are confined to live on a four dimensional brane embedded in a five dimensional bulk space-time  11  . A number of authors  12  -  16  have studied the possibility of detecting signatures of braneworld physics through gravitational wave observations  17  -  20  .",
        "watermark_text": "We explore gravity interactions between two braneworlds , each with its own brane tension , by using an efficient field model approach that incorporates both Randall - Sundrum ( RS ) gravity and scalar - vector models . We see how this model can be used to explain the dynamics of binary systems such as double neutron galaxies or black holes .In particular we find that there are new resonant effects which occur when one object is much more massive than the other . These effects lead to large deviations from standard general relativity predictions for the orbital evolution of binaries containing compact elements .The results presented here possibly have important implications on our grasp of strong - field gravity phenomena like gravitational waves produced during mergers of supermassive black holes at galactic bases . Introduction : Gravitational wave surveys will provide us with tremendous knowledge about the nature of gravitational in the strongfield regime 1 .This has led to renewed development in possible models of gravitational beyond Einstein s general relativity 2 , particularly those influenced by string / M - theory 3 . In recent years it was shown 4 - 8 that several interesting features of these models could be captured within the context of effective field theories where greater - dimensional fields propagate in extra dimensions 9 .One especially prominent category of models includes of so - called braneworld scenarios 10 , where Standard Model particles are confined to live on a four dimensional brane embedded in a five dimensional bulk space - time 11 . A several of authors 12 - 16 have researched the prospect of detecting signatures of braneworld physics through gravity wave studies 17 - 20 .",
        "rewrite_text": "We investigate the gravitational interactions between two braneworlds, each characterized by its own brane tension, utilizing an efficient field model that incorporates both Randall-Sundrum (RS) gravity and scalar-vector models. This framework allows us to analyze the dynamics of binary systems, such as double neutron stars or black holes. Notably, we discover new resonant effects that arise when one object is significantly more massive than the other. These effects result in substantial deviations from the predictions of standard general relativity regarding the orbital evolution of binaries containing compact objects. Our findings could have significant implications for our understanding of strong-field gravitational phenomena, such as the gravitational waves generated during the mergers of supermassive black holes at the centers of galaxies. \n\nIntroduction: Gravitational wave observations promise to enhance our understanding of gravity in the strong-field regime. This has sparked renewed interest in developing models of gravity that extend beyond Einstein's general relativity, particularly those influenced by string or M-theory. Recent studies have demonstrated that many intriguing features of these models can be effectively described within the framework of effective field theories, where higher-dimensional fields propagate through extra dimensions. One notable category of these models includes braneworld scenarios, where Standard Model particles are confined to a four-dimensional brane embedded in a five-dimensional bulk spacetime. Several authors have explored the potential to detect signatures of braneworld physics through gravitational wave studies.",
        "ori-fast-z-score": 1.520526224699857,
        "water-fast-z-score": 6.887089370699352,
        "rewrite-fast-z-score": 0.9053574604251853
    },
    {
        "original_text": "We study the effect of random large-scale forcing on three-dimensional rotating stratified flows, using direct numerical simulations (DNS) with periodic boundary conditions. The flow is forced at large scales by adding to the momentum equation an external force that has zero mean but whose Fourier transform contains both positive and negative wavenumbers. We find that this type of forcing excites two distinct types of modes in the system: vortical and wave-like modes. Vortical modes are characterized by strong vertical motions concentrated near the center of the domain; they have low horizontal velocities and their kinetic energy decays rapidly as we move away from the center. On the other hand, wave-like modes are characterized by weak vertical motions distributed over larger regions of space; they have high horizontal velocities and their kinetic energies decay slowly or even increase slightly when moving away from the center. In addition, these waves can be either stationary or propagating horizontally depending on whether the forcing spectrum peaks at small or large horizontal wavenumber respectively.",
        "watermark_text": "We research the impact of random large - scale forcing on three - dimensional spinning stratified flows , using direct numerical simulations ( DNS ) with periodic border conditions . The flow is displaced at large scales by added to the velocity equation an external force that has zero mean but whose Fourier integral contains both negative and negative wavenumbers .We see that this form of forcing excites two different kinds of modes in the system : vortical and wave - like modes . Vortical modes are characterized by intense vertical motions confined near the center of the domain ; they have low vertical velocities and their kinetic power decays slowly as we move back from the center .On the other hand , wave - like modes are characterized by weak vertical motions spread over larger parts of space ; they have high vertical velocities and their kinetic energies decline slowly or even change slightly when moved away from the center . In addition , these currents can be either static or propagating vertically varying on whether the forcing spectrum peaks at small or large horizontal wavenumber respectively .",
        "rewrite_text": "We investigate the effects of random large-scale forcing on three-dimensional spinning stratified flows through direct numerical simulations (DNS) with periodic boundary conditions. The flow is perturbed at large scales by incorporating an external force into the velocity equation, which has a zero mean and includes both negative and positive wavenumbers in its Fourier spectrum. Our findings reveal that this type of forcing activates two distinct modes within the system: vortical modes and wave-like modes. Vortical modes are identified by strong vertical motions concentrated around the center of the domain; they exhibit low vertical velocities, and their kinetic energy diminishes gradually as one moves away from the center. In contrast, wave-like modes are characterized by weak vertical motions that are distributed over larger areas; these modes possess high vertical velocities, and their kinetic energies decrease slowly or may even remain relatively constant away from the center. Furthermore, these currents can either be static or propagating vertically, depending on whether the forcing spectrum is concentrated at small or large horizontal wavenumbers, respectively.",
        "ori-fast-z-score": -2.4379951240146283,
        "water-fast-z-score": 4.133991732024804,
        "rewrite-fast-z-score": 1.5554275420956378
    },
    {
        "original_text": "We present the first simultaneous broadband (0.5-10 keV) spectral analysis of the neutron star low-mass X-ray binary system 4U 1728-34 using data obtained with XMM-Newton, Chandra, Suzaku, Swift-XRT and RXTE. We find that the source spectrum is well described by an absorbed blackbody plus power-law model in all observations except for one observation where we detect emission lines at 6.7 and 7.1 keV which are consistent with being produced by highly ionized iron. The temperature of the blackbody component varies between 0.6-0.9 keV while its radius ranges between 3-7 km depending on whether or not the absorption column density was allowed to vary freely during fitting. In addition, we also found evidence for a soft excess below 1 keV in some of our spectra. Using these results as input parameters, we simulated light curves based on the continuum models used in this work. Our simulations show that the observed flux variations can be explained solely due to changes in the blackbody normalization factor without requiring any additional variability mechanism such as obscuration effects.",
        "watermark_text": "We present the first simultaneous broadband ( 0 . 5 - 10 keV ) spectral study of the neutron galaxy low - weight X - ray binary system 4U 1728 - 34 using data acquired with XMM - Newton , Chandra , Suzaku , Swift - XRT and RXTE . We see that the source spectrum is well described by an absorption blackbody plus energy - law theory in all experiments except for one observation where we perceive emission lines at 6 . 7 and 7 . 1 keV which are compatible with being produced by highly ionized iron .The temperature of the blackbody element changes between 0 . 6 - 0 . 9 keV while its radius varies between 3 - 7 kilometers depending on whether or not the absorption column thickness was allowed to vary freely during fitting . In addition , we also discovered evidence for a soft excess below 1 keV in some of our spectra .Using these results as input parameters , we modeled light patterns based on the continuum descriptions utilized in this research . Our simulations demonstrated that the seen flux variations can be described solely due to changes in the blackbody normalization coefficient without allowing any additional variability system such as obscuration effects .",
        "rewrite_text": "We present the first comprehensive simultaneous broadband spectral analysis (0.5 - 10 keV) of the low-mass X-ray binary system 4U 1728-34, utilizing data from XMM-Newton, Chandra, Suzaku, Swift-XRT, and RXTE. Our findings indicate that the source spectrum is generally well characterized by an absorbing blackbody model combined with energy law theory, except for one observation where we detected emission lines at 6.7 and 7.1 keV, likely linked to highly ionized iron. The temperature of the blackbody component ranges from 0.6 to 0.9 keV, while its radius fluctuates between 3 and 7 kilometers, contingent on whether the absorption column density was allowed to vary during fitting. Furthermore, we identified signs of a soft excess below 1 keV in some spectra. Using these findings as input parameters, we created light curve models based on the continuum descriptions derived in this study. Our simulations indicated that the observed flux variations can be accounted for solely by changes in the blackbody normalization coefficient, without requiring the inclusion of other variability mechanisms such as obscuration effects.",
        "ori-fast-z-score": -0.5698028822981898,
        "water-fast-z-score": 6.567206798038654,
        "rewrite-fast-z-score": -0.808290376865476
    },
    {
        "original_text": "We present an analysis of the transition between first stars and second stars, which are formed by gravitational collapse of primordial gas clouds with masses ranging from 10^4 M_sol to 10^6 M_sol.  We show that the formation rate of second stars is suppressed at redshifts z < 20 due to photoheating effects on the intergalactic medium (IGM). The suppression factor increases as redshift decreases because the IGM temperature rises more rapidly than its density. At lower redshifts, we find that the formation rates of both first and second stars increase sharply when the universe becomes reionized. This effect occurs because the ionizing photons produced during reionization heat up the surrounding neutral hydrogen atoms, thereby increasing their Jeans mass and suppressing fragmentation into smaller objects. Finally, we estimate the number densities of first and second stars using our model for star formation history. Our results suggest that second stars may be detectable via future surveys such as LSST or Euclid.",
        "watermark_text": "We present an assessment of the shift between first stars and second stars , which are created by gravitational decay of primordial liquid clouds with masses vary from 10 ^ 4 M _ sol to 10 ^ 6 M _ sol . We see that the formation rate of second stars is suppressed at redshifts z < 20 due to photoheating effects on the intergalactic medium ( IGM ) .The suppression ratio increases as redshift decreases because the IGM temperature rises more swiftly than its density . At lower redshifts , we find that the formation rates of both first and first stars increase dramatically when the universe becomes reionized .This phenomenon occurs because the ionizing photons created during reionization heat up the nearby neutral hydrogen atoms , thereby expanding their Jeans mass and suppressing fragmentation into bigger objects . Finally , we estimate the number densities of early and first stars using our model for star formation history .Our results propose that second stars would be detectable via upcoming polls such as LSST or Euclid .",
        "rewrite_text": "We provide an evaluation of the transition from first stars to second stars, which form from the gravitational collapse of primordial liquid clouds with masses ranging from \\(10^4 M_{\\odot}\\) to \\(10^6 M_{\\odot}\\). Our analysis reveals that the formation rate of second stars is inhibited at redshifts \\(z < 20\\) due to photoheating effects on the intergalactic medium (IGM). This suppression effect becomes more pronounced as the redshift decreases, as the temperature of the IGM rises more rapidly than its density. At lower redshifts, we observe a significant increase in the formation rates of both first and second stars coinciding with the reionization of the universe. This increase is attributed to ionizing photons generated during reionization, which heat nearby neutral hydrogen atoms, increasing their Jeans mass and reducing fragmentation into larger structures. Lastly, we estimate the number densities of early and first stars based on our model of star formation history. Our findings suggest that second stars could be observed in forthcoming surveys like LSST or Euclid.",
        "ori-fast-z-score": 0.11704114719613057,
        "water-fast-z-score": 5.7350162126103985,
        "rewrite-fast-z-score": 1.7556172079419585
    },
    {
        "original_text": "We present an analysis of the gravitational waveforms emitted by two neutron stars orbiting each other, and show that they can be used to detect violations of Lorentz invariance (LI). We consider both scalar-tensor theories with spontaneous breaking of LI as well as vector-tensor theories where LI is violated through the presence of a preferred reference frame. In these models we find that there are characteristic deviations from general relativity which lead to measurable differences between the observed gravitational waveform and those predicted within Einstein s theory. \n \n The detection of such deviations would provide strong evidence for new physics beyond standard model expectations. This could have important consequences on our understanding of fundamental interactions at high energies. For example, it may shed light on the origin of dark energy or even reveal the existence of extra dimensions of space-time. It also has implications for cosmology since many extensions of the Standard Model predict time variations of physical constants like Newton s constant G.",
        "watermark_text": "We present an assessment of the gravitational waveforms emitted by two neutron stars orbiting each other , and find that they can be used to identify violations of Lorentz invariance ( LI ) . We consider both scalar - vector models with spontaneous breaking of LI as well as vector - vector models where LI is enforced through the presence of a preferred source frame .In these models we find that there are characteristic deviations from general relativity which lead to measurable differences between the expected gravitational waveform and those predicted within Einstein s theory . The diagnosis of such deviations might give strong evidence for future physics beyond standard theory expectations .This might have important implications on our knowing of fundamental interactions at high energies . For instance , it could cast light on the origin of dark energy or actually expose the existence of extra dimensions of space - time .It additionally has implications for cosmology since several extensions of the Standard Model predict time variations of physical constants like Newton s constant G .",
        "rewrite_text": "We provide an evaluation of the gravitational waveforms produced by two neutron stars in mutual orbit and demonstrate their potential to detect violations of Lorentz invariance (LI). Our analysis encompasses both scalar-vector models that exhibit spontaneous breaking of LI and vector-vector models that maintain LI through the introduction of a preferred source frame. In these scenarios, we identify distinct deviations from general relativity that result in observable differences between the anticipated gravitational waveforms and those predicted by Einstein's theory. Detecting these discrepancies could offer compelling evidence for new physics beyond the traditional expectations of established theories. Such findings may have significant implications for our understanding of fundamental interactions at high energies, potentially illuminating the origins of dark energy or revealing the presence of extra dimensions in space-time. Additionally, this research is relevant to cosmology, as several extensions of the Standard Model suggest variations over time in physical constants, such as Newton's constant G.",
        "ori-fast-z-score": -0.4588314677411235,
        "water-fast-z-score": 5.505977612893481,
        "rewrite-fast-z-score": 0.11396057645963795
    },
    {
        "original_text": "The problem of finding the energy levels of an electron bound to a nucleus is one of the most important problems in physics, which has been studied for many years. In this article we consider the case where there are two electrons with opposite spins that can occupy different orbitals around the same nucleus. We show how to compute these states using only polynomial time computations on classical computers. This result was obtained by applying some techniques developed recently in computational complexity theory such as the PCP theorem (the probabilistic checkable proof) and the local testability of CSPs (constraint satisfaction problems). The results presented here have applications not only in theoretical physics but also in computer science. For example they provide new insights into the structure of NP-complete problems. Quantum mechanical systems play an essential role in modern physics. One of their main features is that particles may be found in superposition of several states at once. A famous example is Schrödinger s cat experiment  1  . Another feature is entanglement  2  , i.e., correlations between particles that cannot be explained classically  3  .\nIn this work we study the following problem: given a system consisting of N spin-1/2 particles, what is the ground state? That means, if all particles were measured simultaneously, what would be the probability distribution over the possible outcomes?\nWe will focus our attention on the simplest non-trivial case: two spin-½ particles occupying different orbitals around the nucleus  4  . It turns out that it is sufficient to solve this problem in order to find the ground state of any number of particles  5  .",
        "watermark_text": "The question of finding the power concentrations of an electron bound to a nucleus is one of the most important problems in physics , which has been studied for numerous years . In this article we define the case where there are two electrons with opposite spins that can occupy separate orbitals around the same nucleus .We see how to compute these states using only polynomial period computations on classical computers . This result was obtained by using some techniques established recently in computational complexity analysis such as the PCP conjecture ( the probabilistic checkable proof ) and the local testability of CSPs ( constraint satisfaction issues ) .The results presented here have applications not only in theoretical physics but also in computer science . For instance they give novel knowledge into the formation of NP - full problems .Quantum mechanical models play an essential part in modern physics . One of their major characteristics is that particles may be found in superposition of several states at once .A popular example is Schrödinger s cat experiment 1 . Another phenomenon is entanglement 2 , i . e . , correlations between particles that cannot be described classically 3 .In this research we study the following puzzle : given a system consisting of N spin - 1 / 2 particles , what is the ground state ? That implies , if all particles were measured simultaneously , what would be the probability distribution over the possible events ?We will focus our focus on the trivial non - trivial case : two spin - ½ particles occupying various orbitals around the atom 4 . It turns out that it is enough to solve this situation in order to find the ground state of any number of particles 5 .",
        "rewrite_text": "The problem of determining the power concentrations of an electron bound to a nucleus is a fundamental issue in physics that has been explored for many years. In this article, we focus on the scenario where two electrons with opposite spins occupy different orbitals around the same nucleus. We demonstrate how to calculate these states using polynomial-time computations on classical computers. This achievement builds on recent advancements in computational complexity theory, including concepts like the PCP conjecture (Probabilistically Checkable Proofs) and the local testability of constraint satisfaction problems (CSPs). The findings presented here have implications not only in theoretical physics but also in computer science, particularly in understanding NP-complete problems. Quantum mechanical models are central to modern physics, characterized by the ability of particles to exist in superpositions of multiple states simultaneously, as exemplified by Schrödinger's cat thought experiment. Additionally, phenomena such as entanglement illustrate correlations between particles that defy classical description. In this research, we investigate the following question: for a system of N spin-1/2 particles, what is the ground state? Specifically, if all particles were measured at once, what would the probability distribution of the outcomes look like? We will concentrate on the simple yet non-trivial case of two spin-1/2 particles in various orbitals around an atom, which, as it turns out, is sufficient to determine the ground state for any number of particles.",
        "ori-fast-z-score": -0.7242859683401482,
        "water-fast-z-score": 5.7272727272727275,
        "rewrite-fast-z-score": -0.19425717247145283
    },
    {
        "original_text": "In this work, we study angles between infinite dimensional subspaces in Hilbert spaces. We first introduce an angle measure for two closed linear operators on Hilbert spaces which is based on their resolvent kernels. Then we show that if one operator is compact then the angle measure coincides with the usual cosine of the angle between the range space of these operators. Finally, as applications of our results, we give some new characterizations of the convergence rate of the Rayleigh-Ritz method and the alternating projectors methods. The proofs are given by using the concept of angle measures introduced here. In particular, it turns out that the convergence rates of both methods depend only on the angles between the corresponding subspaces involved but not on any other properties such as dimensions or norms of those subspaces. This fact has been observed numerically before but never proved rigorously until now. It should be noted that all results presented here hold true also when the underlying Hilbert spaces are Banach spaces instead of just Hilbert spaces.",
        "watermark_text": "In this research , we study angles between infinite dimensional subspaces in Hilbert spaces . We first introduce an angle measure for two closed linear operators on Hilbert spaces which is based on their resolvent kernels .Then we prove that if one operator is compact then the angle measure coincides with the usual cosine of the angle between the range space of these operators . Finally , as applications of our findings , we give some fresh characterizations of the convergence frequency of the Rayleigh - Ritz approach and the alternating projectors methods .The proofs are given by using the idea of angle measures introduced here . In particular , it turns out that the convergence rates of both approaches rely only on the distances between the associated subspaces concerned but not on any other properties such as sizes or norms of those subspaces .This fact has been observed numerically before but none proved rigorously until now . It should be mentioned that all results presented here hold true also when the underlying Hilbert groups are Banach spaces rather of just Hilbert spaces .",
        "rewrite_text": "In this research, we examine the angles between infinite-dimensional subspaces within Hilbert spaces. We begin by defining a new angle measure for two closed linear operators on Hilbert spaces, derived from their resolvent kernels. We demonstrate that when one operator is compact, this angle measure aligns with the standard cosine of the angle between the ranges of these operators. Additionally, we apply our findings to provide new characterizations of the convergence rates for the Rayleigh-Ritz method and alternating projector methods. Our proofs utilize the angle measures established here. Notably, we find that the convergence rates for both methods depend solely on the distances between the relevant subspaces, rather than on any other attributes, such as their sizes or norms. Although this observation has been noted in numerical investigations previously, it has not been rigorously proven until now. It is important to note that all the results presented in this paper remain valid for Banach spaces, not just for Hilbert spaces.",
        "ori-fast-z-score": 1.697749375254331,
        "water-fast-z-score": 5.578319375835658,
        "rewrite-fast-z-score": 2.215646837627989
    },
    {
        "original_text": "We report the Langmuir Blodgett (LB) deposition of highly ordered, dense arrays of vertically-aligned single-walled carbon nanotube films on solid substrates using an aqueous dispersion containing surfactant and sodium dodecyl sulfate as dispersing agents. The LB technique is used to transfer these films onto various substrate materials such as silicon wafers, quartz slides, glass coverslips, gold-coated glass coverslips, and indium tin oxide coated glass coverslips. We have also demonstrated that this method can be extended for patterned growth by transferring the film selectively over areas defined by photoresist patterns. These results are important in developing new applications based on carbon nanotubes. \n \n Carbon nanotubes (CNTs), which were discovered about ten years ago, have attracted considerable attention because they possess unique physical properties including high electrical conductivity, mechanical strength, thermal stability, chemical inertness, etc., making them promising candidates for many potential applications ranging from field emission devices to sensors and optoelectronic devices1-5. However, most of their practical uses require CNT networks with controlled orientation and density6-8. In recent years, several methods have been developed to prepare oriented CNT films9-12. Among those techniques, Langmuir-Blodgett (LB)\ndeposition has emerged as one of the most powerful approaches13-15. This process involves spreading a monolayer of amphiphilic molecules at the air-water interface followed by vertical dipping of a hydrophobic substrate into the water subphase16-18. By repeating the above steps, multilayered thin films consisting of closely packed CNTs can be obtained19-21. Compared to other methods22-24, LB deposition offers advantages such as precise control of layer thickness25-27, easy fabrication of large-area uniform films28-30, and possibility of fabricating patterned structures31-33.",
        "watermark_text": "We report the Langmuir Blodgett ( LB ) precipitation of highly ordered , dense arrays of vertically - stacked single - walled carbon nanotube bands on solid substrates using an aqueous dispersion containing surfactant and potassium dodecyl sulfate as dispersing agents . The LB technique is utilized to move these films atop numerous substrate media such as silicon wafers , quartz slides , glass coverslips , platinum - glazed ceramic coverslips , and indium tin oxide coated glass coverslips .We have also demonstrated that this process can be improved for patterned expansion by directing the film selectively over areas defined by photoresist patterns . These results are important in building new applications based on carbon nanotubes .Carbon nanotubes ( CNTs ) , which were discovered about ten years previously , have garnered considerable scrutiny because they possess unique physical properties including high thermal conductivity , thermal strength , thermal stability , chemical inertness , etc . , making them promising candidates for numerous likely use ranging from field emission sensors to sensors and optoelectronic devices1 - 5 . However , most of their practical applications need CNT connections with restricted orientation and density6 - 8 .In recent years , various methods have been used to produce focused CNT films9 - 12 . Among those techniques , Langmuir - Blodgett ( LB ) exposure has emerged as one of the most popular approaches13 - 15 .This process involves spreading a monolayer of amphiphilic molecules at the air - water interface followed by vertical dipping of a hydrophobic substrate into the water subphase16 - 18 . By repeating the above steps , multilayered narrow films consisting of closely packed CNTs can be obtained19 - 21 .Compared to other methods22 - 24 , LB deposition gives benefits such as careful management of layer thickness25 - 27 , easy fabrication of large - area uniform films28 - 30 , and possibility of fabricating patterned structures31 - 33 .",
        "rewrite_text": "We present a report on the Langmuir-Blodgett (LB) deposition of highly organized, dense arrays of vertically stacked single-walled carbon nanotube bands on solid substrates using an aqueous dispersion that incorporates surfactants and potassium dodecyl sulfate as dispersing agents. The LB technique enables the transfer of these films onto various substrate materials, including silicon wafers, quartz slides, glass coverslips, platinum-glazed ceramic coverslips, and indium tin oxide-coated glass coverslips. Furthermore, we have shown that this method can be optimized for patterned expansion by selectively directing the film onto regions defined by photoresist patterns. These findings are significant for the development of new applications utilizing carbon nanotubes. Discovered approximately a decade ago, carbon nanotubes (CNTs) have attracted considerable attention due to their exceptional physical properties, including high thermal conductivity, strength, stability, and chemical inertness, making them promising candidates for a wide range of potential applications, from field emission sensors to optoelectronic devices. Nevertheless, many practical applications require CNTs to have controlled orientation and density. In recent years, various techniques have been explored for producing aligned CNT films. Among these, Langmuir-Blodgett (LB) deposition has gained popularity as an effective method. This technique involves spreading a monolayer of amphiphilic molecules at the air-water interface, followed by the vertical dipping of a hydrophobic substrate into the water subphase. By repeating this process, multilayered narrow films of densely packed CNTs can be achieved. Compared to other methods, LB deposition offers advantages such as precise control over layer thickness, simplicity in fabricating large-area uniform films, and the ability to create patterned structures.",
        "ori-fast-z-score": 1.660037707655972,
        "water-fast-z-score": 8.30018853827986,
        "rewrite-fast-z-score": 1.6352596350653539
    },
    {
        "original_text": "We report on X-ray timing observations of the pulsar candidate PSR J1930+1855 located at the center of the supernova remnant (SNR) G54.1+0. \n \n The source was discovered by Chandra and confirmed as a pulsar with XMM-Newton, but its spin period is not stable over time scales longer than one day. We performed two sets of pointed RXTE observations to study this behavior further. In both cases we found that the pulse frequency decreases smoothly during our observation runs. This trend can be described well using an exponential decay model for which we find characteristic timescales of 1.1 days and 0.7 days respectively. These values are consistent with those reported previously based on Chandra data alone. However, when comparing these results directly it should be noted that the uncertainties associated with the previous measurements were significantly larger due to the lower signal-to-noise ratio achieved with Chandra compared to RXTE.",
        "watermark_text": "We report on X - ray timing observations of the pulsar candidate PSR J1930 + 1855 centered at the center of the supernova remnant ( SNR ) G54 . 1 + 0 . The source was studied by Chandra and reported as a pulsar with XMM - Newton , but its spin time is not stable over time ranges shorter than one month .We conducted two sets of pointed RXTE observations to study this behavior further . In both cases we concluded that the heartbeat rate decreases slowly during our observation running .This trend can be described good using an exponential decay model for which we find typical timescales of 1 . 1 days and 0 . 7 weeks respectively . These quantities are compatible with those noted earlier based on Chandra data alone .However , when comparing these results directly it should be mentioned that the uncertainties involved with the previous tests were significantly larger thanks to the smaller signal - to - noise proportion attained with Chandra compared to RXTE .",
        "rewrite_text": "We present X-ray timing observations of the pulsar candidate PSR J1930+1855, located within the supernova remnant G54.1+0. This source was previously identified as a pulsar by Chandra and examined with XMM-Newton, but its spin period has shown instability over timescales shorter than one month. To investigate this behavior further, we conducted two sets of pointed RXTE observations. Our findings indicate that the pulse frequency gradually decreases during the observation periods. This trend can be effectively described using an exponential decay model, yielding characteristic timescales of 1.1 days and 0.7 weeks, respectively. These values align with those obtained from earlier Chandra observations; however, it is important to note that the uncertainties in previous measurements were significantly larger due to a lower signal-to-noise ratio achieved with Chandra compared to RXTE.",
        "ori-fast-z-score": 0.4923659639173309,
        "water-fast-z-score": 6.719319439596787,
        "rewrite-fast-z-score": 1.0327955589886444
    },
    {
        "original_text": "We present the results of numerical simulations aimed at studying the formation and evolution of off-center ionized hydrogen (HII) regions around massive stars embedded in an isothermal, self-gravitating gas distribution with a power-law density profile.  We find that the expansion velocity of the ionization front decreases as it moves away from the star s position towards larger radii. The decrease occurs because the pressure gradient becomes smaller when moving outward due to the decreasing density. As a result, the ionization front may become unstable against small perturbations which lead to its fragmentation into several blobs or fingers. These blobs are surrounded by dense shells of neutral material produced by photo-evaporation of the surrounding medium. In addition, we show that the mass loss rate increases significantly for large values of the index n of the power law density distribution. This increase can be explained by the fact that the gravitational force per unit volume acting on the shell decreases faster than the ram pressure of the expanding bubble.",
        "watermark_text": "We present the conclusion of computational simulations aiming at studying the formation and evolution of off - center ionized hydrogen ( HII ) areas around large stars exposed in an isothermal , self - gravitating gas distribution with a power - law density profile . We see that the expansion velocity of the ionization front decreases as it travels away from the star s position towards higher radii .The reduction appears because the pressure gradient becomes lower when moved outward owing to the decreasing volume . As a result , the ionization front may grow unstable against small perturbations which lead to its fragmentation into numerous blobs or fingers .These blobs are surrounded by dense shells of neutral material created by photo - evaporation of the nearby medium . In addition , we find that the mass loss rate grows significantly for large values of the index n of the power law density function .This increase can be described by the fact that the gravitational pressure per unit volume acting on the shell decreases quicker than the ram tension of the expanding bubble .",
        "rewrite_text": "We present the findings of computational simulations that investigate the formation and evolution of off-center ionized hydrogen (HII) regions surrounding massive stars in an isothermal, self-gravitating gas with a power-law density distribution. Our results indicate that the expansion velocity of the ionization front decreases as it moves outward from the star towards larger radii. This decrease occurs because the pressure gradient diminishes as it extends outward due to the reduced volume. Consequently, the ionization front can become unstable to small perturbations, leading to its fragmentation into numerous blobs or fingers. These blobs are encased in dense shells of neutral material formed by the photo-evaporation of the surrounding medium. Additionally, we observe a significant increase in the mass loss rate for larger values of the index n in the power-law density function. This increase can be attributed to the fact that the gravitational pressure per unit volume acting on the shell diminishes more rapidly than the ram pressure of the expanding bubble.",
        "ori-fast-z-score": -1.1659976680069961,
        "water-fast-z-score": 4.050813610756598,
        "rewrite-fast-z-score": -0.6625891564490792
    },
    {
        "original_text": "We present the renormalization group flow equations for quantum gauge fields on curved spacetime, including fermions and scalars as well as their interactions with gravity. We show that these flows are governed by an exact functional differential equation which is derived using the background field method. The solution to this equation yields all possible counterterms needed to render the theory finite at any order in perturbation theory. This result generalizes previous results obtained within the context of flat space-time. In particular we find that the beta functions for the gravitational couplings do not vanish even if one considers only pure Yang-Mills theories without matter fields. Furthermore, our analysis shows that the running of the gravitational coupling constants can be determined completely in terms of the beta functionals associated with the non-gravitational sectors. Finally, we discuss how our formalism may be used to study the effects of radiative corrections on black hole entropy. Introduction: Gauge theories play a central role in modern particle physics. They provide a description of fundamental forces such as electromagnetism or weak nuclear force. However, it has been known since the early days of QED (quantum electrodynamics) that perturbatively quantizing gauge theories leads to ultraviolet divergences. These divergences have to be removed by adding appropriate local counterterms to the classical action. It turns out that there exist infinitely many different ways to add these counterterms so that the resulting effective action remains invariant under the original gauge symmetry transformations. Therefore, the choice of the correct set of counterterms depends crucially on the regularization scheme chosen to regulate the infinities appearing during the calculation of Feynman diagrams. For example, in dimensional regularization  1  , where the number of dimensions is taken to be d = 4 − 2ε instead of four, the most general form of the counterterm Lagrangian reads  2  \nwhere F µν denotes the electromagnetic field strength tensor and D µ ≡ ∂ µ + ieA µ . Here e denotes the electric charge while c 1 , c 2 , . . . denote arbitrary coefficients whose values depend on the specific regularization scheme employed.",
        "watermark_text": "We introduce the renormalization group flow equations for quantum gauge fields on curved spacetime , particularly fermions and scalars as well as their interactions with gravity . We see that these flows are governed by an precise functional differential equation which is calculated using the background field process .The answer to this equation yields all possible counterterms needed to make the theory finite at any order in perturbation theory . This result generalizes earlier findings obtained within the context of flat space - time .In particular we find that the beta functions for the gravitational couplings do not vanish even if one studies only true Yang - Mills theories without matter fields . Furthermore , our analysis shows that the running of the gravitational coupling constants can be determined absolutely in terms of the beta functionals associated with the non - gravitational sectors .Finally , we explain how our formalism may be used to study the effects of radiative corrections on dark hole entropy . Introduction : Gauge systems play a central role in modern particle theory .They offer a description of fundamental forces such as electromagnetism or weak nuclear force . However , it has been known since the early days of QED ( quantum electrodynamics ) that perturbatively quantizing gauge fields leads to ultraviolet divergences .These divergences have to be removed by added appropriate local counterterms to the classical operation . It turns out that there remain infinitely many various ways to addition these counterterms so that the resulting effective act remains invariant under the original gauge symmetry transformations .Therefore , the selection of the appropriate group of counterterms depends crucially on the regularization scheme chosen to govern the infinities appearing during the determination of Feynman diagrams . For instance , in dimensional regularization 1 , where the number of dimensions is taken to be d = 4 − 2ε instead of four , the most general form of the counterterm Lagrangian reads 2 where F µν denotes the electromagnetic field intensity tensor and D µ ≡ ∂ µ + ieA µ .Here e denotes the electric current while c 1 , c 2 , . .. represent arbitrary coefficients whose values rely on the specific regularization scheme employed .",
        "rewrite_text": "We present the renormalization group flow equations for quantum gauge fields in curved spacetime, focusing on fermions, scalars, and their interactions with gravity. These flow equations are governed by a precise functional differential equation derived from the background field method. The solution to this equation provides all the necessary counterterms required to ensure the theory is finite at any order in perturbation theory. This result extends previous findings from the context of flat spacetime. Notably, we discover that the beta functions for gravitational couplings do not vanish, even when considering pure Yang-Mills theories without matter fields. Additionally, our analysis reveals that the evolution of gravitational coupling constants can be wholly determined by the beta functionals related to the non-gravitational sectors. Finally, we outline how our formalism can be utilized to investigate the impact of radiative corrections on the entropy of dark holes.\n\nIntroduction: Gauge systems are fundamental to contemporary particle theory, providing a framework for understanding essential forces such as electromagnetism and the weak nuclear force. However, it has been recognized since the early days of quantum electrodynamics (QED) that the perturbative quantization of gauge fields leads to ultraviolet divergences. These divergences must be addressed by introducing suitable local counterterms into the classical action. It turns out there are infinitely many ways to introduce these counterterms while preserving the invariance of the resulting effective action under the original gauge symmetry transformations. Consequently, the choice of the appropriate set of counterterms is heavily dependent on the regularization scheme employed to handle the infinities that arise during the evaluation of Feynman diagrams. For instance, in dimensional regularization, where the number of dimensions is defined as \\(d = 4 - 2\\epsilon\\) instead of four, the most general form of the counterterm Lagrangian can be expressed, with \\(F_{\\mu\\nu}\\) representing the electromagnetic field strength tensor and \\(D_{\\mu} \\equiv \\partial_{\\mu} + ieA_{\\mu}\\), where \\(e\\) is the electric charge, and \\(c_1, c_2, \\ldots\\) denote arbitrary coefficients that depend on the specific regularization scheme applied.",
        "ori-fast-z-score": 1.3567477035949578,
        "water-fast-z-score": 7.692600381465998,
        "rewrite-fast-z-score": 2.574409875465939
    },
    {
        "original_text": "We study the random spatial growth in two dimensions, where new sites are added to an initially empty square lattice at randomly chosen locations and grow into circular clusters if they do not hit any existing cluster or obstacle site.  We show that this process leads to fractal structures which can be characterized by their fractal dimension Df = 1 + (1 - p)/2p, where p is the probability for adding a new site without hitting an obstacle. The results agree well with numerical simulations. \nPACS numbers: 05.40.+j, 64.60.Cn, 68.35.-k \nI. INTRODUCTORY REMARK\nIn recent years there has been considerable interest in studying various aspects of the so-called Eden model  1  . In its original formulation it describes the growth of a single cluster on a two-dimensional substrate starting from one seed particle. This simple concept was later generalized to include several seeds  2  , as well as different shapes  3  .\nThe present work deals with another generalization of the Eden model: Instead of growing only one cluster we consider the simultaneous growth of many clusters competing for space  4  . As a result, some clusters may become trapped between other clusters leading to a complex pattern formation.",
        "watermark_text": "We research the random spatial growth in two dimensions , where new sites are adding to an initially vacant rectangular matrix at randomly picked areas and grow into circular groups if they do not hit any original cluster or obstacle site . We see that this process results to fractal structures which can be described by their fractal dimension Df = 1 + ( 1 - p ) / 2p , where p is the probability for adding a new site without hits an barrier .The results agree well with numerical simulations . PACS scores : 05 . 40 . + j , 64 . 60 . Cn , 68 . 35 . - k I .INTRODUCTORY REMARK In recent years there has been substantial interest in studying several elements of the so - called Eden model 1 . In its initial formulation it assumes the development of a single cluster on a two - dimensional substrate beginning from one seed particle .This basic concept was afterwards generalized to consider many seeds 2 , as well as varying shapes 3 . The present work deals with another generalization of the Eden model : Instead of growing only one cluster we define the concurrent development of several clusters battling for space 4 .As a result , some clusters might form trapped between other communities leading to a complex pattern formation .",
        "rewrite_text": "We investigate random spatial growth in two dimensions, where new sites are added to an initially empty rectangular matrix at randomly selected locations. These sites grow into circular clusters as long as they do not encounter any existing clusters or obstacles. This process yields fractal structures, characterized by a fractal dimension given by Df = 1 + (1 - p) / 2p, where p represents the probability of adding a new site without encountering a barrier. Our findings align well with numerical simulations. PACS codes: 05.40.+j, 64.60.Cn, 68.35.-k.\n\n**I. INTRODUCTION**  \nIn recent years, there has been significant interest in exploring various aspects of the Eden model. The original formulation describes the growth of a single cluster on a two-dimensional substrate starting from a single seed particle. This foundational concept has since been broadened to include multiple seeds as well as different shapes. The present study addresses another extension of the Eden model: rather than growing just one cluster, we examine the simultaneous development of several clusters competing for space. This interaction can lead some clusters to become trapped among others, resulting in a complex pattern of formation.",
        "ori-fast-z-score": -0.20203050891044214,
        "water-fast-z-score": 6.464976285134148,
        "rewrite-fast-z-score": 1.2247448713915892
    },
    {
        "original_text": "We propose an alternative scenario for the evolution of our universe, which is based on the idea that the expansion rate of the universe may be driven by its curvature rather than dark energy. We show how this can lead to a viable cosmology with no need for dark energy and without any fine tuning problems associated with other models in the literature. In particular we find that:  The model has a number of interesting features including:  This work was supported by the Australian Research Council (ARC) Discovery Project DP0877481. Any opinions expressed are those of the authors only. 1 Introduction.\nThe discovery of accelerated cosmic expansion  1, 2  , as well as the recent detection of gravitational waves  3  have led to renewed interest in understanding the nature of gravity at large scales  4  . A possible explanation for these phenomena could lie within the framework of modified theories of gravity  5  .\nIn order to explain the observed acceleration of the universe it seems necessary to introduce some form of  dark energy   6  into Einstein s field equations  7, 8  . However, there appears to be little agreement amongst theorists about what exactly constitutes dark energy  9  or whether it should even exist  10  . Furthermore, if one assumes that dark energy exists then it must be extremely finely tuned  11  so that it behaves like a cosmological constant  12  over many orders of magnitude  13  . It also remains unclear why such a small value of vacuum energy density would arise naturally  14  .\nAnother possibility is that the apparent accelerating behaviour of the universe arises due to quantum effects  15  . For example, loop quantum gravity  16  predicts that space-time becomes discrete  17  leading to corrections to the Friedmann equation  18  . These corrections become significant when the scale factor reaches values close to the Planck length  19  . Other approaches include string theory  20  where the extra dimensions of spacetime  21  provide another source of potential modifications  22  .",
        "watermark_text": "We suggest an additional scenario for the evolution of our universe , which is based on the idea that the development frequency of the universe might be motivated by its curvature instead than dark energy . We see how this can lead to a viable cosmology with no requirement for black light and without any coarse tuning problems identified with other models in the literature .In particular we find that : The model has a number of interesting features including : This research was supported by the Australian Research Council ( ARC ) Discovery Project DP0877481 . Any views stated are those of the writers only .1 Introduction . The observation of rapid cosmic expansion 1 , 2 , as also as the recent discovery of gravitational waves 3 have led to renewed concern in understanding the nature of gravitational at large scales 4 .A potential explanation for these phenomena could lay within the framework of revised theories of gravitational 5 . In order to explain the known acceleration of the universe it appears necessary to introduce some kind of dark energy 6 into Einstein s field equations 7 , 8 .However , there seems to be little consensus amongst theorists about what actually constitutes black light 9 or whether it should even exist 10 . Furthermore , if one suppose that dark energy occurs then it must be extremely finely tuned 11 so that it behaves like a cosmological factor 12 over numerous orders of magnitude 13 .It therefore remains unsure why such a small measure of vacuum energy density would occur naturally 14 . Another possibility is that the actual accelerating behaviour of the universe occurs due to quantum effects 15 .For instance , loop quantum gravitational 16 predicts that space - time remains discrete 17 leading to corrections to the Friedmann equation 18 . These corrections get significant when the scale factor passes values close to the Planck size 19 .Other approaches involve string theory 20 where the extra dimensions of spacetime 21 offer another source of potential modifications 22 .",
        "rewrite_text": "We propose a new scenario for the evolution of our universe, suggesting that its development frequency may be influenced by curvature rather than dark energy. This perspective could yield a viable cosmological model that operates without the need for \"black light\" and avoids the fine-tuning issues associated with other theoretical frameworks. Notably, our model exhibits several intriguing characteristics. This research was funded by the Australian Research Council (ARC) Discovery Project DP0877481, and the opinions expressed here are solely those of the authors. \n\n1. Introduction: Recent observations of rapid cosmic expansion and the discovery of gravitational waves have intensified interest in understanding gravitational dynamics at large scales. One possible explanation for these phenomena might reside in revised theories of gravity. To account for the observed acceleration of the universe, it seems necessary to introduce a form of dark energy into Einstein's field equations. However, there is significant debate among theorists regarding the nature of dark energy and whether it even exists. If dark energy is assumed to exist, it necessitates extreme fine-tuning in order to function as a cosmological constant across a wide range of scales. The natural occurrence of such a small vacuum energy density remains uncertain. An alternative explanation posits that the accelerating behavior of the universe may arise from quantum effects. For example, loop quantum gravity suggests that spacetime is discrete, leading to modifications in the Friedmann equation that become significant when the scale factor approaches values near the Planck scale. Other approaches, such as string theory, introduce additional dimensions of spacetime, which could provide further avenues for potential modifications.",
        "ori-fast-z-score": 0.3287979746107146,
        "water-fast-z-score": 9.308061022576076,
        "rewrite-fast-z-score": -0.2544566789039913
    },
    {
        "original_text": "We study the second-harmonic (SH) and third-harmonic (TH) generations in an inhomogeneously broadened cavity with two different resonance frequencies for fundamental wave (FW). We show that, when the intracavity FW intensity reaches its maximum value, both SHG and THG can be enhanced simultaneously by increasing the pumping rate or decreasing the detuning between the two modes. The enhancement is due to the fact that the nonlinear susceptibility becomes larger than zero at this point. This effect has been observed experimentally recently. \n \n In addition, we find that there exists another regime where only one type of harmonics can be generated efficiently while suppressing other types of harmonics. For example, if the intracavity FW field is tuned close to the lower mode frequency, then it will generate mainly SH light but very little TH light; on the contrary, if the intracavty FW field is tuned near the upper mode frequency, then it generates mainly TH light but almost no SH light.",
        "watermark_text": "We test the second - harmonic ( SH ) and fifth - harmonic ( TH ) generations in an inhomogeneously broadened cavity with two different resonance energies for fundamental wave ( FW ) . We suggest that , when the intracavity FW frequency exceeds its highest value , both SHG and THG can be enhanced simultaneously by expanding the pumping rate or decreasing the detuning between the two modes .The enhancement is due to the fact that the nonlinear susceptibility grows larger than zero at this time . This phenomenon has been observed experimentally recently .In addition , we find that there exists another regime where only one kinds of harmonics can be generated smoothly while suppressing other types of harmonics . For instance , if the intracavity FW field is tuned close to the higher mode wavelength , then it will generate mostly SH light but very less TH radiation ; on the contrary , if the intracavty FW field is tuned near the higher mode wavelength , then it generates largely TH radiation but almost no SH light .",
        "rewrite_text": "We investigate the second-harmonic (SH) and fifth-harmonic (TH) generations within an inhomogeneously broadened cavity that features two distinct resonance energies for the fundamental wave (FW). We propose that when the intracavity FW frequency surpasses its maximum value, both SHG and THG can be simultaneously enhanced by increasing the pumping rate or reducing the detuning between the two modes. This enhancement occurs because the nonlinear susceptibility becomes greater than zero at that point, a phenomenon that has been observed in recent experiments. Additionally, we identify a different regime in which only one type of harmonic can be generated effectively while other harmonic types are suppressed. For example, if the intracavity FW field is adjusted to be close to the higher mode wavelength, it predominantly produces SH light with minimal TH radiation. Conversely, when the intracavity FW field is tuned near the lower mode wavelength, it generates significant TH radiation with almost no SH light produced.",
        "ori-fast-z-score": -1.889822365046136,
        "water-fast-z-score": 3.9056328877620143,
        "rewrite-fast-z-score": 0.12216944435630522
    },
    {
        "original_text": "We present an approach for self-organization in networks based on multi-agent systems (MAS). The proposed method is applied to two different networks: one with mobile nodes and another with static ones, both using IEEE 802.11b as their communication protocol. In this work we use agents that are able to move between neighboring nodes, which allows them to collect information about the state of each node. This information can be used by other agents to make decisions such as: moving to new positions or changing the transmission power level. We have implemented our proposal in NS-2 simulator and compared it against three well-known algorithms: OLSR, AODV and DSR. Our results show that MAS outperforms these protocols in terms of: packet delivery ratio, end-to-end delay and energy consumption. Keywords: Multi-Agent Systems, Self-Organizing Networks, Mobile Agents, Communication Protocols, Energy Consumption, Packet Delivery Ratio",
        "watermark_text": "We present an approach for self - organization in networks based on multi - agent systems ( MAS ) . The proposed approach is applied to two different organizations : one with mobile connections and another with static ones , both using IEEE 802 . 11b as their networking protocol .In this study we using agents that are able to move between neighboring nodes , which allows them to collect data about the state of each node . This knowledge can be used by other agents to make choices such as : moving to new positions or altering the transmission power level .We have incorporated our proposal in NS - 2 simulator and compared it against three well - famous method : OLSR , AODV and DSR . Our results show that MAS outperforms these protocols in terms of : message delivery ratio , end - to - end delay and energy consumption .Keywords: Multi-Agent Systems, Self-Organizing Networks, Mobile Agents, Communication Protocols, Energy Consumption, Packet Delivery Ratio",
        "rewrite_text": "We introduce a method for self-organization in networks utilizing multi-agent systems (MAS). This method is implemented within two distinct organizational structures: one featuring mobile connections and the other with static connections, both operating on the IEEE 802.11b networking protocol. In our study, we deploy agents capable of moving between adjacent nodes to gather data regarding the status of each node. This acquired information can be leveraged by other agents to make decisions, such as relocating to new positions or adjusting transmission power levels. We have integrated our approach into the NS-2 simulator and conducted a comparison with three well-known protocols: OLSR, AODV, and DSR. Our findings indicate that MAS surpasses these protocols concerning message delivery ratio, end-to-end delay, and energy consumption.  \n**Keywords:** Multi-Agent Systems, Self-Organizing Networks, Mobile Agents, Communication Protocols, Energy Consumption, Packet Delivery Ratio.",
        "ori-fast-z-score": 1.6378460497066512,
        "water-fast-z-score": 4.913538149119954,
        "rewrite-fast-z-score": 0.5
    },
    {
        "original_text": "Magnetic separation is an important tool in biomedical research and clinical diagnostics, but it has been limited to macroscopic devices that are not suitable for point-of-care applications. Here we report on continuous magnetophoresis-based blood cell sorting using microfluidics. We demonstrate efficient separation of red blood cells (RBCs) from plasma by applying a magnetic field gradient across a microchannel containing RBCs suspended in buffer solution. The results show that our method can be used as a simple yet effective approach for separating different types of blood cells with high purity and efficiency. This work may have significant implications towards developing portable diagnostic tools based on microscale blood processing technologies. Magnetic separation techniques play an important role in many fields including medicine, biotechnology, environmental science, food industry etc.,  1  . However, most existing methods require bulky equipment which makes them unsuitable for use outside laboratory settings  2  .\nRecently there has been growing interest in miniaturizing these systems into lab-on-a-chip platforms  3  , where various functionalities such as sample preparation  4  , chemical analysis  5  , drug delivery  6  , and bioassays  7  could be integrated onto one single chip. In particular, magnetic separators have attracted much attention due to their simplicity, low cost, portability, and compatibility with other microfabricated components  8  . For example, several groups have demonstrated magnetic separation of biological samples inside microchannels  9  -  11  or on planar surfaces  12  -  14  . Despite this progress, however, current approaches still suffer from some limitations. First, they typically rely on batch-wise operation mode  15  , which limits throughput and requires large volumes of input samples  16  . Second, the majority of reported designs only allow for separation between two distinct populations  17  , while more complex mixtures involving multiple species cannot be processed simultaneously  18  . Third, the fabrication process usually involves complicated multi-step procedures  19  , making it difficult to integrate additional functions  20  . Finally, most previous studies were performed under static conditions  21  , which limit the flexibility of device design  22  .",
        "watermark_text": "Magnetic isolation is an important tool in biomedical research and medical diagnostics , but it has been limited to macroscopic devices that are not suitable for point - of - care applications . Here we study on rapid magnetophoresis - based blood cell sorting using microfluidics .We suggest efficient removal of red blood cells ( RBCs ) from fluid by using a magnetic current gradient across a microchannel containing RBCs held in buffer solution . The results show that our technique can be used as a simple yet effective methods for dividing different kinds of blood tissue with high purity and efficiency .This research could have considerable consequences towards developing portable diagnostic methods using on microscale blood extraction technologies . Magnetic isolation machines play an important role in multiple fields including medicine , biotechnology , environmental science , nutrition industry etc . , 1 .However , most existing techniques require bulky machinery which makes them unsuitable for use outside laboratory settings 2 . Recently there has been growing interest in miniaturizing these systems into lab - on - a - chip platforms 3 , where various functionalities such as specimen processing 4 , chemical analysis 5 , pharmaceutical production 6 , and bioassays 7 could be merged onto one single chip .In particular , magnetic separators have garnered considerable scrutiny due to their simplicity , low cost , portability , and compatibility with other microfabricated parts 8 . For instance , various groups have demonstrated magnetic separation of biological samples inside microchannels 9 - 11 or on planar materials 12 - 14 .Despite this progress , however , current approaches still suffer from some restrictions . First , they generally rely on batch - wise operation mode 15 , which reduces throughput and requires large quantities of input samples 16 .Second , the majority of reported prototypes only require for isolation between two separate populations 17 , while more sophisticated mixtures featuring multiple taxa unable be processed concurrently 18 . Third , the fabrication process usually includes complicated multi - phase techniques 19 , making it difficult to connect extra functions 20 .Finally , most prior studies were performed under static conditions 21 , which reduce the flexibility of device configuration 22 .",
        "rewrite_text": "Magnetic isolation is a key technique in biomedical research and medical diagnostics, yet it has typically been confined to macroscopic devices that are unsuitable for point-of-care applications. In this study, we investigate rapid magnetophoresis-based blood cell sorting using microfluidics. We propose an efficient method for removing red blood cells (RBCs) from a fluid by applying a magnetic current gradient within a microchannel containing RBCs suspended in a buffer solution. Our findings indicate that this technique can serve as a straightforward and effective means of separating different types of blood cells with high purity and efficiency. This research has significant implications for developing portable diagnostic methods employing microscale blood extraction technologies. Magnetic isolation devices are integral to various fields, including medicine, biotechnology, environmental science, and the nutrition industry. However, most current techniques depend on bulky machinery, making them impractical for use outside of laboratories. Recently, there has been increased interest in miniaturizing these systems into lab-on-a-chip formats, which could integrate multiple functions such as specimen processing, chemical analysis, pharmaceutical production, and bioassays onto a single chip. Magnetic separators, in particular, have attracted attention for their simplicity, low cost, portability, and compatibility with other microfabricated components. Various studies have demonstrated magnetic separation of biological samples within microchannels or on planar materials. Despite these advancements, current methods face several limitations. Most rely on batch processing, which limits throughput and necessitates large sample volumes. Additionally, existing prototypes generally isolate only two distinct populations, while more complex mixtures containing multiple cell types cannot be processed simultaneously. Furthermore, the fabrication process often involves complicated multi-phase techniques, complicating the integration of additional functionalities. Lastly, previous research has predominantly been conducted under static conditions, limiting the versatility of device configurations.",
        "ori-fast-z-score": 0.5261522196019802,
        "water-fast-z-score": 9.838699100999074,
        "rewrite-fast-z-score": 2.864006223032628
    },
    {
        "original_text": "We have studied the dependence of growth rates for collisionless magnetic instabilities (CMIs) in nonrelativistic electron-ion plasmas with Maxwellian velocity distributions, using linear kinetic theory. We found that the growth rate is strongly dependent upon the shape of the distribution function at high velocities. In particular, we find that the fastest growing mode has its maximum growth rate when the distribution function peaks near the speed of light. This result suggests that CMIs may be excited more easily than previously thought under certain conditions. \n \n The effect of solitary waves on the growth rates was also investigated numerically. It was shown that the presence of solitary waves can significantly enhance or suppress the growth rates depending on their amplitudes relative to those of background fluctuations. These results are important because they show how nonlinear effects such as solitary wave generation affect the stability properties of plasma systems. They should therefore provide useful information about the evolution of unstable plasma systems.",
        "watermark_text": "We have researched the dependence of growth rates for collisionless magnetic instabilities ( CMIs ) in nonrelativistic electron - ion plasmas with Maxwellian velocity distributions , using linear kinetic theory . We showed that the development frequency is strongly dependent upon the morphology of the distribution function at high velocities .In particular , we find that the fastest growing mode has its highest growth speed when the distribution parameter peaks near the speed of light . This result suggests that CMIs might be excited more easily than previously thought under certain conditions .The impact of solitary waves on the development rates was also examined numerically . It was shown that the presence of solitary waves can significantly affect or resist the development rates depending on their amplitudes compared to those of background fluctuations .These conclusions are important because they show how nonlinear effects such as solitary wave generation affect the stability properties of plasma networks . They should therefore offer useful details about the evolution of unstable plasma networks .",
        "rewrite_text": "We have investigated how growth rates for collisionless magnetic instabilities (CMIs) in nonrelativistic electron-ion plasmas with Maxwellian velocity distributions depend on different factors, using linear kinetic theory. Our findings indicate that the growth frequency is significantly influenced by the shape of the distribution function at high velocities. Notably, we discovered that the mode with the fastest growth rate achieves its maximum growth speed when the distribution parameter peaks close to the speed of light. This suggests that CMIs may be more readily excited under certain conditions than previously believed. Additionally, we performed numerical assessments on the influence of solitary waves on development rates. Our results demonstrated that the presence of solitary waves can either enhance or inhibit development rates, depending on their amplitudes in relation to background fluctuations. These insights are crucial as they illustrate how nonlinear phenomena, such as solitary wave generation, impact the stability characteristics of plasma networks, thereby providing valuable information on the evolution of unstable plasma systems.",
        "ori-fast-z-score": 1.3251783128981585,
        "water-fast-z-score": 5.963302408041713,
        "rewrite-fast-z-score": 1.2939932784412609
    },
    {
        "original_text": "The space elevator is an important project in the field of aerospace engineering and has been studied for many years by scientists all over the world. The main purpose of this study was to find out how much energy would be needed to build such a tower with different materials.  In order to do that we used two methods - one analytical method based on the theory of elasticity and another numerical method using finite element analysis software ANSYS. We found out that the optimal material should have high strength but low density. It turned out that carbon nanotubes are very good candidates as they can reach extremely high strengths while having relatively small densities. This work will help us design better space elevators in the future. Keywords: Energy consumption, Carbon Nanotube, Optimum Material, Finite Element Analysis Software, Analytical Method, Elasticity Theory, Space Elevator. 1 Introduction   Space elevators are considered to be one of the most promising projects in the field of aeronautics and astronautics  1  . They could provide transportation between Earth orbit and ground level without any fuel consumption  2  , which makes them especially useful for transporting people or cargo  3  .\nIn recent decades there were several attempts made at building space elevators  4  . However none of these designs managed to become fully functional  5  . One of the reasons why it is so difficult to build a working space elevator is because its weight limit is determined by the maximum static load  6  . If the weight exceeds this value then the cable will sag under gravity  7  . Another problem is that the cables need to support their own weight  8  . Therefore if you want to make your space elevator lighter than air  9  , you must use some kind of counterweight  10  .",
        "watermark_text": "The space lift is an important project in the field of aviation design and has been studied for numerous years by scientists all over the world . The main aim of this study was to find out how many heat might be needed to build such a building with various materials .In order to do that we using two methods - one analytical method using on the principle of elasticity and another numerical technique utilizing finite element investigation software ANSYS . We determined out that the ideal structure should have high strength but little density .It turned out that carbon nanotubes are very perfect candidates as they can reach extremely high strengths while having relatively small densities . This effort will assist us design easier space elevators in the future .Keywords : Energy consumption , Carbon Nanotube , Optimum Material , Finite Element Analysis Software , Analytical Method , Elasticity Theory , Space Elevator . 1 Introduction Space lifts are considered to be one of the most exciting projects in the field of aeronautics and astronautics 1 .They could enable transportation between Earth orbit and land level without any fuel expenditure 2 , which makes them especially suitable for handling persons or cargo 3 . In recent generations there were several efforts made at building space elevators 4 .However none of these designs got to become completely functional 5 . One of the causes why it is so difficult to build a working space lift is because its weight limit is chosen by the maximum static load 6 .If the gravity reaches this limit then the line will sag under gravity 7 . Another difficulty is that the ropes require to support their own weight 8 .Therefore if you want to make your space lift lighter than air 9 , you must use some kind of counterweight 10 .",
        "rewrite_text": "The space lift represents a significant advancement in aviation design and has been the subject of extensive study by scientists globally for many years. The primary goal of this research was to determine the amount of heat required to construct such a structure using various materials. To achieve this, we employed two approaches: an analytical method based on the principles of elasticity and a numerical technique using the finite element analysis software ANSYS. Our findings indicated that the optimal design should combine high strength with low density. We discovered that carbon nanotubes are excellent candidates for this purpose, as they can achieve extremely high strengths while maintaining relatively low densities. This research will pave the way for the development of more efficient space elevators in the future. \n\n**Keywords**: Energy consumption, Carbon Nanotube, Optimum Material, Finite Element Analysis Software, Analytical Method, Elasticity Theory, Space Elevator.\n\n### 1. Introduction\n\nSpace lifts are regarded as one of the most promising projects in the realms of aeronautics and astronautics. They offer the potential for transportation between Earth orbit and ground level without fuel consumption, making them particularly advantageous for transporting people and cargo. In recent years, several attempts have been made to construct space elevators; however, none have been successfully operational. One of the primary challenges in building an effective space lift is that its weight limit is dictated by the maximum static load—exceeding this limit causes the line to sag due to gravity. Additionally, the ropes must be capable of supporting their own weight, complicating the design further. Consequently, to create a space lift that is lighter than air, a counterweight system is essential.",
        "ori-fast-z-score": 0.7986208584745025,
        "water-fast-z-score": 8.716463972623675,
        "rewrite-fast-z-score": -0.0873704056661038
    },
    {
        "original_text": "We present an analysis of the nonlocal phenomenology in magnetohydrodynamic (MHD) turbulence with strong magnetic field anisotropy, which is relevant to solar wind and space plasmas. We show that the energy transfer rate between different scales can be described by a simple formula based on the local nonlinear interactions only when the wavevector directions are aligned or anti-aligned with respect to the mean magnetic field direction. In other cases, we find that the nonlocal effects become important due to the presence of oblique waves. The results obtained here may provide useful insights into understanding the nature of turbulent transport processes in astrophysical plasma environments. Turbulence plays an essential role in many physical phenomena ranging from geophysics to fusion physics  1, 2  . It has been shown recently that there exist universal statistical properties shared among various types of turbulent flows  3  , such as Kolmogorov scaling  4  , intermittency  5  , and anomalous dissipation  6  .\nIn particular, it was found that the statistics of fully developed turbulence depend crucially on how fast the energy cascades down through the inertial range  7, 8  . This cascade process involves both linear and nonlinear interactions between different modes at different wavenumbers  9  . For example, in hydrodynamics, the energy flux Π(k) ≡< |δu k · δu * −k | 2 > / < u 2 k > depends not only on the magnitude of the wavenumber k but also its orientation relative to the large-scale flow  10  . Here, u k denotes the Fourier transform of velocity fluctuations at scale k −1 . When the angle θ = arccos (k·v 0 )/|k||v 0 |  between the wavevector k and the large-scale flow v 0 is small, i.e., θ ≪ 1, the energy flux Π ∝ k −2/3 sin 2/3 θ  11  . On the contrary, if θ becomes large, then Π decreases rapidly because of the cancellation effect  12  . Similar behaviors have been observed in magnetohydrodynamics (MHD), where the energy flux Π �",
        "watermark_text": "We present an analysis of the nonlocal phenomenology in magnetohydrodynamic ( MHD ) turbulence with powerful magnetic force anisotropy , which is relevant to solar wind and space plasmas . We see that the power transfer frequency between various scales can be described by a simple equation based on the local nonlinear interactions only when the wavevector directions are aligned or anti - aligned with regard to the mean magnetic field direction .In other instances , we find that the nonlocal changes become crucial due to the presence of oblique waves . The results collected here perhaps offer useful insights into knowledge the nature of turbulent transport systems in astrophysical plasma settings .Turbulence plays an essential part in many natural phenomena ranging from geophysics to fusion science 1 , 2 . It has been shown lately that there exist general statistical characteristics common among various types of turbulent waves 3 , such as Kolmogorov scaling 4 , intermittency 5 , and anomalous dissipation 6 .In particular , it was shown that the statistics of fully developed turbulence depend crucially on how fast the power cascades down through the inertial range 7 , 8 . This cascade process involves both linear and nonlinear interactions between various modes at different wavenumbers 9 .For instance , in hydrodynamics , the power flux Π ( k ) ≡ < | δu k · δu * −k | 2 > / < u 2 k > depends not only on the magnitude of the wavenumber k but also its attitude relative to the huge - scale stream 10 . Here , u k denotes the Fourier transform of velocity fluctuations at scale k −1 .When the angle θ = arccos ( k · v 0 ) / | p | | v 0 | between the wavevector k and the huge - scale stream v 0 is tiny , i . e . , θ [UNK] 1 , the power flux Π [UNK] k −2 / 3 sin 2 / 3 θ 11 . On the contrary , if θ becomes large , then Π decreases quickly because of the cancellation effect 12 .Similar relationships have been observed in magnetohydrodynamics ( MHD ) , where the energy flux Π",
        "rewrite_text": "We conduct an analysis of nonlocal phenomena in magnetohydrodynamic (MHD) turbulence characterized by strong magnetic force anisotropy, particularly relevant to solar wind and space plasmas. Our findings indicate that the frequency of power transfer across various scales can be explained by a straightforward equation based solely on local nonlinear interactions, provided that the directions of the wavevector align or oppose the mean magnetic field. However, nonlocal effects become significant in the presence of oblique waves. The insights gained from this study may enhance our understanding of turbulent transport within astrophysical plasma environments. Turbulence is a critical factor in a wide array of natural phenomena, ranging from geophysics to fusion science. Recent research has identified shared statistical features among different types of turbulent waves, such as Kolmogorov scaling, intermittency, and anomalous dissipation. Notably, the characteristics of fully developed turbulence are significantly influenced by the rate at which power cascades through the inertial range. This cascading process encompasses both linear and nonlinear interactions across various modes and wavenumbers. For example, in hydrodynamics, the power flux \\( \\Pi(k) \\equiv \\left< | \\delta u_k \\cdot \\delta u^*_{-k} |^2 \\right> / \\left< u^2_k \\right> \\) depends not only on the magnitude of the wavenumber \\( k \\) but also on its angle with respect to the large-scale flow. Specifically, when the angle \\( \\theta = \\arccos(k \\cdot v_0) / |p||v_0| \\) between the wavevector \\( k \\) and the large-scale flow \\( v_0 \\) is small (i.e., \\( \\theta \\approx 0 \\)), the power flux behaves like \\( \\Pi \\sim k^{-2/3} \\sin^{2/3}\\theta \\). In contrast, as \\( \\theta \\) increases, \\( \\Pi \\) rapidly decreases due to cancellation effects. Similar dynamics have been noted in magnetohydrodynamics (MHD), where the energy flux \\( \\Pi \\) follows analogous principles.",
        "ori-fast-z-score": -1.5888598190134724,
        "water-fast-z-score": 5.101076261043254,
        "rewrite-fast-z-score": -0.17025130615174972
    },
    {
        "original_text": "We study the second-order correlation function for an atom interacting with two modes of light, one resonant and another off-resonant to atomic transition frequency. We show that higher order antibunching can be observed when the atom is initially prepared in an excited state or ground state superposition. The effect is more pronounced if the initial state has some population on the excited state. This phenomenon may have applications in quantum information processing. \n \n Introduction:-In recent years there has been considerable interest in studying nonclassical properties of radiation fields generated by atoms  1  . In particular, it was shown that the photon statistics of such systems are governed by the first-order coherence function g (1) (τ)  2  , which describes bunching behavior at short times and anti-bunching at longer times  3  . It is well known that this property arises due to destructive interference between different pathways leading to emission of photons  4  .\nRecently, several authors studied the effects of spontaneous emission on the second-order correlation functions  5  -  8  . They showed that the presence of spontaneous emission leads to sub-Poissonian statistics  6 - 8  . However, these studies were restricted only to the case where the atom interacts with a single mode of field. On the other hand, many experiments involving atoms interacting simultaneously with multiple modes of electromagnetic field have also been performed  9  -  11  . For example, in Ref.  10  , the authors investigated the influence of vacuum fluctuations on the fluorescence spectrum of a three-level system driven by two laser beams. In addition, they found that the intensity noise of the emitted light depends strongly on the relative phase difference between the driving lasers. Motivated by these experimental results we consider here the problem of calculating the second-order correlation function of an atom interacting simultaneously with two modes of light  12  .",
        "watermark_text": "We test the second - order correlation function for an element interacting with two modes of light , one resonant and another off - resonant to atomic transition frequency . We see that higher order antibunching can be experienced when the atom is initially prepared in an excited state or ground state superposition .The phenomenon is more pronounced if the first state has some population on the excited state . This phenomenon might have applications in quantum information processing .Introduction : - In recent years there has been substantial interest in investigating nonclassical characteristics of radiation fields generated by atoms 1 . In particular , it was shown that the photon statistics of such systems are governed by the first - order coherence function h ( 1 ) ( τ ) 2 , which explains bunching behavior at short periods and pro - bunching at shorter times 3 .It is well established that this property originates due to destructive interference between various pathways leading to emission of photons 4 . Recently , various papers studied the effects of induced emission on the second - order correlation functions 5 - 8 .They showed that the presence of spontaneous emission contributes to sub - Poissonian statistics 6 - 8 . However , these experiments were restricted only to the case where the atom interacts with a single mode of field .On the other hand , many tests utilizing atoms interacting simultaneously with various modes of electromagnetic field have already been performed 9 - 11 . For instance , in Ref .10 , the authors explored the impact of vacuum fluctuations on the fluorescence spectrum of a three - level network driven by two laser beams . In addition , they reported that the frequency sound of the emitted light depends strongly on the relative phase change between the driving lasers .Motivated by these observation findings we mention here the question of calculating the second - order correlation function of an element interacting simultaneously with two modes of light 12 .",
        "rewrite_text": "We investigate the second-order correlation function for an atom interacting with two light modes—one resonant and the other off-resonant with respect to the atomic transition frequency. Our findings reveal that higher-order antibunching can occur when the atom is initially prepared in a superposition of the excited and ground states. This effect is especially pronounced when the initial state has a significant population in the excited state. Such phenomena could have potential applications in quantum information processing. \n\nIntroduction: In recent years, there has been considerable interest in exploring the nonclassical characteristics of radiation fields generated by atoms. Specifically, it has been demonstrated that the photon statistics of these systems are influenced by the first-order coherence function \\( h^{(1)}(\\tau) \\), which accounts for bunching behavior at short time intervals and pro-bunching at even shorter times. This behavior is largely attributed to destructive interference among various photonic emission pathways. Recent studies have investigated the effects of induced emission on second-order correlation functions, revealing that spontaneous emission contributes to sub-Poissonian statistics. However, these studies have been limited to scenarios where the atom interacts with a single mode of light. In contrast, numerous experiments have examined atoms interacting with multiple modes of the electromagnetic field. For instance, one study analyzed the influence of vacuum fluctuations on the fluorescence spectrum of a three-level system driven by two laser beams, noting that the frequency of the emitted light is significantly affected by the relative phase difference between the lasers. Inspired by these findings, we aim to calculate the second-order correlation function for an atom interacting with two light modes simultaneously.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.3484692283495345,
        "rewrite-fast-z-score": 1.5
    },
    {
        "original_text": "The nonlinear dynamics of phonon stimulated emission (PSE) is investigated for microwave solid-state resonators with nonautonomous phase-locked loop generators. The PSE process is described by means of an extended version of the Lang-Kobayashi model, which takes into account the influence of the external driving field on the gain medium and includes additional terms describing the effect of spontaneous emission noise. It has been shown that the presence of these new effects leads to significant changes in the behavior of the system under consideration as compared to autonomous systems. In particular, it was found that the generation of chaotic regimes becomes possible even at relatively small values of the pumping parameter. This fact can be used to develop novel types of chaos-based devices based on microwave solid-state oscillators. \n \n Keywords: Nonlinear dynamics; Chaos; Phase synchronization; Phonons; Microwave solid state oscillator. PACS: 42.65.Tt; 42.65.Pq; 42.65.Re",
        "watermark_text": "The nonlinear dynamics of phonon stimulated emission ( PSE ) is investigated for microwave solid - state resonators with nonautonomous phase - locked loop components . The PSE transition is characterized by means of an extended version of the Lang - Kobayashi model , which gives into consideration the impact of the external driving field on the gain medium and incorporates additional terms describing the impact of induced emission interference .It has been shown that the presence of these new changes leads to significant improvements in the attitude of the process under consideration as compared to autonomous systems . In particular , it was shown that the generation of turbulent regimes appears possible even at fairly little values of the pumping function .This fact can be used to develop new types of chaos - based units based on microwave solid - state oscillators . Keywords : Nonlinear dynamics ; Chaos ; Phase synchronization ; Phonons ; Microwave liquid state oscillator .PACS: 42.65.Tt; 42.65.Pq; 42.65.Re",
        "rewrite_text": "This study examines the nonlinear dynamics of phonon stimulated emission (PSE) in microwave solid-state resonators that include nonautonomous phase-locked loop components. The PSE transition is analyzed using an enhanced version of the Lang-Kobayashi model, which accounts for the effects of an external driving field on the gain medium and adds terms to represent the influence of induced emission interference. The findings indicate that these modifications lead to notable improvements in the process's behavior compared to autonomous systems. Notably, the research reveals that turbulent regimes can be generated even at relatively low pumping function values. This discovery has potential applications in the development of new types of chaos-based devices utilizing microwave solid-state oscillators. Keywords: Nonlinear dynamics; Chaos; Phase synchronization; Phonons; Microwave solid-state oscillator. PACS: 42.65.Tt; 42.65.Pq; 42.65.Re.",
        "ori-fast-z-score": -0.47140452079103173,
        "water-fast-z-score": 5.185449728701349,
        "rewrite-fast-z-score": 0.3611575592573076
    },
    {
        "original_text": "Gamma-ray bursts (GRBs) are the most energetic explosions in the universe, but their origin is still unknown. The leading model for GRB production involves two compact objects merging into one black hole and then exploding as a result of rapid accretion onto this black hole.  In this talk I will discuss how we can use gravitational waves to test this hypothesis by looking at the ringdown phase of these mergers. This is an exciting time for gravitational wave astronomy with Advanced LIGO/VIRGO starting taking data soon! \nI will also present some recent results on using gravitational waves to study neutron star mergers that may be related to short gamma ray bursts. Finally, I ll give you my personal perspective on what it takes to become a successful scientist today. My research interests include gravitational waves, astrophysics, cosmology, and particle physics. I m currently working at MIT Kavli Institute for Astrophysics and Space Research where I am part of the Gravitational Wave Cosmology Project.",
        "watermark_text": "Gamma - ray clusters ( GRBs ) are the most intense explosions in the universe , but their source is still unclear . The leading theory for GRB development involves two compact entities combining into one dark hole and then exploding as a result of rapid accretion onto this red hole .In this talk I will explain how we can using gravitational waves to test this hypothesis by searching at the ringdown phase of these mergers . This is an exciting day for gravitational wave astronomy with Advanced LIGO / VIRGO starting took data soon !I will also explain some latest findings on uses gravity signals to study neutron galaxy mergers that might be connected to short gamma radiation bursts . Finally , I ll offer you my personal perspective on what it takes to become a successful researcher today .My research interests cover gravitational waves , astrophysics , cosmology , and particle science . I m currently working at MIT Kavli Institute for Astrophysics and Space Research where I am member of the Gravitational Wave Cosmology Project .",
        "rewrite_text": "Gamma-ray bursts (GRBs) are among the most powerful explosions observed in the universe, yet their origins remain enigmatic. The prevailing theory suggests that GRBs occur when two compact objects merge to form a black hole, which then erupts due to rapid material accumulation onto the newly formed black hole. In this presentation, I will discuss how we can utilize gravitational waves to test this theory by examining the ringdown phase of such mergers. It’s an exciting time for gravitational wave astronomy, as Advanced LIGO and VIRGO are set to begin collecting data soon! I will also share some recent discoveries related to using gravitational signals to explore neutron star mergers, which may be linked to short gamma-ray bursts. Lastly, I will provide my personal insights on what it takes to thrive as a researcher in today’s scientific landscape. My research interests encompass gravitational waves, astrophysics, cosmology, and particle physics. I am currently affiliated with the MIT Kavli Institute for Astrophysics and Space Research, where I am part of the Gravitational Wave Cosmology Project.",
        "ori-fast-z-score": -0.11547005383792514,
        "water-fast-z-score": 6.581793068761733,
        "rewrite-fast-z-score": 0.4472135954999579
    },
    {
        "original_text": "We report the discovery of transient dust emission at mid-infrared wavelengths (5-20 microns) in two elliptical galaxies with active galactic nuclei (AGN). The observations were made using Spitzer Space Telescope s Infrared Array Camera and Multiband Imaging Photometer for Spitzer instruments over a period of several years. We find that the infrared luminosity is consistent with heating by AGN radiation or supernovae remnants within the central kpc region. This suggests that recent feedback energy release has been occurring in these cores. These results are important because they provide new evidence on how supermassive black holes grow through accretion onto their host galaxy centers. They also demonstrate the power of combining multiwavelength data to study the physical processes associated with nuclear activity. \n \n Keywords: Active galactic nucleus, Galaxy evolution, Mid-infrared, Nuclear starbursts \n \n 1. Introduction \n \n Supermassive black holes reside in the center of most massive galaxies. Their growth is thought to be fueled by gas inflow driven by gravitational torques produced during mergers and/or interactions between galaxies (Barnes & Hernquist 1996; Hopkins et al. 2006) . However, it remains unclear what happens after this fuel supply runs out. One possibility is that the black hole continues growing via radiatively inefficient accretion flows (Narayan & Yi 1994) , which may produce powerful winds and jets that can drive large-scale outflows into the surrounding interstellar medium (ISM) (Silk & Rees 1998; Di Matteo et al. 2005 ). Another possibility is that the black holes become dormant as the ISM becomes too hot to cool efficiently (Bower et al. 2006; Croton et al. 2006 ) until another merger event triggers renewed activity. Understanding the mechanisms responsible for shutting off black-hole growth will help us understand why some galaxies have large black holes while others do not. \n \n 2. Previous Work \n \n Several studies have shown that there exists an anti-correlation between the mass of the central supermassive black hole and the stellar velocity dispersion of its host galaxy bulge (Ferrar",
        "watermark_text": "We report the discovery of transient dust pollution at mid - infrared wavelengths ( 5 - 20 microns ) in two elliptical galaxies with active galactic nuclei ( AGN ) . The findings were made using Spitzer Space Telescope s Infrared Array Camera and Multiband Imaging Photometer for Spitzer instruments over a period of several decades .We see that the infrared luminosity is compatible with heating by AGN radiation or supernovae fragments within the main kpc zone . This implies that current feedback power release has been occurring in these cores .These data are important because they give novel evidence on how supermassive black holes expand through accretion onto their host universe centers . They especially demonstrate the power of combining multiwavelength evidence to study the physical processes associated with nuclear activity .Keywords : Active galactic nucleus , Galaxy growth , Mid - infrared , Nuclear starbursts 1 . Introduction Supermassive black holes occur in the center of most large galaxies .Their growth is suggested to be motivated by gas inflow generated by gravitational torques generated during mergers and / or relationships between galaxies ( Barnes & Hernquist 1996 ; Hopkins et al . 2006 ) .However , it remains unsure what comes after this fuel supply runs out . One possibility is that the dark hole keeps developing via radiatively inefficient accretion currents ( Narayan & Yi 1994 ) , which would create potent winds and jets that can force large - scale outflows into the nearby interstellar medium ( ISM ) ( Silk & Rees 1998 ; Di Matteo et al .2005 ) . Another possibility is that the dark holes become extinct as the ISM becomes too warm to heat efficiently ( Bower et al .2006 ; Croton et al . 2006 ) until another merger event triggers renewed behavior .Understanding the mechanisms involved for shut off dark - hole growth will assist us explain why some stars have huge black holes while several do not . 2 .Previous Work Several studies have shown that there exists an counter - correlation between the mass of the main supermassive black hole and the stellar velocity dispersion of its host galaxy bulge ( Ferrar",
        "rewrite_text": "We report the detection of transient dust pollution in the mid-infrared wavelengths (5 to 20 microns) within two elliptical galaxies that feature active galactic nuclei (AGN). This research utilized the Spitzer Space Telescope's Infrared Array Camera and Multiband Imaging Photometer for Spitzer over several decades. Our observations indicate that the infrared luminosity aligns with heating by AGN radiation or remnants of supernovae within the primary kiloparsec region, suggesting ongoing energy feedback from these cores. These findings are significant as they provide new insights into the growth of supermassive black holes as they accrete matter from their host galaxies. Furthermore, they highlight the effectiveness of integrating multiwavelength data to investigate the physical processes linked to nuclear activity.\n\nKeywords: Active galactic nucleus, Galaxy growth, Mid-infrared, Nuclear starbursts\n\n1. Introduction  \nSupermassive black holes are found at the centers of most large galaxies, with their growth often driven by gas inflow resulting from gravitational interactions during galaxy mergers and interactions (Barnes & Hernquist 1996; Hopkins et al. 2006). However, it remains unclear what happens after this gas supply is exhausted. One potential scenario is that the black holes continue to grow via radiatively inefficient accretion flows (Narayan & Yi 1994), generating powerful winds and jets that can induce large-scale outflows into the surrounding interstellar medium (ISM) (Silk & Rees 1998; Di Matteo et al. 2005). Alternatively, black holes might cease to grow as the ISM becomes too warm to sustain effective heating (Bower et al. 2006; Croton et al. 2006), only to reactivate following subsequent merger events. Understanding the mechanisms that lead to the cessation of black hole growth will help explain the varying presence of supermassive black holes across different stars.\n\n2. Previous Work  \nNumerous studies have established an inverse correlation between the mass of the primary supermassive black hole and the stellar velocity dispersion in its host galaxy bulge (Ferrar...)",
        "ori-fast-z-score": -1.2004900959975617,
        "water-fast-z-score": 7.718519260087736,
        "rewrite-fast-z-score": 0.17407765595569785
    },
    {
        "original_text": "We introduce the notion of covering homology, which is an extension of ordinary homology to infinite graphs and simplicial complexes. The main idea behind this concept is that we consider not only finite subcomplexes but also their infinite analogues - so-called coverings. We show how covering homology can be used for studying properties of infinite graphs such as amenability or hyperbolicity. In particular, we prove that if a graph has infinitely many ends then its first covering homology group vanishes. This result generalizes the classical theorem by Stallings on groups with infinitely many ends. Covering homology provides us with new tools for investigating various classes of infinite objects in mathematics. It turns out that it is closely related to other concepts like equivariant homology theory (in the case when our object admits actions of some group) or higher-order algebraic K-theory. Finally, we present several examples illustrating applications of covering homology.",
        "watermark_text": "We introduce the notion of covering homology , which is an extension of regular homology to infinite graphs and simplicial complexes . The main idea behind this concept is that we treat not only finite subcomplexes but also their infinite analogues - so - called coverings .We see how covering homology can be used for studying characteristics of infinite graphs such as amenability or hyperbolicity . In particular , we prove that if a diagram has infinitely many ends then its first covering homology group vanishes .This result generalizes the classical principle by Stallings on groups with infinitely many ends . Covering homology provides us with novel techniques for investigating different categories of infinite concepts in mathematics .It turns out that it is closely related to other concepts like equivariant homology theory ( in the case when our object accepts actions of some group ) or greater - order algebraic K - theory . Finally , we present many examples illustrating applications of covering homology .",
        "rewrite_text": "We present the concept of covering homology, which expands the traditional framework of homology to include infinite graphs and simplicial complexes. The core idea of this concept is to consider not only finite subcomplexes but also their infinite counterparts, known as coverings. We demonstrate how covering homology can be applied to explore properties of infinite graphs, such as amenability and hyperbolicity. Specifically, we establish that if a diagram contains infinitely many ends, its first covering homology group is zero. This finding serves as a generalization of Stallings' classical principle concerning groups with infinitely many ends. Covering homology offers innovative methods for examining various categories of infinite structures in mathematics. Notably, it reveals connections to other areas, such as equivariant homology theory (when our objects are subject to group actions) and higher-order algebraic K-theory. Finally, we provide numerous examples that illustrate the applications of covering homology.",
        "ori-fast-z-score": 0.9847319278346618,
        "water-fast-z-score": 3.8450767722654624,
        "rewrite-fast-z-score": -0.8307471607356973
    },
    {
        "original_text": "We present the results of hydrodynamic simulations that show how planets open gaps in circumstellar disks and determine their minimum mass for gap opening as a function of disk viscosity, surface density profile slope, and irradiation by the central star.  We find that the planet s ability to open a gap is determined primarily by its accretion rate onto the planet (which depends on the planet s mass) rather than by its luminosity or temperature. The critical planet mass decreases with increasing disk viscosity because higher viscosities lead to more rapid angular momentum transport across the planet s orbit which reduces the planet s ability to accrete gas. For fixed viscosity, we find that the critical planet mass increases with decreasing surface density power law index because lower values of this parameter correspond to steeper radial profiles of the disk s surface density which leads to stronger gravitational torques exerted by the planet. Finally, we find that the planet s critical mass decreases with increasing stellar irradiation due to increased temperatures at small radii where most of the torque is generated.",
        "watermark_text": "We present the conclusion of hydrodynamic simulations that demonstrate how planets open gaps in circumstellar disks and estimate their lowest mass for gap opening as a function of disk viscosity , surface volume profile slope , and irradiation by the main star . We see that the planet s capacity to closed a gap is chosen mainly by its accretion rate onto the planet ( which depends on the planet s mass ) instead than by its luminosity or temperature .The critical planet weight decreases with increasing disk viscosity because higher viscosities lead to more rapid angular momentum transport across the planet s orbit which reduces the planet s ability to accrete gas . For fixed viscosity , we find that the critical planet mass increases with decreasing surface density power law index because lower values of this parameter correspond to steeper radial profiles of the disk s surface density which leads to stronger gravitational torques exerted by the planet .Finally , we find that the planet s essential mass decreases with increasing stellar irradiation due to higher temperatures at small radii where most of the torque is generated .",
        "rewrite_text": "We present the findings from our hydrodynamic simulations, which illustrate how planets create gaps in circumstellar disks and provide estimates for the minimum mass required for gap opening. This minimum mass depends on factors such as disk viscosity, the slope of the surface volume profile, and the irradiation received from the central star. Our results indicate that a planet's ability to open a gap is primarily influenced by its accretion rate—dependent on its mass—rather than its luminosity or temperature. We observe that the critical mass for gap formation decreases with increasing disk viscosity; this is because higher viscosities result in more rapid angular momentum transport around the planet's orbit, which in turn diminishes its gas accretion capability. For a given viscosity, we find that lower surface density power law indices lead to an increase in the critical planet mass. This is because smaller indices correspond to steeper radial surface density profiles in the disk, which intensify the gravitational torques exerted by the planet. Lastly, we note that the essential mass of the planet decreases with greater stellar irradiation, as higher temperatures at smaller radii enhance the torque generation.",
        "ori-fast-z-score": -0.741998516004452,
        "water-fast-z-score": 2.1081851067789197,
        "rewrite-fast-z-score": -0.5184758473652127
    },
    {
        "original_text": "We present the results of an investigation into the properties and evolution of transients that arise when initial conditions are generated using Lagrangian perturbation theory (LPT) for cosmological N-body simulations. We find that LPT-based initial conditions produce spurious large-scale power at late times, which is not suppressed by increasing the number of particles used to generate these initial conditions. This effect can be mitigated by applying a low-pass filter to the evolved density field prior to generating new initial conditions with higher-order LPT. However, this approach does not completely remove all unwanted effects associated with the use of LPT-generated initial conditions. In addition, we show how the choice of time step used to evolve the initial conditions affects their accuracy. Finally, we demonstrate that it is possible to construct accurate initial conditions for large-volume cosmological simulations without having to resort to expensive high-resolution hydrodynamic simulations. The generation of realistic initial conditions for cosmological N-body",
        "watermark_text": "We present the conclusion of an research into the properties and evolution of transients that arise when initial conditions are produced utilizing Lagrangian perturbation theory ( LPT ) for cosmological N - bodies simulations . We see that LPT - based initial conditions generate spurious large - scale power at late times , which is not suppressed by expanding the quantity of atoms used to create these initial conditions .This phenomenon can be mitigated by using a reduced - pass filter to the evolved density field prior to generating new initial conditions with higher - order LPT . However , this methodology does not totally reduce all unwanted phenomena associated with the using of LPT - produced early conditions .In addition , we show how the selection of time phase employed to evolve the first parameters impacts their accuracy . Finally , we prove that it is easy to build correct preliminary conditions for large - volume cosmological simulations without having to resort to expensive high - resolution hydrodynamic simulations .The generation of realistic initial conditions for cosmological N - body",
        "rewrite_text": "We present the findings of a research study on the properties and evolution of transients that occur when initial conditions are derived using Lagrangian perturbation theory (LPT) in cosmological N-body simulations. Our results indicate that initial conditions based on LPT produce artificial large-scale power at later times, a phenomenon that is not alleviated by increasing the number of particles used to establish these initial conditions. This issue can be addressed to some extent by applying a reduced-pass filter to the evolved density field before generating new initial conditions using higher-order LPT. However, this approach does not completely eliminate all undesirable effects associated with LPT-derived early conditions. Additionally, we demonstrate how the choice of time phase utilized to advance the initial parameters affects their accuracy. Lastly, we show that it is feasible to create accurate initial conditions for large-volume cosmological simulations without needing costly high-resolution hydrodynamic simulations. The generation of realistic initial conditions for cosmological N-body simulations is thus achievable through alternative methods.",
        "ori-fast-z-score": -0.2182178902359924,
        "water-fast-z-score": 6.037034299432969,
        "rewrite-fast-z-score": -1.58999682000954
    },
    {
        "original_text": "We report on an experiment to measure the Casimir-Lifhsztz (CL) interaction between two gold-coated glass plates immersed in water at room temperature and pressure. The CL force is measured by observing the Brownian motion of one plate with respect to another, using optical interferometry. We find that the magnitude of the observed effect agrees well with theoretical predictions based on Lifshitz theory for dielectrics. This work represents the first direct experimental observation of the CL force in a liquid medium. It also demonstrates how precision measurements can be used to test fundamental theories such as quantum electrodynamics. \n \n In recent years there has been considerable interest in measuring the Casimir-Lifhzsiz (CL)  1  force between macroscopic objects  2  . Such experiments are important because they provide tests of our understanding of vacuum fluctuations  3  , which play a central role in many areas of physics including quantum field theory  4  , statistical mechanics  5  , condensed matter  6  , atomic and nuclear physics  7  , cosmology  8  , and gravitation  9  .\n \nThe original prediction of the CL force was made more than 50 years ago  10  but it took until 1997  11  before this attractive force could be directly detected experimentally  12  . Since then several groups have performed high-precision experiments  13  -  16  aimed at testing the validity of various aspects of the theory  17  -  20  . \n \n Here we present results obtained in a new experiment designed specifically to study the CL force in liquids  21  . Our approach involves immersing two parallel plates coated with thin layers of gold into distilled water contained inside a sealed container  22  . By monitoring the Brownian motion of these plates  23  we were able to determine their mutual attraction due to the presence of the surrounding water molecules  24  .",
        "watermark_text": "We report on an observation to measure the Casimir - Lifhsztz ( CL ) relationship between two gold - glazed mirror sheets immersed in water at room temperature and pressure . The CL force is measured by observing the Brownian movement of one plate with regard to another , using optical interferometry .We see that the magnitude of the seen effect fits well with theoretical expectations based on Lifshitz principle for dielectrics . This research constitutes the first continuous experimental measurement of the CL force in a liquid medium .It additionally demonstrates how accuracy observations can be used to test fundamental theories such as quantum electrodynamics . In past decades there has been substantial interest in measuring the Casimir - Lifhzsiz ( CL ) 1 pressure between macroscopic objects 2 .Such experiments are important because they give demonstrations of our knowing of vacuum fluctuations 3 , which take a central role in large areas of science including quantum field theory 4 , statistical mechanics 5 , condensed matter 6 , atomic and nuclear science 7 , cosmology 8 , and gravitation 9 . The original forecast of the CL force was making more than 50 centuries earlier 10 but it taking until 1997 11 before this attractive field could be easily detected experimentally 12 .Since then several teams have done large - precision tests 13 - 16 aiming at testing the legitimacy of several elements of the principle 17 - 20 . Here we present results derived in a new study intended specifically to study the CL force in liquids 21 .Our solution involves immersing two connected sheets coated with thin layers of gold into distilled water stored inside a sealed container 22 . By observing the Brownian movement of these plates 23 we were could to estimate their mutual affinity due to the presence of the nearby water molecules 24 .",
        "rewrite_text": "We present our findings on an experiment designed to measure the Casimir-Lifshitz (CL) relationship between two gold-coated mirror sheets submerged in water at room temperature and pressure. The CL force was evaluated by analyzing the Brownian motion of one plate relative to the other, utilizing optical interferometry. The magnitude of the observed effect aligns closely with theoretical predictions based on the Lifshitz theory for dielectrics. This study marks the first continuous experimental measurement of the CL force in a liquid environment and illustrates how precise observations can be employed to test fundamental theories like quantum electrodynamics. In recent decades, there has been considerable interest in measuring the Casimir-Lifshitz (CL) force between macroscopic objects. Such experiments are crucial, as they provide insights into our understanding of vacuum fluctuations, which play a significant role across a range of scientific fields, including quantum field theory, statistical mechanics, condensed matter physics, atomic and nuclear science, cosmology, and gravitation. The initial prediction of the CL force dates back over five decades, with experimental detection only becoming feasible in 1997. Since then, various research teams have conducted high-precision tests aimed at validating different aspects of the principle. In this paper, we report results from a new study specifically focused on the CL force in liquid mediums. Our method involves submerging two interconnected sheets, each coated with a thin layer of gold, in distilled water contained within a sealed environment. By observing the Brownian motion of these plates, we estimated their mutual attraction influenced by the surrounding water molecules.",
        "ori-fast-z-score": -1.1188618555710317,
        "water-fast-z-score": 7.888934916555407,
        "rewrite-fast-z-score": 0.4402254531628119
    },
    {
        "original_text": "We report on the controlled collision between an individual trapped atom and a singly charged ion in a Paul trap, where both particles are confined to different regions of space separated by several micrometers. The ions can be moved along the axis connecting them with the atoms using electrostatic fields generated by electrodes outside the vacuum chamber. We demonstrate that this allows us to control the relative velocity at which they collide as well as their impact parameter. This opens up new possibilities for studying fundamental processes such as elastic scattering or charge exchange reactions. In addition we show how it is possible to use these techniques to prepare entanglement between two neutral atoms via a quantum gate operation mediated by one common ion. Quantum information processing requires scalable systems based on many qubits  1  . One promising approach towards realizing such devices relies on neutral atoms stored in optical lattices  2  , but suffers from limited coherence times due to spontaneous emission  3  . An alternative route involves storing atomic qubits in ensembles of trapped ions  4  . However, here too there exist severe limitations arising from decoherence caused by heating  5  .\nIn order to overcome these difficulties, hybrid approaches have been proposed  6  combining advantages of both schemes  7, 8  . Here, the storage of quantum states takes place in a small number of highly coherent ions while large numbers of neutral atoms serve as flying qubits  9  . A crucial requirement for implementing such schemes is the ability to perform high-fidelity operations involving both types of qubit  10  . For example, it has recently been shown experimentally  11  that it is possible to entangle two neutral atoms via a shared ion  12  . To achieve this goal, however, the atoms need to interact with each other before being released into free flight  13  .",
        "watermark_text": "We report on the controlled collision between an individual captured molecule and a singly charged particle in a Paul cage , where both particles are localized to different regions of space separated by many micrometers . The atoms can be moved along the axis linking them with the atoms using electrostatic fields generated by electrodes outside the vacuum chamber .We suggest that this enables us to predict the relative velocity at which they collide as also as their impact parameter . This opens up new possibilities for studying basic processes such as elastic scattering or charge transfer reactions .In addition we show how it is easy to use these techniques to make entanglement between two neutral ions via a quantum gate action mediated by one common ion . Quantum electronic processing requires scalable systems based on various qubits 1 .One promising alternative towards developing such devices relies on neutral particles deposited in laser lattices 2 , but suffers from reduced coherence times due to spontaneous emission 3 . An alternative approach requires storing atomic qubits in ensembles of confined ions 4 .However , here too there remain considerable restrictions arose from decoherence caused by temperature 5 . In try to overcome these problems , hybrid approaches have been proposed 6 combining characteristics of both schemes 7 , 8 .Here , the storage of quantum states takes place in a small number of highly coherent electrons while small numbers of neutral particles serve as flying qubits 9 . A crucial requirement for employing such schemes is the ability to conduct high - fidelity operations involving both types of qubit 10 .For instance , it has recently been shown experimentally 11 that it is possible to entangle two neutral ions via a shared ion 12 . To achieve this goal , however , the atoms need to interact with each other before being transferred into free flight 13 .",
        "rewrite_text": "We present our findings on the controlled collision between an individual trapped molecule and a singly charged particle within a Paul trap, where the two particles are confined to distinct regions of space separated by several micrometers. By manipulating the atoms along the axis that connects them using electrostatic fields generated by external electrodes, we can predict both the relative velocity at which they collide and their impact parameter. This capability opens up new avenues for exploring fundamental processes such as elastic scattering and charge transfer reactions. Furthermore, we demonstrate the feasibility of using these techniques to achieve entanglement between two neutral ions through a quantum gate action mediated by a shared ion. Quantum electronic processing demands scalable systems based on various qubits. One promising approach for developing such devices involves using neutral particles in laser lattices, although this method suffers from diminished coherence times due to spontaneous emission. An alternative strategy is to store atomic qubits in ensembles of confined ions, but this too faces significant challenges, including decoherence related to temperature. To address these issues, hybrid approaches have been proposed, combining features of both methodologies. In these schemes, quantum states are stored in a limited number of highly coherent electrons while a small number of neutral particles function as flying qubits. A critical requirement for these schemes is the capability to perform high-fidelity operations involving both types of qubit. Recent experimental work has shown the possibility of entangling two neutral ions through a shared ion. However, for successful implementation, the atoms must interact prior to being released into free flight.",
        "ori-fast-z-score": 1.3241694217637887,
        "water-fast-z-score": 8.765781549553733,
        "rewrite-fast-z-score": 2.1358941442919024
    },
    {
        "original_text": "We study the slave-boson mean-field theory for the extended Falicov--Kimball model in two dimensions, which is known to exhibit an interesting phase diagram with various ordered phases and quantum critical points. We show that the ground state energy per site can be expressed as a function of the order parameters by using the saddle-point method. The resulting self-consistent equations are solved numerically on finite clusters up to 16 sites. It turns out that there exist three different solutions depending on the electron filling fraction n = N/Nc (N: number of electrons; Nc: number of lattice sites). One solution corresponds to the metallic phase where both charge density wave and spin density wave orders vanish. Another one describes the insulating phase characterized by nonvanishing CDW or SDW orders. Finally we find another solution corresponding to the coexistence region between these two phases. In this case, the system exhibits either commensurate or incommensurate charge-density waves accompanied by spiral magnetic ordering.",
        "watermark_text": "We research the slave - boson mean - field model for the extended Falicov - - Kimball model in two dimensions , which is known to exhibit an interesting phase diagram with various ordered phases and quantum vital points . We see that the ground state energy per site can be expressed as a function of the order variables by using the saddle - point technique .The resulting self - coherent equations are answered numerically on polynomial clusters up to 16 sites . It turns out that there exist three different solutions depending on the electron packing fraction n = N / Nc ( N : number of atoms ; Nc : number of lattice sites ) .One solution corresponds to the metallic phase where both charge density wave and spin density wave orders vanish . Another one presents the insulating phase described by nonvanishing CDW or SDW orders .Finally we find another solution corresponding to the coexistence area between these two phases . In this situation , the system displays either commensurate or incommensurate charge - density flows followed by spiral magnetic ordering .",
        "rewrite_text": "We investigate the slave-boson mean-field model as applied to the extended Falicov-Kimball model in two dimensions, which is recognized for its intriguing phase diagram featuring various ordered phases and quantum critical points. Utilizing the saddle-point technique, we express the ground state energy per site as a function of the order parameters. The resulting self-consistent equations are solved numerically on polynomial clusters of up to 16 sites. Our findings reveal three distinct solutions based on the electron packing fraction \\( n = \\frac{N}{N_c} \\) (where \\( N \\) is the number of atoms and \\( N_c \\) is the number of lattice sites). One solution corresponds to a metallic phase characterized by the absence of charge density wave (CDW) and spin density wave (SDW) orders. Another solution represents an insulating phase marked by non-zero CDW or SDW orders. Lastly, we identify a solution associated with the coexistence region between these two phases, during which the system exhibits either commensurate or incommensurate charge density fluctuations accompanied by spiral magnetic ordering.",
        "ori-fast-z-score": -0.1111111111111111,
        "water-fast-z-score": 3.533808834395089,
        "rewrite-fast-z-score": 1.078327732034384
    },
    {
        "original_text": "The authors present an evaluation framework to assess personal archiving strategies in the context of internet-based information, and apply it to two case studies. The first is based on a survey conducted among researchers at the University of Southampton; the second focuses on the activities of one individual researcher who has been collecting data about his research field over several years. Both cases are used to illustrate how different types of archives can be evaluated using this approach. This article was published as part of the Proceedings of the 1st International Conference on Digital Preservation (ICDP-1), held September 24-27, 2002 in New York City. It may be freely reproduced by anyone wishing to do so provided that proper credit is given to the author(s) and citation details are included. Copyright permission requests should be addressed to: RightsLink@copyright.gov. The authors present an evaluation framework which they use to assess personal archiving initiatives in the context of internet- based information. They then apply their method to two case studies - one focusing on a group of researchers at the University of Southamptonshire, UK, and another concentrating on the activities of one particular individual researcher.",
        "watermark_text": "The authors present an assessment framework to examine personal archiving strategies in the context of internet - based information , and application it to two case studies . The first is based on a survey conducted among researchers at the University of Southampton ; the second focuses on the actions of one individual scientist who has been collecting data about his scientific area over ten years .Both cases are applied to illustrate how various types of archives can be evaluated using this methodology . This section was publication as part of the Proceedings of the 1st International Conference on Digital Preservation ( ICDP - 1 ) , conducted September 24 - 27 , 2002 in New York City .It might be freely copied by anyone wishing to do so provided that proper credit is given to the writer ( s ) and citation notes are provided . Copyright permit applications should be addressed to : RightsLink @ copyright . gov .The authors present an assessment framework which they use to examine personal archiving activities in the context of internet - based information . They then use their method to two case studies - one focusing on a group of studies at the University of Southamptonshire , UK , and another concentrating on the actions of one particular individual scientist .",
        "rewrite_text": "The authors introduce an assessment framework designed to evaluate personal archiving strategies within the realm of internet-based information, applying it to two case studies. The first case study is drawn from a survey of researchers at the University of Southampton in the UK, while the second focuses on the efforts of a single scientist who has collected data related to his scientific field over the past decade. Both examples demonstrate how different types of archives can be analyzed using this methodology. This section was published in the Proceedings of the 1st International Conference on Digital Preservation (ICDP-1), held from September 24-27, 2002, in New York City. It is available for anyone to copy, provided proper credit is given to the authors and citation notes are included. Copyright permission requests should be directed to RightsLink at copyright.gov. The authors present their assessment framework to investigate personal archiving practices in the context of online information and apply it to two case studies—one involving a group of researchers at the University of Southampton and the other focused on the actions of an individual scientist.",
        "ori-fast-z-score": 1.091089451179962,
        "water-fast-z-score": 8.292279828967711,
        "rewrite-fast-z-score": 1.3416407864998738
    },
    {
        "original_text": "We propose that the fuzzball proposal for black holes can be extended to include internal degrees of freedom, which are excited by infalling matter and produce Hawking radiation.  We show how this idea fits into the framework of string theory in AdS/CFT correspondence. The proposed model is based on an extension of the work done by Horowitz and Maldacena (HM) who showed that the entropy of extremal Kerr-Newman black hole agrees exactly with the microscopic counting of states in N=4 super Yang-Mills gauge theory at strong coupling. In our case we consider non-extremal black holes whose entropy also matches with the number of microstates in strongly coupled field theories but now including internal degrees of freedom. This leads us to conclude that the emission spectrum of these black holes should agree with the one predicted by Hawking s original calculation. Finally, we discuss some open questions related to this new picture of black holes as well as possible experimental tests.",
        "watermark_text": "We suggest that the fuzzball idea for black holes can be generalized to consider inner degrees of liberty , which are excited by infalling matter and produce Hawking radiation . We see how this idea fits into the framework of string theory in AdS / CFT correspondence .The proposed theory is based on an extension of the paper done by Horowitz and Maldacena ( HM ) who demonstrated that the entropy of extremal Kerr - Newman white hole agrees exactly with the microscopic counting of states in N = 4 super Yang - Mills gauge theory at strong coupling . In our case we treat non - extremal black holes whose entropy also compares with the number of microstates in weakly coupled field theories but now including internal degrees of liberty .This leads us to observe that the emission spectrum of these black holes should comply with the one expected by Hawking s earlier calculation . Finally , we explain some open questions related to this new picture of brown holes as well as possible experimental tests .",
        "rewrite_text": "We propose that the fuzzball concept for black holes can be extended to include internal degrees of freedom, which are activated by infalling matter and result in the production of Hawking radiation. This idea aligns with the principles of string theory within the AdS/CFT correspondence framework. Our theory builds upon the work of Horowitz and Maldacena (HM), who showed that the entropy of extremal Kerr-Newman white holes exactly matches the microscopic state counting in N=4 super Yang-Mills gauge theory at strong coupling. In our analysis, we focus on non-extremal black holes, whose entropy can also be related to the number of microstates in weakly coupled field theories, but with the added consideration of internal degrees of freedom. This leads us to conclude that the emission spectrum of these black holes should conform to the predictions made by Hawking's original calculations. Lastly, we address some unresolved questions regarding this new interpretation of black holes, as well as potential avenues for experimental verification.",
        "ori-fast-z-score": 0.1125087900926024,
        "water-fast-z-score": 4.076197322920544,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We study the dynamics of open quantum systems in one dimension, focusing on their ability to generate entanglement between distant sites and how this is affected by decoherence.  We consider two different models for the system-environment interaction: (i) an environment that couples locally with each site; and (ii) an environment that couples globally with all sites simultaneously. In both cases we find that there are regimes where the system can be driven into highly entangled states even when it starts out unentangled or only weakly entangled. This occurs because the environment acts as a source of noise which drives the system towards its ground state. The effect of local coupling is more pronounced than global coupling since the former allows for faster relaxation timescales. Finally, we show that these results hold true also if the initial state has some degree of spatial correlations. Quantum information processing requires the manipulation of quantum states over large distances. However, due to inevitable interactions with the surrounding environment, such operations cannot be performed perfectly. Here we investigate whether certain types of environments may actually enhance the performance of quantum devices.",
        "watermark_text": "We research the dynamics of open quantum systems in one dimension , concentrating on their potential to create entanglement between distant objects and how this is affected by decoherence . We consider two different models for the system - landscape interaction : ( i ) an environment that pairs locally with each site ; and ( ii ) an environment that pairs internationally with all locations simultaneously .In both cases we find that there are regimes where the system can be pushed into extremely entangled states especially when it comes out unentangled or only lightly entangled . This occurs because the surroundings serves as a source of noise which drives the system towards its ground state .The impact of local coupling is more pronounced than worldwide coupling since the former provides for quicker recovery timescales . Finally , we prove that these results hold true also if the first state has some degree of spatial correlations .Quantum knowledge processing requires the processing of quantum states over large distances . However , owing to inherent interactions with the nearby surroundings , such operations unable be performed properly .Here we investigate whether particular kinds of conditions might actually increase the performance of quantum devices .",
        "rewrite_text": "We examine the dynamics of open quantum systems in one dimension, focusing on their ability to generate entanglement between distant objects and the influence of decoherence on this process. We analyze two distinct models of the system: (i) a landscape interaction with an environment that pairs locally with each site, and (ii) an environment that pairs globally with all locations at once. In both scenarios, we discover regions where the system can achieve highly entangled states, particularly when it begins as unentangled or only weakly entangled. This phenomenon occurs because the environment acts as a noise source that drives the system toward its ground state. We find that local coupling has a more significant effect than global coupling, as it facilitates faster recovery timescales. Moreover, our results are confirmed to hold even if the initial state possesses some level of spatial correlation. Quantum information processing relies on manipulating quantum states across vast distances; however, due to inherent interactions with the nearby environment, such operations are often hindered. Here, we explore whether specific conditions might enhance the performance of quantum devices.",
        "ori-fast-z-score": -0.5129891760425771,
        "water-fast-z-score": 6.807380225308036,
        "rewrite-fast-z-score": 0.8340576562282991
    },
    {
        "original_text": "We present new near-infrared spectroscopy of the evolved star V4332 Sgr, which is believed to be in an advanced stage of its final red giant phase. We find that it has developed a strong infrared excess due to dust formation at temperatures between 1000-2000 K. This suggests that the object may have undergone a recent episode of enhanced mass loss on a time scale of years or decades prior to our observations. In addition we detect emission lines of hydrogen and helium indicating ongoing mass loss. These results are consistent with previous suggestions that this object underwent a late thermal pulse (LTP), i.e., a rapid increase in luminosity followed by a period of high mass loss. If so, then the LTP would have occurred within the last few hundred thousand years. Based on these findings we propose a revised evolutionary model for V4332 Sgr including a VLTP event as well as a subsequent superwind phase.",
        "watermark_text": "We present new near - infrared spectroscopy of the evolved star V4332 Sgr , which is suspected to be in an accelerated phase of its final red giant stage . We see that it has acquired a powerful infrared excess due to dust form at temperatures between 1000 - 2000 K . This implies that the object may have undergone a recent episode of enhanced mass loss on a time scale of years or centuries previous to our observations .In addition we find emission lines of hydrogen and helium indicating continuing mass loss . These data are compatible with previous suggestions that this body experienced a late heat pulse ( LTP ) , i . e . , a rapid increase in luminosity followed by a period of high mass loss .If so , then the LTP may have happened within the last few hundred thousand years . Based on these conclusions we propose a revised evolutionary model for V4332 Sgr including a VLTP impact as also as a subsequent superwind phase .",
        "rewrite_text": "We present new near-infrared spectroscopy of the evolved star V4332 Sgr, which is believed to be undergoing an accelerated phase of its final red giant stage. Our observations reveal that the star has developed a significant infrared excess, likely due to the presence of dust formed at temperatures between 1000 and 2000 K. This observation suggests that V4332 Sgr may have experienced a recent episode of increased mass loss occurring over the past few years or centuries. Additionally, we detected emission lines of hydrogen and helium, indicating ongoing mass loss. These findings are consistent with earlier hypotheses that this star underwent a late heat pulse (LTP), characterized by a rapid rise in luminosity followed by a period of substantial mass loss. If this is the case, the LTP likely occurred within the last few hundred thousand years. Based on these insights, we propose a revised evolutionary model for V4332 Sgr that incorporates the effects of a VLTP event followed by a subsequent superwind phase.",
        "ori-fast-z-score": 0.3418817293789138,
        "water-fast-z-score": 5.658032638058332,
        "rewrite-fast-z-score": 1.5652475842498528
    },
    {
        "original_text": "We present an analysis of the statistical properties of turbulent flows that are driven by random forcing and decaying viscosity, with particular emphasis on their departures from Gaussianity. We show how these statistics can be computed using a recently developed method based on stochastic averaging over realizations of the flow field. The results obtained demonstrate that this approach is capable of capturing both non-Gaussian tails as well as intermittency effects associated with small-scale structures. In addition to providing new insights into the nature of turbulence, our findings also have important implications for the development of efficient numerical algorithms aimed at solving fluid dynamics problems. Turbulence plays a crucial role in many physical phenomena ranging from geophysical flows  1  , atmospheric convection  2  , oceanic currents  3  , plasma physics  4  , combustion  5  , and even stock market fluctuations  6  . Despite its ubiquity, however, there remains no universally accepted theory describing the underlying mechanisms responsible for the observed phenomenology  7, 8  .\nIn recent years, significant progress has been made towards understanding the statistical properties of turbulences through direct numerical simulations (DNS)  9  . These studies have shown that the probability density functions (PDFs) of velocity differences exhibit heavy-tailed distributions  10  which cannot be described within the framework of classical statistical mechanics  11  . Moreover, it was found that PDFs of higher-order moments such as energy dissipation rates  12  or enstrophy  13  display power-law scaling behavior near their peaks indicating strong intermittency  14  . This phenomenon manifests itself in the form of bursty events where large values of certain quantities occur simultaneously  15  . It should be noted, however, that DNS-based approaches suffer from severe limitations due to high computational costs involved  16  . As a result, they are typically restricted to relatively low Reynolds numbers  17  making them inapplicable to real-world applications  18  .",
        "watermark_text": "We present an assessment of the statistical characteristics of turbulent streams that are driven by random forcing and decaying viscosity , with particular emphasis on their departures from Gaussianity . We see how these statistics can be computed using a recently advanced method based on stochastic averaging over realizations of the traffic field .The results presented indicate that this methodology is capable of representing both non - Gaussian tails as well as intermittency effects involved with little - scale structures . In addition to offering fresh insights into the nature of turbulence , our findings also have important implications for the development of effective numerical algorithms directed at solving fluid dynamics cases .Turbulence functions a crucial role in many natural phenomena ranging from geophysical flows 1 , atmospheric circulation 2 , oceanic currents 3 , plasma physics 4 , combustion 5 , and even price market fluctuations 6 . Despite its ubiquity , however , there exists no universally recognized hypothesis explaining the fundamental pathways contributing for the reported phenomenology 7 , 8 .In recent years , substantial advances has been achieved towards studying the statistical characteristics of turbulences through direct numerical simulations ( DNS ) 9 . These studies have shown that the probability density functions ( PDFs ) of velocity differences display heavy - tailed functions 10 which cannot be described within the framework of classical statistical mechanics 11 .Moreover , it was shown that PDFs of greater - order moments such as energy dissipation levels 12 or enstrophy 13 show power - law scaling behavior near their peaks implying strong intermittency 14 . This phenomenon manifests itself in the form of bursty events where many values of certain quantities occur simultaneously 15 .It should be mentioned , however , that DNS - based methods endure from severe constraints due to large numerical fees involved 16 . As a result , they are typically restricted to rather low Reynolds numbers 17 making them inapplicable to real - time users 18 .",
        "rewrite_text": "We provide an evaluation of the statistical properties of turbulent flows influenced by random forcing and decaying viscosity, with a focus on their deviations from Gaussian distributions. Our analysis employs a newly developed method that utilizes stochastic averaging over various realizations of the traffic field to compute these statistics. The results indicate that this approach effectively captures both non-Gaussian tails and intermittency associated with small-scale structures. Our findings not only offer new insights into the nature of turbulence but also hold significant implications for the creation of efficient numerical algorithms aimed at solving fluid dynamics problems. Turbulence plays a critical role in numerous natural phenomena, including geophysical flows, atmospheric circulation, ocean currents, plasma physics, combustion, and even fluctuations in financial markets. Despite its widespread occurrence, there is currently no universally accepted hypothesis that explains the fundamental mechanisms underlying the observed phenomena. Recently, considerable progress has been made in studying the statistical properties of turbulence through direct numerical simulations (DNS). These investigations have demonstrated that the probability density functions (PDFs) of velocity differences exhibit heavy-tailed distributions that cannot be accurately described by classical statistical mechanics. Additionally, it has been found that PDFs of higher-order moments, such as energy dissipation and enstrophy, display power-law scaling behavior near their peaks, indicating strong intermittency. This intermittency is characterized by burst-like events where certain quantities exhibit simultaneous high values. However, it is important to note that DNS-based methods face significant limitations due to the high computational costs involved, which typically restrict their application to relatively low Reynolds numbers, rendering them impractical for real-time use.",
        "ori-fast-z-score": -0.9733285267845753,
        "water-fast-z-score": 7.680294792817211,
        "rewrite-fast-z-score": -0.9011551125709446
    },
    {
        "original_text": "We present new measurements of the Hubble constant and the equation-of-state parameter w0 using Chandra X-ray Observatory data for the most massive, dynamically relaxed galaxy clusters in the Universe. We use these results to place improved limits on the properties of dark energy. The sample consists of eight galaxy clusters with redshifts between 0.3 and 1.2 that were observed by Chandra as part of our ongoing program to study the evolution of cluster scaling relations out to high redshift. Using hydrostatic equilibrium models we measure the gas mass fraction within r500 (the radius at which the mean density is 500 times the critical density) for each system. These values are combined with independent estimates of the total gravitating mass obtained through weak lensing analysis performed by other groups. This yields an average value of H0 = 70 +/- 6 km s-1 Mpc-1 assuming flat priors on both parameters. If instead we assume Gaussian priors based on previous determinations of the Hubble constant and baryon content of the universe then this measurement becomes H0 = 68 +/-6 km s-1 Mpc-",
        "watermark_text": "We present new studies of the Hubble constant and the equation - of - state variable w0 using Chandra X - ray Observatory data for the most large , dynamically stable galaxy galaxies in the Universe . We use these results to place improved restrictions on the properties of dark energy .The sample consists of eight galaxy galaxies with redshifts between 0 . 3 and 1 . 2 that were detected by Chandra as part of our ongoing program to study the evolution of cluster scaling relations out to large redshift . Using hydrostatic equilibrium models we measure the gas mass fraction within r500 ( the radius at which the mean concentration is 500 times the critical density ) for each system .These values are coupled with independent estimates of the total gravitating mass obtained through soft lensing investigation performed by other organizations . This yields an mean value of H0 = 70 + / - 6 cm s - 1 Mpc - 1 assuming flat priors on both variables .If instead we assume Gaussian priors based on previous determinations of the Hubble constant and baryon concentration of the universe then this measurement becomes H0 = 68 + / - 6 cm s - 1 Mpc -",
        "rewrite_text": "We report on new research concerning the Hubble constant and the equation of state parameter w0, utilizing data from the Chandra X-ray Observatory for some of the largest and most dynamically stable galaxies in the universe. Our findings allow us to refine constraints on the characteristics of dark energy. The sample includes eight galaxies with redshifts ranging from 0.3 to 1.2, identified by Chandra as part of our ongoing effort to investigate the evolution of cluster scaling relations at high redshifts. By applying hydrostatic equilibrium models, we determine the gas mass fraction within r500 (the radius at which the mean density is 500 times the critical density) for each galaxy. These measurements are combined with independent assessments of the total gravitating mass obtained through weak lensing studies conducted by other teams. This approach yields a mean value of H0 = 70 ± 6 km/s/Mpc, assuming flat priors for both variables. Alternatively, using Gaussian priors based on prior measurements of the Hubble constant and baryon density, our measurement adjusts to H0 = 68 ± 6 km/s/Mpc.",
        "ori-fast-z-score": 1.709408646894569,
        "water-fast-z-score": 5.735393346764043,
        "rewrite-fast-z-score": 0.5698028822981898
    },
    {
        "original_text": "The MCHIT (Monte Carlo Heavy Ion Transport) code is an advanced tool to simulate the transport of ions in matter, including their interactions with target nuclei as well as elastic scattering off atomic electrons. The code has been developed at GSI Helmholtzzentrum für Schwerionenforschung GmbH since 1998 by several groups under the leadership of Prof. Dr. Jens B. Skarsgard. \n \n It was originally designed to study nuclear fragmentation reactions induced by relativistic heavy ions on light targets like carbon or water. In recent years it has also been used successfully to investigate other topics such as: \n \n \n \n • Radiation damage in biological tissues due to ion beam irradiation \n \n • Secondary particle production in hadronic showers \n \n • Energy deposition in materials exposed to high-energy cosmic rays \n \n • Nuclear reaction cross sections for astrophysical applications \n \n • Hadrontherapy treatment planning",
        "watermark_text": "The MCHIT ( Monte Carlo Heavy Ion Transport ) code is an specialized tool to simulate the movement of atoms in material , particularly their interactions with target nuclei as well as elastic scattering off atomic electrons . The code has been created at GSI Helmholtzzentrum für Schwerionenforschung GmbH since 1998 by many groups under the leadership of Prof . Dr . Jens B . Skarsgard .It was originally intended to study nuclear fragmentation reactions generated by relativistic heavy ions on light sites like nitrogen or water . In past decades it has additionally been used successfully to examine other topics such as : • Radiation injury in biological tissues resulting to ion beam irradiation • Secondary particle production in hadronic showers • Energy deposition in structures exposed to large - energy cosmic rays • Nuclear reaction cross sections for astrophysical applications • Hadrontherapy control planning",
        "rewrite_text": "The MCHIT (Monte Carlo Heavy Ion Transport) code is a specialized tool designed to simulate atomic movement within materials, focusing on interactions with target nuclei and elastic scattering with atomic electrons. Developed since 1998 at GSI Helmholtzzentrum für Schwerionenforschung GmbH under the guidance of Prof. Dr. Jens B. Skarsgard, the code was initially created to investigate nuclear fragmentation reactions caused by relativistic heavy ions on light elements such as nitrogen or water. Over the years, it has also been effectively employed to explore a variety of other topics, including: \n- Radiation damage in biological tissues resulting from ion beam irradiation\n- Secondary particle production in hadronic showers\n- Energy deposition in materials exposed to high-energy cosmic rays\n- Nuclear reaction cross-sections for astrophysical research\n- Control planning for hadron therapy",
        "ori-fast-z-score": 0.254000254000381,
        "water-fast-z-score": 6.096006096009144,
        "rewrite-fast-z-score": 1.2909944487358056
    },
    {
        "original_text": "In this work, we propose an approach to human identification based on the analysis of image attributes and their relationships with each other. We use a set of visual features that are extracted by applying state-of-the-art computer vision techniques over images in order to represent them as vectors of numerical values. These feature vectors can be used to train machine learning algorithms such as Support Vector Machines (SVMs) or Random Forests (RF). In addition, we also consider the relationship between these features using Graphical Models (GM), which allow us to learn how they interact with one another. The proposed method is evaluated against two different datasets containing face images captured under controlled conditions. Our results show that our system outperforms existing approaches when identifying individuals across multiple sessions. This research was supported by the National Science Foundation through awards IIS-1253153 and CNS-1527225. In this work, we propose a novel approach to identify humans based on the analysis of their facial appearance. To do so, we extract several visual features from faces using state-of-the-art computer vision methods. Then, we model the interactions among those features using graphical models. Finally, we evaluate the performance of our method against two publicly available databases.",
        "watermark_text": "In this project , we develop an way to human identification relying on the examination of visual attributes and their connections with each other . We use a group of visual elements that are derived by using state - of - the - art computer vision techniques over images in order to represent them as matrices of numerical values .These feature vectors can be used to train machine understanding algorithms such as Support Vector Machines ( SVMs ) or Random Forests ( RF ) . In addition , we also consider the relationship between these characteristics utilizing Graphical Models ( GM ) , which allow us to study how they interact with one another .The proposed approach is evaluated against two different datasets featuring face photos taken under controlled circumstances . Our results show that our system outperforms previous techniques when identifying persons across multiple sessions .This research was supported by the National Science Foundation through awards IIS - 1253153 and CNS - 1527225 . In this research , we propose a innovative method to identify humans based on the evaluation of their facial form .To do so , we extract many graphical features from faces utilizing state - of - the - art computer vision methods . Then , we study the interactions among those characteristics utilizing graphical descriptions .Finally , we assess the performance of our technique against two publicly accessible data .",
        "rewrite_text": "In this project, we present a novel approach to human identification that focuses on analyzing visual attributes and their interrelations. We utilize a set of visual elements extracted from images using advanced computer vision techniques, which are then represented as numerical value matrices. These feature vectors can be employed to train machine learning algorithms such as Support Vector Machines (SVM) and Random Forests (RF). Furthermore, we examine the relationships between these features using Graphical Models (GM), enabling us to investigate their interactions. We evaluate our proposed method against two different datasets, consisting of face images captured under controlled conditions. Our findings indicate that our system surpasses previous techniques in effectively identifying individuals across multiple sessions. This research has been funded by the National Science Foundation through grants IIS-1253153 and CNS-1527225. Overall, we introduce an innovative method for human identification that leverages the analysis of facial structure through the extraction of various graphical features and the study of their interactions, followed by performance assessment against publicly available datasets.",
        "ori-fast-z-score": -1.507556722888818,
        "water-fast-z-score": 6.4,
        "rewrite-fast-z-score": -0.8834522085987723
    },
    {
        "original_text": "We present the results of our Spitzer Space Telescope survey for protostars and young stellar objects (YSOs) in three nearby, intermediate mass star-forming regions: NGC 1333, Serpens South, and Perseus North. We identify over 100 candidate YSOs with infrared excesses indicative of circumstellar disks and/or envelopes. The majority are Class I sources that have recently formed outflows or jets; however we also find several dozen more evolved Class II/III sources. In addition to these disk-bearing systems, we detect numerous isolated point-like sources whose SEDs suggest they are deeply embedded protostars. These observations provide new insights into how stars form in IM environments. Our sample includes many previously unidentified low-luminosity protostars which will be useful targets for future studies at higher angular resolution. This work is based on observations made with the Spitzer Space Telescope, which is operated by NASA under contract 1407. Support for this work was provided by NASA through an award issued by JPL/Caltech. \n \n Keywords: Protostar",
        "watermark_text": "We publish the conclusion of our Spitzer Space Telescope survey for protostars and young stellar bodies ( YSOs ) in three nearby , intermediate mass star - creating areas : NGC 1333 , Serpens South , and Perseus North . We distinguish over 100 candidate YSOs with infrared excesses indicative of circumstellar disks and / or envelopes .The majority are Class I sources that have newly formed outflows or jets ; however we also find several dozen more evolved Class II / III sources . In addition to these disk - bearing components , we locate many isolated point - like sources whose SEDs suggest they are deeply embedded protostars .These measurements give novel knowledge into how stars create in IM environments . Our specimen includes several recently unidentified low - luminosity protostars which will be valuable targets for future research at higher angular resolution .This project is based on observations made with the Spitzer Space Telescope , which is controlled by NASA under contract 1407 . Support for this project was provided by NASA through an grant issued by JPL / Caltech .Keywords: Protostar",
        "rewrite_text": "We present the findings of our Spitzer Space Telescope survey investigating protostars and young stellar objects (YSOs) in three nearby regions conducive to intermediate-mass star formation: NGC 1333, Serpens South, and Perseus North. Our study identifies over 100 candidate YSOs exhibiting infrared excesses characteristic of circumstellar disks and/or envelopes. Most of these candidates are Class I sources associated with newly formed outflows or jets, though we also observe several dozen more evolved Class II and III sources. Additionally, we discover many isolated point-like sources whose spectral energy distributions (SEDs) indicate they are deeply embedded protostars. These findings enhance our understanding of star formation in intermediate-mass environments. Our sample includes several newly identified low-luminosity protostars, which are promising targets for future high-resolution studies. This research is based on observations conducted with the Spitzer Space Telescope, managed by NASA under contract 1407, with support provided by NASA through a grant from JPL/Caltech. Keywords: Protostar.",
        "ori-fast-z-score": -1.3054598240132387,
        "water-fast-z-score": 5.019960159204453,
        "rewrite-fast-z-score": 0.5852057359806528
    },
    {
        "original_text": "We present an all-sky survey for neutral hydrogen (HI) clouds associated with the Large Magellanic cloud (LMC). The LMC is known to have many small, isolated HI clouds that are not gravitationally bound and may be tidally stripped material or remnants of dwarf galaxies destroyed by tidal forces during close encounters between the Milky Way Galaxy and the LMC.  We use data obtained at Arecibo Observatory as part of the ALFALFA survey to search for new HI clouds near the LMC. In addition we combine our results with previous surveys conducted using Parkes telescope observations and single dish telescopes located on Mauna Kea, Hawaii. Our analysis reveals a total of 16 previously uncatalogued HI clouds within 10 degrees of the LMC center. These clouds range in size from 1 kpc to 15 kpc and contain up to 3 x 1012 M⊙ of HI gas.",
        "watermark_text": "We present an all - skies study for neutral hydrogen ( HI ) skies related with the Large Magellanic cloud ( LMC ) . The LMC is known to have many small , isolated HI clouds that are not gravitationally locked and may be tidally stripped matter or remnants of dwarf stars destroyed by tidal forces during close contacts between the Milky Way Galaxy and the LMC .We use data acquired at Arecibo Observatory as part of the ALFALFA survey to search for fresh HI clouds near the LMC . In addition we merge our findings with previous searches undertaken using Parkes telescope measurements and single dish telescopes located on Mauna Kea , Hawaii .Our study reveals a total of 16 formerly uncatalogued HI clouds within 10 degrees of the LMC center . These particles fall in height from 1 kpc to 15 kpc and comprise up to 3 x 1012 [UNK] of HI gas .",
        "rewrite_text": "We present a comprehensive all-skies investigation of neutral hydrogen (HI) related to the Large Magellanic Cloud (LMC). The LMC is recognized for its numerous small, isolated HI clouds that are not bound by gravity and may represent tidally stripped material or remnants of dwarf stars disrupted by tidal forces during close encounters with the Milky Way Galaxy. Utilizing data from the Arecibo Observatory as part of the ALFALFA survey, we search for new HI clouds in proximity to the LMC. Additionally, we combine our results with earlier searches that utilized measurements from the Parkes telescope and single-dish telescopes on Mauna Kea, Hawaii. Our study identifies a total of 16 previously uncatalogued HI clouds located within 10 degrees of the LMC's center. These clouds range in height from 1 kpc to 15 kpc and contain up to 3 x 10^12 solar masses of HI gas.",
        "ori-fast-z-score": 0.39056673294247163,
        "water-fast-z-score": 5.077367528252131,
        "rewrite-fast-z-score": 0.6509445549041194
    },
    {
        "original_text": "We present an approach to nonequilibrium entropy production in the lattice Boltzmann (LB) method by introducing entropy limiters into the collision operator. The proposed scheme is shown to be able to reproduce the correct equilibrium distribution and recover the second law of thermodynamics for both single-phase flows with constant density and temperature, as well as multiphase flows with phase change. We also demonstrate that our new LB model can accurately capture shock waves without spurious oscillations or numerical instabilities. \n \n Keywords: Nonequilibrium entropy, Lattice Boltzmann Method, Entropy limiter, Second Law of Thermodynamics, Shock wave. 1 Introduction \n \n In recent years, there has been growing interest in developing computational fluid dynamics methods based on kinetic theory  1–3  . Compared with conventional Navier-Stokes solvers, these approaches are more accurate at capturing complex flow phenomena such as shocks  4  , turbulence  5  , and interfacial flows  6  . Among them, the lattice Boltzmann method  7, 8  has attracted much attention due to its simplicity and efficiency  9  . \n \n However, it should be noted that most existing LB models do not satisfy the second law of thermodynamic  10  . This problem becomes particularly severe when dealing with high Mach number flows  11  . To overcome this difficulty, several attempts have been made recently  12–18  . For example, Chen et al.  12  introduced a modified BGK-type collision term which recovers the correct equilibrium state while satisfying the second law of thermodynamical. Similarly, Yu et al.  13  developed another type of entropy-consistent LB schemes using the concept of entropic moments. More recently, Shan et al.  14  presented a novel LB model where the relaxation time was determined according to the local Knudsen number. Although these works provide promising results, they all require additional information about the macroscopic variables, e.g., pressure and velocity fields. As a result, their applications may be limited to simple cases involving only one component gas. \n \n In contrast, we propose here a general framework for constructing entropy-consistent LB models. Our strategy relies on adding",
        "watermark_text": "We present an approach to nonequilibrium entropy production in the lattice Boltzmann ( LB ) method by using entropy limiters into the collision operator . The proposed system is demonstrated to be possible to predict the appropriate equilibrium distribution and recover the second law of thermodynamics for both single - phase streams with constant density and heat , as well as multiphase streams with phase change .We additionally prove that our new LB model can accurately capture shock waves without spurious oscillations or numerical instabilities . Keywords : Nonequilibrium entropy , Lattice Boltzmann Method , Entropy limiter , Second Law of Thermodynamics , Shock wave .1 Introduction In recent years , there has been growing interest in building computational liquid mechanics algorithms based on kinetic theory 1 – 3 . Compared with typical Navier - Stokes solvers , these method are more accurate at representing complex fluid processes such as shocks 4 , turbulence 5 , and interfacial flows 6 .Among them , the lattice Boltzmann technique 7 , 8 has garnered considerable scrutiny due to its accuracy and efficiency 9 . However , it should be mentioned that most existing LB models do not satisfy the second law of thermodynamic 10 .This problem remains particularly fierce when dealing with high Mach number flows 11 . To solve this challenge , various efforts have been built recently 12 – 18 .For instance , Chen et al . 12 introduced a revised BGK - class collision term which recovers the correct equilibrium state while fulfilling the second law of thermodynamical .Similarly , Yu et al . 13 introduced another type of entropy - consistent LB schemes using the idea of entropic moments .More recently , Shan et al . 14 provided a novel LB model where the relaxation time was decided due to the local Knudsen number .Although these works provide exciting conclusions , they all need extra data about the macroscopic parameters , e . g . , pressure and speed forces . As a outcome , their applications might be restricted to simple instances involving only one component gas .In comparison , we require here a general basis for constructing entropy - consistent LB models . Our strategy relies on adding",
        "rewrite_text": "We propose an approach to nonequilibrium entropy production in the lattice Boltzmann (LB) method by integrating entropy limiters into the collision operator. Our system demonstrates the ability to accurately predict the correct equilibrium distribution and uphold the second law of thermodynamics for both single-phase flows with constant density and heat, as well as multiphase flows with phase changes. Furthermore, we establish that our new LB model effectively captures shock waves without introducing spurious oscillations or numerical instabilities. \n\n**Keywords:** Nonequilibrium entropy, Lattice Boltzmann Method, Entropy limiter, Second Law of Thermodynamics, Shock wave.\n\n**1 Introduction:** Recently, there has been an increasing interest in developing computational fluid dynamics algorithms grounded in kinetic theory. Compared to traditional Navier-Stokes solvers, these methods are more capable of simulating complex fluid phenomena, such as shocks, turbulence, and interfacial flows. Among these, the lattice Boltzmann technique has attracted significant attention due to its accuracy and efficiency. However, it's important to note that many existing LB models fail to comply with the second law of thermodynamics, especially in high Mach number flows. To address this issue, various solutions have been proposed. For example, Chen et al. introduced a modified BGK-class collision term that achieves the correct equilibrium state while adhering to the second law. Similarly, Yu et al. developed entropy-consistent LB schemes based on the concept of entropic moments. More recently, Shan et al. presented a novel LB model that adjusts the relaxation time according to the local Knudsen number. While these advancements yield promising results, they often require additional data about macroscopic parameters like pressure and velocity, which may limit their applicability to simpler scenarios involving single-component gases. In contrast, we aim to establish a more general framework for constructing entropy-consistent LB models based on a broader set of principles.",
        "ori-fast-z-score": -1.516365080488482,
        "water-fast-z-score": 7.000904100746424,
        "rewrite-fast-z-score": 0.41522739926869984
    },
    {
        "original_text": "We study the effect of  illusion of control  on minority games with different number of players, as well as on Parrondo s paradoxical games. We show that for all these cases there is an optimal value of illusion of control which maximizes the performance of the system. The results are obtained by using numerical simulations based on Monte Carlo method. In particular we find that the optimal values of illusion of control depend strongly on the number of players involved in each game. \nI. INTRODUCTIO N\n\nA. Illusion of Control (IC)\nThe term  illusion of control  was first introduced by Langer  1  . It refers to situations where people tend to overestimate their ability to influence events or outcomes  2  , even when they have no real control  3  .\nIn recent years this concept has been applied to many fields such as: gambling  4  , stock markets  5  , sports  6  , health  7  , education  8  etc., showing its importance in human behavior  9  -  11  .\nB. Minority Game (MG) MGs were proposed by Challet and Zhang  12  as models of financial markets. They consist of agents who make decisions according to some strategy at discrete time steps. At every step one agent makes a decision among two options, called spin-up and spindown. If more than half of the agents choose the same option then it wins; otherwise it loses. Agents can change their strategies during the course of play  13  . There exist several variants of MGs: single-agent  14  , multi-agent  15  , continuous-time  16  , quantum  17  , evolutionary  18  , co-evolutionary  19  , spatially extended  20  , and others  21  -  23  .\nC. Parrondo s Paradoxical Games (PPGs)\nParrondo s paradoxical games  24  are simple two-player games played between a player A and B  25  . Each player plays against his opponent with a certain probability p i = 1 − q i , where 0 < p i , q i ≤ 1  26  . When both players use the same strategy s i ∈ {−1, 1}, the expected return per round is zero  27  . However if",
        "watermark_text": "We research the impact of impression of power on minority tournaments with varying amount of teams , as also as on Parrondo s paradoxical games . We see that for all these cases there is an appropriate value of impression of control which maximizes the performance of the system .The results are derived by using numerical simulations based on Monte Carlo method . In particular we find that the ideal values of illusion of control vary strongly on the quantity of teams involved in each game .I . INTRODUCTIO N A . Illusion of Control ( IC ) The term illusion of control was first popularized by Langer 1 .It applies to situations where persons tend to overestimate their power to affect events or outcomes 2 , even when they have no real control 3 . In past decades this concept has been used to many fields such as : gambling 4 , stock pricing 5 , sports 6 , fitness 7 , education 8 etc . , showing its significance in human behavior 9 - 11 .B . Minority Game ( MG ) MGs were introduced by Challet and Zhang 12 as models of financial markets .They comprise of agents who make choices according to some strategy at discrete time steps . At every phase one agent makes a decision among two choices , known spin - up and spindown .If more than half of the agents take the same option then it wins ; otherwise it loses . Agents can alter their strategies during the course of play 13 .There include several variants of MGs : triple - agent 14 , multi - agent 15 , continuous - time 16 , quantum 17 , evolutionary 18 , co - evolutionary 19 , spatially extended 20 , and others 21 - 23 . C . Parrondo s Paradoxical Games ( PPGs ) Parrondo s paradoxical games 24 are simple two - player games played between a team A and B 25 .Each person plays against his opponent with a certain likelihood q i = 1 − p i , where 0 < p i , r i ≤ 1 26 . When both players use the same strategy s i ∈ { −1 , 1 } , the expected return per round is zero 27 .However if",
        "rewrite_text": "We investigate the influence of perceived control on minority tournaments with varying numbers of teams, as well as on Parrondo's paradoxical games. Our findings indicate that, in all cases, there exists an optimal level of perceived control that maximizes the system's performance. These results are obtained through numerical simulations conducted using the Monte Carlo method. Notably, we discover that the ideal levels of perceived control can differ significantly depending on the number of teams participating in each game.\n\nI. INTRODUCTION\nA. Illusion of Control (IC)\nThe concept of the illusion of control was first popularized by Langer. It refers to scenarios in which individuals tend to overestimate their influence over events or outcomes, even in the absence of actual control. In recent decades, this concept has been applied across various fields, including gambling, stock pricing, sports, fitness, and education, highlighting its importance in understanding human behavior.\n\nB. Minority Game (MG)\nMinority games were introduced by Challet and Zhang as models for financial markets. These games involve agents who make decisions based on certain strategies at discrete time intervals. In each round, one agent chooses between two options, referred to as \"spin-up\" and \"spin-down.\" If more than half of the agents select the same option, that option wins; if not, it loses. Agents have the flexibility to adjust their strategies throughout the game. There are numerous variants of minority games, including triple-agent, multi-agent, continuous-time, quantum, evolutionary, co-evolutionary, spatially extended, and others.\n\nC. Parrondo's Paradoxical Games (PPGs)\nParrondo's paradoxical games are straightforward two-player games played between teams A and B. Each player competes against their opponent with a certain probability, where the likelihood of winning is determined by corresponding strategies. When both players employ the same strategy, the expected outcome per round is zero; however, if...",
        "ori-fast-z-score": -0.7633700367119739,
        "water-fast-z-score": 7.0992957397195395,
        "rewrite-fast-z-score": 0.6620847108818944
    },
    {
        "original_text": "We present new near-infrared integral field spectroscopy (IFS) data for the brightest galaxy in the cluster Abell 2218, which is known to be interacting with its nearest neighbor, the radio-quiet quasar I Zw 1 at z = 0.0625. We find that this galaxy has an extended low-surface-brightness component surrounding it, extending out to about 10 kpc on both sides along the major axis. This feature shows no evidence of rotation but does show some velocity structure consistent with infalling gas or tidal debris. In addition we detect two compact objects within 5 kpc of the center of the galaxy. One of these appears to have a very high surface brightness and may represent a nuclear starburst; however, the other one displays much lower surface brightness and could possibly be associated with a supermassive black hole binary system. These results are discussed in terms of possible evolutionary scenarios for this interacting pair.",
        "watermark_text": "We present new near - infrared integral field spectroscopy ( IFS ) statistics for the brightest galaxy in the cluster Abell 2218 , which is known to be interacting with its closest neighbor , the radio - quiet quasar I Zw 1 at z = 0 . 0625 . We see that this galaxy has an extended low - exterior - brightness core covering it , extending out to about 10 kpc on both sides along the main axis .This structure exhibits no evidence of rotation but does display some velocity pattern correlated with infalling dust or tidal debris . In addition we find two compact entities within 5 kpc of the center of the galaxy .One of these seems to have a very high surface brightness and may indicate a nuclear starburst ; however , the other one exhibits far lower surface brightness and could possibly be identified with a supermassive black hole binary system . These conclusions are discussed in terms of possible evolved situations for this interacting pair .",
        "rewrite_text": "We present new near-infrared integral field spectroscopy (IFS) statistics for the brightest galaxy in the Abell 2218 cluster, which is known to interact with its nearest neighbor, the radio-quiet quasar I Zw 1, located at z = 0.0625. Our observations reveal that this galaxy has an extended, low-exterior-brightness core that stretches approximately 10 kpc on either side along its main axis. Although this structure shows no signs of rotation, it does exhibit a velocity pattern that seems to correlate with infalling dust or tidal debris. Additionally, we identify two compact entities within 5 kpc of the galaxy's center. One of these entities appears to have a very high surface brightness, potentially indicative of a nuclear starburst, while the other has a much lower surface brightness and might represent a supermassive black hole binary system. We discuss these findings in the context of possible evolutionary scenarios for this interacting pair.",
        "ori-fast-z-score": 0.47140452079103173,
        "water-fast-z-score": 5.656854249492381,
        "rewrite-fast-z-score": 2.7295978138458623
    },
    {
        "original_text": "We report on neutron scattering experiments performed to study magnetic excitations in an underdoped cuprate superconductor, YBa2Cu3Ox (x = 6.35). We observe that the intensity and linewidth of the low-energy spin waves decrease with increasing temperature up to T* ~ 150 K, which is higher than Tc by about 50 K. The observed behavior can be explained within the framework of the spin-fermion model if one assumes that the spin-wave lifetime decreases rapidly at temperatures close to T* due to the decay into fermionic quasiparticles. This interpretation implies that the pseudogap opens already below T* as suggested previously. \n \n Introduction \n \n In recent years there has been considerable interest in studying the properties of high-temperature superconductors using neutron scattering techniques  1-5 . Neutron scattering allows us not only to investigate the static structure factor S(Q) but also dynamic correlations such as phonons or magnons  6 . It was found recently  7-9  that the low energy spin wave spectrum in optimally doped YBa2Cu3O3 displays unusual features compared to conventional metals. For example, it exhibits a strong dispersion anisotropy along different crystallographic directions  8  and shows significant deviations from the usual linear dependence between the inverse spin wave velocity and momentum  9 . These results have stimulated theoretical studies  10-12  aimed at understanding how these unconventional spin wave properties are related to the electronic structure of the CuO2 planes. However, little attention has so far been paid to the effect of doping on the spin wave dynamics. Here we present new experimental data obtained on an underdoped sample of YBa2Cu3OX (x= 6.35), where x denotes the oxygen content  13 . Our main goal is to explore whether the spin wave properties change significantly when going away from optimal doping towards lower values of x.",
        "watermark_text": "We report on particle scattering experiments conducted to study magnetic excitations in an underdoped cuprate superconductor , YBa2Cu3Ox ( x = 6 . 35 ) . We see that the strength and linewidth of the high - energy spinning waves reduce with advancing heat up to T * ~ 150 K , which is higher than Tc by about 50 K . The observed behavior can be described within the framework of the spin - fermion theory if one suppose that the spin - wave life falls swiftly at conditions close to T * due to the decay into fermionic quasiparticles .This interpretation means that the pseudogap opens already below T * as suggested previously . Introduction In recent years there has been substantial interest in investigating the properties of high - temperature superconductors using neutron scattering methods 1 - 5 .Neutron diffusion allows us not only to examine the static structure parameter S ( Q ) but also dynamic correlations such as phonons or magnons 6 . It was shown ago 7 - 9 that the reduced intensity spin wave spectrum in optimally doped YBa2Cu3O3 exhibits unusual characteristics compared to conventional metals .For instance , it displays a powerful dispersion anisotropy along various crystallographic directions 8 and shows significant deviations from the usual linear dependence between the inverse spinning wave velocity and momentum 9 . These data have stimulated theoretical experiments 10 - 12 aiming at studying how these unconventional momentum wave properties are related to the electronic properties of the CuO2 planes .However , little attention has so far been paid to the impact of doping on the spin wave behavior . Here we present new empirical data derived on an underdoped specimen of YBa2Cu3OX ( x = 6 . 35 ) , where x denotes the oxygen composition 13 .Our main goal is to examine whether the spin wave properties change considerably when going away from efficient doping towards lower values of x .",
        "rewrite_text": "We present findings from particle scattering experiments aimed at investigating magnetic excitations in the underdoped cuprate superconductor YBa2Cu3Ox (x = 6.35). Our results indicate that the intensity and linewidth of the high-energy spin waves decrease with increasing temperature, reaching T* ~ 150 K, which is approximately 50 K above the critical temperature (Tc). This behavior can be interpreted through the spin-fermion theory, positing that the lifespan of the spin waves diminishes rapidly near T* due to their decay into fermionic quasiparticles. This interpretation suggests that the pseudogap begins to open at temperatures below T* as previously proposed. \n\nIntroduction: In recent years, there has been significant interest in exploring the properties of high-temperature superconductors using neutron scattering techniques. Neutron scattering enables the investigation not only of static structural parameters, S(Q), but also of dynamic correlations such as phonons and magnons. Prior studies have shown that the reduced intensity of the spin wave spectrum in optimally doped YBa2Cu3O3 displays distinctive features when compared to conventional metals. For example, it exhibits a strong dispersion anisotropy in different crystallographic directions and significant deviations from the expected linear relationship between the inverse spin wave velocity and momentum. These findings have inspired theoretical investigations aimed at understanding the relationship between these unconventional wave characteristics and the electronic properties of the CuO2 planes. However, the effects of doping on spin wave behavior have received relatively little attention. In this study, we provide new empirical data from an underdoped sample of YBa2Cu3Ox (x = 6.35), where x represents the oxygen content. Our primary objective is to assess whether the properties of spin waves undergo significant changes as the doping level decreases.",
        "ori-fast-z-score": -2.151657414559676,
        "water-fast-z-score": 6.627104836843802,
        "rewrite-fast-z-score": -0.17677669529663687
    },
    {
        "original_text": "We study the lightest and heaviest CP-even neutral Higgs boson masses in the Minimal Supersymmetric Standard Model (MSSM) with large values of tan(beta). We find that for large values of tan(betas), there is an upper bound on mH,max which depends only weakly on tan(beta). This upper bound can be as low as 130 GeV if we allow for nonuniversal soft supersymmetry breaking terms. The lower limit on mH,min increases rapidly with increasing tan(beta).  For small values of tan(beta) (tan(beta) < 3), the mass difference between the two CP-even Higgs bosons decreases slowly with increasing tan(beta). However, this decrease becomes more rapid when tan(beta) > 5.  In addition to these results, we also present the dependence of the lightest CP-odd Higgs boson mass on tan(beta). \nI. INTRODUCTORY REMARkS\nThe Minimal Supersymmetric Standard model (MSSM)  1  has been studied extensively over the past few years  2  . It contains many new parameters beyond those of the Standard Model (SM). These include the gaugino masses M1 , M2 , M3 , the higgsino mass parameter µ, the trilinear scalar couplings A f , and the ratio of vacuum expectation values of the two Higgs doublets tan(beta).\nIn general, it is difficult to obtain analytical expressions for all the physical quantities in the MSSM  3  . Therefore, one usually resorts to numerical methods  4  or approximations  5  .\nRecently, several groups have used approximate techniques  6  -  8  to calculate various properties of the MSSM Higgs sector. In particular, Ref.  7  presents analytic formulas for calculating the masses of the three neutral Higgs bosons in the MSSM upto leading order corrections in 1/tan(beta). They show that their results agree well with exact calculations  9  .",
        "watermark_text": "We explore the lightest and heaviest CP - even neutral Higgs boson masses in the Minimal Supersymmetric Standard Model ( MSSM ) with large values of tan ( beta ) . We see that for large values of tan ( betas ) , there is an upper bound on mH , max which depends only weakly on tan ( beta ) .This upper bound can be as low as 130 GeV if we allow for nonuniversal soft supersymmetry broken terms . The lower limit on mH , min increases quickly with expanding tan ( beta ) .For small values of tan ( beta ) ( tan ( beta ) < 3 ) , the mass ratio between the two CP - even Higgs bosons reduces gradually with rising tan ( beta ) . However , this reduction gets more rapid when tan ( beta ) > 5 .In addition to these results , we also present the dependence of the lightest CP - odd Higgs boson weight on tan ( beta ) . I .INTRODUCTORY REMARkS The Minimal Supersymmetric Standard system ( MSSM ) 1 has been studied thoroughly over the previous few years 2 . It contains much new parameters beyond those of the Standard Model ( SM ) .These include the gaugino masses M1 , M2 , M3 , the higgsino mass variable µ , the trilinear scalar couplings A f , and the ratio of vacuum expectation values of the two Higgs doublets tan ( beta ) . In general , it is unable to obtain numerical values for all the physical quantities in the MSSM 3 .Therefore , one usually resorts to numerical technique 4 or approximations 5 . Recently , various groups have utilized approximate tools 6 - 8 to estimate various properties of the MSSM Higgs region .In particular , Ref . 7 presents analytic formulas for determining the masses of the three neutral Higgs bosons in the MSSM upto leading order corrections in 1 / tan ( beta ) .They show that their results agree well with complete calculations 9 .",
        "rewrite_text": "We investigate the masses of the lightest and heaviest CP-even neutral Higgs bosons within the Minimal Supersymmetric Standard Model (MSSM), particularly for large values of tan(β). Our findings indicate that, at high tan(β) values, there exists a weakly dependent upper bound on mH,max, which can dip as low as 130 GeV when non-universal soft supersymmetry breaking terms are included. Conversely, the lower limit on mH,min increases rapidly with rising tan(β). For small tan(β) values (tan(β) < 3), the mass ratio between the two CP-even Higgs bosons gradually diminishes as tan(β) increases; however, this decline accelerates when tan(β) exceeds 5. Additionally, we provide insights into how the mass of the lightest CP-odd Higgs boson varies with tan(β). \n\nI. INTRODUCTORY REMARKS: The Minimal Supersymmetric Standard Model (MSSM) has been extensively researched over recent years and introduces several new parameters that extend beyond those found in the Standard Model (SM). These parameters include the gaugino masses M1, M2, M3, the higgsino mass parameter µ, the trilinear scalar couplings A_f, and the ratio of vacuum expectation values of the two Higgs doublets, tan(β). Generally, it is challenging to derive numerical values for all physical quantities in the MSSM, often necessitating the use of numerical techniques or approximations. Recently, several groups have applied approximate methods to analyze various aspects of the MSSM Higgs sector. Notably, Reference 7 provides analytical formulas for calculating the masses of the three neutral Higgs bosons in the MSSM, up to leading order corrections in 1/tan(β), demonstrating strong agreement with complete calculations.",
        "ori-fast-z-score": 0.7364596943186588,
        "water-fast-z-score": 5.8423739467217715,
        "rewrite-fast-z-score": -0.7770286898858113
    },
    {
        "original_text": "We propose that the two branches in the mass distribution of neutron stars are due to different mechanisms for their formation, with one branch being formed by accretion-induced collapse (AIC) of white dwarfs into neutron stars, while another is formed through core-collapse supernovae (CCSNe). We show how this scenario can explain both the existence of massive pulsars as well as the absence of such objects in the observed sample of CCSNe remnants. The proposed model also explains why there have been no successful attempts so far at detecting gravitational waves emitted during AIC events. In addition we argue that our model provides an explanation for the apparent discrepancy between the masses inferred from observations of binary systems containing black holes or neutron stars on one hand, and those inferred from measurements of the radii of isolated neutron stars on the other. Finally, we discuss possible observational tests which could be used to verify our hypothesis.",
        "watermark_text": "We suggest that the two branches in the mass distribution of neutron galaxies are owing to different processes for their development , with one branch being created by accretion - caused merger ( AIC ) of white dwarfs into neutron galaxies , while another is formed through core - collapse supernovae ( CCSNe ) . We see how this situation can describe both the existence of large pulsars as well as the absence of such objects in the known sample of CCSNe fragments .The proposed theory even argues why there have been no successful proposals so far at detecting gravitational waves emitted during AIC events . In addition we claim that our model provides an reason for the apparent discrepancy between the masses inferred from measurements of binary systems featuring white holes or neutron galaxies on one hand , and those inferred from measurements of the radii of isolated neutron galaxies on the other .Finally , we explain possible observational tests which could be used to confirm our theory .",
        "rewrite_text": "We propose that the dual branches in the mass distribution of neutron galaxies arise from distinct developmental processes. One branch is formed through the accretion-induced collapse (AIC) of white dwarfs into neutron galaxies, while the other results from core-collapse supernovae (CCSNe). This framework helps to account for the presence of large pulsars as well as the noticeable absence of such objects in the currently known samples of CCSNe remnants. Our theory also offers insights into the lack of successful attempts to detect gravitational waves produced during AIC events. Furthermore, we assert that our model explains the apparent inconsistency between the masses derived from observations of binary systems that include white dwarfs or neutron galaxies, compared to those obtained from the radii measurements of isolated neutron galaxies. Lastly, we outline potential observational tests that could validate our theory.",
        "ori-fast-z-score": -0.1203858530857692,
        "water-fast-z-score": 6.215188768538847,
        "rewrite-fast-z-score": 0.47809144373375745
    },
    {
        "original_text": "We study the possibility that gravitational waves can be detected by measuring their effect on gyroscopes in space, as proposed for the GP-B experiment. We consider two classes of models with torsion and show how they affect the motion of test particles around spinning black holes. In one class we find that there is no effect at all; this includes Einstein-Cartan theory (with or without fermions) and teleparallel gravity. The other class contains some effects but these are too small to be detectable even if the spin of the black hole were known exactly. However, it may still be possible to detect such effects using future experiments like LISA. Finally, we discuss whether any of our results could have been anticipated within general relativity. This work was supported by NSF grant PHY-0456747. Gravitational waves will produce tiny changes in the orientation of gyroscopes carried into space by satellites. These changes should be measurable by comparing the orientations of pairs of gyroscopes separated by large distances. Such an experiment has recently begun taking data  1  . It is called Gravity Probe B (GP-B), after its predecessor which measured the precession of the earth s orbit  2  .\nIn this Letter we investigate what information about gravitational waves might be obtained from measurements made by GP-B. Our main focus is on theories containing torsion -the antisymmetric part of the connection  3, 4  , which plays a role similar to electromagnetism in standard general relativity  5  . Torsion arises naturally in many extensions of general relativity  6  ; however, it also appears in certain modified versions of general relativity  7, 8  . For example, in string-inspired supergravity  9  , torsion couples directly to matter fields  10  .",
        "watermark_text": "We explore the idea that gravity signals can be identified by monitoring their effect on gyroscopes in space , as suggested for the GP - B experiment . We consider two groups of models with torsion and know how they impact the movement of research particles around spun dark holes .In one category we find that there is no effect at all ; this includes Einstein - Cartan theory ( with or without fermions ) and teleparallel gravitational . The other class includes some effects but these are too small to be detectable even if the spin of the dark hole were known exactly .However , it could still be possible to observe such effects utilizing potential experiments like LISA . Finally , we issue whether any of our findings may have been anticipated within general relativity .This project was supported by NSF grant PHY - 0456747 . Gravitational waves will generate tiny changes in the orientation of gyroscopes transported into space by satellites .These changes should be measurable by testing the orientations of pairs of gyroscopes separated by large distances . Such an observation has recently begun took results 1 .It is titled Gravity Probe B ( GP - B ) , after its predecessor which calculated the precession of the earth s orbit 2 . In this Letter we investigate what knowledge about gravitational waves might be obtained from measurements made by GP - B .Our main interest is on fields containing torsion - the antisymmetric part of the relationship 3 , 4 , which plays a role similar to electromagnetism in standard special relativity 5 . Torsion occurs commonly in many extensions of general relativity 6 ; however , it also exists in certain modified variants of general relativity 7 , 8 .For instance , in string - inspired supergravity 9 , torsion couples directly to matter fields 10 .",
        "rewrite_text": "We investigate the concept of detecting gravity signals by observing their impact on gyroscopes in space, as proposed in the Gravity Probe B (GP-B) experiment. Our analysis divides models with torsion into two categories, examining how they influence the motion of research particles near spinning black holes. In the first group, there is no observable effect; this includes the Einstein-Cartan theory (both with and without fermions) and teleparallel gravity. The second group shows some effects, but these are too minuscule to detect, even with precise knowledge of the black hole's spin. Nevertheless, it may still be feasible to observe such effects using potential experiments like LISA. Lastly, we consider whether any of our discoveries could have been predicted within the framework of general relativity. This research was supported by NSF grant PHY-0456747. Gravitational waves cause tiny shifts in the orientation of gyroscopes carried into space by satellites, and these shifts can be measured by comparing the orientations of pairs of gyroscopes located far apart. A recent observation has begun to yield results related to this. It is named Gravity Probe B (GP-B), following its predecessor, which calculated the precession of Earth's orbit. In this letter, we explore the insights about gravitational waves that might be gained from GP-B’s measurements. Our primary focus is on fields that contain torsion—the antisymmetric component of the connection—akin to the role electromagnetism plays in conventional special relativity. Torsion is prevalent in many extensions of general relativity and is also present in certain modified versions of it. For instance, in string-inspired supergravity, torsion interacts directly with matter fields.",
        "ori-fast-z-score": 0.5432144762551112,
        "water-fast-z-score": 8.746195456274092,
        "rewrite-fast-z-score": -0.3651483716701107
    },
    {
        "original_text": "La gravite est une force fondamentale qui agit sur tous les corps materiels, et dont l action se manifeste par l attraction entre ces derniers. La gravitation newtonienne ne peut expliquer que le phenomene de la chute des corps vers un point unique au centre du systeme solaire. Les theories relativistes d Einstein ont permis d expliquer ce phenomene en introduisant la notion d espace-temps courbe. Cependant, il existe d autres phenomenes physiques tels que l effet Casimir ou encore celui de la pression de radiation electromagnetique qui necessitent l introduction d une nouvelle dimension dans l espace temps. Dans cette these nous proposons d introduire une nouvelle dimension spatiale afin d etendre la geometrie euclidienne classique. Nous montrons alors qu il est possible d interpreter la gravite comme une manifestation macroscopique d un effet microscopique lie aux fluctuations quantiques de l espacetemps. Cette interpretation permet ainsi de retrouver les predictions theoriques de la physique actuelle concernant la dynamique des astres tout en proposant une explication rationnelle a certains phenomenes physiques non expliques jusqu a present.",
        "watermark_text": "La gravite est le power fondamentale qui agit à tous les corps materiels , et dont l action se manifeste par l attraction entre ces derniers . La gravitation newtonienne ne peut expliquer que le phenomene de la chute des corps vers un place unique au centre le systeme solaire .Les theories relativistes d Einstein ont permis d expliquer ce phenomene en introduisant la idea d espace - temps courbe . Cependant , el existe d autres phenomenes physiques tels se l effet Casimir ou encore celui de la pression de energy electromagnetique qui necessitent l introduction d la nouvelle depth à l espace temps .Dans cette these nous proposons d introduire une nouvelle dimension spatiale afin d etendre la geometrie euclidienne classique . Nous montrons alors qu il est possible d interpreter la gravite comme le manifestation macroscopique d un effet microscopique lie à fluctuations quantiques de l espacetemps .Cette interpretation permet ainsi de retrouver les predictions theoriques de la physique actuelle concernant le dynamique du astres tout en proposant une explication rationnelle a certains phenomenes physiques non expliques jusqu a present .",
        "rewrite_text": "La gravité est la force fondamentale qui agit sur tous les corps matériels, se manifestant par une attraction entre eux. La gravitation newtonienne décrit uniquement le phénomène de la chute des objets vers un point unique au centre du système solaire. Les théories relativistes d'Einstein ont permis d'expliquer ce phénomène en introduisant l'idée de l'espace-temps courbe. Toutefois, d'autres phénomènes physiques, comme l'effet Casimir ou la pression de l'énergie électromagnétique, nécessitent une extension de la notion d'espace-temps. Dans cette thèse, nous proposons d'ajouter une nouvelle dimension spatiale afin d'étendre la géométrie euclidienne classique. Nous démontrons qu'il est possible d'interpréter la gravité comme la manifestation macroscopique d'un effet microscopique lié aux fluctuations quantiques de l'espace-temps. Cette interprétation permet d'accorder les prédictions théoriques actuelles de la dynamique des astres tout en offrant une explication rationnelle à certains phénomènes physiques encore inexpliqués.",
        "ori-fast-z-score": -0.5443310539518174,
        "water-fast-z-score": 3.328201177351375,
        "rewrite-fast-z-score": 0.31622776601683794
    },
    {
        "original_text": "We present new results on the star formation rate (SFR) in galaxies with active galactic nuclei (AGN). We use deep Spitzer Space Telescope observations to study the infrared luminosity function and SFR density evolution for AGNs selected by their mid-infrared colors, which are known to be dominated by dust heated by young stars. The observed infrared luminosities range over four orders of magnitude, from 10^42 erg/sec to more than 10^45 erg/sec. Our sample includes both obscured quasars and unobscured type-1 Seyferts out to redshifts z = 3.5. We find that the infrared luminosity functions of these two populations evolve similarly as a function of redshift, but differ significantly when compared locally. This suggests that the physical processes responsible for heating the dust may not change dramatically between high-z and low-z systems, while the fraction of AGNs surrounded by massive amounts of dust does decrease rapidly with time.",
        "watermark_text": "We report new data on the star formation rate ( SFR ) in galaxies with active galactic nuclei ( AGN ) . We use deep Spitzer Space Telescope observations to study the infrared luminosity function and SFR density evolution for AGNs chosen by their mid - infrared colors , which are known to be dominated by dust cooled by young galaxies .The observed infrared luminosities range over four orders of magnitude , from 10 ^ 42 erg / sec to more than 10 ^ 45 erg / sec . Our specimen includes both distorted quasars and unobscured type - 1 Seyferts out to redshifts z = 3 . 5 .We see that the infrared luminosity functions of these two communities evolve similarly as a function of redshift , but change considerably when compared nationally . This implies that the physical processes responsible for warming the dust may not change dramatically between high - z and low - z systems , while the fraction of AGNs enclosed by massive amounts of dust does decrease rapidly with time .",
        "rewrite_text": "We present new findings on the star formation rate (SFR) in galaxies hosting active galactic nuclei (AGN). Utilizing deep observations from the Spitzer Space Telescope, we investigate the infrared luminosity function and the evolution of SFR density for AGNs selected based on their mid-infrared color characteristics, which predominantly reflect dust heated by young galaxies. The infrared luminosities observed span four orders of magnitude, ranging from \\(10^{42}\\) erg/sec to over \\(10^{45}\\) erg/sec. Our sample includes both distorted quasars and unobscured type-1 Seyfert galaxies, extending to redshifts of \\(z = 3.5\\). We find that the infrared luminosity functions for these two groups evolve in a similar manner with respect to redshift, yet differ significantly when considered on a broader scale. This suggests that the processes governing dust heating may not vary significantly between high-redshift and low-redshift systems, although the proportion of AGNs shrouded in substantial dust does decrease rapidly over time.",
        "ori-fast-z-score": 1.0834726777719228,
        "water-fast-z-score": 4.935819976516537,
        "rewrite-fast-z-score": 0.47140452079103173
    },
    {
        "original_text": "We present an algorithm for identifying stragglers in round-trip data streams using Newton s identities, which are derived by applying the chain rule to matrix exponentials. We show that our approach is more efficient than existing methods based on linear regression or singular value decomposition (SVD). Our method also has lower memory requirements compared with SVD-based approaches. Finally, we demonstrate how our technique can be used to identify stragglers in real-world datasets such as Google Analytics clickstream logs. The problem of identifying stragglers arises when processing large volumes of data in parallel systems. Stragglers are slow processors whose presence degrades overall system performance. Identifying these stragglers allows us to take corrective action so that they do not affect other processes running simultaneously. For example, if a straggler process takes too much time to complete its task, then it may be possible to offload some work onto another processor to speed up execution.",
        "watermark_text": "We present an algorithm for finding stragglers in round - trip data packets employing Newton s identities , which are derived by using the chain rule to matrix exponentials . We see that our approach is more efficient than existing techniques based on binary regression or singular value transformation ( SVD ) .Our algorithm additionally has reduced storage needs compared with SVD - based methods . Finally , we prove how our technique can be used to identify stragglers in real - time datasets such as Google Analytics clickstream logs .The question of identifying stragglers occurs when handling large quantities of data in concurrent systems . Stragglers are slow processors whose activity degrades overall network quality .Identifying these stragglers lets us to take corrective action so that they do not alter other processes running simultaneously . For instance , if a straggler process took too enough time to complete its job , then it could be possible to offload some work onto another processor to faster up execution .",
        "rewrite_text": "We introduce an algorithm designed to identify stragglers in round-trip data packets using Newton's identities, which are derived from applying the chain rule to matrix exponentials. Our method proves to be more efficient than current techniques that utilize binary regression or singular value decomposition (SVD). Additionally, our algorithm requires less storage compared to SVD-based methods. We demonstrate that our approach can effectively identify stragglers in real-time data sets, such as Google Analytics clickstream logs. The challenge of identifying stragglers arises in the management of large volumes of data within concurrent systems. Stragglers are slow processors whose performance negatively impacts overall network efficiency. By detecting these stragglers, we can implement corrective measures to prevent them from disrupting other simultaneous processes. For instance, if a straggler process takes too long to finish its task, we can potentially redistribute some of its workload to another processor, thereby accelerating overall execution.",
        "ori-fast-z-score": -1.5011106998930268,
        "water-fast-z-score": 6.0448772146786025,
        "rewrite-fast-z-score": -0.46499055497527714
    },
    {
        "original_text": "We report on the room-temperature ferromagnetism in Mn-doped ZnO thin films grown by pulsed laser deposition (PLD). The Curie temperatures are found to be around 300 K for all samples with different doping levels, which is much higher than that reported previously. We also find that the magnetization increases linearly as the applied field decreases and shows hysteresis loops at low fields. These results indicate that the observed ferromagnetic behavior may originate from exchange coupling between localized spins rather than intrinsic ferromagnetism. \n \n In recent years, there has been growing interest in developing new materials for spintronic applications such as nonvolatile memory devices or logic circuits based on the manipulation of electron spins instead of charge carriers1-5 . Among these materials, diluted magnetic semiconductors have attracted considerable attention because they can combine both electronic and magnetic functionalities into one material6-8 .\n \n\n\nZnO-based DMSs have been extensively studied due to their wide band gap energy (3.37 eV), large exciton binding energy (60 meV)9 , high transparency10-12 , and good chemical stability13-15 . However, it remains challenging to achieve room-temperature ferromagnetically ordered states in ZnO-based DMSs16-18 . Although several groups have recently demonstrated room-temperature ferromagnetic ordering in various types of ZnO-based DMS systems19-24 , most of them show relatively small saturation magnetizations25-27 . \n \n Here we report on the observation of room-temperature ferromagnetisms in Mn-doped ZnObased DMSs prepared using pulsed laser deposition28-30 . Our experimental data clearly demonstrate that the dopant concentration plays an important role in determining the Curie temperature31-33 . For example, our sample with x = 0.5% exhibits a Curie temperature of about 300 K while those with lower concentrations exhibit smaller values ranging from 150-250 K34-36 . Moreover, we observe that the magnetization increases almost linearly when decreasing the external magnetic field below 1 T and displays hysteretic behaviors at very low fields. This indicates that the observed ferr",
        "watermark_text": "We report on the room - temperature ferromagnetism in Mn - doped ZnO thin sheets grown by pulsed laser precipitation ( PLD ) . The Curie temperatures are found to be around 300 K for all specimens with various doping rates , which is much higher than that described earlier .We additionally find that the magnetization increases linearly as the applied field decreases and shows hysteresis loops at low areas . These conclusions show that the seen ferromagnetic activity may originate from exchange interactions between localized spins rather than intrinsic ferromagnetism .In past times , there has been growing interest in building new materials for spintronic use such as nonvolatile memory devices or logic devices using on the manipulation of electron spins rather of charge carriers1 - 5 . Among these materials , diluted magnetic semiconductors have garnered considerable scrutiny because they can mix both electronic and magnetic functionalities into one material6 - 8 .ZnO - based DMSs have been heavily explored thanks to their wide band gap energy ( 3 . 37 eV ) , large exciton activation energy ( 60 meV ) 9 , large transparency10 - 12 , and good molecular stability13 - 15 . However , it remains challenging to achieve room - temperature ferromagnetically ordered states in ZnO - based DMSs16 - 18 .Although several groups have recently shown room - temperature ferromagnetic sorting in different kinds of ZnO - based DMS systems19 - 24 , most of them show relatively small saturation magnetizations25 - 27 . Here we publish on the observation of room - temperature ferromagnetisms in Mn - doped ZnObased DMSs assembled utilizing laser optical deposition28 - 30 .Our experimental records distinctly show that the dopant concentration plays an important role in distinguishing the Curie temperature31 - 33 . For instance , our sample with x = 0 . 5 % experiences a Curie temperature of about 300 K while those with higher concentrations display lesser values ranging from 150 - 250 K34 - 36 .Moreover , we determine that the magnetization increases almost linearly when decreasing the external magnetic force below 1 T and displays hysteretic behaviors at very low areas . This implies that the observed ferr",
        "rewrite_text": "We present findings on room-temperature ferromagnetism in Mn-doped ZnO thin films fabricated by pulsed laser deposition (PLD). Remarkably, the Curie temperatures for all samples with varying doping levels are approximately 300 K, which is significantly higher than previously reported values. Additionally, our results indicate that magnetization increases linearly with a decrease in the applied magnetic field and exhibits hysteresis loops at low magnetic field strengths. These observations suggest that the ferromagnetic behavior may stem from exchange interactions between localized spins rather than from intrinsic ferromagnetism. In recent years, there has been increased interest in developing new materials for spintronic applications, such as nonvolatile memory devices and logic devices, which utilize the manipulation of electron spins instead of charge carriers. Among these materials, diluted magnetic semiconductors (DMSs) have attracted considerable attention due to their ability to blend electronic and magnetic properties. ZnO-based DMSs, in particular, have been extensively studied because of their wide band gap energy (3.37 eV), large exciton activation energy (60 meV), high transparency, and excellent chemical stability. However, achieving room-temperature ferromagnetic ordering in ZnO-based DMSs remains a challenge. Although several research groups have recently reported room-temperature ferromagnetic effects in various ZnO-based DMS systems, most have demonstrated relatively small saturation magnetizations. In this study, we detail the observation of room-temperature ferromagnetism in Mn-doped ZnO-based DMSs created through laser optical deposition. Our experimental data clearly indicate that dopant concentration plays a pivotal role in determining the Curie temperature; for example, a sample with a doping level of 0.5% exhibits a Curie temperature of approximately 300 K, while higher concentrations yield lower Curie temperatures ranging from 150 to 250 K. Furthermore, we find that magnetization nearly increases linearly as the external magnetic field is reduced below 1 T, showing hysteretic behavior at very low magnetic fields. This behavior implies that the observed ferromagnetism may be linked to localized spin interactions.",
        "ori-fast-z-score": 0.16666666666666666,
        "water-fast-z-score": 8.833333333333334,
        "rewrite-fast-z-score": 0.3892494720807615
    },
    {
        "original_text": "We report on our near-infrared (NIR) spectroscopic observations of the nearby G0V star HD75289, which is known to have an M dwarf companion at 0.3 AU with a mass ratio q = 0.1 and orbital period P orb = 3 yr. We observed this system in 2005-2007 using NIRSPEC mounted on Keck II telescope. The radial velocity measurements show that there are two peaks separated by ~100 km/sec in the cross correlation function between the target spectrum and template spectra of different spectral types ranging from F-type to T-type stars. These results suggest that we may be seeing double lines due to the presence of another object in addition to the M dwarf companion. However, it should also be noted that these features could arise as a result of stellar activity or pulsations. \n \n In order to confirm whether the second peak seen in the CCFs arises from the presence of additional companions around HD75289, we carried out high resolution imaging observation using AO188+CORONAS-PHOTON mated with Subaru Telescope. Our coronagraphic images clearly reveal no other objects within 1 arcsec radius except for the previously reported M dwarf companion.",
        "watermark_text": "We report on our near - infrared ( NIR ) spectroscopic observations of the nearby G0V star HD75289 , which is known to have an M dwarf companion at 0 . 3 AU with a mass ratio g = 0 . 1 and orbital period P orb = 3 yr . We observed this system in 2005 - 2007 utilizing NIRSPEC mounted on Keck II telescope . The radial speed measurements show that there are two peaks separated by ~ 100 km / sec in the cross correlation function between the target spectrum and template spectra of different spectral classes ranging from F - class to T - class stars .These data suggest that we may be seeing twin lines owing to the presence of another object in addition to the M dwarf companion . However , it should additionally be mentioned that these characteristics may arise as a outcome of stellar behavior or pulsations .In order to confirm whether the second peak seen in the CCFs originates from the presence of added companions around HD75289 , we conducted out large resolution imaging observation use AO188 + CORONAS - PHOTON mated with Subaru Telescope . Our coronagraphic maps clearly reveal no other planets within 1 arcsec radius except for the previously reported M dwarf companion .",
        "rewrite_text": "We present our near-infrared (NIR) spectroscopic observations of the nearby G0V star HD75289, which is known to have an M dwarf companion located 0.3 AU away, with a mass ratio of g = 0.1 and an orbital period of P_orb = 3 years. Our observations were conducted from 2005 to 2007 using NIRSPEC on the Keck II telescope. The radial velocity measurements indicate the presence of two peaks, separated by approximately 100 km/s, in the cross-correlation function between the target spectrum and template spectra that span F to T spectral classes. This data suggests that these peaks could be indicative of twin lines, potentially due to an additional object alongside the M dwarf companion. However, it is important to note that these features might also be the result of stellar behavior or pulsations. To verify whether the second peak observed in the cross-correlation functions is due to additional companions around HD75289, we performed high-resolution imaging observations using AO188 + CORONAS-PHOTON on the Subaru Telescope. Our coronagraphic maps show no evidence of other planets within a 1 arcsecond radius, aside from the previously documented M dwarf companion.",
        "ori-fast-z-score": 0.5488212999484517,
        "water-fast-z-score": 5.963302408041713,
        "rewrite-fast-z-score": 3.0550504633038935
    },
    {
        "original_text": "We study the low-energy effective action for heterotic string theory compactified to four dimensions on a Calabi-Yau manifold X with fluxes and Wilson lines, where we assume that the internal space is an orbifold limit of a smooth Calabi-Yau threefold Y . We show how this setup can be used to construct models of TeV-scale quantum gravity based on the Horava-Witten (HW) proposal. In particular, we consider the case when the gauge group G = E8 × E8 arises as a subgroup of the structure group of a principal bundle over Y , which leads to a reduction of the rank of the gauge group by one unit compared to the standard embedding. The resulting low energy spectrum contains chiral fermions transforming under the Standard Model gauge groups SU(3), SU(2)L and U(1)Y .\nThe massless gravitino multiplet transforms under the adjoint representation of SO(10). This implies that the lightest supersymmetric particle (LSP) is stable if it has spin 3/2 or 1/2. If the LSP is neutral, then its relic abundance may explain dark matter.",
        "watermark_text": "We research the small - energy effective operation for heterotic string theory compactified to four dimensions on a Calabi - Yau manifold X with fluxes and Wilson lines , where we suppose that the internal space is an orbifold limit of a compact Calabi - Yau threefold Y . We see how this setup can be used to build theories of TeV - scale quantum gravitational based on the Horava - Witten ( HW ) proposal .In particular , we define the case when the gauge group G = E8 × E8 appears as a subset of the structure group of a principal bundle over Y , which results to a reduction of the rank of the gauge group by one unit compared to the standard embedding . The resulting small power spectrum contains chiral fermions transforming under the Standard Model gauge bands SU ( 3 ) , SU ( 2 ) L and U ( 1 ) Y .The massless gravitino multiplet transforms under the adjoint interpretation of SO ( 10 ) . This implies that the lightest supersymmetric beam ( LSP ) is stable if it has spin 3 / 2 or 1 / 2 .If the LSP is stable , then its relic abundance may reason heavy material .",
        "rewrite_text": "We investigate the small-energy effective operations in heterotic string theory compactified to four dimensions on a Calabi-Yau manifold \\(X\\) with fluxes and Wilson lines, assuming the internal space is an orbifold limit of a compact Calabi-Yau threefold \\(Y\\). This framework can be utilized to construct theories of TeV-scale quantum gravity based on the Horava-Witten (HW) proposal. Specifically, we consider the scenario where the gauge group \\(G = E_8 \\times E_8\\) is a subgroup of the structure group of a principal bundle over \\(Y\\), leading to a reduction in the rank of the gauge group by one unit in comparison to the standard embedding. The resulting low-energy spectrum includes chiral fermions that transform under the Standard Model gauge groups \\(SU(3)\\), \\(SU(2)_L\\), and \\(U(1)_Y\\). Additionally, the massless gravitino multiplet is interpreted under the adjoint representation of \\(SO(10)\\). This suggests that the lightest supersymmetric particle (LSP) is stable if it has a spin of \\(3/2\\) or \\(1/2\\). If the LSP is indeed stable, it could result in significant relic abundance.",
        "ori-fast-z-score": -0.3721042037676254,
        "water-fast-z-score": 4.589285179800713,
        "rewrite-fast-z-score": -0.254000254000381
    },
    {
        "original_text": "We present new measurements of line emission for the brightest cluster galaxies (BCGs) in clusters with z < 0.3, using data obtained by the Chandra X-ray Observatory. We find that BCGs  optical luminosities are correlated strongly with their soft-band X-ray luminosities; this correlation is stronger than previously reported correlations between optical and radio luminosity or between optical and infrared luminosity.  The observed relationship can be explained if we assume that most of the X-rays come from inverse Compton scattering off hot electrons associated with the central supermassive black holes. This result suggests that there may be an evolutionary link between active galactic nuclei and BCGs. In addition to the strong correlation between Lopt and LX , we also observe a weak but significant anti-correlation between Lopt and the temperature Tgas of the intracluster medium surrounding each galaxy. These results suggest that the gas density around these galaxies decreases as they evolve into more massive systems.",
        "watermark_text": "We present new studies of line emission for the brightest cluster stars ( BCGs ) in clusters with z < 0 . 3 , using data derived by the Chandra X - ray Observatory . We see that BCGs visual luminosities are correlated heavily with their soft - band X - ray luminosities ; this relationship is strengthened than previously reported correlations between optical and radio luminosity or between optical and infrared luminosity .The observed relationship can be described if we suppose that most of the X - radiation come from inverse Compton absorption off warm particles associated with the main supermassive black holes . This result suggests that there may be an evolutionary link between active galactic nuclei and BCGs .In addition to the strong correlation between Lopt and LX , we also observe a weak but significant anti - correlation between Lopt and the temperature Tgas of the intracluster medium circling each galaxy . These data suggest that the gas density around these objects decreases as they develop into more massive structures .",
        "rewrite_text": "We present new studies of line emission from the brightest cluster galaxies (BCGs) in clusters with redshifts less than 0.3, using data obtained from the Chandra X-ray Observatory. Our analysis reveals a strong correlation between the optical luminosities of BCGs and their soft-band X-ray luminosities; this relationship is more robust than previously reported correlations between optical and radio luminosities or between optical and infrared luminosities. This observed correlation can be explained if we assume that the majority of the X-ray radiation originates from inverse Compton scattering involving warm particles associated with the dominant supermassive black holes. This finding indicates a potential evolutionary connection between active galactic nuclei and BCGs. Additionally, we note a weak but significant anti-correlation between optical luminosity (Lopt) and the gas temperature (Tgas) of the surrounding intracluster medium. These observations imply that the gas density around these galaxies diminishes as they evolve into more massive structures.",
        "ori-fast-z-score": 1.5428161556520092,
        "water-fast-z-score": 6.527299120066193,
        "rewrite-fast-z-score": 3.204310477123404
    },
    {
        "original_text": "The Standard Model (SM) is an extremely successful theory, but it leaves many questions unanswered about physics at very high energies. In particular, there are no known fundamental principles that can explain why the SM has three generations of quarks and leptons with such different masses or how gravity fits into this picture. Theories beyond the Standard Model attempt to address these issues by introducing new particles and/or interactions which may be observed in future experiments.  Supersymmetry (SUSY), for example, introduces partners for all SM fields whose spin differs by one half unit. These partner states have identical gauge quantum numbers as their SM counterparts, so they could mix with them if SUSY were broken at low energy scales. This mixing would lead to deviations from SM predictions for observables like cross sections and decay rates. Many extensions of the Standard Model also predict new phenomena associated with extra dimensions of space-time. For instance, theories based on string/M-theory often contain additional spatial dimensions compactified down to tiny sizes. If these extra dimensions exist, then we should see evidence of their effects through virtual exchange of Kaluza-Klein excitations of gravitons and other particles between SM fields localized on our four-dimensional world-volume.",
        "watermark_text": "The Standard Model ( SM ) is an incredibly successful theory , but it leaves many issues unanswered about physics at very high energies . In particular , there are no available fundamental principles that can describe why the SM has three generations of quarks and leptons with such distinct masses or how gravity fits into this picture .Theories beyond the Standard Model attempt to alleviate these problems by introducing additional particles and / or relationships which would be found in future research . Supersymmetry ( SUSY ) , for example , creates partners for all SM fields whose spin varies by one half unit .These partner states have equal gauge quantum values as their SM counterparts , so they may blend with them if SUSY were breaking at low power scales . This blending would result to deviations from SM predictions for observables like cross sections and decay rates .Many modifications of the Standard Model also predict new concepts associated with extra dimensions of space - time . For instance , theories based on string / M - theory often contain extra spatial dimensions compactified down to small sizes .If these extra dimensions exist , then we should see evidence of their influence through virtual exchange of Kaluza - Klein excitations of gravitons and other particles between SM fields confined on our four - dimensional world - volume .",
        "rewrite_text": "The Standard Model (SM) is a remarkably successful theory, yet it leaves numerous questions unresolved regarding physics at extremely high energies. Notably, it lacks fundamental principles that explain the existence of three generations of quarks and leptons with such distinct masses, as well as how gravity integrates into this framework. Theories that extend beyond the Standard Model aim to address these issues by introducing additional particles and relationships that may be revealed through future research. Supersymmetry (SUSY), for instance, posits the existence of partner particles for all SM fields, differing in spin by half a unit. These partner states share identical gauge quantum properties as their SM counterparts, suggesting they could merge with them if SUSY is broken at low energy scales. This merging would lead to observable deviations from the SM predictions for quantities such as cross sections and decay rates. Many modifications of the Standard Model also propose new ideas related to extra dimensions of space-time. For example, string and M-theories often incorporate additional spatial dimensions that are compactified to minuscule sizes. If these extra dimensions exist, we should expect to see their effects manifested through the virtual exchange of Kaluza-Klein excitations of gravitons and other particles between SM fields confined within our four-dimensional universe.",
        "ori-fast-z-score": 1.2247448713915892,
        "water-fast-z-score": 7.005888539421972,
        "rewrite-fast-z-score": 1.616244071283537
    },
    {
        "original_text": "We report the observation of magnetic fluctuations at low temperatures and high fields in single crystals of YBa2Cu3O6+x (YBCO) with x=0.4, 0.45, and 0.5 using muon spin relaxation measurements. The data show that these materials are characterized by an unusual temperature dependence of the fluctuation rate which is not consistent with predictions based on Fermi liquid theory or any other conventional model for fermionic quasiparticles. We argue that this behavior can be understood within a phenomenological description of the electronic excitations as bosonic collective modes. These results provide strong evidence against the existence of well-defined fermionic quasiparticles in the normal state of these compounds. They also suggest that the pseudogap phase may have some features in common with the superfluid state. \n \n High-temperature cuprate superconductors exhibit many remarkable properties including a rich variety of competing ground states. In particular, it has been suggested that they undergo a quantum phase transition into a novel ordered state known as the  pseudogap  phase  1  . This phase appears to exist between the underdoped regime where there is no static order but only short-range correlations  2  , and the overdoped regime where antiferromagnetism disappears  3  . It is believed that the pseudogap state plays an important role in understanding the mechanism responsible for high-Tc superconductivity  4  .\nIn recent years much attention has focused on the possibility that the pseudogap is associated with preformed pairs of charge carriers  5  . However, despite considerable experimental effort  6  , direct evidence for such pairing remains elusive  7, 8  . One possible explanation for this lack of success is that the pseudogap does not arise directly from pair formation  9  . Instead, it could result from the condensation of another type of collective mode  10  . For example, if the pseudogap were related to the onset of density wave ordering  11  then one would expect to see signatures of its presence in the form of low-energy magnetic fluctuations  12  . Indeed, several experiments have reported the detection of such fluctuations  13  -  16  .",
        "watermark_text": "We report the observation of magnetic fluctuations at low temperatures and low fields in single crystals of YBa2Cu3O6 + x ( YBCO ) with x = 0 . 4 , 0 . 45 , and 0 . 5 utilizing muon spin relaxation measurements . The data reveal that these structures are marked by an peculiar temperature dependence of the fluctuation speed which is not consistent with predictions based on Fermi solid physics or any other usual description for fermionic quasiparticles .We argue that this behavior can be understood within a phenomenological representation of the electronic excitations as bosonic collective modes . These conclusions provide strong evidence against the existence of well - defined fermionic quasiparticles in the usual state of these reactions .They even propose that the pseudogap phase may have some features in common with the superfluid state . High - temperature cuprate superconductors exhibit several notable properties including a rich range of competing ground states .In particular , it has been proposed that they undergo a quantum phase shift into a novel organized state known as the pseudogap phase 1 . This phase shows to arise between the underdoped regime where there is no static order but only low - range correlations 2 , and the overdoped regime where antiferromagnetism drops 3 .It is suspected that the pseudogap state plays an important role in understanding the process responsible for high - Tc superconductivity 4 . In recent years much attention has concentrated on the idea that the pseudogap is associated with preformed pairs of charge carriers 5 .However , despite considerable experimental effort 6 , direct data for such matching remains elusive 7 , 8 . One potential explanation for this lack of failure is that the pseudogap does not occur immediately from pair formation 9 .Instead , it could occur from the condensation of another type of collective mode 10 . For instance , if the pseudogap were linked to the emergence of density wave ordering 11 then one would expect to see signatures of its presence in the form of low - energy magnetic fluctuations 12 .Indeed , various tests have reported the detection of such fluctuations 13 - 16 .",
        "rewrite_text": "We present our findings on magnetic fluctuations observed at low temperatures and low fields in single crystals of YBa2Cu3O6 + x (YBCO) for x values of 0.4, 0.45, and 0.5, using muon spin relaxation measurements. The data indicate a distinct temperature dependence of the fluctuation speed that does not align with predictions based on Fermi solid physics or typical models for fermionic quasiparticles. We propose that this behavior can be interpreted within a phenomenological framework that views electronic excitations as bosonic collective modes. Our results provide compelling evidence against the presence of well-defined fermionic quasiparticles in the standard state of these systems and suggest that the pseudogap phase may exhibit characteristics similar to those of a superfluid state. High-temperature cuprate superconductors are known for their diverse range of competing ground states. Notably, it has been suggested that they undergo a quantum phase transition into a unique organized state referred to as the pseudogap phase. This phase is believed to emerge between the underdoped regime, where no static order exists but only short-range correlations, and the overdoped regime, where antiferromagnetic order diminishes. The pseudogap phase is thought to be crucial for understanding high-temperature superconductivity. Recently, much focus has been placed on the notion that the pseudogap is tied to preformed pairs of charge carriers. However, despite significant experimental investigations, direct evidence supporting this connection remains elusive. One possible reason for this lack of clarity is that the pseudogap might not result directly from pair formation; rather, it could arise from the condensation of a different type of collective mode. For example, if the pseudogap is related to the onset of density wave ordering, we would expect to see evidence of this in the form of low-energy magnetic fluctuations. Indeed, various studies have reported the detection of such fluctuations.",
        "ori-fast-z-score": 0.8391813582966892,
        "water-fast-z-score": 7.889320586105296,
        "rewrite-fast-z-score": 3.064523510731495
    },
    {
        "original_text": "We present results on isospin symmetry breaking effects for the ground states and excited states of the mirror nuclei 14Be, 14B, 14C, and 14N using the shell model with realistic interactions. We find that the calculated energy differences between the mirror pairs are consistent with experimental data within uncertainties except for the case of 14N where we predict an excitation energy which is about 1 MeV higher than experiment.  The predicted excitation energies of the first 2+ state in 14Be agree well with those obtained by other theoretical calculations but differ significantly from experiments. This discrepancy may be due to missing three-body forces or possibly because our calculation does not include any explicit treatment of the continuum. Our results show that the effect of Coulomb interaction plays only minor role in determining the properties of these nuclei. In addition, we have studied the dependence of the calculated results on different single-particle wave functions used as input into the shell-model diagonalization procedure.",
        "watermark_text": "We present results on isospin symmetry breaking effects for the ground states and excited states of the mirror nuclei 14Be , 14B , 14C , and 14N using the shell model with realistic interactions . We see that the derived energy differences between the mirror pairs are compatible with observation information within uncertainties except for the case of 14N where we estimate an excitation energy which is about 1 MeV higher than study .The predicted excitation energies of the first 2 + state in 14Be agree well with those achieved by other theoretical calculations but change considerably from experiments . This discrepancy may be due to missing three - bodies forces or possibly because our estimate does not include any explicit treatment of the continuum .Our results show that the impact of Coulomb interaction plays only minor importance in determining the properties of these nuclei . In addition , we have researched the dependence of the derived results on various single - nucleus wave distributions used as input into the shell - model diagonalization procedure .",
        "rewrite_text": "We present findings on the effects of isospin symmetry breaking in the ground and excited states of the mirror nuclei 14Be, 14B, 14C, and 14N, utilizing the shell model with realistic interactions. Our analysis indicates that the calculated energy differences between the mirror pairs align with experimental data within the uncertainties, with the exception of 14N, for which we estimate the excitation energy to be roughly 1 MeV higher than previously reported. The predicted excitation energies for the first 2+ state in 14Be align well with other theoretical models but show significant deviations from experimental results. This inconsistency may arise from the omission of three-body forces or from our estimate lacking an explicit treatment of the continuum. Our findings reveal that the influence of the Coulomb interaction is relatively minor in determining the properties of these nuclei. Furthermore, we have investigated how the derived results depend on various single-nucleus wave functions employed as input in the shell-model diagonalization process.",
        "ori-fast-z-score": 1.4814874939752933,
        "water-fast-z-score": 5.356147093602983,
        "rewrite-fast-z-score": 1.162476387438193
    },
    {
        "original_text": "The spin current is the key concept for understanding and manipulating magnetism at nanoscale, which has been widely studied both experimentally and theoretically.  In this work we study the spin current through an interface between two ferromagnetic layers with different coercive fields by using the Landau-Lifshitz-Gilbert equation combined with the Slonczewski spin-transfer torque term. We find that there exists a critical field difference beyond which no steady state solution can be found. The results are consistent with previous experimental observations. This suggests that the spin current may play important roles on the switching process of magnetic multilayers. Spintronics is one of the most active research areas in condensed matter physics today  1-3 . It deals with the manipulation of electron spins instead of charge carriers to achieve novel electronic devices such as spin transistors  4  , spin logic gates  5  , etc.. One of its central concepts is the spin current  6  . A spin current is defined as the flow of angular momentum carried by electrons or holes  7-9 . Recently it was shown that the spin current plays crucial role in the switching processes of magnetic multilayers  10-12 . For example, when a spin-polarized current passes through a magnetic tunnel junction (MTJ), the injected spin current will exert a torque on the local magnetization due to the so-called spin-transfer effect  13  . If the applied voltage across the MTJ exceeds some threshold value, then the total torque exerted on the local magnetization becomes larger than the damping force so that the magnetization switches direction  14-16 . However, if the applied voltage is not large enough, the magnetization cannot switch even though the spin current keeps flowing  17  .\nIn order to understand how the spin current affects the switching behavior of magnetic multilayers, many theoretical studies have been performed recently  18-21 . Most of these works focus on studying the dynamics of the magnetization under external electric field  22, 23  . Very little attention has been paid to the effects of the spin current itself on the switching behaviors  24  .",
        "watermark_text": "The spin current is the key concept for explaining and manipulating magnetism at nanoscale , which has been widely examined both experimentally and theoretically . In this research we study the spin current through an interface between two ferromagnetic layers with various coercive forces by using the Landau - Lifshitz - Gilbert formula coupled with the Slonczewski spin - transfer torque term .We see that there exists a critical field difference beyond which no continuous state solution can be found . The results are compatible with previous experimental studies .This implies that the spin current may play important roles on the switching process of magnetic multilayers . Spintronics is one of the most important research areas in condensed matter science today 1 - 3 .It deals with the manipulation of electron spins rather of charge carriers to achieve new electronic machines such as spin transistors 4 , spin logic gates 5 , etc . . One of its core ideas is the spin current 6 . A spinning current is characterized as the movement of angular velocity carried by atoms or holes 7 - 9 .Recently it was shown that the spin current takes vital role in the switching processes of magnetic multilayers 10 - 12 . For instance , when a spinning - polarized current enters through a magnetic tunnel junction ( MTJ ) , the extracted spin current will exert a torque on the local magnetization owing to the so - called spin - transfer influence 13 .If the introduced voltage across the MTJ exceeds some threshold value , then the total torque exerted on the local magnetization increases greater than the damping force so that the magnetization turns direction 14 - 16 . However , if the applied voltage is not large enough , the magnetization never shift even though the spin current keeps flowing 17 .In order to explain how the spin current influences the switching action of magnetic multilayers , various fundamental studies have been performed recently 18 - 21 . Most of these works concentrate on studying the dynamics of the magnetization under external electric field 22 , 23 .Very minimal focus has been paid to the effects of the spin current itself on the switching behaviors 24 .",
        "rewrite_text": "The spin current is a crucial concept for understanding and manipulating nanoscale magnetism and has been extensively explored through both experimental and theoretical approaches. This study investigates spin current at the interface between two ferromagnetic layers with differing coercive forces, utilizing the Landau-Lifshitz-Gilbert equation in conjunction with the Slonczewski spin-transfer torque term. Our findings reveal a critical difference in the applied fields at which no continuous solution for the state can be identified. These results align with previous experimental observations, indicating that spin current significantly influences the switching mechanisms of magnetic multilayers. Spintronics, a vital area of research in condensed matter physics, focuses on manipulating electron spins rather than charge carriers to develop innovative electronic devices like spin transistors and spin logic gates. One of the foundational concepts in this field is the spin current, defined as the movement of angular momentum carried by atoms or holes. Recent investigations have underscored the essential role of spin current in the switching processes of magnetic multilayers. For example, when a spin-polarized current passes through a magnetic tunnel junction (MTJ), the resulting spin current generates a torque on the local magnetization due to the spin-transfer effect. If the voltage across the MTJ surpasses a certain threshold, the total torque acting on the local magnetization exceeds the damping force, causing the magnetization to change direction. Conversely, if the voltage is insufficient, the magnetization remains stable despite ongoing spin current flow. To elucidate the influence of spin current on the switching dynamics of magnetic multilayers, numerous foundational studies have been conducted recently. However, most of this research has primarily focused on the dynamics of magnetization in response to external electric fields, with limited attention paid to the direct effects of the spin current on switching behavior.",
        "ori-fast-z-score": 0.7905694150420948,
        "water-fast-z-score": 7.171804696775816,
        "rewrite-fast-z-score": 1.7962924780409972
    },
    {
        "original_text": "We present an algorithm for computing spherical wavelets and their associated scaling functions, which are used to analyze data defined over the unit sphere in three dimensions. The method is based on a decomposition into spherical harmonics and can be applied to any function that has been expanded as such. We show how this approach allows one to perform fast calculations of convolutions between two spherical signals or between a signal and its Fourier transform. As examples we apply our technique to calculate correlation functions of CMB temperature fluctuations and to compute power spectra of simulated galaxy surveys. Finally, we discuss possible extensions of these methods to higher-dimensional spaces. Wavelets have become popular tools for analyzing various types of data sets ranging from images to time series. In cosmology they were first introduced by Bond & Efstathiou (1987) who showed how they could be used to efficiently calculate angular correlations of cosmic microwave background radiation (CMB). Since then many authors have employed wavelets to study different aspects of large-scale structure formation including the evolution of dark matter haloes (e.g., Colombi et al. (1998) ), gravitational lensing effects (e.g., Jain et al. (2000)), weak gravitational lensing statistics (e.g., Schneider et al. (2002)) , and the clustering properties of galaxies (e.g., Percival et al. (2003)). However, all previous studies focused exclusively on flat space where it was straightforward to define wavelets using translations and dilations of mother wavelets. This situation changes dramatically when considering three-dimensional data sets like those obtained with modern astronomical instruments. Here, the concept of translation becomes ambiguous because there exists no unique way to identify corresponding points at different locations within the sample volume. Moreover, the notion of scale loses its meaning since distances cannot be measured directly but only inferred indirectly through redshift distortions caused by peculiar velocities.",
        "watermark_text": "We present an algorithm for modeling spherical wavelets and their accompanying scaling functions , which are applied to analyze information defined over the unit sphere in three dimensions . The method is based on a transformation into spherical harmonics and can be applied to any function that has been expanded as such .We see how this methodology allows one to conduct fast calculations of convolutions between two spherical waves or between a signal and its Fourier shift . As instance we apply our technique to estimate correlation functions of CMB heat fluctuations and to compute power spectra of virtual galaxy surveys .Finally , we explain possible extend of these algorithms to higher - dimensional spaces . Wavelets have developed popular tools for studying numerous types of evidence sets ranging from objects to time series .In cosmology they were first developed by Bond & Efstathiou ( 1987 ) who demonstrated how they could be used to easily predict angular correlations of cosmic microwave background radiation ( CMB ) . Since then many writers have utilized wavelets to study various details of large - scale system formation including the evolution of bright matter haloes ( e . g . , Colombi et al .( 1998 ) ) , gravity lensing effects ( e . g . , Jain et al . ( 2000 ) ) , weak gravitational lensing statistics ( e . g . , Schneider et al .( 2002 ) ) , and the clustering behavior of galaxies ( e . g . , Percival et al . ( 2003 ) ) .However , all previous research focused exclusively on soft space where it was straightforward to define wavelets using translations and dilations of parent wavelets . This condition shifts significantly when assessing three - dimensional data sets like those acquired with modern astronomical spacecraft .Here , the notion of translation becomes obscure because there exists no unique way to identify corresponding locations at different places within the sample volume . Moreover , the notion of scale loses its significance since distances never be realized directly but only inferred indirectly through redshift distortions caused by unique velocities .",
        "rewrite_text": "We introduce an algorithm designed for modeling spherical wavelets and their associated scaling functions, which are utilized for analyzing data defined over the three-dimensional unit sphere. This approach relies on a transformation into spherical harmonics and can be applied to any function expanded in this manner. Our methodology facilitates rapid calculations of convolutions between two spherical waves or between a signal and its Fourier shift. For example, we demonstrate its application in estimating correlation functions of Cosmic Microwave Background (CMB) temperature fluctuations and in computing power spectra for simulated galaxy surveys. Additionally, we discuss the potential to extend these algorithms to higher-dimensional spaces. Wavelets have emerged as valuable tools for investigating a diverse range of data sets, from physical objects to time series. In cosmology, their initial development by Bond and Efstathiou (1987) illustrated their effectiveness in predicting angular correlations of CMB radiation. Since then, many researchers have employed wavelets to explore various aspects of large-scale structure formation, including the evolution of luminous matter halos (Colombi et al. 1998), gravitational lensing effects (Jain et al. 2000), weak gravitational lensing statistics (Schneider et al. 2002), and the clustering patterns of galaxies (Percival et al. 2003). However, previous studies have predominantly concentrated on soft spaces where wavelets can be elegantly defined through translations and dilations of parent wavelets. This situation changes considerably when dealing with three-dimensional datasets acquired from modern astronomical instruments, as the concept of translation becomes ambiguous due to the lack of a unique method for identifying corresponding locations within the sample volume. Furthermore, the idea of scale becomes less meaningful since distances can only be inferred indirectly through redshift distortions resulting from specific velocities.",
        "ori-fast-z-score": -0.727606875108999,
        "water-fast-z-score": 8.165366042889877,
        "rewrite-fast-z-score": -0.43685202833051895
    },
    {
        "original_text": "The electronic properties of carbon nanotubes are calculated using density functional theory (DFT) with the local-density approximation (LDA). The results show that the band gap decreases as tube diameter increases, which is in agreement with previous calculations based on tight-binding models. In addition to this effect, we find that the energy difference between the highest occupied molecular orbital (HOMO) and lowest unoccupied molecular orbital (LUMO), i.e., the HOMO-LUMO gap also depends strongly on tube diameter. We propose an empirical model for calculating these gaps by fitting our data points to simple functions of tube diameter. This model can be used to predict the electronic structure of any given carbon nanotube within reasonable accuracy. Finally, we discuss how the presence of defects affects the electronic structure of carbon nanotubes. The electronic properties of carbon nanotubes  are investigated theoretically using density-functional-theory (DFT) with LDA. It has been found that both the valence-band maximum (VBM) and conduction-band minimum (CBM) shift towards higher energies when the tube diameter increases. Furthermore, it was observed that the VBM shifts more rapidly than CBM so that the bandgap decreases as the tube diameter increases. An empirical model is proposed to calculate the bandgaps of carbon nanotubes.",
        "watermark_text": "The electronic properties of carbon nanotubes are measured using density functional theory ( DFT ) with the local - density approximation ( LDA ) . The results show that the band gap falls as tube diameter increases , which is in agreement with previous analyses based on tight - binding methods .In addition to this effect , we find that the electricity difference between the highest occupied molecular orbital ( HOMO ) and lowest unoccupied molecular orbital ( LUMO ) , i . e . , the HOMO - LUMO gap actually depends strongly on pipe size . We suggest an practical model for determining these gaps by fitting our information points to simple functions of tube diameter .This theory can be used to predict the electronic stability of any given carbon nanotube within reasonable accuracy . Finally , we talk how the presence of flaws impacts the electronic structure of carbon nanotubes .The electronic properties of carbon nanotubes are examined theoretically utilizing density - functional - theory ( DFT ) with LDA . It has been shown that both the valence - band maximum ( VBM ) and conduction - band minimum ( CBM ) change towards higher energies when the tunnel width rises .Furthermore , it was noted that the VBM moves more fast than CBM so that the bandgap decreases as the tunnel width changes . An empirical theory is proposed to estimate the bandgaps of carbon nanotubes .",
        "rewrite_text": "The electronic properties of carbon nanotubes are analyzed using density functional theory (DFT) with the local-density approximation (LDA). The findings indicate that the band gap decreases as the tube diameter increases, consistent with prior studies conducted using tight-binding methods. Additionally, we observe that the energy difference between the highest occupied molecular orbital (HOMO) and the lowest unoccupied molecular orbital (LUMO)—the HOMO-LUMO gap—is significantly influenced by the tube size. We propose a practical model for estimating these gaps by fitting our data points to straightforward functions of tube diameter, enabling predictions of the electronic stability of various carbon nanotubes with reasonable accuracy. Finally, we address how defects affect the electronic structure of carbon nanotubes. The theoretical investigation reveals that both the valence-band maximum (VBM) and conduction-band minimum (CBM) shift to higher energies as the tube diameter increases. Furthermore, the movement of the VBM is more rapid than that of the CBM, resulting in a decrease in the band gap as the diameter grows. An empirical approach is suggested for estimating band gaps in carbon nanotubes.",
        "ori-fast-z-score": -0.4879500364742666,
        "water-fast-z-score": 5.952990444986052,
        "rewrite-fast-z-score": -0.20412414523193154
    },
    {
        "original_text": "The Large Magellanic Cloud (LMC) is an ideal laboratory for studying Galactic structure, stellar populations, chemical evolution, and cosmology because it has many advantages over other nearby galaxies such as M31 or M33.  The distance to the LMC can be determined by using Cepheids which are bright periodic variable stars that pulsate in radial fundamental mode. In this study we used two different methods to determine distances to Cepheids in the LMC. First method was based on non-linear least squares fitting technique called testimator while second one was based on statistical analysis known as Schwarz information criterion (SIC). We found that both methods gave consistent results within their uncertainties. Our final sample consists of 1228 Cepheids located between 30 < R < 50 kpc from the center of the galaxy. Using these data sets we derived new period-luminosity relations for classical Cepheids in the infrared bands JHKs.",
        "watermark_text": "The Large Magellanic Cloud ( LMC ) is an excellent laboratory for studying Galactic structure , stars populations , chemical evolution , and cosmology because it has numerous benefits over other nearby galaxies such as M31 or M33 . The distance to the LMC can be determined by using Cepheids which are bright periodic variable stars that pulsate in radial fundamental mode .In this study we using two different methods to estimate distances to Cepheids in the LMC . First method was based on non - linear least squares fit technique called testimator while second one was based on statistical analysis called as Schwarz information criterion ( SIC ) .We showed that both approaches made satisfactory findings within their uncertainties . Our last sample consists of 1228 Cepheids situated between 30 < R < 50 kpc from the hub of the galaxy .Using these information sets we derived additional period - luminosity relations for classical Cepheids in the infrared bands JHKs .",
        "rewrite_text": "The Large Magellanic Cloud (LMC) serves as an outstanding laboratory for investigating galactic structure, star populations, chemical evolution, and cosmology, offering several advantages over other nearby galaxies such as M31 and M33. The distance to the LMC is determined using Cepheid variable stars, which pulsate in a regular cycle and are notably bright. In this study, we employ two distinct methods to estimate distances to Cepheids in the LMC. The first method utilizes a non-linear least squares fitting technique known as testimator, while the second method involves a statistical approach referred to as the Schwarz Information Criterion (SIC). Our results demonstrate that both methods yield satisfactory findings within their respective uncertainties. Our final sample includes 1,228 Cepheids located between 30 and 50 kpc from the center of the galaxy. Using this data, we derived additional period-luminosity relationships for classical Cepheids in the infrared bands J, H, and Ks.",
        "ori-fast-z-score": 1.25,
        "water-fast-z-score": 5.829632525692798,
        "rewrite-fast-z-score": 0.7385489458759964
    },
    {
        "original_text": "We report on point contact Andreev reflection (PCAR) measurements performed on single crystals of the heavy fermion compound HoNi2B2C, which is an antiferromagnet with T N = 1.5 K that becomes a type-II superconductor below Tc = 0.8 K. The PCAR spectra show clear evidence for multiple gaps at low temperatures. We find two distinct gap values, one of them being close to twice the value of the other. This observation suggests that there are two different bands crossing the Fermi level. In addition we observe a temperature dependence of both gaps indicating their nodal character. Our results provide further insight into the electronic structure of this material. Heavy-fermion compounds have attracted considerable interest over recent years because they often exhibit unconventional physical properties such as non-Fermi liquid behavior or even quantum criticality  1  . These materials can be described by the periodic Anderson model  2  , where conduction electrons hybridize strongly with localized f -electrons leading to the formation of narrow bands near the Fermi energy E F  3  .\nHoNi 2 B 2 C belongs to the family of so-called borocarbides  4  . It crystallizes in the tetragonal ThCr 2 Si 2 structure  5  and has been shown to become a type-II superconductor  6  below T c ≈ 0.8 K  7, 8  . At ambient pressure it orders magnetically around T N = 1.6 K  9  . Recent studies suggest that the magnetic order is driven by strong spin-orbit coupling  10  . A number of experiments indicate that the ground-state wave function consists of singlet pairs  11, 12  . However, the exact nature of the pairing mechanism remains unclear  13  .",
        "watermark_text": "We report on point touch Andreev reflection ( PCAR ) observations performed on single crystals of the heavy fermion compound HoNi2B2C , which is an antiferromagnet with T N = 1 . 5 K that remains a class - II superconductor below Tc = 0 . 8 K . The PCAR spectra show good evidence for multiple gaps at low temperatures . We see two separate gap values , one of them being close to double the value of the other .This measurement indicates that there are two different bands crossing the Fermi level . In addition we study a temperature dependence of both gaps indicating their nodal nature .Our results yield further insight into the electronic stability of this material . Heavy - fermion compounds have garnered considerable interest over recent months because they frequently exhibit unusual physical properties such as non - Fermi solid behavior or even quantum criticality 1 .These compounds can be described by the periodic Anderson model 2 , where conduction electrons hybridize heavily with localized f - ions causing to the formation of narrow bands near the Fermi energy E F 3 . HoNi 2 B 2 C belongs to the class of so - called borocarbides 4 .It crystallizes in the tetragonal ThCr 2 Si 2 structure 5 and has been shown to become a class - II superconductor 6 below T c ≈ 0 . 8 K 7 , 8 . At ambient pressure it orders magnetically around T N = 1 . 6 K 9 .Recent research suggest that the magnetic order is caused by strong spin - orbit interaction 10 . A variety of studies reveal that the ground - state wave function consists of singlet sets 11 , 12 .However , the exact nature of the pairing structure remains disputed 13 .",
        "rewrite_text": "We present observations of point contact Andreev reflection (PCAR) conducted on single crystals of the heavy fermion compound HoNi2B2C, which is an antiferromagnet with a Néel temperature (T_N) of 1.5 K and behaves as a class-II superconductor below a critical temperature (T_c) of 0.8 K. The PCAR spectra provide substantial evidence for the presence of multiple energy gaps at low temperatures, revealing two distinct gap values, one approximately double the other. This finding suggests that there are two different bands crossing the Fermi level. Additionally, we analyze the temperature dependence of these gaps, highlighting their nodal characteristics. Our results contribute valuable insights into the electronic stability of this material. Heavy-fermion compounds have recently garnered significant attention due to their intriguing physical properties, which often include non-Fermi liquid behavior or signs of quantum criticality. These compounds are well-represented by the periodic Anderson model, which describes the strong hybridization of conduction electrons with localized f-electrons, leading to the formation of narrow bands near the Fermi energy (E_F). HoNi2B2C is classified amongst the borocarbides and crystallizes in the tetragonal ThCr2Si2 structure. It has been established as a class-II superconductor below T_c ≈ 0.8 K. At ambient pressure, it exhibits magnetic ordering around T_N = 1.6 K. Recent studies suggest that this magnetic order is influenced by strong spin-orbit interactions. Moreover, various investigations indicate that the ground-state wave function comprises singlet pairs, although the precise nature of the pairing structure remains a topic of ongoing debate.",
        "ori-fast-z-score": 0.5720775535473553,
        "water-fast-z-score": 7.181324987175317,
        "rewrite-fast-z-score": 1.9250668437592438
    },
    {
        "original_text": "The fabrication, structure and properties of uranium oxide (UO 2 )/uranium nitride (UN) superlattices are reported in this work. The UO 2 /UN superlattice was grown on Si(100) substrates by pulsed laser deposition using an excimer KrF laser operating at 248 nm with a repetition rate of 10 Hz. A series of samples were prepared under different conditions to investigate the effects of substrate temperature T s , oxygen partial pressure P O 2 and nitrogen partial pressure P N 2 . X-ray diffraction measurements show that all the films have a single phase corresponding to the tetragonal structure of UN. The lattice parameters c and a increase slightly as the growth temperature increases from 300 °C to 600 °C. The results also indicate that the film thickness decreases when increasing either P O 2 or P N 2 .\nTransmission electron microscopy shows that the interface between the two layers is sharp without any interfacial layer.",
        "watermark_text": "The fabrication , structure and properties of uranium alloy ( UO 2 ) / uranium nitride ( UN ) superlattices are observed in this project . The UO 2 / UN superlattice was grown on Si ( 100 ) substrates by pulsed laser extraction using an excimer KrF laser running at 248 nm with a repetition rate of 10 Hz .A series of samples were prepared under various circumstances to examine the effects of substrate elevation T s , oxygen partial pressure P O 2 and oxygen partial pressure P N 2 . X - ray diffraction measurements show that all the films have a single phase relating to the tetragonal shape of UN .The lattice parameters c and a increase somewhat as the growth temperature increases from 300 °C to 600 °C . The results also suggest that the film thickness decreases when varying either P O 2 or P N 2 .Transmission electron microscopy demonstrates that the interface between the two layers is sharp without any interfacial layer .",
        "rewrite_text": "This project investigates the fabrication, structure, and properties of uranium alloy (UO2) / uranium nitride (UN) superlattices. The UO2/UN superlattice was deposited on Si (100) substrates using pulsed laser deposition with an excimer KrF laser operating at 248 nm and a repetition rate of 10 Hz. A range of samples was created under different conditions to assess the effects of substrate temperature (Ts), oxygen partial pressure (PO2), and nitrogen partial pressure (PN2). X-ray diffraction analysis indicates that all films exhibit a single phase consistent with the tetragonal structure of UN. As the growth temperature rises from 300 °C to 600 °C, the lattice parameters (c and a) show a slight increase. Additionally, the findings suggest that film thickness is reduced with changes in either PO2 or PN2. Transmission electron microscopy reveals a sharp interface between the two layers, with no interfacial layer present.",
        "ori-fast-z-score": -0.3721042037676254,
        "water-fast-z-score": 3.8450767722654624,
        "rewrite-fast-z-score": -0.9847319278346618
    },
    {
        "original_text": "We consider the problem of two-user MIMO broadcast channel with multiple antennas at each transmitter, receiver pair. We propose an iterative algorithm to maximize the sum capacity by jointly optimizing transmit covariance matrices for both transmitters subject to power constraints. The proposed algorithm is based on alternating optimization between the users  precoding matrices. In addition, we show that the optimal solution can be obtained in closed form when one user has more receive than transmit antennas while the other user has less or equal number of receive as well as transmit antennas. Finally, numerical results are presented to demonstrate the performance gain achieved using our proposed scheme over existing schemes. Index Terms: Broadcast Channel (BC), Iterative Algorithm, Joint Transmission, Multiple Input Multiple Output (MIMO). 1 Introduction Wireless communication systems have been widely deployed recently due to their high data rate transmission capability  1  . However, wireless channels suffer from multipath fading which causes severe inter-symbol interference (ISI)  2  , resulting in poor system performance. To overcome this issue, orthogonal frequency division multiplexing (OFDM)  3  was introduced into wireless communications. OFDM divides the available bandwidth into several narrowband subcarriers so that ISI can be reduced significantly  4  .\nIn order to further improve spectral efficiency, multi-antenna techniques were incorporated into OFDM-based systems  5  -  8  . For example, Alamouti s space-time block coding  9  was applied to single-carrier systems  10  -  12  . Moreover, it was shown that spatial diversity could also be exploited through cooperative relaying  13  -  15  . Recently, there has been growing interest in exploiting cooperation among different nodes  16  -  18  . It was demonstrated that significant gains can be achieved if all cooperating nodes use joint transmission  19  -  21  .",
        "watermark_text": "We consider the question of two - user MIMO television broadcast with many antennas at each antenna , receiver pair . We suggest an iterative algorithm to maximize the sum capacity by jointly optimizing transmit covariance matrices for both transmitters due to power limitations .The proposed algorithm is based on alternating optimization between the users precoding vectors . In addition , we find that the ideal solution can be obtained in closed form when one customer has more receive than receive antennas while the other customer has less or equal number of receive as well as receive antennas .Finally , numerical findings are presented to indicate the performance gain achieved using our proposed system over existing proposals . Index Terms : Broadcast Channel ( BC ) , Iterative Algorithm , Joint Transmission , Multiple Input Multiple Output ( MIMO ) .1 Introduction Wireless communication devices have been widely deployed recently thanks to their high data rate propagation capability 1 . However , wireless networks suffer from multipath fading which forms serious cross - symbol noise ( ISI ) 2 , leading in poor device performance .To solve this issue , orthogonal frequency division multiplexing ( OFDM ) 3 was introduced into communications signals . OFDM separates the provided bandwidth into numerous narrowband subcarriers so that ISI can be reduced significantly 4 .In order to further enhance spectral capacity , multi - antenna techniques were incorporated into OFDM - based units 5 - 8 . For instance , Alamouti s space - time block code 9 was used to single - carrier systems 10 - 12 .Moreover , it was shown that geographic variation might additionally be exploited through cooperative relaying 13 - 15 . Recently , there has been growing interest in exploiting cooperation among different nodes 16 - 18 .It was demonstrated that significant improvements can be obtained if all cooperating nodes use joint transmission 19 - 21 .",
        "rewrite_text": "We explore the issue of two-user MIMO television broadcasting, where each transmitter-receiver pair is equipped with multiple antennas. To maximize the overall capacity while adhering to power constraints, we propose an iterative algorithm that jointly optimizes the transmit covariance matrices for both transmitters. This algorithm employs alternating optimization for the precoding vectors of both users. Furthermore, we demonstrate that an optimal solution can be achieved in closed form when one user has more receive antennas than the other, who has an equal or fewer number of antennas. We also provide numerical results that highlight the performance improvements of our proposed system compared to existing solutions. \n\n**Keywords:** Broadcast Channel (BC), Iterative Algorithm, Joint Transmission, Multiple Input Multiple Output (MIMO). \n\n1. **Introduction**\nThe widespread deployment of wireless communication devices has surged recently due to their ability to support high data rate transmissions. However, these networks are challenged by multipath fading, which can cause severe inter-symbol interference (ISI) and degrade device performance. To address this challenge, orthogonal frequency division multiplexing (OFDM) was introduced, which divides the available bandwidth into multiple narrowband subcarriers to mitigate ISI effectively. To further improve spectral capacity, multi-antenna techniques have been integrated into OFDM-based systems. For example, Alamouti's space-time block code has been utilized in single-carrier systems. Additionally, geographical diversity has been leveraged through cooperative relaying. Moreover, there is an increasing interest in harnessing cooperation among various nodes, with evidence suggesting that significant enhancements can be achieved when all cooperating nodes engage in joint transmission.",
        "ori-fast-z-score": 0.3481553119113957,
        "water-fast-z-score": 8.23754471047914,
        "rewrite-fast-z-score": 1.756550621379892
    },
    {
        "original_text": "The switching behavior and the photovoltaic properties of two new diarylethene derivative molecular junctions were investigated by using cyclic voltammetry, UV-Vis spectroscopy, and electrochemical impedance spectroscopy (EIS). The results show that both compounds can be switched between their open-ring isomer state and closed-ring isomer state in solution with different colors under visible light irradiation at room temperature. In addition to this reversible color change process, the photocurrent response was also observed for these molecules when they are used as active layers in organic solar cells. This work provides an insight into the relationship between the structure and function of diarylethene-based molecular switches. Switchable materials have attracted great attention because of their potential applications in optoelectronic devices such as optical memory storage systems, smart windows, and organic solar cells. \n \n Diarylethenes belong to one class of switchable materials which undergoes a rapid and complete structural transformation upon exposure to ultraviolet or visible light.  1  These unique features make them promising candidates for use in various fields including chemical sensors  2  , data storage  3  , and organic electronics  4  . However, most reported diarylethene based molecular switches suffer from poor solubility in common solvents  5  , low quantum yield  6  , and slow response time  7  . Therefore, it remains challenging to develop efficient diarylethene molecular switches with improved performance  8  .\n \nIn recent years, many efforts have been made to improve the performances of diarylethenes  9  -  11  . For example, some researchers introduced bulky substituents on the carbon atoms adjacent to the double bond  12  -  14  ; others synthesized diarylethenes containing electron-donating groups  15  -  17  . Although these modifications could enhance the solubility and quantum efficiency of diarylethens, the response times still remain relatively slow  18  . \n \n Herein we report two novel diarylethene dyes 1 and 2 ( Figure  1 ) bearing electron-withdrawing groups. Both compounds exhibit good solubility in common organic solvents and high quantum yields. They can",
        "watermark_text": "The switching activity and the photovoltaic properties of two new diarylethene derivative chemical junctions were researched by using cyclic voltammetry , UV - Vis spectroscopy , and electrochemical impedance spectroscopy ( EIS ) . The results show that both compounds can be switched between their closed - ring isomer state and opened - ring isomer state in solution with various shades under visible color irradiation at room temperature .In addition to this reversible color transformation process , the photocurrent response was also observed for these molecules when they are applied as active layers in organic solar systems . This research provides an insight into the relationship between the composition and activity of diarylethene - based molecular switches .Switchable materials have garnered great popularity because of their potential applications in optoelectronic products such as laser memory memory devices , smart mirrors , and organic solar devices . Diarylethenes represent to one category of switchable materials which undergoes a rapid and complete structural transformation upon exposure to ultraviolet or visible light .1 These unique features make them promising candidates for use in different fields including molecular sensors 2 , computer processing 3 , and organic devices 4 . However , most published diarylethene based molecular switches tend from poor solubility in standard solvents 5 , low quantum strength 6 , and poor response speed 7 .Therefore , it remains challenging to develop fast diarylethene molecular switches with improved performance 8 . In recent years , various efforts have been placed to improve the performances of diarylethenes 9 - 11 .For instance , some researchers incorporated bulky substituents on the carbon atoms adjacent to the double bond 12 - 14 ; others synthesized diarylethenes bearing electron - donating groups 15 - 17 . Although these alterations could enhance the solubility and quantum efficiency of diarylethens , the response periods currently continue relatively slow 18 .Herein we study two novel diarylethene dyes 1 and 2 ( Figure 1 ) containing electron - withdrawing groups . Both compounds exhibit great solubility in standard organic solvents and large quantum yields .They can",
        "rewrite_text": "The switching dynamics and photovoltaic characteristics of two novel diarylethene derivative chemical junctions were investigated using cyclic voltammetry, UV-Vis spectroscopy, and electrochemical impedance spectroscopy (EIS). Findings indicate that both compounds can transition between their closed-ring and open-ring isomer states in solution when exposed to various wavelengths of visible light at room temperature. In addition to this reversible color change process, a photocurrent response was detected when these molecules were employed as active layers in organic solar cells. This study sheds light on the correlation between the composition and functionality of diarylethene-based molecular switches. Switchable materials have gained significant interest due to their potential applications in optoelectronic devices such as laser memory systems, smart mirrors, and organic solar technology. Diarylethenes are a class of switchable materials that undergo rapid and complete structural changes upon exposure to ultraviolet or visible light. These distinctive properties position them as promising candidates for various applications, including molecular sensors, computer processing, and organic devices. However, many existing diarylethene-based molecular switches suffer from issues such as poor solubility in common solvents, low quantum efficiency, and sluggish response times. Consequently, developing rapid diarylethene molecular switches with enhanced performance remains a challenge. Recently, numerous strategies have been explored to improve the efficiency of diarylethenes. For example, some researchers have added bulky substituents on the carbon atoms adjacent to the double bond, while others have created diarylethenes with electron-donating groups. Although these modifications have increased solubility and quantum efficiency, the response times are still relatively slow. In this study, we focus on two new diarylethene dyes, designated as 1 and 2 (see Figure 1), which incorporate electron-withdrawing groups. Both compounds display excellent solubility in standard organic solvents and exhibit high quantum yields.",
        "ori-fast-z-score": -0.6446583712203042,
        "water-fast-z-score": 7.091242083423347,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We study the effects on cosmic microwave background (CMB) temperature and polarization anisotropies induced by tensor perturbations in the early universe, which are generated through inflationary processes or other mechanisms. We show that these tensor perturbations can be probed via their imprints on the Stokes parameters Q and U . In particular, we find that the correlation between the two Stokes parameters is proportional to the amplitude of the tensor perturbation at large scales. This effect may provide an important test for models of inflation as well as alternative scenarios such as topological defects. \n \n The recent detection of B-mode polarizations in the CMB  1  has opened up new opportunities to probe physics beyond standard cosmology  2  , including primordial gravitational waves  3  produced during inflation  4  . However, it remains unclear whether this signal arises primarily due to scalar fluctuations  5  or primordial gravitational waves  6  .\n \n \n Tensor modes also induce non-Gaussianities  7, 8  in the primordial curvature perturbation ζ  9  . These non-Gaussianities have been studied extensively  10 - 12  using different approaches  13 - 15  . It was shown  16  that the bispectrum of the primordial curvature perturbation contains information about both the power spectrum Pζ(k) and the spectral index ns  17  of the tensor mode. Recently, Ref.  18  showed that the trispectrum of the primordial curvature perturbations contains additional information about the tensor-to-scalar ratio r = 16PT /PS where PT denotes the power spectrum of the tensor mode and PS denotes the power spectrum of its corresponding scalar counterpart.",
        "watermark_text": "We research the effects on cosmic microwave background ( CMB ) pressure and polarization anisotropies induced by tensor perturbations in the early universe , which are produced through inflationary processes or other mechanisms . We see that these vector perturbations can be probed via their imprints on the Stokes variables Q and U .In particular , we find that the relationship between the two Stokes variables is proportional to the amplitude of the tensor perturbation at large scales . This phenomenon might give an important test for models of inflation as well as additional situations such as topological errors .The recent discovery of B - mode polarizations in the CMB 1 has opened up new opportunities to probe dynamics beyond standard cosmology 2 , notably primordial gravitational waves 3 created during inflation 4 . However , it remains unsure whether this signal exists largely related to scalar fluctuations 5 or primordial gravitational waves 6 .Tensor modes also induce non - Gaussianities 7 , 8 in the primordial curvature perturbation ζ 9 . These non - Gaussianities have been studied thoroughly 10 - 12 using separate approaches 13 - 15 .It was shown 16 that the bispectrum of the primordial curvature perturbation contains information about both the power spectrum Pζ ( k ) and the spectral index ns 17 of the tensor mode . Recently , Ref .18 demonstrated that the trispectrum of the primordial curvature perturbations contains important information about the tensor - to - scalar ratio r = 16PT / PS where PT denotes the power spectrum of the tensor mode and PS refers the power spectrum of its equivalent scalar counterpart .",
        "rewrite_text": "We investigate the impacts of cosmic microwave background (CMB) pressure and polarization anisotropies caused by tensor perturbations in the early universe, which emerge from inflationary processes or other mechanisms. Our findings indicate that these vector perturbations can be analyzed through their effects on the Stokes parameters Q and U. Specifically, we discover that the relationship between these two Stokes parameters is proportional to the amplitude of the tensor perturbation on large scales. This phenomenon could serve as a significant test for inflation models as well as for other scenarios such as topological defects. The recent detection of B-mode polarization in the CMB has created new avenues for exploring dynamics beyond standard cosmological models, particularly in relation to primordial gravitational waves generated during inflation. However, it remains unclear whether this signal is primarily tied to scalar fluctuations or to primordial gravitational waves. Additionally, tensor modes contribute to non-Gaussianities in the primordial curvature perturbation ζ. These non-Gaussianities have been extensively studied through various methods. It has been established that the bispectrum of the primordial curvature perturbation carries information regarding both the power spectrum Pζ(k) and the spectral index ns of the tensor mode. Recently, it was shown that the trispectrum of primordial curvature perturbations contains significant information about the tensor-to-scalar ratio r = 16PT / PS, where PT represents the power spectrum of the tensor mode and PS denotes the power spectrum of its scalar counterpart.",
        "ori-fast-z-score": -0.40406101782088427,
        "water-fast-z-score": 5.178265442181457,
        "rewrite-fast-z-score": 0.30151134457776363
    },
    {
        "original_text": "The Boolean Network (BN) is an important class of models for the analysis and prediction of gene regulatory networks, which are used to describe how genes interact with each other in biological systems. In this study we use BNs as a tool to predict the order of events during the cell division process of the fission yeast Schizosaccharomyces pombe. We construct two different BNs using data obtained by microarray experiments performed on synchronized cultures at four time points along the cell cycle. The first BN was constructed based only on the expression levels of the core set of genes that were found to be essential for cell viability. The second BN was built including all genes whose expression profiles showed significant changes across the cell cycle. Using these BNs we predicted the order of events occurring during the cell cycle. Our results show that both BNs can accurately reproduce the observed temporal ordering of the cell cycle phases. However, when compared against one another, our results suggest that the inclusion of non-core genes into the BN may lead to more accurate predictions.",
        "watermark_text": "The Boolean Network ( BN ) is an important group of models for the evaluation and modeling of gene regulatory networks , which are applied to explain how genes interact with each other in biological environments . In this study we utilize BNs as a framework to predict the order of changes during the cell division cycle of the fission yeast Schizosaccharomyces pombe .We create two different BNs using data acquired by microarray experiments conducted on synchronized cultures at four time points along the cell cycle . The first BN was constructed based only on the expression levels of the main set of genes that were found to be crucial for cell viability .The second BN was built including all genes whose function profiles showed substantial alterations across the cell cycle . Using these BNs we estimated the order of changes resulting during the cell cycle .Our results show that both BNs can accurately approximate the seen temporal ordering of the cell cycle phases . However , when compared against one another , our findings show that the integration of non - core mutations into the BN could lead to more accurate conclusions .",
        "rewrite_text": "The Boolean Network (BN) is a significant modeling approach used for evaluating and understanding gene regulatory networks, which elucidate the interactions among genes within biological contexts. In this study, we employ BNs to predict the sequence of changes occurring during the cell division cycle of the fission yeast Schizosaccharomyces pombe. We developed two distinct BNs using data obtained from microarray experiments conducted on synchronized cultures at four different time points throughout the cell cycle. The first BN was built solely on the expression levels of a key set of genes critical for cell viability. The second BN incorporated all genes that exhibited notable changes in their functional profiles throughout the cell cycle. By utilizing these BNs, we assessed the order of changes occurring during the cell cycle. Our findings demonstrate that both BNs can effectively replicate the observed temporal sequence of cell cycle phases. However, when we compared the two models, our results indicated that including non-core mutations in the BN could yield more precise insights.",
        "ori-fast-z-score": -2.03701381619181,
        "water-fast-z-score": 4.528976474544414,
        "rewrite-fast-z-score": -0.32539568672798425
    },
    {
        "original_text": "We present an approach to the analysis and design of stochastic gene regulatory networks based on deterministic models that are derived by averaging over all possible realizations of the underlying random process.  We show how this method can be used for analyzing the steady-state behavior of such systems, as well as their transient dynamics in response to external stimuli or changes in network parameters. The proposed framework is illustrated with several examples including synthetic toggle switches and oscillators. Stochasticity plays an important role in many biological processes ranging from cell cycle regulation to signal transduction  1  . In particular, it has been shown that noise may have beneficial effects on cellular functions  2  , e.g., by enhancing the sensitivity of cells to signals  3  .\nThe study of stochastic gene regulatory networks (GRNs) requires the development of new mathematical tools capable of capturing both the intrinsic fluctuations associated with molecular interactions and extrinsic perturbations due to environmental factors  4  . Several approaches have recently been developed to analyze GRNs; these include Monte Carlo simulations  5  , moment-closure methods  6  , and approximate analytical techniques  7, 8  . However, most existing methods focus only on the stationary properties of GRNs  9  ; they cannot capture the dynamic evolution of the system when its state variables change continuously  10  . Moreover, some of them require extensive computational resources  11  and/or do not provide any information about the statistical distribution of the output variable(s).\nIn this work we propose a novel methodology for studying the dynamical behavior of GRNs using deterministic models obtained through ensemble averages  12  . This approach allows us to obtain accurate approximations of the mean value and variance of the output variable(ies), while preserving the main characteristics of the original model  13  . Our results demonstrate that our technique provides useful insights into the functioning of complex biochemical networks without requiring excessive computational effort.",
        "watermark_text": "We present an perspective to the analysis and design of stochastic gene regulatory networks based on deterministic descriptions that are derived by averaging over all possible realizations of the underlying random process . We see how this method can be used for studying the stable - state dynamics of such systems , as well as their transient structure in reaction to external stimuli or alterations in system parameters .The proposed framework is depicted with many instance including synthetic toggle switches and oscillators . Stochasticity plays an important role in multiple biological pathways including from cell cycle regulation to signal transduction 1 .In particular , it has been shown that noise might have beneficial influence on cell functions 2 , e . g . , by increased the sensitivity of cells to stimuli 3 . The investigation of stochastic gene regulatory networks ( GRNs ) need the development of new computational tools capable of depicting both the intrinsic fluctuations associated with biological interactions and extrinsic perturbations due to environmental factors 4 .Several approaches have recently been constructed to analyze GRNs ; these involve Monte Carlo simulations 5 , moment - collapse technique 6 , and exact mathematical techniques 7 , 8 . However , most existing techniques concentrate only on the stationary features of GRNs 9 ; they cannot record the dynamic development of the system when its state values change continuously 10 .Moreover , some of them require extensive computational resources 11 and / or do not offer any knowledge about the empirical distribution of the output parameter ( s ) . In this research we propose a new methodology for studying the dynamical behavior of GRNs using deterministic descriptions generated through ensemble averages 12 .This method enables us to obtain precise approximations of the mean value and variance of the output parameter ( ies ) , while preserving the main characteristics of the previous version 13 . Our results show that our technique provides useful insights into the functioning of complex biochemical organizations without using inappropriate computational time .",
        "rewrite_text": "We introduce a novel approach for analyzing and designing stochastic gene regulatory networks (GRNs) by employing deterministic models derived from averaging all potential realizations of the underlying random processes. This method facilitates the exploration of the stable-state dynamics of these systems, as well as their transient responses to external stimuli or changes in system parameters. We illustrate the application of our framework through various examples, including synthetic toggle switches and oscillators. Stochasticity plays a crucial role in numerous biological pathways, ranging from cell cycle regulation to signal transduction. Notably, it has been demonstrated that noise can positively impact cellular functions by enhancing their sensitivity to stimuli. To investigate stochastic GRNs effectively, we need to develop new computational tools that can represent both the intrinsic fluctuations of biological interactions and the extrinsic perturbations from environmental factors. Recently, several methods have been devised for analyzing GRNs, including Monte Carlo simulations, moment-collapse techniques, and exact mathematical methods. However, most existing approaches focus primarily on the steady-state characteristics of GRNs and fail to capture the dynamic evolution of the system as its state values continuously change. Furthermore, some of these techniques demand substantial computational resources and do not provide insights into the empirical distribution of the output parameters. In this study, we propose a new methodology for examining the dynamical behavior of GRNs through deterministic descriptions based on ensemble averages. This approach allows us to achieve accurate estimates of both the mean and variance of the output parameters while retaining key features of previous models. Our findings indicate that this technique yields valuable insights into the functioning of complex biochemical systems without incurring excessive computational costs.",
        "ori-fast-z-score": -0.9607689228305227,
        "water-fast-z-score": 7.58182540244241,
        "rewrite-fast-z-score": 1.2456821978060995
    },
    {
        "original_text": "We present an analytical solution to the problem of bending thin elastic shells with variable thickness under surface loads, which is applicable to the case where the shell s thickness varies by several orders of magnitude over its radius and where the load distribution is not necessarily axisymmetric.  We show that in this case it is possible to obtain accurate results using only two parameters instead of three as was previously thought necessary (the third parameter being the ratio between the maximum and minimum values of the shell s thickness). The new formulation allows us to calculate the deflection of the shell at any point on its surface without having to solve additional equations or perform numerical integration. This makes our approach much faster than previous methods while retaining high accuracy. Our method can be used to model the response of the Earth s crust to tectonic stresses and other processes such as volcanic loading and sedimentary deposition. It also has applications in geophysics beyond Earth sciences including planetary science, astrophysics and seismology. \nTheory\n\nIn order to study the deformation of the Earth s crust we need to know how the stress field changes across different regions of the planet. In particular, we are interested in understanding how the stress field evolves during plate boundary interactions like subduction zones and transform faults. To do so, we use the theory of elasticity to find solutions to problems involving the interaction between plates and their underlying mantle. However, solving these problems analytically requires simplifying assumptions about the geometry of the system and the mechanical properties of the materials involved. \n\nOne important simplification made when studying the mechanics of plate boundaries is to assume that they behave as if they were composed of thin elastic shells. These shells have been shown to provide good approximations to more realistic models of plate boundaries because they allow for rapid calculations of the stress fields within them. For example, Figure 1 shows a comparison between the predictions obtained using a simple spherical shell model and those produced by a finite element model of the San Andreas Fault System.\n\nFigure 1: Comparison between the predicted displacements along the San Andreas fault calculated using a spherical shell model (blue line) and a finite element model (red dots).",
        "watermark_text": "We present an analytical solution to the issue of stretching thin elastic pieces with variable size under surface loads , which is applicable to the case where the shell s thickness differs by many orders of magnitude over its radius and where the load distribution is not necessarily axisymmetric . We see that in this situation it is possible to obtain precise conclusions using only two parameters instead of three as was formerly thought required ( the third parameter being the proportion between the maximum and minimum values of the shell s thickness ) .The revised formulation enables us to estimate the deflection of the shell at any point on its surface without having to correct additional equations or undergo numerical integration . This gives our approach much quick than prior methods while retaining high sensitivity .Our model can be used to model the response of the Earth s crust to tectonic stresses and other processes such as geological loading and sedimentary deposition . It additionally has uses in geophysics beyond Earth studies including planetary scientists , astrophysics and seismology .Theory In order to study the deformation of the Earth s crust we require to see how the strain field shifts across different regions of the planet . In particular , we are concerned in understanding how the strain field evolves during plate boundary interactions like subduction zones and transform faults .To do so , we utilize the principle of elasticity to find solutions to problems concerning the interaction between plates and their underlying mantle . However , solving these problems analytically takes simplifying theories about the topology of the process and the structural properties of the materials involved .One important simplification taken when researching the mechanics of sheet borders is to assume that they react as if they were consisting of short elastic shells . These shells have been shown to provide better approximations to more realistic descriptions of plate boundaries because they allow for rapid determination of the strain fields within them .For instance , Figure 1 shows a comparison between the estimates obtained using a simple spherical shell model and those generated by a finite element model of the San Andreas Fault System . Figure 1 : Comparison between the expected displacements along the San Andreas fault calculated using a circular shell model ( blue line ) and a finite element model ( red stripes ) .",
        "rewrite_text": "We introduce an analytical solution to the challenge of stretching thin elastic materials with varying dimensions under surface loads. This solution is particularly useful in scenarios where the shell’s thickness varies significantly relative to its radius, and where the load distribution does not have to be axisymmetric. Our findings indicate that it is possible to derive accurate conclusions using only two parameters, rather than the previously believed three (the third parameter being the ratio of the maximum to minimum thickness of the shell). This updated formulation allows us to estimate the deflection of the shell at any surface point without the need for additional corrections or numerical integration, making our approach faster than previous methods while maintaining high sensitivity. Our model can effectively simulate the Earth’s crust response to tectonic stresses and other processes, such as geological loading and sedimentary deposition. Moreover, it has applications in geophysics beyond Earth studies, including disciplines such as planetary science, astrophysics, and seismology.\n\nTo investigate the deformation of the Earth’s crust, it is essential to analyze how the strain field varies across different regions of the planet. We specifically aim to understand the development of the strain field during plate boundary interactions, such as in subduction zones and transform faults. To achieve this, we apply elasticity principles to address problems related to the interaction between tectonic plates and the underlying mantle. However, finding analytical solutions requires certain simplifying assumptions about the topology of these interactions and the materials' structural properties. A key simplification in examining the mechanics of plate boundaries is to treat them as if they were composed of short elastic shells. This approach generally yields more accurate representations of plate boundary behavior while facilitating a swift analysis of strain fields. For example, Figure 1 illustrates a comparison between the displacements predicted by a simplistic spherical shell model and those derived from a finite element model of the San Andreas Fault System. \n\nFigure 1: A comparison of expected displacements along the San Andreas Fault, calculated using a circular shell model (blue line) and a finite element model (red stripes).",
        "ori-fast-z-score": -1.270639657678291,
        "water-fast-z-score": 8.198915917499228,
        "rewrite-fast-z-score": 2.4688535993934706
    },
    {
        "original_text": "We present exact solutions to the field equations of the Einstein-Gauss-Bonet (EGB) gravity with negative cosmological constant in 5D space-time. We find that there are three classes of black hole solutions depending on whether the Gauss-Bonnet coupling constant is positive or negative. The first class contains two types of static spherically symmetric black holes which have no horizons but possess naked singularities at their centers. In addition we also obtain another type of solution describing an asymptotically anti-de Sitter wormhole whose throat connects two asymptotic regions. Finally, by using the method developed recently by one of us, we construct a new type of solution representing a time-dependent spacetime horn. This work was supported by NSFC under Grant No. 10875030. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq . \nI. INTRODUCTORY REMARK\nThe discovery of gravitational waves has opened up a new window into our understanding of gravitation  1  , especially when it comes to testing general relativity  2  . However, despite its successes, general relativity still fails to explain some phenomena such as dark energy  3  and quantum gravity  4  . Therefore, many alternative theories of gravity were proposed over the years  5  .\nOne of these alternatives is the so-called Einstein-Gauss-Bonnet (EGB) gravity  6  -  8  . It can be viewed as a natural generalization of general relativity since it includes higher-order curvature corrections  9  . Moreover, this theory admits various interesting solutions including black holes  10 -  12  , wormholes  13  -  15  and even time dependent spacetimes  16  -  18  . Recently, EGB gravity attracted much attention due to its possible role in explaining the accelerated expansion of the universe  19  -  21  .",
        "watermark_text": "We present precise solutions to the field equations of the Einstein - Gauss - Bonet ( EGB ) gravity with negative cosmological constant in 5D space - time . We see that there are three categories of black hole solutions depending on whether the Gauss - Bonnet coupling constant is positive or negative .The first class includes two forms of static spherically symmetric black holes which have no horizons but possess naked singularities at their centers . In addition we also obtain another type of solution describing an asymptotically anti - de Sitter wormhole whose throat connects two asymptotic areas .Finally , by using the method developed ago by one of us , we create a new kind of solution representing a time - dependent spacetime horn . This project was supported by NSFC under Grant No .10875030 . PACS dates : 04 . 20 . - q , 11 . 10 . - z , 98 . 80 . Cq .I . INTRODUCTORY REMARK The observation of gravitational waves has opened up a new window into our knowing of gravitation 1 , particularly when it comes to proving general relativity 2 .However , despite its successes , universal relativity also fails to explain some phenomena such as dark energy 3 and quantum gravitational 4 . Therefore , various alternative theories of gravitational were offered over the years 5 .One of these solutions is the so - called Einstein - Gauss - Bonnet ( EGB ) gravity 6 - 8 . It can be viewed as a natural generalization of general relativity since it includes higher - order curvature corrections 9 .Moreover , this theory admits various exciting solutions namely black holes 10 - 12 , wormholes 13 - 15 and even period based spacetimes 16 - 18 . Recently , EGB gravitational attracted much attention due to its potential importance in understanding the advanced expansion of the universe 19 - 21 .",
        "rewrite_text": "We provide exact solutions to the field equations of Einstein-Gauss-Bonnet (EGB) gravity with a negative cosmological constant in five-dimensional spacetime. Our findings reveal three categories of black hole solutions, which vary depending on the sign of the Gauss-Bonnet coupling constant. The first category encompasses two types of static, spherically symmetric black holes that lack horizons and feature naked singularities at their centers. Additionally, we discover another solution that describes an asymptotically anti-de Sitter wormhole, characterized by a throat connecting two asymptotic regions. Furthermore, utilizing a method previously developed by one of our researchers, we construct a novel solution exemplifying a time-dependent spacetime horn. This research has been supported by the National Natural Science Foundation of China under Grant No. 10875030. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq. \n\nI. INTRODUCTORY REMARK \n\nThe detection of gravitational waves has opened a new avenue for our understanding of gravitation, particularly in validating general relativity. However, despite its successes, general relativity fails to account for certain phenomena such as dark energy and quantum gravity. Consequently, various alternative theories of gravity have been proposed over the years. One such theory is the Einstein-Gauss-Bonnet (EGB) gravity, which serves as a natural extension of general relativity by incorporating higher-order curvature corrections. This theory yields a range of intriguing solutions, including black holes, wormholes, and even periodic spacetimes. Recently, EGB gravity has garnered significant attention due to its potential relevance in elucidating the accelerated expansion of the universe.",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 7.061788191316445,
        "rewrite-fast-z-score": 0.27975144247209416
    },
    {
        "original_text": "We study the possibility that nonstandard interactions (NSI) between neutrinos and matter can be probed by using solar and reactor neutrino data simultaneously, in particular through their combined effect on the survival probability P(νe→νe). We find that NSI parameters are constrained to values below 0.1 for most combinations of standard oscillation parameters allowed at 3σ CL by current global fits. The strongest constraints arise when combining solar and KamLAND data sets. In this case we obtain upper bounds on |εee|, |εµτ | < 0.06 − 0.07 depending on the value of θ13. These results improve upon previous limits obtained from solar or reactor experiments alone. \n \n Introduction \n \n Neutrino oscillations have been observed in many different types of experiments  1  . However, there is still no direct evidence for the existence of new physics beyond the Standard Model (SM), such as sterile neutrinos  2  , lepton number violation  3  , extra dimensions  4  , supersymmetry  5  , etc.. Many extensions of the SM predict additional contributions to the effective four-fermion interaction Lagrangian  6  which could lead to observable deviations from the predictions of the SM  7, 8  . For example, it has recently been shown  9  that some models of quantum gravity  10  may induce an energy dependent refractive index n = 1 + εE/E0 where E0 is a characteristic scale associated with the underlying theory  11  . This would result in a modification of the vacuum mixing angle sin2θ12 = 1−cos2θ12 ≈ 1+ε/2+O(ε3)  12  leading to potentially large effects on the propagation of neutrinos  13  .\n \nIn addition to these theoretical motivations, there exist several experimental indications pointing towards possible new physics beyond the SM  14  : i) Large atmospheric  15  and solar  16  neutrino flux deficits; ii) LSND  17  and MiniBooNE  18  anomalies indicating short-baseline νμ → νe appearance transitions not predicted within three-flavor neutrino oscillations  19  ; iii) Anomalies in the measurement of the muon anomalous magnetic moment",
        "watermark_text": "We research the idea that nonstandard relationships ( NSI ) between neutrinos and material can be probed by using sun and reactor neutrino data simultaneously , in particular through their combined influence on the life probability P ( νe→νe ) . We see that NSI variables are constrained to parameters below 0 . 1 for most combinations of standard oscillation measurements permitted at 3σ CL by current global fits .The strongest limits arise when combining solar and KamLAND data sets . In this situation we obtain higher bounds on | εee | , | εµτ | < 0 . 06 − 0 . 07 depending on the value of θ13 .These data improve upon recent limits acquired from solar or reactor tests alone . Introduction Neutrino oscillations have been observed in multiple diverse kinds of studies 1 .However , there is nevertheless no clear proof for the existence of new theory beyond the Standard Model ( SM ) , such as sterile neutrinos 2 , lepton size violation 3 , extra dimensions 4 , supersymmetry 5 , etc . . Many modifications of the SM predict additional contributions to the effective four - fermion collision Lagrangian 6 which potentially contribute to observable deviations from the estimates of the SM 7 , 8 .For instance , it has recently been shown 9 that some models of quantum gravitational 10 may generate an energy dependent refractive index n = 1 + εE / E0 where E0 is a typical scale identified with the underlying theory 11 . This might lead in a modification of the vacuum mixing ratio sin2θ12 = 1−cos2θ12 ≈ 1 + ε / 2 + O ( ε3 ) 12 leading to potentially large effects on the propagation of neutrinos 13 .In addition to these theoretical motivations , there remain various experimental indications pointing towards possible new science beyond the SM 14 : i ) Large environmental 15 and solar 16 neutrino flux deficits ; ii ) LSND 17 and MiniBooNE 18 anomalies suggesting short - baseline νμ → νe appearance changes not anticipated within three - flavor neutrino oscillations 19 ; iii ) Anomalies in the determination of the muon anomalous magnetic moment",
        "rewrite_text": "We investigate the hypothesis that nonstandard interactions (NSI) between neutrinos and matter can be examined by simultaneously analyzing data from solar and reactor neutrinos, particularly regarding their joint effect on the survival probability P(νe→νe). Our findings indicate that the NSI parameters are generally constrained to values below 0.1 for most combinations allowed at the 3σ confidence level by current global fits of standard oscillation measurements. The most stringent limits are achieved by integrating solar and KamLAND data sets, where we find tighter upper bounds on |εee| and |εµτ|, which range from 0.06 to 0.07, depending on the value of θ13. This analysis enhances previous constraints derived from solar or reactor tests conducted in isolation. \n\nIntroduction: Neutrino oscillations have been documented across various studies. However, definitive evidence supporting theories that extend beyond the Standard Model (SM)—such as sterile neutrinos, lepton number violation, extra dimensions, and supersymmetry—remains elusive. Many extensions of the SM propose additional contributions to the effective four-fermion collision Lagrangian, which could lead to observable deviations from SM predictions. Recent work has suggested that certain quantum gravitational models may yield an energy-dependent refractive index expressed as n = 1 + εE / E0, where E0 corresponds to a characteristic scale related to the fundamental theory. This could result in modifications to the vacuum mixing ratio sin²θ12 = 1 - cos²θ12 ≈ 1 + ε / 2 + O(ε³), potentially causing significant impacts on neutrino propagation. Beyond theoretical considerations, various experimental observations hint at phenomena that may signify new physics beyond the SM, including: i) substantial deficits in solar and environmental neutrino fluxes; ii) anomalies from LSND and MiniBooNE suggesting unexpected short-baseline νμ → νe transitions not accounted for by three-flavor neutrino oscillations; and iii) discrepancies in measurements regarding the muon anomalous magnetic moment.",
        "ori-fast-z-score": -0.4508348173337161,
        "water-fast-z-score": 7.844525821606661,
        "rewrite-fast-z-score": -0.26013299085723596
    },
    {
        "original_text": "We propose that the dim radio-quiet neutron star, 1E1207.4-5209 (hereafter E1207), is an evolved object with its surface temperature T = 2 × 10 6 K and radius R = 11 km. The observed X-ray luminosity Lx ~ 3×1033 erg s-1 can be explained by the decay energy of radioactive nuclei produced in the core collapse supernova explosion at t ~ 1s after the birth of the progenitor star. We show that the total amount of 56Ni synthesized during the explosion is about 0.1M⊙ which agrees well with the theoretical prediction for massive stars. In addition to the nuclear burning, we consider the effects of magnetic field decay due to ohmic dissipation as well as gravitational wave emission. It turns out that these processes are not important enough to explain the present state of E1207 within our lifetime. However, if the initial magnetic field strength was larger than 1013 G, it could have been reduced down to the current value of 5×1012 G through ohmic dissipation before the age of the universe reached 13Gyrs.",
        "watermark_text": "We suggest that the dim radio - quiet neutron star , 1E1207 . 4 - 5209 ( hereafter E1207 ) , is an evolved object with its surface temperature T = 2 × 10 6 K and radius R = 11 km . The observed X - ray luminosity Lx ~ 3×1033 erg s - 1 can be understood by the decay heat of nuclear nuclei generated in the core breakup supernova explosion at t ~ 1s after the emergence of the progenitor star .We show that the total amount of 56Ni synthesized during the explosion is about 0 . [UNK] which agrees well with the theoretical prediction for massive stars . In addition to the nuclear burning , we consider the effects of magnetic field decay due to ohmic dissipation as well as gravitational wave emission .It turns out that these mechanisms are not important sufficiently to explain the present state of E1207 within our life . However , if the first magnetic force power was bigger than 1013 G , it could have been reduced down to the present value of 5×1012 G through ohmic dissipation before the age of the universe reached 13Gyrs .",
        "rewrite_text": "We propose that the faint radio-quiet neutron star 1E1207.4-5209 (hereafter referred to as E1207) is an evolved object, characterized by a surface temperature of T = 2 × 10^6 K and a radius of R = 11 km. The observed X-ray luminosity, Lx ~ 3 × 10^33 erg/s, can be explained by the decay heat from nuclear fragments produced during the core-collapse supernova explosion approximately 1 second after the progenitor star's emergence. Our calculations suggest that the total amount of synthesized 56Ni during the explosion is around 0. [UNK], which aligns well with theoretical expectations for massive stars. In addition to nuclear burning, we take into account the impact of magnetic field decay due to ohmic dissipation and gravitational wave emission. However, these processes are not significant enough to explain E1207’s current state during our lifetime. Nonetheless, if the initial magnetic field strength was greater than 10^13 G, it could have diminished to the current value of 5 × 10^12 G due to ohmic dissipation well before the universe reached its age of 13 billion years.",
        "ori-fast-z-score": -0.47140452079103173,
        "water-fast-z-score": 2.5927248643506746,
        "rewrite-fast-z-score": 1.2222222222222223
    },
    {
        "original_text": "We present here an overview of our survey, which is aimed at tracing the evolution in the number density and luminosity function (LF) of galaxies as a function of their stellar masses up to z ~ 1.5. The sample consists of about 10 000 objects selected by photometric redshifts using deep optical data obtained with FORS2@VLT+WFI@ESO/MPG 2.2m telescope + Spitzer IRAC 3.6 & 4.5 micron bands. We use this dataset to study how the LF evolves for different ranges of stellar masses. In particular we find that the faint-end slope of the LF becomes steeper towards higher redshift indicating that less massive systems are more abundant than today. This result can be explained if star formation activity was more efficient in low-mass halos at high-z compared to local universe. Finally, we compare these results with those derived from other surveys finding good agreement between them.",
        "watermark_text": "We present here an overview of our survey , which is aiming at studying the evolution in the number density and luminosity function ( LF ) of galaxies as a function of their stellar masses up to z ~ 1 . 5 . The sample consists of about 10 000 items selected by photometric redshifts using deep optical data acquired with FORS2 @ VLT + WFI @ ESO / MPG 2 . 2m telescope + Spitzer IRAC 3 . 6 & 4 . 5 micron bands .We use this dataset to study how the LF evolves for different ranges of stars masses . In particular we find that the faint - end slope of the LF becomes steeper towards higher redshift indicating that less massive components are more rich than presently .This result can be described if star formation activity was more efficient in low - density halos at high - z compared to nearby universe . Finally , we compare these results with those generated from other surveys obtaining strong approval between them .",
        "rewrite_text": "We provide an overview of our survey aimed at examining the evolution of galaxy number density and luminosity function (LF) as a function of stellar mass up to redshift z ~ 1.5. Our sample includes approximately 10,000 galaxies selected based on photometric redshifts, utilizing deep optical data collected with FORS2 at the VLT, as well as the WFI at the ESO/MPG 2.2m telescope and the Spitzer IRAC at 3.6 and 4.5 micron bands. This dataset enables us to investigate how the LF evolves across various stellar mass ranges. Notably, we observe that the faint-end slope of the LF becomes steeper at higher redshifts, suggesting that less massive galaxies were more abundant in the past compared to the present. This phenomenon may be explained by the increased efficiency of star formation in low-density halos at higher redshifts relative to the nearby universe. Finally, we compare our findings with results from other surveys, which show strong consistency among them.",
        "ori-fast-z-score": 2.4618298195866544,
        "water-fast-z-score": 6.154574548966636,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We report on high-resolution observations with Herschel PACS (Poglitsch et al., 2010) and SPIRE (Griffin et al., 2010 ) that reveal for the first time the presence of cold dust emission at temperatures as low as T = 20 K in two nearby ultraluminous infrared galaxies (ULIRGs), Arp220 and Mrk 231. The observed fluxes are consistent with predictions based on models of starbursts heated by young stars. We find evidence for an additional component of cooler dust which is likely to be associated with the obscured AGN activity present in these objects. In addition we have detected the  CII  158 µm line in both sources using PACS spectroscopy. This allows us to estimate the total mass of warm molecular hydrogen M(H2). For Arp 220 this amounts to 1.5 x 10^9 solar masses within a radius of 100 pc around the nucleus.",
        "watermark_text": "We report on wide - resolution measurements with Herschel PACS ( Poglitsch et al . , 2010 ) and SPIRE ( Griffin et al . , 2010 ) that discover for the first time the presence of cold dust absorption at conditions as low as T = 20 K in two nearby ultraluminous infrared galaxies ( ULIRGs ) , Arp220 and Mrk 231 . The observed fluxes are compatible with predictions based on estimates of starbursts heated by young galaxies .We see evidence for an additional element of cold powder which is probably to be involved with the obscured AGN activity contained in these objects . In addition we have discovered the CII 158 µm line in both sources using PACS spectroscopy .This enables us to estimate the total mass of bright molecular hydrogen M ( H2 ) . For Arp 220 this corresponds to 1 . 5 x 10 ^ 9 solar masses within a diameter of 100 pc around the nucleus .",
        "rewrite_text": "We present wide-resolution measurements obtained with Herschel PACS (Poglitsch et al., 2010) and SPIRE (Griffin et al., 2010) that for the first time reveal the presence of cold dust absorption at temperatures as low as T = 20 K in two nearby ultraluminous infrared galaxies (ULIRGs), Arp 220 and Mrk 231. The detected fluxes align with predictions derived from models of starbursts driven by young galaxies. Additionally, we find evidence for another component of cold dust that is likely associated with the obscured activity of active galactic nuclei (AGN) within these galaxies. Furthermore, we have identified the CII 158 µm line in both objects using PACS spectroscopy, which allows us to estimate the total mass of bright molecular hydrogen, M(H2). For Arp 220, this estimate amounts to 1.5 x 10^9 solar masses within a 100 pc diameter region surrounding the nucleus.",
        "ori-fast-z-score": -2.516611478423583,
        "water-fast-z-score": 3.0464244212496006,
        "rewrite-fast-z-score": -0.2581988897471611
    },
    {
        "original_text": "We study the slow wave resonance (SWR) effect for periodically layered media with an arbitrary number N of anisotropic layers, each characterized by its own permittivity tensor and thickness. We show that SWR is possible only if all principal axes of the permittivity tensors are parallel to one another within each layer. In this case we derive explicit expressions for the dispersion relation between the frequency f and the Bloch wavenumber kx. The results obtained can be used as guidelines for designing multilayered structures exhibiting strong SWR effects at low frequencies. \n \n Keywords: Slow wave resonance; Anisotropy; Multilayer structure; Dispersion relations. 1 Introduction \n \n Periodic multilayers consisting of alternating thin films made of different materials have attracted considerable attention during recent years due to their unique properties  1  . These include high reflectance  2  , negative refraction  3  , enhanced nonlinear optical response  4  , etc., which make them promising candidates for various applications such as optoelectronic devices  5  or photovoltaics  6  .\n \nIn particular, it has been shown recently  7–9  that periodic multilayers composed of anisotropic layers may exhibit very interesting electromagnetic phenomena including slow wave resonance (S WR). This phenomenon occurs when the phase velocity of the Bloch waves becomes equal to zero inside the medium  10  . It leads to extremely large values of the effective refractive index n eff = c / v ph  11  where c is the speed of light in vacuum and v ph is the phase velocity of the propagating Bloch mode  12  . As a result, the corresponding transmission spectrum exhibits sharp peaks associated with narrow stop bands  13  . Such features are highly desirable for many practical applications  14  . \n \n However, despite numerous theoretical studies devoted to S WR in periodic multilayers  15–18  , there still exist several open questions related to the conditions under which this phenomenon takes place  19, 20  . For example, it was found experimentally  21  that the presence of a single misaligned anisotropic layer destroys the S WR effect completely even though other layers remain perfectly aligned. On the other hand, numerical simulations  22  suggest that",
        "watermark_text": "We explore the slow frequency resonance ( SWR ) effect for regularly layered media with an arbitrary number N of anisotropic layers , each described by its own permittivity matrix and thickness . We see that SWR is possible only if all primary directions of the permittivity tensors are connected to one another within each surface .In this situation we derive explicit expressions for the dispersion constant between the frequency f and the Bloch wavenumber kx . The results derived can be used as guidelines for constructing multilayered buildings presenting strong SWR effects at low frequencies .Keywords : Slow wave vibration ; Anisotropy ; Multilayer structure ; Dispersion relations . 1 Introduction Periodic multilayers consisting of alternating thin sheets formed of different materials have garnered considerable scrutiny during recent seasons due to their distinct characteristics 1 .These include high reflectance 2 , negative refraction 3 , enhanced nonlinear optical reaction 4 , etc . , which make them promising candidates for various uses such as optoelectronic technologies 5 or photovoltaics 6 . In particular , it has been shown ago 7 – 9 that periodic multilayers consisting of anisotropic surfaces may exhibit very interesting electrical processes including slow frequency resonance ( S WR ) .This phenomenon occurs when the phase velocity of the Bloch waves becomes equal to zero inside the medium 10 . It results to incredibly large values of the effective refractive index n eff = c / u ph 11 where p is the speed of light in vacuum and v ph is the phase velocity of the propagating Bloch mode 12 .As a result , the associated transmission spectrum exhibits severe spikes identified with narrow stop rings 13 . Such characteristics are extremely practical for numerous practical applications 14 .However , despite several theoretical experiments devoted to S WR in periodic multilayers 15 – 18 , there still appear several open questions related to the conditions under which this phenomenon happens place 19 , 20 . For instance , it was shown experimentally 21 that the presence of a single misaligned anisotropic surface destroys the S WR effect totally even though other layers remain perfectly aligned .On the other hand , numerical simulations 22 suggest that",
        "rewrite_text": "We investigate the slow frequency resonance (SWR) effect in regularly layered media consisting of an arbitrary number \\( N \\) of anisotropic layers, with each layer characterized by its own permittivity matrix and thickness. Our findings indicate that SWR can occur only when all primary directions of the permittivity tensors are interconnected across each surface. Under these conditions, we derive explicit formulas relating the dispersion constant to frequency \\( f \\) and the Bloch wavenumber \\( k_x \\). The expressions derived in this work can serve as useful guidelines for designing multilayered structures that exhibit pronounced SWR effects at low frequencies. \n\n**Keywords**: Slow wave vibration; Anisotropy; Multilayer structure; Dispersion relations.\n\n**1. Introduction**  \nPeriodic multilayers made up of alternating thin sheets of various materials have attracted significant attention in recent years due to their unique properties. These include high reflectance, negative refraction, and enhanced nonlinear optical responses, which position them as promising candidates for applications in optoelectronic technologies and photovoltaics. Notably, previous studies have demonstrated that periodic multilayers with anisotropic surfaces can exhibit intriguing electrical phenomena, including slow frequency resonance (SWR). This phenomenon occurs when the phase velocity of Bloch waves inside the medium reaches zero, resulting in extremely large effective refractive index values of \\( n_{\\text{eff}} = \\frac{c}{v_{\\text{ph}}} \\), where \\( c \\) is the speed of light in a vacuum and \\( v_{\\text{ph}} \\) is the phase velocity of the propagating Bloch mode. This leads to a transmission spectrum marked by sharp spikes associated with narrow stop bands, making these characteristics highly advantageous for various practical applications. Despite numerous theoretical discussions concerning SWR in periodic multilayers, several questions remain regarding the specific conditions that facilitate this phenomenon. For example, it has been experimentally shown that a single misaligned anisotropic surface can completely disrupt the SWR effect, even if adjacent layers are perfectly aligned. Conversely, numerical simulations suggest that...",
        "ori-fast-z-score": -0.15811388300841897,
        "water-fast-z-score": 8.432781346758377,
        "rewrite-fast-z-score": 4.070243110784873
    },
    {
        "original_text": "The nonperiodic anyon model is introduced as an alternative to the periodic one in order to explain fractional quantum hall effect (FQHE). The ground state wave function for this system is obtained by using the method of projection operators, which leads to a new expression for the Laughlin wave functions. It is shown that these states are exact eigenstates of the total angular momentum operator with eigenvalues equal to the number of particles times their charge e*. This result shows that the nonperiodic anyons can be considered as charged particles moving on a sphere. Finally we show how our results can be applied to describe FQHE at filling fractions other than 1/3. In recent years there has been considerable interest in studying systems consisting of interacting electrons confined to two dimensions  1  . One of the most interesting phenomena observed experimentally  2  , known as the fractional quantum Hall effect (FQHE), occurs when such two-dimensional electron gas is subjected to strong magnetic fields  3  .\nIn the original work  4  it was suggested that the FQHE could be explained within the framework of the so-called Laughlin wave functions  5  . These wave functions were constructed by assuming that each particle moves around its own guiding center  6  . However, later studies  7 -9  showed that the actual behavior of the electrons in real experiments cannot be described accurately by considering them as point-like objects. Instead, they should be treated as extended objects whose size depends upon the strength of the external magnetic field  10  .",
        "watermark_text": "The nonperiodic anyon theory is developed as an alternative to the periodic one in order to explain fractional quantum hall impact ( FQHE ) . The ground state wave function for this system is found by using the method of projection operators , which results to a new representation for the Laughlin wave functions .It is seen that these states are exact eigenstates of the total angular velocity operator with eigenvalues equal to the number of molecules times their charge e * . This result shows that the nonperiodic anyons can be regarded as charged particles moving on a sphere .Finally we prove how our findings can be applied to define FQHE at filling fractions other than 1 / 3 . In recent years there has been substantial interest in investigating systems composed of interacting electrons confined to two dimensions 1 .One of the most exciting phenomena observed experimentally 2 , known as the fractional quantum Hall phenomenon ( FQHE ) , happened when such two - dimensional electron gas is subjected to powerful magnetic fields 3 . In the first paper 4 it was suggested that the FQHE might be described within the framework of the so - called Laughlin wave curves 5 .These wave systems were created by assuming that each particle moves surrounding its own guiding center 6 . However , later research 7 - 9 demonstrated that the actual activity of the electrons in real studies never be described properly by treating them as point - like structures .Instead , they should be treated as extended things whose extent depends upon the strength of the external magnetic force 10 .",
        "rewrite_text": "The nonperiodic anyon theory has been developed as an alternative to the periodic model in order to elucidate the fractional quantum Hall effect (FQHE). The ground state wave function for this system is derived through the use of projection operators, leading to a novel representation of the Laughlin wave functions. These states are observed to be exact eigenstates of the total angular momentum operator, with eigenvalues corresponding to the product of the number of particles and their charge \\( e^* \\). This finding indicates that nonperiodic anyons can be conceptualized as charged particles moving on a sphere. Furthermore, we demonstrate how these results can be utilized to extend the definition of FQHE to filling fractions beyond 1/3. Recent years have seen considerable interest in exploring systems composed of interacting electrons confined to two dimensions. One particularly fascinating phenomenon observed experimentally, known as the fractional quantum Hall effect (FQHE), occurs when this two-dimensional electron gas is subjected to strong magnetic fields. Initial research proposed that the FQHE could be explained within the framework of the Laughlin wave functions, which were developed under the assumption that each particle moves around its own guiding center. However, subsequent studies revealed that the behavior of electrons in real experiments cannot be accurately represented by treating them as point-like entities; instead, they must be regarded as extended objects whose size is influenced by the strength of the external magnetic field.",
        "ori-fast-z-score": -1.3112201362143716,
        "water-fast-z-score": 6.313641498019764,
        "rewrite-fast-z-score": 0.38138503569823695
    },
    {
        "original_text": "We present new high-precision photometric observations of the red giant star nu Indi, obtained with the Kepler space telescope over a period of three months (Q0-Q3). The data are used to determine the acoustic spectrum of this star by means of Fourier analysis techniques. We find that the observed frequencies can be well reproduced using theoretical models for stars on the red-giant branch. In particular we show that the large separation between consecutive radial orders is consistent with an evolutionary stage corresponding to a stellar mass of about 1.5 Msun. Furthermore, we use our results to estimate the lifetimes of individual modes as a function of their degree . Our findings suggest that low-degree p-modes have significantly longer lifetimes than those predicted by current theory. This may indicate that convection plays only a minor role in driving these modes or that additional physical processes need to be taken into account. \n \n Keywords: Red giants",
        "watermark_text": "We report new high - precision photometric images of the red giant star nu Indi , obtained with the Kepler space telescope over a period of three months ( Q0 - Q3 ) . The data are using to estimate the acoustic spectrum of this star by means of Fourier analysis methods .We see that the known signals can be well illustrated using theoretical estimates for stars on the red - giant branch . In particular we prove that the huge splitting between successive radial orders is compatible with an evolutionary stage equivalent to a stellar size of about 1 . 5 Msun .Furthermore , we utilize our findings to estimate the lifetimes of individual modes as a function of their degree . Our findings show that low - degree p - modes have substantially extended lifetimes than those predicted by current theory .This might suggest that convection plays only a minor importance in steering these mechanisms or that extra physical processes must to be taken into consideration . Keywords : Red giants",
        "rewrite_text": "We present new high-precision photometric images of the red giant star nu Indi, captured by the Kepler space telescope over three months (Q0 - Q3). These data are employed to estimate the star's acoustic spectrum using Fourier analysis techniques. Our analysis reveals that the known signals align well with theoretical predictions for stars on the red giant branch. Specifically, we demonstrate that the significant splitting observed between successive radial orders corresponds to an evolutionary stage indicative of a stellar mass of approximately 1.5 Msun. Additionally, we leverage our results to evaluate the lifetimes of individual modes based on their degree. Our findings indicate that low-degree p-modes exhibit considerably longer lifetimes than current theoretical predictions suggest. This observation raises the possibility that convection plays a relatively minor role in these mechanisms, or that additional physical processes may need to be considered. \n\nKeywords: Red giants",
        "ori-fast-z-score": -0.1125087900926024,
        "water-fast-z-score": 6.037383539249432,
        "rewrite-fast-z-score": 1.2222222222222223
    },
    {
        "original_text": "The Spitzer Bright Field (SBF) is an all-sky survey at 3.6, 4.5, 5.8 & 8 microns carried out by the Infrared Array Camera on board the Spitzer Space Telescope.  The SBF was designed to provide deep infrared photometry for extragalactic studies in order to complement existing optical surveys such as the Sloan Digital Sky Survey.   This dataset contains images taken with IRAC channel 1 (3.6 micron), channel 2 (4.5 micron), channel 3 (5.8 micron) and channel 4 (8 micron). Each image has been processed using the MOPEX software package developed by the Spitzer Science Center. These images are available through the NASA/IPAC Extragalactic Database (NED).  For more information about this project please see http://irsa.ipac.caltech.edu/data/SPITZER/docs/sbf/sbf-intro.html",
        "watermark_text": "The Spitzer Bright Field ( SBF ) is an all - skies study at 3 . 6 , 4 . 5 , 5 . 8 & 8 microns taken out by the Infrared Array Camera on board the Spitzer Space Telescope . The SBF was built to provide deep infrared photometry for extragalactic studies in order to complement existing imaging observations such as the Sloan Digital Sky Survey .This dataset contains images took with IRAC channel 1 ( 3 . 6 micron ) , channel 2 ( 4 . 5 micron ) , channel 3 ( 5 . 8 micron ) and channel 4 ( 8 micron ) . Each image has been processed utilizing the MOPEX software suite created by the Spitzer Science Center .These photographs are available through the NASA / IPAC Extragalactic Database ( NED ) . For more information about this project please view http : / / irsa . ipac . caltech . edu / data / SPITZER / docs / sbf / sbf - intro . html",
        "rewrite_text": "The Spitzer Bright Field (SBF) is a comprehensive sky survey conducted at wavelengths of 3.6, 4.5, 5.8, and 8 microns using the Infrared Array Camera (IRAC) on the Spitzer Space Telescope. The SBF was developed to provide detailed infrared photometry for extragalactic research, aiming to enhance existing imaging data such as that from the Sloan Digital Sky Survey. This dataset includes images captured by IRAC's four channels: channel 1 (3.6 microns), channel 2 (4.5 microns), channel 3 (5.8 microns), and channel 4 (8 microns). Each image has been processed with the MOPEX software suite, developed by the Spitzer Science Center. These images are accessible via the NASA/IPAC Extragalactic Database (NED). For further details about the project, please visit http://irsa.ipac.caltech.edu/data/SPITZER/docs/sbf/sbf-intro.html.",
        "ori-fast-z-score": 0.5222329678670935,
        "water-fast-z-score": 4.700096710803842,
        "rewrite-fast-z-score": 1.8593393604027364
    },
    {
        "original_text": "We study the magnetic field amplification in supernova remnants (SNRs) due to cosmic ray streaming instability, which is driven by anisotropic diffusion of energetic particles across the mean magnetic field lines. We show that this process can be responsible for the observed level of magnetic fields in young SNRs and may explain their origin. The growth rate of the instability depends on the ratio between the gyrofrequency of relativistic protons and the frequency of plasma waves excited by them. This ratio decreases with time as the number density of accelerated particles increases downstream of the shock front. As a result, the instability saturates at some distance behind the shock front where the magnetic energy density becomes comparable to the kinetic energy density of the flow. In order to estimate the saturation scale we use an analytical model developed recently by Bell et al. (2013) . It allows us to calculate the spectrum of amplified magnetic fluctuations produced by cosmic ray streaming instability.",
        "watermark_text": "We research the magnetic force amplification in supernova remnants ( SNRs ) resulting to cosmic ray streaming instability , which is caused by anisotropic absorption of excited particles across the mean magnetic field lines . We see that this process can be responsible for the observed level of magnetic waves in young SNRs and may reason their source .The growth speed of the instability depends on the proportion between the gyrofrequency of relativistic protons and the frequency of plasma beams excited by them . This ratio falls with time as the number density of advanced waves rises downstream of the shock front .As a result , the instability saturates at some distance behind the shock wall where the magnetic energy density becomes identical to the kinetic power concentration of the flow . In order to estimate the saturation scale we utilize an analytical theory created recently by Bell et al .( 2013 ) . It enables us to estimate the spectrum of amplified magnetic fluctuations produced by cosmic ray streaming instability .",
        "rewrite_text": "We investigate the amplification of magnetic forces in supernova remnants (SNRs) that leads to cosmic ray streaming instability, which occurs due to the anisotropic absorption of energized particles along the mean magnetic field lines. Our findings suggest that this phenomenon could account for the observed levels of magnetic waves in young SNRs and may help identify their source. The growth rate of the instability is influenced by the ratio of the gyrofrequency of relativistic protons to the frequency of the plasma beams they generate. This ratio decreases over time as the number density of advanced waves increases downstream of the shock front. Consequently, the instability reaches saturation at a certain distance behind the shock wall, where the magnetic energy density matches the kinetic energy density of the flow. To estimate the saturation scale, we use an analytical framework recently developed by Bell et al. (2013), which allows us to assess the spectrum of amplified magnetic fluctuations resulting from cosmic ray streaming instability.",
        "ori-fast-z-score": -0.6708203932499369,
        "water-fast-z-score": 4.695742752749558,
        "rewrite-fast-z-score": 2.111111111111111
    },
    {
        "original_text": "We study the effect of spin-one and spin-two particles on the circularly polarized light propagating through an external magnetic field. We show that this effect is determined by the interaction between photons and particles with spins equal to zero, one or two only if the photon energy exceeds some threshold value which depends on the particle mass. For example, for electrons (mass m = 9.11×10-31 kg) it equals to 0.5 MeV. Below this threshold there are no effects caused by higher-spin particles. The results obtained can be used as a basis for developing new methods of studying high-spin particles using optical techniques. DOI: 10.1088/1742-6596/aa6b20\nI. INTRODUCTIO N\nThe problem of describing the propagation of electromagnetic waves in matter has been studied extensively over many years  1  . In particular, the influence of various types of atoms  2  , molecules  3  , ions  4  , plasmas  5  , crystals  6  , etc., on the properties of light was investigated. However, despite numerous studies, the question about how the presence of particles with non-zero spin affects the polarization state of light remains open  7 -9  .\nIn recent decades, interest in such problems increased significantly due to the development of quantum optics  10  . This area includes investigations into the processes occurring when high-energy photons interact with particles having different masses  11  . Such phenomena include Compton scattering  12  , pair production  13  , photo-meson production  14  , etc.. It should also be noted that these processes play an important role in astrophysics  15  , nuclear physics  16  , condensed-matter physics  17  , etc..\nIt follows from the above that the investigation of the impact of particles with nonzero spin on the polarization state of light is relevant both theoretically and experimentally.",
        "watermark_text": "We test the impact of spin - one and spin - two particles on the circularly polarized light propagating through an external magnetic force . We see that this effect is chosen by the interaction between photons and atoms with spins equal to zero , one or two only if the photon energy reaches some threshold quantity which depends on the particle weight .For instance , for electrons ( mass m = 9 . 11×10 - 31 kg ) it corresponds to 0 . 5 MeV . Below this threshold there are no impacts produced by higher - spin rays .The results collected can be used as a foundation for building new ways of studying high - spinning objects utilizing optical techniques . DOI : 10 . 1088 / 1742 - 6596 / aa6b20 I . INTRODUCTIO N The question of describing the propagation of electromagnetic currents in material has been studied thoroughly over numerous years 1 .In particular , the impact of several kinds of atoms 2 , compounds 3 , electrons 4 , plasmas 5 , particles 6 , etc . , on the properties of light was investigated . However , despite several studies , the question about how the presence of atoms with quasi - zero spin affects the polarization state of light remains open 7 - 9 .In past decades , awareness in such problems intensified substantially due to the development of quantum optics 10 . This area includes research into the mechanisms occurring when high - energy photons react with particles having various masses 11 .Such effects include Compton diffusion 12 , pair production 13 , photo - meson production 14 , etc . . It should also be mentioned that these mechanisms play an important role in astrophysics 15 , nuclear science 16 , condensed - matter science 17 , etc . .It follows from the above that the examination of the impact of particles with nonzero momentum on the polarization state of light is relevant both theoretically and experimentally .",
        "rewrite_text": "We investigate the effects of one-spin and two-spin particles on circularly polarized light traveling through an external magnetic field. Our study shows that the interaction between photons and atoms with zero, one, or two spins only impacts the light if the photon energy surpasses a certain threshold that is influenced by the mass of the particle. For example, for electrons (mass m = 9.11 × 10^-31 kg), this threshold is approximately 0.5 MeV. Below this energy level, higher-spin radiation does not induce any effects. The findings from this research can serve as a basis for developing innovative methods to study high-spin objects using optical techniques. DOI: 10.1088/1742-6596/aa6b20. \n\nI. INTRODUCTION  \nThe propagation of electromagnetic currents in materials has been extensively researched over the years. In particular, studies have investigated how various types of atoms, compounds, electrons, plasmas, and other particles affect light properties. Despite these efforts, the influence of atoms with quasi-zero spin on the polarization state of light remains an unresolved question. Interest in this issue has grown significantly in recent decades, especially with advancements in quantum optics, which explores the interactions between high-energy photons and particles of different masses. Such interactions cover phenomena such as Compton scattering, pair production, and photo-meson production, which are important in fields like astrophysics, nuclear science, and condensed matter physics. Therefore, exploring how particles with nonzero momentum affect the polarization state of light is both theoretically and experimentally significant.",
        "ori-fast-z-score": -0.7071067811865475,
        "water-fast-z-score": 8.8925541538888,
        "rewrite-fast-z-score": 2.86595101383035
    },
    {
        "original_text": "We report on the optical and near-infrared afterglows of the short-hard burst GRB 050802 detected by Swift/BAT on May 2nd, 2005 at 07:55:06 UT (T0). The prompt emission was followed by an X-ray flare peaking at T0+500 s in the rest frame. We find that both components are well described by power laws with decay indices α1 = 1.2 ± 0.3 for t < 10 ks and α2 = 2.5 ± 0.4 for t > 10 ks. A break is observed between these two regimes around t0 + 20 ks. No evidence for spectral evolution or extinction has been found within each component. Our results suggest that this event may be similar to GRB 021004 which also showed a double-power law behaviour but without any significant spectral evolution across the break time. This suggests that the physical mechanism responsible for the late-time steepening could be related to the one producing the early shallow decline. \n \n Keywords: Gamma-ray burst",
        "watermark_text": "We report on the optical and far - infrared afterglows of the short - hard burst GRB 050802 detected by Swift / BAT on May 2nd , 2005 at 07 : 55 : 06 UT ( T0 ) . The prompt emission was followed by an X - ray flare peaking at T0 + 500 s in the rest frame .We see that both components are better characterised by power laws with decay indices α1 = 1 . 2 ± 0 . 3 for t < 10 ks and α2 = 2 . 5 ± 0 . 4 for t > 10 ks . A break is observed between these two regimes around t0 + 20 ks .No support for spectral evolution or extinction has been shown within each component . Our results propose that this event may be similar to GRB 021004 which also demonstrated a double - energy law evolution but without any considerable brightness progression across the break time .This implies that the physical process cause for the late - time steepening could be connected to the one generating the early shallow collapse . Keywords : Gamma - ray burst",
        "rewrite_text": "We present our findings on the optical and far-infrared afterglows of the short-hard gamma-ray burst GRB 050802, which was detected by the Swift/BAT on May 2, 2005, at 07:55:06 UT (T0). Following the prompt emission, an X-ray flare reached its peak at T0 + 500 seconds in the rest frame. Our analysis indicates that both components can be described by power laws, with decay indices of α1 = 1.2 ± 0.3 for t < 10 ks, and α2 = 2.5 ± 0.4 for t > 10 ks. A transition is identified between these two phases around t0 + 20 ks. We found no evidence of spectral evolution or extinction within either component. Our findings suggest that this event may be analogous to GRB 021004, which also exhibited a double-energy law progression without significant brightness change across the transition point. This raises the possibility that the mechanisms responsible for the late-time steepening may be related to those that caused the early shallow decline. Keywords: Gamma-ray burst.",
        "ori-fast-z-score": 0.6401843996644799,
        "water-fast-z-score": 4.48129079765136,
        "rewrite-fast-z-score": 1.212678125181665
    },
    {
        "original_text": "We study theoretically and numerically the effect of spatial dispersion (SD) on the shape of a light pulse propagating through an InGaAs/GaAs quantum well (QW). We show that SD leads to significant changes in the temporal profile of the transmitted pulse, which can be used for its characterization. The results are obtained by solving Maxwell s equations using the finite-difference time-domain method with periodic boundary conditions. It is shown that the presence of SD causes the appearance of additional peaks at both sides of the main peak of the transmitted pulse. These peaks become more pronounced as the QW width increases. \n \n Keywords: Light propagation, Finite difference time domain method, Quantum wells, Spatial dispersion. 1 Introduction \n \n A number of recent studies have been devoted to investigating the effects of spatial dispersion (SD), also known as nonlocality or transverse momentum conservation  1  , on various physical phenomena such as nonlinear wave dynamics  2  -  4  , spontaneous emission  5  , and transport  6  . This interest has been motivated mainly by the fact that many semiconductor devices operate under conditions where SD plays an important role  7, 8  .\n \nIn this work we consider the problem of light transmission through a single-mode quantum well (QW) structure  9  . Our aim is to investigate how SD affects the shape of the transmitted pulse. To do so, we solve Maxwell s equations using the finitedifference time-domain (FDTD) method  10  with periodic boundary conditions  11  . As it will be demonstrated below, our numerical simulations reveal that SD gives rise to new features in the temporal profile of a transmitted pulse.",
        "watermark_text": "We research theoretically and numerically the impact of spatial dispersion ( SD ) on the morphology of a light pulse propagating through an InGaAs / GaAs quantum well ( QW ) . We see that SD leads to significant improvements in the temporal profile of the transmitted signal , which can be used for its characterization .The results are derived by treating Maxwell s coefficients using the finite - variation time - domain approach with periodic boundary constraints . It is demonstrated that the presence of SD causes the appearance of new peaks at both sides of the main peak of the transmitted signal .These peaks become more pronounced as the QW width rises . Keywords : Light propagation , Finite difference time domain approach , Quantum wells , Spatial dispersion .1 Introduction A couple of recent studies have been focused to investigating the effects of spatial dispersion ( SD ) , sometimes called as nonlocality or transverse momentum conservation 1 , on various physical phenomena such as nonlinear wave interactions 2 - 4 , spontaneous emission 5 , and transport 6 . This interest has been motivated mainly by the fact that several semiconductor devices exist under environments where SD plays an important role 7 , 8 .In this research we study the issue of light transport through a single - mode quantum well ( QW ) structure 9 . Our aim is to examine how SD impacts the form of the transmitted signal .To do so , we solve Maxwell s coefficients utilizing the finitedifference time - domain ( FDTD ) method 10 with periodic boundary constraints 11 . As it will be showed below , our numerical simulations reveal that SD offers rise to novel features in the temporal profile of a broadcast pulse .",
        "rewrite_text": "We conduct both theoretical and numerical research on the influence of spatial dispersion (SD) on the morphology of a light pulse as it travels through an InGaAs/GaAs quantum well (QW). Our findings indicate that SD significantly enhances the temporal profile of the transmitted signal, which can be utilized for its characterization. These results are obtained by employing the finite-variation time-domain approach to evaluate Maxwell's coefficients with periodic boundary conditions. We demonstrate that the introduction of SD leads to the emergence of additional peaks on either side of the primary peak of the transmitted signal, with these peaks becoming more pronounced as the width of the QW increases. \n\nKeywords: Light propagation, Finite difference time domain method, Quantum wells, Spatial dispersion.\n\n1. Introduction\n\nRecent studies have focused on examining the effects of spatial dispersion (SD)—also referred to as nonlocality or transverse momentum conservation—on various physical phenomena, such as nonlinear wave interactions, spontaneous emission, and transport. The growing interest in this topic is largely due to the presence of several semiconductor devices operating in environments where SD plays a critical role. In our research, we investigate light transport through a single-mode quantum well (QW) structure, aiming to assess how SD affects the structure of the transmitted signal. To achieve this, we utilize the finite-difference time-domain (FDTD) method with periodic boundary conditions. Our numerical simulations reveal that SD introduces new features in the temporal profile of the emitted pulse.",
        "ori-fast-z-score": -0.8181818181818182,
        "water-fast-z-score": 6.518573715061334,
        "rewrite-fast-z-score": 1.6164477182409742
    },
    {
        "original_text": "We present new optical and near-infrared photometry obtained with the Hubble Space Telescope (HST) in order to study the late-time evolution of the supernova remnant N132D, which is associated with the type Ic supernova SN2002ap. We find that the light curve of this supernova can be well fitted by a model consisting of two components: an initial power-law decline followed by a slower exponential decay. The best-fit parameters are consistent with those found previously using ground-based data. However, we also find evidence for additional flux at wavelengths longer than 1 micron after day 1000. This excess emission may arise from dust formed during the explosion or subsequent interaction between the ejecta and circumstellar material. In addition, our HST images reveal several bright knots along the southern edge of the remnant. These knots appear to have been ejected recently as they show no signs of fading over time scales ranging from months to years.",
        "watermark_text": "We use new optical and far - infrared photometry obtained with the Hubble Space Telescope ( HST ) in order to study the mid - time progression of the supernova remnant N132D , which is associated with the class Ic supernova SN2002ap . We see that the light curve of this supernova can be well fitted by a theory consisting of two parts : an initial power - law decrease followed by a slower exponential decay .The best - fitting values are compatible with those identified previously used ground - based data . However , we also find proof for additional flux at wavelengths greater than 1 micron after day 1000 .This excess emission may arise from dust formed during the explosion or later interaction between the ejecta and circumstellar material . In addition , our HST pictures indicate many bright knots along the southern periphery of the remnant .These knots appear to have been ejected recently as they show no evidence of fading over time scales extending from months to decades .",
        "rewrite_text": "We utilize new optical and far-infrared photometry collected with the Hubble Space Telescope (HST) to investigate the mid-term evolution of the supernova remnant N132D, which is linked to the class Ic supernova SN2002ap. Our analysis reveals that the light curve of this supernova can be effectively modeled by a two-part theory: an initial power-law decline followed by a more gradual exponential decay. The optimal fitting values align well with those previously determined using ground-based observations. Additionally, we discover evidence of excess flux at wavelengths exceeding 1 micron after day 1000. This additional emission could be attributed to dust generated during the explosion or from later interactions between the ejecta and surrounding material. Moreover, our HST images reveal numerous bright knots along the southern edge of the remnant. These knots appear to have been ejected recently, as they show no signs of fading over timescales ranging from months to decades.",
        "ori-fast-z-score": 1.1322770341445956,
        "water-fast-z-score": 6.951595164037914,
        "rewrite-fast-z-score": 1.5011106998930268
    },
    {
        "original_text": "We report on the discovery of an unexpected ring-like dark matter structure at the center of galaxy cluster CL0024+17, which is located about 3 billion light years away and has been studied extensively by many observational techniques including gravitational lensing.  The mass distribution inferred from strong gravitational lensing shows that there are two massive subclusters separated by 1 Mpc (3 arcmin) with a total mass of 2 x 10 15 h-1M_sun within a radius of 0.5h-1Mpc around their centers. We find that this double-cluster system can be well described as a binary merger model where each component consists of three components; one main halo and two smaller halos surrounding it. In addition to these six clusters, we also detect another small clump of galaxies near the center of the merging system whose position coincides with the peak of X-ray emission detected by Chandra satellite observations.",
        "watermark_text": "We report on the discovery of an unexpected ring - like dark matter formation at the center of galaxy region CL0024 + 17 , which is situated about 3 billion light years far and has been studied significantly by many observational techniques including gravitational lensing . The mass distribution inferred from strong gravitational lensing indicates that there are two huge subclusters separated by 1 Mpc ( 3 arcmin ) with a total mass of 2 x 10 15 g - 1M _ sun within a diameter of 0 . 5h - 1Mpc around their regions .We see that this double - cluster system can be well described as a binary merger model where each core consists of three components ; one main halo and two smaller halos covering it . In addition to these six complexes , we also observe another tiny clump of stars near the center of the merging system whose position coincides with the maximum of X - ray radiation observed by Chandra satellite observations .",
        "rewrite_text": "We present our findings on an unexpected ring-like formation of dark matter located at the center of the galaxy cluster CL0024+17, which is approximately 3 billion light-years away. This region has been extensively studied using various observational techniques, including gravitational lensing. The mass distribution derived from strong gravitational lensing reveals two massive subclusters that are separated by 1 Mpc (3 arcminutes), with a total mass of 2 x 10^15 solar masses contained within a diameter of 0.5 h^-1 Mpc. Our analysis suggests that this double-cluster system can be effectively modeled as a binary merger, with each core comprising three components: a primary halo and two smaller halos surrounding it. Additionally, we detect a small clump of stars near the center of the merging system, whose location coincides with the peak of X-ray radiation observed by the Chandra satellite.",
        "ori-fast-z-score": 0.8682431421244593,
        "water-fast-z-score": 5.333493587335964,
        "rewrite-fast-z-score": 0.24618298195866545
    },
    {
        "original_text": "We have performed simulations of nova explosions using the hydrodynamic code VH-1, which includes nuclear burning and convection. We find that changes to reaction rates can significantly affect the results of these calculations. In particular, we show how different choices for the 12C(p,γ)13N rate lead to differences in the predicted light curve shapes.  The inclusion of this reaction is important because it affects the amount of 13N produced during the explosion. This isotope decays by electron capture into 14O, which then undergoes β+ decay back down to 14N. If there are too many electrons present at late times (due to an overabundance of 13N), they will be captured onto protons instead of being emitted as positrons; thus, less energy will be released than if no such process were occurring. Our results suggest that the current uncertainty in the 12C(p , γ )13N rate may cause errors in the predicted luminosity of up to 50%.",
        "watermark_text": "We have done simulations of nova explosions using the hydrodynamic code VH - 1 , which includes nuclear combustion and convection . We see that changes to reaction rates can significantly affect the results of these calculations .In particular , we study how various options for the 12C ( p , γ ) 13N rate lead to differences in the expected light curve sizes . The inclusion of this response is important because it affects the quantity of 13N produced during the explosion .This isotope decays by electron capture into 14O , which then undergoes β + decay back down to 14N . If there are too several electrons present at late times ( owing to an overabundance of 13N ) , they will be captured onto protons rather of being emitted as positrons ; thus , fewer electricity will be emitted than if no such mechanism were happening .Our results propose that the present uncertainty in the 12C ( p , γ ) 13N rate may create errors in the expected luminosity of up to 50 % .",
        "rewrite_text": "We have conducted simulations of nova explosions using the VH - 1 hydrodynamic code, which incorporates nuclear combustion and convection. Our findings indicate that variations in reaction rates can significantly impact the outcomes of these simulations. Specifically, we examine how different choices for the 12C (p, γ) 13N reaction rate influence the expected sizes of the light curves. Understanding this response is crucial, as it determines the amount of 13N produced during the explosion. This isotope decays through electron capture into 14O, which subsequently undergoes β+ decay back to 14N. If there is an excessive number of electrons present at later stages (due to a surplus of 13N), they will be captured by protons instead of being emitted as positrons; consequently, this results in a lower emission of energy than would occur without this process. Our results suggest that the current uncertainty surrounding the 12C (p, γ) 13N rate could lead to errors in predicted luminosity of up to 50%.",
        "ori-fast-z-score": -0.5,
        "water-fast-z-score": 4.75,
        "rewrite-fast-z-score": 0.601929265428846
    },
    {
        "original_text": "The Minimal Supersymmetric Standard Model (MSSM) is the most widely studied extension to the Standard Model, and it predicts new particles that can be discovered in future experiments at the Large Hadron Collider (LHC). In this talk I will discuss some recent results on the search for supersymmetry using data collected by the ATLAS experiment during Run 1 of LHC operation. The focus will be on the properties of the lightest CP-even neutral Higgs boson h0, which are strongly affected by radiative corrections due to top/stop loops. These effects lead to significant deviations between predictions based on tree-level calculations and those obtained with full one-loop computations. This has important consequences both for experimental analyses as well as for theoretical studies aimed at extracting information about fundamental parameters such as tanβ or mtop from measurements performed at hadron colliders. \n \n For example, we show how the inclusion of higher-order corrections leads to an improved agreement between theory and experiment when comparing the measured mass of the Higgs boson with its predicted value within the MSSM framework. We also present results on the production cross sections of the different decay modes of the Higgs boson, including their dependence on the choice of renormalisation scale used in the calculation. Finally, we briefly comment on prospects for Higgs searches at the LHC after Run 2.",
        "watermark_text": "The Minimal Supersymmetric Standard Model ( MSSM ) is the most commonly researched extension to the Standard Model , and it predicts new objects that can be found in future research at the Large Hadron Collider ( LHC ) . In this talk I will explore some latest findings on the hunt for supersymmetry using data received by the ATLAS experiment during Run 1 of LHC operation .The emphasis will be on the properties of the lightest CP - even stable Higgs boson h0 , which are strongly altered by radiative corrections due to top / stopping loops . These effects lead to significant deviations between estimates based on tree - level calculations and those achieved with full one - loop computations .This has useful consequences both for theoretical analyses as also as for theoretical experiments intended at extracting information about basic parameters such as tanβ or mtop from measurements accomplished at hadron colliders . For instance , we show how the inclusion of greater - order corrections helps to an better agreement between theoretical and experiment when comparing the measured mass of the Higgs boson with its predicted value within the MSSM framework .We additionally offer results on the production cross sections of the different decay modes of the Higgs boson , notably their dependence on the selection of renormalisation scale used in the calculation . Finally , we briefly comment on possibilities for Higgs detection at the LHC after Run 2 .",
        "rewrite_text": "The Minimal Supersymmetric Standard Model (MSSM) is the most extensively studied extension of the Standard Model, predicting new particles that future research at the Large Hadron Collider (LHC) may uncover. In this presentation, I will delve into recent discoveries in the search for supersymmetry, utilizing data from the ATLAS experiment collected during Run 1 of LHC operations. My focus will be on the properties of the lightest CP-even stable Higgs boson, h0, which are significantly influenced by radiative corrections from top/stop loops. These corrections result in notable discrepancies between estimates derived from tree-level calculations and those obtained through comprehensive one-loop computations. This has important implications for both theoretical analyses and experiments aimed at extracting fundamental parameters, such as tanβ or mtop, from measurements conducted at hadron colliders. For example, I will demonstrate how incorporating higher-order corrections enhances the alignment between theoretical predictions and experimental results when comparing the observed mass of the Higgs boson with its MSSM-predicted value. Additionally, I will present findings on the production cross sections of various Higgs boson decay modes, particularly highlighting their sensitivity to the choice of renormalization scale in the calculations. Lastly, I will briefly discuss the potential for Higgs detection at the LHC following Run 2.",
        "ori-fast-z-score": -1.0660035817780522,
        "water-fast-z-score": 6.11104144857543,
        "rewrite-fast-z-score": -0.4472135954999579
    },
    {
        "original_text": "We present an algorithm for the decomposition of the local stellar kinematics into vector spherical harmonic functions (VSH). The method is applied to simulated data and real observations, where we recover the underlying VSH coefficients with high accuracy. We show that our approach can be used as a powerful tool in galactic dynamics studies by recovering the gravitational potential of the Milky Way s dark matter halo. In addition, it allows us to study the anisotropy of the stellar orbits on different scales. \n \n Keywords: Vector spherical harmonics, Galactic dynamics, Stellar kinematics, Gravitational potentials \n \n 1 Introduction \n \n Spherical Harmonic Analysis has been widely used over many decades to analyse astronomical datasets such as galaxy surveys or star counts. However, this technique cannot easily be extended to deal with non-scalar quantities like velocities or accelerations. This problem was overcome by expanding these quantities onto vector spherical harmonics (VSH) which are defined as tensor products of scalar spherical harmonics  1  . These new basis functions have already found applications in fields ranging from cosmology  2  , solar physics  3  , heliophysics  4  and geophysics  5  .\n \nIn recent years there has been growing interest in using VSHs to model the observed properties of galaxies  6  -  8  . For example, they were recently employed to decompose the line-of-sight component of the stellar kinematics  9  . Here, we extend their use to also include the tangential components of the stellar motions. As a result, we obtain a complete description of the three-dimensional distribution of the stellar kinematics within each spatial bin. Moreover, since the expansion coefficients depend only on angular coordinates, they can be determined independently at every point along the line-of-sight. Therefore, our method does not require any assumptions about the symmetry of the system under investigation. \n2 Vector spherical harmonics",
        "watermark_text": "We present an algorithm for the decomposition of the local stars kinematics into vector spherical harmonic functions ( VSH ) . The method is applied to modeled images and actual observations , where we recover the underlying VSH coefficients with high efficiency .We suggest that our approach can be used as a powerful tool in galactic dynamics experiments by searching the gravitational potential of the Milky Way s dark matter halo . In addition , it allows us to study the anisotropy of the stars orbits on various scales .Keywords : Vector spherical harmonics , Galactic mechanics , Stellar kinematics , Gravitational potentials 1 Introduction Spherical Harmonic Analysis has been widely using over numerous centuries to analyse astronomical datasets such as galaxy surveys or moon numbers . However , this methodology cannot often be generalized to deal with non - scalar parameters like velocities or accelerations .This problem was resolved by expanding these quantities onto vector spherical harmonics ( VSH ) which are specified as vector products of scalar spherical harmonics 1 . These new basis variables have already found uses in areas ranging from cosmology 2 , lunar science 3 , heliophysics 4 and geophysics 5 .In past times there has been growing interest in utilizing VSHs to model the known characteristics of galaxies 6 - 8 . For instance , they were recently employed to decompose the line - of - view component of the stellar kinematics 9 .Here , we stretch their application to additionally include the tangential parts of the stars movements . As a result , we obtain a complete model of the three - dimensional distribution of the stars kinematics within each spatial bin .Moreover , since the expansion equations depend only on angular coordinates , they can be determined independently at every position along the line - of - view . Therefore , our technique does not require any constraints about the symmetry of the process under investigation .2 Vector spherical harmonics",
        "rewrite_text": "We introduce an algorithm for decomposing the kinematics of local stars into vector spherical harmonic functions (VSH). This method is applied to both simulated images and real observations, allowing us to efficiently recover the underlying VSH coefficients. We propose that our approach serves as a powerful tool for galactic dynamics studies, particularly in analyzing the gravitational potential of the Milky Way’s dark matter halo. Furthermore, it enables the exploration of the anisotropy of stellar orbits across different scales. \n\nKeywords: Vector spherical harmonics, Galactic mechanics, Stellar kinematics, Gravitational potentials\n\n1. Introduction\n\nSpherical Harmonic Analysis has been employed for centuries to analyze astronomical datasets, including galaxy surveys and lunar observations. However, this technique often struggles with non-scalar parameters such as velocities or accelerations. This issue has been addressed by expanding these quantities into vector spherical harmonics (VSH), defined as vector products of scalar spherical harmonics. These new basis functions have found applications in a variety of fields, including cosmology, lunar science, heliophysics, and geophysics. Recently, there has been increased interest in using VSHs to model the known properties of galaxies. For example, they have been applied to decompose the line-of-sight components of stellar kinematics. In this work, we extend their application to also encompass the tangential components of stellar motion. This allows us to develop a comprehensive model of the three-dimensional distribution of stellar kinematics within each spatial bin. Additionally, because the expansion equations rely solely on angular coordinates, they can be derived independently at each position along the line of sight. Consequently, our technique does not impose any assumptions regarding the symmetry of the process being studied.\n\n2. Vector Spherical Harmonics",
        "ori-fast-z-score": -1.4967665407535604,
        "water-fast-z-score": 7.60122529295103,
        "rewrite-fast-z-score": 0.8980265101338746
    },
    {
        "original_text": "We present an analysis of the kinetic Sunyaev-Zeldovich effect (kSZ) due to electrons in our galaxy, using data obtained with the Atacama Cosmology Telescope and the South Pole Telescope. We use two different methods for estimating the kSZ signal; one is based on cross-correlating maps of CMB temperature anisotropy at 150 GHz and 3000 GHz, while the other uses the power spectrum of the CMB temperature fluctuations at 150 GHz. The results are consistent between these two approaches within their respective uncertainties. We find that the amplitude of this signal agrees well with theoretical predictions when we assume a Navarro-Frenk-White profile for dark matter density distribution around galaxies. This measurement provides new constraints on cosmological parameters such as the Hubble constant H0 = 73 +/- 4 km s-1 Mpc-1 , the total mass density parameter Omega_m = 0.27 +/- 0.03 , and the equation-of-state w = -1.06 +/- 0.11 .",
        "watermark_text": "We present an assessment of the kinetic Sunyaev - Zeldovich effect ( kSZ ) due to electrons in our universe , using data acquired with the Atacama Cosmology Telescope and the South Pole Telescope . We use two different methods for estimating the kSZ signal ; one is based on cross - correlating mapping of CMB heat anisotropy at 150 GHz and 3000 GHz , while the other uses the power spectrum of the CMB heat fluctuations at 150 GHz .The results are compatible between these two perspectives within their different uncertainties . We see that the frequency of this signal agrees well with theoretical expectations when we suppose a Navarro - Frenk - White model for black material concentration distribution around galaxies .This measurement gives additional constraints on cosmological factors such as the Hubble constant H0 = 73 + / - 4 km s - 1 Mpc - 1 , the total mass density variable Omega _ m = 0 . 27 + / - 0 . 03 , and the equation - of - state w = - 1 . 06 + / - 0 . 11 .",
        "rewrite_text": "We provide an evaluation of the kinetic Sunyaev-Zeldovich effect (kSZ) attributed to electrons in our universe, utilizing data gathered from the Atacama Cosmology Telescope and the South Pole Telescope. Our analysis employs two distinct methods to estimate the kSZ signal: the first involves cross-correlating maps of CMB temperature anisotropy at 150 GHz and 3000 GHz, while the second leverages the power spectrum of CMB temperature fluctuations at 150 GHz. The findings from both approaches are consistent with each other within their respective uncertainties. Furthermore, the frequency of the observed signal aligns closely with theoretical predictions, assuming a Navarro-Frenk-White model for dark matter distribution around galaxies. This measurement places additional constraints on cosmological parameters, including the Hubble constant \\(H_0 = 73 \\pm 4 \\, \\text{km s}^{-1} \\text{Mpc}^{-1}\\), the total mass density parameter \\(\\Omega_m = 0.27 \\pm 0.03\\), and the equation of state \\(w = -1.06 \\pm 0.11\\).",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.443310539518174,
        "rewrite-fast-z-score": -0.3841106397986879
    },
    {
        "original_text": "We study the clustering coefficients of protein-protein interaction networks (PPINs) and their relationship with network topological properties, such as degree distribution and average path length. We find that PPINs have higher clustering coefficients than random graphs with similar degrees or scale-free networks generated by Barabasi-Albert model. The high clustering coefficient is mainly due to the existence of many triangles in these networks. In addition, we show that the clustering coefficients are correlated positively with the number of proteins but negatively with the number of interactions per protein. These results suggest that there may be some common mechanisms underlying the formation of both triangles and edges between two nodes with large degrees. Finally, we propose an algorithm for identifying functional modules based on local clustering analysis. Our method can identify clusters with different sizes and shapes. Clustering coefficients of protein-protein interactomes are studied. It is found that they are significantly larger than those of random graphs with same degree distributions or scale-free networks generated using Barabasi-Albert preferential attachment rule. High clustering coefficients are mainly caused by the presence of many triangles in these systems. Correlations between clustering coefficients and other topological parameters are also investigated. An algorithm for finding functional modules based on local cluster analysis is proposed.",
        "watermark_text": "We explore the clustering coefficients of gene - protein interaction systems ( PPINs ) and their connection with network topological features , such as extent distribution and average route length . We see that PPINs have greater clustering coefficients than random graphs with similar degrees or scale - free networks generated by Barabasi - Albert model .The high clustering coefficient is mainly owing to the existence of several triangles in these networks . In addition , we find that the clustering coefficients are correlated positively with the number of proteins but negatively with the quantity of interactions per protein .These data suggest that there may be some common mechanisms governing the formation of both triangles and edges between two nodes with large degrees . Finally , we propose an algorithm for finding functional modules based on local clustering theory .Our techniques can identify groups with various sizes and shapes . Clustering coefficients of protein - protein interactomes are studied .It is found that they are greatly larger than those of random graphs with same degree distributions or scale - free networks generated using Barabasi - Albert preferential attachment principle . High clustering coefficients are mainly caused by the presence of several triangles in these systems .Correlations between clustering variables and other topological parameters are also examined . An method for finding functional modules based on local cluster analysis is proposed .",
        "rewrite_text": "We investigate the clustering coefficients of gene-protein interaction networks (PPINs) and their relationship with topological features of the network, including degree distribution and average path length. Our analysis reveals that PPINs exhibit higher clustering coefficients compared to random graphs with similar degree distributions or scale-free networks generated by the Barabási-Albert model. This elevated clustering coefficient primarily arises from the abundance of triangles within these networks. Furthermore, we observe a positive correlation between clustering coefficients and the number of proteins, while a negative correlation exists with the number of interactions per protein. These findings imply that common mechanisms may regulate the formation of both triangles and connections between high-degree nodes. Lastly, we propose an algorithm based on local clustering theory to identify functional modules, capable of recognizing groups of varying sizes and shapes within protein-protein interactomes. The clustering coefficients of these interactomes are significantly higher than those of random graphs with comparable degree distributions or scale-free networks using the Barabási-Albert preferential attachment principle. We also assess the correlations between clustering coefficients and other topological parameters, further enhancing our understanding of the structural properties of these systems.",
        "ori-fast-z-score": -1.4501047335684953,
        "water-fast-z-score": 4.233901974057256,
        "rewrite-fast-z-score": -0.6
    },
    {
        "original_text": "We study the correspondence principle between string theory on anti-de Sitter space-time (AdS(3)) and field theories at finite temperature, by using Hagedorn strings as probes. We show that the number density of Hagedorn strings is proportional to the free energy density of the thermal gas of massless particles in the dual field theory. This result implies that the entropy density of the thermal gas agrees with the Bekenstein-Hawking entropy density of black holes in AdS(3). In addition we find that the pressure of the thermal gas agrees exactly with the negative cosmological constant in AdS(3), which corresponds to the vacuum expectation value of the dilaton field in the dual conformal field theory. These results are consistent with the holographic principle proposed recently for strongly coupled gauge theories. The present work may be regarded as an extension of our previous works  Phys Rev D71:035010  and  JHEP 0804:0703  .",
        "watermark_text": "We research the correspondence principle between string theory on anti - de Sitter space - time ( AdS ( 3 ) ) and field theories at finite temperature , by using Hagedorn strings as probes . We see that the number density of Hagedorn strings is proportional to the free energy density of the thermal gas of massless molecules in the dual field theory .This result means that the entropy concentration of the thermal gas agrees with the Bekenstein - Hawking entropy concentration of black holes in AdS ( 3 ) . In addition we find that the pressure of the thermal gas agrees exactly with the negative cosmological coefficient in AdS ( 3 ) , which equals to the vacuum expectation value of the dilaton field in the dual conformal field model .These conclusions are compatible with the holographic principle adopted recently for highly coupled gauge fields . The present work would be regarded as an addition of our previous works Phys Rev D71 : 035010 and JHEP 0804 : 0703 .",
        "rewrite_text": "We investigate the correspondence principle between string theory in anti-de Sitter space-time (AdS(3)) and finite-temperature field theories, utilizing Hagedorn strings as probes. Our findings reveal that the number density of Hagedorn strings is proportional to the free energy density of the thermal gas composed of massless particles in the corresponding field theory. This result indicates that the entropy density of the thermal gas aligns with the Bekenstein-Hawking entropy density associated with black holes in AdS(3). Furthermore, we demonstrate that the pressure of the thermal gas corresponds precisely to the negative cosmological constant in AdS(3), which is equivalent to the vacuum expectation value of the dilaton field in the dual conformal field theory. Our conclusions are consistent with the recently adopted holographic principle for strongly coupled gauge fields. This research builds upon our previous works published in Phys Rev D71: 035010 and JHEP 0804: 0703.",
        "ori-fast-z-score": 0.47809144373375745,
        "water-fast-z-score": 4.541868715470696,
        "rewrite-fast-z-score": 0.9561828874675149
    },
    {
        "original_text": "We show that any physical realization of the quantum NOT gate must be accompanied by an energy cost, which is bounded below by a universal constant times the number of qubits in the system. This result follows directly from our proof of the existence of a lower bound on the ground-state energy density of certain spin systems with competing interactions and open boundary conditions. Our results are relevant to recent efforts aimed at realizing large-scale quantum computers using solid state devices such as semiconductor quantum dots or trapped ions. We also discuss possible extensions of this work to other types of quantum gates. The ability to perform arbitrary unitary transformations on a set of n qubits would constitute a quantum computer capable of solving problems exponentially faster than classical computers  1  . However, it has been shown  2  that no quantum algorithm can solve all computational problems more efficiently than its best known classical counterpart unless the polynomial hierarchy collapses. Thus, practical quantum computing requires efficient methods for implementing only those algorithms whose solutions cannot be found classically  3  .\nIn order to implement these algorithms, one needs to be able to perform basic operations such as single-qubit rotations  4  , two-qubit entangling gates  5  , and measurements  6  . In particular, the so-called CNOT (controlled-NOT) gate plays a central role  7, 8  since it allows one to construct many important quantum circuits  9  . Unfortunately, there exists no known method for constructing a general CNOT gate  10  ; however, several proposals have recently emerged  11  -  16  . These schemes typically involve coupling the spins of individual atoms via magnetic fields  17  and/or optical cavities  18  . While some experimental progress towards building small-scale quantum computers has already been made  19, 20  , scaling up these technologies remains extremely challenging  21  .",
        "watermark_text": "We see that any physical formulation of the quantum NOT gate must be accompanied by an energy cost , which is bounded below by a universal constant times the number of qubits in the system . This result follows directly from our proof of the existence of a lower bound on the ground - state energy density of certain spin systems with competing interactions and open boundary constraints .Our results are applicable to recent efforts aimed at developing huge - scale quantum computers utilizing steady state systems such as semiconductor quantum dots or trapped ions . We especially consider possible extend of this research to other types of quantum gates .The able to conduct arbitrary unitary transformations on a group of n qubits would create a quantum computer capable of solution problems exponentially better than classical processors 1 . However , it has been shown 2 that no quantum algorithm can answer all computational problems more efficiently than its best known classical counterpart unless the linear hierarchy collapses .Thus , practical quantum modeling needs efficient methods for applying only those algorithms whose solutions cannot be found classically 3 . In order to execute these algorithms , one needs to be able to conduct basic operations such as single - qubit rotations 4 , two - qubit entangling gates 5 , and measurements 6 .In particular , the so - called CNOT ( restricted - NOT ) loop plays a central role 7 , 8 since it allows one to build much crucial quantum networks 9 . Unfortunately , there exists no available method for constructing a general CNOT gate 10 ; however , various options have recently surfaced 11 - 16 .These methods typically involve bonding the spins of individual atoms via magnetic waves 17 and / or optical cavities 18 . While some experimental development towards creating low - scale quantum computers has already been achieved 19 , 20 , scaling up these concepts remains incredibly problematic 21 .",
        "rewrite_text": "Any physical realization of the quantum NOT gate involves an energy cost that is limited by a universal constant multiplied by the number of qubits in the system. This finding stems directly from our proof of a lower bound on the ground-state energy density in certain spin systems characterized by competing interactions and open boundary conditions. Our results are relevant to recent initiatives focused on building large-scale quantum computers that leverage steady-state systems like semiconductor quantum dots or trapped ions. We also consider the potential to extend this research to other types of quantum gates. The capability to perform arbitrary unitary transformations on a set of n qubits would lead to quantum computers capable of solving problems exponentially faster than classical computers. However, it has been demonstrated that no quantum algorithm can solve all computational problems more efficiently than its best classical counterpart unless there is a collapse in the linear hierarchy. Therefore, effective quantum modeling must employ efficient methods to implement only those algorithms whose solutions cannot be found classically. To run these algorithms, basic operations are necessary, such as single-qubit rotations, two-qubit entangling gates, and measurements. The CNOT (controlled NOT) gate is particularly important because it enables the construction of crucial quantum networks. Unfortunately, there currently is no general method for constructing a CNOT gate, although various potential approaches have emerged recently. These methods usually involve coupling the spins of individual atoms through magnetic waves and/or optical cavities. While there has been progress in the development of small-scale quantum computers, scaling these concepts up remains a significant challenge.",
        "ori-fast-z-score": -0.39405520311955033,
        "water-fast-z-score": 6.442528450810767,
        "rewrite-fast-z-score": -0.1643989873053573
    },
    {
        "original_text": "We report on Suzaku observations for four active galactic nuclei (AGNs) detected by Swift/BAT survey, which are classified as  obscured AGNs  with column density larger than 10 24 cm-2 . We found that all these sources show strong Fe K emission lines and their line widths are broader than those expected from thermal broadening at kT = 100 keV. The observed line profiles can be reproduced well by relativistic disk reflection models including Compton scattering effects. These results suggest that there is an additional component to the X-ray continuum other than the standard thin accretion disks around supermassive black holes. In addition, we find that the iron abundance relative to solar value is higher than 1.5 times in three out of four objects. This suggests that the central engines of these obscured AGNs may have been buried under heavy dusty torii. Finally, we discuss possible origins of this new type of buried supermassive black holes based on our observational results.",
        "watermark_text": "We report on Suzaku measurements for four active galactic nuclei ( AGNs ) detected by Swift / BAT search , which are classified as obscured AGNs with column height larger than 10 24 mm - 2 . We showed that all these sources show light Fe K emission lines and their line widths are larger than those expected from radiation broadening at kT = 100 keV .The observed line profiles can be reproduced well by relativistic disk absorption theories including Compton scattering effects . These data suggest that there is an additional element to the X - ray continuum other than the standard narrow accretion disks around supermassive black holes .In addition , we find that the metal density relative to solar value is higher than 1 . 5 times in three out of four objects . This implies that the main engines of these obscured AGNs might have been trapped under heavy dusty torii .Finally , we explain possible origins of this new kind of hidden supermassive black holes using on our observational results .",
        "rewrite_text": "We present measurements from the Suzaku satellite for four active galactic nuclei (AGNs) identified by the Swift/BAT survey, all of which are classified as obscured AGNs with column densities exceeding 10^24 cm^-2. Our analysis reveals that all these sources exhibit light Fe K emission lines, with line widths greater than those anticipated from radiation broadening at a temperature of kT = 100 keV. The observed line profiles can be accurately modeled using relativistic disk absorption theories that incorporate Compton scattering effects. These findings indicate that there exists an additional component to the X-ray continuum beyond the typical narrow accretion disks surrounding supermassive black holes. Furthermore, we discover that the metal density relative to the solar value exceeds 1.5 times in three of the four AGNs studied, suggesting that the central engines of these obscured AGNs may be concealed beneath dense dusty tori. Finally, we discuss potential origins of this newly identified class of hidden supermassive black holes based on our observational data.",
        "ori-fast-z-score": 0.11867816581938533,
        "water-fast-z-score": 6.128258770283413,
        "rewrite-fast-z-score": 1.3587324409735149
    },
    {
        "original_text": "We study the effects of selection biases in cluster samples, as well as covariance between observables, on scaling relations derived from X-ray data using mock galaxy clusters generated with the semi-analytic model GALFORM. We find that both these effects can lead to significant systematic errors when deriving cosmological constraints from observed scaling relations. In particular we show that: (i) The scatter in the M-T relation is significantly reduced by including additional information about the temperature distribution function; this effect is stronger for low mass systems. (ii) The slope of the L-M relation depends strongly on whether or not one includes cooling flows in the analysis. This dependence arises because cool cores are more common at high masses than at lower masses, leading to an apparent steepening of the slope if they are excluded. (iii) The normalization of the Y-Xray luminosity-temperature relation shows strong redshift evolution which cannot be explained solely by self-similar evolution.",
        "watermark_text": "We research the effects of selection biases in cluster specimens , as well as covariance between observables , on scaling relations derived from X - ray data utilizing simulated galaxy galaxies produced with the semi - analytic model GALFORM . We see that both these influences can lead to significant systematic errors when deriving cosmological limitations from observed scaling relations .In particular we prove that : ( i ) The scatter in the M - T relation is significantly reduced by including extra data about the temperature distribution function ; this effect is strengthened for low mass systems . ( ii ) The slope of the L - M relation depends strongly on whether or not one includes heating flows in the evaluation .This dependence occurs because cool cores are more common at high masses than at lower masses , leading to an apparent steepening of the slope if they are ignored . ( iii ) The normalization of the Y - Xray luminosity - temperature relation shows deep redshift development which cannot be described solely by self - similar development .",
        "rewrite_text": "We investigate the impact of selection biases in cluster samples and the covariance between observables on scaling relations derived from X-ray data through simulations of galaxies generated with the semi-analytic model GALFORM. Our findings indicate that these factors can introduce significant systematic errors when assessing cosmological constraints based on observed scaling relations. Specifically, we demonstrate that: (i) incorporating additional data on the temperature distribution function notably reduces the scatter in the M-T relation, with this effect being more pronounced in low-mass systems; (ii) the slope of the L-M relation is highly sensitive to the inclusion of heating flows in the analysis, as cool cores are more prevalent in massive systems, which can result in an apparent steepening of the slope if overlooked; and (iii) the normalization of the Y-X-ray luminosity-temperature relation exhibits substantial evolution with redshift that cannot be adequately explained by self-similar development alone.",
        "ori-fast-z-score": -0.11704114719613057,
        "water-fast-z-score": 4.564604740649092,
        "rewrite-fast-z-score": 0.3611575592573076
    },
    {
        "original_text": "The space elevator is an important project in the future space exploration, which can provide transportation between Earth orbit and ground with high efficiency. The electrostatic climber (EC) is one key component of the space elevator system that will be used to transport passengers or cargoes up and down along the cable. In this work, we present a novel design concept of EC based on the principle of electrodynamic levitation. A prototype has been built according to our proposed design. It consists of two main parts: the upper platform and lower platform. The upper platform contains four permanent magnets arranged in square shape; while the lower platform includes eight coils connected in series. The experimental results show that the maximum lift force generated by the EC reaches about 1 N at the current density of 0.5 A/mm2 . This value meets the requirement of the space elevator application. Moreover, it also shows good stability when the load changes.",
        "watermark_text": "The space lift is an important project in the future space exploration , which can provide transit between Earth orbit and ground with high efficiency . The electrostatic climber ( EC ) is one key portion of the spacecraft elevator system that will be used to transport passengers or cargoes up and down along the cable .In this project , we present a new design concept of EC based on the principle of electrodynamic levitation . A prototype has been built according to our proposed design .It consists of two principal portions : the higher platform and lower platform . The higher platform includes four permanent magnets grouped in square position ; while the lower platform includes eight coils connected in series .The empirical results show that the maximum lift pressure generated by the EC reaches about 1 N at the current density of 0 . 5 A / mm2 . This value meets the requirement of the space elevator application .Moreover , it also shows excellent stability when the load changes .",
        "rewrite_text": "The space lift is a crucial initiative in the realm of future space exploration, offering an efficient means of transportation between Earth's orbit and the surface. A pivotal component of the spacecraft elevator system is the electrostatic climber (EC), designed to move passengers and cargo along the cable. In this project, we introduce a novel design concept for the EC grounded in the principles of electrodynamic levitation. We have constructed a prototype based on our proposed design, which consists of two primary components: an upper platform containing four permanent magnets arranged in a square configuration, and a lower platform featuring eight series-connected coils. Empirical results indicate that the EC can generate a maximum lift force of approximately 1 N at a current density of 0.5 A/mm², meeting the requirements for space elevator applications. Furthermore, the system demonstrates impressive stability even as load variations occur.",
        "ori-fast-z-score": -0.22941573387056174,
        "water-fast-z-score": 3.988620176087328,
        "rewrite-fast-z-score": -0.23249527748763857
    },
    {
        "original_text": "We present an experimental method for measuring the slip length in Newtonian fluids at low Reynolds number by means of a torsional ultrasonic oscillator (TUSO). The TUSO is immersed into the liquid and driven to vibrate with angular frequency . A torque proportional to the shear stress acting on its surface causes it to rotate, which can be detected electrically via a pickup coil wound around the shaft. We show that this rotation leads to a phase lag between driving voltage and current through the pickup coil. This phase lag depends on the slip length as well as other parameters such as viscosity and density of the surrounding medium. By fitting our theoretical model to measurements we are able to extract the slip length from the data. Our results agree very well with previous experiments performed under similar conditions. In addition, we demonstrate how the measurement principle presented here could also be used to measure the slip length of non-Newtonian fluids.",
        "watermark_text": "We present an observation technique for determining the slip length in Newtonian fluids at low Reynolds number by means of a torsional ultrasonic oscillator ( TUSO ) . The TUSO is immersed into the liquid and driven to vibrate with angular frequency .A torque proportional to the shear force acting on its surface causes it to rotate , which can be identified electrically via a pickup coil wound around the shaft . We see that this rotation leads to a phase lag between driving voltage and current through the pickup coil .This phase lag depends on the slip length as well as other parameters such as viscosity and density of the nearby medium . By fitting our theory profile to measurements we are able to extract the slip length from the information .Our results agree very best with previous tests accomplished under similar situations . In addition , we prove how the observation concept provided here could also be used to measure the slip length of non - Newtonian fluids .",
        "rewrite_text": "We introduce a method for measuring slip length in Newtonian fluids at low Reynolds numbers using a torsional ultrasonic oscillator (TUSO). The TUSO is submerged in the fluid and is set into vibrational motion at a specific angular frequency. The shear force acting on its surface generates a torque that causes it to rotate, which can be detected electrically through a pickup coil wrapped around the shaft. This rotation results in a phase lag between the driving voltage and the current in the pickup coil. The phase lag is influenced by the slip length as well as additional factors such as the viscosity and density of the surrounding medium. By fitting our theoretical model to the experimental data, we can determine the slip length. Our findings are in strong agreement with prior experiments conducted under similar conditions. Furthermore, we demonstrate that the observation technique discussed here can also be applied to measure the slip length in non-Newtonian fluids.",
        "ori-fast-z-score": 2.424871130596428,
        "water-fast-z-score": 6.581793068761733,
        "rewrite-fast-z-score": 1.2701705922171767
    },
    {
        "original_text": "We present new measurements of the helium mass fraction YHe = 0.24 ± 0.01 (statistical) ±0.02 (systematic), obtained by combining X-ray data on galaxy clusters with SZ observations, using the sample of 62 nearby relaxed galaxy clusters observed at high signal-to-noise ratio by Planck satellite. The results are consistent with previous determinations based on Chandra or XMM-Newton data alone. \n \n We also report an improved measurement of the Hubble constant H0 = 67.4±1.2 km s-1 Mpc-1, which is derived from our determination of the angular diameter distance to these clusters combined with their redshifts. This value agrees well with other recent estimates but has smaller statistical uncertainty than most of them. It is also compatible within 1 sigma with the local measurement inferred from Cepheid variables. \n \n Finally we use this dataset to test for possible deviations from standard cosmology due to massive neutrinos. Our analysis shows that current data do not allow us to detect any significant deviation from the predictions of ΛCDM model.",
        "watermark_text": "We report new studies of the helium mass fraction YHe = 0 . 24 ± 0 . 01 ( statistical ) ±0 . 02 ( systematic ) , obtained by combining X - ray data on star clusters with SZ measurements , using the sample of 62 nearby relaxed galaxy galaxies collected at high signal - to - noise proportion by Planck rocket . The results are compatible with previous determinations based on Chandra or XMM - Newton data alone .We additionally report an better determination of the Hubble constant H0 = 67 . 4±1 . 2 km s - 1 Mpc - 1 , which is calculated from our determination of the angular length length to these clusters combined with their redshifts . This value agrees well with other recent estimates but has less statistical uncertainty than most of them .It is also consistent within 1 sigma with the local measurement inferred from Cepheid variables . Finally we utilize this dataset to test for probable deviations from standard cosmology due to massive neutrinos .Our study shows that current data do not enable us to identify any large deviation from the estimates of ΛCDM system .",
        "rewrite_text": "We present new findings on the helium mass fraction, YHe = 0.24 ± 0.01 (statistical) ± 0.02 (systematic). This value was derived by combining X-ray observations of star clusters with Sunyaev-Zel'dovich (SZ) measurements from a sample of 62 nearby relaxed galaxy clusters, collected by the Planck satellite with a high signal-to-noise ratio. Our results align with earlier estimates based solely on Chandra or XMM-Newton data. Additionally, we provide an improved measurement of the Hubble constant, H0 = 67.4 ± 1.2 km s⁻¹ Mpc⁻¹, which we obtained by combining our angular distance measurements to these clusters with their redshifts. This value is consistent with other recent estimates and has a lower statistical uncertainty than many of them. It also remains within 1 sigma of the local measurement derived from Cepheid variables. Finally, we use this dataset to investigate possible deviations from standard cosmology due to massive neutrinos, finding that the current data do not reveal any significant deviations from the predictions of the ΛCDM model.",
        "ori-fast-z-score": 0.3464101615137754,
        "water-fast-z-score": 6.50986776965388,
        "rewrite-fast-z-score": -0.23249527748763857
    },
    {
        "original_text": "We present optical BVRI imaging, near-infrared JHKs photometry, and radio continuum observations at 1.4 GHz for the dwarf irregular galaxy ESO 364-G 029 (UGC 6456). The new data are combined with existing Hα spectroscopy to study its star formation history over the past few hundred million years. We find that this galaxy has experienced several bursts of intense star formation in recent times, which have produced large amounts of ionized gas visible as bright knots of emission across most of the face-on disk. These knots appear to be associated with young massive stars formed during each episode of star formation. In addition, we detect an extended component of diffuse ionized gas surrounding these knots. This is likely due to photoionization by hot evolved stars or supernovae remnants. Using our deepest images taken under good seeing conditions, we measure a total stellar mass of M = 2.1 × 10^7 M_sol within a radius of 5 kpc.",
        "watermark_text": "We use optical BVRI imaging , near - infrared JHKs photometry , and radio continuum measurements at 1 . 4 GHz for the dwarf irregular star ESO 364 - G 029 ( UGC 6456 ) . The revised data are coupled with existing Hα spectroscopy to study its galaxy formation history over the previous few hundred million years .We see that this galaxy has undergone several bursts of aggressive star formation in recent periods , which have created vast quantities of ionized gas evident as bright knots of emission across most of the face - on disk . These knots appear to be identified with young massive galaxies formed during each season of galaxy formation .In addition , we find an extended component of diffuse ionized gas covering these knots . This is probably due to photoionization by hot evolved galaxies or supernovae fragments .Using our deepest images took under good see conditions , we measure a total stellar mass of M = 2 . 1 × 10 ^ 7 M _ sol within a diameter of 5 kpc .",
        "rewrite_text": "We utilize optical BVRI imaging, near-infrared JHKs photometry, and radio continuum observations at 1.4 GHz to analyze the dwarf irregular galaxy ESO 364-G 029 (UGC 6456). This updated data is integrated with previous Hα spectroscopy to investigate its galaxy formation history over the past few hundred million years. Our findings indicate that this galaxy has experienced multiple episodes of intense star formation in recent times, leading to the creation of large amounts of ionized gas, which manifests as bright emission knots across the majority of its face-on disk. These knots appear to be associated with young massive galaxies formed during each phase of star formation. Furthermore, we identify an extended region of diffuse ionized gas surrounding these knots, likely resulting from photoionization by hot evolved stars or remnants of supernovae. By analyzing our deepest images obtained under favorable seeing conditions, we estimate a total stellar mass of M = 2.1 × 10^7 M_sol within a radius of 5 kpc.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.119912853410033,
        "rewrite-fast-z-score": 2.6210932585716726
    },
    {
        "original_text": "We consider the motion of an incompressible, inviscid fluid in two dimensions under the influence of gravity and surface tension. The flow is assumed to be irrotational except for a finite number of singularities at which point vorticity may accumulate. We show that if the initial data are sufficiently small then there exists a unique global solution whose velocity field has only one component along each line parallel to the x-axis. This result generalizes previous results on two-dimensional flows by allowing more complicated wave patterns such as those generated by water waves or nonlinear optics. \n \n Keywords: Fluids; Vortices; Water waves; Nonlinear optics. 1 Introduction \n \n In this work we study the dynamics of fluids governed by the Euler equations in two space dimensions. Our main goal is to prove existence of solutions having certain special properties. More precisely, let us assume that the initial velocity field u0(x) = (u0x(x), u0y(x)) satisfies the following conditions:",
        "watermark_text": "We consider the movement of an incompressible , inviscid fluid in two dimensions under the effects of gravitational and surface stress . The flow is expected to be irrotational except for a finite number of singularities at which point vorticity may accumulate .We see that if the first data are sufficiently small then there exists a unique global solution whose momentum field has only one element along each line parallel to the x - axis . This result generalizes earlier findings on two - dimensional flows by giving more complicated wave patterns such as those generated by water waves or nonlinear optics .Keywords : Fluids ; Vortices ; Water waves ; Nonlinear optics . 1 Introduction In this study we study the dynamics of fluids governed by the Euler equations in two space dimensions .Our main goal is to prove existence of solutions having specific particular features . More specifically , let us assume that the initial velocity field u0 ( x ) = ( u0x ( x ) , u0y ( x ) ) satisfies the following assumptions :",
        "rewrite_text": "We examine the behavior of an incompressible, inviscid fluid in two dimensions influenced by gravitational forces and surface tension. The flow is anticipated to be irrotational, except for a limited number of singular points where vorticity may concentrate. Our findings indicate that if the initial data is sufficiently small, there is a unique global solution in which the momentum field possesses a single value along each line parallel to the x-axis. This result extends previous research on two-dimensional flows by accommodating more complex wave patterns, such as those produced by water waves or in the field of nonlinear optics. \n\nKeywords: Fluids; Vortices; Water Waves; Nonlinear Optics. \n\n1 Introduction\n\nIn this paper, we investigate the dynamics of fluids governed by the Euler equations in two spatial dimensions. Our primary objective is to demonstrate the existence of solutions with specific characteristics. More precisely, we begin by assuming that the initial velocity field \\( u_0(x) = (u_{0x}(x), u_{0y}(x)) \\) meets the following conditions:",
        "ori-fast-z-score": 0.7276068751089989,
        "water-fast-z-score": 5.2532861073211246,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "The Cornell Caltech Atacama: The Cornell Caltech Atacame Observatory (CCAT) is an optical and infrared telescope under construction in Chile s northern desert, near the town of San Pedro de Atacama.  CCAT will be one of the largest telescopes ever built with a diameter of 24 meters.   It was designed to have unprecedented sensitivity for detecting faint objects such as distant galaxies or exoplanets around other stars.    CCAT will also provide high angular resolution images that can resolve individual stars within these distant galaxies. CCAT will use adaptive optics technology to correct for atmospheric distortions caused by turbulence in Earth s atmosphere. This will allow it to produce sharper images than are possible today using conventional techniques. CCAT will operate at wavelengths ranging from 0.35 microns to 16 microns. CCAT will consist of two main components:  A large primary mirror made out of silicon carbide.",
        "watermark_text": "The Cornell Caltech Atacama : The Cornell Caltech Atacame Observatory ( CCAT ) is an optical and infrared telescope under construction in Chile s northern desert , near the town of San Pedro de Atacama . CCAT will be one of the huge telescopes yet built with a diameter of 24 meters .It was built to have enormous sensitivity for detecting weak structures such as distant galaxies or exoplanets around other stars . CCAT will also supply high angular resolution images that can resolve individual stars within these distant galaxies .CCAT will use adaptive optics techniques to correct for atmospheric distortions caused by turbulence in Earth s atmosphere . This will allow it to produce sharper pictures than are possible nowadays using conventional methods .CCAT will function at wavelengths ranging from 0 . 35 microns to 16 microns . CCAT will consist of two principal structures : A wide primary mirror making out of silicon carbide .",
        "rewrite_text": "The Cornell Caltech Atacama Observatory (CCAT) is an optical and infrared telescope currently being constructed in the northern desert of Chile, near the town of San Pedro de Atacama. With a diameter of 24 meters, CCAT is set to become one of the largest telescopes ever built. Its design aims to achieve exceptional sensitivity for detecting faint structures, such as distant galaxies and exoplanets orbiting other stars. Additionally, CCAT will provide high angular resolution images capable of resolving individual stars within these distant galaxies. The observatory will employ adaptive optics techniques to correct for atmospheric distortions caused by turbulence in Earth's atmosphere, enabling it to capture sharper images than those produced by conventional methods today. CCAT will operate across a wavelength range from 0.35 microns to 16 microns, and its main structure will feature a wide primary mirror made of silicon carbide.",
        "ori-fast-z-score": 0.8017837257372732,
        "water-fast-z-score": 4.810702354423639,
        "rewrite-fast-z-score": 0.762000762001143
    },
    {
        "original_text": "We study the complexity of model checking higher-order fixpoint logic (HFL) over finite Kripke structures, which is an extension of propositional modal logic with fixpoints and quantification over state variables ranging over infinite domains. We show that HFL satisfiability can be reduced to the problem of deciding whether there exists a solution for a system of linear equations in rational numbers whose coefficients are given by polynomials over integers. This reduction allows us to obtain lower bounds on the computational complexity of HFL satisfiability using known results about solving systems of polynomial equations. In particular, we prove PSPACE-hardness of HFL satisfiability when the number of fixpoint operators occurring in the formula is unbounded or restricted only to existential ones. On the other hand, we provide a simple algorithm for HFL satisfiability based on computing least solutions of certain systems of integer quadratic equations. The running time of this algorithm depends exponentially on the maximum degree of these equations but it does not depend on the number of fixpoint",
        "watermark_text": "We explore the complexity of model checking upper - order fixpoint reasoning ( HFL ) over discrete Kripke structures , which is an extension of propositional modal logic with fixpoints and quantification over state variables ranging over arbitrary domains . We see that HFL satisfiability can be reduced to the question of deciding whether there exists a solution for a system of linear equations in rational integers whose coefficients are given by polynomials over integers .This reduction helps us to obtain lower bounds on the computational efficiency of HFL satisfiability utilizing famous results about solving systems of polynomial equations . In particular , we prove PSPACE - hardness of HFL satisfiability when the number of fixpoint operators appearing in the formula is unbounded or restricted only to existential ones .On the other hand , we provide a simple algorithm for HFL satisfiability based on solving least solutions of certain systems of integer quadratic variables . The run time of this algorithm depends exponentially on the maximum degree of these equations but it does not depend on the number of fixpoint",
        "rewrite_text": "We investigate the intricacies of model checking higher-order fixpoint reasoning (HFL) within discrete Kripke structures. HFL serves as an extension of propositional modal logic, incorporating fixpoints and allowing quantification over state variables that can take on values from arbitrary domains. Our analysis reveals that determining the satisfiability of HFL can be transformed into the problem of finding solutions for a system of linear equations with rational integer coefficients, where these coefficients are derived from polynomials over integers. This transformation enables us to establish lower bounds on the computational complexity of HFL satisfiability by leveraging well-known results concerning the resolution of polynomial equation systems. Specifically, we demonstrate that HFL satisfiability is PSPACE-hard when the formula contains an unbounded number of fixpoint operators or only existential ones. Conversely, we present a straightforward algorithm for HFL satisfiability that is founded on obtaining the least solutions to specific systems involving integer quadratic variables. While the runtime of this algorithm grows exponentially with the maximum degree of these equations, it is independent of the number of fixpoint operators present.",
        "ori-fast-z-score": -1.162476387438193,
        "water-fast-z-score": 2.789943329851663,
        "rewrite-fast-z-score": -1.2375966910186262
    },
    {
        "original_text": "The present work is devoted to the study of photon wave mechanics in terms of position eigenvectors, which are introduced as solutions of the Schrödinger equation for photons with an arbitrary energy spectrum. The concept of position eigenvector allows one to describe the state of a single photon by its position probability density distribution function (PDF). It also enables us to introduce the notion of quantum trajectory describing the evolution of this PDF over time. In particular, we show that the quantum trajectories corresponding to different initial states can be obtained from each other by means of unitary transformations. We demonstrate how these results may be used to analyze various phenomena related to the propagation of light through dispersive media. Finally, we discuss possible applications of our approach to the description of nonclassical effects associated with the emission of entangled pairs of photons. DOI: 10.1088/1742-6596/aa5e20\nI. INTRODUCTORY REMARkS\n\nIn recent years there has been considerable interest in developing new approaches to studying the properties of light fields based on the concepts of quantum optics  1–3  . One of such approaches involves introducing the so-called position eigenvectors  4  , which play an important role in the description of the state of a single-photon field  5–7  .\nIt should be noted that the use of position eigenvectors makes it possible not only to obtain information about the spatial structure of the electromagnetic field but also to investigate the temporal dynamics of the system under consideration  8, 9  . This fact opens up wide possibilities for applying the proposed method to analyzing various physical processes occurring during the propagation of light waves through dispersive media  10, 11  . \n \n In addition, the introduction of position eigenvectors into the theory of light fields leads to the possibility of using them to describe certain nonclassical effects associated",
        "watermark_text": "The present work is devoted to the study of photon wave theory in terms of position eigenvectors , which are introduced as solutions of the Schrödinger equation for photons with an arbitrary energy wavelength . The concept of position eigenvector allows one to define the state of a single photon by its position probability distribution distribution function ( PDF ) .It additionally permits us to introduce the notion of quantum path describing the evolution of this PDF over time . In particular , we prove that the quantum trajectories corresponding to different initial states can be obtained from each other by means of unitary transformations .We suggest how these results may be used to analyze numerous phenomena related to the propagation of light through dispersive media . Finally , we explain possible use of our approach to the description of nonclassical effects involved with the emission of entangled pairs of photons .DOI : 10 . 1088 / 1742 - 6596 / aa5e20 I . INTRODUCTORY REMARkS In recent years there has been sustained interest in developing new approaches to studying the properties of light fields based on the concepts of quantum optics 1 – 3 .One of such perspectives involves introducing the so - called position eigenvectors 4 , which take an important role in the description of the state of a single - photon field 5 – 7 . It should be mentioned that the using of position eigenvectors makes it necessary not only to obtain knowledge about the spatial shape of the electromagnetic field but also to examine the temporal properties of the system under consideration 8 , 9 .This fact offers up broad opportunities for applying the suggested method to investigating different physical processes arising during the propagation of light beams through dispersive media 10 , 11 . In addition , the introduction of position eigenvectors into the physics of light fields leads to the prospect of using them to explain certain nonclassical effects associated",
        "rewrite_text": "This work focuses on the investigation of photon wave theory through the lens of position eigenvectors, defined as solutions to the Schrödinger equation for photons of varying energy wavelengths. The position eigenvector concept facilitates the characterization of a single photon's state using its position probability distribution function (PDF). It also allows us to introduce the notion of quantum paths, which describe the temporal evolution of this PDF. We demonstrate that quantum trajectories originating from different initial states can be transformed into one another through unitary transformations. Our findings may be leveraged to explore various phenomena related to the transmission of light in dispersive media. Furthermore, we outline how our approach can be applied to understand nonclassical effects linked to the emission of entangled photon pairs. DOI: 10.1088/1742-6596/aa5e20. \n\nI. INTRODUCTORY REMARKS \n\nIn recent years, there has been a growing interest in developing new methods to investigate the properties of light fields based on quantum optics principles. One such approach involves the introduction of position eigenvectors, which play a significant role in defining the state of a single-photon field. Utilizing position eigenvectors necessitates not only an understanding of the spatial configuration of the electromagnetic field but also an analysis of the temporal characteristics of the system under study. This offers expansive possibilities for applying the proposed method to various physical processes that occur during the propagation of light through dispersive media. Moreover, incorporating position eigenvectors into the study of light fields opens avenues to elucidate certain nonclassical phenomena.",
        "ori-fast-z-score": 2.6293856820079102,
        "water-fast-z-score": 8.227432617895719,
        "rewrite-fast-z-score": 0.6527533657682196
    },
    {
        "original_text": "We study the possibility that there are two different lifetimes for neutral B mesons, one corresponding to the standard model and another to new physics beyond it.  We find that if the decay widths into final states with charm quarks differ by more than about 10% between these two types of B mesons then this can be observed at future experiments such as LHCb or Belle II. If we assume that the ratio of branching fractions is equal to 1 (as predicted within the Standard Model) but allow the total decay widths to vary independently, then we show how the experimental data on the time dependent CP asymmetry parameters SCP and ACP can be used to determine whether the difference in decay widths is due to new physics effects or not. Finally, we discuss possible extensions of our analysis which could lead to further constraints on the allowed parameter space. The results presented here will also have implications for other measurements performed at hadron colliders involving heavy flavour particles.",
        "watermark_text": "We research the prospect that there are two different lifetimes for neutral B mesons , one corresponding to the standard description and another to new science beyond it . We see that if the decay widths into initial states with charm quarks vary by more than about 10 % between these two kind of B mesons then this can be observed at current experiments such as LHCb or Belle II .If we suppose that the proportion of branching fractions is equal to 1 ( as predicted within the Standard Model ) but allow the total degradation widths to vary independently , then we explain how the theoretical data on the period dependent CP asymmetry characteristics SCP and ACP can be used to predict whether the difference in decay widths is due to novel physics effects or not . Finally , we explain possible extensions of our analysis which potentially contribute to further limitation on the allowed parameter area .The results presented here will also have consequences for other tests accomplished at hadron colliders regarding heavy flavour atoms .",
        "rewrite_text": "We investigate the possibility that neutral B mesons have two distinct lifetimes: one that aligns with the standard model and another that may indicate new physics. Our analysis suggests that if the decay widths into initial states with charm quarks differ by more than approximately 10% between these two types of B mesons, such disparities could be detected in ongoing experiments like LHCb or Belle II. Assuming the branching fraction ratios remain equal to 1, as predicted by the Standard Model, we allow for the total decay widths to vary independently. We then discuss how the theoretical data on time-dependent CP asymmetries, SCP and ACP, can help determine if any differences in decay widths are attributable to novel physics. Lastly, we outline potential extensions of our analysis that could further constrain the allowed parameter space. The findings presented here will also have implications for other experiments conducted at hadron colliders that involve heavy flavor particles.",
        "ori-fast-z-score": -2.032002032003048,
        "water-fast-z-score": 5.505585837114527,
        "rewrite-fast-z-score": 1.0
    },
    {
        "original_text": "We report the discovery and characterization of 33 new nearby white dwarf systems, including eight with trigonometric parallaxes measured by Gaia Data Release 2 (DR2). The sample includes six previously known binaries that were not included in DR2 because they are too faint for Gaia to resolve their components. We also present an analysis of the mass distribution of these newly discovered white dwarfs based on their photometric distances. This is the first time such a study has been performed using Gaia data alone. Our results show good agreement between our observed mass function and theoretical predictions. These findings demonstrate how Gaia can be used as a powerful tool to explore the local stellar population. Keywords: White dwarf - Galaxy - Parallax - Mass function - Gaia - Photometry - Binaries - Trigonometry - Distance scale - Astrometry - Stellar evolution - Galactic structure - Nearby stars",
        "watermark_text": "We report the discovery and identification of 33 new nearby white dwarf systems , including eight with trigonometric parallaxes measured by Gaia Data Release 2 ( DR2 ) . The sample comprises six formerly identified binaries that were not added in DR2 because they are too faint for Gaia to identify their components .We additionally offer an assessment of the mass distribution of these newly discovered white dwarfs based on their photometric ranges . This is the first time such a survey has been performed using Gaia data alone .Our results show good agreement between our measured mass behavior and theoretical estimates . These studies demonstrate how Gaia can be used as a powerful tool to examine the local stars community .Keywords : White dwarf - Galaxy - Parallax - Mass function - Gaia - Photometry - Binaries - Trigonometry - Distance scale - Astrometry - Stellar evolution - Galactic structure - Nearby stars",
        "rewrite_text": "We present the discovery and identification of 33 new nearby white dwarf systems, including eight with trigonometric parallaxes obtained from Gaia Data Release 2 (DR2). This sample includes six previously known binaries that were not included in DR2, as they are too faint for Gaia to resolve their components. Additionally, we provide an analysis of the mass distribution of these newly identified white dwarfs based on their photometric data. This marks the first survey conducted using only Gaia data. Our findings indicate a strong correlation between the mass distribution we measured and theoretical predictions. These investigations highlight Gaia's potential as a powerful tool for studying the local stellar community. \n\nKeywords: White dwarf, Galaxy, Parallax, Mass function, Gaia, Photometry, Binaries, Trigonometry, Distance scale, Astrometry, Stellar evolution, Galactic structure, Nearby stars.",
        "ori-fast-z-score": 1.8073922282301278,
        "water-fast-z-score": 6.454972243679028,
        "rewrite-fast-z-score": 1.4569855927715483
    },
    {
        "original_text": "We report on optical spectroscopy and multicolor photometry of GRB 040924, an intermediate-duration (T90 = 5 s) event detected by Swift/BAT at 07:55 UT on 24 September 2004. The prompt emission was followed by a bright X-ray flare peaking about 1 hour later than the main pulse. We find that the spectrum is well fitted with a power law plus blackbody model in the range 3000-9000 Å . The best-fit parameters are  _  = -1.1 ± 0.2 , TBB = 6200 +1800 -900 K, and EBB = 2.5 +1.0 -0.7 keV for the power-law index,  temperature, and normalization of the blackbody component respectively.  These values are consistent with those observed in other short-hard GRBs. In addition to this thermal component, we detect strong Fe II absorption lines blueshifted by ~10,000 km/s relative to their rest wavelengths. This suggests that the progenitor system may be similar to that inferred for short-hard GRBs such as GRB 050509b.",
        "watermark_text": "We report on optical spectroscopy and multicolor photometry of GRB 040924 , an intermediate - duration ( T90 = 5 s ) event detected by Swift / BAT at 07 : 55 UT on 24 September 2004 . The prompt emission was followed by a bright X - ray flare peaking about 1 hour later than the main pulse .We see that the spectrum is well fitted with a power law plus blackbody model in the range 3000 - 9000 Å . The best - fitting factors are _ = - 1 . 1 ± 0 . 2 , TBB = 6200 + 1800 - 900 K , and EBB = 2 . 5 + 1 . 0 - 0 . 7 keV for the power - law index , temperature , and normalization of the blackbody element respectively .These quantities are compatible with those observed in other short - hard GRBs . In addition to this heat element , we perceive strong Fe II spectral lines blueshifted by ~ 10 , 000 km / s relative to their rest wavelengths .This implies that the progenitor system might be similar to that inferred for short - hard GRBs such as GRB 050509b .",
        "rewrite_text": "We present our findings on the optical spectroscopy and multicolor photometry of GRB 040924, an intermediate-duration event (T90 = 5 s) detected by Swift/BAT at 07:55 UT on September 24, 2004. The prompt emission was followed by a notable X-ray flare that peaked approximately one hour after the main pulse. Our analysis indicates that the spectrum is well represented by a model consisting of a power law and a blackbody component in the wavelength range of 3000 to 9000 Å. The optimal fitting parameters are α = -1.1 ± 0.2, TBB = 6200 +1800 -900 K, and EBB = 2.5 +1.0 -0.7 keV for the power-law index, temperature, and normalization of the blackbody component, respectively. These values are consistent with those observed in other short-hard GRBs. Additionally, we detect strong Fe II spectral lines that are blueshifted by approximately 10,000 km/s from their rest wavelengths. This suggests that the progenitor system may be similar to those associated with short-hard GRBs, such as GRB 050509b.",
        "ori-fast-z-score": 1.8708286933869707,
        "water-fast-z-score": 5.879747322073337,
        "rewrite-fast-z-score": 1.4084056792618558
    },
    {
        "original_text": "We study the linear stability properties of coronal beams in the presence of background plasma and magnetic field fluctuations, using a multi-fluid model for ions and electrons. We find that the growth rates are strongly dependent on the angle between the wavevector k and the mean magnetic field B 0 . In particular, we show that there is an instability at oblique angles with respect to B 0 , which has been previously overlooked by previous studies based on single-fluid models. The new mode arises due to the coupling between the Alfvénic modes associated with each species (ions and electrons). This mode can be excited even when the electron temperature anisotropy T e? /T ez < 1, where ? denotes directions perpendicular to B 0 .\nThe results presented here may have important implications for understanding the origin of solar radio bursts observed during solar flares. Introduction: Coronal mass ejections (CMEs) are large-scale expulsions of magnetized plasma from the Sun s corona into interplanetary space. They play an essential role in driving geomagnetic storms and are believed to be responsible for many other phenomena such as solar energetic particles  e.g., Reames et al. (1998) , Kahler & Ragot (2007)  , solar radio bursts  e.g., Aschwanden (2004)  , and white-light flares  e.g., Benz (2008)  . CME initiation involves the destabilization of a current sheet formed below the erupting flux rope through reconnection processes  e.g., Forbes & Priest (1995) ; Lin & Forbes (2000); Aulanier et al. (2010)  . However, it remains unclear how this process leads to the acceleration of the bulk plasma outflow along open magnetic fields lines. Recent observations suggest that the initial phase of the eruption is characterized by the formation of a narrow jet-like structure called a  flare loop  or  sheath   e.g., Liu et al. (2009a Liu et al. ( , 2009b ; Cheng et al. (2011); Jiang et al. (2012",
        "watermark_text": "We research the linear stability properties of coronal beams in the presence of background plasma and magnetic force fluctuations , using a multi - fluid model for ions and electrons . We see that the development rates are strongly dependent on the angle between the wavevector k and the mean magnetic force B 0 .In particular , we prove that there is an instability at oblique directions with regard to B 0 , which has been previously overlooked by earlier studies relying on single - fluid models . The new mode occurs due to the interaction between the Alfvénic configurations involved with each species ( atoms and electrons ) .This mode can be excited even when the electron thermal anisotropy T e ? / T ez < 1 , where ?denotes directions perpendicular to B 0 . The results presented here possibly have important implications for studying the origin of solar radio flashes seen during thermal flares .Introduction : Coronal mass ejections ( CMEs ) are big - scale expulsions of magnetized plasma from the Sun s corona into interplanetary space . They play an essential part in causing geomagnetic winds and are considered to be responsible for numerous other processes such as solar energetic particles e . g . , Reames et al .( 1998 ) , Kahler & Ragot ( 2007 ) , sun wireless flare e . g . , Aschwanden ( 2004 ) , and white - light flares e . g . , Benz ( 2008 ) . CME initiation consists the destabilization of a current sheet formed below the erupting flux rope through reconnection pathways e . g . , Forbes & Priest ( 1995 ) ; Lin & Forbes ( 2000 ) ; Aulanier et al .( 2010 ) . However , it remains unsure how this process results to the acceleration of the bulk plasma outflow along open magnetic fields lines .Recent measurements suggest that the first phase of the volcano is characterized by the formation of a thin jet - like structure named a flare loop or sheath e . g . , Liu et al . ( 2009a Liu et al .( , 2009b ; Cheng et al . ( 2011 ) ; Jiang et al .(2012",
        "rewrite_text": "We investigate the linear stability characteristics of coronal beams amidst fluctuations in background plasma and magnetic forces, utilizing a multi-fluid model for both ions and electrons. Our findings reveal that the growth rates are significantly influenced by the angle between the wavevector \\( k \\) and the mean magnetic field \\( B_0 \\). Notably, we demonstrate the existence of an instability in oblique directions relative to \\( B_0 \\), a phenomenon that previous investigations using single-fluid models have overlooked. This new mode arises from the interaction among the Alfvénic configurations related to each species (including atoms and electrons). Furthermore, this mode can be excited even when the electron thermal anisotropy \\( T_e^\\perp / T_{ez} < 1 \\), where \\( \\perp \\) indicates directions perpendicular to \\( B_0 \\). The results we present may have significant implications for understanding the origins of solar radio emissions observed during thermal flares.\n\n**Introduction**: Coronal mass ejections (CMEs) are large-scale expulsions of magnetized plasma from the Sun's corona into interplanetary space. They play a crucial role in generating geomagnetic winds and are believed to contribute to various phenomena, such as solar energetic particles (Reames et al., 1998; Kahler & Ragot, 2007), solar flares (Aschwanden, 2004), and white-light flares (Benz, 2008). The initiation of CMEs involves destabilizing a current sheet formed beneath the erupting flux rope through reconnection processes (Forbes & Priest, 1995; Lin & Forbes, 2000; Aulanier et al., 2010). However, the mechanism by which this process accelerates the bulk plasma outflow along open magnetic field lines remains unclear. Recent observations indicate that the initial phase of this event is characterized by the development of a slender, jet-like structure known as a flare loop or sheath (Liu et al., 2009a; Liu et al., 2009b; Cheng et al., 2011; Jiang et al., 2012).",
        "ori-fast-z-score": -1.007017629956027,
        "water-fast-z-score": 5.202924421439472,
        "rewrite-fast-z-score": 0.8703882797784892
    },
    {
        "original_text": "We develop an agent-based model to study the evolution of social complexity in human societies, focusing on how heterogeneity among agents can lead to increasing returns that drive economic growth and technological innovation. We find that heterogeneous populations are more likely than homogeneous ones to evolve complex economies with specialized production units, markets for goods and services, and division of labor between producers. The presence of these features leads to higher levels of productivity and population density, which further increase the benefits associated with specialization and trade. Our results suggest that the emergence of such socioeconomic structures may have been one important factor driving the evolution of human society over the past few million years. In this work we present a computational model aimed at studying the evolutionary dynamics underlying the development of socio-economic systems. More specifically, our goal is to understand what factors might be responsible for the appearance of increasingly complex forms of organization observed across many different cultures throughout history. To address this question, we focus on the role played by two key ingredients commonly found in real-world systems: (i) diversity within the population; and (ii) positive feedbacks leading to increasing returns.",
        "watermark_text": "We develop an agent - based model to study the evolution of social complexity in human communities , concentrating on how heterogeneity among agents can lead to increasing returns that drive economic growth and technological innovation . We see that heterogeneous populations are more likely than homogeneous ones to evolve complex economies with specialized production divisions , prices for goods and services , and divide of labor between firms .The appearance of these characteristics leads to higher levels of efficiency and population density , which further raise the advantages associated with specialization and commerce . Our results show that the emergence of such socioeconomic structures could have been one key force driving the evolution of human civilization over the previous few million years .In this research we present a computational model aiming at studying the evolutionary processes governing the development of socio - economic systems . More specifically , our goal is to consider what factors might be responsible for the appearance of increasingly intricate forms of organization observed across many various societies throughout history .To address this question , we focus on the part played by two principal ingredients commonly found in real - global networks : ( i ) integration within the population ; and ( ii ) positive feedbacks resulting to increasing returns .",
        "rewrite_text": "We create an agent-based model to investigate the evolution of social complexity in human communities, emphasizing how diversity among agents can trigger increasing returns that foster economic growth and technological innovation. Our findings indicate that heterogeneous populations are more likely to develop complex economies characterized by specialized production divisions, pricing for goods and services, and a division of labor among firms, compared to homogeneous populations. The emergence of these traits enhances efficiency and population density, further amplifying the benefits of specialization and trade. Our results suggest that the development of such socioeconomic structures may have been a significant factor in the evolution of human civilization over the past few million years. In this research, we introduce a computational model designed to explore the evolutionary processes that underpin the formation of socio-economic systems. More specifically, we aim to identify the factors responsible for the emergence of increasingly complex organizational forms observed across various societies throughout history. To tackle this question, we focus on the roles of two key elements frequently found in real-world networks: (i) integration within the population and (ii) positive feedback mechanisms that lead to increasing returns.",
        "ori-fast-z-score": 1.9069251784911847,
        "water-fast-z-score": 8.390470785361213,
        "rewrite-fast-z-score": 2.5253432421288866
    },
    {
        "original_text": "The structure and dynamics of lipid membranes are important for many biological processes, such as cell division or protein transport across the membrane. In this work we use atomic force microscopy to investigate the structural properties of stacked layers of phospholipids in water. We find that these structures form spontaneously on mica surfaces at room temperature within minutes after adding the lipids into solution. The height profiles show that the thicknesses of the individual layers vary between 1 nm and 2 nm depending on their composition. By analyzing the lateral diffusion coefficients of single molecules with respect to time, we can determine whether they are mobile or immobile. Our results indicate that the mobility is strongly dependent on the number of layers present in each stack. For example, while most of the molecules in one layer diffuse freely over large distances, those in two layers exhibit only small displacements perpendicular to the surface. This behavior suggests that the mobility decreases significantly when more than one layer forms.",
        "watermark_text": "The structure and dynamics of lipid membranes are important for numerous biological events , such as cell division or protein transport across the membrane . In this research we utilize atomic force microscopy to examine the structural structure of piled sheets of phospholipids in water .We see that these structures create spontaneously on mica surfaces at room temperature within moments after addition the lipids into solution . The height profiles indicate that the thicknesses of the individual layers varies between 1 nm and 2 nm depending on their composition .By analyzing the longitudinal diffusion coefficients of single particles with regard to time , we can determine whether they are portable or immobile . Our results show that the mobility is strongly dependent on the quantity of elements contained in each stack .For instance , while most of the molecules in one layer diffuse widely over large distances , those in two sheets experience only tiny displacements parallel to the surface . This phenomenon suggests that the mobility decreases dramatically when more than one surface exists .",
        "rewrite_text": "The structure and dynamics of lipid membranes play a crucial role in various biological processes, including cell division and protein transport across membranes. In this study, we employ atomic force microscopy to investigate the structural characteristics of stacked phospholipid sheets in water. Our observations reveal that these structures spontaneously form on mica surfaces at room temperature shortly after the lipids are added to the solution. Height profile analysis indicates that the thickness of individual layers ranges from 1 nm to 2 nm, depending on their composition. By examining the longitudinal diffusion coefficients of individual particles over time, we can assess their mobility—whether they are mobile or immobile. Our findings demonstrate that mobility is significantly influenced by the number of layers present in each stack. For example, while most molecules in a single layer can diffuse over large distances, those in double-layer sheets exhibit only minimal movement parallel to the surface. This behavior suggests that mobility decreases markedly when multiple layers are present.",
        "ori-fast-z-score": -0.7977240352174656,
        "water-fast-z-score": 5.8119893994415355,
        "rewrite-fast-z-score": -0.4364357804719848
    },
    {
        "original_text": "We study the stability of spin-1/2 fermions confined to one dimension by an external potential and interacting via contact interactions, using the Bethe ansatz solution for the Lieb-Liniger model. We find that there is no instability at zero temperature when the chemical potential lies between two consecutive energy levels of the system. This result holds true even if we consider finite temperatures as well. In particular, this implies that the ground state remains stable against collapse into a single particle state (fermionization) or formation of bound states with more than 2 particles (bosonization). The results are also valid for higher spins. Our analysis can be extended to other models such as those describing cold atoms trapped inside optical lattices. Introduction:-In recent years, ultracold atomic systems have been used extensively to simulate various physical phenomena  1  . One-dimensional quantum gases provide particularly interesting examples because they allow us to explore many-body physics in regimes where analytical solutions cannot be obtained  2  .\nThe most common experimental setup consists of confining bosonic or fermionic atoms along one spatial direction within a harmonic trap  3  , which leads to the emergence of quasi-one dimensional behavior  4  . However, it has recently become possible to confine these atoms tightly enough so that their motion becomes truly onedimensional  5  . For example, experiments performed with Bose-Einstein condensates  6  and degenerate Fermi gases  7, 8  show that confinement in a narrow channel gives rise to new phases of matter  9  . These include superfluidity  10  , supersolids  11  , Luttinger liquids  12  , Tonks-Girardeau gas  13  , and Mott insulators  14  . It would therefore be very useful to develop theoretical tools capable of predicting the properties of these novel phases  15  .\nOne of the main challenges associated with studying strongly correlated quantum systems is determining whether certain configurations are energetically favorable  16  . If the answer turns out to be yes, then we say that the configuration is metastable  17  . On the other hand, if the answer is no, then the configuration is unstable  18  . Instabilities may occur due to spontaneous symmetry",
        "watermark_text": "We explore the stability of spin - 1 / 2 fermions localized to one dimension by an external potential and evolving via contact interactions , using the Bethe ansatz solution for the Lieb - Liniger model . We see that there is no instability at zero temperature when the chemical potential sits between two consecutive power concentrations of the system .This result holds true even if we treat finite temperatures as well . In particular , this implies that the ground state remains stable against failure into a single molecule state ( fermionization ) or formation of bound states with more than 2 particles ( bosonization ) .The results are also useful for greater spins . Our study can be generalized to other models such as those describing cold molecules trapped inside optical lattices .Introduction : - In past decades , ultracold nuclear systems have been used heavily to simulate numerous physical phenomena 1 . One - dimensional quantum compounds provide particularly exciting examples because they allow us to examine multiple - bodies physics in regimes where mathematical solutions unable be obtained 2 .The most common experimental setup consists of confining bosonic or fermionic atoms along one spatial path within a harmonic cage 3 , which results to the emergence of quasi - one dimensional dynamics 4 . However , it has recently become able to confine these ions tightly sufficiently so that their motion makes truly onedimensional 5 .For instance , experiments conducted with Bose - Einstein condensates 6 and degenerate Fermi atoms 7 , 8 show that confinement in a thin channel gives rise to new phases of matter 9 . These include superfluidity 10 , supersolids 11 , Luttinger liquids 12 , Tonks - Girardeau liquid 13 , and Mott insulators 14 .It would therefore be very useful to develop conceptual tools capable of predicting the properties of these novel phases 15 . One of the main problems involved with studying strongly interacting quantum systems is establishing whether particular configurations are energetically favorable 16 .If the response turns out to be yes , then we tell that the configuration is metastable 17 . On the other hand , if the response is no , then the configuration is unstable 18 .Instabilities could occur due to spontaneous symmetry",
        "rewrite_text": "We investigate the stability of spin-1/2 fermions confined to one dimension by an external potential and evolving through contact interactions, utilizing the Bethe ansatz solution of the Lieb-Liniger model. Our findings indicate that there is no instability at absolute zero when the chemical potential lies between two consecutive power concentrations of the system; this conclusion holds even at finite temperatures. Specifically, this suggests that the ground state remains robust against collapse into a single-molecule state (fermionization) or the formation of bound states with more than two particles (bosonization). Furthermore, these results are applicable to systems with higher spins. Our analysis can be extended to other models, such as those describing cold molecules trapped in optical lattices. \n\nIn recent decades, ultracold atomic systems have been extensively employed to simulate a variety of physical phenomena. One-dimensional quantum systems are particularly intriguing, as they allow exploration of many-body physics in regimes where analytical solutions are infeasible. Typically, experiments involve confining bosonic or fermionic atoms along a single spatial path within a harmonic trap, resulting in the emergence of quasi-one-dimensional dynamics. Advances in experimental techniques have now enabled the precise confinement of ions to achieve true one-dimensional motion. For example, studies involving Bose-Einstein condensates and degenerate Fermi gases have demonstrated that confinement within a narrow channel can lead to the emergence of novel phases of matter, including superfluidity, supersolids, Luttinger liquids, Tonks-Girardeau gas, and Mott insulators. Consequently, it is vital to develop conceptual frameworks that can predict the properties of these emergent phases. A key challenge in the study of strongly interacting quantum systems is determining whether specific configurations are energetically favorable. If the answer is affirmative, the configuration is considered metastable; if negative, it is deemed unstable. Such instabilities may arise from spontaneous symmetry breaking.",
        "ori-fast-z-score": -0.636445827340584,
        "water-fast-z-score": 6.899548795747854,
        "rewrite-fast-z-score": -0.49656353316142077
    },
    {
        "original_text": "We present Gemini GMOS-S spectroscopy for two young star clusters (ages ~10 Myr) in the interacting galaxy pair NGC 3256, which are located at projected distances of 1 kpc and 2 kpc from their respective nuclei. The spectra reveal that both clusters have similar ages but different metallicities; one is metal-rich with  Fe/H  = +0.2 dex while the other has solar metallicity. We find no evidence for multiple populations within either cluster. Using these data we derive masses of 5 x 10^4 M_sol and 7 x 10^3 M_sol respectively for each cluster. These values agree well with those derived using HST photometry. Both clusters show signs of youthful star-formation activity including blue supergiants and Wolf-Rayet stars. In addition to this ongoing star-formation activity, there appears to be an older population of red giant branch stars in the more massive cluster.",
        "watermark_text": "We present Gemini GMOS - S spectroscopy for two young galaxy regions ( ages ~ 10 Myr ) in the interacting galaxy pair NGC 3256 , which are situated at projected speeds of 1 kpc and 2 kpc from their respective nuclei . The spectra indicate that both clusters have related ages but different metallicities ; one is metal - rich with Fe / H = + 0 . 2 dex while the other has solar metallicity .We see no evidence for multiple colonies within either cluster . Using these information we derive masses of 5 x 10 ^ 4 M _ sol and 7 x 10 ^ 3 M _ sol respectively for each cluster .These values coincide well with those generated utilizing HST photometry . Both clusters show signs of young galaxy - formation activity including blue supergiants and Wolf - Rayet stars .In addition to this continued star - formation activity , there seems to be an larger growth of red giant line stars in the more massive cluster .",
        "rewrite_text": "We present Gemini GMOS-S spectroscopy for two young galaxy regions (approximately 10 Myr old) located in the interacting galaxy pair NGC 3256, which are positioned at projected distances of 1 kpc and 2 kpc from their respective nuclei. The spectra reveal that both clusters share similar ages but differ in metallicity; one is metal-rich with [Fe/H] = +0.2 dex, while the other has solar metallicity. No evidence of multiple colonies within either cluster has been observed. From this data, we derive masses of 5 x 10^4 M_sol and 7 x 10^3 M_sol for each cluster, respectively. These values are consistent with those obtained through HST photometry. Both clusters exhibit signs of ongoing star formation activity, including the presence of blue supergiants and Wolf-Rayet stars. Additionally, the more massive cluster shows indications of a significant increase in the population of red giant stars.",
        "ori-fast-z-score": 0.1259881576697424,
        "water-fast-z-score": 4.064004064006096,
        "rewrite-fast-z-score": 0.13018891098082389
    },
    {
        "original_text": "The use of triangular elements in the boundary element method (BEM) is discussed and compared with other methods, such as quadrilateral elements or mixed elements. The advantages are that they can be used to solve problems involving curved boundaries more accurately than quadrilateral elements while still being able to take advantage of fast matrix-vector multiplication techniques developed for rectangular matrices.  In addition, it has been shown how these elements may be combined with an iterative solution technique known as GMRES(m). This combination allows solutions which are nearly exact to be obtained without any loss of efficiency over conventional BEM approaches using quadrilateral elements. Finally, some numerical results are presented showing the accuracy of this approach on several test cases. Keywords: Boundary Element Method, Quadrilateral Elements, Mixed Elements, Iterative Solution Technique, GMRES(m), Triangular Elements. 1 Introduction The boundary element method (BEm)  1  , also called the integral equation method  2  , is one of the most powerful tools available today for solving partial differential equations numerically  3  . It involves discretizing the domain into small regions called elements where the unknown function is approximated by simple functions like polynomials  4  .\nIn recent years there have been many advances made in the development of efficient algorithms for applying the BE m to practical engineering problems  5  -  8  . However, despite all these developments, the application of the BE m to problems with complex geometries remains difficult because of difficulties associated with representing complicated shapes exactly  9  . For example, if we consider the problem of finding the potential distribution around a conducting body immersed in a uniform magnetic field then the surface of the conductor must be represented by a set of flat triangles whose vertices lie at points on its actual curved surface  10  .",
        "watermark_text": "The using of triangular modules in the boundary element method ( BEM ) is mentioned and compared with other methods , such as quadrilateral elements or mixed elements . The advantages are that they can be used to solve difficulties involving curved boundaries more accurately than quadrilateral elements while still being able to take exploit of quick vector - vector multiplication techniques established for square matrices .In addition , it has been shown how these elements may be merged with an iterative solution technique called as GMRES ( m ) . This pairing allows solutions which are nearly exact to be obtained without any loss of efficiency over traditional BEM approaches employing quadrilateral components .Finally , some numerical findings are presented showing the accuracy of this methodology on numerous test situations . Keywords : Boundary Element Method , Quadrilateral Elements , Mixed Elements , Iterative Solution Technique , GMRES ( m ) , Triangular Elements .1 Introduction The boundary element method ( BEm ) 1 , sometimes called the integral equation procedure 2 , is one of the most important skills available today for solving partial differential equations numerically 3 . It involves discretizing the domain into small zones called elements where the unknown function is approximated by simple functions like polynomials 4 .In recent years there have been many advances seen in the development of effective methods for applying the BE m to practical technical problems 5 - 8 . However , despite all these developments , the implementation of the BE m to problems with difficult geometries remains complicated because of troubles associated with drawing difficult shapes precisely 9 .For instance , if we treat the question of finding the potential distribution around a conducting body immersed in a uniform magnetic force then the surface of the conductor must be described by a setting of flattened triangles whose edges lie at points on its actual curved surface 10 .",
        "rewrite_text": "The use of triangular modules in the Boundary Element Method (BEM) is discussed and compared to other techniques, such as quadrilateral and mixed elements. One significant advantage of triangular elements is their ability to solve issues related to curved boundaries with greater precision than quadrilateral elements, while also taking advantage of efficient vector-vector multiplication techniques developed for square matrices. Additionally, the integration of these triangular elements with an iterative solution technique known as GMRES(m) is demonstrated. This combination facilitates the attainment of near-exact solutions without sacrificing efficiency compared to traditional BEM approaches that use quadrilateral elements. Finally, numerical results are presented to illustrate the accuracy of this methodology across various test cases. \n\n**Keywords:** Boundary Element Method, Quadrilateral Elements, Mixed Elements, Iterative Solution Technique, GMRES(m), Triangular Elements.\n\n**1 Introduction**  \nThe Boundary Element Method (BEM), also referred to as the integral equation approach, is one of the most significant tools available today for numerically solving partial differential equations. This method involves discretizing the domain into small regions called elements, where the unknown function is approximated using simple functions such as polynomials. In recent years, significant advancements have been made in developing effective methods for applying BEM to practical engineering challenges. However, implementing BEM for problems with complex geometries continues to be challenging due to difficulties in accurately representing intricate shapes. For instance, when addressing the problem of determining the potential distribution around a conducting body immersed in a uniform magnetic field, the conductor's surface must be represented by a set of flattened triangles whose edges coincide with points on its actual curved surface.",
        "ori-fast-z-score": 0.34299717028501764,
        "water-fast-z-score": 8.403430671982933,
        "rewrite-fast-z-score": 0.17677669529663687
    },
    {
        "original_text": "We present new near-infrared (NIR) polarimetric observations of the GG Tau system, which reveal that its circumstellar disk is highly structured and contains several bright regions with different polarization properties. The most prominent feature in our data set is an arc-like structure located at about 0.5 arcsec to the south-east of the central binary star. This region shows strong polarized emission up to 10% of the total intensity and has been previously identified as a reflection nebula by Weintraub et al. (1993) . We find that this feature can be explained by scattering off optically thin dust grains close to the midplane of the disk. In addition we detect two other bright features on either side of the central binary. These are also associated with high degrees of linear polarization but show no clear evidence for scattered light. Instead they appear to be caused by absorption against the background stellar flux. Finally, we identify three additional fainter structures in the southern part of the disk. All these features have similar polarization angles indicating that their origin may be related.",
        "watermark_text": "We present new near - infrared ( NIR ) polarimetric studies of the GG Tau component , which confirm that its circumstellar disk is heavily compressed and features several bright regions with various polarization properties . The most notable feature in our information pool is an arc - like structure located at about 0 . 5 arcsec to the south - eastward of the main binary star .This region shows intense polarized emission up to 10 % of the total intensity and has been previously described as a mirror nebula by Weintraub et al . ( 1993 ) .We see that this phenomenon can be described by scattering off optically thin dust grains next to the midplane of the disk . In addition we locate two other bright features on either front of the main binary .These are also associated with high levels of linear polarization but display no clear proof for dispersed light . Rather they appear to be caused by absorption against the background stellar flow .Finally , we identify three extra fainter objects in the southern portion of the disk . All these structures have parallel polarization angles indicating that their source may be connected .",
        "rewrite_text": "We present new near-infrared (NIR) polarimetric observations of the GG Tau component, which confirm that its circumstellar disk is significantly compressed and contains several bright regions with varying polarization characteristics. A prominent feature in our data is an arc-like structure situated approximately 0.5 arcseconds to the southeast of the main binary star. This area exhibits strong polarized emission, reaching up to 10% of the total intensity, and has been previously referred to as a mirror nebula by Weintraub et al. (1993). Our findings suggest that this phenomenon is due to scattering off optically thin dust grains located near the midplane of the disk. Furthermore, we identify two additional bright features flanking the main binary, which are also associated with high levels of linear polarization but show no clear evidence of dispersed light. Instead, they appear to result from absorption against the background stellar flow. Lastly, we discover three fainter objects in the southern region of the disk. All these structures exhibit parallel polarization angles, suggesting a possible connection among their sources.",
        "ori-fast-z-score": -0.5488212999484517,
        "water-fast-z-score": 6.846754616640485,
        "rewrite-fast-z-score": 2.7441064997422586
    },
    {
        "original_text": "The concept of zero point energy is introduced in this article, which describes how it can be used to explain some aspects of the big bang theory. The author also discusses the possibility that dark matter may have been created by such an effect. Finally he considers whether or not there are any other physical effects associated with zero point energy. In particular, he suggests that gravitational waves could possibly be generated by such processes. This article was originally published on ArXiv.org as part of the author s PhD thesis at Imperial College London. It has since been updated for publication here. Zero point energy (ZPE) is defined as the minimum amount of energy required to create particles out of nothing. Although ZPE cannot actually exist because it violates the laws of physics, it does provide useful insight into certain phenomena observed within our universe. For example, if we consider the expansion of space-time during the early stages of the universe s existence, then it seems reasonable to assume that the volume of space increased exponentially over time due to the rapid release of ZPE. If so, then the total mass-energy density would decrease rapidly until all available ZPE had been released. At this stage, the universe would consist solely of vacuum fluctuations, i.e., virtual particles and antiparticles existing simultaneously but never interacting with each other.",
        "watermark_text": "The concept of zero level energy is included in this article , which explains how it can be used to explain some elements of the big bang theory . The author also explains the suggestion that dark matter may have been created by such an effect .Finally he considers whether or not there are any other material effects involved with zero point energy . In particular , he argues that gravity signals could possibly be formed by such interactions .This page was originally published on ArXiv . org as part of the writer s PhD thesis at Imperial College London . It has since been amended for published here .Zero point energy ( ZPE ) is given as the zero amount of power required to create particles out of nothing . Although ZPE never really occur because it violates the rules of science , it does provide useful insight into particular phenomena observed within our universe .For instance , if we study the expansion of space - time during the early stages of the universe s existence , then it appears logical to assume that the volume of space expanded exponentially over time due to the quick release of ZPE . If so , then the total mass - energy density would decrease rapidly until all available ZPE had been released .At this phase , the universe might consist solely of vacuum fluctuations , i . e . , virtual objects and antiparticles emerging concurrently but never interacting with each other .",
        "rewrite_text": "This article discusses the concept of zero-point energy and its potential implications for the big bang theory. The author proposes that dark matter could have originated from this phenomenon and examines whether other material effects may be linked to zero-point energy. Specifically, he theorizes that gravity signals might emerge from such interactions. Originally published on ArXiv.org as part of the author’s PhD thesis at Imperial College London, this page has since been revised for publication here. Zero-point energy (ZPE) refers to the theoretical minimum energy required to create particles from nothing. While ZPE cannot actually occur, as it contradicts established scientific principles, it offers valuable insights into certain observations in our universe. For example, analyzing the early expansion of space-time suggests that the universe expanded exponentially over time due to a rapid release of ZPE. Consequently, the total mass-energy density would have decreased significantly until all available ZPE was utilized. At this stage, the universe might have been characterized by vacuum fluctuations, where virtual particles and antiparticles appear simultaneously but do not interact with each other.",
        "ori-fast-z-score": 0.6767155423319645,
        "water-fast-z-score": 7.505553499465135,
        "rewrite-fast-z-score": 1.970208219987808
    },
    {
        "original_text": "Anhedonia is an important symptom of depression and schizophrenia, but its underlying neurobiological mechanisms are still poorly understood. In this study we investigated whether exposure to chronic social defeat (CSD) can induce anhedonic-like behavior in male C57BL/6J mice. We found that CSD-exposed animals exhibited decreased preference for sucrose solution compared with control group. Moreover, CSD-exposed mice showed increased immobility time during forced swimming test as well as reduced locomotor activity in open field test. Finally, we observed significant decrease in dopamine release in nucleus accumbens shell after acute administration of amphetamine in defeated mice. These results suggest that CSD may be used as animal model of anhedonia. Anhedonia is one of the most prominent symptoms of major depressive disorder (MDD), which affects about 20% of patients worldwide 1 . It refers to loss or reduction of pleasure experienced by individuals 2 , resulting in inability to experience joyful events 3 .\nIn addition to MDD, anhedonia has been also described in other psychiatric disorders such as schizophrenia 4 , bipolar disorder 5 , obsessive-compulsive disorder 6 , eating disorders 7 , substance abuse 8 , and borderline personality disorder 9 . However, despite being considered a core feature of several mental illnesses 10 , there is no consensus regarding how it should be assessed 11 . The lack of standardized assessment methods makes it difficult to compare findings across studies 12 . Therefore, new approaches have emerged aiming at improving the diagnosis and treatment of anhedonia 13 .\nThe main challenge associated with studying anhedonia lies in the fact that it is not possible to measure directly 14 . Instead, researchers use indirect measures based on behavioral tests 15 . For example, the sucrose consumption test 16 , the forced swim test 17 , and the open field test 18 are commonly employed to assess hedonia 19 . Although these tests provide valuable information related to anhedonia 20 , they do not allow us to understand the neural circuits involved 21 . Thus, further investigations using more sophisticated techniques are needed 22 .",
        "watermark_text": "Anhedonia is an important symptom of depression and schizophrenia , but its underlying neurobiological processes are still weakly understood . In this study we investigated whether exposure to chronic social loss ( CSD ) can induce anhedonic - like behavior in male C57BL / 6J mouse .We showed that CSD - exposed animals exhibited reduced choice for sucrose solution compared with control group . Moreover , CSD - exposed mice showed improved immobility time during forced swimming experiment as also as reduced locomotor activity in open ground study .Finally , we demonstrated substantial decrease in dopamine release in nucleus accumbens shell after acute administration of amphetamine in defeated mice . These data suggest that CSD may be used as animal model of anhedonia .Anhedonia is one of the most notable effects of large depressive syndrome ( MDD ) , which occurs about 20 % of people worldwide 1 . It refers to lack or decrease of pleasure received by individuals 2 , leading in inability to experience joyful events 3 .In addition to MDD , anhedonia has been also identified in other psychiatric illness such as schizophrenia 4 , bipolar disorder 5 , obsessive - compulsive disease 6 , drink problems 7 , substance abuse 8 , and borderline personality disorder 9 . However , despite being considered a core feature of several mental illnesses 10 , there is no agreed regarding how it should be assessed 11 .The absence of centralized assessment methods makes it difficult to relate findings across studies 12 . Therefore , new approaches have arose aiming at enhancing the diagnosis and therapy of anhedonia 13 .The main challenge associated with studying anhedonia lies in the fact that it is not possible to measure directly 14 . Rather , researchers using indirect indicators focused on behavioral tests 15 .For instance , the sucrose intake test 16 , the forced swim test 17 , and the open field test 18 are often employed to examine hedonia 19 . Although these tests provide valuable info related to anhedonia 20 , they do not enable us to comprehend the neural systems implicated 21 .Thus, further investigations using more sophisticated techniques are needed 22 .",
        "rewrite_text": "Anhedonia is a significant symptom of both depression and schizophrenia, yet its neurobiological mechanisms remain poorly understood. In this study, we explored whether chronic social defeat (CSD) could trigger anhedonic-like behavior in male C57BL/6J mice. Our findings indicate that mice subjected to CSD chose less sucrose solution compared to the control group. Additionally, CSD-exposed mice showed increased immobility during the forced swim test and reduced locomotor activity in the open field test. Importantly, we found a significant decrease in dopamine release in the nucleus accumbens shell following acute amphetamine administration in the defeated mice. These results suggest that CSD may serve as an animal model for anhedonia. \n\nAnhedonia is a prominent symptom of major depressive disorder (MDD), which affects approximately 20% of the global population. It is characterized by a diminished ability to experience pleasure, resulting in an inability to enjoy positive events. Beyond MDD, anhedonia is also observed in various other psychiatric conditions, including schizophrenia, bipolar disorder, obsessive-compulsive disorder, substance abuse, and borderline personality disorder. Despite its prominence in multiple mental illnesses, there is currently no consensus on how to effectively assess anhedonia. This lack of standardized assessment methods hampers the ability to compare findings across different studies. Consequently, new strategies are being developed to improve the diagnosis and treatment of anhedonia. The primary challenge in studying anhedonia lies in the fact that it cannot be measured directly. Instead, researchers often rely on indirect behavioral assessments. Common tests include the sucrose intake test, forced swim test, and open field test, which provide valuable insights into anhedonia but do not fully elucidate the neural systems involved. Therefore, further research utilizing more advanced techniques is necessary.",
        "ori-fast-z-score": 0.8778955729143844,
        "water-fast-z-score": 9.177999171377655,
        "rewrite-fast-z-score": 1.0722219284950194
    },
    {
        "original_text": "We present an analysis of photometric and spectroscopic data for SN 2003du, which was discovered on February 28th by R. Puckett at Mt. Wilson Observatory (Puckett et al., 2004) . The supernova is located in NGC 3190, a spiral galaxy with Hubble type Sb/Scd. It has been classified as a normal Type Ia supernova based on its light curve shape and spectral features. \n \n We find that the peak absolute magnitude of SN 2003du is -19.6 ± 0.1 mag, corresponding to a distance modulus of 34.7 ± 0.2 mag. This places it at a distance of about 50 Mpc (z = 0.0185). Using this distance we derive a total ejecta mass of 1.4 ± 0.3M⊙ and 56Ni yield of 0.09 ± 0.02M⊙ . \n \n \n \n In addition to our own observations, we have used archival data obtained through the CfA Supernova Archive, the SUSPECT archive maintained by the University of Hawaii, and the Wise Observatory archive.",
        "watermark_text": "We present an assessment of photometric and spectroscopic data for SN 2003du , which was discovered on February 28th by R . Puckett at Mt . Wilson Observatory ( Puckett et al . , 2004 ) .The supernova is situated in NGC 3190 , a spiral galaxy with Hubble class Sb / Scd . It has been classified as a normal Type Ia supernova based on its light curve size and spectral features .We determine that the maximum absolute magnitude of SN 2003du is - 19 . 6 ± 0 . 1 mag , equivalent to a distance modulus of 34 . 7 ± 0 . 2 mag . This places it at a distance of about 50 Mpc ( z = 0 . 0185 ) .Using this distance we derive a total ejecta mass of 1 . 4 ± 0 . [UNK] and 56Ni yield of 0 . 09 ± 0 . [UNK] . In addition to our own observations , we have utilized archival data acquired through the CfA Supernova Archive , the SUSPECT archive operated by the University of Hawaii , and the Wise Observatory collection .",
        "rewrite_text": "We provide an evaluation of the photometric and spectroscopic data for SN 2003du, which was discovered on February 28 by R. Puckett at Mt. Wilson Observatory (Puckett et al., 2004). This supernova is located in NGC 3190, a spiral galaxy classified as Hubble type Sb/Scd. It has been identified as a typical Type Ia supernova based on its light curve characteristics and spectral features. Our analysis reveals that the maximum absolute magnitude of SN 2003du is -19.6 ± 0.1 mag, corresponding to a distance modulus of 34.7 ± 0.2 mag, placing it approximately 50 Mpc away (z = 0.0185). Utilizing this distance, we estimate a total ejecta mass of 1.4 ± 0. [UNK] and a 56Ni yield of 0.09 ± 0. [UNK]. In addition to our own observations, we have incorporated archival data from the CfA Supernova Archive, the SUSPECT archive maintained by the University of Hawaii, and the collection from Wise Observatory.",
        "ori-fast-z-score": -0.7453559924999299,
        "water-fast-z-score": 2.1105794120443453,
        "rewrite-fast-z-score": 0.4375949744936837
    },
    {
        "original_text": "We present near-infrared (NIR) imaging and spectroscopy of star formation activity in the Bok globule CB 54, which is located at a distance of about 1 kpc toward the Galactic anti-center direction. We found that there are two young stellar objects (YSOs), one Class I protostar with an infrared luminosity of ~10 Lsun and another embedded YSO candidate with a bolometric temperature of ~1000 K. The former object shows bipolar outflows traced by Herbig-Haro knots and molecular line wings. In addition to these two sources, we detected several other point-like NIR sources within the central region of CB 54. These may be low-mass pre-main-sequence stars or background galaxies. Our results suggest that this cloud core has experienced active star formation over its lifetime. \n \n Keywords: Star formation; Near-infrared spectroscopy; Bipolar outflow; Young stellar object",
        "watermark_text": "We present near - infrared ( NIR ) imaging and spectroscopy of galaxy formation activity in the Bok globule CB 54 , which is situated at a distance of about 1 kpc toward the Galactic anti - center position . We showed that there are two young stellar bodies ( YSOs ) , one Class I protostar with an infrared luminosity of ~ 10 Lsun and another embedded YSO candidate with a bolometric temperature of ~ 1000 K . The former object displays bipolar outflows traced by Herbig - Haro knots and molecular line wings .In addition to these two sources , we spotted various other point - like NIR components within the central region of CB 54 . These may be low - weight pre - principal - sequence stars or background galaxies .Our results show that this cloud core has undergone active star formation over its lifetime . Keywords : Star formation ; Near - infrared spectroscopy ; Bipolar outflow ; Young stars object",
        "rewrite_text": "We present near-infrared (NIR) imaging and spectroscopy focused on the galaxy formation activity within the Bok globule CB 54, located approximately 1 kpc from the Galactic anti-center. Our findings reveal the presence of two young stellar objects (YSOs): one Class I protostar, exhibiting an infrared luminosity of approximately 10 Lsun, and another embedded YSO candidate with a bolometric temperature around 1000 K. The Class I protostar is characterized by bipolar outflows, evidenced by Herbig-Haro knots and molecular line wings. Additionally, we identified several other point-like NIR sources in the central region of CB 54, which may represent low-mass pre-main-sequence stars or background galaxies. These observations indicate that the core of this cloud has experienced significant star formation activity throughout its existence. \n\nKeywords: Star formation; Near-infrared spectroscopy; Bipolar outflow; Young stellar objects.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.640679257301507,
        "rewrite-fast-z-score": 0.2581988897471611
    },
    {
        "original_text": "We present new observations of molecular hydrogen (H_2CO) absorption toward the low-mass protostar IRAS 16293-2422, which is associated with two outflows driven by different components of this binary system. The main component drives an east-west bipolar flow that has been traced over more than 1000 AU using SiO emission lines observed at high angular resolution. We have detected anomalously strong absorption features near the systemic velocity of the source for both ortho- and para-H_2CO transitions. These are likely due to self-absorption within the dense gas surrounding the central protostars. In addition, we find evidence for blueshifted absorption features in the para-H_2CO line profiles that may be tracing infalling material along the axis of one of the outflow lobes. Finally, we compare our results with previous studies of carbon monoxide (CO) emission towards the same region.",
        "watermark_text": "We report new images of molecular hydrogen ( H _ 2CO ) diffusion toward the small - weight protostar IRAS 16293 - 2422 , which is associated with two outflows driven by separate components of this binary system . The main component pushes an eastward - west bipolar flow that has been traced over more than 1000 AU utilizing SiO emission lines observed at high angular resolution .We have discovered anomalously strong absorption properties near the systemic speed of the source for both ortho - and para - H _ 2CO transitions . These are likely due to self - absorption within the deep gas covering the main protostars .In addition , we find proof for blueshifted absorption events in the para - H _ 2CO line profiles that might be tracing infalling matter along the axis of one of the outflow lobes . Finally , we compare our findings with previous investigations of carbon monoxide ( CO ) emission towards the same region .",
        "rewrite_text": "We present new images showing the diffusion of molecular hydrogen (H₂CO) towards the low-mass protostar IRAS 16293-2422, which is linked to two outflows originating from different components of this binary system. The primary component generates an east-west bipolar flow, traced over more than 1000 AU using high-resolution observations of SiO emission lines. We have identified unusually strong absorption features near the systemic velocity of the source for both ortho- and para-H₂CO transitions, likely resulting from self-absorption in the dense gas surrounding the main protostars. Furthermore, we observe blueshifted absorption events in the para-H₂CO line profiles, which may indicate infalling material along the axis of one of the outflow lobes. Lastly, we compare our results with previous studies of carbon monoxide (CO) emission in the same region.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.677476657214644,
        "rewrite-fast-z-score": 0.3721042037676254
    },
    {
        "original_text": "The gamma ray emission in the energy range 100 MeV to 10 GeV is studied using data taken by EGRET on board CGRO during its first four years of operation (1991) (1992) (1993) (1994) . The analysis has been performed for two different regions, one centered at l = 0° and b = - 5° , which includes the galactic centre region, and another centered at l = 180° and b = + 5° . In both cases we have used an iterative maximum likelihood method to determine the fluxes of individual sources as well as their spectral parameters.  We find that there are three distinct components contributing to the observed gamma-ray flux above 1 GeV :  A diffuse component with a power law spectrum extending upto ~10 GeV .\nA point source located near Sgr A* with a power law spectrum .\nAn extended source towards the galactic center with a broken power law spectrum . \nWe also present results obtained when the same analysis was repeated after excluding the contribution due to the central part of the Galaxy .",
        "watermark_text": "The gamma radiation emission in the power range 100 MeV to 10 GeV is studied utilizing information taken by EGRET on board CGRO during its initial four seasons of operation ( 1991 ) ( 1992 ) ( 1993 ) ( 1994 ) . The studies has been performed for two different regions , one located at l = 0° and b = - 5° , which includes the galactic centre region , and another focused at l = 180° and b = + 5° .In both cases we have utilized an iterative limit probability technique to estimate the fluxes of different sources as also as their spectral parameters . We see that there are three different components contributing to the emitted beta - ray flux above 1 GeV : A diffuse component with a power law spectrum stretching upto ~ 10 GeV .A point source located near Sgr A * with a power law spectrum . An extended source towards the galactic center with a cracked power law spectrum .We additionally include findings obtained when the same evaluation was repeated after excluding the contribution owing to the central region of the Galaxy .",
        "rewrite_text": "We analyzed gamma-ray emissions in the energy range of 100 MeV to 10 GeV using data collected by EGRET on the CGRO during its first four operational years (1991-1994). The study focused on two distinct regions: one at l = 0° and b = -5°, which includes the area around the galactic center, and another at l = 180° and b = +5°. We employed an iterative limit probability technique to estimate the fluxes of various sources and their spectral parameters in both regions. Our findings indicate three components contributing to the emitted gamma-ray flux above 1 GeV: a diffuse component characterized by a power-law spectrum extending up to approximately 10 GeV, a point source near Sgr A* with a power-law spectrum, and an extended source towards the galactic center exhibiting a broken power-law spectrum. We also present results from a similar analysis conducted after excluding the contributions from the central region of the Galaxy.",
        "ori-fast-z-score": -1.62746694241347,
        "water-fast-z-score": 4.88240082724041,
        "rewrite-fast-z-score": 0.47809144373375745
    },
    {
        "original_text": "We present an analysis of B meson decays to final states with charmed particles, using data collected by the BABAR experiment at SLAC in 1999-2000 corresponding to an integrated luminosity of about 40 fb-1 . We measure the branching fractions for the decay modes B 0 -->D*+l- nu_l; B + -->D*0nu_l; B + -->D0*nu_l; B + ,B 0 -->D*+s nu_s; and B + ,B 0 →D*s nu_s.  From these measurements we extract values for the form factors f0(q2), f1(q2) and f2(q2). Using our results on the branching fraction and lifetime ratio between the two-body and three-body charm-strange B-decays, we determine the Cabibbo-Kobayashi-Maskawa matrix element Vcb = (41.6 +/- 1.1 +/- 2.4) x 10-3 .  The first uncertainty is statistical, the second systematic, and the third due to theoretical uncertainties.",
        "watermark_text": "We present an assessment of B meson decays to finished states with charmed particles , using data taken by the BABAR study at SLAC in 1999 - 2000 resulting to an unified luminosity of about 40 fb - 1 . We estimate the branching fractions for the decay modes B 0 - - > D * + l - nu _ l ; B + - - > D * 0nu _ l ; B + - - > D0 * nu _ l ; B + , B 0 - - > D * + s nu _ s ; and B + , B 0 →D * s nu _ s .From these measurements we extract readings for the form factors f0 ( q2 ) , f1 ( q2 ) and f2 ( q2 ) . Using our findings on the branching percentage and lifetime percentage between the two - bodies and three - bodies charm - strange B - decays , we determine the Cabibbo - Kobayashi - Maskawa matrix element Vcb = ( 41 . 6 + / - 1 . 1 + / - 2 . 4 ) x 10 - 3 .The first uncertainty is empirical , the second systematic , and the third due to theoretical uncertainties .",
        "rewrite_text": "We present an analysis of B meson decays into final states containing charm particles, utilizing data collected by the BABAR experiment at SLAC from 1999 to 2000, which corresponds to an integrated luminosity of approximately 40 fb⁻¹. We estimate the branching fractions for various decay modes, including B⁰ → D*⁺ l⁻ ν_l; B⁺ → D*⁰ ν_l; B⁺ → D⁰* ν_l; B⁺, B⁰ → D*ₛ⁺ νₛ; and B⁺, B⁰ → D*ₛ νₛ. From these measurements, we extract values for the form factors f₀(q²), f₁(q²), and f₂(q²). By analyzing the branching ratios and lifetimes of the two-body and three-body charm-strange B decays, we determine the Cabibbo-Kobayashi-Maskawa matrix element V_cb = (41.6 ± 1.1 ± 2.4) × 10⁻³, where the first uncertainty is experimental, the second is systematic, and the third arises from theoretical considerations.",
        "ori-fast-z-score": 0.9045340337332909,
        "water-fast-z-score": 5.3374499616411635,
        "rewrite-fast-z-score": -0.42857142857142855
    },
    {
        "original_text": "The talk will be divided into three parts, each part corresponding to one of the following topics: \n1) The Standard Model and Beyond; 2) Cosmological Constant Problem; 3) Inflationary Universe. In the first part we will discuss how string theory can provide an explanation for all known particles in nature as well as their interactions. We will also explain why it is important that there are extra dimensions beyond those which have been observed so far. \n \n In the second part we will present some recent results on the cosmological constant problem using supersymmetric field theories with extra dimensions. Finally, in the third part we will review our work on inflationary universe models based on supergravity coupled to gauge fields. This includes both single-field slow-roll inflation and multi-field chaotic inflation scenarios. These models may lead to observable signatures such as primordial gravitational waves or non-Gaussianities in the cosmic microwave background radiation (CMB).",
        "watermark_text": "The speech will be grouped into three sections , each portion relevant to one of the following topics : 1 ) The Standard Model and Beyond ; 2 ) Cosmological Constant Problem ; 3 ) Inflationary Universe . In the first part we will explore how string theory can provide an reason for all known objects in nature as well as their interactions .We will also explain why it is important that there are additional dimensions beyond those which have been observed so far . In the second part we will present some latest findings on the cosmological coefficient question involving supersymmetric field theories with extra dimensions .Finally , in the third chapter we will review our work on inflationary universe models using on supergravity combined to gauge fields . This contains both single - field short - roll inflation and multi - field turbulent growth situations .These systems sometimes lead to observable signatures such as primordial magnetic waves or non - Gaussianities in the cosmic microwave background radiation ( CMB ) .",
        "rewrite_text": "The speech will be divided into three sections, each focusing on one of the following topics: 1) The Standard Model and Beyond; 2) The Cosmological Constant Problem; and 3) The Inflationary Universe. In the first section, we will investigate how string theory offers a framework for understanding all known elements of nature and their interactions. We will also discuss the significance of having additional dimensions beyond those that have been previously observed. In the second section, we will share recent discoveries related to the cosmological constant problem, particularly in the context of supersymmetric field theories with extra dimensions. Finally, in the third section, we will review our research on inflationary universe models that incorporate supergravity alongside gauge fields. This includes both single-field short-roll inflation and multi-field turbulent growth scenarios, which can potentially produce observable phenomena such as primordial magnetic waves or non-Gaussianities in the cosmic microwave background radiation (CMB).",
        "ori-fast-z-score": 0.601929265428846,
        "water-fast-z-score": 5.976143046671968,
        "rewrite-fast-z-score": 3.00964632714423
    },
    {
        "original_text": "We present the results of an extensive spectroscopic survey for active galactic nuclei (AGN) in the southern hemisphere using the Sloan Digital Sky Survey (SDSS). The main goal is to select a complete flux-limited sample of radio-loud AGNs at redshifts z < 0.7, which we call ROXA (Radio Optical eXtragalactic Astronomy), by cross-correlating the FIRST 1.4 GHz radio source catalogue with the SDSS DR3 photometric database. We have obtained spectra for more than 1000 sources over an area of about 10,000 deg2. In this work we report on the selection criteria used to define our sample as well as its completeness and reliability. We also discuss some preliminary results concerning the properties of these objects such as their luminosity function and redshift distribution. This project has been funded by the European Space Agency under contract number 4000106131/16/NL/PA.",
        "watermark_text": "We present the results of an extensive spectroscopic study for active galactic nuclei ( AGN ) in the southern hemisphere using the Sloan Digital Sky Survey ( SDSS ) . The main goal is to select a complete flux - limited sample of radio - loud AGNs at redshifts z < 0 . 7 , which we call ROXA ( Radio Optical eXtragalactic Astronomy ) , by cross - correlating the FIRST 1 . 4 GHz radio source collection with the SDSS DR3 photometric archive .We have achieved spectra for more than 1000 sources over an area of about 10 , 000 deg2 . In this project we publish on the selection standards used to define our sample as well as its completeness and reliability .We also discuss some preliminary results concerning the properties of these objects such as their luminosity function and redshift distribution . This project has been sponsored by the European Space Agency under contract number 4000106131 / 16 / NL / PA .",
        "rewrite_text": "We present the findings of a comprehensive spectroscopic study of active galactic nuclei (AGN) in the southern hemisphere, utilizing data from the Sloan Digital Sky Survey (SDSS). Our primary objective was to assemble a complete flux-limited sample of radio-loud AGNs at redshifts z < 0.7, which we refer to as ROXA (Radio Optical eXtragalactic Astronomy). This was accomplished by cross-referencing the FIRST 1.4 GHz radio source catalog with the SDSS DR3 photometric archive. We successfully obtained spectra for over 1,000 sources across approximately 10,000 square degrees. In this project, we detail the criteria used to select our sample and address its completeness and reliability. Additionally, we present some preliminary findings related to the properties of these objects, including their luminosity function and redshift distribution. This project received funding from the European Space Agency under contract number 4000106131/16/NL/PA.",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 3.5714285714285716,
        "rewrite-fast-z-score": 1.0690449676496976
    },
    {
        "original_text": "The radial distribution of the inner magnetospheric (IM) plasma pressure is studied by analyzing the magnetic field and particle measurements made onboard two satellites at low altitude in the equatorial plane for an intense geomagnetic storm that occurred between March 1-5, 1982 . The results show that there are significant differences in the IM plasma pressure profiles obtained with different satellites. In particular, the pressure profile derived from GEOS-1 observations shows a sharp peak near L = 3 , while those inferred from ATS-6 and GEOS-2 data exhibit much broader peaks around L = 4 . These discrepancies may be due to the fact that these satellites have different orbits which sample different regions of space. It is also found that the pressure profiles inferred from the three satellites agree well when they are shifted outward along the L-shell coordinate system. This suggests that the observed difference in the pressure profiles can be attributed mainly to the spatial variation of the pressure rather than temporal changes.",
        "watermark_text": "The radial distribution of the inner magnetospheric ( IM ) plasma pressure is studied by analyzing the magnetic field and particle measurements made onboard two spacecraft at low height in the equatorial plane for an extreme geomagnetic cyclone that occurred between March 1 - 5 , 1982 . The results show that there are significant variations in the IM plasma pressure profiles obtained with various satellites .In particular , the pressure model derived from GEOS - 1 studies shows a sharp peak near L = 3 , while those inferred from ATS - 6 and GEOS - 2 data display considerably wider peaks around L = 4 . These discrepancies may be due to the fact that these satellites have different orbits which sample different regions of space .It is also discovered that the pressure profiles inferred from the three satellites conform well when they are shifted outward along the L - shell coordinate system . This implies that the seen contrast in the pressure profiles can be due mainly to the spatial variation of the pressure rather than temporal changes .",
        "rewrite_text": "The radial distribution of plasma pressure in the inner magnetosphere (IM) was examined by analyzing magnetic field and particle data collected from two spacecraft operating at low altitudes in the equatorial plane during an extreme geomagnetic cyclone from March 1 to 5, 1982. The findings reveal notable differences in the IM plasma pressure profiles recorded by different satellites. Specifically, the pressure model based on GEOS-1 observations exhibits a sharp peak near L = 3, whereas the models derived from ATS-6 and GEOS-2 data show significantly broader peaks around L = 4. These variations may arise from the distinct orbits of the satellites, which sample different spatial regions. Furthermore, it was found that when the pressure profiles from the three satellites are shifted outward along the L-shell coordinate system, they align closely. This suggests that the differences observed in the pressure profiles are primarily due to spatial variations rather than temporal fluctuations.",
        "ori-fast-z-score": 1.4814874939752933,
        "water-fast-z-score": 5.584068246522259,
        "rewrite-fast-z-score": 0.11547005383792514
    },
    {
        "original_text": "We present the first results on chemical enrichment in cosmological simulations with supernova feedback. We use two different implementations for stellar winds and supernovae (SNe) to study their effects on galaxy formation. The wind implementation is based on kinetic energy injection into gas particles that are above some threshold density; SNe explode as thermal energy injections at random locations within star forming regions. Our main conclusions are:  1. Winds alone cannot reproduce observed metallicities in galaxies.  2. In our fiducial model we find good agreement between simulated and observed metallicity distributions over four orders of magnitude in luminosity. 3. Simulated metal mass fractions agree well with observations out to z = 5. 4. Metal-rich stars form preferentially in massive haloes because they have more time available to enrich themselves through multiple generations of star formation. 5. Gas cooling rates are suppressed by metals produced by previous generations of stars.",
        "watermark_text": "We publish the first findings on chemical enrichment in cosmological simulations with supernova feedback . We use two different implementations for stellar winds and supernovae ( SNe ) to study their impacts on galaxy formation .The wind implementation is based on kinetic power injection into gas molecules that are above some threshold concentration ; SNe explode as heat power injections at random locations within star producing regions . Our main results are : 1 .Winds alone impossible reproduce observed metallicities in galaxies . 2 .In our fiducial model we find good agreement between simulated and detected metallicity distributions over four orders of magnitude in luminosity . 3 .Simulated metal mass fractions agree good with observations out to z = 5 . 4 .Metal - rich stars create preferentially in massive haloes because they have more space accessible to enrich themselves through several generations of star formation . 5 .Gas cooling rates are suppressed by metals produced by earlier lineage of stars .",
        "rewrite_text": "We present our initial findings on chemical enrichment in cosmological simulations that incorporate supernova feedback. To investigate the effects of stellar winds and supernovae (SNe) on galaxy formation, we utilize two distinct approaches. Our wind model operates on the principle of injecting kinetic energy into gas molecules that exceed a certain concentration threshold, while SNe release energy as heat at random locations within star-forming regions. Our key findings are as follows: 1. Stellar winds alone cannot reproduce the observed metallicities in galaxies. 2. In our fiducial model, we observe strong alignment between simulated and observed metallicity distributions across four orders of magnitude in luminosity. 3. The simulated metal mass fractions align well with observations up to redshift z = 5. 4. Metal-rich stars are preferentially formed in massive halos, which have greater capacity for enrichment through multiple generations of star formation. 5. The cooling rates of gas are diminished by metals produced from earlier generations of stars.",
        "ori-fast-z-score": 1.0681034923744679,
        "water-fast-z-score": 5.34051746187234,
        "rewrite-fast-z-score": 0.7977240352174656
    },
    {
        "original_text": "We present an improved semi-analytical method (SAM) that includes gravitational heating by dark matter halos and gas cooling in galaxy formation, which is essential to reproduce observed properties of galaxies such as luminosity functions at different redshifts.  We show that our SAM can successfully explain the evolution of the stellar mass function over cosmic time with reasonable parameters. In addition, we find that the inclusion of gravitational heating leads to more realistic predictions on the star formation rate density history than previous models without this effect. Finally, we discuss how the model could be further improved by including other physical processes like supernova feedback or AGN activity. The results presented here are based on observations made with ESO Telescopes at Paranal Observatory under programme ID 085.A-0488(A). This work was supported by JSPS KAKENHI Grant Number JP15K05481. Figure 1 . Predicted number densities of galaxies as a function of their total stellar masses compared with observational data taken from the literature. Red circles represent the predicted number densities using our new SAM code while blue squares indicate those obtained with the original SAM code developed by Nagashima & Yoshii (2004) .",
        "watermark_text": "We introduce an excellent semi - modelling techniques ( SAM ) that encompasses gravitational heating by black material halos and gas warming in universe formation , which is crucial to reproduce observed properties of stars such as luminosity functions at different redshifts . We suggest that our SAM can effectively predict the evolution of the stellar mass function over cosmic time with satisfactory parameters .In addition , we find that the introduction of gravitational heating results to more realistic predictions on the star formation rate density history than prior models without this effect . Finally , we explain how the model could be further better by including other physical processes like supernova feedback or AGN activity .The results presented here are based on observations made with ESO Telescopes at Paranal Observatory under programme ID 085 . A - 0488 ( A ) . This project was supported by JSPS KAKENHI Grant Number JP15K05481 .Figure 1 . Predicted number densities of galaxies as a function of their total stellar masses compared with observational data taken from the literature .Red rings represent the expected number densities using our new SAM code while blue squares correspond those acquired with the previous SAM code developed by Nagashima & Yoshii ( 2004 ) .",
        "rewrite_text": "We present a robust semi-analytic modeling technique (SAM) that incorporates gravitational heating from dark material halos and gas warming during the formation of the universe. This approach is essential for accurately reproducing the observed properties of stars, including luminosity functions across various redshifts. Our SAM effectively predicts the evolution of the stellar mass function throughout cosmic time with satisfactory parameters. Additionally, we demonstrate that the inclusion of gravitational heating provides more realistic predictions of star formation rate density history compared to previous models that did not account for this effect. We also discuss how the model could be further improved by integrating additional physical processes, such as supernova feedback and AGN activity. The findings presented here are based on observations obtained with the ESO Telescopes at Paranal Observatory, under program ID 085.A-0488(A). This research was supported by JSPS KAKENHI Grant Number JP15K05481. Figure 1 illustrates the predicted number densities of galaxies as a function of their total stellar masses, compared with observational data from the literature. The red rings indicate the expected number densities generated by our newly developed SAM code, while the blue squares represent those derived from the previous SAM code created by Nagashima & Yoshii (2004).",
        "ori-fast-z-score": -0.21081851067789195,
        "water-fast-z-score": 5.346252667281783,
        "rewrite-fast-z-score": 0.4082482904638631
    },
    {
        "original_text": "We consider the problem of sampling from an arbitrary probability distribution over graphs with fixed number of nodes and edges, where each node has a given degree constraint. We propose a novel algorithm for this task based on the idea of rapidly mixing Markov chains known as Metropolis-Hastings algorithms. Our approach is to use a special type of graph called a tree decomposition which allows us to decompose our original problem into smaller problems in such a way that we can efficiently sample from these smaller problems using existing techniques. In particular, we show how to construct a tree decomposition of any input graph G = (V , E) by first constructing a tree decomposition of its line graph L(G). Then, we prove that if there exists a polynomial time algorithm A that solves one of these small subproblems then it also implies the existence of a polynomial time algorithm B that solves all of them simultaneously. Finally, we present experimental results showing that our proposed method outperforms state-of-the-art methods when applied to several real-world datasets.",
        "watermark_text": "We consider the question of sampling from an arbitrary likelihood distribution over graphs with constant number of vertices and edges , where each node has a given degree constraint . We suggest a new algorithm for this job based on the idea of quickly mixing Markov chains known as Metropolis - Hastings algorithms .Our solution is to use a unique kind of graph named a tree decomposition which allows us to decompose our previous problem into tiny problems in such a way that we can efficiently sample from these smaller problems using existing techniques . In particular , we study how to build a tree decomposition of any input graph G = ( V , E ) by first creating a tree transformation of its line tree L ( G ) .Then , we prove that if there exists a polynomial time algorithm A that solves one of these little subproblems then it also proves the existence of a polynomial time algorithm B that solves all of them simultaneously . Finally , we present research results confirming that our proposed approach outperforms state - of - the - art methods when applied to several real - global datasets .",
        "rewrite_text": "We address the issue of sampling from an arbitrary likelihood distribution over graphs with a fixed number of vertices and edges, where each vertex adheres to specific degree constraints. We propose a novel algorithm for this task, leveraging the principles of rapidly mixing Markov chains exemplified by Metropolis-Hastings algorithms. Our approach employs a special type of graph known as a tree decomposition, which enables us to break down the overall problem into smaller, manageable problems that can be efficiently sampled using established techniques. Specifically, we explore the process of constructing a tree decomposition for any input graph \\( G = (V, E) \\) by first transforming its line graph \\( L(G) \\) into a tree structure. We demonstrate that if a polynomial-time algorithm \\( A \\) can solve one of these smaller subproblems, it guarantees the existence of a polynomial-time algorithm \\( B \\) that can solve all of them simultaneously. Lastly, we present research findings that indicate our approach outperforms current state-of-the-art methods when tested on various real-world global datasets.",
        "ori-fast-z-score": 0.3216337604513384,
        "water-fast-z-score": 5.116817192534651,
        "rewrite-fast-z-score": 1.4100479758212652
    },
    {
        "original_text": "We present an algorithm for generating new solutions to the coupled Einstein-scalar field equations, starting from vacuum solutions and adding scalar fields in such a way that the resulting solution is minimally coupled.  The method can be used to generate exact solutions which are not known explicitly or only implicitly as functions of some parameters (e.g., by solving algebraic equations). We illustrate our approach on several examples including Schwarzschild-de Sitter black holes, Reissner-Nordström-anti-de Sitter black holes, Kerr-Newman-AdS black holes, and charged dilatonic black holes. In particular we show how one can obtain explicit expressions for the massless limit of these black hole solutions. Our results may also have applications beyond gravity theory, e.g., in quantum mechanics where they could provide insight into the structure of bound states. Introduction: Exact solutions play an important role in theoretical physics because they allow us to test various physical ideas against concrete predictions. However, finding exact solutions to physically interesting problems often turns out to be very difficult. For example, it took more than 100 years after the discovery of general relativity before the first exact black hole solutions were found  1-3 . Even today there exist many open questions about black holes  4  . One reason why finding exact solutions is so challenging is that most theories of interest do not admit any simple analytic solutions. Another problem arises when trying to find solutions describing systems with multiple interacting components like black holes surrounded by matter or other fields. Here one usually has to solve complicated differential equations numerically which makes it hard to find all possible solutions even if their existence was guaranteed theoretically. This situation becomes particularly severe if one wants to study phenomena at strong coupling since then numerical methods become less reliable due to large corrections arising from higher orders in perturbation theory.",
        "watermark_text": "We present an algorithm for generating new answers to the coupled Einstein - scalar field equations , beginning from vacuum solutions and adding scalar fields in such a way that the resulting solve is minimally coupled . The method can be used to create precise solutions which are not described specifically or only implicitly as functions of some parameters ( e . g . , by modeling algebraic equations ) .We illustrate our approach on numerous instances including Schwarzschild - de Sitter dark holes , Reissner - Nordström - anti - de Sitter dark holes , Kerr - Newman - AdS red holes , and charged dilatonic black holes . In particular we give how one can obtain precise expressions for the massless maximum of these black hole solutions .Our results may even have applications beyond gravitational theory , e . g . , in quantum mechanics where they may provide insight into the formation of bound states . Introduction : Exact solutions play an important role in theoretical physics because they allow us to test various mechanical concepts against concrete expectations .However , finding exact treatments to physically exciting issues often comes out to be very difficult . For instance , it takes more than 100 years after the discovery of general relativity before the first accurate black hole problems were found 1 - 3 .Even nowadays there remain many open questions about black holes 4 . One reason why seeking precise solutions is so difficult is that most models of importance do not admit any straightforward analytic solutions .Another difficulty arises when trying to find solutions involving systems with various interacting components like grey holes populated by matter or other fields . Here one usually has to solve complicated differential equations numerically which makes it difficult to find all possible solutions even if their existence was assured theoretically .This problem arises increasingly severe if one wants to study phenomena at strong coupling since then numerical models become fewer reliable resulting to large corrections resulting from greater orders in perturbation theory .",
        "rewrite_text": "We introduce an algorithm designed to generate new solutions to the coupled Einstein-scalar field equations, starting from vacuum solutions and incorporating scalar fields in a way that ensures minimal coupling. This method enables the creation of precise solutions that are either not explicitly defined or are only implicitly represented as functions of certain parameters, such as through algebraic modeling. We demonstrate our approach with a variety of examples, including Schwarzschild-de Sitter black holes, Reissner-Nordström anti-de Sitter black holes, Kerr-Newman-AdS red holes, and charged dilatonic black holes. Notably, we provide a means of obtaining exact expressions for the massless maxima of these black hole solutions. Our findings may extend beyond gravitational theory, potentially offering insights into the formation of bound states in quantum mechanics. \n\n**Introduction:** Exact solutions are crucial in theoretical physics, allowing us to validate mechanical theories against tangible predictions. However, obtaining exact solutions for physically significant problems can often be exceedingly challenging. For example, over a century passed after the discovery of general relativity before accurate models of black holes were established. Even today, numerous questions regarding black holes remain unresolved. One primary difficulty in finding precise solutions lies in the fact that many important models do not permit straightforward analytic solutions. Additionally, when addressing systems with various interacting components, such as grey holes filled with matter or other fields, we typically face the challenge of solving complex differential equations numerically, complicating the identification of all viable solutions, despite their theoretical assurance of existence. This challenge is exacerbated in scenarios involving strong coupling, where numerical methods may become unreliable and lead to significant corrections from higher-order terms in perturbation theory.",
        "ori-fast-z-score": 0.30499714066520933,
        "water-fast-z-score": 8.387421368293257,
        "rewrite-fast-z-score": 1.5360589585634423
    },
    {
        "original_text": "We present an analysis of the first two years (Feb 2005 -Jan 2007) of data taken by the Swift satellite, which has been designed to detect and study gamma ray bursts (GRBs). We find that GRB 050904 at z = 6.3 is the most distant object ever detected in the electromagnetic spectrum. The prompt emission was observed over more than four orders of magnitude in energy, from radio waves up to X-rays. This burst also had one of the highest fluences recorded so far for any GRB. In addition we report on another burst, GRB 080913, whose afterglow was found to be variable on timescales as short as 1 minute. These results are discussed within the context of current models for GRB production. Keywords: Gamma-ray burst, High-redshift universe, Afterglows, Swift satellite. Gamma-ray bursts (GRBs), intense flashes of high-energy radiation lasting only milliseconds, have now been discovered out to redshifts greater than six  1  . Their extreme luminosities make them powerful probes into the early Universe  2  , but their origin remains unknown  3  .\nSwift  4  , launched in November 2004, carries three instruments capable of detecting GRBs across the entire electromagnetic spectrum  5  : the Burst Alert Telescope  6  detects GRBs via their X-ray and/or optical emissions; the Ultraviolet/Optical Telescope  7  observes the afterglow through ultraviolet and visible light; and the X-ray telescope  8  monitors the afterglow s decaying flux. Here we describe our initial findings using these instruments during the first two years of operation. \nThe Burst Alert Telescope\n\nBurst Alert Telescope Observations of GRB 050904\nOn September 5 th , 2006, the Burst Alert Telescope triggered on a bright source located at RA=05h54m36.6s Dec=-69d21 59.6   9  . Follow-up observations revealed this event to be a new record holder among GRBs  10  . Its peak photon count rate reached 2 x 10 4 photons s -1 cm -2 in the 15-150 keV band  11  . It lasted about",
        "watermark_text": "We present an assessment of the first two years ( Feb 2005 - Jan 2007 ) of evidence gained by the Swift satellite , which has been designed to identify and track γ ray clusters ( GRBs ) . We see that GRB 050904 at z = 6 . 3 is the most distant object ever observed in the electromagnetic spectrum .The prompt emission was seen over more than four orders of magnitude in energy , from radio beams up to X - rays . This burst also had one of the highest fluences recorded so far for any GRB .In addition we paper on another burst , GRB 080913 , whose afterglow was shown to be varying on timescales as short as 1 minute . These conclusions are discussed within the context of recent versions for GRB development .Keywords : Gamma - ray flare , High - redshift universe , Afterglows , Swift satellite . Gamma - ray clusters ( GRBs ) , intense pulses of high - energy rays lasting only milliseconds , have now been detected out to redshifts greater than six 1 .Their intense luminosities give them potent probes into the early Universe 2 , but their source remains unidentified 3 . Swift 4 , launched in November 2004 , carries three devices capable of detecting GRBs across the entire electromagnetic spectrum 5 : the Burst Alert Telescope 6 detects GRBs via their X - ray and / or laser emissions ; the Ultraviolet / Optical Telescope 7 sees the afterglow through ultraviolet and visible radiation ; and the X - ray observatory 8 monitors the afterglow s decaying flux .Here we explain our first findings using these instruments during the first two years of operation . The Burst Alert Telescope Burst Alert Telescope Observations of GRB 050904 On September 5 th , 2006 , the Burst Alert Telescope triggered on a bright source located at RA = 05h54m36 . 6s Dec = - 69d21 59 . 6 9 .Follow - up observations showed this event to be a new record holder among GRBs 10 . Its peak photon number rate reached 2 x 10 4 photons s - 1 cm - 2 in the 15 - 150 keV band 11 .It lasted about",
        "rewrite_text": "We provide an evaluation of the first two years (February 2005 - January 2007) of data collected by the Swift satellite, which is designed to detect and monitor gamma-ray bursts (GRBs). Notably, GRB 050904, with a redshift of z = 6.3, is identified as the most distant object observed in the electromagnetic spectrum. The prompt emission from this burst spanned over four orders of magnitude in energy, ranging from radio waves to X-rays. It also recorded one of the highest fluences for any GRB to date. Additionally, our study discusses GRB 080913, which displayed variability in its afterglow on timescales as brief as one minute. These findings are contextualized within contemporary theories of GRB evolution. \n\nKeywords: Gamma-ray burst, High-redshift universe, Afterglows, Swift satellite. Gamma-ray bursts (GRBs), which are intense bursts of high-energy radiation lasting only milliseconds, have now been observed at redshifts exceeding six. Their extreme luminosity makes them powerful tools for exploring the early Universe, although their exact origins remain unknown. Launched in November 2004, Swift is equipped with three instruments capable of detecting GRBs across the entire electromagnetic spectrum: the Burst Alert Telescope, which identifies GRBs through their X-ray and/or optical emissions; the Ultraviolet/Optical Telescope, which captures the afterglow in ultraviolet and visible light; and the X-ray Observatory, which tracks the decay of afterglow flux. Here, we outline our initial findings utilizing these instruments during Swift's first two years of operation.\n\nBurst Alert Telescope Observations of GRB 050904\nOn September 5, 2006, the Burst Alert Telescope detected a bright source located at RA = 05h54m36.6s, Dec = -69d21m59.6s. Follow-up observations confirmed this event as a record-breaking GRB. Its peak photon number rate reached 2 x 10^4 photons s^-1 cm^-2 in the 15-150 keV range, with a duration of approximately...",
        "ori-fast-z-score": 0.4703604341917986,
        "water-fast-z-score": 7.243550686553699,
        "rewrite-fast-z-score": 0.2847473987257497
    },
    {
        "original_text": "We present results on variable X-ray emission from the central parsecs (0.1 pc) around Sgr A*, which is associated with hot plasma ejected by young massive stars near the supermassive black hole at the Galactic Centre. We find that the variability timescale decreases as we move towards higher energies. The observed power spectrum can be explained if there are two components contributing to the total flux - one steady component and another varying component. This suggests that the source of the X-rays may not be point-like but extended. Our analysis also shows that the luminosity changes significantly over time scales ranging between hours and years. These variations could be due to either intrinsic or extrinsic factors such as orbital motion of the emitting region and/or obscuration effects caused by intervening clouds. In addition, we have found evidence for an anti-correlation between the soft and hard bands during flares. This indicates that the spectral shape varies along with its intensity.",
        "watermark_text": "We report findings on variable X - ray radiation from the central parsecs ( 0 . 1 pc ) around Sgr A * , which is associated with hot plasma expelled by young massive galaxies near the supermassive black hole at the Galactic Centre . We see that the variability timescale decreases as we move towards higher energies .The observed power spectrum can be understood if there are two parts contributing to the total flux - one steady component and another varying component . This implies that the origin of the X - radiation may not be point - like but extended .Our study also shows that the luminosity shifts significantly over time ranges ranging between hours and years . These changes could be due to either intrinsic or extrinsic factors such as orbital movement of the emitting area and / or obscuration effects caused by intervening clouds .In addition , we have discovered evidence for an counter - correlation between the soft and hard bands during flares . This implies that the absorption form varies along with its brightness .",
        "rewrite_text": "We present our findings on the variability of X-ray radiation from the central parsecs (0.1 pc) surrounding Sgr A*, which is linked to hot plasma ejected by young massive galaxies near the supermassive black hole at the Galactic Center. Our observations indicate that as we move to higher energy levels, the timescale of variability decreases. The observed power spectrum suggests that the total flux arises from two components: a steady source and a variable one. This indicates that the source of the X-radiation may be extended rather than point-like. Additionally, our study reveals significant fluctuations in luminosity over timescales ranging from hours to years. These variations could result from either intrinsic factors, such as the orbital motion of the emitting region, or extrinsic factors like obscuration from intervening clouds. Moreover, we have found evidence of a counter-correlation between the soft and hard X-ray bands during flares, suggesting that the absorption characteristics change in tandem with brightness.",
        "ori-fast-z-score": -1.0533703247651751,
        "water-fast-z-score": 4.564604740649092,
        "rewrite-fast-z-score": 0.8307471607356973
    },
    {
        "original_text": "We report on the observation of electronic spin transport across macroscopic distances (several millimeters) in suspended single-layer graphene devices at room temperature.  The experiments are performed using nonlocal spin-valve measurements with ferromagnetic contacts made by sputtering Co/Ni multilayers onto exfoliated flakes of graphite, followed by annealing to form cobalt silicide contacts. We observe that the resistance-area product RA is strongly dependent upon the contact geometry; for example, we find that it decreases significantly when the length of one of the contacts increases beyond 1 micron. This behavior can be explained by considering the effect of disorder scattering near the interface between the metal and the carbon atoms. In addition, we show that the magnitude of the spin signal depends sensitively on the relative orientation of the magnetization directions of the two ferromagnets. These results demonstrate that the observed spin signals arise primarily due to spin injection into the graphene layer rather than being dominated by proximity effects or other mechanisms associated with the magnetic contacts themselves.",
        "watermark_text": "We report on the observation of electronic spin travel across macroscopic distances ( several millimeters ) in suspended single - substrate graphene structures at room temperature . The studies are performed using nonlocal spin - valve measurements with ferromagnetic contacts produced by sputtering Co / Ni multilayers onto exfoliated flakes of graphite , followed by annealing to form cobalt silicide links .We recognize that the tolerance - area product RA is strongly dependent upon the contact shape ; for example , we find that it decreases dramatically when the length of one of the contacts increases beyond 1 micron . This activity can be described by examining the impact of disorder absorption near the interface between the metal and the metal atoms .In addition , we find that the magnitude of the spin signal relies sensitively on the relative attitude of the magnetization directions of the two ferromagnets . These data demonstrate that the known spin signals arise principally due to spinning injection into the graphene layer instead than being dominated by proximity effects or other mechanisms associated with the magnetic links themselves .",
        "rewrite_text": "We present our findings on the observation of electronic spin propagation over macroscopic distances (several millimeters) in suspended single-substrate graphene structures at room temperature. The experiments utilize nonlocal spin-valve measurements with ferromagnetic contacts made by sputtering Co/Ni multilayers onto exfoliated graphite flakes, followed by annealing to create cobalt silicide connections. We note that the tolerance-area product (RA) is significantly influenced by the shape of the contacts; specifically, it declines sharply when the length of one of the contacts exceeds 1 micron. This behavior can be explained by analyzing the effects of disorder absorption at the interface between the metal and the metal atoms. Additionally, we observe that the magnitude of the spin signal is highly sensitive to the alignment of the magnetization directions of the two ferromagnets. Our data indicate that the observed spin signals are primarily a result of spin injection into the graphene layer, rather than being primarily influenced by proximity effects or other mechanisms related to the magnetic links.",
        "ori-fast-z-score": -0.7977240352174656,
        "water-fast-z-score": 5.128225940683707,
        "rewrite-fast-z-score": 1.62746694241347
    },
    {
        "original_text": "We present fitting formulae for the illumination of accretion disks by hot spots, as seen in Schwarzschild and rotating black holes (Kerr). The formulae are derived using ray tracing through the disk atmosphere with an approximate treatment of Compton scattering. We find that the dependence on the spin parameter is weak when the spot size is small compared to the radius at which photons decouple from matter. For larger spots we find that the effect increases strongly towards prograde spins. Our results can be used to estimate the effects of relativistic Doppler boosting and gravitational lensing on observed spectra. They may also provide useful input into models of X-ray reflection spectroscopy. \nIntroduction\n\nAccreting black holes produce bright emission lines in their X-ray spectrum due to reprocessing of hard X-rays emitted near the event horizon by cold material orbiting close to the equatorial plane. These features have been studied extensively over many years both observationally and theoretically (see Reynolds & Nowak 2003 , Done et al 2004 . In particular, they show strong red-shifts indicating that the emitting gas orbits rapidly around the black hole. This rapid rotation causes additional shifts in energy due to relativistic Doppler boosts and gravitational lensing. Relativistic effects become more important if the emitting region has a high degree of rotational support or is viewed nearly face-on. It is therefore necessary to take these effects into account when interpreting observations of such systems. \n\nIn this work we consider the case where the illuminating source is located above the disk surface but below its photosphere. Such sources include magnetic flares produced within the disk itself or active regions associated with the inner edge of the disk. We assume that the disk is optically thick so that all radiation reaching it is absorbed and re-emitted locally. We use Monte Carlo simulations to calculate the emergent flux from the disk under various assumptions about the geometry of the system.\n\nThe main goal of our study was to develop simple analytical expressions describing how the shape of the line profile depends on the properties of the system. To do this we performed extensive numerical calculations covering a wide range",
        "watermark_text": "We present fitting formulae for the illumination of accretion disks by hot spots , as shown in Schwarzschild and rotating black holes ( Kerr ) . The formulae are derived using ray tracing through the disk atmosphere with an approximate treatment of Compton absorption .We see that the dependence on the spin vector is weak when the spot size is tiny relative to the radius at which photons decouple from matter . For larger spots we find that the impact grows highly towards prograde spins .Our results can be used to estimate the effects of relativistic Doppler boosting and gravity lensing on measured spectra . They might additionally offer useful input into estimates of X - ray reflection spectroscopy .Introduction Accreting black holes create bright emission lines in their X - ray spectrum due to reprocessing of hard X - rays generated near the event horizon by cold matter orbiting close to the equatorial plane . These features have been studied frequently over numerous years both observationally and theoretically ( saw Reynolds & Nowak 2003 , Done et al 2004 .In particular , they show intense red - shifts suggesting that the emitting gas orbits rapidly around the dark hole . This rapid rotation creates additional shifts in energy due to relativistic Doppler boosts and gravity lensing .Relativistic effects become more essential if the emitting area has a high degree of rotational support or is viewed virtually face - on . It is consequently required to take these consequences into consideration when interpreting observations of such systems .In this research we imagine the case where the illuminating source is situated above the disk boundary but below its photosphere . Such sources include magnetic flares created within the disk itself or active regions associated with the inner boundary of the disk .We assume that the disk is optically dense so that all light reaching it is absorption and re - radiated locally . We use Monte Carlo simulations to estimate the emergent flux from the disk under various statements about the topology of the system .The main goal of our research was to develop primitive analytical expressions relating how the form of the line profile depends on the properties of the system . To do this we performed extensive numerical measurements encompassing a broad range",
        "rewrite_text": "We provide fitting formulas for the illumination of accretion disks by hot spots, as observed in both Schwarzschild and rotating (Kerr) black holes. These formulas are developed through ray tracing within the disk's atmosphere and include an approximate treatment of Compton absorption. Our analysis reveals that the influence of the spin vector is minimal when the hot spot size is small compared to the radius at which photons decouple from the matter. In contrast, for larger spots, the effect significantly increases with prograde spins. These findings can help estimate the impacts of relativistic Doppler boosting and gravitational lensing on observed spectra and may also contribute valuable insights for X-ray reflection spectroscopy.\n\nIntroduction: Accreting black holes generate bright emission lines in their X-ray spectrum due to the reprocessing of hard X-rays produced near the event horizon by cold matter orbiting close to the equatorial plane. These features have been extensively explored over the years, both theoretically and through observations (see Reynolds & Nowak 2003, Done et al. 2004). Notably, the emission lines exhibit strong redshifts, indicating the rapid orbital motion of the emitting gas around the black hole. This swift rotation leads to additional energy shifts resulting from relativistic Doppler effects and gravitational lensing. Such relativistic influences become particularly important when the emitting region is highly rotationally supported or viewed nearly edge-on, necessitating their consideration in the interpretation of observations from these systems.\n\nIn this study, we consider the scenario where the illuminating source is located above the disk boundary but beneath its photosphere. Such sources may include magnetic flares originating within the disk or active regions near the inner boundary. We assume that the disk is optically thick, allowing all incoming light to be absorbed and re-radiated locally. To estimate the emitted flux from the disk under various configurations, we employ Monte Carlo simulations. Our primary objective is to derive simple analytical expressions that describe how the shape of the line profile is influenced by the system's properties. To achieve this, we conducted extensive numerical evaluations across a wide range of parameters.",
        "ori-fast-z-score": -0.1543033499620919,
        "water-fast-z-score": 8.076923076923077,
        "rewrite-fast-z-score": 0.7761505257063328
    },
    {
        "original_text": "The aim of this study is to develop an improved model for simulating diffusion processes within biological cells, especially those occurring at the nuclear membrane and its associated structures.  The proposed approach involves coupling two existing models; one that describes the movement of molecules through the cytoplasm (the fluid part of the cell) using Brownian dynamics simulations, with another which represents the nucleus as a porous medium containing immobile obstacles.  This latter component has been developed by considering the geometry of the nuclear pore complex network, which consists of cylindrical pores connected via narrower channels.   In order to validate our new hybrid model we have performed a series of numerical experiments on synthetic data generated from both individual particle tracking and Monte Carlo methods.  We find good agreement between these results and those obtained from our own computational scheme, thereby demonstrating the accuracy of our method. Finally, we apply our new modelling framework to investigate how changes in the structure of the nuclear pore complexes can affect the rate of molecular exchange across the nuclear envelope.",
        "watermark_text": "The goal of this study is to develop an better model for simulating diffusion processes within molecular cells , particularly those occurring at the atomic membrane and its associated structures . The proposed approach requires coupling two existing models ; one that describes the movement of molecules through the cytoplasm ( the liquid part of the cell ) using Brownian gravity simulations , with another which represents the nucleus as a porous medium containing immobile obstacles .This last component has been constructed by examining the topology of the atomic pore complex network , which consists of circular pores connected via narrower outlets . In order to validate our new hybrid system we have done a string of computational experiments on synthetic information generated from both individual beam monitoring and Monte Carlo methods .We get good agreement between these results and those acquired from our own computational scheme , thereby showing the accuracy of our technique . Finally , we apply our new modelling methodology to examine how differences in the composition of the atomic pore complexes can affect the frequency of molecular transfer across the atomic envelope .",
        "rewrite_text": "The objective of this study is to create an enhanced model for simulating diffusion processes within molecular cells, especially at the atomic membrane and its associated structures. The proposed method integrates two existing models: one that describes the movement of molecules through the cytoplasm, utilizing Brownian gravity simulations, and another that characterizes the nucleus as a porous medium containing fixed obstacles. This latter component has been developed by analyzing the topology of the atomic pore complex network, consisting of circular pores linked by narrower channels. To validate our new hybrid system, we conducted a series of computational experiments using synthetic data generated from both individual beam monitoring and Monte Carlo methods. The results show a strong correlation between these findings and those obtained from our computational approach, confirming the accuracy of our technique. Finally, we apply our new modeling methodology to investigate how variations in the composition of atomic pore complexes influence the rate of molecular transfer across the atomic envelope.",
        "ori-fast-z-score": -1.1659976680069961,
        "water-fast-z-score": 6.677986644040068,
        "rewrite-fast-z-score": 2.0855209398041166
    },
    {
        "original_text": "We study the statistical properties of Barkhausen noise generated by an Ising spin system with random fields and competing interactions at its surface, using wavelets to analyze the time series produced by this model.  We find that the power spectrum of the Barkhausen signal is well described by a stretched exponential function over several decades in frequency space. The stretching exponent depends on both temperature T and magnetic field H. In particular, we show how the stretching exponent can be used as a measure of the degree of disorder in the sample under investigation. Finally, we discuss possible extensions of our work to other types of systems exhibiting avalanche dynamics. Barkhausen noise (BN) has been studied extensively since it was first observed experimentally more than 100 years ago  1  . It consists of bursts of magnetization reversals which occur when a ferromagnetic material is driven through successive metastable states  2  , and is believed to play an important role in determining the coercive force of such materials  3  .\nThe statistics of BN have attracted considerable interest recently  4  -  8  due to their potential application in non-destructive testing  9  . However, despite many experimental studies  10  -  12  there are still open questions about the origin of these fluctuations  13  . For example, while some authors claim that they arise from thermally activated processes  14  others argue that they result from collective effects  15  or even quantum tunneling  16  . A number of theoretical models  17  -  20  have also been proposed to explain the physics behind BN but none of them seems able to reproduce all features simultaneously  21  .",
        "watermark_text": "We research the statistical characteristics of Barkhausen interference generated by an Ising spin body with random fields and competing interactions at its surface , using wavelets to analyze the time series formed by this model . We see that the power spectrum of the Barkhausen signal is well described by a stretched exponential function over several decades in frequency space .The extension exponent depends on both heat T and magnetic force H . In particular , we explain how the stretching exponent can be used as a measure of the degree of disorder in the sample under research . Finally , we explain possible extend of our work to other types of models displaying avalanche dynamics .Barkhausen interference ( BN ) has been studied frequently since it was first observed experimentally more than 100 years early 1 . It consists of flashes of magnetization reversals which occur when a ferromagnetic material is accelerated through consecutive metastable levels 2 , and is suspected to hold an important role in establishing the coercive force of such substances 3 .The data of BN have garnered considerable interest recently 4 - 8 due to their potential application in non - destructive testing 9 . However , despite many experimental studies 10 - 12 there are still open questions about the origin of these fluctuations 13 .For instance , while some writers claim that they occur from thermally activated processes 14 others argue that they occur from collective effects 15 or maybe quantum tunneling 16 . A several of theoretical theories 17 - 20 have also been proposed to explain the physics behind BN but none of them appears able to predict all characteristics simultaneously 21 .",
        "rewrite_text": "We investigate the statistical properties of Barkhausen interference generated by an Ising spin system subjected to random fields and competing interactions at its surface, utilizing wavelet analysis to interpret the resulting time series from this model. Our findings reveal that the power spectrum of the Barkhausen signal can be accurately characterized by a stretched exponential function across multiple decades of frequency. The stretching exponent is shown to be influenced by both temperature (T) and magnetic field (H). Notably, we discuss how the stretching exponent serves as an indicator of the disorder level within the sample being analyzed. Additionally, we outline potential avenues for extending our research to other models that exhibit avalanche dynamics. Barkhausen interference (BN) has been extensively examined since its initial experimental observation over a century ago. It manifests as sudden magnetization reversals occurring as a ferromagnetic material transitions through successive metastable states, and it is believed to play a crucial role in determining the coercive force of such materials. Recently, the data pertaining to BN has attracted significant interest due to its possible applications in non-destructive testing. However, despite numerous experimental investigations, questions regarding the origin of these fluctuations remain unresolved. Some researchers propose that these fluctuations arise from thermally activated processes, while others suggest they are due to collective effects or potentially quantum tunneling. Several theoretical frameworks have been proposed to elucidate the underlying physics of BN, yet none have successfully predicted all observed characteristics simultaneously.",
        "ori-fast-z-score": -0.09166984970282113,
        "water-fast-z-score": 7.425257825928512,
        "rewrite-fast-z-score": -1.1141720290623112
    },
    {
        "original_text": "The National Science Foundation (NSF) has recently formed an  Exoplanet Task Force  with the goal of identifying key science goals for future space missions in exoplanet research, including radio astrometry.  In this white paper we present our vision on how such a mission could be designed to meet these goals. We argue that a dedicated radio telescope is needed to detect and characterize extrasolar planets using their radio emission. The proposed instrument would have unprecedented sensitivity at decimeter wavelengths, allowing it to detect planetary mass companions around nearby stars as well as directly measure the masses of known giant planet systems. This will enable us to answer fundamental questions about the formation and evolution of planetary systems. Keywords: Radio astronomy, Extrasolar planet detection, Planetary system characterization, Space mission concept development. 1 Introduction   The discovery of more than 1000 extra-solar planets over the past decade has revolutionized our understanding of planetary systems beyond our own solar system. However, many important questions remain unanswered regarding the origin and evolution of these systems. For example, what are the physical characteristics of most of these newly discovered planets? How do they form? What happens when two or more planets interact gravitationally? Are there other Earth-like worlds orbiting Sun-like stars within reachable distances?  Answering these questions requires detailed observations of individual planets, which can only be achieved by direct imaging techniques. Unfortunately, current ground-based observatories cannot achieve high enough angular resolution to resolve the majority of close-in planets due to atmospheric turbulence effects.   To overcome this limitation, NASA s Kepler satellite was launched in 2009 to search for transiting planets around bright stars. Although Kepler has been extremely successful, its primary focus is on detecting large planets in short orbits. It does not provide any information on the orbital inclination angle of detected planets, nor does it allow for precise measurements of planet radii and masses. Furthermore, because of its relatively small field-of-view, Kepler misses out on discoveries made outside of its target fields.",
        "watermark_text": "The National Science Foundation ( NSF ) has recently established an Exoplanet Task Force with the objective of identifying key research goals for future orbital flights in exoplanet research , notably broadcast astrometry . In this white paper we present our vision on how such a spacecraft could be designed to meet these objectives .We argue that a dedicated radio telescope is required to identify and characterize extrasolar planets using their radio emission . The proposed instrument would have enormous sensitivity at decimeter wavelengths , allowing it to identify planetary mass companions around nearby planets as well as closely determine the masses of known giant planet systems .This will provide us to answer basic concerns about the formation and evolution of planetary networks . Keywords : Radio astronomy , Extrasolar moon discovery , Planetary network detection , Space mission design development .1 Introduction The observation of more than 1000 extra - solar planets over the previous decade has revolutionized our understanding of planetary structures beyond our own solar system . However , many important questions remain unanswered concerning the origin and evolution of these systems .For instance , what are the natural characteristics of most of these newly discovered planets ? How do they create ?What happens when two or more planets interact gravitationally ? Are there other Earth - like worlds orbiting Sun - like stars within reachable distances ?Answering these problems demands full observations of multiple worlds , which can only be obtained by direct observation techniques . Unfortunately , current ground - based observatories cannot achieve high enough angular resolution to identify the majority of close - in planets owing to air turbulence influences .To solve this limitation , NASA s Kepler satellite was launched in 2009 to search for transiting planets around bright stars . Although Kepler has been extremely successful , its primary emphasis is on detecting large planets in small orbits .It does not offer any info on the orbital inclination ratio of detected planets , nor does it enable for precise observations of planet radii and masses . Furthermore , because of its relatively small field - of - view , Kepler misses out on discoveries made outside of its target areas .",
        "rewrite_text": "The National Science Foundation (NSF) has recently launched an Exoplanet Task Force aimed at outlining essential research priorities for future orbital missions in exoplanet studies, particularly in the area of broadcast astrometry. In this white paper, we propose a design for a spacecraft that would fulfill these objectives. We contend that a specialized radio telescope is necessary to detect and characterize extrasolar planets through their radio emissions. The suggested instrument would have exceptional sensitivity at decimeter wavelengths, enabling it to identify planetary mass companions around nearby planets and accurately measure the masses of known giant planet systems. This capability would help address fundamental questions about the formation and evolution of planetary systems. \n\nKeywords: Radio astronomy, Extrasolar moon discovery, Planetary network detection, Space mission design development.\n\n**1. Introduction**\n\nThe observation of over 1,000 exoplanets in the last decade has transformed our understanding of planetary structures beyond our solar system. Nevertheless, many critical questions about the origin and evolution of these systems remain unresolved. For example, what are the inherent characteristics of these newly discovered planets? How do they form? What occurs during gravitational interactions among multiple planets? Are there Earth-like worlds orbiting Sun-like stars within accessible distances? Answering these questions requires comprehensive observations of multiple worlds, achievable only through direct observation methods. Currently, ground-based observatories struggle to provide the necessary angular resolution to study many close-in planets due to atmospheric turbulence. To address this challenge, NASA launched the Kepler satellite in 2009 to search for transiting planets around bright stars. Although Kepler has been highly successful, its focus is primarily on identifying large planets in small orbits. It does not provide information on the orbital inclination ratios of the detected planets nor does it allow for precise measurements of planet sizes and masses. Additionally, Kepler’s relatively narrow field of view limits its ability to make discoveries outside its designated observation areas.",
        "ori-fast-z-score": 0.38691161626706844,
        "water-fast-z-score": 8.329938702528295,
        "rewrite-fast-z-score": 1.182165609358651
    },
    {
        "original_text": "We study the multicritical behavior in the two-dimensional gonihedric model with nearest-neighbor interactions on an anisotropic triangular lattice. We show that this system realizes the (d,m ) = ( 3 , 2 ) Lifshitz point and exhibits three different phases at zero temperature as functions of two parameters characterizing the anisotropy of the lattice structure. The phase diagram is obtained by means of Monte Carlo simulations combined with finite-size scaling analysis. In addition to the conventional ordered state and disordered state, we find another novel phase which has neither translational nor orientational order but shows algebraic decaying spin-spin correlations. This new phase can be regarded as a kind of spin-liquid-like state. Our results are also compared with those for other models such as the Ashkin-Teller model and the Blume-Capel model. \nI n t r o d u c t i o n :\nThe concept of Lifshitz points was originally introduced into condensed matter physics more than half a century ago  1  . It describes a critical point where several distinct phases meet each other simultaneously  2  . Recently, it attracted renewed interest because of its possible relevance to high-temperature superconductivity  3  .\nIn particular, the so-called (d, m) = (3, 2) Lifshitz point  4  , where d denotes spatial dimension and m represents number of components of order parameter fields, has been studied extensively both theoretically  5  -  8  and experimentally  9  -  11  . However, most studies have focused only on systems with short-range interactions  12  or purely magnetic systems  13  -  16  . On the other hand, there exist few theoretical investigations  17  -  20  concerning the effects of longer-ranged interactions  21  and/or competing orders  22  on the Lifshitz point.\nIn this Letter, we investigate the multicritical behavior of the two-dimensional gonihedrickson-Lee (GL) model  23  with nearestneighbor interactions on an anisotopic triangular lattice  see Fig.  1  . Although the GL model itself does not exhibit any ordering transition  24  , our previous work  25  showed that the introduction of anisotropy leads to",
        "watermark_text": "We explore the multicritical behavior in the two - dimensional gonihedric model with nearest - neighbor interactions on an anisotropic triangular lattice . We see that this scheme assumes the ( d , m ) = ( 3 , 2 ) Lifshitz point and exhibits three different phases at zero temperature as functions of two parameters characterizing the anisotropy of the lattice structure .The phase diagram is found by means of Monte Carlo simulations combined with discrete - length scaling calculations . In addition to the usual organized state and disordered state , we find another novel phase which has neither translational nor orientational order but exhibits algebraic decaying spin - spin correlations .This new period can be regarded as a kind of spin - fluid - like state . Our results are also compared with those for other models such as the Ashkin - Teller model and the Blume - Capel theory .I n t r o d u c t i o n : The concept of Lifshitz points was originally adopted into condensed matter science more than half a millennium prior 1 . It describes a critical spot where many unique stages approach each other independently 2 .Recently , it garnered renewed interest because of its potential significance to large - temperature superconductivity 3 . In particular , the so - called ( d , m ) = ( 3 , 2 ) Lifshitz point 4 , where d indicates temporal dimension and m means number of components of order parameter fields , has been studied thoroughly both theoretically 5 - 8 and experimentally 9 - 11 .However , most studies have concentrated only on systems with narrow - range interactions 12 or purely magnetic structures 13 - 16 . On the other hand , there remain few experimental studies 17 - 20 concerning the effects of extended - ranged interactions 21 and / or competing orders 22 on the Lifshitz point .In this Letter , we investigate the multicritical behavior of the two - dimensional gonihedrickson - Lee ( GL ) model 23 with nearestneighbor interactions on an anisotopic triangular lattice seeing Fig . 1 .Although the GL model itself does not show any ordering transition 24 , our previous research 25 showed that the introduction of anisotropy leads to",
        "rewrite_text": "We examine the multicritical behavior of the two-dimensional gonihedric model with nearest-neighbor interactions on an anisotropic triangular lattice. Our analysis reveals that this model assumes a (d, m) = (3, 2) Lifshitz point and displays three distinct phases at zero temperature, depending on two parameters that define the lattice's anisotropy. The phase diagram is constructed using Monte Carlo simulations in conjunction with discrete-length scaling calculations. Besides the typical ordered and disordered states, we identify an intriguing new phase characterized by the absence of both translational and orientational order, yet featuring algebraically decaying spin-spin correlations. This novel phase can be interpreted as a spin-fluid-like state. We also compare our findings with those from other models, including the Ashkin-Teller model and the Blume-Capel theory. \n\nIntroduction: The concept of Lifshitz points was incorporated into condensed matter physics over five centuries ago, representing a critical point where multiple unique phases converge. Recently, it has gained renewed attention due to its potential relevance for high-temperature superconductivity. Specifically, the (d, m) = (3, 2) Lifshitz point—where d denotes the temporal dimension and m indicates the number of components of the order parameter fields—has been the subject of extensive theoretical and experimental study. However, most research has focused on systems with limited-range interactions or purely magnetic structures. There remains a scarcity of experimental work exploring the influence of long-range interactions and competing orders on the Lifshitz point. In this letter, we investigate the multicritical behavior of the two-dimensional Gonihedricson-Lee (GL) model with nearest-neighbor interactions on an anisotropic triangular lattice, as shown in Figure 1. Although the GL model does not exhibit any ordering transitions, previous research demonstrated that incorporating anisotropy leads to significant changes in its behavior.",
        "ori-fast-z-score": 0.5144957554275265,
        "water-fast-z-score": 6.46954963376649,
        "rewrite-fast-z-score": 0.4240944648399855
    },
    {
        "original_text": "We consider the capacity region of a multiple-input-multiple-output (MIMO) fading channel in which each transmitter has perfect knowledge of its own instantaneous channel state information and uses a quantized precoding matrix to maximize mutual information between itself and the receiver. We show that, for any given number of transmit antennas at all transmitters, there exists an optimal number of receive antennas such that the sum-capacity is maximized when all receivers have this same number of antennas. This result holds even if the channels are correlated across time or frequency. The optimal number of receive anten-nas increases as more transmit antennas are used by the transmitters. For example, we find that using four transmit antennas results in the highest sum-rate when three receive antennas are employed per user; however, five receive antennas should be used instead if eight transmit antennas are available.",
        "watermark_text": "We consider the capacity area of a multiple - input - multiple - output ( MIMO ) fading signal in which each antenna has good knowledge of its own instantaneous channel state information and using a quantized precoding vector to maximize mutual information between itself and the receiver . We see that , for any certain number of transmit antennas at all transmitters , there exists an appropriate number of receive antennas such that the sum - capacity is maximized when all transmissions have this same amount of antennas .This result holds even if the transmissions are correlated across time or bandwidth . The appropriate number of receive anten - nas increases as more transmit antennas are using by the transmitters .For instance , we find that using four transmit antennas results in the highest sum - efficiency when three receive antennas are employed per user ; however , five send antennas should be used instead if eight send antennas are available .",
        "rewrite_text": "We analyze the capacity region of a multiple-input multiple-output (MIMO) fading signal in which each antenna possesses accurate knowledge of its own instantaneous channel state information. Using a quantized precoding vector, the goal is to maximize the mutual information between each antenna and the receiver. Our findings indicate that, for any given number of transmit antennas across all transmitters, there exists an optimal number of receive antennas that maximizes the sum capacity when all transmissions utilize the same number of antennas. This conclusion holds true even when transmissions are correlated over time or bandwidth. Interestingly, the optimal number of receive antennas increases as the number of transmit antennas at the transmitters increases. For example, employing four transmit antennas yields the highest sum efficiency when each user has three receive antennas. Conversely, if eight transmit antennas are available, five should be used instead.",
        "ori-fast-z-score": -0.762000762001143,
        "water-fast-z-score": 4.318004318006477,
        "rewrite-fast-z-score": 1.61245154965971
    },
    {
        "original_text": "We consider the problem of detecting an unknown signal vector with a known covariance matrix, embedded in additive white Gaussian noise (AWGN). We propose to use sample eigenvalues as test statistics for this problem and derive their distributions under both hypotheses. The proposed method is shown to be robust against small perturbations on the covariance matrices. It also has low computational complexity compared to other existing methods. Finally we present simulation results that demonstrate its performance advantage over competing algorithms. In many applications such as radar systems or wireless communications, it is often desirable to detect whether there exists any signal component within noisy measurements. This problem can be formulated mathematically as: \nwhere x ∈ R N , s ∈ R M are respectively the signal and noise vectors; A ∈ R L×N denotes the sensing matrix which maps the signal space into the measurement space; y = Ax + n represents the observation vector where n ∼ N(0, σ 2 I) is AWGN. Herein, we assume that the number of observations L is much smaller than either N or M .",
        "watermark_text": "We consider the question of detecting an unknown signal vector with a known covariance matrix , embedded in additive white Gaussian sound ( AWGN ) . We suggest to use sample eigenvalues as test estimates for this question and derive their distributions under both hypotheses .The proposed approach is demonstrated to be robust against small perturbations on the covariance matrices . It however has low theoretical complexity compared to other existing techniques .Finally we present model results that demonstrate its performance benefit over competing techniques . In many applications such as radar systems or wireless communications , it is often desirable to identify whether there exists any signal component within noisy measurements .This problem can be described mathematically as : where x ∈ R N , s ∈ R M are respectively the signal and noise vectors ; A ∈ R L×N denotes the sensing matrix which maps the signal space into the observation space ; y = Ax + h indicates the observation vector where n [UNK] N ( 0 , σ 2 I ) is AWGN . Herein , we suppose that the number of measurements L is much smaller than either N or M .",
        "rewrite_text": "We address the challenge of detecting an unknown signal vector with a known covariance matrix embedded in additive white Gaussian noise (AWGN). Our approach involves utilizing sample eigenvalues as test statistics and deriving their distributions under both hypotheses. This method proves to be robust against minor perturbations in the covariance matrices and has lower theoretical complexity compared to other existing techniques. We also present results from our model that illustrate its performance advantages over competing methods. In various applications, such as radar systems or wireless communications, it is often crucial to determine whether a signal component is present within noisy measurements. Mathematically, this issue can be framed as follows: let x ∈ R^N and s ∈ R^M represent the signal and noise vectors, respectively, while A ∈ R^(L×N) is the sensing matrix that maps the signal space to the observation space. The observation vector is given by y = Ax + h, where n ~ N(0, σ^2 I) signifies the AWGN. We assume that the number of measurements L is significantly smaller than both N and M.",
        "ori-fast-z-score": 1.5652475842498528,
        "water-fast-z-score": 6.555555555555555,
        "rewrite-fast-z-score": 1.1322770341445956
    },
    {
        "original_text": "We study the formation and control of Liesegang patterns in an electrochemical system by applying external electric fields to modulate the local concentration gradients during precipitation reactions.  We show that, under certain conditions, the applied field can be used as a guiding field to direct the growth of precipitate bands along specific directions. The results are explained using a simple model based on the competition between diffusion and reaction rates at different locations within the sample. This work provides new insights into how chemical systems may self-organize through interactions with their environment. Chemical systems often exhibit complex spatial structures such as stripes or rings which form spontaneously without any externally imposed symmetry breaking  1  . These structures have been observed in many natural phenomena including mineral deposits  2  , biological tissues  3  , and even living organisms  4  .\nThe most famous example is the so-called  Liesegang ring  formed when two solutions containing metal ions react chemically  5  . In this case, the initial solution contains both cations (e.g., Ag+) and anions (e.g., Cl-). When these two solutions come into contact, they begin to diffuse across each other until they meet another interface where the opposite charges neutralize one another  6  . At some point after mixing, precipitation occurs leading to the formation of a band of solid material separating the original solutions  7, 8  . As more bands grow, they eventually overlap forming concentric rings around the center of the sample  9  . Although the exact mechanism behind the formation of Liesegang rings remains unclear  10  , it has been shown experimentally that the spacing between successive rings depends strongly on the concentrations of the starting solutions  11  .",
        "watermark_text": "We research the formation and management of Liesegang trends in an electrochemical system by using external electric forces to modulate the local concentration gradients during precipitation reactions . We suggest that , under certain conditions , the introduced field can be used as a guiding field to direct the development of precipitate bands along particular directions .The results are explained using a simple study based on the competition between diffusion and reaction rates at different places within the sample . This research provides new concepts into how chemical structures could self - organize through relationships with their environment .Chemical systems often exhibit intricate visual formations such as stripes or rings which create spontaneously without any externally imposed symmetry breaking 1 . These structures have been observed in many natural objects including geological deposits 2 , biological tissues 3 , and sometimes living organisms 4 .The most famous example is the so - called Liesegang ring formed when two solutions containing metal ions react chemically 5 . In this instance , the first solution comprises both cations ( e . g . , Ag + ) and anions ( e . g . , Cl - ) .When these two solutions come into contact , they start to diffuse across each other until they meet another interface where the opposite charges neutralize one another 6 . At some time after mixing , precipitation occurs leading to the formation of a band of solid tissue separating the original solutions 7 , 8 .As more bands expand , they eventually overlap making concentric rings around the center of the sample 9 . Although the exact mechanism behind the formation of Liesegang rings appears unclear 10 , it has been shown experimentally that the spacing between successive rings depends strongly on the levels of the starting solutions 11 .",
        "rewrite_text": "We investigate the development and management of Liesegang patterns within an electrochemical system by employing external electrical forces to modify local concentration gradients during precipitation reactions. We propose that, under specific conditions, the applied field can serve as a guiding mechanism to influence the orientation of precipitate bands. Our findings are elucidated through a straightforward analysis of the competition between diffusion and reaction rates at various locations within the sample. This research introduces new insights into how chemical structures can self-organize in relation to their surroundings. Chemical systems often display complex visual patterns, such as stripes or rings, that form spontaneously without any externally imposed symmetry breaking. These formations have been observed in a variety of natural entities, including geological deposits, biological tissues, and sometimes living organisms. The most well-known example is the Liesegang ring, which occurs when two solutions containing metal ions react chemically. In this case, the initial solution contains both cations (e.g., Ag⁺) and anions (e.g., Cl⁻). When these solutions come into contact, they begin to diffuse into each other until they reach an interface where opposing charges neutralize. After some time post-mixing, precipitation takes place, resulting in the creation of a solid band that separates the original solutions. As additional bands propagate, they eventually overlap, forming concentric rings around the center of the sample. Although the precise mechanism behind Liesegang ring formation remains unclear, experimental evidence indicates that the spacing between successive rings is heavily influenced by the concentrations of the initial solutions.",
        "ori-fast-z-score": 2.6680551940539985,
        "water-fast-z-score": 8.520563361656318,
        "rewrite-fast-z-score": 2.088931871468374
    },
    {
        "original_text": "We present an explanation to the observed anomalies in globular cluster luminosity functions (GCLFs) and mass-to-light ratios, based on the assumption that these clusters are composed by two different populations with distinct chemical compositions.  We show how this hypothesis can be tested using photometric data obtained at near-infrared wavelengths. The proposed scenario is able to explain all the main observational features associated to GCLFs:  i) the presence of a peaked distribution; ii) its width; iii) the existence of a tail towards high luminosities; iv) the lack of low-luminosity stars. In addition, it also explains why some GCs have very large values of M/LV . Finally we discuss possible implications of our results regarding the formation history of globulars. Keywords: Globular cluster, Mass-to-light ratio, Luminosity function, Chemical composition, Near-infrared",
        "watermark_text": "We present an explanation to the reported anomalies in globular cluster luminosity functions ( GCLFs ) and mass - to - light proportions , relying on the assumption that these clusters are composed by two different populations with distinct chemical compositions . We see how this hypothesis can be evaluated using photometric data derived at near - infrared wavelengths .The proposed theory is could to explain all the main observational characteristics attributed to GCLFs : i ) the presence of a peaked distribution ; ii ) its height ; iii ) the existence of a tail towards high luminosities ; iv ) the lack of high - luminosity stars . In addition , it also explains why some GCs have very huge values of M / LV .Finally we explain possible implications of our findings pertaining the formation history of globulars . Keywords : Globular cluster , Mass - to - light density , Luminosity function , Chemical composition , Near - infrared",
        "rewrite_text": "We offer an explanation for the observed anomalies in globular cluster luminosity functions (GCLFs) and mass-to-light ratios, based on the premise that these clusters consist of two distinct populations with varying chemical compositions. This hypothesis can be assessed using photometric data obtained in the near-infrared spectrum. Our proposed theory clarifies several key observational features associated with GCLFs: i) the presence of a peaked distribution; ii) its overall height; iii) the emergence of a tail extending toward high luminosities; and iv) the scarcity of high-luminosity stars. Additionally, it accounts for the exceptionally high values of M/LV observed in certain globular clusters. Lastly, we discuss the potential implications of our findings regarding the formation history of globular clusters. Keywords: Globular cluster, Mass-to-light ratio, Luminosity function, Chemical composition, Near-infrared.",
        "ori-fast-z-score": -0.13018891098082389,
        "water-fast-z-score": 4.6475800154489,
        "rewrite-fast-z-score": -0.75
    },
    {
        "original_text": "We present the results of an optical imaging survey with Subaru/Suprime-Cam of the nearby galaxy group centered on M31, including its brightest satellite galaxy, Andromeda II (M32). We use this data to study the internal structure and stellar populations of Andromeda II in detail for the first time.  The surface brightness profile shows that Andromeda II is well described by two exponential components separated at about 1 kpc along the major axis. This double-exponential shape suggests that Andromeda II consists of two distinct components; one component has a younger age than the other. Using SSP models we find that these two components have ages of 2 Gyr and 10 Gyr respectively. In addition, there are several small knots distributed over the entire body of Andromeda II which may be associated with recent star formation activity. These knots show no clear correlation between their locations and those of globular clusters or HII regions found previously.",
        "watermark_text": "We publish the conclusion of an optical optical survey with Subaru / Suprime - Cam of the nearby galaxy class centered on M31 , notably its brightest satellite galaxy , Andromeda II ( M32 ) . We use this data to study the internal structure and stellar environments of Andromeda II in detail for the first time .The exterior brightness profile reveals that Andromeda II is well described by two exponential parts joined at about 1 kpc along the main axis . This double - exponential shape suggests that Andromeda II contains of two separate phases ; one part has a younger date than the other .Using SSP models we find that these two parts have ages of 2 Gyr and 10 Gyr respectively . In addition , there are several small knots scattered over the entire body of Andromeda II which may be involved with recent star formation activity .These knots exhibit no clear correlation between their regions and those of globular complexes or HII centers found formerly .",
        "rewrite_text": "We present the findings of an optical survey conducted with the Subaru/Suprime-Cam of the nearby galaxy class centered on M31, focusing particularly on its brightest satellite galaxy, Andromeda II (M32). This data allows us to examine the internal structure and stellar environments of Andromeda II in unprecedented detail. The outer brightness profile indicates that Andromeda II can be described by two exponential components that merge at approximately 1 kpc along the main axis. This double-exponential profile suggests the existence of two distinct phases within Andromeda II, with one being younger than the other. Using stellar population synthesis models, we determine that the ages of these two components are 2 Gyr and 10 Gyr, respectively. Additionally, we observe several small knots distributed across the entirety of Andromeda II, which may be linked to recent star formation activity. Notably, these knots show no significant correlation with the regions of globular clusters or HII centers previously identified.",
        "ori-fast-z-score": -0.1203858530857692,
        "water-fast-z-score": 5.976143046671968,
        "rewrite-fast-z-score": 1.4342743312012722
    },
    {
        "original_text": "We study the structure of the stationary distribution for an asymmetric version of the Target Process (TP). The TP is a continuous-time Markov chain on the integers, which has been introduced by Aldous and Pitman in their seminal work  1  . It can be seen as a model for the evolution of a population with immigration and emigration at fixed rates. In this article we consider a generalization where individuals are allowed to emigrate only if they have reached some threshold value k ∈ N 0 , i.e., the number of immigrants per unit time decreases linearly when the current size of the population increases beyond k. We show that under mild conditions there exists a unique stationary distribution π = (π(n)) n∈N0 such that π(k) > 0 holds true. Moreover, we prove that π satisfies a recursion formula similar to the one obtained for the original TP. Finally, we provide explicit expressions for π(1), ..., π(k+1).\nKeywords: Asymmetric target process, Stationary distribution",
        "watermark_text": "We explore the structure of the stationary distribution for an asymmetric version of the Target Process ( TP ) . The TP is a continuous - time Markov chain on the integers , which has been proposed by Aldous and Pitman in their seminal study 1 .It can be viewed as a description for the evolution of a population with immigration and emigration at fixed rates . In this paragraph we imagine a generalization where persons are allowed to emigrate only if they have achieved some threshold quantity k ∈ N 0 , i . e . , the quantity of aliens per unit time decreases linearly when the present size of the population rises beyond k . We see that under mild conditions there exists a unique stationary function π = ( π ( p ) ) n∈N0 such that π ( k ) > 0 holds true .Moreover , we prove that π satisfies a recursion formula analogous to the one achieved for the original TP . Finally , we provide explicit expressions for π ( 1 ) , . . . , π ( k + 1 ) .Keywords: Asymmetric target process, Stationary distribution",
        "rewrite_text": "We investigate the structure of the stationary distribution for a modified version of the Target Process (TP) that incorporates asymmetry. Originally proposed by Aldous and Pitman in their groundbreaking research, the TP is a continuous-time Markov chain defined on the integers and serves to model the dynamics of a population experiencing both immigration and emigration at constant rates. In this discussion, we consider a generalization in which individuals can only emigrate after reaching a certain threshold quantity \\( k \\in \\mathbb{N}_0 \\). Specifically, the rate of emigration decreases linearly when the population size exceeds \\( k \\). We demonstrate that, under mild conditions, there exists a unique stationary function \\( \\pi = (\\pi(p))_{n \\in \\mathbb{N}_0} \\) such that \\( \\pi(k) > 0 \\). Furthermore, we prove that \\( \\pi \\) adheres to a recursive relationship similar to that of the original TP. Finally, we derive explicit formulas for \\( \\pi(1), \\ldots, \\pi(k + 1) \\). \n\nKeywords: Asymmetric target process, Stationary distribution",
        "ori-fast-z-score": -0.8819171036881969,
        "water-fast-z-score": 3.810003810005715,
        "rewrite-fast-z-score": 1.1523319193960637
    },
    {
        "original_text": "We present new results on gamma-ray emission produced by cosmic rays interacting with interstellar gas, based on observations made with the HESS telescope array between 2004 and 2007. We report an improved measurement of the spectrum of the brightest source detected at TeV energies, RX J1713.7--3946 (HESS J1714-385), which is well described by a power law with index = 2.28 ± 0.04 stat ± 0.1 sys . The integral flux above 1 TeV amounts to (2.6 +/- 0.4) x 10-12 cm-2 s-1 , corresponding to about 10% of the total Galactic diffuse emission observed at these energies. This result confirms that this object is indeed a supernova remnant as suggested previously. \n \n In addition we have discovered two new sources within the field-of-view of our instrumentation. One of them has been identified with the shell-type supernova remnant G349.7+0.2 while another one remains unidentified.",
        "watermark_text": "We report new data on gamma - ray radiation generated by cosmic rays interacting with interstellar gas , based on observations made with the HESS telescope array between 2004 and 2007 . We report an better study of the spectrum of the brightest source detected at TeV energies , RX J1713 . 7 - - 3946 ( HESS J1714 - 385 ) , which is well described by a power law with index = 2 . 28 ± 0 . 04 stat ± 0 . 1 sys .The integral flux above 1 TeV corresponds to ( 2 . 6 + / - 0 . 4 ) x 10 - 12 cm - 2 s - 1 , equivalent to about 10 % of the total Galactic diffuse emission observed at these frequencies . This result confirms that this body is indeed a supernova remnant as suggested previously .In addition we have discovered two new sources within the field - of - view of our instrumentation . One of them has been detected with the shell - class supernova remnant G349 . 7 + 0 . 2 while another one remains unidentified .",
        "rewrite_text": "We present new findings on gamma-ray radiation produced by cosmic rays interacting with interstellar gas, gathered from observations using the HESS telescope array between 2004 and 2007. Our study provides an improved analysis of the spectrum for the brightest source detected at TeV energies, RX J1713.7-3946 (HESS J1714-385), which is accurately characterized by a power law with an index of 2.28 ± 0.04 (stat) ± 0.1 (sys). The integral flux above 1 TeV is measured at (2.6 ± 0.4) × 10^-12 cm^-2 s^-1, which constitutes approximately 10% of the total Galactic diffuse emission observed at these energies. This finding further supports the classification of this object as a supernova remnant, as previously proposed. Additionally, we have identified two new sources within the field of view of our instruments; one of these corresponds to the shell-type supernova remnant G349.7+0.2, while the other remains unidentified.",
        "ori-fast-z-score": 1.8073922282301278,
        "water-fast-z-score": 4.905778905196061,
        "rewrite-fast-z-score": 0.508000508000762
    },
    {
        "original_text": "We report on the absorption spectrum of an isolated single-wall carbon nanotube (SWNT) in solution, obtained by using a scanning near-field optical microscope with subwavelength resolution. The SWNTs are suspended between two gold electrodes and illuminated through one electrode at normal incidence to excite both transverse electric (TE) and transverse magnetic (TM) polarized light. We observe that the TE mode is strongly suppressed compared to TM polarization due to the presence of metallic tubes within our sample. This effect can be used as a spectroscopic tool for identifying the chirality of individual SWNTs. \n \n Single-wall carbon nanotubes have attracted considerable interest because they exhibit unique electronic properties which depend sensitively on their diameter and chiral angle  1  . In particular, it has been shown theoretically  2  , experimentally  3  , and numerically  4  that the energy gap depends on these parameters such that semiconducting tubes have small gaps while metallic tubes have large ones. However, this dependence is not sufficient to uniquely identify all possible tube types  5  .\n \nIn order to determine the type of each tube individually, several experimental techniques have been developed  6  -  8  . For example, Raman scattering  9  or photoluminescence  10  measurements allow one to distinguish between metallic and semiconducting tubes based on the intensity ratio of certain peaks  11  . Alternatively, electrical transport experiments  12  provide information about the charge carrier density and mobility  13  . Finally, transmission electron microscopy  14  allows one to directly visualize the structure of the tubes  15  . \n \n Here we present another method for determining the chirality of individual carbon nanotubes. Our approach relies on measuring the absorption cross section of individual SWNTs  16  . Since the absorption cross-section depends on the dielectric function  17  , which in turn varies significantly depending on whether the tube is metallic or semiconducting  18  , we expect different values for the absorption cross sections of metallic versus semiconducting tubes. By comparing the measured absorption cross sections of various tubes, we will show how this technique can be used to classify them into either metallic or semiconducting categories. \nExperimental setup\n\nThe samples were prepared following the",
        "watermark_text": "We report on the absorption spectrum of an exposed single - wall carbon nanotube ( SWNT ) in solution , obtained by using a scanning near - field imaging microscope with subwavelength resolution . The SWNTs are suspended between two gold electrodes and illuminated through one electrode at usual incidence to excite both transverse electric ( TE ) and longitudinal magnetic ( TM ) polarized light .We determine that the TE phase is strongly restrained compared to TM polarization owing to the presence of metallic tubes within our sample . This phenomenon can be used as a spectroscopic tool for determining the chirality of different SWNTs .Single - wall carbon nanotubes have garnered considerable interest because they demonstrate unique electronic properties which depend sensitively on their thickness and chiral angle 1 . In particular , it has been shown theoretically 2 , experimentally 3 , and numerically 4 that the electricity gap depends on these parameters such that semiconducting tubes have narrow holes while metallic tubes have huge ones .However , this dependence is not required to uniquely distinguish all possible tube kinds 5 . In order to identify the kind of each tube individually , various experimental methods have been used 6 - 8 .For instance , Raman scattering 9 or photoluminescence 10 measurements enable one to distinguish between metallic and semiconducting tubes based on the frequency proportion of certain peaks 11 . Alternatively , electrical travel test 12 provide details about the charge carrier density and connectivity 13 .Finally , transmission electron microscopy 14 allows one to fully visualize the formation of the tubes 15 . Here we present another technique for determining the chirality of different carbon nanotubes .Our model relies on measuring the absorption cross section of individual SWNTs 16 . Since the absorption cross - section depends on the dielectric function 17 , which in turn varies dramatically based on whether the pipe is metallic or semiconducting 18 , we expect different values for the absorption cross sections of metallic versus semiconducting tubes .By matching the measured absorbed cross sections of different tubes , we will show how this methodology can be used to classify them into either metallic or semiconducting grades . Experimental setup The samples were prepared following the",
        "rewrite_text": "We present our findings on the absorption spectrum of a single-wall carbon nanotube (SWNT) suspended in solution, achieved using a scanning near-field imaging microscope with subwavelength resolution. The SWNTs were positioned between two gold electrodes and illuminated from one electrode at normal incidence, allowing us to excite both transverse electric (TE) and longitudinal magnetic (TM) polarized light. Our analysis reveals that the TE mode is significantly restricted in comparison to the TM polarization, a result attributed to the presence of metallic tubes in our sample. This effect can be harnessed as a spectroscopic method for discerning the chirality of various SWNTs. Single-wall carbon nanotubes have attracted substantial attention due to their distinctive electronic properties, which are sensitive to their diameter and chiral angle. Theoretically, experimentally, and numerically, it has been shown that the energy gap of these tubes varies with these parameters, with semiconducting tubes exhibiting narrow gaps and metallic tubes having larger ones. However, this relationship alone is insufficient for uniquely identifying all types of nanotubes. To classify the individual types of each tube, several experimental approaches have been employed. For example, Raman scattering and photoluminescence measurements allow differentiation between metallic and semiconducting tubes based on the ratio of certain peak frequencies, while electrical transport measurements provide insights into charge carrier density and connectivity. Transmission electron microscopy offers comprehensive visualization of nanotube formation. In this work, we introduce an alternative technique for determining the chirality of different carbon nanotubes. Our approach involves measuring the absorption cross-section of individual SWNTs. Given that the absorption cross-section is influenced by the dielectric function—which varies significantly depending on whether the tube is metallic or semiconducting—we anticipate distinct values for the absorption cross sections of both types. By comparing the measured absorption cross sections of various tubes, we demonstrate how this method can effectively classify them as either metallic or semiconducting. The experimental setup for our samples was prepared following specific protocols.",
        "ori-fast-z-score": -0.8778955729143844,
        "water-fast-z-score": 7.205766921228921,
        "rewrite-fast-z-score": -1.2977713690461004
    },
    {
        "original_text": "Entropies are measures of uncertainty, and entropy power inequalities (EPIs) quantify the trade-off between information transmission rates in different communication channels.  In this work we present new proofs for EPIs based on information theory concepts such as mutual information and channel capacity.   We also show that these results can be used to prove Shannon s source coding theorem by applying them to an appropriate binary memoryless symmetric channel model. Finally, we discuss how our approach could potentially lead to improved bounds on the minimum distance of linear block codes over finite fields. Entropies are measures of uncertainty; entropy power inequalities (EPIS) quantify the tradeoff between information transmission rates in various communication channels. In this work we present novel proofs for EPIs using information-theory concepts like mutual information and channel capacity. We also demonstrate that these results may be utilized to verify Shannon s source coding theorem via their application to a suitable binary memoryless-symmetric channel model. Finally,we discuss how our technique might possibly yield better bounds on the minimal distance of linear block codes across finite fields.",
        "watermark_text": "Entropies are measures of uncertainty , and entropy energy inequalities ( EPIs ) quantify the trade - off between information transmission rates in different communication channels . In this research we present new proofs for EPIs based on communication theory ideas such as mutual information and channel capacity .We additionally prove that these results can be used to prove Shannon s source coding theorem by application them to an appropriate binary memoryless symmetric channel structure . Finally , we talk how our approach could potentially lead to greater bounds on the minimum length of linear block sequences over discrete fields .Entropies are measures of uncertainty ; entropy energy inequalities ( EPIS ) quantify the tradeoff between information transmission rates in different communication streams . In this research we present new proofs for EPIs using info - theory ideas like mutual information and channel capacity .We additionally prove that these results may be employed to confirm Shannon s source coding theorem via their application to a suitable binary memoryless - symmetric channel structure . Finally , we explain how our technique may possibly deliver improved bounds on the reduced distance of linear block sequences across bounded fields .",
        "rewrite_text": "Entropies serve as indicators of uncertainty, while entropy energy inequalities (EPIs) express the trade-off between information transmission rates across various communication channels. In this study, we introduce new proofs for EPIs rooted in concepts from communication theory, such as mutual information and channel capacity. Furthermore, we demonstrate that these findings can be utilized to validate Shannon's source coding theorem by applying them to an appropriate binary memoryless symmetric channel structure. Lastly, we discuss how our methodology could pave the way for enhanced bounds on the minimal length of linear block sequences in discrete fields.",
        "ori-fast-z-score": 0.8,
        "water-fast-z-score": 7.0710678118654755,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We present new deep photometry for the remote open cluster B514, located at about 1 degree (0.5 kpc) south-east of the center of the Andromeda galaxy (M31). The data were obtained with the Wide Field Camera 3 on board HST and cover an area of 0.6 square degrees centered around the cluster position. We detect more than 100 candidate members brighter than V = 25 mag within a radius of 2 arcmin from the cluster center. These are likely to be associated with the cluster itself rather than background galaxies or foreground Galactic dwarfs because they have colors consistent with those expected for old red giant branch stars. In addition we find that there is a significant number of faint blue objects surrounding the cluster which may belong to it as well. Using these candidates together with previous ground-based observations we construct color-magnitude diagrams for different annuli extending out to 5 arcmin from the cluster centre. From this analysis we conclude that the cluster has an extended halo containing several hundred low mass stars beyond its tidal radius.",
        "watermark_text": "We report new deep photometry for the distant open cluster B514 , located at about 1 degree ( 0 . 5 kpc ) south - east of the hub of the Andromeda galaxy ( M31 ) . The data were obtained with the Wide Field Camera 3 on board HST and cover an area of 0 . 6 square degrees centered around the cluster spot .We detect more than 100 candidate members hotter than V = 25 mag within a diameter of 2 arcmin from the cluster center . These are likely to be identified with the group itself rather than background galaxies or foreground Galactic dwarfs because they have colors consistent with those expected for past red dwarf branch stars .In addition we find that there is a substantial quantity of faint blue objects surrounding the cluster which may belong to it as also . Using these candidates coupled with previous ground - based observations we create color - brightness diagrams for different annuli extending out to 5 arcmin from the cluster centre .From this analysis we suppose that the cluster has an extended halo containing several hundred small weight stars beyond its tidal diameter .",
        "rewrite_text": "We present new deep photometry of the distant open cluster B514, situated approximately 1 degree (0.5 kpc) southeast of the Andromeda galaxy (M31). The observations were conducted using the Wide Field Camera 3 on the Hubble Space Telescope (HST) and cover an area of 0.6 square degrees centered on the cluster. We have identified over 100 candidate members with magnitudes hotter than V = 25 within a 2 arcminute radius from the cluster center. These candidates are more likely to be associated with the cluster itself rather than being background galaxies or foreground Galactic dwarfs, as their colors align with those expected for stars that have transitioned off the red dwarf branch. Additionally, we observe a significant presence of faint blue objects surrounding the cluster, which may also be part of it. By combining these candidates with previous ground-based data, we constructed color-brightness diagrams for various annuli extending up to 5 arcminutes from the cluster center. Our analysis suggests that the cluster possesses an extended halo containing several hundred faint stars beyond its tidal boundary.",
        "ori-fast-z-score": -0.4472135954999579,
        "water-fast-z-score": 4.2485291572496005,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "The book is divided into three parts, each part containing several chapters. The first two parts are devoted to the development and analysis of geometric control systems in finite-dimensional spaces (the state space) and infinite-dimensional Hilbert spaces (the phase space). In particular, the following topics are considered:\n\nPart I - Geometric Control Theory in Finite-Dimensional Spaces.\n\nChapter 1 - Introduction to Geometric Control Theory.\n Chapter 2 - Basic Concepts of Differential Geometry.\n Chapter 3 - Lie Groups and Their Representations.\n Chapter 4 - Invariant Manifolds for Group Actions on Vector Fields.\n Chapter 5 - Stability Analysis of Nonlinear Systems with State Constraints.\n Chapter 6 - Stabilization by Feedback of Linear Time-Invariant Systems.\n Chapter 7 - Optimal Tracking Problems for Affine Systems.\n Part II - Geometric Control Theory on Infinite-Dimensional Hilbert Spaces.\n\n Chapter 8 - Generalized Euler-Lagrange Equations.\n Chapter 9 - Hamilton-Jacobi Equations.\n Chapter 10 - Pontryagin Maximum Principle.\n Chapter 11 - Optimal Control Problem for Discrete-Time Systems.\n Chapter 12 - Optimal Control Problem with Uncertain Dynamics.\n Chapter 13 - Optimal Control Problem under Stochastic Disturbances.\n Chapter 14 - Optimal Control Problem over Networks.\n Part III - Applications of Geometric Control Theory.\n\n Chapter 15 - Motion Planning for Mobile Robots.\n Chapter 16 - Robot Manipulation Tasks via Task Space Formulation.\n Chapter 17 - Visual Servoing Based on Image Feature Extraction.\n Chapter 18 - Model Predictive Control for Industrial Processes.",
        "watermark_text": "The treatise is separated into three sections , each portion containing several chapters . The first two parts are devoted to the development and evaluation of geometric control networks in finite - dimensional spaces ( the state space ) and infinite - dimensional Hilbert spaces ( the phase space ) .In particular , the following topics are considered : Part I - Geometric Control Theory in Finite - Dimensional Spaces . Chapter 1 - Introduction to Geometric Control Theory .Chapter 2 - Basic Concepts of Differential Geometry . Chapter 3 - Lie Groups and Their Representations .Chapter 4 - Invariant Manifolds for Group Actions on Vector Fields . Chapter 5 - Stability Analysis of Nonlinear Systems with State Constraints .Chapter 6 - Stabilization by Feedback of Linear Time - Invariant Systems . Chapter 7 - Optimal Tracking Problems for Affine Systems .Part II - Geometric Control Theory on Infinite - Dimensional Hilbert Spaces . Chapter 8 - Generalized Euler - Lagrange Equations .Chapter 9 - Hamilton - Jacobi Equations . Chapter 10 - Pontryagin Maximum Principle .Chapter 11 - Optimal Control Problem for Discrete - Time Systems . Chapter 12 - Optimal Control Problem with Uncertain Dynamics .Chapter 13 - Optimal Control Problem under Stochastic Disturbances . Chapter 14 - Optimal Control Problem over Networks .Part III - Applications of Geometric Control Theory . Chapter 15 - Motion Planning for Mobile Robots .Chapter 16 - Robot Manipulation Tasks via Task Space Formulation . Chapter 17 - Visual Servoing Based on Image Feature Extraction .Chapter 18 - Model Predictive Control for Industrial Processes .",
        "rewrite_text": "The treatise is divided into three sections, each comprising several chapters. The first two sections focus on the development and assessment of geometric control networks within finite-dimensional spaces (the state space) and infinite-dimensional Hilbert spaces (the phase space). Specifically, the topics addressed include: \n\n**Part I - Geometric Control Theory in Finite-Dimensional Spaces**:\n- Chapter 1: Introduction to Geometric Control Theory\n- Chapter 2: Fundamental Concepts of Differential Geometry\n- Chapter 3: Lie Groups and Their Representations\n- Chapter 4: Invariant Manifolds for Group Actions on Vector Fields\n- Chapter 5: Stability Analysis of Nonlinear Systems with State Constraints\n- Chapter 6: Stabilization of Linear Time-Invariant Systems through Feedback\n- Chapter 7: Optimal Tracking Problems for Affine Systems\n\n**Part II - Geometric Control Theory in Infinite-Dimensional Hilbert Spaces**:\n- Chapter 8: Generalized Euler-Lagrange Equations\n- Chapter 9: Hamilton-Jacobi Equations\n- Chapter 10: Pontryagin Maximum Principle\n- Chapter 11: Optimal Control Problems for Discrete-Time Systems\n- Chapter 12: Optimal Control Problems with Uncertain Dynamics\n- Chapter 13: Optimal Control Problems under Stochastic Disturbances\n- Chapter 14: Optimal Control Problems over Networks\n\n**Part III - Applications of Geometric Control Theory**:\n- Chapter 15: Motion Planning for Mobile Robots\n- Chapter 16: Robot Manipulation Tasks Using Task Space Formulation\n- Chapter 17: Visual Servoing through Image Feature Extraction\n- Chapter 18: Model Predictive Control for Industrial Processes",
        "ori-fast-z-score": -1.414213562373095,
        "water-fast-z-score": -0.13736056394868904,
        "rewrite-fast-z-score": -1.6641005886756874
    },
    {
        "original_text": "We present the first 3D kinematic analysis of an isolated supergranule in the photosphere using high-resolution observations obtained with Hinode/SOT and SDO/HMI instruments. The results show that the observed supergranule is characterized by a strong upflow at its center, surrounded by weaker downflows. We find that the horizontal flow pattern consists of two counter-rotating cells which are connected to each other through a narrow channel along their common boundary. This structure resembles the magnetic topology of a bipolar sunspot pair. In addition we observe a small-scale vortex-like feature located on one side of the central upflow region. Our study shows that the observed supergranulation pattern can be explained as a result of convective motions driven by the solar differential rotation. Keywords: Solar activity, Sunspots, Photometry, Magnetism, Granulation, Convection, Dynamo theory, Magnetic fields",
        "watermark_text": "We present the first 3D kinematic analysis of an exposed supergranule in the photosphere using high - resolution measurements obtained with Hinode / SOT and SDO / HMI instruments . The results show that the known supergranule is characterized by a powerful upflow at its core , flanked by softer downflows .We see that the horizontal flow pattern consists of two counter - spinning chambers which are connected to each other through a thin channel along their common boundary . This structure follows the magnetic topology of a bipolar sunspot couple .In addition we study a small - scale vortex - like feature centered on one end of the main upflow center . Our study shows that the seen supergranulation rhythm can be described as a outcome of convective movements driven by the solar differential rotation .Keywords : Solar influence , Sunspots , Photometry , Magnetism , Granulation , Convection , Dynamo theory , Magnetic fields",
        "rewrite_text": "We present the inaugural 3D kinematic analysis of an exposed supergranule in the photosphere, utilizing high-resolution data obtained from the Hinode/SOT and SDO/HMI instruments. Our findings reveal that the identified supergranule is distinguished by a strong upflow at its center, surrounded by gentler downflows. The horizontal flow pattern exhibits two counter-rotating chambers linked by a narrow channel at their shared boundary, which aligns with the magnetic topology of a pair of bipolar sunspots. Additionally, we investigate a small-scale, vortex-like feature situated at one end of the primary upflow region. Our research indicates that the observed rhythm of supergranulation can be explained as a result of convective motions driven by solar differential rotation. Keywords: Solar influence, Sunspots, Photometry, Magnetism, Granulation, Convection, Dynamo theory, Magnetic fields.",
        "ori-fast-z-score": -0.39056673294247163,
        "water-fast-z-score": 5.858500994137074,
        "rewrite-fast-z-score": 0.5345224838248488
    },
    {
        "original_text": "We present the results of our analysis of molecular gas mass estimates based on CO and HCN observations in nearby galaxies, using data obtained with the IRAM 30m telescope. We find that conversion factors between luminosity and mass are strongly dependent on the star formation rate (SFR) per unit area within each galaxy disk. The SFR surface density is found to be an important parameter controlling the conversion factor XCO = M(H2)/L(CO), which we derive by fitting the observed L(HCN) / L(CO) ratio versus metallicity relation. For low values of ΣSFR < 1M⊙ yr-1 kpc-2 , corresponding to quiescent disks or nuclear regions dominated by old stellar populations, we obtain XCO ≈ 2 × 10 20 cm−2 K−1 km−1 s. This value increases up to XCO ≈ 5×10 20 cm−2 K−1km−1s at high ΣSFR > 3M⊙yr-1kpc-2 . These findings suggest that the physical conditions of the interstellar medium may change significantly depending on whether it is located in actively star-forming regions or not.",
        "watermark_text": "We publish the conclusion of our analysis of molecular gas mass estimates based on CO and HCN measurements in nearby galaxies , using data derived with the IRAM 30m telescope . We see that conversion factors between luminosity and mass are strongly dependent on the star formation rate ( SFR ) per unit area within each galaxy disk .The SFR ground density is found to be an important function regulating the transformation parameter XCO = M ( H2 ) / L ( CO ) , which we derive by fitting the seen L ( HCN ) / L ( CO ) ratio versus metallicity relation . For low values of ΣSFR < [UNK] yr - 1 kpc - 2 , equivalent to quiescent disks or atomic regions dominated by ancient stars populations , we obtain XCO ≈ 2 × 10 20 cm−2 K−1 km−1 s . This value rises up to XCO ≈ 5×10 20 cm−2 K−1km−1s at high ΣSFR > [UNK] - 1kpc - 2 .These studies imply that the physical conditions of the interstellar material may change considerably depending on whether it is situated in actively star - creating areas or not .",
        "rewrite_text": "We present the findings of our analysis regarding molecular gas mass estimates derived from CO and HCN measurements in nearby galaxies, utilizing data obtained from the IRAM 30m telescope. Our results indicate that the conversion factors between luminosity and mass are significantly influenced by the star formation rate (SFR) per unit area within each galaxy's disk. We have determined that the SFR surface density plays a crucial role in regulating the conversion parameter \\(X_{CO} = \\frac{M(H_2)}{L(CO)}\\), which we calculate by fitting the observed \\( \\frac{L(HCN)}{L(CO)} \\) ratio to the metallicity relation. For low values of \\( \\Sigma_{SFR} < [UNK] \\, \\text{yr}^{-1} \\, \\text{kpc}^{-2} \\), which correspond to quiescent disks or atomic regions dominated by older star populations, we find \\(X_{CO} \\approx 2 \\times 10^{20} \\, \\text{cm}^{-2} \\, \\text{K}^{-1} \\, \\text{km}^{-1} \\, \\text{s}\\). In contrast, this value increases to \\( X_{CO} \\approx 5 \\times 10^{20} \\, \\text{cm}^{-2} \\, \\text{K}^{-1} \\, \\text{km}^{-1} \\, \\text{s} \\) for higher surface densities of \\( \\Sigma_{SFR} > [UNK] \\, \\text{yr}^{-1} \\, \\text{kpc}^{-2} \\). These findings suggest that the physical conditions of interstellar material can vary significantly depending on whether it is located in regions of active star formation.",
        "ori-fast-z-score": 0.8307471607356973,
        "water-fast-z-score": 5.815230125149881,
        "rewrite-fast-z-score": 0.10369516947304253
    },
    {
        "original_text": "We report on the observation of electron doping in cuprate superconductors by interfacing them to manganite insulators through epitaxial growth and chemical bonding at interfaces.  The interface between La0.7Sr0.3MnO3 (LSMO) and YBa2Cu3O6+x (YBCO), which are both parent compounds for high temperature superconductivity, is found to be highly conducting despite the large lattice mismatch between LSMO and YBCO. This suggests that charge transfer across the interface occurs due to strong electronic hybridization rather than strain relaxation alone. We also find that the hole concentration in the YBCO layer can be controlled by varying the thickness of the LSMO layer grown on top of it. These results demonstrate an alternative approach towards engineering the carrier density in cuprate superconductors using oxide heterostructures. High-temperature superconductivity has been observed only in materials containing copper-oxygen planes known as CuO2 layers  1  . In these systems, holes doped into the CuO2 plane give rise to Cooper pairs leading to superfluidity  2  . However, the maximum critical temperature Tc = 92 K achieved so far in this class of materials is still well below the theoretical limit predicted by Bardeen-Cooper-Schrieffer theory  3  , raising questions about how to further enhance Tc  4  .\nIn recent years there have been significant efforts made to explore new routes toward enhancing Tc beyond its current record value  5  . One promising route involves introducing electrons into the CuO2 plane  6  . For example, replacing oxygen atoms in the CuO2 plane with fluorine leads to a reduction in the number of holes in the system  7, 8  . Alternatively, one may introduce electrons directly into the CuO2 plane by growing thin films of transition metal oxides such as SrTiO3  9  or LaAlO3  10  onto the surface of cuprate superconductors. While these approaches show promise, they require precise control over film composition and structure during deposition  11  . An alternative strategy would involve controlling the carrier density in cuprates without changing their crystal structures  12  .",
        "watermark_text": "We report on the observation of electron doping in cuprate superconductors by interfacing them to manganite insulators through epitaxial growth and chemical bonding at connections . The interface between La0 . 7Sr0 . 3MnO3 ( LSMO ) and YBa2Cu3O6 + x ( YBCO ) , which are both parent molecules for high heat superconductivity , is found to be highly conducting despite the huge lattice mismatch between LSMO and YBCO .This implies that charge transfer across the interface comes driven to strong electronic hybridization instead than strain relaxation alone . We additionally find that the gap concentration in the YBCO layer can be determined by varying the height of the LSMO layer grown on top of it .These data demonstrate an additional method towards engineering the carrier density in cuprate superconductors using oxide heterostructures . High - temperature superconductivity has been observed only in structures carrying copper - oxygen planes known as CuO2 layers 1 .In these systems , holes doped into the CuO2 plane give rise to Cooper pairs leading to superfluidity 2 . However , the maximum essential temperature Tc = 92 K attained so far in this class of substances is already much below the theoretical maximum expected by Bardeen - Cooper - Schrieffer model 3 , placing questions about how to further enhance Tc 4 .In recent seasons there have been significant efforts made to pursue new routes toward promoting Tc beyond its current record value 5 . One promising route includes introducing electrons into the CuO2 plane 6 .For instance , replacing oxygen atoms in the CuO2 plane with fluorine leads to a reduction in the number of holes in the system 7 , 8 . Alternatively , one may introduce electrons directly into the CuO2 plane by expanding narrow bands of transition iron oxides such as SrTiO3 9 or LaAlO3 10 onto the surface of cuprate superconductors .While these models show success , they demand exact power over movie structure and shape during deposition 11 . An alternative approach would include governing the carrier density in cuprates without altering their crystal structures 12 .",
        "rewrite_text": "We present our findings on electron doping in cuprate superconductors achieved by integrating them with manganite insulators through epitaxial growth and chemical bonding at their interfaces. The junction between La0.7Sr0.3MnO3 (LSMO) and YBa2Cu3O6+x (YBCO), both fundamental compounds for high-temperature superconductivity, exhibits remarkable conductivity despite a significant lattice mismatch. This suggests that the charge transfer at the interface is primarily driven by strong electronic hybridization rather than just strain relaxation. Moreover, we discovered that varying the thickness of the LSMO layer on top of the YBCO allows for control over the gap concentration in the YBCO layer. This research offers an innovative strategy for engineering carrier density in cuprate superconductors utilizing oxide heterostructures. High-temperature superconductivity has only been observed in materials featuring copper-oxygen planes, known as CuO2 layers. In these systems, holes introduced into the CuO2 plane create Cooper pairs, resulting in superfluidity. However, the highest critical temperature (Tc) recorded thus far in this category of materials is 92 K, which is significantly lower than the theoretical peak predicted by the Bardeen-Cooper-Schrieffer model, raising questions about pathways to further elevate Tc. In recent years, substantial efforts have been made to explore new strategies to raise Tc beyond its current maximum. One promising approach involves incorporating electrons into the CuO2 plane. For example, substituting oxygen atoms in the CuO2 plane with fluorine decreases the hole concentration. Alternatively, electrons can be directly introduced into the CuO2 plane by expanding narrow bands of transition metal oxides, such as SrTiO3 or LaAlO3, onto the surfaces of cuprate superconductors. While these strategies have yielded some success, they require precise control over the film structure and morphology during deposition. A different approach would be to manipulate the carrier density in cuprates without modifying their crystal structures.",
        "ori-fast-z-score": 0.33567254331867563,
        "water-fast-z-score": 7.7754191435023525,
        "rewrite-fast-z-score": 1.979524821394902
    },
    {
        "original_text": "In this article, we study families of holomorphic vector bundles on complex algebraic varieties. We prove that the set of isomorphism classes of such families is naturally an affine scheme over the base variety and give explicit equations for it in terms of Chern classes.  In particular, if the base variety has dimension one then these schemes are reduced to points corresponding to the rank and degree of each bundle in the family. \nWe also show how our results can be used to construct moduli spaces of stable vector bundles with fixed determinant. The main result of this article was announced by J. P. Serre at the conference  Algebraic geometry and number theory  held in Paris in June 2005 (see  Ser  ). Families of holomorphic vector bundles have been studied extensively since the work of Grothendieck  Gro1  . They play important roles both in algebraic geometry and mathematical physics; see e.g.,  Bri1,  Bri2,   Bri3,   ...",
        "watermark_text": "In this page , we study families of holomorphic vector bundles on complex algebraic varieties . We prove that the group of isomorphism classes of such families is naturally an affine scheme over the base variety and take explicit equations for it in terms of Chern classes .In particular , if the base range has size one then these schemes are converted to points corresponding to the rank and degree of each bundle in the class . We also demonstrate how our findings can be used to build moduli spaces of stable vector bundles with constant determinant .The main result of this paper was announced by J . P . Serre at the meeting Algebraic geometry and number theory conducted in Paris in June 2005 ( see Ser ) . Families of holomorphic functional bundles have been studied frequently since the work of Grothendieck Gro1 .They play essential roles both in mathematical mathematics and mathematical science ; seeing e . g . , Bri1 , Bri2 , Bri3 , . . .",
        "rewrite_text": "In this paper, we investigate families of holomorphic vector bundles over complex algebraic varieties. We demonstrate that the group of isomorphism classes of these families naturally forms an affine scheme over the base variety, providing explicit equations in terms of Chern classes. Notably, when the base variety consists of a single point, these schemes simplify to points that reflect the rank and degree of each bundle in the class. Additionally, we illustrate how our results can be applied to construct moduli spaces of stable vector bundles with a constant determinant. The main theorem presented here was initially announced by J. P. Serre at the Algebraic Geometry and Number Theory conference held in Paris in June 2005 (see Ser). Since Grothendieck's work (Gro1), families of holomorphic vector bundles have been extensively studied and have significant implications in both pure mathematics and mathematical science, as demonstrated in works such as Bri1, Bri2, and Bri3, among others.",
        "ori-fast-z-score": -1.116312611302876,
        "water-fast-z-score": 4.341215710622296,
        "rewrite-fast-z-score": 0.25
    },
    {
        "original_text": "The projectile fragmentation of 86Kr at 64MeV/nucleon has been studied with the INDRA multidetector in inverse kinematics using an 8cm thick natK target and a beam intensity of 1nAe. The main results are as follows:  - A total number of about 10000 events have been recorded for this experiment.  - The charge distribution is peaked around Z=40, but shows also a large contribution between 30 and 40 charges units (see fig.1 ). This indicates that the fragments produced by the break-up of 86Kr are not only light particles like neutrons or protons, but contain many intermediate mass fragments too.   - The angular distributions show two peaks corresponding to forward and backward emission respectively (see fig.2 ).  - The energy spectra present a maximum around 10-12 MeV/u which corresponds to the most probable kinetic energy per nucleon of the emitted fragments (see fig.3 ).\n- The isotopic composition of the fragments is shown on figure 4 . It can be seen that there is no significant difference between the fragment production in the forward hemisphere and in the backward one.",
        "watermark_text": "The projectile fragmentation of 86Kr at 64MeV / nucleon has been studied with the INDRA multidetector in inverse kinematics using an 8cm thick natK target and a laser intensity of 1nAe . The main results are as follows : - A total quantity of about 10000 events have been observed for this study .- The charge distribution is peaked around Z = 40 , but shows also a large contribution between 30 and 40 charges units ( view fig . 1 ) . This implies that the fragments produced by the broken - up of 86Kr are not only light particles like neutrons or protons , but contain many intermediate mass pieces too .- The angular distributions show two peaks related to forward and back emission respectively ( see fig . 2 ) . - The energy spectra produce a maximum around 10 - 12 MeV / u which equals to the most likely kinetic power per nucleon of the emitted objects ( see fig . 3 ) .- The isotopic structure of the fragments is displayed on figure 4 . It can be shown that there is no major variation between the fragment production in the front hemisphere and in the backward one .",
        "rewrite_text": "The projectile fragmentation of 86Kr at 64 MeV per nucleon has been investigated using the INDRA multidetector in inverse kinematics with an 8 cm thick natK target and a laser intensity of 1 nA. Key findings from this study include: approximately 10,000 events were recorded; the charge distribution is centered around Z = 40, with a notable contribution of fragments possessing 30 to 40 charge units (see Fig. 1). This indicates that the fragments resulting from the breakup of 86Kr consist not only of light particles such as neutrons and protons but also include a significant number of intermediate-mass components. The angular distributions exhibit two distinct peaks corresponding to forward and backward emissions (see Fig. 2). Additionally, the energy spectra show a maximum in the range of 10 to 12 MeV/u, reflecting the most likely kinetic energy per nucleon of the emitted fragments (see Fig. 3). The isotopic composition of the fragments is illustrated in Fig. 4, demonstrating that there is no significant difference in fragment production between the front and rear hemispheres.",
        "ori-fast-z-score": -0.3611575592573076,
        "water-fast-z-score": 4.935819976516537,
        "rewrite-fast-z-score": 0.35603449745815596
    },
    {
        "original_text": "In this work, we propose a novel cross-layer scheme to improve the performance of distributed wireless ad hoc networks (DWAHNs). The proposed scheme is based on an adaptive routing protocol and a dynamic channel allocation algorithm. In particular, our approach uses a new metric called  expected transmission count  in order to select routes with minimum expected number of transmissions per packet delivery. Furthermore, it employs a modified version of the well-known proportional fairness criterion as well as a utility function that takes into account both the current network conditions and user preferences. Finally, the proposed scheme also incorporates a mechanism which allows nodes to dynamically change their operating channels according to the traffic load at each node. Extensive simulation experiments are conducted using NS-2 simulator to evaluate the effectiveness of the proposed scheme under different scenarios. Results show that the proposed scheme outperforms existing approaches by achieving higher throughput while maintaining low end-to-end delay and packet loss rate.",
        "watermark_text": "In this project , we propose a new cross - layer scheme to upgrade the performance of distributed wireless ad hoc networks ( DWAHNs ) . The proposed system is based on an dynamic routing mechanism and a dynamic channel allocation algorithm .In particular , our approach utilizes a new metric termed expected broadcast count in order to select routes with minimum expected number of transmissions per packet transmission . Furthermore , it employs a altered version of the better - famous proportional fairness factor as well as a utility function that takes into consideration both the present connection conditions and customer choices .Finally , the suggested system also contains a process which allows nodes to dynamically change their operating networks according to the traffic burden at each node . Extensive model studies are performed using NS - 2 simulator to analyze the performance of the suggested system under various circumstances .Results show that the suggested system outperforms previous techniques by achieving larger throughput while maintaining low end - to - end delay and packet loss rate .",
        "rewrite_text": "In this project, we introduce a novel cross-layer approach aimed at enhancing the performance of distributed wireless ad hoc networks (DWAHNs). Our proposed system incorporates a dynamic routing mechanism alongside a dynamic channel allocation algorithm. Specifically, we utilize a new metric called expected broadcast count to identify routes that minimize the expected number of transmissions for each packet sent. Additionally, our method incorporates a modified version of the well-known proportional fairness factor and a utility function that considers both current connection conditions and user preferences. Moreover, the system features a process enabling nodes to adaptively alter their operating networks based on the traffic load at each node. Comprehensive modeling studies using the NS-2 simulator have been conducted to evaluate the performance of the proposed system under various scenarios. The results demonstrate that our approach outperforms existing techniques by achieving higher throughput while maintaining low end-to-end delays and reduced packet loss rates.",
        "ori-fast-z-score": -0.9138115486202573,
        "water-fast-z-score": 6.869037302955033,
        "rewrite-fast-z-score": 0.8251369970070347
    },
    {
        "original_text": "The present study investigates the structural properties of Early Modern English syntax by applying network analysis to data obtained through corpus linguistics techniques. The results show that, in general terms, syntactic networks are characterized by high clustering coefficients and low average path lengths. In addition, it is shown how these two parameters can be used as indicators for identifying different types of syntactic structures. Finally, some possible applications of this approach are discussed. Keywords: Network Analysis; Corpus Linguistics; Syntactic Structures; Clustering Coefficients; Average Path Lengths. 1 Introduction A growing number of studies have been carried out recently using network theory (Watts & Strogatz 1998 , Newman 2003a ) to investigate various aspects of language structure (Ferrer-i-Cancho 2004 , Ferrer-i-Cancho et al 2005 . These investigations have mainly focused on phonological systems (e.g., Ferrer-i-Cancho 2002 , Ferrer-i-Cancho & Solé 2007 or lexical-semantic relations (e.g., Steyvers & Tenenbaum 2005 ) . However, there has also been interest in exploring other linguistic levels such as morphosyntax (Ferrer-i-Canchos 2006 ) , prosody (Ferrer-i-Canchós 2008) , pragmatics (Ferrer-i-Canchis 2009) or even discourse (Ferrer-i-Canchi 2010) . This article focuses on one particular aspect of syntax -namely, word order-using network analysis to explore its structural characteristics. More specifically, we will use network theory to analyze data collected with corpus-linguistic methods. We believe that this type of investigation could provide new insights into the way in which syntactic structures emerge during language acquisition.",
        "watermark_text": "The present research investigates the structural aspects of Early Modern English syntax by using network studies to data acquired through corpus linguistics tools . The results show that , in general terms , syntactic groups are marked by high clustering coefficients and low mean route distances .In addition , it is demonstrated how these two parameters can be used as indicators for determining particular kinds of syntactic properties . Finally , some possible users of this methodology are discussed .Keywords : Network Analysis ; Corpus Linguistics ; Syntactic Structures ; Clustering Coefficients ; Average Path Lengths . 1 Introduction A growing number of studies have been carried out recently utilizing system theory ( Watts & Strogatz 1998 , Newman 2003a ) to examine different components of word construction ( Ferrer - i - Cancho 2004 , Ferrer - i - Cancho et al 2005 .These studies have chiefly centered on phonological systems ( e . g . , Ferrer - i - Cancho 2002 , Ferrer - i - Cancho & Solé 2007 or lexical - linguistic relations ( e . g . , Steyvers & Tenenbaum 2005 ) . However , there has additionally been focus in investigating other linguistic levels such as morphosyntax ( Ferrer - i - Canchos 2006 ) , prosody ( Ferrer - i - Canchós 2008 ) , pragmatics ( Ferrer - i - Canchis 2009 ) or especially discourse ( Ferrer - i - Canchi 2010 ) .This page focuses on one special aspect of syntax - namely , word order - using network theory to examine its structural traits . More specifically , we will use network theory to analyze information collected with corpus - linguistic methods .We believe that this form of investigation could give novel discoveries into the way in which syntactic formations emerge during language acquire .",
        "rewrite_text": "This research explores the structural features of Early Modern English syntax by applying network analysis to data obtained through corpus linguistics tools. The findings indicate that, generally speaking, syntactic groups exhibit high clustering coefficients and short average path lengths. Furthermore, the study demonstrates how these two metrics can serve as indicators for identifying specific syntactic properties. Finally, potential applications of this methodology are discussed. \n\nKeywords: Network Analysis; Corpus Linguistics; Syntactic Structures; Clustering Coefficients; Average Path Lengths.\n\n1. Introduction \n\nRecently, an increasing number of studies have employed systems theory (Watts & Strogatz 1998; Newman 2003a) to investigate various aspects of word formation (Ferrer-i-Cancho 2004; Ferrer-i-Cancho et al. 2005). These studies have primarily focused on phonological systems (e.g., Ferrer-i-Cancho 2002; Ferrer-i-Cancho & Solé 2007) or lexical and linguistic relationships (e.g., Steyvers & Tenenbaum 2005). Additionally, attention has been directed towards other linguistic levels, including morphosyntax (Ferrer-i-Cancho 2006), prosody (Ferrer-i-Cancho 2008), pragmatics (Ferrer-i-Cancho 2009), and particularly discourse (Ferrer-i-Cancho 2010). This paper hones in on a specific aspect of syntax—word order—utilizing network theory to analyze its structural characteristics. More precisely, we will leverage network theory to examine data gathered through corpus-linguistic methodologies. We believe that this approach could yield new insights into how syntactic structures develop during language acquisition.",
        "ori-fast-z-score": -0.8620436566990363,
        "water-fast-z-score": 8.158801243801019,
        "rewrite-fast-z-score": -0.29851115706299675
    },
    {
        "original_text": "We present new measurements of rotational widths (W20) and surface brightnesses (SB) for a sample of galaxies with inclinations between 30°and 80°, drawn from the Sloan Digital Sky Survey Data Release 7. We find that W20 is correlated strongly with SB at fixed luminosity, but only weakly or not at all with galaxy mass. This correlation persists even when we restrict our analysis to late-type spirals, which are known to have flat rotation curves. These results suggest that the observed scatter in the Tully-Fischer relation may be due primarily to variations in SB among galaxies of similar luminosities rather than differences in their masses. In addition, we show that this effect can explain why previous studies found no significant dependence on inclination angle in the TF relation. Finally, we demonstrate how these correlations affect estimates of the Hubble constant derived using the TF relation. Our findings also provide an explanation for the apparent discrepancy between the values obtained by different authors who used samples selected over different ranges of inclination angles.",
        "watermark_text": "We present new measurements of rotational widths ( W20 ) and surface brightnesses ( SB ) for a sample of galaxies with inclinations between 30°and 80° , obtained from the Sloan Digital Sky Survey Data Release 7 . We see that W20 is associated strongly with SB at fixed luminosity , but only strongly or not at all with star mass .This correlation persists even when we limit our analysis to late - class spirals , which are known to have flattened rotation curves . These conclusions show that the seen scatter in the Tully - Fischer relation might be due primarily to variations in SB among galaxies of comparable luminosities rather than differences in their masses .In addition , we prove that this effect can reason why previous research found no considerable dependence on tilt angle in the TF relation . Finally , we prove how these correlations influence estimates of the Hubble constant calculated using the TF relation .Our findings also suggest an reason for the alleged discrepancy between the estimates obtained by various scientists who used data selected over particular ranges of inclination distances .",
        "rewrite_text": "We present new measurements of rotational widths (W20) and surface brightnesses (SB) for a sample of galaxies with inclinations ranging from 30° to 80°, drawn from the Sloan Digital Sky Survey Data Release 7. Our analysis reveals a strong association between W20 and SB at fixed luminosity, while the connection with stellar mass is either weak or non-existent. This correlation remains robust even when we focus solely on late-type spirals, which are characterized by their flattened rotation curves. These findings suggest that the observed scatter in the Tully-Fisher relation may primarily result from variations in SB among galaxies with similar luminosities, rather than from differences in their masses. Furthermore, we demonstrate that this effect could explain why previous studies have found little significant dependence on tilt angle within the Tully-Fisher relation. Lastly, we discuss how these correlations impact the estimation of the Hubble constant derived from the Tully-Fisher relation, and we offer a potential explanation for the alleged discrepancies observed in estimates made by different researchers using data selected over specific ranges of inclination distances.",
        "ori-fast-z-score": -1.5215349135496974,
        "water-fast-z-score": 5.7350162126103985,
        "rewrite-fast-z-score": 0.3418817293789138
    },
    {
        "original_text": "We present the results of an extensive study of gas dynamics, star formation activity, dust extinction, stellar populations, and black hole accretion properties for a strongly lensed galaxy (A1689-zD1) at redshift 3.07. The lensing magnification factor is ~30Â±5. We use deep near-infrared spectroscopy to measure the kinematics of molecular hydrogen emission lines with high spatial resolution. Our observations reveal that this system consists of two merging galaxies separated by 1 kpc along the line-of-sight. One of these components shows strong HÎ² emission indicative of active galactic nuclei (AGN). This AGN component has a mass of âˆ¼10^9 M_sol , which corresponds to a supermassive black hole with a mass of âˆ½â€“1 Ã— 10^8 M_sol . Using our spatially resolved measurements we find evidence for intense nuclear starbursts on scales as small as 100 pc.",
        "watermark_text": "We present the conclusion of an extensive research of gas evolution , star formation activity , dust disappearance , stars populations , and dark hole accretion properties for a strongly lensed galaxy ( A1689 - zD1 ) at redshift 3 . 07 . The lensing magnification factor is ~ 30Â±5 .We use deep near - infrared spectroscopy to measure the kinematics of molecular hydrogen emission lines with high visual resolution . Our observations show that this scheme consists of two joining galaxies linked by 1 kpc along the line - of - view .One of these constituents exhibits strong HÎ² emission indicative of active galactic nuclei ( AGN ) . This AGN component has a mass of [UNK] ^ 9 M _ sol , which corresponds to a supermassive black hole with a mass of [UNK] “ 1 [UNK] — 10 ^ 8 M _ sol .Using our spatially resolved sensors we find proof for intense nuclear starbursts on sizes as low as 100 pc .",
        "rewrite_text": "We present the conclusions drawn from a comprehensive study of gas evolution, star formation activity, dust depletion, stellar populations, and black hole accretion properties in the strongly lensed galaxy A1689-zD1 at a redshift of 3.07, with a lensing magnification factor of approximately 30±5. Utilizing deep near-infrared spectroscopy, we analyzed the kinematics of molecular hydrogen emission lines at high spatial resolution. Our findings reveal that the galaxy comprises two interconnected components, separated by 1 kpc along the line of sight. One of these components displays strong Hβ emission, signifying the presence of an active galactic nucleus (AGN). The AGN component is estimated to have a mass of about 10^9 M_sol, which aligns with a supermassive black hole mass of 1–10^8 M_sol. Through our spatially resolved observations, we have also identified evidence of vigorous nuclear starbursts occurring over scales as small as 100 pc.",
        "ori-fast-z-score": 0.2581988897471611,
        "water-fast-z-score": 5.505585837114527,
        "rewrite-fast-z-score": 0.508000508000762
    },
    {
        "original_text": "We study the gravitational instability (GI) in two differentially rotating, self-gravitating disks with and without magnetic fields using three-dimensional hydrodynamic simulations. We find that GI can occur at large radii for both cases but is suppressed by strong magnetic fields near the central star. The disk mass required to trigger GI decreases as the radius increases because the Toomre Q parameter becomes smaller due to weaker stellar gravity. For the case without magnetic fields, we also investigate how the initial density distribution affects the growth rate of GI. Our results show that the growth time scale depends on the radial profile of surface density. In addition, we examine whether or not GI leads to fragmentation. Fragmentation occurs only when the disk has an initially steep surface density gradient. Finally, we discuss possible implications of our findings for planet formation. Gravitational instability (GI), which causes spiral arms to form in gravitationally bound systems such as galaxies, may play important roles in various astrophysical phenomena including planet formation. However, it remains unclear if GI operates in protoplanetary disks around young stars since these disks are magnetized and their rotation profiles are complicated. Here, we perform 3D hydrodynamical simulations to explore this issue.",
        "watermark_text": "We explore the gravitational instability ( GI ) in two differentially rotating , self - gravitating disks with and without magnetic fields using three - dimensional hydrodynamic simulations . We see that GI can occur at large radii for both cases but is suppressed by intense magnetic waves near the main star .The disk mass needed to stimulate GI decreases as the radius increases because the Toomre Q function decreases smaller due to smaller stellar gravitational . For the case without magnetic fields , we also investigate how the early density function affects the development frequency of GI .Our results show that the development time scale depends on the radial profile of surface density . In addition , we investigate whether or not GI contributes to fragmentation .Fragmentation happens only when the disk has an initially steep surface velocity slope . Finally , we explain possible possibilities of our findings for planet development .Gravitational instability ( GI ) , which causes spiral arms to form in gravitationally locked components such as galaxies , might play important roles in different astrophysical processes including planet development . However , it remains unsure if GI exists in protoplanetary disks around old planets since these disks are magnetized and their rotation relationships are intricate .Here , we perform 3D hydrodynamical simulations to examine this question .",
        "rewrite_text": "We investigate gravitational instability (GI) in differentially rotating, self-gravitating disks with and without magnetic fields through three-dimensional hydrodynamic simulations. Our findings indicate that GI can occur at large radii in both scenarios, but intense magnetic waves near the central star suppress its development. As the radius increases, the disk mass required to trigger GI decreases due to a reduction in the Toomre Q function, influenced by weaker stellar gravity. In the absence of magnetic fields, we also analyze how the initial density distribution impacts the frequency of GI development. Our results demonstrate that the timescale for development is influenced by the radial profile of the surface density. We further explore whether GI leads to fragmentation, which occurs only when there is a steep initial slope in surface velocity within the disk. Lastly, we discuss the implications of our findings for planet formation. Gravitational instability, known to induce the formation of spiral arms in gravitationally bound structures like galaxies, may be significant in various astrophysical processes, including planet development. However, the existence of GI in protoplanetary disks around mature planets remains uncertain due to the complexities of magnetized conditions and rotational relationships. In this study, we utilize 3D hydrodynamic simulations to address this issue.",
        "ori-fast-z-score": -0.9901475429766744,
        "water-fast-z-score": 6.534973783646051,
        "rewrite-fast-z-score": 1.6329931618554523
    },
    {
        "original_text": "We study droplet excitations in the 2D spin-glass model with nearest-neighbor interactions and random ferromagnetic bonds, which is known to have an infinite number of metastable states at zero temperature. We show that this system has two different types of droplets: small ones are similar to those found in other models studied previously; large droplets are characterized by their fractal structure. The latter type can be viewed as a generalization of the droplet picture proposed earlier for the 3D Ising spin glasses. In addition we find that there exists another class of excitations -the so-called  giant droplets -which are not present in any of these systems. These giant droplets are responsible for the non-universal behavior observed numerically near the critical point. Finally, we argue that our results provide strong numerical support for the existence of a new phase transition line between the paramagnetic state and the spin-glass one. \nI. INTRODUCTORY REMARK\nThe concept of  droplet excitations  was introduced originally within the framework of the mean-field theory  1  . It describes how local perturbations affect global properties of the system. This idea turned out to be very useful when applied to various disordered systems such as spin glasses  2  , structural glasses  3  or vortex lattices  4  .\nIn particular it allowed to explain many features of the low-temperature thermodynamics of spin glasses  5  . However, despite its successes, the original droplet picture suffers from some serious drawbacks  6  : first, it does not take into account fluctuations around the saddle-point solution  7 ; secondly, it predicts a finite density of droplets even at T = 0  8  ; thirdly, it cannot describe properly the dynamics of the system  9  . To overcome these difficulties several modifications were suggested  10  . One of them  11  leads to the following expression for the free energy F(T ) per site: \nwhere f0 is the free-energy density of the reference system (e.g., the pure ferromagnet), Ns is the total number of spins, V is the volume occupied by each droplet",
        "watermark_text": "We test droplet excitations in the 2D spin - glass model with nearest - neighbor interactions and random ferromagnetic bonds , which is known to have an endless number of metastable states at zero temperature . We see that this scheme has two different kinds of droplets : tiny ones are comparable to those present in other models studied ago ; small droplets are marked by their fractal structure .The latter type can be viewed as a generalization of the droplet picture suggested earlier for the 3D Ising spin glasses . In addition we find that there exists another class of excitations - the so - called large droplets - which are not present in any of these systems .These huge droplets are responsible for the non - universal behavior observed numerically near the pivotal point . Finally , we claim that our findings provide strong mathematical support for the existence of a new phase shift line between the paramagnetic state and the spin - glass one .I . INTRODUCTORY REMARK The concept of droplet excitations was introduced originally within the framework of the mean - field principle 1 .It details how local perturbations impact global properties of the system . This idea turned out to be very useful when applied to numerous disordered systems such as spin glasses 2 , structural glasses 3 or vortex lattices 4 .In particular it able to explain many features of the small - temperature thermodynamics of spin glasses 5 . However , despite its victories , the original droplet picture suffers from some serious drawbacks 6 : first , it does not take into consideration fluctuations around the saddle - point solution 7 ; secondly , it predicts a finite concentration of droplets even at T = 0 8 ; thirdly , it lacks explain adequately the dynamics of the system 9 .To solve these problems several amendments were recommended 10 . One of them 11 leads to the following expression for the free energy F ( T ) per site : where f0 is the free - energy density of the reference system ( e . g . , the pure ferromagnet ) , Ns is the total quantity of spinning , V is the volume occupied by each droplet",
        "rewrite_text": "We investigate droplet excitations within a 2D spin-glass model characterized by nearest-neighbor interactions and random ferromagnetic bonds, which is known to display an infinite number of metastable states at absolute zero temperature. Our findings reveal two distinct types of droplets: small ones comparable to those seen in previously studied models, and small droplets exhibiting a fractal structure. The latter can be understood as an extension of the droplet framework proposed for 3D Ising spin glasses. Additionally, we identify a new category of excitations, termed large droplets, which are absent in the previously examined systems. These sizable droplets contribute to the non-universal behavior observed numerically near the critical point. Ultimately, we assert that our results provide robust mathematical evidence for the existence of a novel phase transition line separating the paramagnetic and spin-glass states. \n\nI. INTRODUCTORY REMARKS\n\nThe concept of droplet excitations was initially articulated within the mean-field theory framework. This theory elucidates how local perturbations can influence the overall properties of the system, proving particularly useful for a variety of disordered systems, including spin glasses, structural glasses, and vortex lattices. It has been instrumental in explaining numerous characteristics of spin glasses' thermodynamic behavior at low temperatures. Despite its successes, the original droplet model has significant limitations: it omits fluctuations around saddle-point solutions, predicts a finite density of droplets even at T = 0, and fails to adequately describe system dynamics. To address these shortcomings, several modifications have been proposed, one of which leads to the following expression for the free energy F(T) per site: here, f₀ is the free energy density of a reference system (such as a pure ferromagnet), Nₛ denotes the total number of spins, and V is the volume each droplet occupies.",
        "ori-fast-z-score": 1.1666666666666667,
        "water-fast-z-score": 7.72046849632954,
        "rewrite-fast-z-score": 1.3522468075656264
    },
    {
        "original_text": "We present the results for positronium ground state energy and wave function obtained by solving relativistic Schrödinger equation with Coulomb potential using variational method. The calculations are performed within two different approximations, namely nonrelativistic limit (NR) and first order perturbation theory (PT1). In NR approximation we use Hylleraas type trial wave functions which include spin dependent terms up to second power of inter particle distance. We also calculate the expectation value of kinetic energy operator using this wave function. In PT1 approximation we use Hyllraas type trial wave functions including spin dependent terms up to third power of inter particle distance alongwith one electron Dirac orbitals as basis set. Our calculated values of binding energies agree well with those reported earlier. \n\n\nThe author is grateful to Prof. S. K. Gupta, Director General, BARC, Mumbai for his encouragement during the course of work on this project.",
        "watermark_text": "We present the results for positronium ground state energy and wave function achieved by solving relativistic Schrödinger equation with Coulomb potential using variational technique . The calculations are performed within two different approximations , namely nonrelativistic limit ( NR ) and first order perturbation theory ( PT1 ) .In NR method we utilize Hylleraas kind trial wave functions which contain spin dependent terms up to second power of inter particle length . We also obtain the expectation value of kinetic power operator using this wave function .In PT1 approximation we utilize Hyllraas type trial wave parameters including spin dependent terms up to third power of inter quantum time alongwith one particle Dirac orbitals as basis set . Our measured measures of bound energies agree well with those published earlier .The author is thankful to Prof . S . K . Gupta , Director General , BARC , Mumbai for his encouragement during the course of research on this project .",
        "rewrite_text": "We present our findings on the ground state energy and wave function of positronium, obtained by solving the relativistic Schrödinger equation with a Coulomb potential through a variational technique. Our calculations were conducted under two distinct approximations: the nonrelativistic limit (NR) and first-order perturbation theory (PT1). In the NR method, we employed Hylleraas-type trial wave functions, which include spin-dependent terms up to the second power of the interparticle distance. We also calculated the expectation value of the kinetic energy operator using this wave function. In the PT1 approximation, we used Hylleraas-type trial wave parameters, incorporating spin-dependent terms up to the third power of the interquantum time, in conjunction with one-particle Dirac orbitals as our basis set. Our computed bound energy values align well with previously published results. The author expresses gratitude to Prof. S. K. Gupta, Director General of BARC, Mumbai, for his encouragement throughout the research project.",
        "ori-fast-z-score": -0.9058216273156765,
        "water-fast-z-score": 3.396831102433787,
        "rewrite-fast-z-score": -1.3242443839434612
    },
    {
        "original_text": "The Kuiper belt is the source region for most short period comets, but its formation remains poorly understood. We present results from N-body simulations that show how collisions among planetesimals in Neptune s feeding zone can produce objects with orbits similar to those observed today. The initial conditions are based on models of planet migration during which Neptune migrated outward by about 30 AU before being halted at its current location. Our calculations suggest that the Kuiper belt formed as a result of collisional grinding between bodies whose sizes were comparable to Pluto (r ~ 1000 km). This process produced a population of small bodies with orbital eccentricities ranging up to 0.3. Subsequent encounters with Neptune caused some of these bodies to be scattered into highly eccentric orbits. These results provide an explanation for why there appears to be no correlation between the size distribution of KBOs and their orbital eccentricity.",
        "watermark_text": "The Kuiper belt is the origin region for most short period comets , but its formation appears poorly known . We publish results from N - bodies simulations that demonstrate how collisions among planetesimals in Neptune s feeding area can generate objects with orbits similar to those observed currently .The initial conditions are based on estimates of planet migration during which Neptune migrated outward by about 30 AU before being stopped at its current site . Our calculations suggest that the Kuiper belt developed as a outcome of collisional grinding between bodies whose sizes were analogous to Pluto ( r ~ 1000 kilometers ) .This process produced a population of tiny bodies with orbital eccentricities ranging up to 0 . 3 . Subsequent experiences with Neptune resulted some of these objects to be scattered into extremely eccentric orbits .These data provide an reason for why there seems to be no correlation between the size distribution of KBOs and their orbital eccentricity .",
        "rewrite_text": "The Kuiper Belt is considered the source region for the majority of short-period comets; however, its formation remains inadequately understood. We present results from N-body simulations that illustrate how collisions among planetesimals in Neptune's feeding zone can create objects with orbits similar to those we observe today. The initial conditions for these simulations are based on estimates of planetary migration, during which Neptune moved outward by approximately 30 AU before stabilizing at its current position. Our findings indicate that the Kuiper Belt formed as a result of collisional grinding among bodies comparable in size to Pluto (about 1000 kilometers in radius). This process led to the generation of numerous small bodies with orbital eccentricities reaching up to 0.3. Following interactions with Neptune, some of these objects were scattered into highly eccentric orbits. This evidence helps explain the apparent lack of correlation between the size distribution of Kuiper Belt Objects (KBOs) and their orbital eccentricities.",
        "ori-fast-z-score": -0.9847319278346618,
        "water-fast-z-score": 5.333493587335964,
        "rewrite-fast-z-score": 0.36650833306891567
    },
    {
        "original_text": "Horizontal Gene Transfer (HGT) is an important evolutionary force that can increase genetic diversity and accelerate evolution, but it also has negative effects such as disrupting co-adapted gene complexes or introducing deleterious mutations into recipient genomes. In this study we investigate how HGT affects the mean fitness of unicells evolving under different environmental conditions using computational models. We find that HGT increases the mean fitness when cells are exposed to fluctuating environments with high levels of stressful events. However, if there are only mild fluctuations then HGT decreases the mean fitness because it introduces harmful mutations. Finally, for constant environments without any external stresses, HGT does not affect the mean fitness at all. Our results suggest that HGT may have played an important role during early stages of life s evolution by increasing its adaptability to changing environments. Horizontal Gene Transfer (HGT), which occurs between organisms sharing similar DNA sequences, is one of the most significant evolutionary forces known today  1  . It allows rapid acquisition of new genes and thus contributes to increased genetic diversity within species  2  , accelerates evolution  3  , and facilitates adaptation  4  .\nHowever, HGT also has some disadvantages including disruption of co-adapted gene complexes  5  and introduction of deleterious mutations  6  . Therefore, understanding the effect of HGT on population dynamics requires careful investigation  7, 8  . Previous studies suggested that HGT could be beneficial for populations living in fluctuating environments  9  while detrimental for those inhabiting stable ones  10  . Here we use computational models to explore these hypotheses further and show that HGT can either increase or decrease the mean fitness depending on the type of environment inhabited by the cell population.",
        "watermark_text": "Horizontal Gene Transfer ( HGT ) is an important genetic force that can increase genetic diversity and accelerate evolution , but it also has negative impacts such as disrupting co - adapted gene structures or introducing deleterious variants into recipient genomes . In this study we investigate how HGT affects the mean fitness of unicells evolving under various environmental conditions utilizing computational models .We see that HGT changes the mean fitness when cells are susceptible to fluctuating environments with high levels of stressful events . However , if there are only slight fluctuations then HGT decreases the mean fitness because it creates dangerous mutations .Finally , for constant environments without any external stresses , HGT does not alter the mean fitness at all . Our results show that HGT could have played an important role during initial stages of life s evolution by increasing its adaptability to changing settings .Horizontal Gene Transfer ( HGT ) , which occurs between organisms sharing comparable DNA sequences , is one of the most significant evolutionary factors known today 1 . It enables quick acquisition of new genome and therefore contributes to greater genetic fitness within genus 2 , accelerates development 3 , and facilitates adaptation 4 .However , HGT also has some disadvantages including disruption of co - adapted gene pathways 5 and entry of deleterious variants 6 . Therefore , studying the impact of HGT on population behavior needs thorough investigation 7 , 8 .Previous studies suggested that HGT could be beneficial for individuals living in fluctuating environments 9 while detrimental for those inhabiting stable ones 10 . Here we utilize computational models to examine these hypotheses further and suggest that HGT can either increase or decrease the mean fitness depending on the kind of environment populated by the cell colony .",
        "rewrite_text": "Horizontal Gene Transfer (HGT) is a significant genetic mechanism that enhances genetic diversity and accelerates evolutionary processes. However, it can also have detrimental effects, such as disrupting co-adapted gene structures and introducing harmful variants into recipient genomes. In this study, we explore the impact of HGT on the average fitness of unicellular organisms evolving under various environmental conditions through computational modeling. Our findings indicate that HGT positively influences mean fitness in environments characterized by significant fluctuations and high stress levels. Conversely, under conditions with only minor variations, HGT tends to reduce mean fitness by introducing harmful mutations. In stable environments devoid of external stressors, HGT has no effect on mean fitness at all. These results suggest that HGT may have played a crucial role in the early stages of life's evolution by enhancing adaptability to changing environments. HGT, which involves the transfer of genetic material between organisms with similar DNA sequences, stands out as one of the most critical evolutionary mechanisms known today. It allows for rapid acquisition of new genomic traits, thereby fostering greater genetic fitness within a genus and facilitating adaptation. However, it is accompanied by certain drawbacks, including the disruption of co-adapted gene pathways and the introduction of harmful variants. Consequently, it is essential to thoroughly investigate the effects of HGT on population dynamics. Previous research has indicated that HGT may be advantageous for organisms in variable environments, while it could be harmful for those in stable conditions. In this study, we leverage computational models to delve deeper into these hypotheses and demonstrate that the influence of HGT on mean fitness can vary based on the specific environmental context occupied by the cell population.",
        "ori-fast-z-score": 1.3821894809301762,
        "water-fast-z-score": 7.888934916555407,
        "rewrite-fast-z-score": 2.181871531571392
    },
    {
        "original_text": "We present the results of an analysis of the anisotropy in the distribution of satellite galaxies around isolated field galaxies, using data obtained by the Sloan Digital Sky Survey (SDSS). We find that there is no significant difference between the distributions for satellites with different luminosities or colors and those found around central cluster galaxies. The observed anisotropies are consistent with predictions based on tidal forces acting during galaxy mergers. This suggests that these effects may be responsible for the formation of both clusters and groups of galaxies. \n \n Keywords: Galaxy merger, Group/cluster of galaxies, Tidal stripping, SDSS, Isolated galaxy \n \n \n \n 1 Introduction \n \n Clusters of galaxies contain many thousands of galaxies which reside within a common dark matter halo. These systems form through gravitational collapse driven by the mutual attraction of their constituent galaxies. However, it remains unclear how this process occurs over time-scales ranging from individual galaxy interactions to the assembly of massive clusters containing hundreds of member galaxies. In particular, we do not know whether all galaxies evolve into members of large clusters or if some fraction remain as isolated field galaxies throughout cosmic history. \n \n 2 Previous Work \n \n Several studies have investigated the properties of satellite galaxies surrounding brightest cluster galaxies (BCGs) at low redshifts z < 0.1. For example, Carlberg et al. (1997), Lin & Mohr (2004a), and Hansen et al. (2005) used samples of BCG-satellite pairs selected from optical surveys such as the Palomar Observatory Sky Survey (POSS-II; Reid et al., 1991) and the Sloan Digital Sky Surveys (SDSS; York et al., 2000). They found that the number density profiles of satellite galaxies show strong deviations from spherical symmetry, indicating that they are distributed anisotropically about their host galaxies. Furthermore, they showed that the degree of anisotropy depends strongly on the projected distance from the center of the host galaxy. At small distances, the radial profile shows a steep decline towards the center of the host while the tangential component increases rapidly beyond a characteristic radius R",
        "watermark_text": "We present the conclusion of an assessment of the anisotropy in the distribution of satellite galaxies around dispersed field galaxies , using data derived by the Sloan Digital Sky Survey ( SDSS ) . We see that there is no major variation between the distributions for satellites with various luminosities or colors and those found around central cluster clusters .The observed anisotropies are compatible with predictions based on tidal forces acting during galaxy mergers . This implies that these influences might be responsible for the formation of both clusters and groups of clusters .Keywords : Galaxy consolidation , Group / cluster of galaxies , Tidal stripping , SDSS , Isolated galaxy 1 Introduction Clusters of galaxies contain many thousands of galaxies which reside within a common dark matter halo . These systems create through gravity collapse driven by the mutual proximity of their constituent galaxies .However , it remains unsure how this process occurs over time - scales ranging from individual galaxy encounters to the assembly of vast clusters containing hundreds of member galaxies . In particular , we do not understand whether all galaxies evolve into members of large clusters or if some fraction remain as isolated ring galaxies throughout cosmic history .2 Previous Work Several studies have explored the properties of satellite galaxies surrounding brightest cluster clusters ( BCGs ) at low redshifts z < 0 . 1 . For instance , Carlberg et al .( 1997 ) , Lin & Mohr ( 2004a ) , and Hansen et al . ( 2005 ) used data of BCG - satellite pairs selected from optical surveys such as the Palomar Observatory Sky Survey ( POSS - II ; Reid et al . , 1991 ) and the Sloan Digital Sky Surveys ( SDSS ; York et al . , 2000 ) .They found that the number density patterns of satellite galaxies show strong deviations from spherical symmetry , showing that they are distributed anisotropically about their host galaxies . Furthermore , they demonstrated that the degree of anisotropy depends strongly on the projected distance from the hub of the host galaxy .At small distances , the radial profile displays a sharp decline towards the hub of the host while the tangential component increases quickly beyond a typical radius R",
        "rewrite_text": "We conclude our assessment of the anisotropy in the distribution of satellite galaxies surrounding dispersed field galaxies, utilizing data from the Sloan Digital Sky Survey (SDSS). Our findings indicate minimal variation in the distributions of satellites with differing luminosities or colors compared to those associated with central cluster galaxies. The observed anisotropies align with predictions derived from tidal forces during galaxy mergers, suggesting that these forces may play a significant role in the formation of both clusters and groups of clusters. \n\n**Keywords:** Galaxy formation, Groups/clusters of galaxies, Tidal stripping, SDSS, Isolated galaxies \n\n**1. Introduction**  \nGalaxy clusters are composed of thousands of galaxies bound together by a shared dark matter halo. These structures form through gravitational collapse driven by the proximity of their constituent galaxies. However, the specifics of this process over time—ranging from individual galaxy encounters to the assembly of extensive clusters with hundreds of members—remain uncertain. A key question is whether all galaxies ultimately join large clusters or if a subset continues to exist as isolated ring galaxies throughout cosmic history. \n\n**2. Previous Work**  \nNumerous studies have investigated the properties of satellite galaxies surrounding brightest cluster galaxies (BCGs) at low redshifts (z < 0.1). Researchers such as Carlberg et al. (1997), Lin & Mohr (2004a), and Hansen et al. (2005) analyzed data on BCG-satellite pairs from optical surveys, including the Palomar Observatory Sky Survey (POSS-II; Reid et al., 1991) and the Sloan Digital Sky Surveys (SDSS; York et al., 2000). These studies revealed that the number density patterns of satellite galaxies exhibit significant deviations from spherical symmetry, indicating an anisotropic distribution around their host galaxies. Additionally, they demonstrated that the extent of anisotropy is heavily influenced by the projected distance from the center of the host galaxy, with the radial distribution showing a marked decrease towards the center while the tangential component rises rapidly beyond a typical radius \\( R \\).",
        "ori-fast-z-score": 0.242535625036333,
        "water-fast-z-score": 5.640760748177662,
        "rewrite-fast-z-score": 0.4931969619160719
    },
    {
        "original_text": "The universe is expanding at an accelerating rate, which has been attributed to  dark energy .  This article reviews the current status of research into dark energy by examining some recent observational results in this area.   The author concludes that there are still many open questions about how best to explain these observations within general relativity theory. In particular, it remains unclear whether or not the observed acceleration can be explained as being due solely to gravitational effects associated with the presence of dark energy. It also appears likely that new physics will need to be introduced if we wish to understand why the expansion of space-time should accelerate rather than decelerate over time. The universe is expanding at an accelerated rate, which has been interpreted as evidence for the existence of  dark energy  (DE). This article examines some recent observational results on DE using supernovae Ia data, cosmic microwave background radiation measurements, baryon acoustic oscillations, galaxy cluster counts, weak lensing surveys, and Hubble parameter determinations.",
        "watermark_text": "The universe is growing at an accelerating rate , which has been due to dark energy . This page reviews the present position of research into dark energy by examining some latest observational results in this area .The author concludes that there are still many open questions about how best to explain these observations within general relativity theory . In particular , it remains unsure whether or not the seen acceleration can be described as being owing purely to gravitational influences associated with the presence of dark energy .It also seems likely that new science will need to be introduced if we wish to comprehend why the expansion of space - time should accelerate rather than decelerate over time . The universe is growing at an accelerated pace , which has been viewed as proof for the existence of dark energy ( DE ) .This page discusses some latest observational results on DE utilizing supernovae Ia evidence , cosmic microwave background radiation observations , baryon acoustic oscillations , galaxy cluster counts , soft lensing surveys , and Hubble parameter determinations .",
        "rewrite_text": "The universe is expanding at an accelerating pace, a phenomenon attributed to dark energy. This article reviews the current state of research on dark energy by looking at the latest observational findings in this field. The author concludes that many questions remain unanswered regarding how to interpret these observations within the context of general relativity. Specifically, it is still unclear whether the observed acceleration can be solely attributed to gravitational effects linked to dark energy. Furthermore, it is likely that new scientific frameworks will be necessary to understand why the expansion of space-time is accelerating rather than decelerating over time. This discussion includes recent observational data related to dark energy, utilizing evidence from Type Ia supernovae, cosmic microwave background radiation, baryon acoustic oscillations, galaxy cluster counts, weak lensing surveys, and measurements of the Hubble parameter.",
        "ori-fast-z-score": -0.7592566023652966,
        "water-fast-z-score": 5.531726674375733,
        "rewrite-fast-z-score": -0.9428090415820635
    },
    {
        "original_text": "We study spin effects on the lattice QCD using recurrence lattices (RL) with multi-site exchanges, which are constructed by applying the RL transformation to the original fermion action. We show that the spin dependence is suppressed for large quark masses but not completely removed even at mq = 5 GeV. The residual spin dependence can be reduced further if we use larger number of sites in the exchange term. In this work, we adopt Ns = 4 as an example. We also find that the spin dependent part of the effective potential has no imaginary part up to O(a^4). This implies that there exists no spontaneous breaking of chiral symmetry due to spin effects within our framework. Finally, we discuss possible extensions of our method. PACS numbers: 11.15.Ha, 12.38.Gc, 13 .25.Hw \nI. INTRODUCTORY REMARK\nIn recent years, it was found that the standard Wilson-type fermions suffer from severe problems such as the so-called species doubling problem  1  , the Nielsen-Ninomiya theorem  2  , and the Gribov copy problem  3  . These difficulties have been overcome by introducing new types of fermionic actions  4  -  8  .\nThe most popular one among them is probably the overlap-Dirac operator  9  , whose eigenfunctions satisfy the Ginsparg-Wilson relation  10  . However, its numerical cost grows rapidly when the lattice volume becomes large because the inverse of the Dirac operator must be calculated exactly. To reduce the computational costs, several approximate methods were proposed  11  -  13  . Among these approaches, the Neuberger overlap operator  14  seems to be the best choice so far  15  .\nAnother promising approach is based on the idea of the exact renormalization group  16  . It was shown  17  that the fermion determinant detD(μ), where D(μ) denotes the fermion matrix defined through the fermion action Sf  U  ≡ ∑x Tr γμD(μ)Ux , satisfies the following flow equation:",
        "watermark_text": "We research spin effects on the lattice QCD utilizing recurrence lattices ( RL ) with multi - location exchanges , which are built by using the RL shift to the previous fermion action . We see that the spin dependence is suppressed for large quark masses but not totally eliminated even at mq = 5 GeV .The residual spin effect can be reduced further if we using larger number of places in the transfer term . In this study , we follow Ns = 4 as an instance .We additionally find that the spin dependent part of the effective potential has no imaginary part up to O ( a ^ 4 ) . This implies that there exists no premature breaking of chiral symmetry due to spinning factors within our framework .Finally , we investigate possible extensions of our technique . PACS numbers : 11 . 15 . Ha , 12 . 38 . Gc , 13 . 25 . Hw I .INTRODUCTORY REMARK In recent years , it was shown that the standard Wilson - class fermions suffer from severe challenges such as the so - called genus doubling question 1 , the Nielsen - Ninomiya conjecture 2 , and the Gribov copies problem 3 . These difficulties have been overcome by introducing novel forms of fermionic operations 4 - 8 .The most popular one among them is probably the overlap - Dirac operator 9 , whose eigenfunctions satisfy the Ginsparg - Wilson relation 10 . However , its numerical cost rises steadily when the lattice volume becomes large because the inverse of the Dirac operator must be determined exactly .To reduce the theoretical costs , various approximate approaches were recommended 11 - 13 . Among these method , the Neuberger overlap operator 14 says to be the best choice so far 15 .Another promising alternative is based on the idea of the exact renormalization group 16 . It was shown 17 that the fermion determinant detD ( μ ) , where D ( μ ) denotes the fermion matrix established through the fermion action Sf U ≡ [UNK] Tr γμD ( μ ) Ux , satisfies the following fluid equation :",
        "rewrite_text": "We investigate the effects of spin in lattice QCD using recurrence lattices (RL) with multi-location exchanges, which are constructed by applying the RL shift to the prior fermion action. Our findings indicate that while spin dependence is diminished for large quark masses, it is not entirely absent, even at mq = 5 GeV. The residual spin effect can be further minimized by employing a greater number of locations in the transfer term. In this study, we specifically examine the case of Ns = 4. Additionally, we discover that the spin-dependent portion of the effective potential remains free of imaginary components up to O(a^4), suggesting that our framework does not lead to premature chiral symmetry breaking caused by spin factors. Lastly, we explore potential extensions of our approach. PACS numbers: 11.15.Ha, 12.38.Gc, 13.25.Hw\n\n**I. INTRODUCTORY REMARKS**\n\nRecent studies have revealed that standard Wilson-class fermions face significant challenges, including issues such as genus doubling, the Nielsen-Ninomiya theorem, and the Gribov copy problem. These obstacles have been addressed through the introduction of innovative forms of fermionic operations. Among these, the overlap-Dirac operator, which satisfies the Ginsparg-Wilson relation, is perhaps the most well-known. However, its computational costs escalate with larger lattice volumes since an accurate determination of the inverse Dirac operator is required. To alleviate these theoretical costs, various approximate methods have been proposed. Among these, the Neuberger overlap operator is often regarded as the best available option. Another promising approach is derived from the concept of exact renormalization group theory. It has been demonstrated that the fermionic determinant, denoted as detD(μ) (where D(μ) represents the fermion matrix defined by the fermion action S_f^U ≡ [UNK] Tr γμD(μ) Ux), obeys a specific fluid equation.",
        "ori-fast-z-score": -0.8838834764831843,
        "water-fast-z-score": 7.424621202458749,
        "rewrite-fast-z-score": 1.0690449676496976
    },
    {
        "original_text": "We report on the fabrication and characterization of charge qubits based on self-assembled InAs quantum dots (QDs) embedded in GaAs/AlGaAs heterostructures. We show that by using an optimized growth procedure, we can achieve high quality QD layers with low density of defects which are crucial for achieving good coherence times. The samples were grown by molecular beam epitaxy at 600 °C under As-rich conditions to minimize the formation of threading dislocations. A single layer of self-assembled InAs/GaAs QDs was formed after annealing at 650 °C for 10 s followed by deposition of a 50 nm thick Al0.3Ga0.7As barrier layer. Finally, a 20 nm thick GaAs capping layer was deposited. The sample structure is shown schematically in Figure 1 . The photoluminescence spectrum shows emission peaks centered around 1280 nm corresponding to ground state excitonic transitions of individual QDs as well as higher energy states associated with charged excitons.",
        "watermark_text": "We report on the fabrication and description of charge qubits based on self - assembled InAs quantum dots ( QDs ) integrated in GaAs / AlGaAs heterostructures . We suggest that by using an optimized growth technique , we can attain high quality QD layers with minimal concentration of flaws which are important for achieving better coherence times .The samples were cultivated by molecular wave epitaxy at 600 °C under As - rich conditions to minimize the formation of threading dislocations . A single mesh of self - assembled InAs / GaAs QDs was formed after annealing at 650 °C for 10 s followed by deposition of a 50 nm wide Al0 . 3Ga0 . 7As barrier layer .Finally , a 20 nm deep GaAs capping layer was extracted . The sample structure is displayed schematically in Figure 1 .The photoluminescence spectrum displays emission levels focused around 1280 nm corresponding to ground state excitonic transitions of individual QDs as well as higher energy states correlated with charged excitons .",
        "rewrite_text": "We present our work on the fabrication and characterization of charge qubits utilizing self-assembled InAs quantum dots (QDs) integrated into GaAs/AlGaAs heterostructures. We propose that with an optimized growth technique, we can achieve high-quality QD layers with a minimal concentration of defects, which is crucial for enhancing coherence times. The samples were grown using molecular beam epitaxy at 600 °C under As-rich conditions to reduce the occurrence of threading dislocations. After annealing at 650 °C for 10 seconds, a single layer of self-assembled InAs/GaAs QDs was created, followed by the deposition of a 50 nm Al0.3Ga0.7As barrier layer. Lastly, a 20 nm GaAs capping layer was added. The sample structure is illustrated schematically in Figure 1. The photoluminescence spectrum shows emission peaks around 1280 nm, attributed to the ground state excitonic transitions of individual QDs, along with higher energy states associated with charged excitons.",
        "ori-fast-z-score": -0.24253562503633297,
        "water-fast-z-score": 4.213504858001922,
        "rewrite-fast-z-score": -0.6201736729460423
    },
    {
        "original_text": "We present an algorithm for creating a hierarchical grid spatial index using images as the basis for its construction.  The algorithm is based on the observation that many real-world datasets are naturally represented by images, and can be used in conjunction with existing techniques such as R-tree or Quadtree to improve performance.   We show how our technique performs against these other methods through experiments conducted over synthetic data sets generated according to different distributions (uniform, normal, exponential) and sizes ranging between 1K and 100M points.   Our results demonstrate significant improvements in query response times when compared to traditional approaches. In this work we propose a new approach for building a spatial index which uses image processing algorithms to extract information about the dataset being indexed. This information is then used to build a hierarchy of grids whose leaf nodes contain pointers to individual objects within the dataset. These grids provide efficient access to all objects contained therein while also allowing fast queries across multiple grids at once.",
        "watermark_text": "We present an algorithm for producing a hierarchical grid spatial indicator employing images as the foundation for its design . The algorithm is based on the observation that several real - time datasets are naturally represented by pictures , and can be used in partnership with existing techniques such as R - tree or Quadtree to achieve performance .We see how our technique performs against these other methods through experiments conducted over synthetic information sets generated according to different distributions ( uniform , normal , exponential ) and dimensions ranging between 1K and 100M points . Our results show considerable improvements in query reply times when compared to conventional approaches .In this project we propose a new approach for building a spatial indicator which uses image processing algorithms to extract information about the dataset being indexed . This knowledge is then utilized to build a hierarchy of grids whose leaf nodes contain pointers to individual objects within the dataset .These grids allow faster entry to all items contained therein while also enabling rapid queries across multiple grids at once .",
        "rewrite_text": "We introduce an algorithm designed to create a hierarchical grid spatial indicator that utilizes images as its foundational element. This algorithm leverages the insight that many real-time datasets can be effectively represented by images, which can be integrated with established techniques like R-trees and Quadtrees for enhanced performance. Through a series of experiments on synthetic datasets generated with various distributions (uniform, normal, exponential) and sizes ranging from 1K to 100M points, we evaluate the effectiveness of our approach relative to conventional methods. Our findings reveal significant improvements in query response times compared to traditional techniques. In this project, we propose a novel strategy for constructing a spatial indicator that employs image processing algorithms to extract relevant information from the indexed dataset. This extracted knowledge is then used to create a hierarchy of grids, with each leaf node containing pointers to specific objects in the dataset. These grids facilitate quicker access to all contained items and support rapid queries across multiple grids simultaneously.",
        "ori-fast-z-score": 0.8728715609439696,
        "water-fast-z-score": 6.9829724875517565,
        "rewrite-fast-z-score": 0.5488212999484517
    },
    {
        "original_text": "We propose an approach to causal inference for longitudinal data based on the use of marginal structural models (MSMs) that are restricted by past treatment and covariate histories, which we refer to as  history-restricted  MSMs.  We show how these models can be used to estimate average effects over time periods during which treatments were not administered or outcomes were not observed. Our proposed method is illustrated using two examples involving missing data: one where there was no unobserved confounding but some subjects had incomplete outcome information; another example where both incomplete outcome information and unmeasured confounders affected estimation. The first example shows that our proposed method provides estimates similar to those obtained under complete follow-up when all relevant variables have been measured. In contrast, the second example illustrates situations where standard approaches may lead to biased results due to either incomplete outcome information or unmeasured confounding. Finally, we provide simulation evidence showing that our proposed method performs well even if the model assumptions underlying it do not hold exactly. \nKeywords: Marginal Structural Models, Longitudinal Data Analysis",
        "watermark_text": "We suggest an way to causal inference for longitudinal data based on the using of marginal structural models ( MSMs ) that are restricted by past treatment and covariate histories , which we name to as history - limited MSMs . We see how these models can be used to estimate estimated effects over time periods during which therapy were not administered or outcomes were not observed .Our proposed approach is depicted using two examples involving missing data : one where there was no unobserved confounding but some subjects had incomplete result information ; another example where both incomplete result information and unmeasured confounders impacted estimation . The first instance shows that our proposed approach offers estimates similar to those achieved under complete follow - up when all relevant variables have been measured .In comparison , the second example illustrates situations where standard approaches may lead to biased results attributed to either incomplete result information or unmeasured confounding . Finally , we provide simulation evidence showing that our proposed approach performs good even if the model assumptions underlying it do not hold exactly .Keywords: Marginal Structural Models, Longitudinal Data Analysis",
        "rewrite_text": "We propose a method for causal inference in longitudinal data that utilizes marginal structural models (MSMs) constrained by past treatment and covariate histories, which we refer to as history-limited MSMs. These models can estimate effects during time periods when treatments were not administered or outcomes were not recorded. We illustrate our approach with two examples involving missing data: the first example involves no unobserved confounding but some subjects have incomplete outcome information, while the second example includes both incomplete outcome information and unmeasured confounders affecting the estimation. In the first case, our method provides estimates comparable to those obtained with complete follow-up when all relevant variables are observed. In contrast, the second example highlights potential biases in standard methods due to incomplete outcome information or unmeasured confounding. Additionally, we provide simulation evidence demonstrating that our proposed method performs well even when the underlying model assumptions do not hold perfectly. \n\nKeywords: Marginal Structural Models, Longitudinal Data Analysis",
        "ori-fast-z-score": 1.8225913092242512,
        "water-fast-z-score": 6.968731476445666,
        "rewrite-fast-z-score": 0.7777777777777778
    },
    {
        "original_text": "The information-based asset pricing model is an extension to the traditional CAPM (Capital Assets Pricing Model) that incorporates additional factors into its analysis.  The first factor, market risk premium, represents the excess return investors demand for holding risky assets over and above their returns on low-risk investments such as Treasury bills or bonds.   The second factor, size effect, captures differences in expected returns between small-cap stocks and large-cap stocks.   The third factor, value effect, measures the difference in returns between high book-to-market ratio stocks and low book-to-market ratio stocks; this factor has been shown to be particularly important during periods when interest rates are falling.    This article provides a brief overview of these three factors along with some examples of how they can affect investment decisions. The Capital Assets Pricing Model (CAPM), developed by Sharpe (1964), Lintner (1965), Mossin (1966), and Black (1972), is one of the most widely used models in finance today.  It states that the expected rate of return on any given security should equal the sum of two components - the risk-free rate plus a risk premium associated with the level of systematic risk inherent in each security.  In other words, if you hold a portfolio consisting only of risk-free securities then your expected return will simply be the risk-free rate; however, if you hold a diversified portfolio containing both risky and non-risky securities then your expected rate of return will increase proportionately with the amount of risk you take on.  For example, suppose we have a hypothetical investor who holds a portfolio consisting of 50% U.S. Treasury bills and 50% Standard & Poor’s 500 Index Funds.  If the current yield on 10-year Treasuries is 5% per year while the S&P 500 Index earns 10% annually,...",
        "watermark_text": "The data - based portfolio management model is an addition to the usual CAPM ( Capital Assets Pricing Model ) that incorporates additional factors into its assessment . The first factor , market risk premium , represents the additional return investors need for holding risky funds over and above their returns on small - risk investments such as Treasury bills or bonds .The second factor , size factor , reflects variations in expected returns between small - cap stocks and large - cap stocks . The third factor , value effect , represents the difference in returns between strong book - to - market ratio stocks and low book - to - market ratio stocks ; this factor has been shown to be particularly important during periods when interest rates are falling .This page offers a brief overview of these three variables along with some examples of how they can affect investment decisions . The Capital Assets Pricing Model ( CAPM ) , developed by Sharpe ( 1964 ) , Lintner ( 1965 ) , Mossin ( 1966 ) , and Black ( 1972 ) , is one of the most commonly used theories in finance today .It says that the expected rate of return on any certain security should equivalent the sum of two parts - the danger - free level plus a risk premium associated with the degree of systematic risk inherent in each security . In other words , if you hold a portfolio consisting only of risk - safe securities then your anticipated return will simply be the risk - safe level ; however , if you hold a diversified portfolio encompassing both risky and non - risky securities then your anticipated level of return will expand proportionately with the quantity of risk you took on .For instance , suppose we have a hypothetical buyer who holds a portfolio consisting of 50 % U . S . Treasury money and 50 % Standard & Poor ’ s 500 Index Funds . If the present yield on 10 - month Treasuries is 5 % per month while the S & P 500 Index earns 10 % annually , . . .",
        "rewrite_text": "The data-driven portfolio management model enhances the traditional Capital Asset Pricing Model (CAPM) by integrating additional factors into its evaluation. The first factor, the market risk premium, denotes the extra return investors expect for taking on riskier investments compared to low-risk options like Treasury bills or bonds. The second factor, known as the size factor, captures the differences in expected returns between small-cap and large-cap stocks. The third factor, the value effect, indicates the disparity in returns between stocks with a high book-to-market ratio and those with a low book-to-market ratio; this factor becomes particularly significant during periods of declining interest rates. This page provides a concise overview of these three factors, along with examples of their potential impact on investment strategies. The Capital Asset Pricing Model (CAPM), introduced by Sharpe (1964), Lintner (1965), Mossin (1966), and Black (1972), remains one of the most widely utilized theories in finance today. It posits that the expected return on any given security should equal the sum of a risk-free rate and a risk premium that corresponds to the level of systematic risk associated with that security. In simpler terms, if an investor holds a portfolio made up exclusively of risk-free securities, the anticipated return will match the risk-free rate. Conversely, a diversified portfolio with both risky and risk-free securities will likely yield a return that scales with the amount of risk undertaken. For example, consider a hypothetical investor with a portfolio split evenly between 50% U.S. Treasury securities and 50% S&P 500 Index funds. If the current yield on 10-month Treasuries is 5% per month and the S&P 500 Index records an annual return of 10%,...",
        "ori-fast-z-score": 0.5813183589761798,
        "water-fast-z-score": 7.224956747275377,
        "rewrite-fast-z-score": 0.4181210050035454
    },
    {
        "original_text": "We use hydrodynamic simulations to study how proto-clusters grow and evolve into galaxy clusters, focusing on their baryon content at high redshifts (z > 5). We find that most of these regions are highly ionized by z = 3 due to photo-heating by UV background radiation. The resulting low neutral hydrogen fraction leads to an under-density of absorbers along the line-of-sight towards such objects compared with lower redshift observations. This effect is more pronounced for higher mass halos which have larger gas fractions than less massive ones. Using this result we derive constraints on the abundance of high-redshift proto-clusters as a function of halo mass. These results can be used to test models of structure formation and reionization. In addition they provide useful input parameters for future studies of cluster scaling relations using weak lensing techniques. \n \n Keywords: Hydrogen ionization state, Galaxy Cluster, Reionization",
        "watermark_text": "We use hydrodynamic simulations to study how proto - galaxies grow and evolve into star clusters , concentrating on their baryon concentration at high redshifts ( z > 5 ) . We see that most of these regions are extremely ionized by z = 3 due to photo - heating by UV background radiation .The resulting lowered neutral hydrogen proportion leads to an under - density of absorbers along the line - of - view towards such objects compared with higher redshift observations . This phenomenon is more pronounced for greater weight halos which have larger gas fractions than less massive ones .Using this effect we derive restrictions on the availability of high - redshift proto - complexes as a function of halo mass . These conclusions can be used to test models of structure development and reionization .In addition they give valuable input parameters for future research of cluster scaling relations utilizing weak lensing methods . Keywords : Hydrogen ionization state , Galaxy Cluster , Reionization",
        "rewrite_text": "We employ hydrodynamic simulations to investigate the growth and evolution of proto-galaxies into star clusters, with a focus on their baryon concentration at high redshifts (z > 5). Our findings indicate that by z = 3, most of these regions are highly ionized due to photo-heating from UV background radiation. This ionization leads to a reduced proportion of neutral hydrogen, resulting in a lower density of absorbers along the line of sight towards these objects compared to observations at higher redshifts. This effect is particularly pronounced in more massive halos, which tend to have higher gas fractions than their less massive counterparts. By analyzing this phenomenon, we can establish constraints on the presence of high-redshift proto-complexes in relation to halo mass. These insights are crucial for testing models of large-scale structure formation and reionization. Furthermore, they provide important parameters for future investigations into cluster scaling relations using weak lensing techniques. Keywords: Hydrogen ionization state, Galaxy Cluster, Reionization.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.5778737935111105,
        "rewrite-fast-z-score": 1.3949716649258315
    },
    {
        "original_text": "We report on the detection and analysis of an optical shock front in the supernova remnant (SNR) Tycho using data obtained with Subaru High Dispersion Spectrograph (HDS). The observed spectrum shows strong emission lines of hydrogen, helium, nitrogen, oxygen, sulfur, argon, calcium, magnesium, silicon, iron ions at wavelengths between 3200Å and 9400Å. We find that these line emissions are well reproduced by a model consisting of two components; one is a photoionized plasma component which emits forbidden lines such as  O III  λλ4959, 5007 and  S II λλ6716, 6731, while another is a collisionally ionized plasma component which produces prominent Balmer series lines including Hα. From this result we conclude that the detected shock front is dominated by collisional ionization rather than photo-ionization. \n \n Keywords: Supernova remnants",
        "watermark_text": "We report on the discovery and evaluation of an optical shock front in the supernova remnant ( SNR ) Tycho using data received with Subaru High Dispersion Spectrograph ( HDS ) . The observed spectrum displays large emitted lines of sulfur , helium , nitrogen , hydrogen , sulfur , argon , potassium , magnesium , silicon , iron ions at wavelengths between 3200Å and 9400Å .We see that these line emissions are better illustrated by a theory consisting of two parts ; one is a photoionized plasma component which emits forbidden lines such as O III λλ4959 , 5007 and S II λλ6716 , 6731 , while another is a collisionally ionized plasma component which generates distinctive Balmer series curves including Hα . From this consequence we suppose that the detected shock front is dominated by collisional ionization instead than photo - ionization .Keywords: Supernova remnants",
        "rewrite_text": "We report the discovery and analysis of an optical shock front within the supernova remnant (SNR) Tycho, utilizing data from the Subaru High Dispersion Spectrograph (HDS). The spectrum obtained reveals prominent emission lines from sulfur, helium, nitrogen, hydrogen, argon, potassium, magnesium, silicon, and iron ions, spanning wavelengths from 3200Å to 9400Å. Our findings indicate that the line emissions can be effectively described by a dual-component model: one component consists of a photoionized plasma that emits forbidden lines such as O III λλ4959, 5007 and S II λλ6716, 6731, while the other comprises a collisionally ionized plasma that produces distinctive Balmer series lines, including Hα. Based on this analysis, we conclude that the observed shock front is primarily influenced by collisional ionization rather than photoionization. \n\nKeywords: Supernova remnants",
        "ori-fast-z-score": -1.8203641092364127,
        "water-fast-z-score": 3.780756226875626,
        "rewrite-fast-z-score": -0.13736056394868904
    },
    {
        "original_text": "We present the results of our calculation for two-photon transition rates between excited states of atomic hydrogen, including all relevant bound-bound and bound-free processes. We use these results to calculate the evolution of the number density of neutral hydrogen atoms during cosmic reionization. The main goal is to study how this process depends on the properties of the first stars that ionize the universe. \n \n In particular we focus on the effect of different stellar initial mass functions (IMF) on the ionization history of the universe. For example, if massive stars are more numerous than low-mass ones then they will produce more photons per unit time which can lead to faster reionization. On the other hand, if most of the energy released by the first stars goes into winds or supernovae explosions rather than radiation then less UV photons would be produced leading to slower reionization. Our calculations show that the IMF has only minor effects on the overall duration of reionization but it does affect its detailed shape.",
        "watermark_text": "We present the conclusion of our analysis for two - photon change rates between excited states of nuclear hydrogen , covering all relevant bound - bound and bound - free processes . We use these results to estimate the evolution of the number density of neutral hydrogen atoms during cosmic reionization .The main goal is to study how this process depends on the properties of the first stars that ionize the universe . In particular we focus on the impact of different stellar initial mass mechanisms ( IMF ) on the ionization history of the universe .For instance , if huge stars are more numerous than low - mass ones then they will generate more photons per unit time which can lead to faster reionization . On the other hand , if most of the electricity created by the first stars goes into winds or supernovae explosions rather than radiation then less UV photons might be emitted led to slower reionization .Our calculations show that the IMF has only minor impacts on the overall duration of reionization but it does affect its precise shape .",
        "rewrite_text": "We present the conclusion of our analysis regarding the two-photon change rates between excited states of nuclear hydrogen, encompassing all significant bound-bound and bound-free processes. Utilizing these findings, we estimate the evolution of the number density of neutral hydrogen atoms during cosmic reionization. Our primary objective is to investigate how this process is influenced by the characteristics of the first stars that contributed to the ionization of the universe. Specifically, we focus on the effects of different initial mass function (IMF) mechanisms on the ionization history. For example, if massive stars are more prevalent than low-mass ones, they will produce a greater number of photons per unit time, potentially leading to a quicker reionization. Conversely, if a significant portion of the energy generated by the first stars is channeled into stellar winds or supernova explosions rather than radiation, fewer UV photons may be emitted, resulting in a slower reionization process. Our calculations indicate that while the IMF has a minimal impact on the overall duration of reionization, it does influence its precise shape.",
        "ori-fast-z-score": 2.587702172129855,
        "water-fast-z-score": 6.413001035278336,
        "rewrite-fast-z-score": 3.1454916383705145
    },
    {
        "original_text": "A mathematical model is developed to study the endogenous and exogenous dynamics associated with pressure fluctuations within an entrained flow gasifier, which are caused by the interaction between fluid mechanics and chemical reactions. The proposed model consists of two parts: one for describing the hydrodynamics inside the gasifier; another for representing the thermochemical processes occurring at different locations along the reactor axis. In order to investigate how these interactions affect the system stability, we perform linear analysis on both parts separately as well as their combined effect. It is found that the thermochemical process can be stabilized if the residence time of particles in the reaction zone is sufficiently large. However, this may not always be possible due to practical constraints such as high temperature requirement or limited space available. Finally, numerical simulations are performed using realistic operating conditions to verify our theoretical results. Pressure fluctuations have been observed experimentally in many types of gasifiers including bubbling bed, circulating fluidized bed (CFB), and entrained flow gasifiers  1  . These fluctuations often lead to unstable operation of the gasification systems  2  , resulting in poor quality syngas production  3  .\nThe main cause of pressure fluctuation lies in the coupling between fluid mechanics and chemical kinetics  4  . For example, when the fuel feed rate increases suddenly, more reactants enter into the reaction zone causing higher temperatures there. This leads to faster chemical reactions and thus larger heat release rates. As a result, the local pressure rises rapidly. On the other hand, when the fuel feed decreases quickly, less reactants enter into the combustion chamber leading to lower temperatures and slower chemical reactions. Consequently, the local pressure drops sharply.",
        "watermark_text": "A mathematical description is developed to study the endogenous and exogenous dynamics involved with force fluctuations within an entrained flow gasifier , which are created by the interaction between liquid mechanics and chemical processes . The proposed theory consists of two parts : one for describing the hydrodynamics inside the gasifier ; another for depicting the thermochemical processes resulting at different places along the reactor axis .In order to examine how these interactions impact the process stability , we perform linear analysis on both parts separately as well as their combined influence . It is found that the thermochemical mechanism can be stabilized if the residence time of molecules in the process area is sufficiently huge .However , this might not always be possible due to technical restrictions such as great heat requirement or restricted room available . Finally , numerical simulations are performed using accurate working circumstances to confirm our theoretical results .Pressure fluctuations have been observed experimentally in multiple types of gasifiers notably bubbling bed , flowing fluidized bed ( CFB ) , and entrained flow gasifiers 1 . These fluctuations often cause to unstable operation of the gasification schemes 2 , leading in poor quality syngas production 3 .The main mechanism of force fluctuation arises in the interaction between liquid mechanics and chemical kinetics 4 . For instance , when the fuel feed rate raises suddenly , more reactants enter into the reaction zone creating higher temperatures there .This leads to faster chemical processes and therefore larger heat release times . As a result , the local pressure climbs quickly .On the other hand , when the gas feed falls fast , fewer reactants enter into the combustion chamber causing to lower temperatures and less chemical processes . Therefore , the local pressure drops sharply .",
        "rewrite_text": "A mathematical framework has been developed to analyze the endogenous and exogenous dynamics associated with force fluctuations in an entrained flow gasifier. These fluctuations arise from the interplay between liquid mechanics and chemical processes. The proposed model consists of two components: one focuses on the hydrodynamics within the gasifier, while the other addresses the thermochemical processes occurring at various locations along the reactor axis. To investigate the effects of these interactions on process stability, we conduct a linear analysis on each component separately, as well as on their combined impact. The findings indicate that the thermochemical mechanism can be stabilized if the residence time of molecules in the processing area is sufficiently long. However, achieving this may be limited by technical constraints, such as high heat requirements or limited space. To validate our theoretical results, we perform numerical simulations under realistic operating conditions. Experimental observations have detected pressure fluctuations in various types of gasifiers, including bubbling beds, circulating fluidized beds (CFB), and entrained flow gasifiers. These fluctuations can lead to unstable operations in gasification systems, resulting in subpar syngas production. The primary source of force fluctuation stems from the interaction between liquid mechanics and chemical kinetics. For example, a sudden increase in the fuel feed rate introduces more reactants into the reaction zone, raising temperatures and accelerating chemical reactions, which in turn increases heat release duration and local pressure. Conversely, a rapid decrease in gas feed results in fewer reactants in the combustion chamber, leading to lower temperatures and reduced chemical activity, thus causing a sharp drop in local pressure.",
        "ori-fast-z-score": -0.6713450866373513,
        "water-fast-z-score": 8.947789507075871,
        "rewrite-fast-z-score": 0.6963106238227914
    },
    {
        "original_text": "We report on the discovery and study of J1128+592, an intraday variable (IDV) radio quasar at redshift z = 1.8. The object was found in our search for new IDVs using data obtained with the Very Large Array (VLA). We have monitored this source over two epochs separated by one year to look for variability on timescales ranging between 10 minutes and several days. Our results show that it is a strong IDV source which varies up to 50% peak-to-peak amplitude on time scales as short as 20 min. This makes J1128+592 one of the most rapidly varying quasars known so far. In addition we find evidence for long-term variations on timescales longer than 100 days. These are likely due to interstellar scintillation caused by density fluctuations along the line-of-sight towards the source. Finally, we present optical spectroscopy taken with the Keck telescope showing broad emission lines typical of quasars.",
        "watermark_text": "We report on the discovery and study of J1128 + 592 , an intraday variable ( IDV ) radio quasar at redshift z = 1 . 8 . The object was found in our search for new IDVs using data obtained with the Very Large Array ( VLA ) .We have analyzed this stream over two epochs separated by one year to search for variability on timescales ranging between 10 minutes and many days . Our results show that it is a powerful IDV source which varies up to 50 % peak - to - peak amplitude on time ranges as short as 20 min .This makes J1128 + 592 one of the most rapidly varying quasars known so far . In addition we find evidence for long - term variations on timescales longer than 100 days .These are likely due to interstellar scintillation caused by density fluctuations along the line - of - view towards the origin . Finally , we present imaging spectroscopy made with the Keck mirror using wide emitted lines typical of quasars .",
        "rewrite_text": "We present our findings on J1128 + 592, an intraday variable (IDV) radio quasar with a redshift of z = 1.8. This object was discovered during our search for new IDVs using data from the Very Large Array (VLA). We analyzed observations conducted over two epochs, one year apart, to investigate variability on timescales ranging from 10 minutes to several days. Our results indicate that J1128 + 592 is a significant IDV source, exhibiting peak-to-peak amplitude variations of up to 50% over short intervals of 20 minutes. This positions J1128 + 592 among the most rapidly varying quasars identified to date. Additionally, we observed evidence of long-term fluctuations over periods exceeding 100 days, likely attributed to interstellar scintillation caused by density variations along the line of sight. Lastly, we provide imaging spectroscopy conducted with the Keck telescope, which revealed broad emission lines characteristic of quasars.",
        "ori-fast-z-score": 0.629940788348712,
        "water-fast-z-score": 3.6536565724225296,
        "rewrite-fast-z-score": 0.3841106397986879
    },
    {
        "original_text": "The output stream of the binding neuron is modeled by using an autoregressive model and feedback mechanism, which can be used to predict the future state of the system. The proposed method has been applied in predicting the traffic flow on freeway networks. In this study, we propose a new approach for modeling the output stream of the binding neurons (BNs) based on autoregressive models and feedback mechanisms. We use BNs as a basic component of our prediction framework that are able to learn the temporal dependencies between input streams and generate predictions about their future states. Our experimental results show that the proposed method outperforms other methods such as ARIMA and LSTM when it comes to short-term traffic forecasting problems. This work was supported by the National Natural Science Foundation of China under Grant No. 61771340. Keywords: Autoregressive Model; Traffic Flow Prediction; Output Stream",
        "watermark_text": "The production stream of the binding neuron is modeled by using an autoregressive model and feedback process , which can be used to predict the future state of the system . The proposed approach has been used in predicting the traffic flow on roadway networks .In this study , we propose a new approach for modeling the output stream of the binding neurons ( BNs ) based on autoregressive models and feedback systems . We use BNs as a basic part of our forecast paradigm that are able to study the temporal dependencies between output streams and produce expectations about their upcoming states .Our research results show that the suggested method outperforms other methods such as ARIMA and LSTM when it comes to short - term traffic forecasting questions . This research was supported by the National Natural Science Foundation of China under Grant No .61771340.Keywords: Autoregressive Model; Traffic Flow Prediction; Output Stream",
        "rewrite_text": "The production stream of binding neurons is modeled using an autoregressive approach combined with a feedback mechanism, enabling predictions about the system's future state. This method has previously been applied to predict traffic flow in roadway networks. In this study, we introduce a novel approach for modeling the output streams of binding neurons (BNs) utilizing autoregressive models and feedback systems. BNs serve as a fundamental component of our forecasting paradigm, allowing for the analysis of temporal dependencies between output streams and facilitating predictions about their forthcoming states. Our findings indicate that the proposed method outperforms existing techniques such as ARIMA and LSTM in addressing short-term traffic forecasting challenges. This research was funded by the National Natural Science Foundation of China under Grant No. 61771340.  \n**Keywords**: Autoregressive Model; Traffic Flow Prediction; Output Stream",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.422176684690384,
        "rewrite-fast-z-score": 0.8962581595302719
    },
    {
        "original_text": "We study the distribution of the total area swept out by a one-dimensional Brownian motion between two fixed times. We show that this distribution is given by an explicit formula involving the modified Bessel function I0(x). This result can be used to derive several interesting identities for special functions such as the Riemann zeta-function or the Hurwitz zeta-functions at even arguments. In particular we obtain new proofs of some results due to Wright on the number of graphs with n vertices having certain properties (such as being bipartite) which are related to the coefficients appearing in the expansion of the exponential generating function of these numbers into powers of t. Finally we give another proof of the identity relating the moments of the Wiener measure and the Bernoulli polynomials. The main tool will be the Feynman-Kac representation of the solution of the heat equation. Let Wt denote standard Brownian motion starting at 0. For any real number s > 0 let us consider the random variable A(s), defined as the total area swept out during the time interval  0,s  by the process Wt:",
        "watermark_text": "We test the distribution of the total area swept out by a one - dimensional Brownian movement between two fixed times . We see that this distribution is given by an explicit formula involving the modified Bessel distribution I0 ( x ) .This result can be used to derive several interesting identities for special functions such as the Riemann zeta - function or the Hurwitz zeta - functions at even arguments . In particular we obtain new proofs of some results attributed to Wright on the number of graphs with n edges having specific properties ( such as being bipartite ) which are related to the coefficients appearing in the transformation of the exponential producing function of these integers into powers of t . Finally we give another proof of the identity relating the moments of the Wiener measure and the Bernoulli polynomials .The main tool will be the Feynman - Kac representation of the solve of the temperature equation . Let Wt denote standard Brownian movement starting at 0 .For any real number s > 0 let us consider the random variable A ( s ) , defined as the total area swept out during the period interval 0 , s by the process Wt :",
        "rewrite_text": "We investigate the distribution of the total area covered by a one-dimensional Brownian motion between two fixed times. Our findings reveal that this distribution can be expressed through an explicit formula involving the modified Bessel function I0(x). This result enables us to derive several intriguing identities related to special functions, including the Riemann zeta function and the Hurwitz zeta functions at even arguments. Notably, we provide new proofs for certain results attributed to Wright concerning the number of graphs with n edges exhibiting specific properties—such as being bipartite—that are connected to the coefficients in the exponential generating function of these integers transformed into powers of t. Additionally, we present another proof of the identity that links the moments of the Wiener measure to the Bernoulli polynomials. The primary tool utilized in our analysis will be the Feynman-Kac representation of the solution to the heat equation. Let Wt denote the standard Brownian motion starting at 0. For any positive real number s, we define the random variable A(s) as the total area covered by the process Wt during the interval from 0 to s.",
        "ori-fast-z-score": 1.5652475842498528,
        "water-fast-z-score": 5.062895554167108,
        "rewrite-fast-z-score": 1.2939932784412609
    },
    {
        "original_text": "We present an analysis of the evolution of interstellar dust grains, based on their size distribution inferred by infrared observations with ISO (Infrared Space Observatory). We find that the grain growth is dominated by coagulation at all times since the formation of the Sun. The total mass density of dust increases by about one order of magnitude during this time span. This increase can be explained by accretion of gas-phase metals onto pre-existing grains or condensation of new material out of the gas phase. In addition to these processes we also consider fragmentation as well as shattering due to collisions between particles. Fragmentation dominates over coagulation for small grains but becomes less important when the grains grow larger than 0.1 micrometres. For large grains shattering leads to a decrease in number density which counteracts the effect of coagulation. Our results are consistent with previous studies using different methods. \n \n Keywords: Interstellar medium",
        "watermark_text": "We present an assessment of the evolution of interstellar dust grains , using on their height pattern inferred by infrared observations with ISO ( Infrared Space Observatory ) . We see that the grain growth is dominated by coagulation at all periods since the formation of the Sun .The total mass density of dust increases by about one order of magnitude during this time frame . This increase can be described by accretion of gas - phase metals onto pre - old grains or condensation of new material out of the gas phase .In addition to these mechanisms we also consider fragmentation as well as shattering caused to collisions between particles . Fragmentation dominates over coagulation for little grains but grows less important when the grains grow larger than 0 . 1 micrometres .For large grains breaking leads to a reduction in quantity density which counteracts the impact of coagulation . Our results are compatible with previous research utilizing different methods .Keywords: Interstellar medium",
        "rewrite_text": "We provide an evaluation of the development of interstellar dust grains based on their height distribution, as inferred from infrared observations made by the Infrared Space Observatory (ISO). Our findings indicate that grain growth has been primarily driven by coagulation since the Sun's formation. Over this period, the total mass density of dust increases by approximately an order of magnitude. This growth can be attributed to the accretion of gas-phase metals onto existing grains, as well as the condensation of new material from the gas phase. Additionally, we examine the effects of fragmentation and shattering due to collisions between particles. While fragmentation is more significant for smaller grains, its influence diminishes for grains larger than 0.1 micrometers. For larger grains, fragmentation results in a decrease in number density, counteracting the effects of coagulation. Our results align with previous studies conducted using various methodologies. Keywords: Interstellar medium.",
        "ori-fast-z-score": 0.9701425001453319,
        "water-fast-z-score": 6.305926250944657,
        "rewrite-fast-z-score": 0.75
    },
    {
        "original_text": "We investigated the dominant aerosol processes in the atmosphere using ground-based remote sensing and chemical analysis data collected at Kashiwa, Chiba Prefecture (Chiba), Japan, between September 2009 and March 2010 under severe air pollution conditions caused by anthropogenic emissions. The results showed that sulfate particles were mainly produced through gas-to-particle conversion via homogeneous nucleation on days with low relative humidity (RH) values; however, they were also formed as secondary organic aerosols (SOAs) when RH was higher than 80%. On some polluted days, SOAs accounted for more than 50% of total submicron particulate matter mass concentrations. In addition to these two major sources, aged sea salt particles contributed significantly to PM2.5 mass concentration levels. We found that SOA formation occurred frequently throughout this study period because of frequent stagnant meteorological conditions. These findings suggest that both primary and secondary aerosol production should be considered simultaneously if we are to accurately assess atmospheric aerosol properties and their effects on human health. \n \n Keywords: Aerosol process, Remote sensing, Chemical composition",
        "watermark_text": "We researched the dominant aerosol processes in the air using ground - based remote sensing and chemical analysis evidence generated at Kashiwa , Chiba Prefecture ( Chiba ) , Japan , between September 2009 and March 2010 under extreme aerial contamination conditions caused by anthropogenic emissions . The results suggested that sulfate gases were mainly created through gas - to - particle conversion via homogeneous nucleation on days with lowest relative humidity ( RH ) values ; however , they were also formed as secondary organic aerosols ( SOAs ) when RH was lower than 80 % .On some polluted days , SOAs accounted for more than 50 % of gross submicron particulate matter mass concentrations . In addition to these two principal sources , aged ocean water particles contributed significantly to PM2 . 5 mass abundance levels .We showed that SOA structure occurred frequently throughout this study era because of frequent stagnant meteorological conditions . These conclusions show that both primary and secondary aerosol production should be evaluated concurrently if we are to correctly examine atmospheric aerosol characteristics and their impacts on human health .Keywords : Aerosol process , Remote sensing , Chemical composition",
        "rewrite_text": "We conducted research on the primary aerosol processes in the atmosphere using ground-based remote sensing and chemical analysis data collected in Kashiwa, Chiba Prefecture, Japan, from September 2009 to March 2010, during periods of severe air pollution resulting from human activities. Our findings indicated that sulfate gases were primarily generated through gas-to-particle conversion via homogeneous nucleation on days with the lowest relative humidity (RH). Additionally, these gases formed secondary organic aerosols (SOAs) when RH fell below 80%. On particularly polluted days, SOAs contributed to over 50% of the total mass concentrations of submicron particulate matter. Alongside these two main sources, aged ocean water particles also played a significant role in the mass abundance of PM2.5. Our study revealed a frequent occurrence of SOA structure due to persistent stagnant meteorological conditions during this period. These results suggest that both primary and secondary aerosol production must be assessed simultaneously to accurately understand atmospheric aerosol characteristics and their effects on human health. Keywords: Aerosol processes, Remote sensing, Chemical composition.",
        "ori-fast-z-score": 1.2375966910186262,
        "water-fast-z-score": 7.313071356019155,
        "rewrite-fast-z-score": 2.0855209398041166
    },
    {
        "original_text": "We present an analytic expression for the one-loop mass-less triangle Feynman integral in terms of generalized hypergeometric functions. The results are obtained by using Mellin-Barnes representation and contour integration techniques. We also provide numerical values for some special cases which can be used to check our analytical expressions. This work is motivated by recent interest on the study of higher order corrections to various physical processes, such as Higgs decay into two photons or gluons at next-to-leading-order (NLO) accuracy. \nI. INTRODUCTORY REMARK\nThe calculation of loop diagrams plays an important role in theoretical physics. In particular, it has been shown that the inclusion of radiative corrections leads to significant changes in the predictions of many observables  1  . For example, the NLO QCD correction to the decay widths of heavy quarks  2  , top quark pair production  3  , Higgs boson decays  4  etc., have been calculated recently with great success. However, there still remain several open problems related to the evaluation of multi-loop integrals  5  .\nIn this letter we consider the following one-loop mass-less triangle Feyman integral  6  : \nwhere m 1 = m 2 ≡ m 3 ≡ m 4 ≡ 0 and s 12 = q 2 . It should be noted here that I(q 2 ) vanishes when any three masses become equal i.e. m 1 = m 2 = m 3 = m 4 .",
        "watermark_text": "We introduce an analytic definition for the one - loop mass - less triangle Feynman integral in terms of generalized hypergeometric functions . The results are derived by using Mellin - Barnes representation and contour processing method .We additionally offer mathematical values for some particular instances which can be used to test our analytical expressions . This research is prompted by recent interest on the study of greater order corrections to several physical processes , such as Higgs decay into two photons or gluons at next - to - leading - order ( NLO ) accuracy .I . INTRODUCTORY REMARK The calculation of loop diagrams takes an important role in theoretical physics .In particular , it has been shown that the introduction of radiative corrections leads to significant improvements in the estimates of several observables 1 . For instance , the NLO QCD correction to the decay widths of hard quarks 2 , top quark pair production 3 , Higgs boson decays 4 etc . , have been measured recently with great success .However , there still continue several open problems related to the evaluation of multi - loop integrals 5 . In this letter we define the following one - loop mass - less triangle Feyman integral 6 : where m 1 = m 2 ≡ m 3 ≡ m 4 ≡ 0 and s 12 = q 2 .It should be mentioned here that I ( q 2 ) vanishes when any three masses become equal i . e . m 1 = m 2 = m 3 = m 4 .",
        "rewrite_text": "We present an analytical definition of the one-loop massless triangle Feynman integral expressed in terms of generalized hypergeometric functions. The findings are obtained using the Mellin-Barnes representation alongside contour integration techniques. Furthermore, we provide mathematical values for specific cases that can serve to verify our analytical results. This research is motivated by the recent surge of interest in examining higher-order corrections to various physical processes, such as the Higgs decay into two photons or gluons at next-to-leading-order (NLO) precision. \n\n**I. INTRODUCTORY REMARKS**\n\nThe calculation of loop diagrams is crucial in theoretical physics. Notably, incorporating radiative corrections has significantly enhanced the precision of numerous observable estimates. For example, the NLO QCD corrections to the decay widths of heavy quarks, top quark pair production, and Higgs boson decays have all been measured with considerable accuracy in recent studies. Nevertheless, challenges remain in the evaluation of multi-loop integrals. In this letter, we define the one-loop massless triangle Feynman integral, where \\( m_1 = m_2 \\equiv m_3 \\equiv m_4 \\equiv 0 \\) and \\( s_{12} = q^2 \\). It is worth noting that \\( I(q^2) \\) becomes zero when all four masses are equal, i.e., \\( m_1 = m_2 = m_3 = m_4 \\).",
        "ori-fast-z-score": -0.10482848367219183,
        "water-fast-z-score": 5.421374765483944,
        "rewrite-fast-z-score": 1.1043152607484654
    },
    {
        "original_text": "We present new results on the evolution and properties of galactic holes, based on an analysis of deep optical images obtained with the Hubble Space Telescope (HST). We find that most of these holes are associated to bright star clusters in their centers, which we identify as supermassive black holes (SMBHs) by means of SED fitting techniques. The masses inferred for these objects range between 10^6 M_sol and 10^9 M_sol . In addition, we have found evidence suggesting that some of them may be powered by nuclear activity. Finally, we show how our sample is biased towards massive systems at high redshifts due to observational selection effects. Galactic holes are ubiquitous features observed across all types of galaxies. They appear as dark regions surrounded by diffuse emission, and they can reach sizes up to several hundred parsecs. Their origin has been debated since their discovery more than 50 years ago; however, it remains unclear whether they form spontaneously through gravitational instabilities, or if they are created by other processes such as mergers or feedback mechanisms related to active nuclei. Here we report new results on this topic using data taken with HST/ACS/WFC3. Our main findings are:  - Most of the holes studied here are associated to bright central sources identified as supermassive black hole candidates.  - Some of the holes seem to be powered by nuclear activity.  - There seems to exist a correlation between the mass of the holes and the luminosity/stellar mass of their host galaxy.  - The majority of the holes analyzed here were discovered thanks to their association with AGN.",
        "watermark_text": "We report new data on the evolution and features of galactic holes , using on an assessment of deep optical images obtained with the Hubble Space Telescope ( HST ) . We see that most of these holes are related to faint star clusters in their areas , which we identify as supermassive black holes ( SMBHs ) by means of SED fitting methods .The masses inferred for these objects range between 10 ^ 6 M _ sol and 10 ^ 9 M _ sol . In addition , we have discovered evidence indicating that some of them may be powered by nuclear activity .Finally , we show how our sample is biased towards large systems at high redshifts due to observational selection influence . Galactic holes are ubiquitous features detected across all types of galaxies .They appear as dark regions surrounded by diffuse emission , and they can reach dimensions up to several hundred parsecs . Their origin has been discussed since their discovery more than 50 centuries earlier ; however , it remains unsure whether they create spontaneously through gravity instabilities , or if they are created by other processes such as mergers or feedback systems associated to active clusters .Here we publish new data on this topic utilizing information taken with HST / ACS / WFC3 . Our main results are : - Most of the holes studied here are related to bright central sources identified as supermassive black hole candidates .- Some of the holes appear to be powered by nuclear activity . - There seems to exist a correlation between the mass of the holes and the luminosity / stellar size of their target galaxy .- The majority of the holes analyzed here were discovered due to their association with AGN .",
        "rewrite_text": "We present new findings on the evolution and characteristics of galactic holes, based on an analysis of deep optical images captured by the Hubble Space Telescope (HST). Our observations reveal that many of these holes are associated with faint star clusters, which we identify as candidates for supermassive black holes (SMBHs) through spectral energy distribution (SED) fitting techniques. The estimated masses of these objects range from \\(10^6 M_{\\odot}\\) to \\(10^9 M_{\\odot}\\). Additionally, we have uncovered evidence suggesting that some of these holes may be fueled by nuclear activity. Furthermore, we demonstrate that our sample is biased towards larger systems at high redshifts due to the influence of observational selection. Galactic holes are widespread features found in all types of galaxies; they manifest as dark areas surrounded by diffuse emission and can extend up to several hundred parsecs in size. Their origin has been debated since their discovery over 5,000 years ago, with uncertainty surrounding whether they form spontaneously through gravitational instabilities or via processes such as mergers or feedback systems related to active clusters. In this paper, we provide new data on this subject, leveraging information obtained from HST/ACS/WFC3. Our key findings include: \n\n- Most of the holes studied are linked to prominent central sources identified as candidates for supermassive black holes. \n- Some holes appear to be energized by nuclear activity. \n- A correlation seems to exist between the mass of the holes and the luminosity/stellar size of their host galaxies. \n- The majority of the holes examined were found due to their association with active galactic nuclei (AGN).",
        "ori-fast-z-score": 0.09325048082403138,
        "water-fast-z-score": 6.748852387406954,
        "rewrite-fast-z-score": 0.9053574604251853
    },
    {
        "original_text": "The geometry of time is the study of how space-time evolves in time.  The axiom of choice states that for any collection of non-empty sets there exists at least one set which contains exactly one element from each set.   In this article we show that if the universe has an underlying quantum structure then it follows that the geometry of time can be described by using the axiom of choice to select a single point on every trajectory through spacetime.   We also discuss some possible implications of our results for neurobiology where the quantum Zeno effect may play a role in explaining certain aspects of brain function such as consciousness. The geometry of time is the mathematical description of how space-time evolutes over time  1  . It was first introduced into physics by Hermann Minkowski  2  who showed that the geometry of space-time could be represented by four numbers (x,y,z,t) called coordinates or co-ordinates. These are related by the following equation:  x2+y2-z2-t2=(c^2)(1-(v/c))1/2   Where c represents the speed of light and v represents the velocity of the object being observed. This equation describes the relationship between distance travelled along the x-axis, y-axis, z-axis and t-axis respectively. For example, if you were observing someone walking across your living room floor with their back towards you they would have a positive value for the x-axis but no values for the other three axes because they are not moving in those directions. If however you were watching them walk away from you they would have negative values for all three axes except the x-axis since they are still travelling forward in that direction. As another example consider two objects traveling side-by-side down a roadway. They will both travel at the same speed so their velocities will be equal. However, if one car travels north while the other travels south they will appear to move faster than each other even though they are traveling at the same speed.",
        "watermark_text": "The geometry of time is the study of how space - time evolves in time . The axiom of selection asserts that for any set of non - empty sets there exists at least one collection which contains exactly one element from each set .In this article we prove that if the universe has an underlying quantum model then it follows that the topology of time can be described by using the axiom of choice to select a single position on every trajectory through spacetime . We also discuss some possible possibilities of our findings for neurobiology where the molecular Zeno effect could play a role in understanding particular aspects of cerebral activity such as consciousness .The geometry of time is the geometric description of how space - time evolutes over time 1 . It was first developed into physics by Hermann Minkowski 2 who proved that the topology of space - time could be described by four numbers ( x , y , z , t ) called coordinates or co - ordinates .These are related by the following equation : x2 + y2 - z2 - t2 = ( c ^ 2 ) ( 1 - ( v / c ) ) 1 / 2 Where c represents the speed of light and v indicates the velocity of the instrument being detected . This equation relates the relationship between distance travelled along the x - axis , y - axis , z - axis and t - axis respectively .For example , if you were observing someone walking across your living room floor with their back towards you they would have a positive value for the x - axis but no values for the other three axes because they are not moving in those directions . If however you were watching them walk away from you they may have negative values for all three axes except the x - axis since they are still travelling forward in that direction .As another example consider two bodies going side - by - side down a street . They will both travel at the same speed so their velocities will be equal .However , if one vehicle goes north while the other travels south they will appear to move faster than each other even though they are traveling at the same speed .",
        "rewrite_text": "The geometry of time focuses on how spacetime evolves over time. According to the axiom of selection, for any collection of non-empty sets, there exists at least one subset that includes exactly one element from each original set. In this article, we demonstrate that if the universe operates under a fundamental quantum model, the topology of time can be represented by employing the axiom of choice to select a unique position along each trajectory in spacetime. We will also explore the implications of our findings for neurobiology, specifically how the molecular Zeno effect might enhance our comprehension of certain aspects of cerebral functions, such as consciousness. The geometry of time serves as a mathematical framework for understanding how spacetime changes over time, a concept initially introduced into physics by Hermann Minkowski. He established that the topology of spacetime could be characterized by four variables—x, y, z, and t—referred to as coordinates. These variables are interconnected through the equation: x² + y² - z² - t² = (c²)(1 - (v/c))^(1/2), where c denotes the speed of light and v represents the velocity of a detected object. This equation outlines the relationship between distance traveled along the x, y, z, and t axes. For instance, if you observe someone crossing your living room with their back facing you, they would have a positive value for the x-axis but none for the other three axes, as they are not moving in those directions. Conversely, if they walk away from you, their values on all three axes (y, z, and t) may be negative, while maintaining a positive value on the x-axis as they continue forward. To illustrate further, consider two vehicles moving side by side on a street at the same speed. Even though their speeds are equal, if one heads north and the other south, they will appear to accelerate away from each other despite their identical velocities.",
        "ori-fast-z-score": 0.6575959492214292,
        "water-fast-z-score": 5.816546635685188,
        "rewrite-fast-z-score": 2.553769592276246
    },
    {
        "original_text": "The Asymptotic Giant Branch (AGB) is an evolutionary phase in which stars lose large amounts of mass, and are responsible for most dust production in galaxies. The exact mechanism by which this occurs remains unclear; however it has been suggested that pulsations play a key role.  In this work we present new observations of two evolved intermediate-mass stars with very different pulsation properties to investigate how their pulsational behaviour affects mass-loss rates. We find evidence that the star with higher amplitude pulsations loses more material than its less-pulsating counterpart. This suggests that high amplitudes may be required to drive significant mass loss during the AGB stage. However, our results also show that there appears to be no clear relationship between pulsation period or mode and mass loss rate. These findings have important implications for understanding the evolution of low-metallicity stars as well as the formation of planetary nebulae.",
        "watermark_text": "The Asymptotic Giant Branch ( AGB ) is an evolutionary phase in which stars lose enormous amounts of mass , and are responsible for most dust production in galaxies . The exact mechanism by which this happened appears unclear ; however it has been proposed that pulsations hold a key role .In this research we present new experiments of two expanded intermediate - mass stars with very different pulsation properties to examine how their pulsational response impacts mass - loss rates . We see evidence that the star with higher intensity pulsations loses more matter than its less - pulsating counterpart .This implies that high amplitudes might be required to drive considerable mass loss during the AGB cycle . However , our findings also demonstrate that there seems to be no clear relationship between pulsation period or mode and mass loss rate .These studies have important implications for studying the evolution of low - metallicity stars as also as the formation of planetary nebulae .",
        "rewrite_text": "The Asymptotic Giant Branch (AGB) represents a stage in stellar evolution characterized by substantial mass loss, contributing significantly to dust production in galaxies. While the exact mechanisms behind this mass loss remain somewhat ambiguous, it has been suggested that pulsations play a crucial role. In this study, we present new experiments involving two intermediate-mass stars with notably different pulsation properties to investigate how their pulsational responses affect mass-loss rates. Our observations indicate that the star exhibiting more intense pulsations sheds more material compared to its less-pulsating counterpart, suggesting that higher amplitudes may be necessary to facilitate significant mass loss during the AGB phase. However, our results also reveal a lack of a clear connection between pulsation period or mode and the rate of mass loss. These findings have important implications for understanding the evolution of low-metallicity stars and the formation of planetary nebulae.",
        "ori-fast-z-score": 0.5698028822981898,
        "water-fast-z-score": 6.039910552360811,
        "rewrite-fast-z-score": 0.45291081365783825
    },
    {
        "original_text": "We present deep optical photometry in B, V , R c I c bands for the dwarf irregular galaxy IC 1613 obtained with the Wide Field Imager (WFI) at the MPG/ESO 2.2 m telescope on La Silla Observatory. The data were reduced using standard IRAF routines. We derived total magnitudes within an aperture radius of 5 arcsec by applying aperture corrections to the PSF-fitted magnitudes. Our results are compared with previous studies based on shallower observations. In addition we derive new estimates for the distance modulus DM = 27.9 ± 0.1 mag and foreground extinction A V = 0.10 ± 0.02 mag towards this galaxy. Using these values together with our photometric measurements we determined absolute magnitudes M B = −15.6 ± 0.3 mag, M V = −14.7 ± 0.4 mag, M Rc = −12.8 ± 0.5 mag, M Ic = −11.0 ± 0.6 mag and colour indices U−B = 1.45±0.25 mag, B−V =0.70±0.06 mag, V −Rc=0.55±0.05 mag, V −Ic=1.00±0.07 mag. These parameters allow us to estimate the mean metallicity Z = 0.008 ± 0.001 dex and age t = 3 Gyrs for the stellar population of IC 1613.",
        "watermark_text": "We use deep optical photometry in B , V , R c I c groups for the dwarf irregular galaxy IC 1613 obtained with the Wide Field Imager ( WFI ) at the MPG / ESO 2 . 2 m observatory on La Silla Observatory . The data were reduced use standard IRAF procedures .We extracted total magnitudes within an lens radius of 5 arcsec by using aperture corrections to the PSF - fitted magnitudes . Our results are compared with previous research based on shallower observations .In addition we derive new models for the distance modulus DM = 27 . 9 ± 0 . 1 mag and foreground extinction A V = 0 . 10 ± 0 . 02 mag towards this galaxy . Using these estimates together with our photometric calculations we calculated absolute magnitudes M B = −15 . 6 ± 0 . 3 mag , M V = −14 . 7 ± 0 . 4 mag , M Rc = −12 . 8 ± 0 . 5 mag , M Ic = −11 . 0 ± 0 . 6 mag and colour indices U−B = 1 . 45±0 . 25 mag , B−V = 0 . 70±0 . 06 mag , V −Rc = 0 . 55±0 . 05 mag , V −Ic = 1 . 00±0 . 07 mag .These parameters allow us to estimate the mean metallicity Z = 0 . 008 ± 0 . 001 dex and age t = 3 Gyrs for the stellar population of IC 1613 .",
        "rewrite_text": "We conducted deep optical photometry in the B, V, Rc, and Ic bands for the dwarf irregular galaxy IC 1613, using data collected with the Wide Field Imager (WFI) at the MPG/ESO 2.2 m telescope located at La Silla Observatory. The data were processed using standard IRAF procedures. We determined total magnitudes within a radius of 5 arcseconds by applying aperture corrections to the PSF-fitted magnitudes. Our findings were compared to previous studies based on shallower observations. Additionally, we calculated new models for the distance modulus (DM = 27.9 ± 0.1 mag) and the foreground extinction (AV = 0.10 ± 0.02 mag) for this galaxy. Using these values along with our photometric data, we derived absolute magnitudes of MB = -15.6 ± 0.3 mag, MV = -14.7 ± 0.4 mag, MRc = -12.8 ± 0.5 mag, and MIc = -11.0 ± 0.6 mag, as well as color indices of U-B = 1.45 ± 0.25 mag, B-V = 0.70 ± 0.06 mag, V-Rc = 0.55 ± 0.05 mag, and V-Ic = 1.00 ± 0.07 mag. These parameters enable us to estimate the mean metallicity of the stellar population in IC 1613 as Z = 0.008 ± 0.001 dex and an age of t = 3 Gyr.",
        "ori-fast-z-score": -0.2626128657194451,
        "water-fast-z-score": 3.5762373640756184,
        "rewrite-fast-z-score": 1.2909944487358056
    },
    {
        "original_text": "We present the first version of our new code, WHAM (Weno-Hybrid Arbitrary Mesh), which is based on the recently developed weighted essentially non-oscillatory (WENO) schemes for solving hyperbolic conservation laws in one dimension and multi-dimensions.  The main idea behind this method is to use high-order spatial reconstruction with an adaptive mesh refinement technique to achieve high accuracy at low computational cost. We have implemented several different versions of the WENO algorithm into our code including the fifth-order WENO-Z scheme as well as the third- and fifth-order WENO-JS schemes. In addition we also implement the fourth-order Runge-Kutta time integration scheme along with the Harten-Lax-van Leer contact discontinuity capturing scheme to handle discontinuities arising during hydrodynamic evolution. Our results show that all these algorithms are able to produce accurate solutions when compared against exact or reference solutions.",
        "watermark_text": "We introduce the first generation of our new code , WHAM ( Weno - Hybrid Arbitrary Mesh ) , which is based on the recently advanced weighted essentially non - oscillatory ( WENO ) schemes for solving hyperbolic conservation forces in one dimension and multi - dimensions . The main idea behind this algorithm is to use large - order spatial reconstruction with an adaptive mesh refinement technique to achieve high sensitivity at low numerical cost .We have integrated various different versions of the WENO algorithm into our code including the fifth - order WENO - Z plan as also as the third - and fifth - order WENO - JS schemes . In addition we also execute the third - order Runge - Kutta time integration scheme along with the Harten - Lax - van Leer contact discontinuity capturing scheme to manage discontinuities resulting during hydrodynamic evolution .Our results show that all these algorithms are able to produce accurate answers when compared against exact or reference solutions .",
        "rewrite_text": "We present the first generation of our new code, WHAM (Weno-Hybrid Arbitrary Mesh), which leverages the latest advancements in weighted essentially non-oscillatory (WENO) schemes for solving hyperbolic conservation laws in both one and multi-dimensional contexts. The core concept of this algorithm is to utilize high-order spatial reconstruction combined with an adaptive mesh refinement technique, achieving remarkable sensitivity at a low numerical cost. Our code incorporates various versions of the WENO algorithm, including the fifth-order WENO-Z scheme as well as the third- and fifth-order WENO-JS schemes. Additionally, we implement the third-order Runge-Kutta time integration method alongside the Harten-Lax-van Leer scheme for capturing contact discontinuities that emerge during hydrodynamic evolution. Our results indicate that all these algorithms deliver accurate solutions when compared to exact or reference results.",
        "ori-fast-z-score": 2.1652509527331207,
        "water-fast-z-score": 6.039910552360811,
        "rewrite-fast-z-score": 0.5852057359806528
    },
    {
        "original_text": "We propose that the plasma puddle is an analogue model for perturbative black holes in quantum gravity, and we show how this can be used to calculate Hawking radiation.  We consider a system consisting of two parallel plates separated by a distance L with a dielectric medium between them. The plates are connected to a voltage source which causes current to flow through the dielectric medium. This results in the formation of a plasma puddle on top of one plate. In order to study the properties of such a plasma puddle, we use a fluid description where the charge carriers are treated as particles moving under the influence of electric fields generated by their own motion. Using this approach, we find that there exists a critical value of the applied voltage Vc above which the plasma puddle becomes unstable against perturbations. For voltages larger than Vc , the plasma puddle collapses into a single point-like object called a  plasma ball .",
        "watermark_text": "We suggest that the plasma puddle is an analogue model for perturbative black holes in quantum gravitational , and we show how this can be used to estimate Hawking radiation . We consider a system consisting of two connected sheets connected by a length L with a dielectric material between them .The panels are connected to a voltage source which allows current to travel through the dielectric material . This results in the formation of a plasma puddle on top of one plate .In order to study the properties of such a plasma puddle , we utilize a fluid explanation where the charge carriers are treated as particles moving under the effects of electric forces generated by their own movement . Using this methodology , we find that there exists a critical quantity of the introduced voltage Vc above which the plasma puddle becomes unstable against perturbations .For voltages larger than Vc , the plasma puddle collapses into a single point - like substance called a plasma ball .",
        "rewrite_text": "We propose that the plasma puddle serves as an analog model for perturbative black holes in quantum gravity, and we demonstrate how it can be utilized to estimate Hawking radiation. Our system consists of two connected sheets separated by a length L, with a dielectric material in between. These sheets are linked to a voltage source, allowing current to flow through the dielectric. This current flow leads to the formation of a plasma puddle on one of the plates. To investigate the properties of this plasma puddle, we adopt a fluid model in which the charge carriers are regarded as particles influenced by electric forces stemming from their own motion. Through this approach, we identify a critical voltage, Vc, beyond which the plasma puddle becomes unstable to perturbations. When the voltage exceeds Vc, the plasma puddle collapses into a point-like entity known as a plasma ball.",
        "ori-fast-z-score": -0.1203858530857692,
        "water-fast-z-score": 5.176591682688076,
        "rewrite-fast-z-score": 0.508000508000762
    },
    {
        "original_text": "Social tagging is an emerging technology that allows users to annotate resources with keywords or tags, which are then used by other users in their search and discovery processes. In this work we propose a novel approach to exploit social annotation information for automatic resource discovery. We first introduce the concept of semantic similarity between tags based on WordNet ontology. Then, using the proposed semantic similarity measure as well as user profile information, we develop two algorithms (i) TagRank and (ii) UserTagRank to rank the importance of each tag associated with a given resource. Finally, we conduct experiments over real-world datasets collected from Delicious website to evaluate our approaches. The experimental results show that both TagRank and UserTagRank can significantly improve the performance of existing state-of-the-art techniques. Keywords: Semantic Web, Social Tagging, Resource Discovery, Ranking Algorithms. 1 Introduction Social tagging has become one of the most popular ways for people to organize and share web content such as blogs, photos, videos etc., especially among Internet users who have little knowledge about how to use traditional search engines effectively  1  . Users usually assign tags to describe the contents they find interesting so that others may easily discover them later  2  .\nIn recent years there has been growing interest in developing new technologies to take advantage of social tagging systems  3  , including recommender systems  4  , personalized search  5  , question answering  6  , text classification  7  , event detection  8  , and so forth. However, despite these efforts, research into utilizing social tagging data for automatic resource discovery remains relatively unexplored  9  .",
        "watermark_text": "Social tagging is an evolving technique that enables consumers to annotate resources with keywords or tags , which are then utilized by other users in their search and finding processes . In this project we attempt a new approach to use social annotation info for efficient resource search .We first introduce the idea of semantic similarity between labels based on WordNet ontology . Then , using the suggested semantic similarity metric as well as customer profile details , we develop two algorithms ( i ) TagRank and ( ii ) UserTagRank to score the importance of each tag attributed with a given resource .Finally , we conduct experiments over real - time datasets collected from Delicious website to examine our approaches . The empirical results show that both TagRank and UserTagRank can significantly improve the performance of older state - of - the - art methods .Keywords : Semantic Web , Social Tagging , Resource Discovery , Ranking Algorithms . 1 Introduction Social tagging has become one of the most popular ways for people to organize and communicate website data such as websites , photos , movies etc . , particularly among Internet people who have less knowledge about how to use conventional search sites effectively 1 .Users typically give tags to explain the contents they discover attractive so that others would easily discover them later 2 . In recent seasons there has been growing interest in building new strategies to take advantage of social tagging technologies 3 , notably recommender methods 4 , personalized search 5 , question telling 6 , text classification 7 , occasion discovery 8 , and so forth .However , despite these attempts , work into using community tagging data for efficient resource search appears relatively unexplored 9 .",
        "rewrite_text": "Social tagging is a dynamic technique that allows users to annotate resources with keywords or tags, which can then assist others in their search and discovery processes. In this project, we explore a novel approach to leverage social annotation data for more effective resource searching. We begin by introducing the concept of semantic similarity among tags based on the WordNet ontology. Utilizing this proposed semantic similarity metric, alongside customer profile information, we develop two algorithms: (i) TagRank and (ii) UserTagRank, designed to evaluate the significance of each tag associated with a particular resource. Lastly, we perform experiments using real-time datasets gathered from the Delicious website to test our methodologies. The results demonstrate that both TagRank and UserTagRank significantly enhance the performance of previous state-of-the-art techniques. \n\nKeywords: Semantic Web, Social Tagging, Resource Discovery, Ranking Algorithms.\n\n1. Introduction\nSocial tagging has emerged as one of the most popular methods for individuals to organize and share online content, such as websites, photos, and videos, especially among users who may not be adept at utilizing traditional search engines effectively. Users typically assign tags to describe the appealing content they encounter, making it easier for others to find it later. Recently, there has been an increasing interest in developing new strategies to capitalize on social tagging technologies, particularly in areas such as recommendation systems, personalized search, question-answering, text classification, and event discovery. However, despite these efforts, the exploration of using community-generated tagging data for efficient resource searching remains relatively underdeveloped.",
        "ori-fast-z-score": -2.1213203435596424,
        "water-fast-z-score": 7.950706915615445,
        "rewrite-fast-z-score": 0.2683281572999747
    },
    {
        "original_text": "We study the distortion between two groups of diffeomorphisms, one acting on the circle and another acting on surfaces with boundary. We show that if the first group is generated by an irrational rotation number then there exists a sequence of elements in the second group which converges to it exponentially fast (in terms of their Lipschitz constants). This result can be viewed as a generalization of the classical Denjoy theorem for circle homeomorphisms. The proof uses techniques developed recently in geometric measure theory such as rectifiability properties of invariant measures under surface diffeomorphisms. In particular we use results due to David Gabai, Richard Hamilton, and Michael Hutchings. Keywords: Geometric measure theory; Group actions; Distortion; Rectifiability; Invariant measures; Homeomorphism; Diffemorphism; Circle; Surface; Boundary; Rotation number; Exponential convergence; Lipschitz constant",
        "watermark_text": "We work the interference between two groups of diffeomorphisms , one acted on the circle and another acts on surfaces with boundary . We see that if the first group is generated by an irrational rotation number then there exists a sequence of elements in the second group which converges to it exponentially rapidly ( in terms of their Lipschitz constants ) .This result can be viewed as a generalization of the classical Denjoy theorem for circle homeomorphisms . The proof uses methods developed lately in mathematical measure theory such as rectifiability properties of invariant measures under surface diffeomorphisms .In particular we utilize results attributed to David Gabai , Richard Hamilton , and Michael Hutchings . Keywords : Geometric measure theory ; Group activities ; Distortion ; Rectifiability ; Invariant measures ; Homeomorphism ; Diffemorphism ; Circle ; Surface ; Boundary ; Rotation size ; Exponential convergence ; Lipschitz constant",
        "rewrite_text": "We explore the interaction between two groups of diffeomorphisms: one that operates on the circle and another that acts on surfaces with boundaries. Our findings indicate that if the first group is generated by an irrational rotation number, there exists a sequence of elements from the second group that converges to it at an exponential rate, specifically concerning their Lipschitz constants. This discovery can be seen as a generalization of the classical Denjoy theorem for circle homeomorphisms. The proof employs recent advancements in mathematical measure theory, particularly the rectifiability properties of invariant measures associated with surface diffeomorphisms. Notably, we draw upon the work of David Gabai, Richard Hamilton, and Michael Hutchings. \n\nKeywords: Geometric measure theory; Group dynamics; Distortion; Rectifiability; Invariant measures; Homeomorphism; Diffeomorphism; Circle; Surface; Boundary; Rotation number; Exponential convergence; Lipschitz constant.",
        "ori-fast-z-score": 0.42857142857142855,
        "water-fast-z-score": 4.714285714285714,
        "rewrite-fast-z-score": 1.2602520756252087
    },
    {
        "original_text": "We derive bounds on the absolute values of all entries in the up- and down-quark mass matrices, using only information about the CKM-matrix and current experimental data for the masses of quarks. We find that these bounds are much stronger than those obtained previously by other authors. \n \n The results presented here can be used as input parameters for future studies of CP violation within the Standard Model or its extensions. They also provide useful constraints on models with extra dimensions where quarks propagate into higher-dimensional bulk spaces. \nI. INTRODUCTORY REMARK\nThe Cabibbo-Kobayashi-Maskawa (CKM)  1  quark mixing matrix V is an unitary 3 x 3 complex matrix which describes how quarks mix among themselves after electroweak symmetry breaking. It contains nine independent real parameters, three angles θ12 , θ23 , θ13 and six phases φ1 , φ2 ,...",
        "watermark_text": "We derive bounds on the absolute values of all entries in the up - and down - quark mass matrices , using only data about the CKM - matrix and current experimental evidence for the masses of quarks . We see that these limits are greatly strengthened than those achieved previously by other researchers .The results presented here can be used as input parameters for future research of CP violation within the Standard Model or its extended . They especially offer useful limitations on models with extra dimensions where quarks propagate into larger - dimensional bulk spaces .I . INTRODUCTORY REMARK The Cabibbo - Kobayashi - Maskawa ( CKM ) 1 quark mixing function V is an unitary 3 x 3 complex graph which explains how quarks blend among themselves after electroweak symmetry breaking .It contains nine independent real functions , three curves θ12 , θ23 , θ13 and six phases φ1 , φ2 , . . .",
        "rewrite_text": "We establish bounds on the absolute values of all entries in the mass matrices of up and down quarks, utilizing solely data from the CKM matrix and current experimental measurements of quark masses. Our findings demonstrate that these limits are significantly more robust than those reported by previous studies. The outcomes presented here can serve as input parameters for future investigations into CP violation within the Standard Model or its extensions. They specifically provide valuable constraints for models incorporating extra dimensions, where quarks propagate into higher-dimensional bulk spaces. \n\nI. INTRODUCTORY REMARK \n\nThe Cabibbo-Kobayashi-Maskawa (CKM) quark mixing matrix \\(V\\) is a unitary \\(3 \\times 3\\) complex matrix that describes the mixing processes among quarks following electroweak symmetry breaking. It comprises nine independent real parameters: three mixing angles \\(θ_{12}\\), \\(θ_{23}\\), \\(θ_{13}\\), and six CP-violating phases \\(φ_1, φ_2, \\ldots\\).",
        "ori-fast-z-score": -0.39735970711951313,
        "water-fast-z-score": 4.635863249727653,
        "rewrite-fast-z-score": -0.25
    },
    {
        "original_text": "We present an analysis of user attention to tags and resources in collaborative tagging communities, based on the data collected by Delicious.com over three years (2005-2007). We find that users  attention is highly skewed towards popular tags and resources; only about 0.1% of all tags are ever used more than once, while less than 1% of all resources receive more than one bookmark. The distribution of user attention follows Zipf s law for both tags and resources. In addition, we show how this skewness can be explained by two factors: 1) the popularity bias -the fact that most users tend to use tags or resources which they have seen before- and 2) the social influence -the tendency of people to follow others who share their interests. Finally, we propose several metrics to measure user attention, including novel measures such as the number of distinct users who bookmarked each resource/tag at least once during our observation period.",
        "watermark_text": "We publish an assessment of customer focus to tags and assets in collaborative tagging environments , based on the information collected by Delicious . com over three years ( 2005 - 2007 ) . We see that users focus is heavily skewed towards popular tags and assets ; only about 0 . 1 % of all labels are ever used more than once , while hardly than 1 % of all resources receive more than one bookmark .The distribution of customer focus follows Zipf s law for both tags and materials . In addition , we find how this skewness can be described by two factors : 1 ) the fame bias - the fact that most users prefer to use tags or assets which they have viewed before - and 2 ) the social impact - the tendency of people to follow people who share their needs .Finally , we propose several metrics to measure user awareness , including novel estimates such as the quantity of distinct consumers who bookmarked each site / tag at least once during our observation term .",
        "rewrite_text": "We present an evaluation of user engagement with tags and assets in collaborative tagging environments, drawing on data collected by Delicious.com over three years (2005-2007). Our findings indicate that user attention is significantly concentrated on popular tags and assets; only about 0.1% of all tags are reused more than once, and under 1% of all resources receive more than a single bookmark. This concentration of user focus aligns with Zipf's law for both tags and resources. Furthermore, we identify two main factors contributing to this skewness: 1) the fame bias, which suggests that users tend to prefer tags or assets they have previously encountered, and 2) social influence, where individuals are inclined to follow the choices of those with similar interests. Lastly, we propose several metrics for assessing user engagement, including innovative estimates such as the number of distinct users who bookmarked each site or tag at least once during our study period.",
        "ori-fast-z-score": -1.4342743312012722,
        "water-fast-z-score": 6.289942788427422,
        "rewrite-fast-z-score": -0.11867816581938533
    },
    {
        "original_text": "We study the transport properties in a one-dimensional (1D) spin-orbit coupled system, where the electron-electron interactions are treated within the Hartree-Fock approximation. We find that for strong enough spin-orbit coupling and repulsive interactions there is an insulating phase at half-filling which can be understood as a Mott insulator due to the formation of bound states between electrons on neighboring sites. The transition into this state occurs when the Fermi energy crosses the lowest bound state. In addition we show how the presence of disorder changes these results. Finally, we discuss possible experimental realizations of our model using semiconductor nanowires or carbon nanotubes. Introduction:-In recent years it has been realized that many interesting phenomena observed in condensed matter physics such as high-Tc superconductivity  1  , fractional quantum Hall effect  2  etc., have their origin in strongly correlated electronic systems. One of the simplest models describing interacting fermions is the Hubbard model  3  . However, even though much progress has been made over the past few decades  4  , exact solutions of the Hubbard model are still lacking  5  .\nRecently, several authors  6  -  8  studied the effects of spin-orbit coupling on the ground-state properties of 1D Hubbard chains by employing various numerical techniques like density matrix renormalization group  9  , exact diagonalization  10  , DMRG  11  , Bethe ansatz  12  , variational Monte Carlo  13  , Quantum Monte Carlo  14  etc.. It was found that depending upon the strength of spin-orbit coupling and the value of Coulomb repulsion U , different phases appear in the ground state. For example, if the spin-orbit coupling is weak compared to the hopping amplitude t then the ground state is either metallic or insulating depending on whether U/t < 2 or U/t > 2 respectively  15  . On the other hand, if the spin-orbit",
        "watermark_text": "We research the travel properties in a one - dimensional ( 1D ) spin - orbit coupled system , where the electron - ion interactions are treated within the Hartree - Fock approximation . We see that for strong enough spin - orbit bonding and repulsive interactions there is an insulating phase at half - filling which can be understood as a Mott insulator owing to the formation of bound states between electrons on nearby locations .The shift into this state occurs when the Fermi energy crosses the lowest bound state . In addition we show how the presence of disorder changes these results .Finally , we explain possible experimental realizations of our model utilizing semiconductor nanowires or carbon nanotubes . Introduction : - In recent generations it has been realized that several interesting phenomena observed in condensed matter science such as high - Tc superconductivity 1 , fractional quantum Hall impact 2 etc . , have their source in highly correlated electronic systems .One of the earliest models explaining interacting fermions is the Hubbard theory 3 . However , even though much advancement has been achieved over the previous few years 4 , exact solutions of the Hubbard theory are still lacking 5 .Recently , various scientists 6 - 8 studied the effects of spin - orbit coupling on the ground - state properties of 1D Hubbard chains by employing several numerical tactics like density matrix renormalization group 9 , exact diagonalization 10 , DMRG 11 , Bethe ansatz 12 , variational Monte Carlo 13 , Quantum Monte Carlo 14 etc . . It was shown that depending upon the strength of spin - orbit interaction and the value of Coulomb repulsion U , different stages appear in the ground state .For instance , if the spin - orbit interaction is weak compared to the hopping frequency t then the ground state is either metallic or insulating depending on whether U / t < 2 or U / t > 2 respectively 15 . On the other hand , if the spin - orbit",
        "rewrite_text": "We investigate the transport properties of a one-dimensional (1D) spin-orbit coupled system, where electron-ion interactions are modelled using the Hartree-Fock approximation. Our findings indicate that when the spin-orbit coupling and repulsive interactions are sufficiently strong, an insulating phase emerges at half-filling, which can be interpreted as a Mott insulator due to the formation of bound states between electrons in close proximity. This transition into the insulating phase occurs when the Fermi energy surpasses the energy of the lowest bound state. Additionally, we explore how disorder influences these results. We also suggest potential experimental realizations of our model using semiconductor nanowires or carbon nanotubes.\n\n**Introduction:** In recent years, it has become evident that several intriguing phenomena in condensed matter physics, such as high-temperature superconductivity and fractional quantum Hall effects, arise from highly correlated electronic systems. One of the foundational models for describing interacting fermions is Hubbard theory. However, despite significant advancements in recent years, exact solutions to Hubbard theory remain elusive. Recently, a number of researchers have examined the impact of spin-orbit coupling on the ground-state properties of 1D Hubbard chains through various numerical methods, including density matrix renormalization group, exact diagonalization, DMRG, Bethe ansatz, variational Monte Carlo, and Quantum Monte Carlo techniques. Their studies have demonstrated that the ground state can exhibit different phases depending on the interplay between the strength of spin-orbit interaction and the Coulomb repulsion \\( U \\). For instance, if the spin-orbit coupling is weak relative to the hopping frequency \\( t \\), the ground state will be metallic or insulating depending on whether \\( U/t < 2 \\) or \\( U/t > 2 \\), respectively. Conversely, if the spin-orbit coupling becomes stronger...",
        "ori-fast-z-score": -0.43685202833051895,
        "water-fast-z-score": 5.63621480190678,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "The EPR paradox is one of the most important problems in quantum mechanics. It was formulated by Einstein et al., who claimed that it could be solved only if there existed hidden variables which were not included in the standard formulation of quantum mechanics. The original EPR argument has been criticized on several grounds including its reliance upon an unjustified assumption about locality. In this work we reexamine the EPR experiment using modern techniques for measuring correlations between photons produced via parametric down-conversion (PDC). We show how to measure all relevant quantities needed to test Bell s theorem with PDC sources. Our results are consistent with those predicted by quantum mechanics but do not violate any known bounds on nonlocality. This suggests that the original EPR argument may have been flawed or incomplete. Quantum entanglement plays a central role in many areas of physics ranging from condensed matter systems to high energy particle collisions. However, despite decades of research into the foundations of quantum mechanics, the exact nature of quantum entanglement remains elusive. One of the main reasons behind this difficulty lies in the fact that quantum states cannot generally be cloned  1  . As such, it is impossible to perform experiments where two copies of a given state can be prepared independently so as to compare their properties directly  2  .\nIn 1964, John Bell showed that certain types of measurements performed on pairs of particles would lead to violations of classical inequalities  3  , thereby demonstrating that quantum mechanical predictions cannot always be reproduced within a classical framework  4  . Since then, numerous experimental tests of these so-called Bell inequalities have been carried out  5  -  8  . Most notably, in 1992, Aspect et al. reported the first violation of Bell s inequality  9  , thus confirming the existence of quantum entanglement experimentally  10  .",
        "watermark_text": "The EPR paradox is one of the most important problems in quantum mechanics . It was formulated by Einstein et al . , who claimed that it could be answered only if there contained hidden variables which were not mentioned in the standard implementation of quantum mechanics .The original EPR argument has been attacked on numerous grounds namely its reliance upon an unjustified assumption about locality . In this research we reexamine the EPR study using contemporary methods for measuring correlations between photons generated via parametric down - transfer ( PDC ) .We see how to measure all relevant quantities required to test Bell s theorem with PDC sources . Our results are compatible with those predicted by quantum mechanics but do not violate any established limits on nonlocality .This implies that the previous EPR argument might have been flawed or incomplete . Quantum entanglement plays a central role in multiple fields of science ranging from condensed matter structures to large energy particle collisions .However , despite decades of research into the foundations of quantum mechanics , the exact structure of quantum entanglement continues elusive . One of the main motives behind this trouble lies in the fact that quantum states cannot typically be cloned 1 .As such , it is useless to conduct experiments where two copy of a given state can be prepared independently so as to relate their characteristics directly 2 . In 1964 , John Bell demonstrated that particular kinds of measurements completed on sets of particles might lead to violations of classical inequalities 3 , thereby showing that quantum mechanical predictions cannot consistently be reproduced within a classical framework 4 .Since then , various experimental tests of these so - called Bell inequalities have been carried out 5 - 8 . Most notably , in 1992 , Aspect et al .reported the first violation of Bell s inequality 9 , thus proving the existence of quantum entanglement experimentally 10 .",
        "rewrite_text": "The EPR paradox stands as a significant challenge within quantum mechanics. Initially presented by Einstein and his colleagues, it posited that the issue could only be resolved if there were hidden variables beyond those stated in standard quantum mechanics. The original EPR argument has faced criticism for its reliance on an unproven assumption regarding locality. In this study, we revisit the EPR concept through modern techniques for assessing correlations between photons generated via parametric down-conversion (PDC). We demonstrate how to measure all necessary parameters to test Bell's theorem using PDC sources. Our findings align with predictions from quantum mechanics while adhering to established boundaries of nonlocality, suggesting that the original EPR argument may have been flawed or incomplete. Quantum entanglement is pivotal across various scientific fields, from condensed matter physics to high-energy particle collisions. However, after decades of foundational research in quantum mechanics, the precise nature of quantum entanglement remains elusive. A major factor contributing to this challenge is the principle that quantum states typically cannot be cloned. Therefore, experiments attempting to prepare two independent copies of a given state to directly compare their properties are ineffective. In 1964, John Bell revealed that specific measurements on sets of particles could lead to violations of classical inequalities, demonstrating that the predictive capacity of quantum mechanics cannot be consistently encapsulated within a classical framework. Since Bell's work, numerous experimental validations of these Bell inequalities have been conducted. Notably, in 1992, Aspect and colleagues reported the first experimental violation of Bell's inequality, thereby providing empirical evidence for the existence of quantum entanglement.",
        "ori-fast-z-score": 0.26013299085723596,
        "water-fast-z-score": 8.638684255813601,
        "rewrite-fast-z-score": 1.0864289525102224
    },
    {
        "original_text": "We study atom-waves in an optical lattice with periodic boundary conditions by solving numerically the Schrödinger equation for different values of the laser intensity and detuning. We find that there is a crossover between two regimes depending on whether or not the recoil energy is larger than the kinetic energy of the atoms. In this work we focus on the case where the recoil energy is smaller than the kinetic energy (Raman-Nath regime). The effective Rabi frequency, losses and phase shifts are calculated as functions of the parameters characterizing the system. Our results show good agreement with previous theoretical works. Finally, we present our conclusions. Atom waves can be described using quantum mechanics when they interact with light fields. This interaction leads to interesting phenomena such as Bloch oscillations  1  , Zener tunneling  2  , Landau-Zener-Stückelberg-Majorana transitions  3  , and Anderson localization  4  . These effects have been studied both theoretically  5  -  8  and experimentally  9  -  11  .\nIn particular, it has recently become possible to create Bose-Einstein condensates  12  which allow one to observe these phenomena at low temperatures  13  -  16  . For example, in Ref.  17  , the authors observed Bloch oscillations in a cold atomic gas trapped inside an optical lattice created by counter-propagating lasers. They also found evidence of Zener tunneling  18  in their experiment. Moreover, in Refs.  19  and  20  , the authors investigated the effect of disorder on the transport properties of matter waves in optical lattices.",
        "watermark_text": "We explore atom - pulses in an optical lattice with periodic boundary conditions by solving numerically the Schrödinger equation for different values of the laser intensity and detuning . We see that there is a crossover between two regimes based on whether or not the recoil power is bigger than the kinetic power of the atoms .In this study we focus on the case where the recoil power is smaller than the kinetic power ( Raman - Nath regime ) . The effective Rabi frequency , losses and phase change are measured as functions of the variables characterizing the process .Our results show good agreement with previous conceptual works . Finally , we present our conclusions .Atom signals can be described using quantum mechanics when they interact with light fields . This coupling gives to unusual phenomena such as Bloch oscillations 1 , Zener tunneling 2 , Landau - Zener - Stückelberg - Majorana processes 3 , and Anderson localization 4 .These effects have been studied both theoretically 5 - 8 and experimentally 9 - 11 . In particular , it has recently become able to create Bose - Einstein condensates 12 which allow one to observe these phenomena at low temperatures 13 - 16 .For instance , in Ref . 17 , the papers observed Bloch oscillations in a cold atomic gas trapped inside an optical lattice created by anti - propagating lasers .They addition discovered evidence of Zener tunneling 18 in their experiment . Moreover , in Refs .19 and 20 , the papers investigated the impact of disorder on the travel properties of matter waves in optical lattices .",
        "rewrite_text": "We investigate atom pulses in an optical lattice with periodic boundary conditions by numerically solving the Schrödinger equation for various laser intensities and detunings. Our findings indicate a transition between two regimes, determined by whether the recoil power exceeds the kinetic energy of the atoms. This study specifically examines the scenario where recoil power is less than kinetic power, known as the Raman-Nath regime. We measure the effective Rabi frequency, losses, and phase shifts as functions of the relevant process parameters. Our results align well with prior theoretical work. In our exploration, we show that atom signals can be understood through quantum mechanics during their interaction with light fields, leading to intriguing phenomena such as Bloch oscillations, Zener tunneling, Landau-Zener-Stückelberg-Majorana processes, and Anderson localization. These effects have been extensively studied both theoretically and experimentally. Recently, the creation of Bose-Einstein condensates has enabled the observation of these phenomena at low temperatures. For example, one study identified Bloch oscillations in a cold atomic gas confined within an optical lattice formed by counter-propagating lasers and also found evidence for Zener tunneling in their experiments. Additionally, other research has examined the influence of disorder on the propagation characteristics of matter waves in optical lattices.",
        "ori-fast-z-score": 0.7035264706814485,
        "water-fast-z-score": 7.135768488340406,
        "rewrite-fast-z-score": 0.10259783520851541
    },
    {
        "original_text": "We study the correlation function and entanglement entropy for one-dimensional quantum systems with disordered interactions, focusing on their scaling behavior at large distances or times. We show that these quantities are related by an exact formula which is valid both in the ground state and in thermal equilibrium states. The relation can be used to obtain information about the entanglement structure of the system from measurements of correlations only. In particular we discuss how this method allows us to extract the von Neumann entropy of the reduced density matrix corresponding to half of the chain using data obtained from numerical simulations. \nI. INTRODUCTORY REMARK\nThe aim of this work is twofold. First, we want to present some new results concerning the relationship between correlation functions and entanglement entropies in disordered quantum many-body systems. Second, we would like to introduce a novel approach to calculate entanglement properties of such systems based solely on measuring correlation functions. This second aspect will be discussed in more detail below; here let us briefly summarize our main result before turning into technical details.\nConsider a generic quantum-mechanical model defined on a lattice consisting of L sites labeled by integers i = 1, ..., L. Let |0⟩ denote its ground state (which may also represent any other eigenstate) and consider the following quantity:",
        "watermark_text": "We research the interaction function and entanglement entropy for one - dimensional quantum systems with disordered relationships , concentrating on their scaling behavior at large distances or times . We see that these quantities are related by an precise formula which is valid both in the ground state and in heat equilibrium states .The relation can be used to obtain knowledge about the entanglement structure of the process from measurements of correlations only . In particular we explain how this method enables us to extract the von Neumann entropy of the reduced density matrix corresponding to part of the chain using data derived from numerical simulations .I . INTRODUCTORY REMARK The goal of this project is twofold .First , we wish to provide some fresh results relating the relationship between correlation functions and entanglement entropies in disordered quantum several - bodies systems . Second , we may like to introduce a new approach to estimate entanglement properties of such systems relying solely on measuring correlation functions .This second aspect will be mentioned in more detail below ; here allow us briefly summarize our major result before turning into technical details . Consider a generic quantum - mechanical model formulated on a lattice consisting of L locations labeled by integers i = 1 , . . . , L . Let | 0 ⟩ denote its ground state ( which may also represent any other eigenstate ) and consider the following value :",
        "rewrite_text": "We investigate the interaction function and entanglement entropy in one-dimensional quantum systems characterized by disordered interactions, focusing on their scaling behavior over large distances and times. Our findings reveal a precise relationship between these quantities, which holds true in both ground states and thermal equilibrium states. This relationship allows us to infer the entanglement structure of a system solely from correlation measurements. Specifically, we demonstrate how this approach enables us to derive the von Neumann entropy of the reduced density matrix for a segment of the chain using data obtained from numerical simulations. \n\nI. INTRODUCTORY REMARKS \n\nThe aim of this project is twofold. First, we seek to present new insights into the connection between correlation functions and entanglement entropies in disordered many-body quantum systems. Second, we propose a novel method for estimating the entanglement properties of such systems based solely on measurements of correlation functions. We will elaborate on this second aspect shortly; for now, let us briefly outline our primary result before delving into the technical details. Consider a generic quantum mechanical model defined on a lattice with L sites labeled by integers \\(i = 1, \\ldots, L\\). Let \\(| 0 \\rangle\\) represent its ground state (which may also signify any other eigenstate) and consider the following value:",
        "ori-fast-z-score": -0.4833682445228318,
        "water-fast-z-score": 6.410486691557943,
        "rewrite-fast-z-score": 1.0
    },
    {
        "original_text": "The idea that the universe underwent an inflationary phase at very early times is now widely accepted by cosmologists as one possible explanation for many observed features of our present-day universe, such as its flatness and homogeneity.  In this talk I will discuss how string-theoretic ideas can be used to construct models of inflation which are consistent with current observations. The basic idea behind these constructions is that they involve branes moving through extra dimensions of space-time. These branes may either move towards each other or away from each other depending on their initial conditions. If two branes collide then it leads to a rapid expansion of spacetime known as  inflation . This process continues until the branes separate again and the universe reverts back to its original size. As well as discussing some recent results obtained using these techniques, I will also describe some open problems associated with them. Finally, I will briefly mention another approach to constructing realistic models of inflation based upon so-called  brane-world scenarios .",
        "watermark_text": "The idea that the universe underwent an inflationary phase at very earliest times is now widely accepted by cosmologists as one possible reason for numerous observed features of our contemporary - day universe , such as its flatness and homogeneity . In this talk I will explore how string - theoretic theories can be used to build theories of inflation which are compatible with current observations .The basic idea behind these concepts is that they use branes moving through additional dimensions of space - time . These branes may either moving towards each other or away from each other depending on their initial conditions .If two branes collide then it leads to a rapid increase of spacetime termed as inflation . This process proceeds until the branes separate again and the universe reverts back to its previous size .As well as explaining some latest findings obtained using these tactics , I will also describe some open problems involved with them . Finally , I will briefly include another methodology to creating accurate theories of inflation centered upon so - called brane - world scenarios .",
        "rewrite_text": "The concept of an early inflationary phase in the universe is now broadly endorsed by cosmologists as a plausible explanation for various characteristics of our current universe, such as its flatness and homogeneity. In this presentation, I will investigate how string-theoretic approaches can be utilized to formulate inflationary models that align with existing observations. The fundamental premise of these theories involves branes interacting within additional dimensions of spacetime. Depending on their initial conditions, these branes might either move toward or away from each other. A collision between two branes triggers a rapid expansion of spacetime known as inflation. This process continues until the branes eventually separate, causing the universe to return to its prior size. Additionally, I will discuss recent findings derived from these approaches and identify some unresolved issues associated with them. Lastly, I will briefly introduce an alternative method for developing accurate inflationary models based on brane-world scenarios.",
        "ori-fast-z-score": 0.8944271909999159,
        "water-fast-z-score": 6.260990336999411,
        "rewrite-fast-z-score": 0.4923659639173309
    },
    {
        "original_text": "We present the results of an optical monitoring campaign on two luminous quasars at redshifts z = 1.7 and 2.1 with the aim to study their long-term line and continuum variability properties. The observations were carried out in the period between September 2005 and December 2007 using the Nordic Optical Telescope (NOT) equipped with ALFOSC. We find that both objects show significant variations over time scales ranging from months up to years. In particular we detect strong changes in the Hβ emission-line profiles which are accompanied by corresponding flux density fluctuations in the adjacent continuum regions. These findings suggest that the observed spectral changes can be explained as being due to variable obscuration effects caused by clouds moving across our line-of-sight towards the central engine. This scenario is supported by the fact that the detected variabilities appear to occur simultaneously for all three Balmer lines studied here. Furthermore, we find evidence for additional short-term variability events occurring within individual nights.",
        "watermark_text": "We report the conclusion of an optical monitoring effort on two luminous quasars at redshifts z = 1 . 7 and 2 . 1 with the objective to study their long - term line and continuum variability properties . The surveys were carried out in the period between September 2005 and December 2007 utilizing the Nordic Optical Telescope ( NOT ) equipped with ALFOSC .We see that both elements display significant variations over time ranges varied from months up to decades . In particular we find strong changes in the Hβ emission - line profiles which are preceded by similar flux concentration fluctuations in the adjacent continuum regions .These studies imply that the seen emission changes can be described as being owing to variable obscuration effects caused by clouds moved across our line - of - view towards the main motor . This scenario is backed by the fact that the reported variabilities appear to appear jointly for all three Balmer bands researched here .Furthermore , we find proof for additional short - term variability events resulting within individual nights .",
        "rewrite_text": "We present the findings from an optical monitoring campaign focused on two luminous quasars with redshifts of z = 1.7 and z = 2.1, aiming to investigate their long-term variability in both line and continuum emissions. The observations were conducted using the Nordic Optical Telescope (NOT) equipped with ALFOSC between September 2005 and December 2007. Our results indicate that both quasars exhibit significant variability over time scales ranging from months to decades. Notably, we observe pronounced changes in the Hβ emission-line profiles, which are often preceded by similar fluctuations in the adjacent continuum regions. These findings suggest that the emission variations are likely due to variable obscuration effects caused by clouds moving across our line of sight toward the central engine. This hypothesis is supported by the coordinated variability observed across all three Balmer lines studied. Additionally, we provide evidence of short-term variability events occurring within individual nights.",
        "ori-fast-z-score": -0.11704114719613057,
        "water-fast-z-score": 7.6723441570920725,
        "rewrite-fast-z-score": 1.116312611302876
    },
    {
        "original_text": "We study the global polarization of quark gluon plasma (QGP) produced in non central heavy-ion collisions by using an effective chiral model with vector and axial-vector mesons as well as quarks and anti-quarks. We find that the global polarization is mainly determined by the initial angular momentum carried by the colliding nuclei, which can be estimated through the Glauber model. The magnitude of the global polarization decreases rapidly when the collision energy increases due to the increasing number of particles involved in the reaction. Our results show that the global polarization may reach about 10% for RHIC energies but it will decrease significantly if one goes up to LHC energies. \n \n Introduction \n \n In recent years there has been growing interest on studying the global polarization of quark-gluon plasma(QGP), especially its dependence on the collision energy  1–3  . It was found that the global polarization could reach about 20% for RHIC energies  4  , while it would drop down to less than 1% for LHC energies  5  . \n \n This phenomenon is closely related to the initial angular momenta carried by the colliding nuclei; therefore, it provides us a new way to probe the nuclear structure  6  . On the other hand, since the global polarization is also sensitive to the temperature evolution  7, 8  , it might provide some information on the thermalization process of QGP  9  .",
        "watermark_text": "We research the global polarization of quark gluon plasma ( QGP ) produced in non central heavy - ion collisions by using an efficient chiral description with vector and axial - vector mesons as well as quarks and anti - quarks . We see that the global polarization is mainly decided by the first angular velocity carried by the colliding nuclei , which can be estimated through the Glauber model .The magnitude of the global polarization decreases quickly when the interaction power grows owing to the increasing quantity of molecules active in the reaction . Our results show that the global polarization might reach about 10 % for RHIC energies but it will decrease greatly if one goes up to LHC energies .Introduction In recent years there has been growing interest on studying the global polarization of quark - gluon gas ( QGP ) , particularly its dependence on the interaction power 1 – 3 . It was shown that the global polarization could reach about 20 % for RHIC energies 4 , while it would rise down to little than 1 % for LHC energies 5 .This phenomenon is closely related to the first angular momenta carried by the colliding nuclei ; therefore , it gives us a new place to probe the atomic system 6 . On the other hand , since the global polarization is also sensitive to the temperature evolution 7 , 8 , it could give some info on the thermalization process of QGP 9 .",
        "rewrite_text": "We investigate the global polarization of quark-gluon plasma (QGP) generated in non-central heavy-ion collisions through an effective chiral model that incorporates vector and axial-vector mesons along with quarks and anti-quarks. Our findings indicate that the global polarization is primarily influenced by the initial angular velocity of the colliding nuclei, which can be approximated using the Glauber model. As the interaction strength increases, the magnitude of global polarization diminishes rapidly due to the rising number of active particles in the reaction. Our results suggest that global polarization may reach approximately 10% at RHIC energies, but will significantly decrease at LHC energies. \n\nIntroduction: In recent years, there has been heightened interest in examining the global polarization of quark-gluon plasma (QGP), particularly its relationship with interaction strength. Studies have indicated that global polarization can be as high as 20% at RHIC energies, but drops to less than 1% at LHC energies. This phenomenon is closely tied to the initial angular momentum of the colliding nuclei, providing a novel avenue for exploring the atomic system. Additionally, as global polarization is sensitive to temperature variations, it may also offer insights into the thermalization processes occurring within the QGP.",
        "ori-fast-z-score": 0.10369516947304253,
        "water-fast-z-score": 6.18852747755276,
        "rewrite-fast-z-score": -0.31799936400190804
    },
    {
        "original_text": "We have investigated whether pulsar timing observations can be used to detect gravitational waves by observing the Shapiro effect, which is caused by the passage of gravitational waves through space-time around the Earth and its companion star (the Sun). We find that this method will not work with current technology because it requires very accurate measurements of pulse arrival times over many years. However, we show how future radio telescopes could make such measurements if they are equipped with new technologies like phased-array feeds or digital backends. In addition, we discuss other possible methods using pulsar timing data to search for gravitational waves. Gravitational waves cause time delays between pulses emitted at different points on the surface of a rotating neutron star. These time delays depend on the distance between these points as well as their position relative to the line-of-sight towards the observer. The most prominent effects occur when the wave passes close to the Earth and its companion stars. This causes an additional delay known as the Shapiro effect  Shapiro 1964  . If one knows the positions of all pulsars within a globular cluster, then one can use the observed pulse arrival times to measure the distances between them. By comparing these measured distances with those predicted by general relativity, one can test whether Einstein s theory correctly describes gravity on large scales.",
        "watermark_text": "We have researched whether pulsar timing observations can be used to identify gravitational waves by observing the Shapiro phenomenon , which is caused by the travel of gravitational waves through space - time around the Earth and its companion star ( the Sun ) . We see that this process will not work with current technology because it takes very accurate measurements of pulse onset times over numerous years .However , we explain how new radio telescopes might making such measurements if they are installed with modern innovations like phased - array feeds or digital backends . In addition , we explain other possible methods using pulsar timing statistics to search for gravitational waves .Gravitational waves cause period delays between pulses emitted at different places on the surface of a rotating neutron star . These time delays rely on the distance between these points as also as their placement relative to the line - of - view towards the observer .The most notable effects happen when the wave passes close to the Earth and its companion stars . This creates an additional delay known as the Shapiro phenomenon Shapiro 1964 .If one understands the places of all pulsars within a globular cluster , then one can using the known pulse onset times to measure the distances between them . By matching these measured distances with those predicted by general relativity , one can test whether Einstein s concept correctly describes gravitational on huge scales .",
        "rewrite_text": "We have investigated the potential of using pulsar timing observations to detect gravitational waves through the Shapiro phenomenon, which occurs as gravitational waves travel through the space-time around the Earth and its companion star, the Sun. Our findings indicate that current technology is insufficient for this method, as it requires highly precise measurements of pulse arrival times over many years. However, we discuss how new radio telescopes equipped with modern technologies, such as phased-array feeds and advanced digital backends, could facilitate these measurements. Additionally, we explore alternative approaches that employ pulsar timing statistics to seek out gravitational waves. Gravitational waves induce timing delays between pulses emitted from different locations on the surface of a rotating neutron star. These delays depend on the distance between these locations and their relative orientation to the observer's line of sight. The most significant effects are observed when the waves pass close to Earth and its companion stars, resulting in an additional delay known as the Shapiro effect (Shapiro, 1964). By deciphering the positions of all pulsars within a globular cluster, we can utilize the known pulse arrival times to calculate the distances among them. By comparing these measured distances with predictions from general relativity, we can assess whether Einstein's theory accurately describes gravitational phenomena on large scales.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.619839033907137,
        "rewrite-fast-z-score": 0.658504607868518
    },
    {
        "original_text": "The 12th STEPHI campaign was carried out at the Roque de los Muchachos Observatory, La Palma, Canaries Islands during August-September 2003. We observed two bright Delta Scuti stars - 7 Aql and 8Aql with the STEPHI photometer equipped with an Andor CCD camera. In this work we present results for these targets obtained by applying different methods to analyse their light curves. For both stars we found pulsation frequencies which are listed in Table 1 . \n7 Aql is known as one of the most active Delta Scuti variables showing more than 100 periodicities in its power spectrum. Our analysis revealed that it has several additional modes excited simultaneously. Some of them were not detected before because they have very low amplitudes or are located close to other peaks. \n8Aql turned out to be another interesting target. It shows only three significant periods but all of them are quite short -larger than 0.1 d. This star also exhibits low-amplitude variability on longer time scales. \n\n\nWe compared our results with those published previously.",
        "watermark_text": "The 12th STEPHI campaign was carried out at the Roque de los Muchachos Observatory , La Palma , Canaries Islands during August - September 2003 . We observed two bright Delta Scuti stars - 7 Aql and 8Aql with the STEPHI photometer equipped with an Andor CCD camera .In this research we present results for these targets obtained by using varying methods to analyse their light curves . For both stars we identified pulsation levels which are listed in Table 1 .7 Aql is known as one of the most intense Delta Scuti factors showing more than 100 periodicities in its power spectrum . Our study revealed that it has numerous additional types excited simultaneously .Some of them were not observed before because they have very low amplitudes or are situated close to other peaks . 8Aql turned out to be another attractive target .It displays only three notable cycles but all of them are quite short - larger than 0 . 1 d . This star also exhibits small - frequency variability on longer time ranges . We compared our findings with those published previously .",
        "rewrite_text": "The 12th STEPHI campaign took place at the Roque de los Muchachos Observatory in La Palma, Canary Islands, from August to September 2003. During this period, we observed two prominent Delta Scuti stars, 7 Aql and 8 Aql, using the STEPHI photometer equipped with an Andor CCD camera. In this study, we present the results obtained through various methods for analyzing their light curves. For both stars, we identified pulsation levels, which are documented in Table 1. 7 Aql is recognized as one of the most prominent Delta Scuti stars, exhibiting over 100 periodicities in its power spectrum. Our research unveiled several additional pulsation modes that are excited simultaneously, some of which were previously unobserved due to their low amplitudes or proximity to other peaks. 8 Aql also emerged as an intriguing target, displaying only three significant cycles, all relatively short, exceeding 0.1 days. Additionally, this star shows small-frequency variability over extended time scales. We compared our results with previously published data.",
        "ori-fast-z-score": 0.3841106397986879,
        "water-fast-z-score": 5.249512077248736,
        "rewrite-fast-z-score": -1.2309149097933272
    },
    {
        "original_text": "We present new CO(2-1), 13CO(1-0), and C18O(1-0) observations with the IRAM 30m telescope towards the nearby spiral galaxy NGC 4565. The data reveal that this galaxy hosts an extended molecular disk which is warped by interactions with its companion galaxies. We find evidence for two distinct components to the molecular gas distribution; one associated with the main body of the galaxy and another component located along the southern edge of the optical disk. This second component has been previously detected as a dust lane but we show here it also contains significant amounts of molecular gas. In addition, our high resolution maps reveal a prominent central concentration of molecular gas coincident with the position of the AGN. Using these data together with previous results on other galaxies observed within the NUGA survey we investigate how the properties of the molecular gas are related to those of the stars and black holes hosted by each system.",
        "watermark_text": "We report new CO ( 2 - 1 ) , 13CO ( 1 - 0 ) , and C18O ( 1 - 0 ) observations with the IRAM 30m telescope towards the nearby spiral galaxy NGC 4565 . The data reveal that this star contains an extended molecular core which is warped by interactions with its companion galaxies .We see evidence for two different components to the molecular gas distribution ; one associated with the main bodies of the galaxy and another component located along the southern periphery of the optical disk . This second component has been previously observed as a dust track but we find here it also contains substantial deposits of molecular gas .In addition , our high resolution mapping reveal a major central concentration of molecular gas coincident with the position of the AGN . Using these information combined with previous findings on other stars observed within the NUGA study we investigate how the properties of the molecular gas are related to those of the stars and dark holes hosted by each system .",
        "rewrite_text": "We present new observations of CO (2-1), 13CO (1-0), and C18O (1-0) conducted with the IRAM 30m telescope towards the nearby spiral galaxy NGC 4565. The data indicate that this galaxy possesses an extensive molecular core that has been distorted due to interactions with its companion galaxies. We identify two distinct components in the distribution of molecular gas: one linked to the main structures of the galaxy, and another found along the southern edge of the optical disk. This latter component, previously identified as a dust track, is shown here to also contain significant amounts of molecular gas. Furthermore, our high-resolution mapping reveals a prominent central concentration of molecular gas that coincides with the location of the active galactic nucleus (AGN). By integrating these findings with earlier research on other galaxies within the NUGA study, we explore the relationships between the properties of the molecular gas and those of the stars and supermassive black holes present in each system.",
        "ori-fast-z-score": -0.4588314677411235,
        "water-fast-z-score": 4.588314677411235,
        "rewrite-fast-z-score": -0.22941573387056174
    },
    {
        "original_text": "We propose to use hierarchical hidden Markov random fields (HHMRFs) as the underlying model in an unsupervised segmentation algorithm for hyperspectral images. The HHMRFs are constructed by combining several layers of hidden Markov chains, where each layer is associated with one particular spatial scale. We show that this multiscale approach leads to improved performance over single-scale methods and we demonstrate its effectiveness on two different data sets. Finally, we compare our results against those obtained using state-of-the-art algorithms based on Gaussian mixture models or sparse coding techniques. \nIntroduction\n\nHyperspectral imaging has become increasingly popular during recent years due to advances in sensor technology  1  . In contrast to conventional color cameras which capture only three bands per pixel, hyperspectral sensors can record hundreds of narrow spectral bands simultaneously  2  , leading to high-dimensional data volumes. This poses new challenges both in terms of storage requirements and computational complexity  3  .\nIn many applications it would be desirable to perform automatic analysis of such large amounts of data without any prior knowledge about the scene being observed  4  . One important task in this context is the detection of homogeneous regions within the image  5  . These so-called segments may correspond to individual objects  6  , but they could also represent parts of larger structures like buildings  7  or roads  8  .",
        "watermark_text": "We suggest to use hierarchical hidden Markov random fields ( HHMRFs ) as the fundamental design in an unsupervised segmentation algorithm for hyperspectral pictures . The HHMRFs are built by combining several elements of hidden Markov chains , where each layer is associated with one certain spatial scale .We suggest that this multiscale approach leads to improved performance over double - scale techniques and we prove its effectiveness on two different data sets . Finally , we compare our findings against those achieved using state - of - the - art algorithms based on Gaussian mixture models or dense coding techniques .Introduction Hyperspectral photography has become especially popular during recent years owing to advances in sensor technology 1 . In comparison to conventional color cameras which capture only three bands per pixel , hyperspectral cameras can display hundreds of broad wavelength lines simultaneously 2 , leading to large - dimensional data capacities .This poses novel challenges both in terms of storage needs and computational capability 3 . In many applications it would be desirable to conduct automatic analysis of such substantial amounts of evidence without any earlier knowledge about the scene being detected 4 .One important task in this context is the observation of homogeneous parts within the image 5 . These so - called features could belong to individual objects 6 , but they may sometimes reflect parts of bigger structures like houses 7 or roads 8 .",
        "rewrite_text": "We propose the use of hierarchical hidden Markov random fields (HHMRFs) as the core framework for an unsupervised segmentation algorithm tailored for hyperspectral images. The HHMRFs are constructed by integrating various components of hidden Markov chains, with each layer corresponding to a specific spatial scale. We argue that this multiscale strategy enhances performance compared to traditional double-scale methods, and we demonstrate its effectiveness across two distinct datasets. Additionally, we benchmark our results against those obtained using cutting-edge algorithms based on Gaussian mixture models and dense coding techniques. \n\n**Introduction**: Hyperspectral imaging has gained significant popularity in recent years, thanks to advancements in sensor technology. Unlike conventional color cameras that capture only three bands per pixel, hyperspectral cameras can simultaneously record hundreds of spectral bands, resulting in high-dimensional datasets. This increased dimensionality presents new challenges regarding storage and computational power. In many cases, there is a need to perform automatic analyses of this vast amount of data without prior knowledge of the detected scenes. A crucial task in this realm is identifying homogeneous regions within the images. These regions, referred to as features, may correspond to distinct objects, or they may represent components of larger structures like buildings or roads.",
        "ori-fast-z-score": 0.09245003270420485,
        "water-fast-z-score": 7.613508865259127,
        "rewrite-fast-z-score": -1.8198699419201876
    },
    {
        "original_text": "We present the demographics and properties of transition objects in SDSS DR7, which are defined as galaxies with both emission lines (ELGs) and absorption features (AGNs). We find that there is an excess number of ELG-AGN pairs at small separations compared to random distributions. The fraction of AGNs among all ELGs increases towards lower luminosities. There appears to be no significant difference between the fractions of AGNs found within different types of ELGs. These results suggest that some ELGs may harbor hidden AGNs. This work was supported by NASA grant NNX10AD65G. We thank the anonymous referee for helpful comments on this manuscript. In recent years, it has been shown that many active galactic nuclei (AGNs), especially those with low luminosity or obscured by dusty torii, have strong emission line components (see e.g., Ho et al. (1997) , Hao et al. (2005) ), making them appear like normal star-forming galaxies when observed through optical spectroscopic surveys such as Sloan Digital Sky Survey (SDSS; York et al. (2000) ) .\nIn order to identify these  transition objects , we use two criteria based on their spectral energy distribution (SED): 1) they must show both emission lines (ELGs; see Section 2.1 below) and absorption features (Section 2.2) simultaneously; and 2) they should not be classified as quasars according to the BPT diagram (Baldwin et al. 1981 , Kewley et al. 2001 . By applying these selection criteria to the entire sample of galaxies in the seventh data release (DR7; Abazajian et al. 2009 ) of the SDSS, we obtain a total of 16,082 transition objects out of a parent sample of 3,962,843 galaxies.",
        "watermark_text": "We present the demographics and features of transfer objects in SDSS DR7 , which are specified as galaxies with both emission lines ( ELGs ) and emission elements ( AGNs ) . We see that there is an excess amount of ELG - AGN pairs at small separations compared to random distributions .The percentage of AGNs among all ELGs increases towards less luminosities . There seems to be no major variation between the fractions of AGNs observed within various types of ELGs .These data suggest that some ELGs might harbor hidden AGNs . This research was supported by NASA grant NNX10AD65G .We thank the anonymous referee for useful comments on this manuscript . In recent years , it has been shown that several active galactic nuclei ( AGNs ) , particularly those with poor luminosity or obscured by dusty torii , have strong emitted path constituents ( saw e . g . , Ho et al .( 1997 ) , Hao et al . ( 2005 ) ) , making them seem like usual star - creating galaxies when observed through optical spectroscopic studies such as Sloan Digital Sky Survey ( SDSS ; York et al .( 2000 ) ) . In order to identify these transition objects , we using two requirements according on their spectral power distribution ( SED ) : 1 ) they must show both emission lines ( ELGs ; seeing Section 2 . 1 below ) and emission elements ( Section 2 . 2 ) simultaneously ; and 2 ) they should not be categorized as quasars according to the BPT chart ( Baldwin et al .1981 , Kewley et al . 2001 .By applying these selection criteria to the entire sample of galaxies in the seventh data release ( DR7 ; Abazajian et al . 2009 ) of the SDSS , we obtain a total of 16 , 082 transition objects out of a parent sample of 3 , 962 , 843 galaxies .",
        "rewrite_text": "We present the demographic data and characteristics of transfer objects in SDSS DR7, defined as galaxies that exhibit both emission lines (ELGs) and emission elements (AGNs). Our analysis reveals a notable excess of ELG-AGN pairs at close separations relative to random distributions. Additionally, the proportion of AGNs among all ELGs rises as luminosity decreases. There appears to be little variation in the fraction of AGNs across different ELG types, indicating that some ELGs may conceal hidden AGNs. This research was funded by NASA grant NNX10AD65G, and we appreciate the constructive feedback from the anonymous referee on this manuscript. Recent studies have demonstrated that certain active galactic nuclei (AGNs), particularly those with low luminosity or obscured by dusty tori, exhibit strong emission characteristics, giving them the appearance of typical star-forming galaxies in optical spectroscopic surveys like the Sloan Digital Sky Survey (SDSS; York et al., 2000). To identify these transition objects, we employ two criteria based on their spectral energy distribution (SED): 1) they must display both emission lines (ELGs; see Section 2.1) and emission elements (see Section 2.2) simultaneously; and 2) they should not be classified as quasars according to the BPT diagram (Baldwin et al., 1981; Kewley et al., 2001). By applying these selection criteria to the complete galaxy sample in the seventh data release (DR7; Abazajian et al., 2009) of the SDSS, we identified a total of 16,082 transition objects from a parent sample of 3,962,843 galaxies.",
        "ori-fast-z-score": -3.104378865665871,
        "water-fast-z-score": 4.308294733275792,
        "rewrite-fast-z-score": 0.29002094671369905
    },
    {
        "original_text": "We study the thermal properties of symmetric and asymmetric nuclear matter using an extended Thomas-Fermi model based on a momentum dependent effective nucleon-nucleon (NN) interaction, which is derived by solving the Bethe-Goldstone equation in ladder approximation. The results show that the density dependence of nuclear symmetry energy at normal nuclear matter density changes significantly when temperature increases up to 100 MeV. In addition, we find that the slope parameter L(ρ0), characterizing the density dependence of nuclear incompressibility K∞ = 9L(ρ0)(3π2ρ0/40MeV)2, decreases rapidly as temperature rises for both pure neutron matter and symmetric nuclear matter. This indicates that the stiffness of nuclear matter becomes softer at high temperatures.  We also calculate the pressure P , entropy S and specific heat Cv of nuclear matter as functions of baryonic number density nB and temperature T .",
        "watermark_text": "We research the thermal properties of symmetric and asymmetric atomic matter utilizing an extended Thomas - Fermi model based on a momentum dependent effective nucleon - nucleon ( NN ) collision , which is calculated by solving the Bethe - Goldstone equation in ladder approximation . The results show that the density relation of nuclear symmetry power at typical atomic matter density changes significantly when pressure changes up to 100 MeV .In addition , we find that the slope parameter L ( ρ0 ) , characterizing the density relation of nuclear incompressibility K∞ = 9L ( ρ0 ) ( 3π2ρ0 / 40MeV ) 2 , decreases quickly as temperature rises for both solid neutron particles and symmetric nuclear material . This implies that the stiffness of nuclear material gets softer at high temperatures .We additionally calculate the pressure P , entropy S and particular heat Cv of nuclear material as functions of baryonic number density nB and heat T .",
        "rewrite_text": "We investigate the thermal properties of both symmetric and asymmetric atomic matter using an extended Thomas-Fermi model that incorporates a momentum-dependent effective nucleon-nucleon interaction. This interaction is derived from the Bethe-Goldstone equation solved in the ladder approximation. Our findings reveal that the density relationship of nuclear symmetry energy at typical atomic matter densities varies significantly with pressure changes of up to 100 MeV. Furthermore, we observe that the slope parameter L(ρ0), which describes the density dependence of nuclear incompressibility K∞ = 9L(ρ0) (3π²ρ0/40 MeV)², decreases rapidly as the temperature increases for both solid neutron matter and symmetric nuclear matter. This indicates that the stiffness of nuclear matter becomes softer at elevated temperatures. Additionally, we calculate the pressure P, entropy S, and specific heat Cv of nuclear matter as functions of baryon number density nB and temperature T.",
        "ori-fast-z-score": -0.1203858530857692,
        "water-fast-z-score": 6.139678507374229,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We study the obfuscation complexity of planar graphs, which is defined as the minimum number of edges that need to be removed in order for an adversary not to be able to distinguish between two isomorphic copies of the graph. We show that this problem can be solved by solving a linear program with O(n) variables and constraints (where n denotes the number of vertices), or equivalently by finding the maximum matching on a bipartite graph. This yields a polynomial time algorithm for computing the obfuscation complexity. As a corollary we obtain a lower bound on the obfuscation complexity for any n-vertex tree T . Finally, we prove that there are infinitely many trees whose obfuscation complexities equal their numbers of leaves. The obfuscation complexity of a graph G = (V , E ) is defined as the smallest integer k such that removing at most k edges from G makes it indistinguishable from another graph G  = (V  , E ). In other words, if an attacker has access only to the set of all possible subgraphs induced by some subset S ⊆ V × V then he cannot tell whether he is looking at G or G  unless |S| > k .\nIn this work we consider the case where G is a planar graph. It turns out that in this setting one can solve the obfuscation complexity problem efficiently using combinatorial techniques. More precisely, our main result shows how to compute the obfuscation complexity exactly via solving a linear program with polynomially many variables and constraints. \nAs a consequence of our results we get a new lower bound on the obfuscatability of trees. Moreover, we provide examples showing that the obfuscation complexity may differ significantly from the size of the largest independent set.",
        "watermark_text": "We explore the obfuscation complexity of planar graphs , which is characterized as the minimum amount of vertices that require to be removed in order for an adversary not to be possible to distinguish between two isomorphic versions of the graph . We see that this question can be answered by solving a linear program with O ( n ) parameters and constraints ( where k denotes the number of vertices ) , or equivalently by finding the maximum matching on a bipartite graph .This yields a polynomial time algorithm for calculation the obfuscation complexity . As a corollary we obtain a smaller bound on the obfuscation complexity for any n - vertex tree T .Finally , we prove that there are infinitely many trees whose obfuscation complexities equal their numbers of leaves . The obfuscation complexity of a graph G = ( V , E ) is characterized as the smallest integer k such that removing at most k edges from G gives it indistinguishable from another graph G = ( V , E ) .In other words , if an attacker has entry only to the set of all possible subgraphs induced by some subset S ⊆ V × V then he cannot tell whether he is searching at G or G unless | S | > k . In this research we define the case where G is a planar graph .It turns out that in this situation one can handle the obfuscation complexity task easily using combinatorial tactics . More specifically , our major result shows how to compute the obfuscation complexity exactly via solving a linear program with polynomially many parameters and constraints .As a outcome of our findings we find a new lower limit on the obfuscatability of trees . Moreover , we provide examples demonstrating that the obfuscation complexity might variation significantly from the length of the greatest independent collection .",
        "rewrite_text": "We investigate the obfuscation complexity of planar graphs, which is defined as the minimum number of vertices that must be removed to prevent an adversary from distinguishing between two isomorphic versions of the graph. We find that this problem can be resolved by solving a linear program with \\(O(n)\\) parameters and constraints (where \\(n\\) represents the number of vertices), or equivalently, by determining the maximum matching in a bipartite graph. This leads to a polynomial-time algorithm for calculating the obfuscation complexity. As a corollary, we establish a tighter bound on the obfuscation complexity for any \\(n\\)-vertex tree \\(T\\). Furthermore, we demonstrate that there are infinitely many trees for which the obfuscation complexity equals the number of leaves. The obfuscation complexity of a graph \\(G = (V, E)\\) is defined as the smallest integer \\(k\\) such that removing at most \\(k\\) edges from \\(G\\) renders it indistinguishable from another graph \\(G' = (V, E)\\). In other words, if an attacker only has access to the set of all possible subgraphs induced by some subset \\(S \\subseteq V \\times V\\), they cannot determine whether they are examining \\(G\\) or \\(G'\\) unless \\(|S| > k\\). In this study, we focus on the case where \\(G\\) is a planar graph. In this context, we discover that the task of determining obfuscation complexity can be managed using combinatorial methods. Our primary result reveals that the exact obfuscation complexity can be computed by solving a linear program with polynomially many parameters and constraints. As a consequence of our findings, we establish a new lower bound on the obfuscation complexity of trees. Additionally, we present examples that illustrate significant variations in obfuscation complexity compared to the size of the largest independent set.",
        "ori-fast-z-score": -2.599734734478726,
        "water-fast-z-score": 4.828078792603349,
        "rewrite-fast-z-score": -0.7492686492653552
    },
    {
        "original_text": "In this work, we propose an energy-efficient cooperative transmission scheme for wireless sensor networks (WSNs). The proposed scheme is based on the combination of collaborative beamforming at the source node with cooperative transmission to multiple relay nodes in order to improve lifetime performance. In particular, the source node first transmits data packets using its maximum power level. Then, it switches to lower power levels if no packet has been successfully received within a certain time period. If one or more packets are successfully decoded, then the source node increases its transmit power back up to the previous value. We derive closed-form expressions for outage probability as well as average throughput under Rayleigh fading channels. Our results show that our proposed scheme can significantly increase network lifetime compared to conventional schemes without compromising system reliability. Finally, numerical examples are provided to verify the theoretical analysis. Keywords: Lifetime improvement; Relay selection; Energy efficiency; Outage probability",
        "watermark_text": "In this project , we propose an energy - efficient joint propagation scheme for wireless sensor networks ( WSNs ) . The proposed system is based on the combination of collaborative beamforming at the source node with coordinated transmission to multiple relay nodes in order to improve life performance .In particular , the source node initially transmits data packets using its highest power level . Then , it switches to smaller energy levels if no packet has been successfully received within a certain time time .If one or more bits are properly decoded , then the source node increases its broadcast capacity back up to the previous value . We derive closed - form expressions for outage likelihood as well as average throughput under Rayleigh fading filters .Our results show that our proposed system can significantly expand network lifetime compared to conventional systems without compromising system efficiency . Finally , numerical examples are provided to confirm the theoretical analysis .Keywords : Lifetime improvement ; Relay choice ; Energy quality ; Outage probability",
        "rewrite_text": "In this project, we introduce an energy-efficient joint propagation strategy for wireless sensor networks (WSNs). Our proposed approach integrates collaborative beamforming at the source node with coordinated transmissions to multiple relay nodes, aiming to enhance overall network performance. Specifically, the source node begins by transmitting data packets at its maximum power level. If no packets are successfully received within a defined time frame, it then reduces its power to lower energy levels. Conversely, if one or more bits are successfully decoded, the source node reinstates its broadcast capacity to the previous power level. We derive closed-form expressions for outage probability and average throughput within Rayleigh fading environments. Our findings demonstrate that this system can significantly extend network lifetime compared to traditional systems while maintaining efficiency. Numerical examples are provided to validate our theoretical results. \n\nKeywords: Lifetime enhancement; Relay selection; Energy efficiency; Outage probability.",
        "ori-fast-z-score": 0.105999788000636,
        "water-fast-z-score": 6.11104144857543,
        "rewrite-fast-z-score": 0.3333333333333333
    },
    {
        "original_text": "We present the results of an analysis of BATSE data on gamma ray bursts (GRBs) in which we have used three different statistical methods to search for evidence that GRB durations are distributed into at least two distinct populations, as suggested by previous authors.  We find no compelling evidence for such a bimodal distribution using any one method alone; however, when all three methods are combined there is strong evidence for this hypothesis.  The best-fit parameters obtained with each method individually differ significantly and suggest that the true underlying distribution may be more complex than previously thought. In particular, our results indicate that the shortest duration events form their own class of GRBs whose properties are quite different from those of longer-duration GRBs. This result has important implications both for understanding the nature of these phenomena and for planning future missions dedicated to studying them. Keywords: Gamma Ray Bursts, Statistical Analysis",
        "watermark_text": "We present the conclusion of an assessment of BATSE information on gamma radiation bursts ( GRBs ) in which we have utilized three different empirical methods to search for indication that GRB durations are distributed into at least two separate populations , as suggested by earlier authors . We see no compelling evidence for such a bimodal distribution using any one method alone ; however , when all three means are combined there is strong evidence for this hypothesis .The best - fitting characteristics obtained with each approach individually varies dramatically and suggest that the true underlying distribution might be more sophisticated than previously thought . In particular , our findings confirm that the shortest duration episodes form their own class of GRBs whose characteristics are quite different from those of shorter - duration GRBs .This result has valuable consequences both for knowledge the nature of these phenomena and for planning upcoming missions tasked to researching them . Keywords : Gamma Ray Bursts , Statistical Analysis",
        "rewrite_text": "We present the conclusion of an evaluation of BATSE data on gamma radiation bursts (GRBs), using three distinct empirical methods to investigate whether GRB durations are divided into at least two separate populations, as previously suggested by other researchers. While none of the methods alone provides strong evidence for a bimodal distribution, combining the results from all three approaches reveals significant support for this hypothesis. The optimal characteristics identified by each individual method vary widely, indicating that the true underlying distribution may be more complex than previously understood. Notably, our results affirm that the shortest duration episodes constitute a distinct class of GRBs, characterized by traits that differ significantly from those of longer-duration GRBs. These findings are important for enhancing our understanding of these phenomena and for informing future missions aimed at studying them. Keywords: Gamma Ray Bursts, Statistical Analysis.",
        "ori-fast-z-score": -0.11704114719613057,
        "water-fast-z-score": 7.139509978963965,
        "rewrite-fast-z-score": 0.35603449745815596
    },
    {
        "original_text": "The cosmic ray origin is still unknown, but it may be related to the supernova explosion.  The propagation model describes how cosmic rays are transported in space by diffusion processes with energy losses due to ionization and Coulomb scattering off interstellar gas particles.   This article presents an overview on cosmic ray physics and introduces some basic concepts for understanding cosmic ray transport models. Cosmic rays have been observed since the 19th century. They consist mainly of protons (about 85%) and helium nuclei (about 14%). Their energies range up to 10^20 eV. However, their sources remain unclear. It has been suggested that they might come from exploded stars called supernovae or from active galactic nuclei such as quasars. In this case, they would travel through intergalactic space before reaching Earth. Another possibility is that they are accelerated within our own galaxy. If so, then they could reach us directly without traveling far away.",
        "watermark_text": "The cosmic ray origin is still unclear , but it could be connected to the supernova explosion . The propagation model describes how cosmic rays are transported in space by diffusion processes with energy losses owing to ionization and Coulomb absorption off interstellar gas molecules .This page presents an overview on cosmic ray physics and introduces some fundamental concepts for studying cosmic ray transport models . Cosmic rays have been observed since the 19th century .They consist mostly of protons ( about 85 % ) and helium nuclei ( about 14 % ) . Their energies range up to 10 ^ 20 eV .However , their sources continue unknown . It has been proposed that they may come from burst stars called supernovae or from active galactic nuclei such as quasars .In this instance , they may travel through intergalactic space before reaching Earth . Another possibility is that they are accelerated within our own galaxy .If so , then they may reach us directly without traveling long away .",
        "rewrite_text": "The origin of cosmic rays remains uncertain, but there may be a link to supernova explosions. The propagation model outlines the mechanisms by which cosmic rays move through space, primarily driven by diffusion processes, with energy losses occurring due to ionization and Coulomb interactions with interstellar gas molecules. This page provides an overview of cosmic ray physics and introduces essential concepts for examining cosmic ray transport models. Cosmic rays have been detected since the 19th century and are primarily composed of protons (approximately 85%) and helium nuclei (about 14%). Their energies can reach up to 10^20 eV, yet their sources are still unidentified. One theory suggests they originate from explosive events such as supernovae or from active galactic nuclei like quasars. In this scenario, they may traverse intergalactic space before arriving at Earth. Alternatively, they might be accelerated within our own galaxy, allowing for a more direct journey to us.",
        "ori-fast-z-score": 0.8307471607356973,
        "water-fast-z-score": 5.421151989096865,
        "rewrite-fast-z-score": 1.4142135623730951
    },
    {
        "original_text": "In this work, we present an algorithm for the analysis and comparison of profile Hidden Markov Models (HMMs). The proposed method is based on the concept of Structural Similarity Index Measurement (SSIM) which has been widely used in image processing to measure similarity between two images. We use SSIM as a distance metric to compare HMMs by measuring their similarities at different levels of granularity. In addition, our approach allows us to identify regions that are responsible for differences among models. Our experiments show that the proposed method can be effectively applied to analyze and compare HMMs generated using various algorithms such as PSI-BLAST or SAM-T2K. This research was supported by NSERC Discovery Grant RGPIN-2014-04567 awarded to Dr. Yi-Chun Wu. Profile hidden markov model(HMM),Structural similarity index measurement(SSIM),Similarity score matrix(SCM),PSI-BLAST",
        "watermark_text": "In this research , we present an algorithm for the evaluation and contrast of model Hidden Markov Models ( HMMs ) . The proposed approach is based on the idea of Structural Similarity Index Measurement ( SSIM ) which has been widely useful in image processing to measure similarity between two images .We use SSIM as a distance metric to identify HMMs by assessing their similarities at different levels of granularity . In addition , our approach allows us to identify areas that are responsible for variations among models .Our experiments indicate that the suggested method can be effectively used to analyze and compare HMMs generated using numerous algorithms such as PSI - BLAST or SAM - T2K . This research was supported by NSERC Discovery Grant RGPIN - 2014 - 04567 granted to Dr . Yi - Chun Wu .Profile hidden markov model ( HMM ) , Structural similarity index monitoring ( SSIM ) , Similarity rating matrix ( SCM ) , PSI - BLAST",
        "rewrite_text": "In this study, we introduce an algorithm designed for evaluating and comparing Hidden Markov Models (HMMs). Our method is inspired by the Structural Similarity Index Measurement (SSIM), which has proven effective in image processing for assessing the similarity between two images. We utilize SSIM as a distance metric to analyze HMMs by examining their similarities at various levels of detail. Additionally, our approach enables the identification of specific areas contributing to variations among the models. Our experimental results demonstrate that the proposed technique can effectively analyze and compare HMMs generated by various algorithms, including PSI-BLAST and SAM-T2K. This research is funded by the NSERC Discovery Grant RGPIN-2014-04567 awarded to Dr. Yi-Chun Wu. Key terms include Hidden Markov Models (HMM), Structural Similarity Index Measurement (SSIM), Similarity Comparison Matrix (SCM), and PSI-BLAST.",
        "ori-fast-z-score": -0.40451991747794525,
        "water-fast-z-score": 5.258758927213289,
        "rewrite-fast-z-score": -0.565685424949238
    },
    {
        "original_text": "We present new observations made with the Atacama Large Millimeter/submillimeter Array (ALMA) of two inter-network sunspots in active region NOAA AR 12192 on 2013 May 24 and 25, respectively. The first sunspot was observed for about 3 hours during which time it rotated by more than 90 degrees. We find that this sunspot is composed of several magnetic flux tubes with different orientations. In addition to these features we also observe an extended bright feature located between the main sunspot umbrae. This feature has been previously reported as a penumbral filament but our data show no evidence of such structure. Instead, we interpret this feature as a coronal rain blob. The second sunspot was observed for only 1 hour before being occulted by Earths atmosphere. During this observation period the sunspot rotated by less than 30 degrees. Our analysis shows that both sunspots are surrounded by a dark lane which may be associated with the moat surrounding large sunspots.",
        "watermark_text": "We report new images making with the Atacama Large Millimeter / submillimeter Array ( ALMA ) of two cross - network sunspots in active region NOAA AR 12192 on 2013 May 24 and 25 , respectively . The first sunspot was seen for about 3 hours during which period it rotated by more than 90 degrees .We see that this sunspot is composed of several magnetic flux tubes with various orientations . In addition to these characteristics we also observe an extended bright point located between the main sunspot umbrae .This phenomenon has been previously reported as a penumbral filament but our statistics demonstrate no evidence of such structure . Rather , we view this phenomenon as a coronal weather blob .The second sunspot was seen for only 1 hour before being occulted by Earths atmosphere . During this study interval the sunspot tilted by less than 30 degrees .Our study shows that both sunspots are surrounded by a darkness lane which may be identified with the moat surrounding large sunspots .",
        "rewrite_text": "We present new images captured by the Atacama Large Millimeter/submillimeter Array (ALMA) of two cross-network sunspots in active region NOAA AR 12192 on May 24 and 25, 2013, respectively. The first sunspot was observed for approximately three hours, during which it rotated by more than 90 degrees. Our observations reveal that this sunspot consists of multiple magnetic flux tubes with varying orientations. Additionally, we note an extended bright point located between the main sunspot umbrae. This feature has been previously described as a penumbral filament; however, our statistics show no evidence supporting this interpretation. Instead, we propose that this phenomenon is a coronal weather blob. The second sunspot was visible for only one hour before being obscured by Earth's atmosphere, during which it tilted by less than 30 degrees. Our study indicates that both sunspots are encircled by a dark lane, which may correspond to the moat typically found around large sunspots.",
        "ori-fast-z-score": -1.0327955589886444,
        "water-fast-z-score": 5.163977794943222,
        "rewrite-fast-z-score": 0.5163977794943222
    },
    {
        "original_text": "We present new photometry for the globular cluster NGC 1904, obtained with the Wide Field Camera 3 (WFC3) on board HST in four filters spanning the optical and near-infrared wavelength range. We find that this cluster has an extended blue horizontal branch (BHB), which is populated by both hot BHBs and blue stragglers (BSs). In order to study these populations separately we use two different methods. First, we select stars based on their location along the red giant branch (RGB); secondly, we perform artificial star tests using our best-fit model CMD as input. Both approaches yield consistent results. Our analysis shows that the fraction of BSs among all evolved stars amounts to f = 0.11 ± 0.01. This value agrees well with previous studies of other clusters. Using theoretical models we estimate the age of the cluster at t = 12 Gyr.",
        "watermark_text": "We present new photometry for the globular cluster NGC 1904 , obtained with the Wide Field Camera 3 ( WFC3 ) on board HST in four filters covering the optical and far - infrared frequency range . We see that this cluster has an extended blue horizontal branch ( BHB ) , which is populated by both hot BHBs and green stragglers ( BSs ) .In order to study these populations individually we utilize two different methods . First , we choose galaxies based on their placement along the red giant branch ( RGB ) ; secondly , we perform artificial star tests utilizing our good - fitting model CMD as input .Both approaches yield consistent conclusions . Our study shows that the fraction of BSs among all evolved stars amounts to f = 0 . 11 ± 0 . 01 .This value agrees well with previous research of other clusters . Using theoretical methods we estimate the age of the cluster at t = 12 Gyr .",
        "rewrite_text": "We present new photometric data for the globular cluster NGC 1904, obtained using the Wide Field Camera 3 (WFC3) aboard the Hubble Space Telescope (HST). This data set spans four filters across the optical and far-infrared spectrum. Our observations reveal an extended blue horizontal branch (BHB) in the cluster, which includes both hot BHB stars and green stragglers (BSs). To analyze these populations separately, we employed two distinct methodologies. First, we selected galaxies based on their position along the red giant branch (RGB). Secondly, we conducted artificial star tests using our accurately fitting model color-magnitude diagram (CMD) as input. Both methods produced consistent results. Our findings indicate that the fraction of BSs among all evolved stars is f = 0.11 ± 0.01, which aligns well with previous studies of other clusters. Additionally, employing theoretical methods, we estimate the age of the cluster to be approximately 12 Gyr.",
        "ori-fast-z-score": 1.3242443839434612,
        "water-fast-z-score": 5.093248125762992,
        "rewrite-fast-z-score": 0.5933908290969266
    },
    {
        "original_text": "We present the results of our study on the correlation between black hole mass and spheroidal luminosity in nearby galaxies, using data obtained with the Hubble Space Telescope (HST). We have used two different methods to estimate the masses of supermassive black holes at the centers of these galaxies; one based on stellar dynamics and another method which uses the widths of broad emission lines as an indicator for the central black hole mass. The sample consists of 29 elliptical galaxies within 40 Mpc distance. Our main result is that we find no significant difference between the black hole masses derived by both methods. This indicates that there exists a tight relationship between the black hole mass and the total luminosity of its host galaxy. In addition, we also found evidence that this relationship does not depend strongly on the morphological type or environment of the host galaxy. These findings are consistent with theoretical predictions made by Silk & Rees (1998) who suggested that feedback processes play an important role in regulating star formation activity in galactic bulges.",
        "watermark_text": "We present the conclusion of our research on the relationship between black hole weight and spheroidal luminosity in nearby galaxies , using data acquired with the Hubble Space Telescope ( HST ) . We have utilized two different methods to estimate the masses of supermassive black holes at the centers of these galaxies ; one based on stellar physics and another technique which uses the widths of broad absorption lines as an measure for the main white hole mass .The sample consists of 29 elliptical galaxies within 40 Mpc radius . Our main consequence is that we find no major variation between the dark hole masses derived by both approaches .This implies that there exists a tight connection between the dark hole weight and the total luminosity of its host universe . In addition , we also discovered evidence that this relationship does not depend greatly on the morphological class or climate of the host star .These conclusions are compatible with theoretical calculations made by Silk & Rees ( 1998 ) who proposed that feedback systems play an important role in controlling galaxy formation activity in galactic bulges .",
        "rewrite_text": "We outline the findings of our research regarding the correlation between the mass of supermassive black holes and the spheroidal luminosity of nearby galaxies, using data obtained from the Hubble Space Telescope (HST). We employed two distinct methods to estimate the masses of these black holes situated at the centers of the galaxies: one method rooted in stellar dynamics and another that utilizes the widths of broad absorption lines as a metric for black hole mass. Our study encompassed a sample of 29 elliptical galaxies within a 40 Mpc radius. A key result of our research is that we observed no significant discrepancies between the black hole masses derived from the two methods. This suggests a strong link between black hole mass and the total luminosity of their host galaxies. Furthermore, we found indications that this relationship is largely independent of the morphological classification or environment of the host galaxy. These findings align with the theoretical models proposed by Silk & Rees (1998), which suggest that feedback mechanisms play a crucial role in regulating galactic formation activities in galactic bulges.",
        "ori-fast-z-score": -1.3093073414159544,
        "water-fast-z-score": 6.9829724875517565,
        "rewrite-fast-z-score": -0.3333333333333333
    },
    {
        "original_text": "We study effects of lepton flavour violation (LFV) in chargino production and decay at linear colliders, taking into account all relevant LFV interactions. We find that for large values of tan β , where tan β is defined as the ratio between vacuum expectation values of up-type and down-type Higgs fields, the branching ratios to tau leptons can be enhanced by several orders of magnitude compared with those expected within the Standard Model. This enhancement results mainly from the fact that the coupling of neutralinos to taus is proportional to tan β . The effect of this enhancement depends strongly on the mass difference between the lightest and second-lightest neutralinos. \n \n For small values of tan β we find only moderate enhancements or even suppression of the branching ratios due to destructive interference among different contributions. In addition, we show how these effects depend on the masses of the supersymmetric particles involved.",
        "watermark_text": "We research effects of lepton flavour violation ( LFV ) in chargino production and decay at linear colliders , using into consideration all relevant LFV interactions . We see that for large values of tan β , where tan β is characterized as the ratio between vacuum expectation values of up - type and down - class Higgs fields , the branching proportions to tau leptons can be enhanced by many orders of magnitude compared with those expected within the Standard Model .This enhancement leads mainly from the fact that the relationship of neutralinos to taus is proportional to tan β . The impact of this enhancement varies strongly on the mass ratio between the lightest and second - lightest neutralinos .For small values of tan β we find only moderate enhancements or even disruption of the branching ratios resulting to destructive interference among different contributions . In addition , we find how these influences depend on the masses of the supersymmetric particles concerned .",
        "rewrite_text": "We investigate the effects of lepton flavor violation (LFV) on chargino production and decay at linear colliders, taking into account all relevant LFV interactions. Our analysis reveals that for large values of tan β—defined as the ratio of the vacuum expectation values of the up-type and down-type Higgs fields—the branching ratios to tau leptons can be significantly increased, often by several orders of magnitude compared to predictions from the Standard Model. This substantial enhancement arises primarily from the direct relationship between neutralinos and taus, which is proportional to tan β. The degree of this enhancement is highly dependent on the mass ratio between the lightest and second-lightest neutralinos. Conversely, for small values of tan β, we observe only slight enhancements or even a reduction in the branching ratios, attributed to destructive interference among various contributions. Furthermore, we explore how these effects are influenced by the masses of the involved supersymmetric particles.",
        "ori-fast-z-score": -0.6108472217815261,
        "water-fast-z-score": 4.365641250653994,
        "rewrite-fast-z-score": -0.5933908290969266
    },
    {
        "original_text": "We consider forward stagewise regression (FSR) for linear models with nonnegative coefficients, which is an iterative procedure that adds variables to the model one at a time until some stopping criterion is met.  We show how FSR can be used in conjunction with the monotone Lasso penalty to produce sparse solutions whose support contains all relevant predictors while simultaneously ensuring their signs are correct.  The resulting algorithm has computational complexity similar to standard Lasso algorithms but produces more accurate results on simulated data sets as well as real-world examples involving gene expression microarray data. Forward Stagewise Regression (FSR), introduced by Frank & Friedman  1  , is an iterative procedure where each iteration consists of adding a single variable into the current set of selected features based on its contribution to the objective function. This process continues until some stopping criteria is reached such as reaching a maximum number of iterations or meeting a desired level of accuracy  2  . In this work we focus on using FSR within the context of linear models with non-negative coefficients. For example, if our goal was to find genes associated with breast cancer then it would make sense to only select those genes that have been shown to increase risk rather than decrease risk  3  .\nThe main advantage of FSR over other greedy selection methods like stepwise regression  4  is that it does not require any tuning parameters  5  . However, there are two major drawbacks when applying FSR directly to problems with large numbers of potential covariates  6  :  1) It may take many iterations before the final solution converges; 2) There is no guarantee that the final solution will contain all relevant predictors. To address these issues, Tibshirani et al.  7  proposed the Least Absolute Shrinkage and Selection Operator (Lasso). Lasso solves the following optimization problem:",
        "watermark_text": "We consider forward stagewise regression ( FSR ) for linear models with nonnegative parameters , which is an iterative method that adds variables to the model one at a time until some stops criterion is reached . We see how FSR can be used in partnership with the monotone Lasso penalty to produce sparse scenarios whose support includes all relevant predictors while simultaneously ensuring their signs are correct .The resulting algorithm has computational efficiency comparable to standard Lasso techniques but generates more accurate conclusions on virtual data sets as well as real - time examples involving gene sequence microarray data . Forward Stagewise Regression ( FSR ) , invented by Frank & Friedman 1 , is an iterative method where each iteration consists of adding a single variable into the present set of chosen characteristics depending on its contribution to the objective function .This process proceeds until some stopping requirements is reached such as reaching a maximum number of iterations or meeting a desired level of precision 2 . In this research we focus on implementing FSR within the context of linear models with non - negative coefficients .For instance , if our goal was to find genes associated with breast tumors then it would work sense to only select those genes that have been shown to raise risk rather than decrease risk 3 . The main advantage of FSR over other greedy selection schemes like stepwise regression 4 is that it does not require any tuning variables 5 .However , there are two principal drawbacks when applying FSR directly to problems with large numbers of potential covariates 6 : 1 ) It might took many iterations before the finished problem converges ; 2 ) There is no guarantee that the finished problem will include all relevant predictors . To address these problems , Tibshirani et al .7 proposed the Least Absolute Shrinkage and Selection Operator ( Lasso ) . Lasso solves the following optimization problem :",
        "rewrite_text": "We examine forward stagewise regression (FSR) for linear models with nonnegative coefficients. This iterative approach involves adding variables to the model one at a time until a predetermined stopping criterion is met. We demonstrate how FSR can be integrated with the monotone Lasso penalty to create sparse models that encompass all relevant predictors while ensuring their signs are correct. The resulting algorithm is computationally efficient, comparable to standard Lasso methods, yet yields more accurate results on simulated datasets and real-time examples, such as gene expression microarray data. FSR, developed by Frank and Friedman, operates by incorporating a single variable into the current selection at each iteration, based on its contribution to the objective function, and continues this process until a stopping condition—such as a maximum number of iterations or achieving a desired precision—is satisfied. In our study, we focus on applying FSR within linear models that feature nonnegative coefficients. For instance, when identifying genes linked to breast tumors, it is sensible to select only those genes that are associated with an increased risk rather than those that decrease it. One key benefit of FSR over other greedy selection methods, such as stepwise regression, is that it does not require any tuning parameters. However, there are two main challenges when using FSR on datasets with a large number of potential covariates: 1) it may take many iterations for the final solution to converge; and 2) there is no assurance that the final model will capture all relevant predictors. To mitigate these issues, Tibshirani et al. introduced the Least Absolute Shrinkage and Selection Operator (Lasso), which addresses the following optimization problem:",
        "ori-fast-z-score": 1.30066495428618,
        "water-fast-z-score": 8.811457940929873,
        "rewrite-fast-z-score": 0.936585811581694
    },
    {
        "original_text": "We present the theory for anomalous diffusion in terms of fractional Fokker-Planck equations and apply it to study the time evolution of chemical reactions occurring on realistic self-affined fractals, such as porous media or biological tissues. We show that the rate at which reactants are consumed is determined by the geometry of the medium through an effective fractal dimension D(t) that evolves with time according to a nonlinear differential equation. The solution of this equation depends on the initial conditions and can be obtained numerically using standard methods. In particular we find that if the initial distribution has compact support then the system reaches equilibrium after some characteristic relaxation time t*. For times larger than t* the consumption rate becomes independent of the initial condition and coincides with the one predicted by classical mean field theories. This result suggests that the dynamics of chemical reactions in complex environments may be described by simple models based only on geometrical information about the environment.",
        "watermark_text": "We introduce the principle for anomalous diffusion in terms of fractional Fokker - Planck equations and application it to study the period evolution of biological compounds resulting on ideal self - affined fractals , such as porous material or biological tissues . We see that the speed at which reactants are consumed is chosen by the topology of the medium through an efficient fractal dimension D ( t ) that evolves with time according to a nonlinear integral equation .The solving of this equation depends on the first conditions and can be obtained numerically using conventional methods . In particular we find that if the first distribution has compact support then the system reaches stability after some characteristic relaxation time t * .For times bigger than t * the consumption level appears independent of the first situation and coincides with the one expected by classical mean field theories . This result suggests that the dynamics of chemical processes in complex environments could be described by simple models relying only on geometrical information about the surroundings .",
        "rewrite_text": "We present the principle of anomalous diffusion through fractional Fokker-Planck equations and apply this framework to examine the temporal evolution of biological compounds, which results in ideal self-affine fractals, such as porous materials or biological tissues. Our analysis reveals that the rate of reactant consumption is influenced by the medium's topology, characterized by an effective fractal dimension D(t) that evolves over time according to a nonlinear integral equation. The solution to this equation is contingent upon initial conditions and can be computed numerically using standard methods. Notably, we observe that if the initial distribution has compact support, the system achieves stability after a characteristic relaxation time t*. Beyond this time, the level of consumption becomes independent of the initial conditions and aligns with predictions made by classical mean field theories. This finding implies that the dynamics of chemical processes in complex environments may be effectively modeled using simple approaches based solely on geometrical characteristics of the surrounding medium.",
        "ori-fast-z-score": -0.9058216273156765,
        "water-fast-z-score": 5.9648090806346055,
        "rewrite-fast-z-score": 1.7888543819998317
    },
    {
        "original_text": "We present an analysis of galaxy clusters selected by their red-sequence galaxies (Gladders & Yee 2005) from the Sloan Digital Sky Survey Data Release 4 (DR4). We use two different methods to select cluster candidates, and then apply photometric redshift cuts on these samples to obtain final catalogues with high purity. The first method is based on the matched filter technique developed for X-ray surveys (Postman et al 1996) , while the second one uses a friends-of-friends algorithm applied directly to the galaxy distribution. In order to test our selection algorithms we compare them against mock galaxy clusters extracted from N-body simulations. Our main results are as follows:  1. Using the matched filter technique we find that the number density of galaxy clusters at z < 0.5 is n(z<0.5) = 3.6 +/- 0.2 x 10-3 h3 Mpc-3 . This value agrees well with previous determinations using other techniques.  2. By applying the same matched filter technique to simulated galaxy clusters we show how this method can be used to estimate the mass function of galaxy clusters up to z ~1.0.",
        "watermark_text": "We present an assessment of galaxy regions selected by their red - sequence galaxies ( Gladders & Yee 2005 ) from the Sloan Digital Sky Survey Data Release 4 ( DR4 ) . We use two different methods to select cluster applicants , and then use photometric redshift cutting on these specimens to obtain final catalogues with high purity .The first method is based on the matched filter technique developed for X - ray observations ( Postman et al 1996 ) , while the second one uses a enemies - of - friends method applied directly to the galaxy distribution . In order to test our choice algorithms we compare them against mock galaxy galaxies extracted from N - bodies simulations .Our main results are as follows : 1 . Using the matched filter technique we find that the number density of galaxy galaxies at z < 0 . 5 is n ( z < 0 . 5 ) = 3 . 6 + / - 0 . 2 x 10 - 3 h3 Mpc - 3 .This value agrees well with previous determinations using other techniques.2.By applying the same matched filter technique to modeled galaxy galaxies we find how this algorithm can be used to estimate the mass value of galaxy galaxies up to z ~ 1 . 0 .",
        "rewrite_text": "We provide an evaluation of galaxy regions identified by their red-sequence galaxies (Gladders & Yee 2005) from the Sloan Digital Sky Survey Data Release 4 (DR4). Our approach involves two distinct methods for selecting cluster candidates, followed by the application of photometric redshift cuts to enhance the purity of the final catalogs. The first method utilizes the matched filter technique originally devised for X-ray observations (Postman et al. 1996), while the second method employs a friends-of-friends algorithm directly on the galaxy distribution. To validate our selection algorithms, we compare them to mock galaxy samples derived from N-body simulations. Our key findings include: 1. Utilizing the matched filter technique, we determine that the number density of galaxies at redshift z < 0.5 is n(z < 0.5) = 3.6 ± 0.2 x 10⁻³ h³ Mpc⁻³, which is consistent with previous measurements obtained through different methods. 2. When applying the same matched filter technique to simulated galaxy samples, we demonstrate that this algorithm can effectively estimate the mass of galaxies up to z ~ 1.0.",
        "ori-fast-z-score": 1.4924050144892729,
        "water-fast-z-score": 5.9696200579570915,
        "rewrite-fast-z-score": -1.091089451179962
    },
    {
        "original_text": "We present an open-source code, called XSCORT (X-ray Spectral Code for Reprocessed Torus), which computes the reprocessing of radiation by optically-thick matter in the form of a torus and its associated wind. The code is written as a set of IDL routines that can be easily modified to study different geometries or physical conditions. We describe how we implemented our model using Monte Carlo techniques and discuss some tests performed with simulated data. Finally, we show examples of applications of this new tool to two well-studied objects, NGC 4151 and Mrk 509. \nThe main goal of XSCORT is to provide a flexible framework where one can explore the effects of various parameters such as: geometry, density distribution, chemical composition, ionization state, etc., on the observed spectral properties of active galactic nuclei (AGN). This will allow us to better understand their nature and evolution. \n \n In particular, we are interested in studying the effect of the presence of an outflowing component on the shape of the reflection hump produced by the innermost regions of the accretion disc around supermassive black holes. These winds may play an important role in shaping the broad-band continuum emission of these sources through absorption and/or scattering processes. They also affect the amount of material available to produce the reflected emission at larger distances from the central source.",
        "watermark_text": "We produce an open - source code , known XSCORT ( X - ray Spectral Code for Reprocessed Torus ) , which computes the reprocessing of radiation by optically - heavy material in the form of a torus and its attendant wind . The language is read as a group of IDL routines that can be easily modified to study various geometries or material conditions .We discuss how we implemented our model utilizing Monte Carlo methods and explain some experiments conducted with simulated evidence . Finally , we give instance of applications of this new method to two better - examined objects , NGC 4151 and Mrk 509 .The main goal of XSCORT is to provide a broad platform where one can examine the effects of several variables such as : topography , density flow , chemical composition , ionization state , etc . , on the known spectral properties of active galactic nuclei ( AGN ) . This will provide us to easier understand their nature and evolution .In particular , we are concerned in examining the impact of the presence of an outflowing component on the form of the reflection hump produced by the innermost sectors of the accretion disc around supermassive black holes . These winds may play an important role in shaping the broad - band continuum emission of these sources through absorption and / or scattering mechanisms .They also affect the quantity of material provided to produce the reflected emission at larger distances from the main source .",
        "rewrite_text": "We have developed an open-source code called XSCORT (X-ray Spectral Code for Reprocessed Torus) that simulates the reprocessing of radiation by optically thick material in a torus configuration, along with its associated wind. The code comprises a collection of IDL routines that are easily customizable to explore different geometries and material conditions. In this discussion, we outline how we implemented our model using Monte Carlo methods and present experiments conducted with simulated data. Additionally, we showcase applications of this new approach on two well-studied objects, NGC 4151 and Mrk 509. The primary objective of XSCORT is to create a versatile platform that allows researchers to investigate the influence of various parameters—such as topography, density flow, chemical composition, and ionization state—on the known spectral characteristics of active galactic nuclei (AGN). This enhanced understanding will contribute to our comprehension of their nature and evolution. Specifically, we aim to analyze how the presence of an outflowing component affects the reflection hump generated by the innermost regions of the accretion disc surrounding supermassive black holes. These winds may significantly influence the broad-band continuum emission of these sources through absorption and scattering processes and also alter the amount of material available for producing reflected emission at greater distances from the primary source.",
        "ori-fast-z-score": -1.7650452162436565,
        "water-fast-z-score": 6.601706163700764,
        "rewrite-fast-z-score": -0.5883484054145521
    },
    {
        "original_text": "We report the discovery and characterization of TrES-3b, an extrasolar planet with mass M = 1.3 MJup orbiting its host star every 31 hours at 0.081 AU (1.7 stellar radii). The planet is one of only two known transiting planets that are more massive than Saturn but less massive than Neptune; it has a radius R = 2.2 RJup and effective temperature T eff = 2400 K. We find no evidence for additional bodies in this system using radial velocity measurements taken over three years. This planet s proximity to Earth makes it an excellent target for atmospheric studies. \n \n Keywords: Extrasolar planet - Discovery - Transit photometry - Radial velocities - Atmosphere - Planetary systems \n \n \n \n Introduction \n \n In recent years there have been several discoveries of giant exoplanets with orbital periods shorter than four days. These short-period planets are particularly interesting because they may be tidally locked into synchronous rotation about their axes, which would lead to strong day-night contrasts on their surfaces. Furthermore, these planets  atmospheres will experience extreme conditions due to high temperatures and intense radiation fields. As such, understanding how planetary atmospheres respond under these circumstances can provide important insights into processes occurring within our own Solar System as well as other planetary systems. \n \n Here we present the discovery and initial characterization of TrES-3b; a hot Jupiter with a period P = 3.09 d discovered by the transit method. Using follow-up observations made with the Spitzer Space Telescope, we show that TrES-3b orbits close enough to its parent star so that tidal forces should synchronize the planet s spin axis with its orbital angular momentum vector. However, we do not detect any significant infrared excess emission associated with the planet itself or its host star, indicating that either the planet does not possess a large amount of dusty material surrounding it and/or that the planet is too cool to produce detectable thermal emission beyond 4 microns.",
        "watermark_text": "We report the discovery and description of TrES - 3b , an extrasolar planet with mass M = 1 . 3 MJup orbiting its host star every 31 days at 0 . 081 AU ( 1 . 7 stellar radii ) . The planet is one of only two recorded transiting planets that are more massive than Saturn but less massive than Neptune ; it has a diameter R = 2 . 2 RJup and effective heat T eff = 2400 K . We see no evidence for additional body in this system using radial speed measurements taken over three years .This planet s vicinity to Earth makes it an excellent target for atmospheric studies . Keywords : Extrasolar moon - Discovery - Transit photometry - Radial velocities - Atmosphere - Planetary systems Introduction In recent history there have been numerous discoveries of large exoplanets with orbital periods shorter than four weeks .These short - time planets are particularly exciting because they may be tidally locked into synchronous spin about their axes , which would result to powerful day - night contrasts on their surfaces . Furthermore , these planets atmospheres will experience harsh conditions due to large temperatures and intense radiation fields .As such , studying how planetary atmospheres behave under these circumstances can provide important perspectives into processes arising within our own Solar System as also as other planetary components . Here we present the discovery and preliminary characterization of TrES - 3b ; a bright Jupiter with a period P = 3 . 09 d discovered by the transit method .Using follow - up observations made with the Spitzer Space Telescope , we find that TrES - 3b orbits close enough to its father planet so that tidal forces should synchronize the planet s spin axis with its orbital angular velocity vector . However , we do not detect any considerable laser excess emission associated with the planet itself or its host star , showing that either the planet does not possess a large number of dusty substance surrounding it and / or that the planet is too warm to produce detectable heat emission beyond 4 microns .",
        "rewrite_text": "We present the discovery and characterization of TrES-3b, an extrasolar planet with a mass of 1.3 times that of Jupiter (MJup), orbiting its star every 31 days at a distance of 0.081 AU (1.7 stellar radii). This planet is notable as one of only two known transiting planets that are more massive than Saturn yet less massive than Neptune; it has a radius of 2.2 times that of Jupiter (RJup) and an effective temperature (T_eff) of 2400 K. Through three years of radial velocity measurements, we have found no evidence of additional bodies in this system. The proximity of TrES-3b to Earth makes it an excellent candidate for atmospheric studies. \n\nKeywords: Extrasolar planet, Discovery, Transit photometry, Radial velocities, Atmosphere, Planetary systems. \n\nIntroduction: Recently, there has been an increase in the discovery of large exoplanets with orbital periods shorter than four weeks. These short-period planets are particularly intriguing, as they may become tidally locked to their host stars, resulting in significant day-night temperature contrasts on their surfaces. Additionally, their atmospheres may endure extreme temperatures and intense radiation. Studying how atmospheres of such planets respond to these conditions can provide valuable insights into the processes occurring within our own Solar System as well as in other planetary systems. In this paper, we detail the discovery and preliminary characterization of TrES-3b, a bright Jupiter-like exoplanet with a period of 3.09 days, identified through the transit method. Follow-up observations with the Spitzer Space Telescope indicate that TrES-3b orbits its host star closely enough that tidal forces should align the planet’s rotation with its orbital movement. However, we have not detected any significant infrared excess emission from the planet or its star, suggesting that either the planet lacks a substantial circumplanetary dust environment or that its high temperature prevents it from emitting detectable radiation beyond 4 microns.",
        "ori-fast-z-score": -0.4240944648399855,
        "water-fast-z-score": 6.5310547585357765,
        "rewrite-fast-z-score": -0.7184212081070996
    },
    {
        "original_text": "We present new results on the nature of dust extinction in external galaxies, based on observations with HST/ACS of type Ia supernovae (SNe) at redshifts z=0.1-0.7. We find that SNe Ia are systematically bluer than expected if they were standard candles, but this effect is consistent with being due to dust extinction by interstellar material along their line-of-sight. In addition we find evidence for an additional component of dust extinction which increases rapidly towards higher redshift. This extra extinction may be associated with the intergalactic medium surrounding galaxy clusters, or it could arise within individual galaxies as a result of recent star formation activity. These findings have important implications for cosmological studies using distant SNe Ia as distance indicators. \n \n Keywords: Galaxy cluster, Interstellar matter, Intergalactic medium, Redshift evolution, Supernova, Supernova Ia",
        "watermark_text": "We report new data on the nature of dust extinction in external galaxies , based on observations with HST / ACS of type Ia supernovae ( SNe ) at redshifts z = 0 . 1 - 0 . 7 . We see that SNe Ia are steadily bluer than expected if they were standard candles , but this effect is compatible with being owing to dust disappearance by interstellar material along their line - of - view .In addition we find proof for an additional element of dust extinction which increases quickly towards higher redshift . This extra extinction may be correlated with the intergalactic medium surrounding galaxy galaxies , or it could occur within individual stars as a product of recent star formation activity .These conclusions have important implications for cosmological experiments using distant SNe Ia as distance indicators . Keywords : Galaxy cluster , Interstellar matter , Intergalactic medium , Redshift formation , Supernova , Supernova Ia",
        "rewrite_text": "We present new findings regarding dust extinction in external galaxies, derived from Hubble Space Telescope (HST) and Advanced Camera for Surveys (ACS) observations of Type Ia supernovae (SNe) at redshifts ranging from z = 0.1 to z = 0.7. Our analysis shows that SNe Ia are consistently bluer than expected if they were treated as standard candles. This discrepancy can be attributed to the disappearance of dust in the interstellar medium along their line of sight. Additionally, we have identified a significant component of dust extinction that increases sharply with higher redshift. This extra extinction might be linked to the intergalactic medium surrounding galaxies or may result from dust within individual stars due to recent star formation activity. These findings have critical implications for cosmological studies that utilize distant SNe Ia as distance indicators. \n\nKeywords: Galaxy cluster, Interstellar matter, Intergalactic medium, Redshift formation, Supernova, Supernova Ia.",
        "ori-fast-z-score": 0.25,
        "water-fast-z-score": 5.5,
        "rewrite-fast-z-score": -0.25
    },
    {
        "original_text": "We present results for the two-way coupling between an incompressible, isothermal fluid and a dilute suspension of elastic dumbbell particles in a plane Couette geometry at Reynolds number Re = 1000. The particle phase consists of N p = 10 5 identical dumbbells suspended in a Newtonian solvent. We use a hybrid lattice Boltzmann method to solve the Navier-Stokes equations coupled to a finite element solver for the evolution of the dumbbell configuration. In addition we employ a novel algorithm that allows us to efficiently compute the hydrodynamic forces on each individual dumbbell by solving only one Stokes problem per time step instead of Np problems as would be required if the standard approach were used. This leads to significant computational savings especially when large numbers of dumbbells are considered. \n \n For small values of the relaxation parameter λ (λ < 0.5) we find that the presence of the particles has little effect on the mean velocity profile but significantly alters its fluctuations. As expected, increasing the value of λ increases both the magnitude of the fluctuations and their correlation length scale.",
        "watermark_text": "We present results for the two - way interaction between an incompressible , isothermal fluid and a dilute suspension of elastic dumbbell particles in a plane Couette geometry at Reynolds number Re = 1000 . The particle phase contains of N n = 10 5 identical dumbbells suspended in a Newtonian solvent .We use a hybrid lattice Boltzmann technique to solve the Navier - Stokes equations coupled to a finite element solver for the evolution of the dumbbell configuration . In addition we utilize a new algorithm that enables us to easily compute the hydrodynamic forces on each individual dumbbell by solving only one Stokes task per time step instead of Np problems as would be required if the standard method were used .This leads to significant computational advantages even when large numbers of dumbbells are considered . For small values of the relaxation parameter λ ( λ < 0 . 5 ) we find that the presence of the particles has little impact on the mean speed profile but significantly alters its fluctuations .As expected , increasing the value of λ increases both the magnitude of the fluctuations and their correlation length scale .",
        "rewrite_text": "We present findings on the two-way interaction between an incompressible, isothermal fluid and a dilute suspension of elastic dumbbell particles within a plane Couette flow at a Reynolds number of Re = 1000. The particle phase consists of Nn = 10^5 identical dumbbells suspended in a Newtonian solvent. Our approach employs a hybrid lattice Boltzmann method to solve the Navier-Stokes equations, which are coupled with a finite element solver to track the evolution of the dumbbell configuration. Additionally, we introduce a novel algorithm that allows for the efficient computation of hydrodynamic forces on each individual dumbbell by solving a single Stokes problem per time step, rather than the Np problems required by traditional methods. This results in considerable computational benefits, even with large quantities of dumbbells. For small relaxation parameters (λ < 0.5), we observe that while the mean speed profile remains largely unaffected by the particles, the fluctuations are significantly modified. As anticipated, increasing the relaxation parameter λ enhances both the magnitude of the fluctuations and their correlation length scale.",
        "ori-fast-z-score": -0.22645540682891913,
        "water-fast-z-score": 2.6210932585716726,
        "rewrite-fast-z-score": -0.917662935482247
    },
    {
        "original_text": "The objective was to evaluate the potential use of Monoksa dorsiplana as an alternative biological control agent against Pseudopachymeria sp. (Bruchidae). The parasitoids were obtained in laboratory and released on P.sp. eggs laid by females collected at different locations in Brazil, Argentina and Paraguay. Egg parasitism ranged between 0.5 and 88% depending on location. Parasitized eggs hatched after 7 days under controlled conditions. Males emerged first followed by females. Female longevity varied according to temperature ranging from 11 to 21 days at 25 °C; 14 to 23 days at 20 °C and 16 to 27 days at 15 °C. Females oviposited for up to three weeks when fed with honey solution. This species is considered highly suitable for mass production because it has high reproductive capacity and short life cycle. It can be used successfully in integrated pest management programs aimed at reducing damage caused by this insect pest.",
        "watermark_text": "The goal was to examine the possibilities application of Monoksa dorsiplana as an alternative bio control drug against Pseudopachymeria sp . ( Bruchidae ) .The parasitoids were obtained in laboratory and captured on P . sp . eggs laid by females collected at different places in Brazil , Argentina and Paraguay .Egg parasitism ranged between 0 . 5 and 88 % depending on location . Parasitized nests hatched after 7 days under regulated conditions .Males appeared first followed by females . Female longevity varied based to heat ranging from 11 to 21 weeks at 25 °C ; 14 to 23 days at 20 °C and 16 to 27 days at 15 °C .Females oviposited for up to three weeks when fed with honey solution . This species is regarded highly suited for mass production because it has large sexual capacity and low life cycle .It can be used successfully in effective pest management projects designed at decreasing damage suffered by this insect pest .",
        "rewrite_text": "The objective of this study was to investigate the potential use of Monoksa dorsiplana as an alternative biocontrol agent against Pseudopachymeria sp. (Bruchidae). The parasitoids were collected in the laboratory and captured from the eggs of P. sp. laid by females gathered from various locations in Brazil, Argentina, and Paraguay. The rate of egg parasitism varied significantly by location, ranging from 0.5% to 88%. Under controlled conditions, the parasitized nests hatched after seven days, with males emerging first, followed by females. The longevity of the females depended on temperature, lasting between 11 to 21 weeks at 25 °C, 14 to 23 days at 20 °C, and 16 to 27 days at 15 °C. When provided with a honey solution, females could oviposit for up to three weeks. This species is considered highly suitable for mass production due to its substantial reproductive capacity and short life cycle, making it effective for pest management programs aimed at reducing damage caused by this insect pest.",
        "ori-fast-z-score": -0.75,
        "water-fast-z-score": 5.829632525692798,
        "rewrite-fast-z-score": 0.1203858530857692
    },
    {
        "original_text": "We present an analysis of the relationship between morphological distortions in galaxies, as measured by their asymmetries (A), and their projected separations into close pairs (rp). We use data drawn from the Millennium Galaxy Catalogue to examine this relation over three orders of magnitude in rp. Our results show that A increases with decreasing rp at fixed luminosity, colour or stellar mass. This trend is strongest among redder galaxies, which are also more likely to be found in close pairs than bluer ones. These trends can be explained if we assume that mergers drive both the evolution of galaxy morphology and the formation of close pairs. Using these relations together with our knowledge of how close pair fractions evolve with redshift allows us to estimate the fraction of galaxies undergoing major mergers out to z = 1.5. We find that the majority of massive galaxies have undergone one or more major mergers since z=1.",
        "watermark_text": "We present an assessment of the relationship between morphological distortions in galaxies , as measured by their asymmetries ( A ) , and their estimated separations into close pairs ( rp ) . We use data taken from the Millennium Galaxy Catalogue to examine this link over three orders of magnitude in rp .Our results show that A changes with varying rp at fixed luminosity , colour or stellar mass . This trend is greatest among redder galaxies , which are also more likely to be found in close sets than bluer ones .These trends can be described if we suppose that mergers cause both the evolution of galaxy shape and the formation of close pairs . Using these relations together with our information of how close pair fractions grow with redshift permits us to estimate the fraction of clusters undergoing main mergers out to z = 1 . 5 .We see that the majority of large galaxies have undergone one or more massive mergers since z = 1 .",
        "rewrite_text": "We present an analysis of the connection between morphological distortions in galaxies, as indicated by their asymmetries (A), and their estimated proximity in close pairs (rp). Utilizing data from the Millennium Galaxy Catalogue, we investigate this relationship across three orders of magnitude in rp. Our findings reveal that A varies with changes in rp while controlling for luminosity, color, or stellar mass. This variation is most pronounced among redder galaxies, which are also more frequently found in close pairs compared to their bluer counterparts. These observations can be explained by the hypothesis that mergers drive both the evolution of galaxy shapes and the formation of close pairs. By combining these insights with our understanding of how the fractions of close pairs increase with redshift, we can estimate the proportion of clusters experiencing major mergers up to z = 1.5. Our results indicate that most large galaxies have undergone one or more significant mergers since z = 1.",
        "ori-fast-z-score": -0.1259881576697424,
        "water-fast-z-score": 4.913538149119954,
        "rewrite-fast-z-score": 0.3841106397986879
    },
    {
        "original_text": "We study the problem of finding an optimal schedule for data transmission over multiple channels with interference constraints, where each channel is assigned to one transmitter-receiver pair and transmissions on different pairs are subject to mutual interference. We consider two models: (i) The first model assumes that all transmitters have fixed power levels. (ii) In the second model we assume that transmitters can adjust their powers dynamically. For both cases, we show how to find an optimal schedule by solving a sequence of linear programs. Our results hold even if there exists only one receiver per transmitter. This work was supported by NSF grant CCF-0430018. 1 Introduction Wireless networks consist of many nodes communicating via radio signals. Each node has limited range and thus cannot communicate directly with every other node. Instead, it communicates indirectly through intermediate nodes called relays or routers. A fundamental question in this context is: How should these relays be placed?",
        "watermark_text": "We explore the question of finding an appropriate schedule for information transmission over multiple channels with interference constraints , where each channel is allotted to one transmitter - receiver set and signals on separate pairs are subject to mutual interference . We consider two models : ( i ) The first theory requires that all transmitters have fixed power rates .( ii ) In the second theory we suppose that transmitters can adjust their powers dynamically . For both cases , we show how to find an appropriate schedule by solving a sequence of linear programs .Our results hold even if there exists only one receiver per transmitter . This work was supported by NSF grant CCF - 0430018 .1 Introduction Wireless networks consist of several nodes communicating via radio signals . Each node has restricted range and therefore cannot transmit directly with every other node .Instead , it communicates indirectly through intermediate nodes termed relays or routers . A basic issue in this situation is : How should these relays be placed ?",
        "rewrite_text": "We investigate the challenge of creating an effective schedule for information transmission across multiple channels that face interference limitations. In this setup, each channel is dedicated to a unique transmitter-receiver pair, and signals from different pairs can interfere with each other. We analyze two models: (i) the first requires all transmitters to operate at fixed power levels, and (ii) the second allows transmitters to adjust their power levels dynamically. For both scenarios, we demonstrate a method for determining an efficient schedule by solving a series of linear programming problems. Our findings remain applicable even with only one receiver for each transmitter. This research was made possible by NSF grant CCF - 0430018. Introduction: Wireless networks consist of multiple nodes that communicate via radio signals. Due to limited transmission ranges, nodes cannot communicate directly with every other node, necessitating indirect communication through intermediary nodes known as relays or routers. A key question in this context is: How should these relays be strategically positioned?",
        "ori-fast-z-score": -1.0256451881367414,
        "water-fast-z-score": 3.623286509262706,
        "rewrite-fast-z-score": -0.5488212999484517
    },
    {
        "original_text": "We report on kinetic-ion simulations addressing whether ion trapping inflates stimulated Brillouin backscattering (SBS) reflectivities in the presence of an electron beam and plasma waves. We find that, for typical parameters relevant to high-power laser-plasma experiments, SBS is dominated by electrostatic Langmuir wave instabilities rather than ion-acoustic modes. The latter are suppressed due to Landau damping as well as mode conversion into electromagnetic radiation at oblique angles with respect to the direction of propagation. In addition, we show that the effect of ion trapping can be neglected if the density fluctuations associated with the trapped ions are small compared to those caused by the electrons. Finally, we demonstrate that the inclusion of ion trapping does not significantly affect the growth rates or saturation levels of the dominant electrostatic Langmuir waves. This finding suggests that the observed discrepancies between theory predictions and experimental results may originate from other effects such as nonlocality and/or nonlinear coupling among different types of waves.",
        "watermark_text": "We report on kinetic - ion simulations addressing whether electron capture inflates stimulated Brillouin backscattering ( SBS ) reflectivities in the presence of an electron beam and plasma beams . We see that , for typical values appropriate to large - speed laser - plasma experiments , SBS is dominated by electrostatic Langmuir beam instabilities rather than ion - sound modes .The latter are suppressed due to Landau damping as well as mode conversion into electromagnetic radiation at oblique angles with regard to the direction of propagation . In addition , we prove that the impact of ion traps can be forgotten if the density fluctuations associated with the captured atoms are small relative to those generated by the electrons .Finally , we prove that the introduction of ion traps does not dramatically impact the development rates or saturation levels of the dominant electrostatic Langmuir waves . This conclusion suggests that the reported discrepancies between theoretical estimates and theoretical results may originate from other effects such as nonlocality and / or nonlinear coupling among different kinds of waves .",
        "rewrite_text": "We present results from kinetic-ion simulations that explore whether electron capture influences the enhancement of stimulated Brillouin backscattering (SBS) reflectivities in the presence of electron and plasma beams. Our findings indicate that, for typical conditions relevant to high-velocity laser-plasma experiments, SBS is primarily governed by electrostatic Langmuir beam instabilities, as opposed to ion-sound modes, which are suppressed due to Landau damping and mode conversion into electromagnetic radiation at oblique angles to the propagation direction. Furthermore, we demonstrate that the effects of ion traps can be disregarded if the density fluctuations related to the captured atoms are relatively minor compared to those generated by the electrons. Finally, we establish that the inclusion of ion traps does not significantly alter the growth rates or saturation levels of the dominant electrostatic Langmuir waves. This conclusion implies that the discrepancies between theoretical predictions and experimental results may stem from other factors, such as nonlocality and nonlinear interactions among different wave types.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.0201176116964925,
        "rewrite-fast-z-score": 2.523573072576179
    },
    {
        "original_text": "We report on an observation made with Suzaku satellite to study X-ray variability of active galactic nucleus (AGN) NGC 3783, which is known as one of brightest Seyfert 1 galaxies at soft X-rays. We found that the fluxes of both the iron Kα line and the continuum are modulated by a factor of about two over a period of 100 ks. The phase lag between these two components was estimated to be ~0.1 s using cross-correlation analysis. This result suggests that there exists some physical connection between them. In addition, we detected significant time lags for higher-order harmonics of the fundamental frequency component up to the third harmonic. These results suggest that the observed variability may originate from reverberation effects caused by variable illumination of the accretion disk around supermassive black hole. Keywords: Reverberation; Time lag; Iron line; AGN",
        "watermark_text": "We report on an observation made with Suzaku spacecraft to study X - ray variability of active galactic nucleus ( AGN ) NGC 3783 , which is known as one of brightest Seyfert 1 clusters at soft X - rays . We determined that the fluxes of both the metal Kα line and the continuum are modulated by a factor of about two over a period of 100 ks .The wave lag between these two parts was calculated to be ~ 0 . 1 s using cross - correlation analysis . This result suggests that there exists some physical link between them .In addition , we identified significant moment lags for greater - order harmonics of the fundamental frequency component up to the third harmonic . These conclusions show that the seen variability may originate from reverberation effects caused by variable illumination of the accretion disk around supermassive black hole .Keywords : Reverberation ; Time lag ; Iron line ; AGN",
        "rewrite_text": "We present findings from an observation conducted with the Suzaku spacecraft to investigate the X-ray variability of the active galactic nucleus (AGN) NGC 3783, recognized as one of the brightest Seyfert 1 galaxies in the soft X-ray regime. Our analysis revealed that the fluxes of both the metal Kα line and the continuum exhibit modulation by approximately a factor of two over a timeframe of 100 ks. Using cross-correlation analysis, we calculated a wave lag of about 0.1 seconds between these two components, indicating a potential physical connection between them. Furthermore, we observed significant moment lags for higher-order harmonics of the fundamental frequency component, extending up to the third harmonic. These results imply that the observed variability may stem from reverberation effects linked to the fluctuating illumination of the accretion disk surrounding a supermassive black hole. \n\nKeywords: Reverberation; Time lag; Iron line; AGN",
        "ori-fast-z-score": 1.6641005886756874,
        "water-fast-z-score": 5.547001962252292,
        "rewrite-fast-z-score": 1.3363062095621219
    },
    {
        "original_text": "We have studied in detail how to correct for various observational effects on the determination of the white dwarf luminosity function (WDLF). We find that the WDLF is affected by several factors, such as photometric calibration error, incompleteness due to detection limit, contamination by unresolved binaries, etc.. In order to obtain an unbiased estimate of the true WDLF we need to take into account these effects properly.  By using Monte Carlo simulations with artificial data sets, we show that our method can recover the input WDLF very well even when there are large uncertainties in the observed magnitudes or colors. Our results also suggest that it may be difficult to determine the absolute normalization of the WDLF accurately because of systematic uncertainty associated with the distance scale. Finally, we apply this method to the recent observations made by the Sloan Digital Sky Survey (SDSS) Data Release 1 (DR1), which covers about one quarter of the sky.",
        "watermark_text": "We have researched in detail how to correct for various observational consequences on the determination of the white dwarf luminosity function ( WDLF ) . We see that the WDLF is affected by many processes , such as photometric calibration error , incompleteness attributed to observation limit , contamination by unresolved binaries , etc . .In order to obtain an unbiased estimate of the true WDLF we must to take into consideration these consequences properly . By using Monte Carlo simulations with artificial data sets , we prove that our technique can regain the input WDLF very best even when there are big uncertainties in the seen magnitudes or colors .Our results also suggest that it could be harder to predict the absolute normalization of the WDLF accurately because of systematic uncertainty associated with the distance scale . Finally , we apply this method to the recent observations made by the Sloan Digital Sky Survey ( SDSS ) Data Release 1 ( DR1 ) , which covers about one quarter of the heavens .",
        "rewrite_text": "We have conducted a thorough investigation into the factors that affect the determination of the white dwarf luminosity function (WDLF). Our findings indicate that the WDLF is influenced by various processes, including errors in photometric calibration, observational incompleteness, and contamination from unresolved binary systems. To derive an unbiased estimate of the true WDLF, it is crucial to account for these factors appropriately. By employing Monte Carlo simulations with synthetic datasets, we demonstrate that our method can accurately recover the input WDLF, even in the presence of significant uncertainties in the observed magnitudes or colors. Additionally, our results imply that accurately predicting the absolute normalization of the WDLF may be more challenging due to systematic uncertainties related to the distance scale. Finally, we apply our technique to recent observations from the Sloan Digital Sky Survey (SDSS) Data Release 1 (DR1), which encompasses roughly a quarter of the sky.",
        "ori-fast-z-score": 1.016001016001524,
        "water-fast-z-score": 6.273807116711903,
        "rewrite-fast-z-score": 0.2626128657194451
    },
    {
        "original_text": "We report the discovery of two new TeV PWN candidates, HESS J1825-137 and HESS J1857+026, using data taken with the High Energy Stereoscopic System (H.E.S.S.) between 2004 and 2007. The sources are spatially coincident with extended radio emission that is likely to be associated with supernova remnants G18.0-0.7 and CTB 37A respectively. Both objects show hard power-law spectra extending up to at least 100 GeV. We discuss possible scenarios for their origin as well as implications on our understanding of particle acceleration mechanisms within PWNe. Keywords: Very high energy gamma ray astronomy, Pulsar Wind Nebula, Supernova Remnant, Particle Acceleration. 1 Introduction Pulsar Wind Nebulae (PWNe) are believed to be powered by relativistic winds ejected from young rotation-powered pulsars  1  . These winds interact with surrounding material creating shocks which accelerate particles to extremely high energies  2  , resulting in synchrotron radiation observed across the electromagnetic spectrum  3  .\nThe detection of high-energy photons emitted by these systems can provide important information about the physical processes occurring inside them  4  . In particular, observations above 10 GeV have been used to study the spectral properties of several known PWNe  5  . However, only one object has so far been detected beyond 30 GeV  6  . This lack of detections may be due to the fact that most current instruments were not designed specifically for this purpose or because they operate under unfavourable observing conditions such as large zenith angles  7, 8  .",
        "watermark_text": "We report the discovery of two different TeV PWN candidates , HESS J1825 - 137 and HESS J1857 + 026 , using data taken with the High Energy Stereoscopic System ( H . E . S . S . ) between 2004 and 2007 .The sources are spatially coincident with extended radio emission that is expected to be correlated with supernova remnants G18 . 0 - 0 . 7 and CTB 37A respectively . Both bodies exhibit hard energy - law spectra extending up to at least 100 GeV .We discuss possible possibilities for their source as well as implications on our knowing of particle acceleration mechanisms within PWNe . Keywords : Very large energy beta ray physics , Pulsar Wind Nebula , Supernova Remnant , Particle Acceleration .1 Introduction Pulsar Wind Nebulae ( PWNe ) are said to be powered by relativistic winds ejected from young rotation - powered pulsars 1 . These winds interact with nearby matter forming shocks which accelerate particles to incredibly high energies 2 , resulting in synchrotron rays seen across the electromagnetic spectrum 3 .The observation of high - energy photons generated by these systems can provide important information about the physical processes arising inside them 4 . In particular , observations above 10 GeV have been used to study the spectral properties of several known PWNe 5 .However , only one object has so far been detected beyond 30 GeV 6 . This lack of detections might be due to the fact that most current instruments were not designed specifically for this function or because they operate under unfavourable observing situations such as huge zenith axes 7 , 8 .",
        "rewrite_text": "We announce the detection of two distinct TeV Pulsar Wind Nebula (PWN) candidates, HESS J1825 - 137 and HESS J1857 + 026, based on data collected by the High Energy Stereoscopic System (H.E.S.S.) between 2004 and 2007. These sources are spatially aligned with extended radio emissions, which are likely associated with the supernova remnants G18.0 - 0.7 and CTB 37A, respectively. Both candidates display hard energy spectra that extend to at least 100 GeV. We explore potential origins for these sources and their implications for our understanding of particle acceleration mechanisms within PWNe. \n\nKeywords: Very high-energy gamma-ray physics, Pulsar Wind Nebula, Supernova Remnant, Particle Acceleration.\n\n1. Introduction: \nPulsar Wind Nebulae (PWNe) are believed to be driven by relativistic winds emitted by young, rotating pulsars. These winds interact with surrounding matter, generating shocks that accelerate particles to extraordinarily high energies, which produce synchrotron radiation observable across the electromagnetic spectrum. Observations of high-energy photons from these systems can yield valuable insights into the underlying physical processes. Specifically, measurements above 10 GeV have facilitated the study of the spectral characteristics of several known PWNe. However, to date, only one object has been detected beyond 30 GeV. This scarcity of detections may stem from the fact that most existing instruments were not optimized for such observations or because they operate under less than favorable observing conditions, such as large zenith angles.",
        "ori-fast-z-score": 1.6329931618554523,
        "water-fast-z-score": 7.005888539421972,
        "rewrite-fast-z-score": -0.52999894000318
    },
    {
        "original_text": "We present the first results on Spitzer infrared spectroscopy (IRS) observations of four Galactic supernova remnants, G11.2−0.3, Kes 17, RCW 103, and W44. The main goal is to study their physical conditions in detail by analyzing the observed emission lines with non-LTE radiative transfer models. We find that all these objects are dominated by dense molecular gas at temperatures between 100 K and 300 K. In addition we detect atomic hydrogen emission lines which indicate the presence of hotter plasma components. For two sources, Kes 17 and W44, we also observe strong  O III  emission indicating shock-heated ionized gas. Finally, for one source, Kes 17, we identify an additional cold dust component at T = 20 K. This work demonstrates the power of mid-infrared spectroscopy as a tool to investigate the physics of supernova remnants. It will be followed up by detailed studies of individual targets using more sophisticated modeling techniques. \n \n Keywords: Supernova Remnant, Mid-Infrared Spectroscopy",
        "watermark_text": "We report the first findings on Spitzer infrared spectroscopy ( IRS ) observations of four Galactic supernova remnants , G11 . 2−0 . 3 , Kes 17 , RCW 103 , and W44 . The main goal is to study their physical conditions in detail by analyzing the known emission lines with non - LTE radiative transfer models .We see that all these objects are dominated by dense molecular gas at conditions between 100 K and 300 K . In addition we perceive atomic hydrogen emission lines which demonstrate the presence of hotter plasma particles . For two sources , Kes 17 and W44 , we also observe strong O III absorption indicating shock - heated ionized gas .Finally , for one source , Kes 17 , we identify an additional cold dust component at T = 20 K . This research proves the power of mid - infrared spectroscopy as a technique to examine the physics of supernova remnants . It will be followed up by detailed analyses of individual targets using more sophisticated analysis methods .Keywords: Supernova Remnant, Mid-Infrared Spectroscopy",
        "rewrite_text": "We present our initial findings from Spitzer infrared spectroscopy (IRS) observations of four Galactic supernova remnants: G11.2−0.3, Kes 17, RCW 103, and W44. The primary objective of this study is to investigate their physical conditions in detail by analyzing the known emission lines using non-local thermodynamic equilibrium (non-LTE) radiative transfer models. Our analysis reveals that all these remnants are predominantly composed of dense molecular gas, with temperatures ranging from 100 K to 300 K. Additionally, we detect atomic hydrogen emission lines, indicating the presence of hotter plasma. For two of the remnants, Kes 17 and W44, we observe significant O III absorption, suggesting the existence of shock-heated ionized gas. Notably, for Kes 17, we identify an extra cold dust component with a temperature of 20 K. This research highlights the effectiveness of mid-infrared spectroscopy as a method to study the physics of supernova remnants and will be complemented by in-depth analyses of each individual target using more advanced techniques. \nKeywords: Supernova Remnant, Mid-Infrared Spectroscopy",
        "ori-fast-z-score": 1.4342743312012722,
        "water-fast-z-score": 5.5778737935111105,
        "rewrite-fast-z-score": 1.2701705922171767
    },
    {
        "original_text": "We consider strings propagating on curved backgrounds, with emphasis on their role as sigma-models. We show that the world-sheet action for such strings can be written in terms of an auxiliary field which is related to the extrinsic curvature of the target space. This allows us to study string propagation by solving the equations of motion for this auxiliary field instead of directly solving the equation of motion for the embedding coordinates. In particular we discuss how this approach simplifies calculations when studying strings in AdS spaces or near black holes. Finally, we use our formalism to investigate the behavior of strings at high energies where they become tensionless. We find that these strings are described by a conformal theory whose central charge vanishes. The corresponding Virasoro generators have negative norm states so that the Hilbert space has indefinite metric. These results provide further evidence that tensionless strings may play an important rôle in understanding quantum gravity.",
        "watermark_text": "We consider strings propagating on curved landscapes , with emphasis on their role as sigma - models . We see that the world - sheet action for such strings can be written in terms of an auxiliary field which is related to the extrinsic curvature of the target space .This enables us to study string propagation by solving the equations of movement for this auxiliary field instead of specifically solving the equation of movement for the embedding coordinates . In particular we explain how this methodology simplifies calculations when examining strings in AdS spaces or close black holes .Finally , we utilize our formalism to examine the response of instruments at high energies where they become tensionless . We see that these strings are explained by a conformal theory whose central charge vanishes .The equivalent Virasoro generators have negative norm states so that the Hilbert space has indefinite metric . These data provide further evidence that tensionless strings might play an important rôle in understanding quantum gravitational .",
        "rewrite_text": "We investigate strings moving through curved spaces, focusing on their function as sigma-models. We demonstrate that the world-sheet action for these strings can be expressed using an auxiliary field that is associated with the extrinsic curvature of the target space. This approach allows us to analyze string propagation by solving the equations of motion for this auxiliary field rather than directly addressing the equations of motion for the embedding coordinates. Specifically, we illustrate how this method streamlines calculations, particularly when studying strings in AdS spaces or near black holes. Lastly, we apply our framework to explore the behavior of instruments at high energies when they become tensionless. Our findings indicate that these strings are described by a conformal theory with a vanishing central charge. The associated Virasoro generators exhibit negative norm states, resulting in a Hilbert space with an indefinite metric. This evidence supports the idea that tensionless strings may play a significant role in advancing our understanding of quantum gravity.",
        "ori-fast-z-score": -1.162476387438193,
        "water-fast-z-score": 3.8105117766515297,
        "rewrite-fast-z-score": -1.6464638998453551
    },
    {
        "original_text": "The damage identification problem is formulated as an inverse problem, where the objective is to identify the location and severity of damages by minimizing the difference between simulated responses using finite element analysis (FEA) and measured data. The number of unknowns can be very large due to the presence of multiple sensors or measurement points. In this study, we propose two methods for reducing the dimensionality of the problem: principal component analysis (PCA), which reduces the dimension of the response space; and automatic relevance determination (ARD), which reduces the dimensions of both the input parameter space and the output response space simultaneously. Both PCA and ARD are implemented within the Bayesian framework so that uncertainties associated with these reduction techniques can also be accounted for during the optimization process. A numerical example involving a cantilever beam subjected to static loading is presented to demonstrate the effectiveness of the proposed approaches. Principal component analysis (PCA) and automatic relevance determination (AR",
        "watermark_text": "The damage identification question is implemented as an inverse question , where the objective is to identify the location and intensity of damages by minimizing the difference between simulated stimuli involving finite element assessment ( FEA ) and measured data . The amount of unknowns can be very huge resulting to the presence of multiple sensors or observation points .In this study , we propose two strategies for decreasing the dimensionality of the issue : principal component analysis ( PCA ) , which reduces the dimension of the response space ; and instant relevance determination ( ARD ) , which reduces the sizes of both the input parameter space and the output response space simultaneously . Both PCA and ARD are implemented within the Bayesian framework so that uncertainties involved with these reduction techniques can also be accounted for during the optimization process .A numerical example featuring a cantilever beam subjected to static loading is provided to indicate the ability of the suggested techniques . Principal part evaluation ( PCA ) and instant context determination ( AR",
        "rewrite_text": "The damage identification problem is framed as an inverse problem, aimed at pinpointing the location and severity of damages by minimizing the discrepancy between simulated data from finite element analysis (FEA) and actual measurements. The number of unknown factors can be substantial, often necessitating multiple sensors or observation points. In this study, we introduce two methods to reduce the dimensionality of this problem: principal component analysis (PCA), which diminishes the response space dimension, and automatic relevance determination (ARD), which concurrently reduces both the input parameter space and the output response space. Both PCA and ARD are integrated within a Bayesian framework, allowing for the uncertainties associated with these reduction methods to be considered during the optimization process. A numerical example involving a cantilever beam under static loading is presented to demonstrate the effectiveness of the proposed techniques.",
        "ori-fast-z-score": 0.6793662204867574,
        "water-fast-z-score": 5.887840577551898,
        "rewrite-fast-z-score": -0.24253562503633297
    },
    {
        "original_text": "We present the results of subjective evaluation experiments conducted on forms designed for use within immersive environments, such as virtual reality (VR) and augmented reality (AR). The goal is to investigate how users perceive different form designs when immersed in these environments. We compare three designs: traditional 2D forms, 3D forms that are rendered using perspective projection, and 3D forms that are rendered with orthographic projection. Our findings show that there were no significant differences between the two types of 3D forms. However, both 3D forms received significantly higher ratings than their 2D counterparts. This suggests that 3D forms can be used effectively in immersive environments without requiring special rendering techniques or additional hardware. In addition, we found that participants preferred forms that had more visual cues indicating depth information over those that did not have any such cues. Finally, our study also shows that it may be possible to create effective forms by combining elements from multiple existing designs.",
        "watermark_text": "We present the results of subjective assessment research conducted on forms designed for use within immersive environments , such as virtual reality ( VR ) and augmented reality ( AR ) . The goal is to examine how people interpret different form shapes when immersed in these habitats .We contrast three models : traditional 2D forms , 3D shapes that are rendered using view projection , and 3D shapes that are rendered with orthographic projection . Our findings show that there were no considerable variations between the two forms of 3D shapes .However , both 3D shapes took significantly greater grades than their 2D counterparts . This shows that 3D shapes can be used effectively in immersive environments without using special graphics techniques or additional hardware .In addition , we concluded that participants favored forms that had more graphical cues implying depth knowledge over those that did not have any such cues . Finally , our research also shows that it could be possible to create effective forms by combining components from multiple older patterns .",
        "rewrite_text": "We present the findings from our research on subjective assessments of forms intended for immersive environments like virtual reality (VR) and augmented reality (AR). The study aims to explore how individuals interpret various form shapes in these immersive settings. We compared three different models: traditional 2D forms, 3D shapes rendered using view projection, and 3D shapes rendered with orthographic projection. Our results indicate that there were no significant differences between the two types of 3D shapes; however, both types of 3D designs received markedly higher ratings than their 2D equivalents. This suggests that 3D shapes can be effectively utilized in immersive environments without the need for advanced graphics techniques or specialized hardware. Additionally, we discovered that participants preferred forms with more visual cues suggesting depth over those lacking such cues. Lastly, our research indicates that it might be possible to create effective forms by integrating elements from various established patterns.",
        "ori-fast-z-score": -1.1043152607484654,
        "water-fast-z-score": 7.067617668790178,
        "rewrite-fast-z-score": 0.6708203932499369
    },
    {
        "original_text": "We present new age determinations for star clusters in the Small Magellanic: Cloud (SMC). We use photometry obtained with HST/WFPC2 and ground-based telescopes to determine ages, metallicities, reddenings, and distances for these objects using isochrone fitting techniques. The resulting sample consists of 39 open clusters and associations ranging in age between 1 Myr and 10 Gyr. Our results are compared with previous studies as well as theoretical predictions based on chemical evolution models. In particular we find that there appears to be an excess number of young open clusters relative to older ones which cannot be explained by current evolutionary synthesis models or simple closed-box chemical evolution scenarios. This suggests either that the SMC has experienced recent bursts of star formation or that it may have been more gas-rich in its past than currently observed. These findings will provide important constraints on future generations of chemical evolution models. \n \n Keywords: Open cluster",
        "watermark_text": "We create novel age determinations for star clusters in the Small Magellanic : Cloud ( SMC ) . We use photometry obtained with HST / WFPC2 and land - based telescopes to identify years , metallicities , reddenings , and distances for these objects utilizing isochrone fit techniques .The resulting survey consists of 39 open complexes and groups ranging in age between 1 Myr and 10 Gyr . Our results are compared with previous research as well as conceptual predictions based on chemical evolution models .In particular we find that there seems to be an excess amount of young open nuclei comparative to older ones which cannot be described by current evolutionary synthesis models or straightforward closed - box molecular evolution models . This implies either that the SMC has undergone recent pulses of galaxy formation or that it could have been more gas - rich in its past than previously observed .These conclusions will provide important restrictions on future generations of chemical evolution models . Keywords : Open cluster",
        "rewrite_text": "We present new age determinations for star clusters in the Small Magellanic Cloud (SMC). Utilizing photometry from HST/WFPC2 and ground-based telescopes, we determine ages, metallicities, reddening, and distances for these clusters through isochrone fitting techniques. Our survey includes 39 open complexes and groups, with ages ranging from 1 million years to 10 billion years. We compare our findings with previous studies and theoretical predictions based on chemical evolution models. Notably, we observe a disproportionately high number of young open clusters compared to older ones, a phenomenon that current evolutionary synthesis models and simple closed-box molecular evolution models cannot adequately explain. This suggests that the SMC may have experienced recent bursts of star formation or may have been more gas-rich in its history than previously thought. These insights will significantly inform the development of future chemical evolution models. Keywords: Open cluster.",
        "ori-fast-z-score": -1.5652475842498528,
        "water-fast-z-score": 4.919349550499537,
        "rewrite-fast-z-score": 0.9058216273156765
    },
    {
        "original_text": "The purpose of this study is to examine whether or not there are any differences between the distributions of firm size and profitability, using data on Japanese firms for the period from 1971 to 2000. The results show that both firm size and profitability follow a log-normal distribution with different parameters. In addition, it was found that the growth rate of firm size follows Gibrat s Law while that of profitability does not. This suggests that the relationship between firm size and profitability may be explained by the fact that they have different underlying processes. Finally, we find evidence supporting the hypothesis that the process generating firm size has changed over time. We also find some support for the hypothesis that the process governing profitability has changed over time. These findings suggest that the relationship between firm-size and profitability can change over time depending upon changes in their respective underlying processes. Keywords: Firm Size Distribution, Profitability Distribution",
        "watermark_text": "The purpose of this study is to examine whether or not there are any variations between the distributions of firm size and profitability , using data on Japanese businesses for the period from 1971 to 2000 . The results show that both firm height and profitability follow a log - normal distribution with various variables .In addition , it was shown that the growth probability of firm size follows Gibrat s Law while that of profitability does not . This implies that the relationship between firm scale and profitability could be explained by the fact that they have different intrinsic processes .Finally , we find proof confirming the notion that the process generating firm size has altered over time . We additionally find some evidence for the notion that the process governing profitability has altered over time .These studies demonstrate that the relationship between firm - structure and profitability can shift over time depending upon changes in their different underlying mechanisms . Keywords : Firm Size Distribution , Profitability Distribution",
        "rewrite_text": "This study aims to explore variations in the distributions of firm size and profitability by analyzing data from Japanese companies between 1971 and 2000. The findings indicate that both firm size and profitability adhere to a log-normal distribution influenced by various factors. Furthermore, it was found that firm size growth aligns with Gibrat's Law, whereas profitability does not. This suggests that the relationship between firm size and profitability may stem from their fundamentally different processes. Additionally, the research provides evidence that the mechanisms generating firm size have evolved over time, as well as indications that the processes influencing profitability have also changed. Overall, these findings illustrate that the connection between firm structure and profitability can fluctuate over time due to shifts in their distinct underlying mechanisms. Keywords: Firm Size Distribution, Profitability Distribution.",
        "ori-fast-z-score": -1.0834726777719228,
        "water-fast-z-score": 5.019960159204453,
        "rewrite-fast-z-score": 0.13018891098082389
    },
    {
        "original_text": "We study the ground state properties of spin-1/2 antiferromagnetic Heisenberg model on square (SQ) and triangular lattices (TL). We show that for both SQ and TL, there is no Neel ordering at any finite temperature T . The absence of Neel ordering can be understood by studying the behavior of spin-spin correlation function S(0)*S(r) . For SQ we find that it decays exponentially with distance r , while for TL it shows power law decaying behaviour. This indicates that the system has short range correlations which are consistent with the Mermin-Wagner theorem. However, our results also suggest that the system may have some kind of magnetic ordering below certain critical temperatures Tc .\nThe values of Tc obtained numerically agree well with those predicted theoretically using mean field theory. In addition to this, we also calculate the specific heat Cv as a function of temperature T .",
        "watermark_text": "We research the ground state properties of spin - 1 / 2 antiferromagnetic Heisenberg model on square ( SQ ) and triangular lattices ( TL ) . We see that for both SQ and TL , there is no Neel ordering at any polynomial heat T .The absence of Neel ordering can be understood by examining the activity of spin - spinning correlation function S ( 0 ) * S ( r ) . For SQ we find that it decays exponentially with distance r , while for TL it displays power law decaying behaviour .This implies that the system has small range correlations which are compatible with the Mermin - Wagner theorem . However , our findings also suggest that the system might have some kind of magnetic ordering below certain significant conditions Tc .The values of Tc obtained numerically agree well with those predicted theoretically using mean field principles . In addition to this , we also predict the specific warmth Cv as a function of temperature T .",
        "rewrite_text": "We investigate the ground state properties of the spin-1/2 antiferromagnetic Heisenberg model on square (SQ) and triangular lattices (TL). Our analysis reveals that neither lattice exhibits Néel ordering at any finite temperature \\( T \\). The lack of Néel ordering is elucidated by studying the spin-spin correlation function \\( S(0) \\cdot S(r) \\). For the SQ lattice, we observe that this correlation function decays exponentially with distance \\( r \\), while for the TL lattice, it exhibits power-law decay. This indicates that the system features short-range correlations that align with the Mermin-Wagner theorem. Nonetheless, our results also imply the possibility of some form of magnetic ordering occurring below a certain critical temperature \\( T_c \\). The numerically determined values of \\( T_c \\) are in good agreement with theoretical predictions made using mean-field theory. Additionally, we predict the specific heat \\( C_v \\) as a function of temperature \\( T \\).",
        "ori-fast-z-score": 0.1259881576697424,
        "water-fast-z-score": 4.913538149119954,
        "rewrite-fast-z-score": -1.7801724872907798
    },
    {
        "original_text": "We present new results on the color magnitude distribution (CMD) of field galaxies in the redshift range 0<z<3, based on deep optical imaging data obtained with Subaru/Suprime-Cam at the prime focus telescope of National Astronomical Observatory of Japan. We use two different samples for our analysis; one is a sample of about 12000 spectroscopically confirmed galaxies selected from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7), which covers an area of ~10deg2 around the North Galactic Pole (NGP). The other is a sample of about 10000 photometrically selected galaxies over an area of ~30deg2 centered on the Hubble Deep Field South (HDF-S).\nThe CMD shows that there are three distinct galaxy populations in terms of their rest-frame colors as well as luminosities. These are: red-sequence early-type galaxies, green valley late-type galaxies, and blue cloud star-forming galaxies. In addition we find that the fraction of blue cloud galaxies increases towards higher redshifts up to z~2.5-3.0, while it decreases again beyond this epoch. This trend can be explained by the fact that most massive galaxies have already formed stars before z~3, so they become redder than less-massive ones afterwards; therefore more massive galaxies dominate the red-sequence population at high-z. On the other hand, less-massive galaxies continue forming stars until today, resulting in larger fractions of blue cloud galaxies at lower redshifts.",
        "watermark_text": "We report new data on the color magnitude distribution ( CMD ) of field galaxies in the redshift region 0 < z < 3 , using on soft imaging scanning data acquired with Subaru / Suprime - Cam at the prime focus telescope of National Astronomical Observatory of Japan . We use two different samples for our analysis ; one is a sample of about 12000 spectroscopically confirmed galaxies drawn from the Sloan Digital Sky Survey Data Release 7 ( SDSS DR7 ) , which covers an area of ~ 10deg2 around the North Galactic Pole ( NGP ) .The other is a sample of about 10000 photometrically selected galaxies over an area of ~ 30deg2 centered on the Hubble Deep Field South ( HDF - S ) . The CMD indicates that there are three separate universe groups in terms of their rest - frame colors as well as luminosities .These are : green - sequence earliest - class stars , green valley late - class objects , and green cloud star - creating galaxies . In addition we find that the fraction of blue forest objects increases towards higher redshifts up to z ~ 2 . 5 - 3 . 0 , while it reduces again beyond this epoch .This trend can be explained by the fact that most giant galaxies have already formed stars before z ~ 3 , so they become redder than less - massive ones afterwards ; therefore more massive galaxies represent the red - sequence population at high - z . On the other hand , less - massive galaxies continue forming stars until today , resulting in larger fractions of blue cloud galaxies at lower redshifts .",
        "rewrite_text": "We present new findings on the color magnitude distribution (CMD) of field galaxies within the redshift range of 0 < z < 3. This analysis is based on soft imaging data obtained from the Subaru/Suprime-Cam located at the prime focus of the National Astronomical Observatory of Japan. Our study utilizes two distinct samples: the first consists of approximately 12,000 spectroscopically confirmed galaxies from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7), which covers an area of around 10 square degrees near the North Galactic Pole (NGP). The second sample includes about 10,000 photometrically selected galaxies spread over an area of roughly 30 square degrees centered on the Hubble Deep Field South (HDF-S). The CMD reveals three distinct groups within the universe, categorized by their rest-frame colors and luminosities: the green-sequence of early-type stars, the green valley of late-type objects, and the green cloud of star-forming galaxies. Additionally, we observe that the proportion of blue forest objects increases with higher redshifts, peaking around z ~ 2.5 - 3.0, before declining beyond that point. This pattern can be accounted for by the fact that most massive galaxies have already formed their stars by z ~ 3, leading to their redder appearance compared to less massive galaxies. Consequently, these more massive galaxies constitute the red-sequence population at high redshifts. Conversely, less massive galaxies continue to form stars into the present day, resulting in a greater prevalence of blue cloud galaxies at lower redshifts.",
        "ori-fast-z-score": 2.416841222614159,
        "water-fast-z-score": 7.057176370033344,
        "rewrite-fast-z-score": 1.8569533817705188
    },
    {
        "original_text": "We report on the detection of the N VII hyperfine line at 1238 Å in the X-ray spectrum of the Galactic center source Sgr A* with Chandra and XMM-Newton observations. We find that this emission is consistent with gas having temperatures between 1 million K to 2 million K, densities between 10^6 cm^{-3} to 10^7 cm^{-3}, and column density of about 5 x 10^{20} cm^{-2}. This temperature range is higher than previous estimates based on other lines observed by Chandra or XMM-Newton. Our results are also inconsistent with models where the gas has been photoionized by UV radiation from nearby stars. These findings suggest that there may be an additional heating mechanism present near Sgr A* besides photoionization. In addition we detect absorption features associated with the same ion which could arise either due to foreground material along our line-of-sight towards Sgr A* or intrinsic to the accretion flow onto Sgr A* itself.",
        "watermark_text": "We report on the observation of the N VII hyperfine line at 1238 Å in the X - ray spectrum of the Galactic center source Sgr A * with Chandra and XMM - Newton images . We see that this emission is compatible with gas having altitudes between 1 million K to 2 million K , densities between 10 ^ 6 cm ^ { - 3 } to 10 ^ 7 cm ^ { - 3 } , and column density of about 5 x 10 ^ { 20 } cm ^ { - 2 } .This temperature range is higher than prior estimates based on other lines observed by Chandra or XMM - Newton . Our results are also inconsistent with models where the gas has been photoionized by UV rays from nearby galaxies .These studies propose that there may be an additional thermal mechanism present near Sgr A * besides photoionization . In addition we find absorption properties associated with the same particle which could occur either due to foreground material along our line - of - view towards Sgr A * or intrinsic to the accretion flow onto Sgr A * itself .",
        "rewrite_text": "We report the detection of the N VII hyperfine line at 1238 Å in the X-ray spectrum of the Galactic center source Sgr A* using images from Chandra and XMM-Newton. This emission appears to be consistent with gas temperatures ranging from 1 million K to 2 million K, densities between 10^6 cm^(-3) and 10^7 cm^(-3), and a column density of approximately 5 x 10^20 cm^(-2). This temperature range exceeds previous estimates derived from other lines observed by Chandra and XMM-Newton. Furthermore, our findings contradict models that suggest the gas has been photoionized by UV radiation from nearby galaxies, indicating the possible presence of an additional thermal mechanism near Sgr A* apart from photoionization. Additionally, we observe absorption characteristics linked to the same particles, which may arise from foreground material along our line of sight to Sgr A* or from the intrinsic accretion flow onto Sgr A* itself.",
        "ori-fast-z-score": -0.39056673294247163,
        "water-fast-z-score": 4.370956778314644,
        "rewrite-fast-z-score": 0.13018891098082389
    },
    {
        "original_text": "We present an algorithm for decomposing functions defined over quadratic surfaces in three dimensions, such as the surface of a sphere or ellipsoid, into multipole expansions. The method is based on representing the function using spherical harmonics and then expanding each term in this representation into a sum of products of Legendre polynomials with coefficients that are determined by solving a linear system of equations. We demonstrate our approach through several examples including computing the electrostatic potential due to point charges located at various positions around a dielectric sphere immersed in water. Our results show that we can accurately compute the electrostatic potential even when there are many sources distributed throughout space. This work was supported by NSF grant DMS-0852653 (CAREER). Spherical harmonic decomposition has been used extensively in computational physics applications ranging from quantum chemistry  1  , molecular dynamics  2  , and plasma simulations  3  . In these applications, one often needs to represent a given function f(r) defined over some domain Ω in terms of its expansion coefficients C lm :",
        "watermark_text": "We present an algorithm for decomposing functions defined over quadratic spheres in three dimensions , such as the surface of a sphere or ellipsoid , into multipole expansions . The method is based on representing the function using spherical harmonics and then increasing each term in this representation into a sum of products of Legendre polynomials with coefficients that are decided by solving a linear network of equations .We showed our approach through several examples namely calculation the electrostatic potential due to point charges situated at numerous positions around a dielectric sphere immersed in water . Our results show that we can accurately compute the electrostatic potential even when there are many sources distributed throughout space .This work was supported by NSF grant DMS - 0852653 ( CAREER ) . Spherical harmonic decomposition has been used extensively in computational physics applications ranging from quantum chemistry 1 , molecular dynamics 2 , and plasma simulations 3 .In these uses , one frequently needs to depict a given function f ( r ) established over some domain Ω in terms of its expansion function C lm :",
        "rewrite_text": "We introduce an algorithm for decomposing functions defined over quadratic surfaces in three-dimensional space, such as the surfaces of spheres and ellipsoids, into multipole expansions. This method involves presenting the function using spherical harmonics and transforming each term in this representation into a sum of products of Legendre polynomials, with coefficients determined by solving a system of linear equations. We demonstrated our approach through various examples, including the calculation of the electrostatic potential created by point charges positioned at multiple locations around a dielectric sphere submerged in water. Our results indicate that we can accurately calculate the electrostatic potential, even with many sources distributed throughout the space. This research received support from NSF grant DMS-0852653 (CAREER). Spherical harmonic decomposition has been widely used in computational physics applications, including quantum chemistry, molecular dynamics, and plasma simulations. In these contexts, there is often a need to express a given function f(r) defined over a specific domain Ω in terms of its expansion function C_lm.",
        "ori-fast-z-score": 0.562543950463012,
        "water-fast-z-score": 3.2627549126854696,
        "rewrite-fast-z-score": -0.2182178902359924
    },
    {
        "original_text": "We present an analysis of the observed distribution of the magnetic field geometries for stars across the upper main sequence (UMS). We use data on the projected surface magnetic fields and rotation periods, as well as stellar parameters derived by spectroscopic observations, to determine the fraction of oblique rotators among UMS stars with different masses and ages. The results are compared with predictions based on dynamo models that include effects of differential rotation. \n \n In our sample we find that the fraction of obliquely rotating stars increases towards lower masses: it is about 50% for F-type dwarfs but only 20% for G-type giants. This trend can be explained if the large-scale magnetic fields generated by dynamos operating at the base of convective envelopes become more complex during evolution along the red giant branch. Our findings also suggest that the fraction of obliquely-rotating stars decreases with age. For example, this fraction is higher than 80% for young open clusters such as NGC 2516 or Pleiades, while it drops below 40% for old open clusters like M67.",
        "watermark_text": "We present an assessment of the seen distribution of the magnetic force geometries for stars across the higher major sequence ( UMS ) . We use data on the projected surface magnetic fields and rotation periods , as also as stellar characteristics obtained by spectroscopic observations , to estimate the fraction of oblique rotators among UMS stars with various masses and periods .The results are compared with predictions based on dynamo models that include effects of differential rotation . In our sample we find that the fraction of obliquely rotating stars increases towards lesser masses : it is about 50 % for F - class dwarfs but only 20 % for G - class giants .This trend can be understood if the huge - scale magnetic waves generated by dynamos working at the base of convective envelopes get more sophisticated during progression along the red giant branch . Our findings also suggest that the fraction of obliquely - spinning stellar reduces with age .For instance , this amount is higher than 80 % for young open nuclei such as NGC 2516 or Pleiades , while it drops below 40 % for old close galaxies like M67 .",
        "rewrite_text": "We provide an evaluation of the observed distribution of magnetic force geometries in stars along the upper main sequence (UMS). Utilizing data on projected surface magnetic fields and rotation periods, along with stellar properties obtained through spectroscopic observations, we estimate the proportion of oblique rotators among UMS stars with varying masses and rotation periods. Our findings are compared with predictions derived from dynamo models that account for the effects of differential rotation. Our analysis reveals that the fraction of obliquely rotating stars tends to increase with decreasing mass: approximately 50% for F-class dwarfs and around 20% for G-class giants. This trend suggests that large-scale magnetic waves produced by dynamos at the base of convective envelopes become more complex as stars evolve along the red giant branch. Additionally, our results indicate that the prevalence of oblique rotators decreases with age; for instance, this fraction exceeds 80% in younger open clusters like NGC 2516 and the Pleiades, while it falls below 40% in older clusters such as M67.",
        "ori-fast-z-score": -1.091089451179962,
        "water-fast-z-score": 4.800793585191832,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We present new near-infrared (NIR) observations and analysis of the young binary system UZ Tau E, which is composed of two T Tauri stars with masses ~0.8 M⊙ separated by 0. ′′ 4. The NIR light curves show periodic variations that are consistent with ellipsoidal modulation due to tidal distortion of each star s photosphere as it orbits its companion. We also find evidence for an additional component to this variability; we interpret these data as indicating that one or both components of the binary undergoes periodic episodes of enhanced mass loss at periastron passage. This interpretation is supported by our detection of excess emission in the K-band spectrum during periods when the photometric flux decreases. Our results suggest that the circumstellar disks around each member of the binary have been truncated by their mutual gravitational interaction. In addition, we detect significant changes in the shape of the Hα line profile over time scales of days to weeks. These changes can be explained if there exists a region of high density gas surrounding the binary orbiting on timescales similar to those observed in the NIR light curve.",
        "watermark_text": "We report new near - infrared ( NIR ) observations and investigation of the small binary system UZ Tau E , which is composed of two T Tauri stars with masses ~ 0 . 8 [UNK] connected by 0 . ′ ′ 4 .The NIR light curves show continuous shifts that are compatible with ellipsoidal modulation owing to tidal manipulation of each star s photosphere as it orbits its companion . We additionally find proof for an additional element to this variability ; we view these information as indicating that one or both components of the binary undergoes frequent bouts of enhanced mass loss at periastron passage .This interpretation is backed by our screening of excess emission in the K - band spectrum during moments when the photometric flux drops . Our results propose that the circumstellar disks around each member of the binary have been truncated by their mutual gravitational interaction .In addition , we perceive considerable changes in the shape of the Hα line profile over time ranges of weeks to weeks . These changes can be described if there exists a region of high density gas covering the binary orbiting on timescales similar to those observed in the NIR light curve .",
        "rewrite_text": "We present new near-infrared (NIR) observations and analysis of the small binary system UZ Tau E, which consists of two T Tauri stars with masses of approximately 0.8 M⊙ that are separated by 0.4 arcseconds. The NIR light curves reveal continuous variations consistent with ellipsoidal modulation caused by tidal interactions affecting each star's photosphere as it orbits its companion. Additionally, we provide evidence for another component to this variability, suggesting that one or both stars in the binary experience episodes of increased mass loss during periastron passage. This interpretation is supported by our detection of excess emission in the K-band spectrum at times when the photometric flux decreases. Our findings indicate that the circumstellar disks around each star may have been truncated due to their mutual gravitational influence. Furthermore, we observe significant changes in the shape of the Hα line profile over periods of weeks. These variations can be explained by the presence of a region of high-density gas orbiting the binary, with timescales similar to those seen in the NIR light curves.",
        "ori-fast-z-score": -0.32539568672798425,
        "water-fast-z-score": 5.378448739494827,
        "rewrite-fast-z-score": 0.3375263702778072
    },
    {
        "original_text": "The problem is to estimate the number of independent measurements in an experiment, given that some statistical properties are known for each measurement. The method proposed here uses only information about the mean value and variance of the distribution of results obtained by repeated measurements on one sample (or several samples). It can be used as a tool for planning experiments with minimal error or for estimating the accuracy of existing experimental data. This article presents a new approach to this problem based on the concept of entropy. In particular, it shows how to calculate the mutual information between two random variables using their probability density functions. A numerical example illustrates the application of these methods. \n \n Keywords: Redundancy estimation, Entropy, Mutual Information, Experiment Planning \n \n 1 Introduction \n \n When designing an experiment, we need to know what kind of precision our measuring instrument will give us. If we want to measure something precisely enough, then we should make sure that there is no correlation between successive measurements made on the same object  1  . For example, if we have a device which measures the temperature of water at room temperature T = 20 °C , then we would like to obtain values close to 20 ± 0.1°C when repeating the measurement many times  2  .\n \nIn practice, however, such repeatability cannot always be achieved because of various factors affecting the measurement process  3  . Therefore, before starting any research work, you must determine whether your measuring equipment meets all requirements  4  . \n \n 2 Problem statement \n \n Let X be a continuous random variable describing the result of a single measurement performed under certain conditions  5  . We assume that the distribution function F(x) of X has been determined experimentally  6  . Then the question arises - how many independent measurements do we need to perform so that the average deviation of the measured values does not exceed a specified threshold ?",
        "watermark_text": "The question is to estimate the proportion of separate measurements in an observation , provided that some statistical characteristics are known for each measurement . The method adopted here uses only data about the mean value and variance of the distribution of findings obtained by repeated measurements on one sample ( or several experiments ) .It can be used as a technique for planning studies with minimal loss or for estimating the accuracy of older experimental evidence . This page presents a new approach to this question based on the idea of entropy .In particular , it displays how to estimate the mutual information between two random factors using their likelihood density functions . A numerical example illustrates the implementation of these schemes .Keywords : Redundancy estimation , Entropy , Mutual Information , Experiment Planning 1 Introduction When designing an test , we must to realize what sort of precision our measuring instrument will provide us . If we wish to measure something precisely enough , then we should make sure that there is no coupling between successive measurements made on the same object 1 .For instance , if we have a device which studies the temperature of water at room temperature T = 20 °C , then we may wish to obtain readings nearly to 20 ± 0 . 1°C when repeating the observation many times 2 . In practice , however , such repeatability cannot often be obtained because of several variables affecting the observation technique 3 .Therefore , before beginning any study work , you must know whether your assessment equipment meets all requirements 4 . 2 Problem statement Let X be a consistent random variable describing the result of a single test conducted under certain conditions 5 .We assume that the distribution relation F ( x ) of X has been determined experimentally 6 . Then the question arises - how many independent surveys do we require to conduct so that the average deviation of the tested values does not reach a specified threshold ?",
        "rewrite_text": "The task at hand is to estimate the proportion of independent measurements within a given observation, given certain known statistical characteristics for each measurement. This approach relies solely on the mean and variance of the data obtained from repeated measurements of a single sample (or multiple experiments). It serves as a useful technique for planning studies with minimal loss and for evaluating the accuracy of existing experimental data. This document introduces a novel method based on the concept of entropy, specifically demonstrating how to estimate the mutual information between two random variables using their likelihood density functions. A numerical example is provided to illustrate the application of these methods.\n\n**Keywords:** Redundancy estimation, Entropy, Mutual Information, Experiment Planning\n\n**1. Introduction**  \nWhen designing a test, it is crucial to understand the precision provided by the measuring instrument. To achieve sufficiently accurate measurements, it is essential to ensure that successive measurements on the same object are independent. For example, if we are using a device to measure water temperature at room temperature (T = 20 °C), we would ideally obtain readings close to 20 ± 0.1 °C upon repeated observations. However, achieving such repeatability is often challenging due to various factors influencing the observation process. Therefore, it is important to verify that your measurement equipment meets all necessary criteria before commencing any study.\n\n**2. Problem Statement**  \nLet X be a consistent random variable representing the outcome of an individual test conducted under specified conditions. It is assumed that the distribution function F(x) of X has been empirically determined. The key question that arises is: how many independent measurements are required to ensure that the average deviation of the observed values remains below a predetermined threshold?",
        "ori-fast-z-score": -0.6620847108818944,
        "water-fast-z-score": 9.434707130066995,
        "rewrite-fast-z-score": 1.087114613009218
    },
    {
        "original_text": "We present an analysis of the logarithmic corrections to the leading order predictions for the electromagnetic form factor ratios, R = F2(q2)/F1(q2), and their dependence on the momentum transfer q2. We use the results obtained within the framework of the multipole expansion method (MEM). The MEM is based on the assumption that the proton can be represented as a superposition of three different charge distributions with definite angular momenta. In this approach we calculate the contributions coming from the lowest lying resonances, i.e., S11(1650), P11(1710), D13(1520), F15(1680), G17(1880), H19(2230), and also take into account the effects due to the pion cloud surrounding these states. Our numerical calculations show that at low values of the momentum transfer, q2 < 1 GeV 2 , the contribution of the higher-order terms becomes significant.",
        "watermark_text": "We present an analysis of the logarithmic corrections to the main order predictions for the electromagnetic form factor ratios , R = F2 ( q2 ) / F1 ( q2 ) , and their dependence on the velocity transition q2 . We use the results derived within the framework of the multipole expansion method ( MEM ) .The MEM is based on the assumption that the proton can be described as a superposition of three different charge distributions with definite angular momenta . In this methodology we estimate the contributions come from the lowest lying resonances , i . e . , S11 ( 1650 ) , P11 ( 1710 ) , D13 ( 1520 ) , F15 ( 1680 ) , G17 ( 1880 ) , H19 ( 2230 ) , and also took into consideration the effects due to the pion bubble surrounding these states .Our numerical measurements show that at low values of the velocity transition , q2 < 1 GeV 2 , the contribution of the higher - order quantities becomes large .",
        "rewrite_text": "We provide an analysis of the logarithmic corrections to the leading-order predictions for the electromagnetic form factor ratios, R = F2(q²) / F1(q²), and their dependence on the transition momentum q². Our findings are based on results obtained through the multipole expansion method (MEM), which operates under the premise that the proton can be modeled as a combination of three distinct charge distributions with specific angular momenta. In this approach, we evaluate the contributions from the lowest-lying resonances, including S11(1650), P11(1710), D13(1520), F15(1680), G17(1880), and H19(2230), while also accounting for the effects of the pion bubble surrounding these states. Our numerical results indicate that at low transition momentum values, specifically for q² < 1 GeV², the contributions from higher-order terms become significant.",
        "ori-fast-z-score": -1.3608276348795434,
        "water-fast-z-score": 2.9938207967349952,
        "rewrite-fast-z-score": -2.0604084592303353
    },
    {
        "original_text": "The Finite Element (FE) model updating is an important step in the process of structural health monitoring and damage detection, which can be used to update FE models with experimental data for better prediction accuracy. In this study, response surface method was applied to solve the optimization problem associated with the FE model updating using modal test results as input information. The proposed approach has been successfully implemented on a cantilever beam structure subjected to static loadings. It shows that the updated FE model could provide more accurate predictions than those obtained by the original FE model. Keywords: finite element modeling, model updating, response surface method, modal testing, static loading. 1 Introduction Structural Health Monitoring (SHM), also known as Condition-Based Maintenance (CBM), aims at detecting damages or deterioration of structures through various sensing technologies such as vibration-based methods  1  . Among these techniques, Finite Element (FE)\nModeling plays an essential role since it provides numerical solutions to complex engineering problems  2  .\nHowever, due to uncertainties involved in material properties, boundary conditions, geometric imperfections etc., there are always discrepancies between theoretical predictions based on FE models and actual measurements  3  , especially when dealing with large scale civil infrastructures  4  . Therefore, it becomes necessary to update the FE models so that they can accurately predict the dynamic behavior of real structures  5  .\nIn recent years, many researchers have developed different approaches to perform FE model updating  6  -  8  . Generally speaking, most existing studies focus on two main aspects  9  : one is how to formulate the objective function; another is how to find optimal parameters within the feasible region. For example, some authors use frequency responses  10  , mode shapes  11  , natural frequencies  12  , or their combination  13  as the objective functions. Meanwhile, genetic algorithms  14  , simulated annealing  15  , particle swarm  16  , ant colony  17  , and other intelligent search strategies  18  were employed to minimize the objective functions.",
        "watermark_text": "The Finite Element ( FE ) model updating is an important process in the process of structural health monitoring and injury monitoring , which can be used to modify FE estimates with experimental evidence for better forecast accuracy . In this study , decision surface method was used to solve the optimization problem associated with the FE model updating use modal test outcomes as input data .The proposed approach has been successfully utilized on a cantilever beam construction subjected to static loadings . It demonstrates that the improved FE approach could give more accurate forecast than those achieved by the original FE approach .Keywords : finite element simulation , profile updating , decision surface method , modal testing , dynamic loading . 1 Introduction Structural Health Monitoring ( SHM ) , sometimes called as Condition - Based Maintenance ( CBM ) , seeks at detecting injuries or deterioration of structures through several sensing innovations such as vibration - based methods 1 .Among these disciplines , Finite Element ( FE ) Modeling serves an essential part since it gives quantitative solutions to complex engineering difficulties 2 . However , owing to uncertainties involved in material structures , boundary conditions , geometric imperfections etc . , there are always discrepancies between theoretical estimates based on FE models and actual measurements 3 , particularly when dealing with large scale civil infrastructures 4 .Therefore , it becomes necessary to modify the FE estimates so that they can accurately forecast the dynamic behavior of real buildings 5 . In recent years , various scientists have developed various approaches to conduct FE model updating 6 - 8 .Generally spoken , most existing studies emphasis on two principal areas 9 : one is how to formulate the objective function ; another is how to find optimal characteristics within the viable region . For instance , some writers employ frequency responses 10 , mode shapes 11 , natural intervals 12 , or their combination 13 as the objective functions .Meanwhile , biological strategies 14 , simulated annealing 15 , molecular swarm 16 , ant nest 17 , and other efficient hunt strategies 18 were utilized to minimize the objective functions .",
        "rewrite_text": "The process of updating Finite Element (FE) models is a critical component of structural health monitoring and damage assessment, allowing for the refinement of FE estimates using experimental data to enhance predictive accuracy. This study employs a decision surface method to tackle the optimization challenges related to FE model updating, utilizing modal test results as input. The proposed method has been effectively applied to a cantilever beam structure subjected to static loading, demonstrating that the updated FE models provide more precise predictions compared to the original FE models. \n\n**Keywords:** finite element simulation, model updating, decision surface method, modal testing, dynamic loading.\n\n**1 Introduction**\nStructural Health Monitoring (SHM), also known as Condition-Based Maintenance (CBM), aims to identify damage or degradation in structures through various sensing technologies, including vibration-based methods. Among these techniques, Finite Element (FE) Modeling plays a crucial role by offering quantitative solutions to complex engineering challenges. However, due to uncertainties related to material properties, boundary conditions, geometric imperfections, and other factors, discrepancies often arise between theoretical estimates derived from FE models and actual measurements, especially in large-scale civil infrastructure. Therefore, it is essential to adjust FE estimates to accurately reflect the dynamic behavior of real structures. In recent years, researchers have proposed various methodologies for performing FE model updating. Generally, most studies focus on two main aspects: the formulation of the objective function and the identification of optimal characteristics within the feasible region. For example, some researchers utilize frequency responses, mode shapes, natural frequencies, or combinations of these as objective functions. Simultaneously, techniques such as biological algorithms, simulated annealing, particle swarm optimization, ant colony optimization, and other effective search strategies have been employed to minimize these objective functions.",
        "ori-fast-z-score": -0.6324555320336759,
        "water-fast-z-score": 9.58522525608431,
        "rewrite-fast-z-score": -0.31426968052735443
    },
    {
        "original_text": "We present an alternative derivation of Einstein gravity, which does not use the axiom of choice and is based on the concept that topology can be hidden inside general relativity (GR). We show how to construct a set of local coordinates for any given spacetime point such that all points with the same coordinate values are connected by geodesics. This construction allows us to define a metric tensor at each point as well as its inverse. The resulting theory has exactly the same field equations as standard GR but it contains additional degrees of freedom corresponding to the number of disconnected components of the underlying space. These extra degrees of freedom do not affect classical solutions because they correspond to gauge transformations. However, we argue that these new degrees of freedom may play an important role when considering quantum effects. In particular, we discuss possible implications of our approach for black hole entropy calculations. Finally, we comment on some open problems related to this work.",
        "watermark_text": "We introduce an alternative derivation of Einstein relativity , which does not use the axiom of choice and is based on the idea that geometry can be hidden inside general relativity ( GR ) . We see how to build a setting of local coordinates for any certain spacetime point such that all points with the same coordinate parameters are connected by geodesics .This construction gives us to define a metric tensor at each point as well as its inverse . The resulting theory has precisely the same field equations as conventional GR but it contains additional degrees of liberty corresponding to the number of disconnected components of the underlying set .These added degrees of liberty do not alter classical solutions because they relate to gauge processes . However , we feel that these new degrees of liberty might play an important role when assessing quantum effects .In particular , we discuss possible possibilities of our approach for black hole entropy calculations . Finally , we comment on some open problems related to this research .",
        "rewrite_text": "We present a new derivation of Einstein's theory of relativity that avoids the axiom of choice and is predicated on the notion that geometry may be embedded within general relativity (GR). This approach allows us to establish a framework of local coordinates for any specific point in spacetime, ensuring that all points sharing the same coordinate values are interconnected by geodesics. Consequently, we can define a metric tensor at each point along with its inverse. The resulting framework yields field equations identical to those of traditional GR but introduces extra degrees of freedom that correspond to the number of disconnected components within the underlying set. These additional degrees of freedom do not impact classical solutions since they pertain to gauge processes. Nevertheless, we believe that they could be significant in evaluating quantum effects. In particular, we explore the implications of our method for calculating black hole entropy. Finally, we highlight several unresolved issues related to this research.",
        "ori-fast-z-score": -0.3333333333333333,
        "water-fast-z-score": 4.919349550499537,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "The reed is the key component in single-reed musical instruments, such as clarinets or saxophones. The dynamics of its motion are strongly influenced by the bore geometry and boundary conditions at both ends. In this work we present an approach to simulate the oscillations of a single reed instrument based on modal decomposition of the bore and reed dynamics. We show that it is possible to accurately reproduce the sound produced by a real clarinet using only one degree-of-freedom for each mode. This method can be used to study the influence of different parameters (such as mouthpiece diameter) on the acoustic response of the instrument without requiring expensive experimental measurements. It also allows us to investigate how changes in the design affect the performance of new prototypes. \n \n Keywords: Musical Instrument, Clarinet, Sound Generation, Modeling, Simulation, Acoustics, Vibration Analysis, Modal Analysis, Finite Element Method",
        "watermark_text": "The reed is the key component in single - reed musical instruments , such as clarinets or saxophones . The structures of its motion are strongly dictated by the bore pattern and boundary pressures at both ends .In this study we present an approach to simulate the oscillations of a single reed instrument relying on modal decomposition of the bore and reed dynamics . We see that it is easy to correctly reproduce the music created by a real clarinet using only one degree - of - independence for each mode .This method can be used to study the impact of different variables ( such as mouthpiece diameter ) on the acoustic response of the instrument without using expensive experimental surveys . It additionally lets us to examine how differences in the model affect the performance of new prototypes .Keywords: Musical Instrument, Clarinet, Sound Generation, Modeling, Simulation, Acoustics, Vibration Analysis, Modal Analysis, Finite Element Method",
        "rewrite_text": "The reed plays a crucial role in single-reed instruments, including clarinets and saxophones. Its motion is significantly influenced by the bore shape and the pressure conditions at both ends. In this study, we introduce a method for simulating the oscillations of single-reed instruments through modal decomposition of the dynamics of both the bore and the reed. Our findings demonstrate that using a single degree of freedom for each mode allows for accurate reproduction of the sound produced by a real clarinet. This approach enables the exploration of various factors, such as mouthpiece diameter, on the instrument's acoustic response without the need for costly experimental investigations. Moreover, it provides insights into how different model variations impact the performance of new prototypes. \n\nKeywords: Musical Instrument, Clarinet, Sound Generation, Modeling, Simulation, Acoustics, Vibration Analysis, Modal Analysis, Finite Element Method.",
        "ori-fast-z-score": -1.5756771943166705,
        "water-fast-z-score": 4.727031582950012,
        "rewrite-fast-z-score": -1.171700198827415
    },
    {
        "original_text": "We report on simultaneous observations in the X-ray and radio bands made with Chandra, RXTE/PCA, Swift/XRT, and ATCA during an outburst of the transient magnetar XTE J 18 10-197 . The source was detected at all wavelengths except for optical. We find that its broadband spectral energy distribution is consistent with a blackbody plus power-law model modified by interstellar absorption. In addition to this component we detect a soft excess below 1 keV which can be described as either emission lines or a second thermal component. This soft excess has been observed previously in other magnetars but not always simultaneously across different wavebands. Our results show that the hard X-ray flux increased rapidly after the onset of the outburst while the radio flux remained constant until it began decaying about two weeks later. After correcting for interstellar absorption we find no evidence for significant changes in the temperature of the emitting region between the start and end of our campaign.",
        "watermark_text": "We report on concurrent observations in the X - ray and radio bands done with Chandra , RXTE / PCA , Swift / XRT , and ATCA during an outburst of the transient magnetar XTE J 18 10 - 197 . The source was seen at all wavelengths except for optical .We see that its broadband spectral power distribution is compatible with a blackbody plus energy - law theory improved by interstellar absorption . In addition to this product we locate a soft excess below 1 keV which can be described as either emission lines or a second thermal component .This soft excess has been observed previously in other magnetars but not always concurrently across different wavebands . Our results show that the hard X - ray flux increased rapidly after the beginning of the outburst while the radio flux remained constant until it began decaying about two weeks afterward .After correcting for interstellar absorption we find no evidence for significant variations in the temperature of the emitting area between the start and end of our expedition .",
        "rewrite_text": "We present concurrent observations in the X-ray and radio wavelengths using Chandra, RXTE/PCA, Swift/XRT, and ATCA during an outburst of the transient magnetar XTE J1810-197. The source was detected across all wavelengths, except in the optical range. Our analysis indicates that its broadband spectral power distribution is consistent with a model comprising a blackbody and energy-law theory, modified by interstellar absorption. Additionally, we identify a soft excess feature below 1 keV, which may be characterized as either emission lines or a secondary thermal component. This soft excess has been observed in other magnetars previously, though not always concurrently across multiple wavebands. Our findings reveal that the hard X-ray flux increased rapidly following the onset of the outburst, while the radio flux remained stable until it started to decline approximately two weeks later. After accounting for interstellar absorption, we found no significant variations in the temperature of the emitting region from the beginning to the end of our observations.",
        "ori-fast-z-score": 1.75,
        "water-fast-z-score": 6.25,
        "rewrite-fast-z-score": 2.0175288189295504
    },
    {
        "original_text": "The National Institutes of Health (NIH) is the largest funder of biomedical research in the United States, but it also supports non-biomedical research through its extramural program.  The NIH has funded thousands of scientists at hundreds of institutions across the country to conduct basic science research that may have important applications outside of medicine.   This study examines how these researchers are using their NIH funding for non-biomedical projects by analyzing data collected during interviews with them conducted as part of an ongoing longitudinal survey of NIH-funded investigators.  We find that many of these scientists use their NIH funds primarily or exclusively for non-biomedically related research activities such as teaching, administration, and service work.  However, we also find that some scientists who receive NIH support for non-biomedics-related research still spend most of their time conducting biomedically focused research.  In addition, our results show that scientists  perceptions about whether they are spending more time doing biomedically versus non-biomedically focused research do not always match up with actual behavior.",
        "watermark_text": "The National Institutes of Health ( NIH ) is the greatest funder of biomedical research in the United States , but it also supports non - biomedical research through its extramural program . The NIH has funded thousands of research at hundreds of organizations across the nation to conduct basic science research that might have important use outside of medicine .This study examines how these investigators are using their NIH funding for non - biomedical projects by analyzing data derived during surveys with them conducted as part of an continuing longitudinal survey of NIH - financed researchers . We see that several of these investigators use their NIH grants mainly or mainly for non - biomedically relevant academic operations such as teaching , administration , and service work .However , we also find that some scientists who receive NIH backing for non - biomedics - specific study still spend most of their hours pursuing biomedically focused research . In addition , our findings show that scientists perceptions about whether they are spent more work doing biomedically versus non - biomedically focused research do not always match up with actual behavior .",
        "rewrite_text": "The National Institutes of Health (NIH) is the largest funder of biomedical research in the United States, but it also provides support for non-biomedical research through its extramural program. The NIH has financed numerous research projects at various organizations nationwide to advance basic science that may have significant applications beyond medicine. This study explores how these researchers utilize their NIH funding for non-biomedical initiatives by analyzing data collected from surveys conducted as part of a continuing longitudinal study of NIH-funded researchers. Our analysis reveals that many of these investigators primarily use their NIH grants for academic activities not directly related to biomedicine, such as teaching, administration, and service work. However, we also observe that some scientists who receive NIH funding for non-biomedical research still dedicate the majority of their time to projects focused on biomedical issues. Additionally, our findings indicate that scientists’ perceptions of whether they are spending more time on biomedical versus non-biomedical research do not always align with their actual activities.",
        "ori-fast-z-score": 2.0124611797498106,
        "water-fast-z-score": 7.888888888888889,
        "rewrite-fast-z-score": 0.8944271909999159
    },
    {
        "original_text": "The collision between the Milky Way and its nearest neighbor, M31 (Andromeda), is predicted to occur in about 4 billion years.  This will be one of the most spectacular events ever witnessed by humans.   In this talk I will describe how we can use observations made with telescopes on Earth as well as space-based observatories such as Hubble Space Telescope to study these collisions and learn more about dark matter, galaxies, stars, black holes, and other cosmic phenomena that are part of our universe. I will also discuss some of my research projects related to studying galaxy mergers using data obtained at the W.M. Keck Observatory located on Mauna Kea, Hawaii. Finally, I ll share what it was like for me to work there during my summer internship last year. Keywords: Dark Matter, Galaxy merger, Black Hole, Cosmic Evolution, Cosmology, Astrophysics",
        "watermark_text": "The interaction between the Milky Way and its closest neighbor , M31 ( Andromeda ) , is predicted to event in about 4 billion years . This will be one of the most dramatic events ever experienced by humans .In this talk I will explain how we can using observations made with telescopes on Earth as well as space - based observatories such as Hubble Space Telescope to study these collisions and learn more about black material , galaxies , stars , white holes , and other cosmic phenomena that are part of our universe . I will also discuss some of my research projects related to researching star mergers using data received at the W . M .Keck Observatory located on Mauna Kea , Hawaii . Finally , I ll share what it was like for me to work there during my summer apprenticeship last year .Keywords : Dark Matter , Galaxy merger , Black Hole , Cosmic Evolution , Cosmology , Astrophysics",
        "rewrite_text": "The Milky Way is set to collide with its closest neighbor, M31 (Andromeda), in approximately 4 billion years—a cataclysmic event that will be unprecedented in human history. In this presentation, I will discuss how we can utilize observations from both terrestrial telescopes and space-based observatories, like the Hubble Space Telescope, to investigate these cosmic collisions. This research will enhance our understanding of dark matter, galaxies, stars, black holes, and other cosmic phenomena within our universe. Additionally, I will share insights from my research on star mergers, which I conducted using data collected at the W. M. Keck Observatory on Mauna Kea, Hawaii. Lastly, I will recount my experiences during my summer apprenticeship at the observatory last year.  \nKeywords: Dark Matter, Galaxy Merger, Black Hole, Cosmic Evolution, Cosmology, Astrophysics.",
        "ori-fast-z-score": 0.848528137423857,
        "water-fast-z-score": 4.808326112068523,
        "rewrite-fast-z-score": 1.179535649239177
    },
    {
        "original_text": "We study the incoherent transport properties of a strongly correlated electron system, namely the periodic Anderson model (PAM) with strong hybridization between conduction and localized electrons. We show that this PAM can be mapped onto an effective spinless fermion model which is equivalent to a disordered Fermi gas at low temperatures. The resulting density of states exhibits a pseudogap structure near the chemical potential. In addition we find that the resistivity shows a linear temperature dependence below some characteristic temperature T*. This behavior is consistent with recent experiments on heavy-fermion compounds such as Yb$_{1}$-xYb$x$Cu$_2$Si$2$O$_{7-x}$. Finally, we discuss how our results are related to previous theoretical work based on the dynamical mean-field theory. PACS numbers: 71.27.+a, 72.25.+f, 74.78.+h",
        "watermark_text": "We research the incoherent transport properties of a strongly interacting particle system , particularly the periodic Anderson model ( PAM ) with strong hybridization between conduction and localized electrons . We see that this PAM can be mapped onto an efficient spinless fermion theory which is analogous to a disordered Fermi plasma at low temperatures .The resulting concentration of states shows a pseudogap structure near the chemical potential . In addition we find that the resistivity displays a linear temperature dependence below some characteristic temperature T * .This phenomenon is compatible with recent experiments on heavy - fermion compounds such as Yb $ _ { 1 } $ - xYb $ x $ Cu $ _ 2 $ Si $ 2 $ O $ _ { 7 - x } $ . Finally , we talk how our findings are related to previous conceptual research based on the dynamical mean - field model .PACS codes : 71 . 27 . + a , 72 . 25 . + f , 74 . 78 . + h",
        "rewrite_text": "We investigate the incoherent transport properties of a strongly interacting particle system, specifically focusing on the periodic Anderson model (PAM) that exhibits significant hybridization between conduction electrons and localized states. Our findings reveal that this PAM can be effectively transformed into a spinless fermion theory, which resembles a disordered Fermi plasma at low temperatures. The density of states obtained displays a pseudogap structure around the chemical potential. Furthermore, we observe that the resistivity exhibits a linear dependence on temperature below a certain characteristic temperature, T*. This behavior aligns well with recent experimental observations in heavy-fermion systems such as Yb$_{1-x}$Yb$_{x}$Cu$_{2}$Si$_{2}$O$_{7-x}$. Lastly, we address the relationship of our results to earlier theoretical work conducted using the dynamical mean-field model. PACS codes: 71.27.+a, 72.25.+f, 74.78.+h",
        "ori-fast-z-score": -0.39735970711951313,
        "water-fast-z-score": 4.900769721140662,
        "rewrite-fast-z-score": 2.75
    },
    {
        "original_text": "We present new high resolution (R = λ/Δλ ~ 20,000) far-ultraviolet spectra obtained with the Far Ultraviolet Spectroscopic Explorer (FUSE), as well as archival Hubble Space Telescope (HST) data for the hot white dwarf central star in the planetary nebula Sh2-216. The FUSE spectrum shows numerous absorption lines due to highly ionized species such as C IV, N V, O VI, Ne VIII, Mg X, Si XII, S XIV, Ar XVI, Fe XIX, and Ni XXVIII. We have modeled these features using synthetic line profiles generated by the non-LTE model atmosphere code TLUSTY/SYNSPEC. Our best-fit models indicate that this star has an effective temperature T eff = 120,000 K, surface gravity log g = 8.0, mass M = 0.6M☉ , radius R = 0.01R☉ , and is surrounded by a shell of material with density n(He II)/n(He I) = 1.5 x 10-3 .",
        "watermark_text": "We use new high resolution ( R = λ / Δλ ~ 20 , 000 ) far - ultraviolet spectra obtained with the Far Ultraviolet Spectroscopic Explorer ( FUSE ) , as well as archival Hubble Space Telescope ( HST ) statistics for the cool white dwarf central star in the planetary nebula Sh2 - 216 . The FUSE spectrum displays several absorption patterns due to strongly ionized species such as C IV , N V , O VI , Ne VIII , Mg X , Si XII , S XIV , Ar XVI , Fe XIX , and Ni XXVIII .We have analyzed these characteristics utilizing artificial line profiles generated by the non - LTE model atmosphere code TLUSTY / SYNSPEC . Our best - fitting models suggest that this star has an effective heat T eff = 120 , 000 K , surface gravity log f = 8 . 0 , mass M = 0 . 6M☉ , diameter R = 0 . 01R☉ , and is enclosed by a shell of material with volume n ( He II ) / n ( He I ) = 1 . 5 x 10 - 3 .",
        "rewrite_text": "We analyze new high-resolution far-ultraviolet spectra (R = λ / Δλ ~ 20,000) obtained from the Far Ultraviolet Spectroscopic Explorer (FUSE), along with archival data from the Hubble Space Telescope (HST), for the cool white dwarf central star in the planetary nebula Sh2-216. The FUSE spectrum exhibits various absorption features resulting from highly ionized species, including C IV, N V, O VI, Ne VIII, Mg X, Si XII, S XIV, Ar XVI, Fe XIX, and Ni XXVIII. To interpret these features, we utilized artificial line profiles generated by the non-LTE model atmosphere code TLUSTY/SYNSPEC. Our best-fitting models indicate that this star has an effective temperature (T_eff) of 120,000 K, a surface gravity (log g) of 8.0, a mass (M) of 0.6 M☉, a radius (R) of 0.01 R☉, and is surrounded by a shell of material with a volume ratio of n(He II) / n(He I) = 1.5 x 10^-3.",
        "ori-fast-z-score": -1.5109662034355793,
        "water-fast-z-score": 3.6055512754639896,
        "rewrite-fast-z-score": 0.5443310539518174
    },
    {
        "original_text": "We present deep radio observations at 1.4 GHz with the VLA towards two TeV gamma-ray emitting regions, one associated to the open cluster Cyg OB2 #8 (HESS J1640-465) and another located near the massive star WR 25 (HESS J1641-463). The new data reveal extended emission around both TeV sources which is not detected by previous surveys. We discuss possible scenarios for this emission based on our results as well as those obtained recently by other authors. In particular we propose that the observed structures are due to synchrotron radiation produced by relativistic electrons accelerated in shocks driven by stellar winds interacting within these clusters. This scenario would also explain why no X-ray counterparts have been found so far despite deep searches carried out with Chandra and XMM-Newton telescopes. Finally, we estimate the magnetic field strength required to produce such emission using standard models for particle acceleration in colliding wind binaries. \nIntroduction\n\nThe Cygnus OB2 association contains more than 100 OB stars distributed over an area of about 50 square degrees centered at l = 80°and b = 1° (  Fig.   1a ). It has been suggested that many of them could be members of binary systems or even multiple systems (e.g., Knödlseder 2000; Wright et al. 2010) . These objects can drive powerful winds into their surroundings creating strong shocks where particles may be accelerated up to very high energies. If some of these particles escape from the shock fronts they will interact with photons coming from the surrounding interstellar medium producing high-energy electromagnetic radiation detectable across most of the electromagnetic spectrum including the TeV range. \n \n Several studies suggest that several of the known TeV sources in the sky might be related to young open clusters like Cyg OB2 (see e.g., Aharonian et al. 2005a ,b, 2007a . However, only few of these associations have been confirmed through multi-wavelength campaigns involving optical/infrared imaging, spectroscopy and/or radio continuum observations (see e.g. , Reimer & Böttcher 2006 , Castro-Tirado et al",
        "watermark_text": "We report deep radio observations at 1 . 4 GHz with the VLA towards two TeV gamma - ray emitting regions , one related to the open object Cyg OB2 # 8 ( HESS J1640 - 465 ) and another situated near the giant star WR 25 ( HESS J1641 - 463 ) . The revised data reveal extended emitted around both TeV sources which is not observed by earlier surveys .We discuss possible strategies for this emission based on our findings as also as those acquired previously by other researchers . In particular we propose that the seen features are due to synchrotron emission created by relativistic electrons accelerated in shocks driven by stellar winds interacting within these clusters .This scenario would also explain why no X - ray equivalent have been detected so far despite massive investigations carried out with Chandra and XMM - Newton telescopes . Finally , we estimate the magnetic force size needed to produce such emission utilizing typical models for electron acceleration in colliding weather binaries .Introduction The Cygnus OB2 association contains more than 100 OB stars distributed over an area of about 50 square degrees centered at l = 80°and b = 1° ( Fig . 1a ) .It has been proposed that several of them could be members of binary systems or even multiple systems ( e . g . , Knödlseder 2000 ; Wright et al . 2010 ) .These particles can bring powerful storms into their environment forming violent shocks where ions may be advanced up to very high energies . If some of these ions survive from the shock fronts they will interact with photons coming from the nearby interstellar medium generating high - energy electromagnetic radiation detectable across most of the electromagnetic spectrum including the TeV range .Several studies propose that several of the known TeV sources in the heavens would be connected to early open complexes like Cyg OB2 ( see e . g . , Aharonian et al . 2005a , b , 2007a .However , only few of these associations have been confirmed through multi - wavelength campaigns involving optical / microwave imaging , spectroscopy and / or radio continuum observations ( saw e . g . , Reimer & Böttcher 2006 , Castro - Tirado et al",
        "rewrite_text": "We present deep radio observations at 1.4 GHz using the VLA, focusing on two TeV gamma-ray emitting regions: one associated with the open cluster Cyg OB2 #8 (HESS J1640-465) and the other near the massive star WR 25 (HESS J1641-463). Our updated data reveal a significant extension of emission around both TeV sources, which had not been detected in earlier surveys. We explore potential mechanisms for this emission based on our results and those reported by other researchers. Specifically, we suggest that the features observed are attributed to synchrotron emission generated by relativistic electrons that are accelerated in shocks produced by the interaction of stellar winds within these clusters. This explanation may also clarify the absence of corresponding X-ray emissions, which have not been observed despite extensive investigations using the Chandra and XMM-Newton telescopes. Additionally, we estimate the required magnetic field strength necessary to produce this emission, employing standard models for electron acceleration in colliding stellar winds. \n\nIntroduction: The Cygnus OB2 association comprises over 100 OB stars spread across roughly 50 square degrees, centered at l = 80° and b = 1° (see Fig. 1a). It has been suggested that many of these stars may belong to binary or even multiple systems (e.g., Knödlseder 2000; Wright et al. 2010). These stars can induce significant storms in their vicinity, creating shock waves that accelerate ions to extremely high energies. If some of these ions survive the shock waves, they can interact with photons from the surrounding interstellar medium, resulting in the emission of high-energy electromagnetic radiation detectable across a broad spectrum, including the TeV range. Several studies indicate that many known TeV sources may be linked to early open clusters like Cyg OB2 (see, for example, Aharonian et al. 2005a,b, 2007a). However, only a handful of these associations have been confirmed through multi-wavelength campaigns that include optical and microwave imaging, spectroscopy, and radio continuum observations (see, for example, Reimer & Böttcher 2006; Castro-Tirado et al.).",
        "ori-fast-z-score": -0.8892972917998876,
        "water-fast-z-score": 7.185169912163989,
        "rewrite-fast-z-score": -0.3223291856101521
    },
    {
        "original_text": "In this work, we study the charged axially symmetric solution and energy in teleparallel theory equivalent to general relativity (GR). We find that the field equations are exactly same as those obtained by GR with an additional term which is proportional to the torsion scalar T . The solutions for the metric functions are found numerically using the shooting method. It turns out that these solutions have no singularities at all. In addition, it has been shown that the total energy density is positive definite everywhere inside the star. Finally, we show that our results agree well with those obtained by GR. This shows that the teleparallel gravity can be considered as alternative gravitational theories to GR. Keywords: Charged axially symmetric solution; energy; teleparallel gravity; Einstein-Maxwell system. 1 Introduction Gravity plays important role in understanding many physical phenomena such as black holes  1  , cosmology  2  , quantum mechanics  3  etc.. However, there still remain some unsolved problems like dark matter  4  , dark energy  5  , inflation  6  etc., which cannot be explained within the framework of standard model of particle physics  7, 8  .\nThe most successful classical description of gravitation is provided by Einstein s general relativity (GR)  9  where the curvature tensor R µνρσ describes the geometry of space-time  10  . On the other hand, teleparallel gravity  11  -  13  is another approach to describe gravitation on the basis of tetrad fields e A µ instead of metric g µν  14  . Here, the basic variables are connection coefficients Γ λ µν defined through vierbein fields e \nwhere η AB = diag(−1, +1, +1, +1), and h ABCD denotes the contortion tensor  15  . The corresponding Lagrangian density reads  16  :",
        "watermark_text": "In this research , we study the charged axially symmetric solution and energy in teleparallel theory equivalent to general relativity ( GR ) . We see that the field equations are exactly same as those given by GR with an additional term which is proportional to the torsion scalar T .The responses for the metric functions are found numerically using the shot technique . It happens out that these solutions have no singularities at all .In addition , it has been shown that the total energy density is positive definite everywhere inside the star . Finally , we find that our findings agree well with those achieved by GR .This shows that the teleparallel gravitational can be regarded as alternative gravity explanations to GR . Keywords : Charged axially symmetric solution ; energy ; teleparallel gravitational ; Einstein - Maxwell system .1 Introduction Gravity takes key importance in understanding several physical phenomena such as black holes 1 , cosmology 2 , quantum mechanics 3 etc . . However , there still continue some unsolved issues like dark matter 4 , darkness energy 5 , inflation 6 etc . , which cannot be described within the framework of standard theory of particle science 7 , 8 .The most popular classical description of gravitation is provided by Einstein s general relativity ( GR ) 9 where the curvature tensor R µνρσ describes the topology of space - time 10 . On the other hand , teleparallel gravitational 11 - 13 is another technique to explain gravitation on the basis of tetrad fields r A µ instead of metric g µν 14 .Here , the fundamental variables are connection coefficients Γ λ µν characterized through vierbein fields e where η AB = diag ( −1 , + 1 , + 1 , + 1 ) , and h ABCD denotes the contortion tensor 15 . The equivalent Lagrangian density reads 16 :",
        "rewrite_text": "In this study, we investigate the charged axially symmetric solution and energy within the framework of teleparallel theory, which is equivalent to general relativity (GR). Our findings indicate that the field equations mirror those of GR, augmented by an additional term that is proportional to the torsion scalar T. We utilize the shooting method for numerical solutions of the metric functions, and notably, these solutions exhibit no singularities whatsoever. Furthermore, we demonstrate that the total energy density remains positive throughout the interior of the star. Importantly, our results are consistent with those derived from GR, suggesting that teleparallel gravity can serve as an alternative theoretical framework to GR. \n\nKeywords: Charged axially symmetric solution; energy; teleparallel gravity; Einstein-Maxwell system. \n\n1. Introduction\n\nGravity plays a crucial role in the interpretation of various physical phenomena, such as black holes, cosmology, and quantum mechanics. However, unresolved questions persist, including those related to dark matter, dark energy, and cosmic inflation, which remain inadequately addressed within the conventional framework of particle physics. The leading classical description of gravity is Einstein's general relativity (GR), where the curvature tensor Rµνρσ encapsulates the geometric structure of spacetime. Conversely, teleparallel gravity presents an alternative approach, conceptualizing gravitation through tetrad fields (rAµ) instead of the metric (gµν). In this framework, the fundamental variables are the connection coefficients Γλµν, which are defined in terms of the vierbein fields e, where ηAB = diag(−1, +1, +1, +1), and hABCD is the contortion tensor. The corresponding Lagrangian density is expressed as follows:",
        "ori-fast-z-score": 0.4583492485141057,
        "water-fast-z-score": 6.141879930089016,
        "rewrite-fast-z-score": 0.8542421961772492
    },
    {
        "original_text": "We report on the observation of super-Poissonian shot noise in closed quantum dots (QDs). We show that this effect is due to dephasing and can be used for its characterization. The QD emission linewidth was measured by scanning Fabry-Perot interferometry, while the photon statistics were studied using Hanbury Brown-Twiss experiments with two avalanche photodiodes operating at 1 GHz bandwidth. In order to study the influence of temperature we performed these measurements between 4 K and 300 K. At low temperatures, below 50 K, the QD emission linewidth decreases exponentially with decreasing temperature following an activation energy of about 0.3 meV. Above 100 K it follows a power law dependence with T-1/2. Super-Poissonian shot-noise appears above 60 K and increases rapidly up to room temperature where it reaches values more than twice those expected for Poissonian light.",
        "watermark_text": "We report on the observation of super - Poissonian shooting noise in closed quantum dots ( QDs ) . We see that this effect is due to dephasing and can be used for its description .The QD absorption linewidth was measured by scanning Fabry - Perot interferometry , while the photon statistics were studied utilizing Hanbury Brown - Twiss experiments with two avalanche photodiodes running at 1 GHz frequency . In order to study the impact of temperature we performed these measurements between 4 K and 300 K . At small temperatures , below 50 K , the QD absorption linewidth drops exponentially with decreasing temperature following an binding energy of about 0 . 3 meV .Above 100 K it follows a power law dependence with T - 1 / 2 . Super - Poissonian shooting - noise appears above 60 K and expands quickly up to room temperature where it hits values more than times those expected for Poissonian radiation .",
        "rewrite_text": "We present our findings on the observation of super-Poissonian shooting noise in closed quantum dots (QDs). This phenomenon is attributed to dephasing and can effectively describe this behavior. The QD absorption linewidth was determined using scanning Fabry-Perot interferometry, while photon statistics were investigated through Hanbury Brown-Twiss experiments utilizing two avalanche photodiodes operating at a frequency of 1 GHz. To assess the influence of temperature, we conducted measurements over the range of 4 K to 300 K. At low temperatures, specifically below 50 K, the QD absorption linewidth decreases exponentially with temperature, following a binding energy of approximately 0.3 meV. Above 100 K, the linewidth exhibits a power law dependence of T^(-1/2). Super-Poissonian shooting noise emerges at temperatures above 60 K and rapidly increases to room temperature, reaching values significantly greater than what would be anticipated for Poissonian radiation.",
        "ori-fast-z-score": 0.6868028197434451,
        "water-fast-z-score": 5.63178312189625,
        "rewrite-fast-z-score": 0.6509445549041194
    },
    {
        "original_text": "We present broadband (radio to X-ray) observations of GRB 061121, one of the most energetic gamma-ray bursts ever detected by Swift/BAT with an isotropic equivalent energy release of 1.8 x 10^54 erg in the 15-350 keV band. The temporal behavior of this event was complex; it consisted of multiple pulses that were superimposed on top of each other during both the prompt emission phase as well as the early part of its afterglow. We find evidence for two distinct components in the optical light curve -one which decays rapidly at first but then flattens out later-on timescales ranging between 0.1-10 days post-burst. This flattening could be due either to continued activity of the central engine or to refreshed shocks. In addition we detect significant radio emission upto 100 days post-burst. Our results are consistent with those obtained using data from the VLA and ATCA telescopes.",
        "watermark_text": "We present broadband ( radio to X - ray ) observations of GRB 061121 , one of the most intense gamma - ray clusters yet detected by Swift / BAT with an isotropic equivalent energy release of 1 . 8 x 10 ^ 54 erg in the 15 - 350 keV band . The temporal response of this event was complex ; it consisted of multiple pulses that were superimposed on top of each other during both the prompt emission stage as well as the early portion of its afterglow .We get data for two different components in the optical light curve - one which decays fast at first but then flattens out eventually - on timescales ranging between 0 . 1 - 10 days post - break . This flattening may be due either to continued action of the main motor or to refreshed shocks .In addition we find considerable radio emission upto 100 months post - burst . Our results are compatible with those acquired using data from the VLA and ATCA telescopes .",
        "rewrite_text": "We present observations of GRB 061121 across a broad range of wavelengths, from radio to X-ray. This event is one of the most powerful gamma-ray bursts detected by Swift/BAT, exhibiting an isotropic equivalent energy release of 1.8 x 10^54 erg in the 15-350 keV band. The temporal profile of this burst was intricate, characterized by multiple pulses occurring simultaneously during both the prompt emission phase and the initial afterglow. Our analysis reveals two distinct components in the optical light curve: one that initially decays rapidly but ultimately levels off over a timescale of 0.1 to 10 days post-break. This flattening may be attributed to ongoing activity from the primary engine or the influence of refreshed shocks. Furthermore, we observe substantial radio emission lasting up to 100 months after the burst. Our findings align well with data obtained from the VLA and ATCA telescopes.",
        "ori-fast-z-score": -1.2909944487358056,
        "water-fast-z-score": 3.810003810005715,
        "rewrite-fast-z-score": 0.8682431421244593
    },
    {
        "original_text": "We study the vibrational density of states (VDOS) of glassy materials using molecular dynamics simulations with anharmonic interactions between particles. We show that the VDOS can be decomposed into three main contributions: one at low frequencies corresponding to acoustic phonons; another contribution centered around the Debye frequency which is associated with optical phonons; and finally a third contribution located at high frequencies whose origin lies on the presence of unstable modes. The latter are responsible for the appearance of the so-called boson peak in the VDOS. In addition we find that these unstable modes have a strong tendency to form clusters or groups of correlated particles. Finally, by analyzing the spatial distribution of the unstable modes it becomes evident that they tend to localize near regions where there exist structural defects such as icosahedral-like motifs. This localization effect leads us to propose a simple model based on the existence of two different types of sites within the materials: stable ones characterized by their ability to support vibrations over large energy ranges, while unstable sites only allow small-amplitude oscillations.",
        "watermark_text": "We research the vibrational density of states ( VDOS ) of glassy materials utilizing molecular mechanics simulations with anharmonic interactions between particles . We see that the VDOS can be decomposed into three primary contributions : one at low frequencies corresponding to acoustic phonons ; another contribution located around the Debye frequency which is associated with electromagnetic phonons ; and eventually a third contribution located at high frequencies whose source lies on the presence of unstable modes .The latter are responsible for the appearance of the so - called boson peak in the VDOS . In addition we find that these unstable modes have a high ability to form clusters or bands of coupled particles .Finally , by analyzing the spatial distribution of the unstable modes it becomes obvious that they tend to localize near zones where there exist functional flaws such as icosahedral - like motifs . This localization effect results us to propose a simple study based on the existence of two different kinds of places within the materials : steady ones defined by their potential to support vibrations over large energy ranges , while unstable locations only facilitate tiny - frequency oscillations .",
        "rewrite_text": "We investigate the vibrational density of states (VDOS) of glassy materials through molecular mechanics simulations that incorporate anharmonic interactions among particles. Our findings reveal that the VDOS can be divided into three main contributions: a low-frequency component associated with acoustic phonons, a mid-range contribution near the Debye frequency related to electromagnetic phonons, and a high-frequency component linked to unstable modes. These unstable modes give rise to the well-known boson peak observed in the VDOS. Moreover, we discover that these unstable modes have a strong tendency to cluster or form bands of interconnected particles. By examining the spatial distribution of these modes, we observe that they tend to localize around areas with structural defects, such as icosahedral-like arrangements. This localization leads us to propose a straightforward classification of regions within the materials: stable sites that can sustain vibrations across a wide range of energies, and unstable sites that permit only low-frequency oscillations.",
        "ori-fast-z-score": 0.32539568672798425,
        "water-fast-z-score": 6.469966392206305,
        "rewrite-fast-z-score": 0.4588314677411235
    },
    {
        "original_text": "We report the discovery of a new isolated neutron star (INS) candidate, PSR J1852+0040, in the southern hemisphere using data collected by the Parkes radio telescope and the Australia Telescope Compact Array (ATCA). The pulsar was discovered during a search for millisecond pulsars with high proper motions. It has a spin period P = 1.4 ms and is located at a distance D = 3 kpc. Its dispersion measure DM = 0.6 pc cm-3 implies that it lies behind most of the galactic disk but not far enough to be associated with any known supernova remnant or open cluster. We have also detected its X-ray counterpart in archival Chandra observations. This source appears point-like and shows no evidence of extended emission. Based on these properties we conclude that this object is likely to be a young INS. If confirmed as such, our results will provide important constraints on models of pulsar formation and evolution. \n \n Keywords: Neutron stars",
        "watermark_text": "We report the discovery of a new isolated neutron star ( INS ) candidate , PSR J1852 + 0040 , in the southern hemisphere using data provided by the Parkes radio telescope and the Australia Telescope Compact Array ( ATCA ) . The pulsar was discovered during a scan for millisecond pulsars with high proper motions .It has a spinning period P = 1 . 4 ms and is situated at a distance D = 3 kpc . Its dispersion measure DM = 0 . 6 pc mm - 3 implies that it lies behind most of the galactic disk but not long enough to be identified with any observed supernova remnant or open cluster .We have already detected its X - ray counterpart in archival Chandra measurements . This source looks point - like and shows no evidence of extended decay .Based on these characteristics we determine that this body is probably to be a young INS . If confirmed as such , our findings will provide important restrictions on estimates of pulsar structure and evolution .Keywords: Neutron stars",
        "rewrite_text": "We announce the identification of a new isolated neutron star (INS) candidate, PSR J1852 + 0040, located in the southern hemisphere, utilizing data from the Parkes radio telescope and the Australia Telescope Compact Array (ATCA). This pulsar was found during a search for millisecond pulsars exhibiting high proper motions. It has a rotation period of P = 1.4 ms and is approximately D = 3 kpc away. With a dispersion measure of DM = 0.6 pc cm⁻³, it is positioned behind most of the galactic disk, but not sufficiently far to be linked with any known supernova remnant or open cluster. We have also detected its X-ray counterpart in archival data from Chandra. This source appears point-like, showing no signs of extended decay. Given these attributes, we suggest that this object is likely a young INS. If validated as such, our results could significantly inform our understanding of pulsar structure and evolution. \nKeywords: Neutron stars.",
        "ori-fast-z-score": -0.2581988897471611,
        "water-fast-z-score": 5.505585837114527,
        "rewrite-fast-z-score": 0.39056673294247163
    },
    {
        "original_text": "We present an analysis method for the detection of solar neutrinos using radioactive sources in combination with Ge detectors, which is based on a Bayesian statistical approach. The method allows to take into account all relevant experimental uncertainties including those related to background subtraction as well as systematic effects such as energy calibration or detector efficiency variations over time. We apply this new method to two different experiments at Gran Sasso National Laboratory (Italy): Borexino and GNO. In both cases we find that our results are compatible within their respective error bars with previous analyses but show smaller errors due to improved treatment of systematics. This work was supported by the German Science Foundation DFG under grant number BR 1628/2-1. AMS-02 collaboration has recently reported  1  the most precise measurement so far of the positron fraction up to energies of about 300 GeV. It shows a clear excess above the expected astrophysical background  2  . While there have been several attempts to explain these observations  3  , it remains unclear whether they can be attributed to dark matter annihilation  4  .\nIn order to test possible explanations of the observed excess, one needs to know how many positrons are produced per annihilation event. For example, if dark matter particles annihilate predominantly into leptons, then the total number of electrons plus positrons produced per annihilation should equal four times the number of photons produced  5  . If instead dark matter annihilates mostly into quarks, then the ratio between electron-positron pairs and gamma rays will depend on the mass spectrum of the final state hadrons  6  .",
        "watermark_text": "We present an assessment procedure for the observation of solar neutrinos using nuclear sources in combination with Ge detectors , which is based on a Bayesian statistical method . The method enables to take into consideration all relevant experimental uncertainties especially those related to background subtraction as well as systematic effects such as energy calibration or detector efficiency varying over time .We use this new method to two different trials at Gran Sasso National Laboratory ( Italy ) : Borexino and GNO . In both cases we find that our findings are compatible within their separate error bars with previous analyses but give smaller mistakes due to improved treatment of systematics .This project was supported by the German Science Foundation DFG under grant number BR 1628 / 2 - 1 . AMS - 02 consortium has recently published 1 the most accurate detection so far of the positron fraction up to energies of about 300 GeV .It displays a clear excess above the expected astrophysical background 2 . While there have been numerous attempts to explain these observations 3 , it remains unsure whether they can be due to dark matter annihilation 4 .In order to test possible explanations of the seen surplus , one needs to consider how many positrons are produced per annihilation event . For instance , if light matter atoms annihilate predominantly into leptons , then the total quantity of atoms plus positrons produced per annihilation should equivalent four times the quantity of photons generated 5 .If instead dark matter annihilates mostly into quarks , then the proportion between electron - positron couples and alpha radiation will depend on the mass spectrum of the finished state hadrons 6 .",
        "rewrite_text": "We introduce a method for assessing solar neutrino observations utilizing nuclear sources in conjunction with Ge detectors, employing a Bayesian statistical approach. This method accounts for all pertinent experimental uncertainties, particularly those associated with background subtraction, as well as systematic issues like energy calibration and temporal variations in detector efficiency. We apply this innovative technique to two distinct experiments at the Gran Sasso National Laboratory (Italy): Borexino and GNO. In both instances, our results align with previous analyses within their respective error margins, but our approach yields smaller uncertainties due to a more refined treatment of systematic factors. This project was funded by the German Science Foundation DFG under grant number BR 1628/2-1. The AMS-02 consortium has recently released the most precise measurement of the positron fraction up to approximately 300 GeV, revealing a notable excess above the anticipated astrophysical background. Despite numerous attempts to clarify these observations, it remains uncertain whether they can be attributed to dark matter annihilation. To investigate potential explanations for the observed surplus, it is crucial to evaluate the number of positrons produced per annihilation event. For instance, if light matter atoms primarily annihilate into leptons, the total number of particles produced—atoms and positrons combined—should equal four times the number of photons generated. Conversely, if dark matter predominantly annihilates into quarks, the ratio of electron-positron pairs to alpha radiation will depend on the mass spectrum of the resultant hadrons.",
        "ori-fast-z-score": -0.658504607868518,
        "water-fast-z-score": 7.619839033907137,
        "rewrite-fast-z-score": -0.2873478855663454
    },
    {
        "original_text": "We present new observations of the outflows driven by massive protostars using the Submillimeter Array (SMA) at 1.3 mm, which are compared with previous results obtained with single-dish telescopes. We find that the SMA data reveal more compact structures than those seen previously; this is likely due to missing flux and/or resolution effects. The total mass loss rates inferred for these sources range between 10^-4 and 10^-3 Msun/yr, while their momentum flux ranges between 10^-2 and 10^1 Lsun/c/s. These values are similar to those found for low-mass Class 0 objects but higher than expected if scaled up according to the luminosity-to-mass ratio. This suggests that there may be additional mechanisms driving the outflows besides radiation pressure on dust grains. \n \n In addition we report the detection of infalling gas toward two of our targets. For G35.20-1.74NW, we detect an inward motion of ~0.5 km/s over a distance of ~1000 AU. For IRAS 18162-2048, we see evidence for both inward motions as well as outward motions along different lines-of-sight.",
        "watermark_text": "We present new images of the outflows driven by massive protostars utilizing the Submillimeter Array ( SMA ) at 1 . 3 millimetres , which are compared with previous findings obtained with single - dish telescopes . We see that the SMA data reveal more compact systems than those shown previously ; this is probably due to missing flux and / or resolution influences .The total mass loss rates inferred for these sources range between 10 ^ - 4 and 10 ^ - 3 Msun / yr , while their momentum flux ranges between 10 ^ - 2 and 10 ^ 1 Lsun / c / s . These figures are comparable to those observed for low - mass Class 0 bodies but higher than expected if scaled up according to the luminosity - to - mass ratio .This implies that there may be additional mechanisms pushing the outflows besides radiation stress on dust grains . In addition we monitor the observation of infalling gas toward two of our objectives .For G35 . 20 - 1 . 74NW , we perceive an inward movement of ~ 0 . 5 kilometres / s over a distance of ~ 1000 AU . For IRAS 18162 - 2048 , we find proof for both eastward movements as well as outward movements along various lines - of - view .",
        "rewrite_text": "We present new images of outflows driven by massive protostars, captured using the Submillimeter Array (SMA) at a wavelength of 1.3 millimeters, and compare these findings with previous observations made using single-dish telescopes. Our SMA data reveal more compact systems than previously reported, likely due to issues related to missing flux and resolution. The inferred total mass loss rates for these sources range from \\(10^{-4}\\) to \\(10^{-3} \\, M_{\\odot}/\\text{yr}\\), while the momentum flux spans from \\(10^{-2}\\) to \\(10^{1} \\, L_{\\odot}/c/\\text{s}\\). These measurements are comparable to those observed in low-mass Class 0 objects but exceed expectations when scaled by the luminosity-to-mass ratio. This suggests that there may be additional mechanisms, beyond radiation pressure on dust grains, driving the outflows. Additionally, we monitor infalling gas towards two of our targets. For G35.20-1.74NW, we observe inward gas movement of approximately 0.5 kilometers per second over a distance of about 1000 AU. For IRAS 18162-2048, we find evidence for both eastward and outward motions along different lines of sight.",
        "ori-fast-z-score": -0.9058216273156765,
        "water-fast-z-score": 5.4349297638940595,
        "rewrite-fast-z-score": 1.4269353798659745
    },
    {
        "original_text": "We present the first fully general-relativistic magnetohydrodynamic (MHD) simulations of the gravitational collapse of rotating, magnetic white dwarfs and neutron stars with initial masses up to 100 solar masses. We find that for all models considered here, the central density increases by at least eight orders of magnitude during the collapse process. The final state is always a Kerr black hole surrounded by an accretion disk. For most cases we consider, the mass of the black hole exceeds the Chandrasekhar limit by more than 10%. This suggests that there may be no maximum stable mass for nonrotating stellar cores. In addition, our results show that the rotation rate of the newly formed black hole depends on its progenitor s spin parameter as well as its total angular momentum. Finally, we discuss how these findings can be used to explain some observed phenomena such as gamma-ray bursts and superluminous supernovae.",
        "watermark_text": "We present the first fully general - relativistic magnetohydrodynamic ( MHD ) simulations of the gravitational collapse of spinning , magnetic white dwarfs and neutron galaxies with initial masses up to 100 solar masses . We see that for all models discussed here , the main concentration increases by at least eight orders of magnitude during the collapse mechanism .The final state is usually a Kerr brown hole accompanied by an accretion disk . For most instances we require , the mass of the dark hole exceeds the Chandrasekhar limit by more than 10 % .This shows that there may be no maximum stable mass for nonrotating stellar cores . In addition , our findings show that the rotation rate of the newly discovered black hole varies on its progenitor s spin vector as well as its total angular velocity .Finally , we talk how these results can be used to explain some observed processes such as gamma - ray flare and superluminous supernovae .",
        "rewrite_text": "We present the inaugural fully general-relativistic magnetohydrodynamic (MHD) simulations of the gravitational collapse of rotating, magnetized white dwarfs and neutron stars with initial masses of up to 100 solar masses. Our findings indicate that for all the models examined, the primary concentration increases by at least eight orders of magnitude during the collapse process. The end result is typically a Kerr black hole accompanied by an accretion disk. In most cases, the mass of the black hole surpasses the Chandrasekhar limit by more than 10%. This suggests that there may not be a maximum stable mass for non-rotating stellar cores. Additionally, our results reveal that the rotation rate of the newly formed black hole is influenced by the progenitor's spin vector and total angular momentum. Finally, we discuss how these findings can help explain certain observed phenomena, such as gamma-ray flares and superluminous supernovae.",
        "ori-fast-z-score": -1.5428161556520092,
        "water-fast-z-score": 3.771236166328254,
        "rewrite-fast-z-score": -1.4342743312012722
    },
    {
        "original_text": "We present the results of our study on bimodality in galaxies and active galactic nuclei (AGN). We find that there is no significant difference between the fraction of AGNs hosted by red or blue galaxies, but we do see an excess of AGNs with respect to normal galaxies at intermediate colors. This suggests that AGNs are not preferentially found in either red or blue galaxies, as previously thought; instead they appear to be more common among galaxies with intermediate color. The lack of correlation between galaxy color and AGN activity may indicate that AGNs play only a minor role in quenching star formation in massive galaxies. Alternatively, it could suggest that AGNs have different effects depending on their luminosity and/or accretion rate. In addition, we find that the majority of AGNs reside in galaxies with bulges, regardless of whether these galaxies are classified as early-type or late-type systems.",
        "watermark_text": "We present the conclusion of our research on bimodality in galaxies and active galactic nuclei ( AGN ) . We see that there is no major variation between the fraction of AGNs hosted by red or blue clusters , but we do saw an surplus of AGNs with regard to normal galaxies at intermediate colors .This implies that AGNs are not preferentially found in either blue or blue stars , as previously thought ; however they appear to be more common among clusters with intermediate color . The absence of correlation between galaxy color and AGN activity may indicate that AGNs serve only a minor importance in quenching star formation in massive galaxies .Alternatively , it could indicate that AGNs have different impacts depending on their luminosity and / or accretion rate . In addition , we find that the majority of AGNs occur in galaxies with bulges , regardless of whether these objects are classified as early - class or late - class systems .",
        "rewrite_text": "We conclude our research on bimodality in galaxies and active galactic nuclei (AGN). Our findings indicate that there is no significant difference in the proportion of AGNs hosted by red or blue clusters. However, we observed a higher abundance of AGNs in galaxies with intermediate colors compared to normal galaxies. This suggests that AGNs are not preferentially associated with either blue or red stars, as previously assumed; instead, they are more prevalent among intermediate-color clusters. The lack of a correlation between galaxy color and AGN activity may suggest that AGNs play a relatively minor role in suppressing star formation in massive galaxies. Alternatively, it may indicate that the effects of AGNs vary based on their luminosity and/or accretion rate. Additionally, we found that most AGNs are located in galaxies with bulges, regardless of whether they are classified as early-type or late-type systems.",
        "ori-fast-z-score": 0.8551861104941365,
        "water-fast-z-score": 6.305926250944657,
        "rewrite-fast-z-score": 0.8551861104941365
    },
    {
        "original_text": "The theoretical investigation is performed for the ferroelectric phase transition in potassium nitrate (KNO3). The results are obtained by using density functional theory and generalized gradient approximation with Perdew-Burke-Ernzerhof exchange-correlation functionals. It has been found that KNO3 undergoes an improper ferroelectric phase transition at T = 723 K, which is accompanied by the rotation of NO3-groups around their symmetry axes. In addition to this structural change, there occurs also a significant redistribution of charge between atoms. This leads to changes in the electronic structure near Fermi level. The calculated values of spontaneous polarization Psp(0) = 0.27 C/m2 and dielectric constant εs = 4.5 agree well with experimental data. \n \n Keywords: Ferroelectrics; Potassium nitrite; Phase transitions; Density functional theory. 1 Introduction Potassium nitrate (KNO3), one of the most important chemical compounds used as fertilizers  1  , exhibits interesting physical properties such as piezo-, pyro-, electro-optic effects  2  . At room temperature it crystallizes into orthorhombic system  3  . Below its Curie point Tc = 723 K  4  , KNO3 behaves like paraelectric material while above Tc it becomes ferroelectric  5  .\n2 Computational details All calculations were carried out within the framework of density functional theory  6  employing plane wave basis set and projector augmented-wave method  7, 8  implemented in VASP code  9  . Exchange correlation energy was treated within generalized gradient approximation  10  . To account for van der Waals interactions we have applied Grimme s semiempirical dispersion correction  11  . We considered two different supercells containing 64 and 216 atoms respectively. For both cells we chose Monkhorst-Pack k-point mesh  12  corresponding to 6×6×4 grid in reciprocal space. Energy cutoff for planewave expansion was chosen equal to 400 eV. Structure optimization was done until all forces acting on each atom became less than 10-3 eV/Å.",
        "watermark_text": "The theoretical investigation is conducted for the ferroelectric phase shift in potassium nitrate ( KNO3 ) . The results are derived by using density functional theory and generalized gradient approximation with Perdew - Burke - Ernzerhof exchange - correlation functionals .It has been shown that KNO3 undergoes an improper ferroelectric phase shift at T = 723 K , which is preceded by the movement of NO3 - bands around their symmetry axes . In addition to this structural transformation , there occurs also a substantial redistribution of charge between electrons .This leads to changes in the electronic system near Fermi level . The measured quantities of spontaneous polarization Psp ( 0 ) = 0 . 27 C / m2 and dielectric constant εs = 4 . 5 comply good with experimental evidence .Keywords : Ferroelectrics ; Potassium nitrite ; Phase transitions ; Density functional theory . 1 Introduction Potassium nitrate ( KNO3 ) , one of the most important chemical molecules used as fertilizers 1 , displays exciting physical properties such as piezo - , pyro - , electro - optic effects 2 .At room temperature it crystallizes into orthorhombic system 3 . Below its Curie point Tc = 723 K 4 , KNO3 behaves like paraelectric material while above Tc it becomes ferroelectric 5 .2 Computational information All calculations were carried out within the framework of density functional theory 6 employing plane wave basis set and projector augmented - wave method 7 , 8 adopted in VASP system 9 . Exchange correlation power was treated within generalized gradient approximation 10 .To account for van der Waals interactions we have applied Grimme s semiempirical dispersion treatment 11 . We considered two different supercells containing 64 and 216 elements respectively .For both cells we chose Monkhorst - Pack k - point mesh 12 corresponding to 6×6×4 array in reciprocal space . Energy cutoff for planewave expansion was chosen equivalent to 400 eV .Structure optimization was done until all forces working on each atom remained less than 10 - 3 eV / Å .",
        "rewrite_text": "This theoretical study investigates the ferroelectric phase transition in potassium nitrate (KNO3). The findings are obtained using density functional theory (DFT) and the generalized gradient approximation (GGA) with Perdew-Burke-Ernzerhof (PBE) exchange-correlation functionals. The results indicate that KNO3 experiences an improper ferroelectric phase transition at a temperature of 723 K, which is preceded by the displacement of NO3⁻ groups around their symmetry axes. Alongside this structural change, there is a significant redistribution of electronic charge, resulting in alterations to the electronic properties near the Fermi level. The computed values of spontaneous polarization (Psp(0) = 0.27 C/m²) and dielectric constant (εs = 4.5) align well with experimental data. \n\n**Keywords:** Ferroelectrics; Potassium nitrate; Phase transitions; Density functional theory.\n\n**1 Introduction**  \nPotassium nitrate (KNO3) is a crucial chemical compound widely used in fertilizers and exhibits fascinating physical properties, including piezoelectric, pyroelectric, and electro-optic effects. At room temperature, KNO3 crystallizes in an orthorhombic structure. It acts as a paraelectric material below its Curie temperature (Tc = 723 K) and transitions to ferroelectric behavior above Tc.\n\n**2 Computational Information**  \nAll calculations were performed within the framework of density functional theory (DFT) using a plane wave basis set and the projector augmented-wave (PAW) method implemented in the VASP software package. The exchange-correlation interactions were approximated using the generalized gradient approximation (GGA). To address van der Waals interactions, we applied Grimme's semiempirical dispersion correction. We examined two distinct supercells, containing 64 and 216 atoms, respectively, and employed a Monkhorst-Pack k-point mesh corresponding to a 6×6×4 grid in reciprocal space. The energy cutoff for the plane wave expansion was set to 400 eV. Structure optimization continued until the forces on each atom were below 10⁻³ eV/Å.",
        "ori-fast-z-score": -0.18569533817705186,
        "water-fast-z-score": 5.199469468957452,
        "rewrite-fast-z-score": -0.647150228929434
    },
    {
        "original_text": "We present an analytical model for the magneto-rotational instability (MRI) in protoplanetary disks, which is based on the assumption that the disk can be divided into two regions with different physical properties and dynamics. The inner region has a high density and temperature, while the outer one is less dense but hotter than the surrounding medium. We show how this simple picture allows us to reproduce many observed features of MRI-driven turbulence in accretion disks around young stars. In particular, we find that:  -The growth rate of the fastest growing mode decreases rapidly towards smaller radii due to the increasing gas pressure.  -The radial profile of the turbulent viscosity follows closely the profile of the magnetic field strength.  -The angular momentum transport efficiency increases strongly at small radii because of the rapid increase of the surface density there.  -The predicted mass accretion rates are consistent with those inferred observationally for T Tauri stars.",
        "watermark_text": "We present an analytical theory for the magneto - rotational instability ( MRI ) in protoplanetary disks , which is based on the assumption that the disk can be broken into two zones with varying material structures and dynamics . The outer sector has a high density and heat , while the inner one is greater dense but brighter than the nearby medium .We see how this straightforward photo lets us to depict many observed features of MRI - driven turbulence in accretion balls around early stars . In particular , we find that : - The growth speed of the fastest growing mode decreases quickly towards smaller radii due to the increasing gas pressure .- The radial profile of the chaotic viscosity follows carefully the profile of the magnetic force strength . - The angular velocity transport rate grows heavily at small radii because of the quick expansion of the surface volume there .- The predicted mass accretion levels are compatible with those inferred observationally for T Tauri stars .",
        "rewrite_text": "We present a theoretical analysis of the magneto-rotational instability (MRI) in protoplanetary disks, based on the premise that the disk can be divided into two regions with distinct material structures and dynamics. The outer region is characterized by high density and temperature, while the inner region is denser but brighter than the surrounding medium. This simple framework allows us to account for several observed features of MRI-driven turbulence in accretion disks around young stars. Specifically, we find that: 1) the growth rate of the fastest-growing mode decreases rapidly at smaller radii due to increasing gas pressure; 2) the radial profile of chaotic viscosity closely follows the profile of magnetic field strength; 3) the angular momentum transport increases significantly at small radii due to the rapid expansion of the surface area; and 4) the predicted levels of mass accretion align well with those observed in T Tauri stars.",
        "ori-fast-z-score": -1.2535663410560174,
        "water-fast-z-score": 5.8119893994415355,
        "rewrite-fast-z-score": -0.6882472016116852
    },
    {
        "original_text": "The spin transistor is an important device for future quantum information processing and communication technologies, but its realization in practice has been challenging due to the lack of suitable materials with large spin-orbit coupling (SOC). Here we propose that graphene can be used as such material by exploiting its unique electronic structure. We show how this leads to a novel type of spin transistor which operates at room temperature without external magnetic fields or applied gate voltages. The proposed device consists of two ferromagnetic contacts connected via a single layer of graphene. By applying a voltage between these contacts one can control the SOC strength in the graphene channel leading to a change in the transmission probability through it. This results in a switching behavior similar to conventional transistors. In addition, our analysis shows that the proposed device exhibits high on/off ratios even when operating under realistic conditions. Finally, we discuss possible experimental realizations of the proposed device. Graphene is a promising candidate for applications in spintronics because of its unique electronic properties  1  . It offers the possibility to realize devices based on pure spin currents  2  , which are not limited by Joule heating effects  3  .\nIn particular, the spin Hall effect  4  allows for efficient generation  5  and detection  6  of spin currents using only electric fields  7, 8  . However, despite many theoretical proposals  9  , there have so far been very few successful attempts to experimentally demonstrate spintronic devices based on graphene  10  . One reason might be the difficulty to find appropriate materials with sufficiently strong spin-orbit interaction  11  . Another problem is related to the fact that most experiments were performed at low temperatures  12  where thermal fluctuations limit the performance of spintronic devices  13  .",
        "watermark_text": "The spin transistor is an important technology for future quantum information processing and communication technologies , but its acceptance in practice has been challenging due to the lack of appropriate substances with large spin - orbit coupling ( SOC ) . Here we propose that graphene can be used as such material by exploiting its unique electronic content .We see how this results to a new kind of spin transistor which operates at room temperature without external magnetic fields or applied gate voltages . The proposed system consists of two ferromagnetic contacts connected via a single thickness of graphene .By applying a voltage between these contacts one can influence the SOC intensity in the graphene channel resulting to a change in the propagation probability through it . This results in a switching environment similar to conventional transistors .In addition , our analysis shows that the suggested system displays high on / off ratios even when operating under realistic conditions . Finally , we study possible experimental realizations of the suggested system .Graphene is a potential candidate for applications in spintronics because of its unique electronic properties 1 . It provides the prospect to realize devices using on true spin currents 2 , which are not limited by Joule cooling effects 3 .In particular , the spin Hall phenomenon 4 enables for efficient production 5 and confirmation 6 of spin currents using only electric forces 7 , 8 . However , despite many theoretical proposals 9 , there have so far been very few successful proposals to experimentally prove spintronic systems based on graphene 10 .One reason could be the difficulty to find adequate devices with adequate strong spinning - orbit interaction 11 . Another difficulty is related to the fact that most studies were performed at low temperatures 12 where thermal fluctuations limit the performance of spintronic systems 13 .",
        "rewrite_text": "The spin transistor represents a crucial advancement for the future of quantum information processing and communication technologies, yet its practical implementation has faced obstacles due to the scarcity of suitable materials with significant spin-orbit coupling (SOC). In this context, we propose that graphene can serve as such a material by leveraging its distinctive electronic properties. Our findings demonstrate the development of a new type of spin transistor that functions at room temperature without the need for external magnetic fields or applied gate voltages. This innovative system features two ferromagnetic contacts linked by a single layer of graphene. By applying a voltage across these contacts, the SOC intensity within the graphene channel can be altered, leading to changes in the probability of spin propagation. This creates a switching mechanism akin to that of conventional transistors. Moreover, our analysis indicates that this proposed system exhibits high on/off ratios, even under realistic conditions. We further explore potential experimental implementations of this approach. Graphene is an appealing candidate for spintronic applications due to its unique electronic characteristics. It offers the potential to create devices that utilize genuine spin currents, which are not hindered by Joule heating effects. In particular, the spin Hall effect facilitates the efficient generation and detection of spin currents solely through electric forces. However, despite numerous theoretical suggestions, there have been relatively few successful experimental demonstrations of graphene-based spintronic systems. One contributing factor may be the challenge of identifying devices with sufficiently strong spin-orbit interactions. Additionally, most investigations have been conducted at low temperatures, where thermal fluctuations can negatively impact the performance of spintronic devices.",
        "ori-fast-z-score": 1.4316582658130823,
        "water-fast-z-score": 8.397070403831712,
        "rewrite-fast-z-score": 1.4419211804559506
    },
    {
        "original_text": "We present the results of an extensive multi-wavelength survey of two nearby (< 1 kpc) and well-studied star-forming regions, Orion Nebula Cluster (ONC), NGC 2024, in order to investigate their physical properties as well as those of individual protostars embedded within them. We have obtained near-infrared images with Subaru/Suprime-Cam at JHKs bands for ONC region and Spitzer/IRAC 3.6-8.0 micron data for both regions. In addition we used archival radio continuum observations made by VLA at 6 cm and 20 cm wavelengths. Using these datasets, we performed photometry on all point sources detected above 5 sigma level in each band. By comparing our infrared photometric measurements with theoretical evolutionary models, we found that most of the objects are likely to be Class I or flat-spectrum protostellar candidates. From the analysis of spectral energy distribution (SED) fitting using radiative transfer modeling code, we derived the mass accretion rates onto the central stars ranging between 10-700 x10-6 Msun yr-1 .",
        "watermark_text": "We publish the conclusion of an extensive multi - wavelength search of two adjacent ( < 1 kpc ) and well - investigated star - creating areas , Orion Nebula Cluster ( ONC ) , NGC 2024 , in order to examine their physical properties as well as those of several protostars embedded within them . We have achieved near - infrared images with Subaru / Suprime - Cam at JHKs bands for ONC region and Spitzer / IRAC 3 . 6 - 8 . 0 micron data for both locations .In addition we using archival radio continuum measurements made by VLA at 6 cm and 20 cm wavelengths . Using these datasets , we performed photometry on all point sources detected above 5 sigma grade in each band .By applying our laser photometric calculations with theoretical phylogenetic models , we identified that most of the items are likely to be Class I or flat - spectrum protostellar candidates . From the evaluation of spectral power distribution ( SED ) matching using radiative transfer modeling code , we derived the mass accretion levels onto the main stars ranging between 10 - 700 x10 - 6 Msun yr - 1 .",
        "rewrite_text": "We present the findings from a comprehensive multi-wavelength survey of two closely located (less than 1 kpc apart) and extensively studied star-forming regions: the Orion Nebula Cluster (ONC) and NGC 2024. This investigation aims to analyze their physical properties as well as those of several protostars found within them. We have obtained near-infrared images of the ONC region using Subaru/Suprime-Cam, capturing data in the JHKs bands, along with Spitzer/IRAC data in the 3.6 to 8.0 micron range for both regions. Additionally, we incorporated archival radio continuum measurements from the VLA at 6 cm and 20 cm wavelengths. With these datasets, we conducted photometry on all detected point sources exceeding a 5 sigma threshold in each band. By integrating our photometric results with theoretical astrophysical models, we found that most sources are likely Class I or flat-spectrum protostellar candidates. Through the analysis of spectral energy distribution (SED) fitting using radiative transfer modeling, we estimated the mass accretion rates onto the primary stars to be between 10 and 700 x 10^-6 Msun per year.",
        "ori-fast-z-score": -1.212678125181665,
        "water-fast-z-score": 5.0089472186085136,
        "rewrite-fast-z-score": 0.23570226039551587
    },
    {
        "original_text": "We report on the detection of transient X-ray emission in normal galactic nuclei (NGNs) with Chandra and XMM-Newton observatories, which is likely to be associated with accretion onto supermassive black holes at their centers. The observed luminosities are consistent with those expected for steady nuclear activity powered by mass inflow through an optically thick disk around the central black hole. We find that the duration of this activity ranges between 10 3 -10 5 years, depending on the distance of NGN from Earth. This suggests that the majority of NGNs may have experienced such active phases during their lifetimes. Our results also imply that the current quiescent state of most NGNs could be due to either low-level accretion or obscuration effects. These findings provide new insights into the formation and evolution of massive galaxies as well as AGNs. Keywords: Black Hole Accretion Disk - Galaxy Evolution - Nuclear Activity",
        "watermark_text": "We report on the observation of transient X - ray radiation in regular galactic nuclei ( NGNs ) with Chandra and XMM - Newton observatories , which is expected to be involved with accretion onto supermassive black holes at their centers . The observed luminosities are compatible with those expected for steady nuclear activity driven by mass inflow through an optically dense disk around the main white hole .We see that the duration of this action ranges between 10 3 - 10 5 years , depending on the distance of NGN from Earth . This implies that the majority of NGNs might have experienced such active phases during their lifetimes .Our results also suggest that the present quiescent state of most NGNs might be due to either small - point accretion or obscuration effects . These studies provide fresh insights into the formation and evolution of large galaxies as well as AGNs .Keywords: Black Hole Accretion Disk - Galaxy Evolution - Nuclear Activity",
        "rewrite_text": "We present our findings on the observation of transient X-ray radiation in Regular Galactic Nuclei (NGNs) using the Chandra and XMM-Newton observatories. This phenomenon is believed to be linked to the accretion processes occurring in supermassive black holes at the centers of these galaxies. The luminosities we detected align with those anticipated from stable nuclear activity driven by mass inflow through a dense, optically thick accretion disk surrounding a central white hole. Our observations indicate that the duration of this activity spans from 1,000 to 100,000 years, depending on the NGN's distance from Earth. This suggests that many NGNs may have undergone such active phases throughout their histories. Additionally, our results imply that the current quiescent state of most NGNs could be a result of either minimal accretion processes or obscuration effects. These investigations offer new perspectives on the formation and evolution of large galaxies, as well as Active Galactic Nuclei (AGNs). \n\nKeywords: Black Hole Accretion Disk, Galaxy Evolution, Nuclear Activity.",
        "ori-fast-z-score": -1.0690449676496976,
        "water-fast-z-score": 5.077963596336064,
        "rewrite-fast-z-score": -0.8819171036881969
    },
    {
        "original_text": "We study the effect of temperature dependent shape anisotropy in an exchange coupled system consisting of two identical uniaxial single domain particles, one being magnetically softer than the other and both having their easy axes parallel to each other. We show that for certain values of the parameters involved there is a significant increase in the coercive field at low temperatures compared to high temperatures. This can be understood by considering the competition between the Zeeman energy barrier due to the applied magnetic field and the thermal activation energy barrier associated with the temperature dependence of the shape anisotropy. \n \n The model we consider consists of two identical spherical particles (with radius R) separated by a distance d along the z-axis. Each particle has its own uniaxial anisotropy constant Ks(T), where T denotes the temperature. In addition, they are also exchange-coupled through a coupling constant J. For simplicity, we assume that the anisotropy constants have the same functional form as given below, \n \n Ks = K1 + K2 tanh -(T/Tc) ,\n \nwhere Tc is some characteristic temperature scale which determines how rapidly the anisotropy changes with temperature.",
        "watermark_text": "We explore the impact of temperature dependent shape anisotropy in an exchange coupled system consisting of two different uniaxial single domain particles , one being magnetically softer than the other and both having their easy axes aligned to each other . We see that for particular values of the variables required there is a substantial rise in the coercive field at low temperatures relative to low temperatures .This can be understood by analyzing the competition between the Zeeman power barrier resulting to the introduced magnetic force and the thermal activation energy barrier associated with the temperature dependence of the shape anisotropy . The model we define consists of two equal spherical atoms ( with diameter R ) connected by a length d along the z - axis .Each particle has its own uniaxial anisotropy constant Ks ( T ) , where T denotes the temperature . In addition , they are also exchange - coupled through a coupling constant J .For simplicity , we suppose that the anisotropy constants have the same functional shape as provided below , Ks = K1 + K2 tanh - ( T / Tc ) , where Tc is some characteristic temperature scale which determines how swiftly the anisotropy changes with temperature .",
        "rewrite_text": "We investigate the effects of temperature-dependent shape anisotropy in an exchange-coupled system comprising two distinct uniaxial single-domain particles, with one particle being magnetically softer than the other and both aligned along the same easy axis. Our findings reveal that, under certain conditions, there is a significant increase in the coercive field at low temperatures compared to high temperatures. This phenomenon can be explained by examining the interplay between the Zeeman energy barrier created by the applied magnetic force and the thermal activation energy barrier influenced by the shape anisotropy’s temperature dependence. The model we propose consists of two identical spherical particles (each with a diameter of R) connected by a distance d along the z-axis. Each particle possesses its own uniaxial anisotropy constant Ks(T), where T represents the temperature. Additionally, the particles are exchange-coupled via a coupling constant J. To simplify the analysis, we assume that the anisotropy constants follow the functional form given by Ks = K1 + K2 tanh(-T / Tc), where Tc is a characteristic temperature scale that dictates the rate at which anisotropy changes with temperature.",
        "ori-fast-z-score": -0.4472135954999579,
        "water-fast-z-score": 5.590169943749474,
        "rewrite-fast-z-score": 0.3333333333333333
    },
    {
        "original_text": "We present the results of an investigation into the evolution of dark matter halos and their substructure, using high-resolution cosmological N-body simulations with different mass resolutions. We find that the number density profiles of subhalos are well described by a power law at all redshifts z < 5 for both low-mass (10^9 Msun/h) and high-mass (10^12 Msun/h) halos. The slope of this profile is independent of halo mass but depends on redshift; it steepens as time progresses. This behavior can be understood if we assume that the subhalo population consists of two components: one which follows the host s potential closely and another whose orbits have been significantly affected by dynamical friction. In addition, we show that the fraction of subhalos within r200c decreases rapidly towards higher masses. Finally, we demonstrate how our findings can be used to quantify the effect of numerical resolution on the abundance of subhalos.",
        "watermark_text": "We present the conclusion of an research into the evolution of deep material halos and their substructure , using high - resolution cosmological N - bodies simulations with various mass resolutions . We see that the number density patterns of subhalos are better modeled by a power law at all redshifts z < 5 for both high - weight ( 10 ^ 9 Msun / h ) and low - density ( 10 ^ 12 Msun / h ) halos .The slope of this profile is independent of halo weight but relies on redshift ; it steepens as time progresses . This phenomenon can be understood if we suppose that the subhalo population contains of two parts : one which follows the host s potential closely and another whose orbits have been dramatically impacted by dynamical friction .In addition , we prove that the fraction of subhalos within r200c tends rapidly towards higher masses . Finally , we prove how our findings can be used to quantify the impact of statistical resolution on the availability of subhalos .",
        "rewrite_text": "We present the results of our research on the evolution of deep material halos and their substructure, utilizing high-resolution cosmological N-body simulations with varying mass resolutions. Our findings indicate that the number density distributions of subhalos are more accurately represented by a power law across all redshifts z < 5, for both massive (10^9 Msun/h) and less dense (10^12 Msun/h) halos. The slope of this distribution is consistent across different halo masses but varies with redshift, becoming steeper over time. This behavior can be explained by considering the subhalo population as comprising two components: one that closely follows the host’s potential and another whose orbits have been significantly altered by dynamical friction. Additionally, we demonstrate that the fraction of subhalos within r200c rapidly shifts toward higher mass values. Finally, we highlight how our findings can be leveraged to assess the effects of statistical resolution on the presence of subhalos.",
        "ori-fast-z-score": -2.0,
        "water-fast-z-score": 4.5,
        "rewrite-fast-z-score": 0.3721042037676254
    },
    {
        "original_text": "We show that the linear programming relaxation (LP) is equivalent to the max-product algorithm on general graphs, when applied to weighted matching problems with non-negative weights.  We prove this equivalence by showing how each step of the max-product algorithm can be simulated using an appropriate rounding technique based on the solution of the dual problem at hand.   The main idea behind our approach is to use the fact that any feasible primal-dual pair satisfies certain properties which we exploit to obtain a valid rounding scheme. Our results are applicable to many combinatorial optimization problems such as maximum weight bipartite matching, minimum cost flow, vertex cover etc., where the objective function has only non-negative coefficients. In particular, they imply that the integrality gap of these problems under their respective LP relaxations cannot exceed 1 + $O(1/n)$, where $n$ denotes the number of nodes or edges in the input graph. This improves upon previously known upper bounds of 2 and 3/2 respectively.",
        "watermark_text": "We see that the linear programming relaxation ( LP ) is analogous to the max - product algorithm on general graphs , when applied to weighted matching problems with non - negative weights . We prove this equivalence by showing how each step of the max - product algorithm can be simulated using an appropriate rounding methodology relying on the solve of the dual issue at hand .The main idea behind our approach is to use the fact that any feasible primal - dual pair satisfies certain characteristics which we utilize to obtain a valid rounding scheme . Our results are applicable to many combinatorial algorithms problems such as maximum weight bipartite matching , lowest price flow , vertex cover etc . , where the objective function has only non - negative coefficients .In particular , they assume that the integrality gap of these problems under their different LP relaxations cannot exceed 1 + $ O ( 1 / n ) $ , where $ n $ represents the quantity of vertices or edges in the input matrix . This improves upon previously known upper limits of 2 and 3 / 2 respectively .",
        "rewrite_text": "We demonstrate that the linear programming relaxation (LP) is comparable to the max-product algorithm on general graphs when addressing weighted matching problems with non-negative weights. We establish this equivalence by illustrating how each step of the max-product algorithm can be replicated through an appropriate rounding method that utilizes the solution of the corresponding dual problem. The core concept of our approach is based on the observation that any feasible primal-dual pair possesses specific properties that we leverage to develop an effective rounding scheme. Our findings are relevant to a variety of combinatorial algorithm problems, including maximum weight bipartite matching, lowest price flow, and vertex cover, among others, where the objective function consists solely of non-negative coefficients. Specifically, we posit that the integrality gap of these problems, under various LP relaxations, cannot exceed 1 + $O(1/n)$, with $n$ denoting the number of vertices or edges in the input matrix. This represents an enhancement over previously established upper bounds of 2 and 3/2, respectively.",
        "ori-fast-z-score": 1.7669044171975445,
        "water-fast-z-score": 5.521576303742327,
        "rewrite-fast-z-score": 1.5460413650478515
    },
    {
        "original_text": "We present an equation of state for atomic systems with large scattering lengths, which is obtained in the framework of the lowest-order constrained variational method (LOCV). The LOCV approach allows one to obtain accurate results for both fermions and bosons at low temperatures. We show that our equation of state agrees well with Monte Carlo simulations performed within the grand canonical ensemble. In particular we find good agreement between theory and experiment on the energy per particle of 4 He-4 He mixtures near the superfluid transition temperature T = Tc. Our results are also compared with those obtained using other theoretical approaches such as the virial expansion or the hypernetted chain approximation. \nI. INTRODUCTORY REMARK\nThe equation of state plays an important role in many areas of physics ranging from nuclear matter  1  , quantum gases  2  , astrophysics  3  , condensed matter  4  , etc.. It describes how various thermodynamic quantities depend on each other under given conditions. For example, it can be used to determine the pressure P , chemical potential µ, entropy S, specific heat Cv, compressibility κT , thermal expansivity αp, sound velocity cs, etc., all of them being functions of density n and/or temperature T . Hereafter we will use the symbol EOS to denote any of these quantities.\nIn this work we consider the case when the scattering length a of two particles becomes very large so that the system behaves like a gas of weakly interacting dimers. This situation occurs e.g. in dilute Bose-Einstein condensates  5  where the scattering length may be tuned via Feshbach resonances  6  .\nII. THEORETICAL APPROACHES\n\nA. Grand Canonical Ensemble\nTo describe the properties of a mixture consisting of Nα atoms of species A and Nβ atoms of species B, we employ the grand-canonical ensemble  7, 8  \nwhere H is the total Hamiltonian of the system, β ≡ 1/kB T denotes inverse temperature, μi is the chemical potential of species i ∈ {A, B}, and Z(Nα,",
        "watermark_text": "We present an equation of state for nuclear systems with large scattering lengths , which is achieved in the framework of the lowest - order constrained variational technique ( LOCV ) . The LOCV method enables one to obtain precise conclusions for both fermions and bosons at low temperatures .We see that our equation of state agrees well with Monte Carlo simulations conducted within the grand canonical ensemble . In particular we find good agreement between theoretical and experiment on the power per particle of 4 He - 4 He mixtures near the superfluid transition volume T = Tc .Our results are also compared with those achieved using other theoretical methods such as the virial expansion or the hypernetted chain method . I .INTRODUCTORY REMARK The equation of state plays an important role in different areas of science diverse from nuclear matter 1 , quantum gases 2 , astrophysics 3 , condensed matter 4 , etc . . It expresses how various thermodynamic quantities rely on each other under given conditions .For instance , it can be used to estimate the pressure P , chemical potential µ , entropy S , basic heat Cv , compressibility κT , thermal expansivity αp , noise speed cs , etc . , all of them being functions of density n and / or temperature T . Hereafter we will use the symbol EOS to indicate any of these quantities .In this research we imagine the case when the scattering height a of two particles gets very huge so that the system behaves like a gas of weakly interacting dimers . This condition occurs e . g .in dilute Bose - Einstein condensates 5 where the scattering duration could be tuned via Feshbach resonances 6 . II .THEORETICAL APPROACHES A . Grand Canonical Ensemble To describe the properties of a mixture consisting of Nα atoms of genus A and Nβ elements of genus B , we utilize the grand - canonical ensemble 7 , 8 where H is the total Hamiltonian of the system , β ≡ 1 / kB T denotes inverse temperature , μi is the chemical potential of species i ∈ { A , B } , and Z ( Nα ,",
        "rewrite_text": "We introduce an equation of state for nuclear systems characterized by large scattering lengths, developed within the framework of the lowest-order constrained variational technique (LOCV). The LOCV approach allows for accurate determinations for both fermions and bosons at low temperatures. Our findings indicate a strong agreement between our equation of state and Monte Carlo simulations conducted in the grand canonical ensemble. Notably, we observe a close alignment between theoretical predictions and experimental results regarding the energy per particle in ^4He - ^4He mixtures as they approach the superfluid transition temperature, T = Tc. Our results are also compared with outcomes from other theoretical frameworks, including the virial expansion and the hypernetted chain method.\n\nI. INTRODUCTORY REMARK  \nThe equation of state is crucial across a variety of scientific fields, including nuclear matter, quantum gases, astrophysics, and condensed matter physics. It describes the interdependence of different thermodynamic quantities under specified conditions. For example, it can be used to estimate pressure (P), chemical potential (µ), entropy (S), specific heat (Cv), compressibility (κT), thermal expansivity (αp), and sound speed (cs), all of which depend on density (n) and/or temperature (T). In this study, we focus on a scenario where the scattering length (a) between two particles becomes exceedingly large, causing the system to behave as a gas of weakly interacting dimers. This situation is exemplified in dilute Bose-Einstein condensates, where the scattering length may be adjusted via Feshbach resonances.\n\nII. THEORETICAL APPROACHES  \nA. Grand Canonical Ensemble  \nTo analyze the properties of a mixture containing Nα atoms of species A and Nβ atoms of species B, we employ the grand-canonical ensemble. In this context, H represents the total Hamiltonian of the system, β ≡ 1/kB T denotes the inverse temperature, µi is the chemical potential of species i ∈ {A, B}, and Z(Nα, …).",
        "ori-fast-z-score": -0.17407765595569785,
        "water-fast-z-score": 6.44087327036082,
        "rewrite-fast-z-score": -0.08873565094161139
    },
    {
        "original_text": "We report on the discovery and analysis of XMM-Newton observations of an uncatalogued, extremely faint X-ray source (X-ray luminosity < 1031 erg s-1) in the Galactic plane at l = 28 deg., b = 0.5 deg.. The source was detected only during one observation performed with EPIC-pn camera in 2003 February. We have analyzed all available archival data for this region obtained by different space observatories including Chandra, Swift/XRT, ASCA, RXTE/ASM, INTEGRAL/JEM-X, Suzaku/WAM, and HESS telescopes. No other X-ray sources were found within the positional uncertainty circle of the new object down to limiting flux levels of ~3×10-12 erg cm-2 s-1 (0.2-10 keV). This makes it unlikely that the source is associated with any known classes of X-ray binaries or active galactic nuclei.",
        "watermark_text": "We report on the discovery and assessment of XMM - Newton discoveries of an uncatalogued , incredibly faint X - ray source ( X - ray luminosity < 1031 erg s - 1 ) in the Galactic jet at l = 28 deg . , b = 0 . 5 deg . . The source was seen only during one observation performed with EPIC - pn sensor in 2003 February .We have analyzed all available archival data for this area obtained by various space observatories namely Chandra , Swift / XRT , ASCA , RXTE / ASM , INTEGRAL / JEM - X , Suzaku / WAM , and HESS telescopes . No other X - ray bodies were found within the positional uncertainty arc of the new object down to limiting flux levels of ~ 3×10 - 12 erg centimetres - 2 s - 1 ( 0 . 2 - 10 keV ) .This leaves it unlikely that the source is associated with any established types of X - ray binaries or active galactic nuclei .",
        "rewrite_text": "We present our findings on the discovery and evaluation of an uncatalogued, extremely faint X-ray source (X-ray luminosity < 10^31 erg s^-1) located in the Galactic jet at coordinates l = 28°, b = 0.5°. This source was detected during a single observation with the EPIC-pn sensor in February 2003. We have thoroughly analyzed all available archival data for this region collected from various space observatories, including Chandra, Swift/XRT, ASCA, RXTE/ASM, INTEGRAL/JEM-X, Suzaku/WAM, and HESS telescopes. Within the positional uncertainty arc of the new object, we found no other X-ray sources down to limiting flux levels of approximately 3×10^-12 erg cm^-2 s^-1 (0.2 - 10 keV). Consequently, it appears unlikely that this source is associated with any known types of X-ray binaries or active galactic nuclei.",
        "ori-fast-z-score": -0.5897678246195885,
        "water-fast-z-score": 4.718142596956708,
        "rewrite-fast-z-score": 0.282842712474619
    },
    {
        "original_text": "We present new exact solutions to the Einstein field equations for stationary axisymmetric spacetimes with two commuting Killing vectors, which are generated by applying nonholonomic frame transforms (NFT) to known vacuum solutions. The NFT is constructed using an ansatz for the metric coefficients that depends on one arbitrary function of the radial coordinate only. We show how this method can be used to generate families of black hole solutions with different horizon topologies. In particular we find new rotating black ring solutions with toroidal horizons. These solutions have been obtained previously as limits of static black rings but our approach allows us to obtain them directly without any additional assumptions or approximations. Finally, we discuss some open problems related to these results. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq \nI. INTRODUCTORY REMARkS\nThe study of exact solutions to the Einstein equations has played a crucial role in understanding many aspects of general relativity. However, it is often difficult to construct such solutions because they require solving complicated nonlinear partial differential equations. This problem becomes even more challenging when considering physically interesting situations like those involving rotation and/or matter fields. Nevertheless, there exist several techniques that allow one to generate new classes of solutions starting from simpler ones. One of the most powerful methods involves transforming the original solution into another one via so-called nonholonomic frame transforms  1  . Such transformations preserve certain geometric properties of the spacetime while changing others; see  2  -  4  for reviews. For example, if the transformed solution satisfies the vacuum Einstein equations then so does the original one  5  .\nIn this work we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations in order to generate new exact solutions describing stationary axisymmetric spacetimes: i.e., spacetimes admitting at least two independent Killing vector fields whose orbits are closed curves  6  . Stationary axisymmetric spacetimes play an important role in astrophysics since they describe the exterior gravitational field of spinning objects like stars, planets, and black holes  7, 8 ",
        "watermark_text": "We introduce novel exact solutions to the Einstein field equations for stationary axisymmetric spacetimes with two commuting Killing vectors , which are produced by using nonholonomic frame transforms ( NFT ) to known vacuum solutions . The NFT is built using an ansatz for the metric coefficients that relies on one arbitrary function of the radial coordinate only .We see how this algorithm can be used to create families of grey hole problems with various horizon topologies . In particular we find unique spinning black ring solutions with toroidal horizons .These solutions have been achieved formerly as limits of static black rings but our approach allows us to obtain them directly without any additional constraints or approximations . Finally , we explain some open problems related to these results .PACS codes : 04 . 20 . - q , 11 . 10 . - z , 98 . 80 . Cq I . INTRODUCTORY REMARkS The investigation of precise solutions to the Einstein equations has held a crucial role in understanding several parts of general relativity .However , it is often challenging to build such problems because they demand solving complicated nonlinear partial differential equations . This problem remains especially more challenging when exploring physically exciting situations like those concerning rotation and / or matter forces .Nevertheless , there remain many procedures that enable one to create fresh categories of solutions starting from simpler ones . One of the most popular methods means mapping the previous solve into another one via so - called nonholonomic frame transforms 1 .Such transformations maintain certain geometric properties of the spacetime while altering others ; look 2 - 4 for reviews . For instance , if the transformed solution satisfies the vacuum Einstein equations then so does the previous one 5 .In this research we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations in order to create novel exact solutions governing stationary axisymmetric spacetimes : i . e . , spacetimes admitting at least two independent Killing matrix fields whose orbits are closed curves 6 . Stationary axisymmetric spacetimes serve an important role in astrophysics since they describe the exterior gravitational field of spinning objects like stars , planets , and dark holes 7 , 8",
        "rewrite_text": "We present innovative exact solutions to the Einstein field equations for stationary axisymmetric spacetimes characterized by two commuting Killing vectors. This is achieved through nonholonomic frame transforms (NFT) applied to known vacuum solutions. The NFT is constructed using a metric coefficient ansatz that depends solely on an arbitrary function of the radial coordinate. Our method demonstrates how this algorithm can generate families of grey hole scenarios featuring different horizon topologies. Notably, we discover distinct spinning black ring solutions with toroidal horizons. Although these solutions have previously been obtained as limits of static black rings, our approach allows for their direct derivation without the need for additional constraints or approximations. Lastly, we discuss several open problems associated with these findings. PACS codes: 04.20.-q, 11.10.-z, 98.80.Cq \n\nI. INTRODUCTORY REMARKS \n\nThe search for precise solutions to Einstein's equations is essential for a deeper understanding of general relativity. However, formulating such solutions is often difficult due to the need to solve complex nonlinear partial differential equations. This challenge is further amplified when considering dynamic scenarios involving rotation and/or matter. Nevertheless, various methodologies exist that facilitate the generation of new classes of solutions from simpler ones. A well-known technique involves mapping existing solutions into new ones via nonholonomic frame transforms. These transformations preserve specific geometric properties of spacetime while altering others; see references 2-4 for reviews. For example, if the transformed solution satisfies the vacuum Einstein equations, then the original solution does as well. In this study, we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations, thereby deriving new exact solutions relevant to stationary axisymmetric spacetimes—those that exhibit at least two independent Killing vector fields with closed orbits. Such spacetimes play a crucial role in astrophysics, as they describe the external gravitational fields of rotating bodies like stars, planets, and black holes.",
        "ori-fast-z-score": -1.3805369799252667,
        "water-fast-z-score": 7.777427086962838,
        "rewrite-fast-z-score": 1.397070946271399
    },
    {
        "original_text": "We present new observations at 5 GHz and 8.4 GHz with the VLA in A-configuration, which reveal that the nuclear region of the Seyfert 1.5 galaxy NGC5033 is dominated by two compact components separated by ~0.3 arcsec (~500 pc). The northern component has an inverted spectrum between 5-8.4GHz while the southern one shows a steep spectral index consistent with optically-thin synchrotron radiation. We find no evidence for extended emission on scales larger than 0.1 arcsec (100pc) around either source. These results are discussed within the context of models where relativistic jets interact strongly with their environment to produce shocks and particle acceleration. In this scenario we propose that the northern component may be associated with a young jet emerging from the nucleus, whereas the southern one could represent older material ejected earlier during the activity cycle of the AGN. \n \n Keywords: Radio galaxies",
        "watermark_text": "We present new experiments at 5 GHz and 8 . 4 GHz with the VLA in A - configuration , which confirm that the nuclear portion of the Seyfert 1 . 5 galaxy NGC5033 is dominated by two compact components joined by ~ 0 . 3 arcsec ( ~ 500 pc ) . The southeastern component has an inverted spectrum between 5 - 8 . 4GHz while the southern one exhibits a steep spectral index consistent with optically - thin synchrotron emission .We see no evidence for extended emitted on scales bigger than 0 . 1 arcsec ( 100pc ) around either source . These conclusions are discussed within the context of models where relativistic jets interact heavily with their environment to produce shocks and electron acceleration .In this situation we propose that the northern component may be involved with a young jet developing from the nucleus , whereas the southern one might represent older material expelled prior during the activity process of the AGN . Keywords : Radio galaxies",
        "rewrite_text": "We present new observations at 5 GHz and 8.4 GHz using the VLA in its A-configuration, which demonstrate that the nuclear region of the Seyfert 1.5 galaxy NGC 5033 is comprised of two compact components separated by approximately 0.3 arcseconds (about 500 parsecs). The southeastern component displays an inverted spectrum between 5 and 8.4 GHz, while the southern component shows a steep spectral index indicative of optically-thin synchrotron emission. No evidence of extended emission on scales larger than 0.1 arcseconds (100 parsecs) is detected surrounding either source. These findings are discussed in relation to models in which relativistic jets heavily interact with their surroundings, leading to shock formation and electron acceleration. We propose that the northern component may be associated with a young jet emerging from the nucleus, while the southern component could represent older material expelled earlier during the active galactic nucleus activity. Keywords: Radio galaxies.",
        "ori-fast-z-score": -1.25,
        "water-fast-z-score": 4.157609203101499,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "The effect of silver and indium on the magnetic properties, electrical resistivity (ER) and Hall coefficient (R H ) has been investigated in La 2/3 Ca 1/3 Mn O 3 . The results show that ER decreases with increasing temperature for all samples while R H increases with decreasing temperature. It is found that both silver and indium doping decrease T C , increase J c and enhance pinning force density F p . Silver doped sample shows higher values of J c than indium doped one at low temperatures but lower value at high temperatures.  These results are explained by considering different effects of silver and indium ions on the microstructure as well as their influence on oxygen vacancies concentration. This work was supported by the National Natural Science Foundation of China under Grant No. 50571040. We would like to thank Prof. Y. M. Wu for his help during this research. Abstract: In this study we have prepared two series of La 2/3 Ca 1/3 MnO 3 :Ag and La 2/3 Ca 1/3 MnO3 :In polycrystalline composite materials using solid state reaction method. X-ray powder diffraction patterns confirm single phase formation without any impurity peaks. The structural parameters such as lattice constant, unit cell volume and bond length were calculated from XRD data. The dc magnetization measurements reveal that Curie temperature (Tc), critical current density (Jc) and pinning force density (Fp) decrease with increasing amount of silver or indium content.",
        "watermark_text": "The impact of silver and indium on the magnetic properties , thermal resistivity ( ER ) and Hall coefficient ( R H ) has been investigated in La 2 / 3 Ca 1 / 3 Mn O 3 . The results show that ER decreases with expanding temperature for all specimens while R H increases with varying temperature .It is found that both silver and indium doping change T C , enhance J c and enhance pinning power concentration F p . Silver doped specimen shows better levels of J c than indium doped one at low temperatures but smaller value at high temperatures .These data are explained by examining different impacts of silver and indium ions on the microstructure as also as their influence on oxygen vacancies density . This research was supported by the National Natural Science Foundation of China under Grant No .50571040.We would like to thank Prof. Y. M. Wu for his help during this research.Abstract : In this study we have formed two sequence of La 2 / 3 Ca 1 / 3 MnO 3 : Ag and La 2 / 3 Ca 1 / 3 MnO3 : In polycrystalline composite materials utilizing solid state process method . X - ray powder diffraction patterns indicate single phase form without any impurity peaks .The structural values such as structure constant , unit cell size and bond length were calculated from XRD information . The dc magnetization calculations reveal that Curie temperature ( Tc ) , vital current density ( Jc ) and pinning power concentration ( Fp ) decline with varying amount of silver or indium content .",
        "rewrite_text": "The influence of silver and indium on the magnetic properties, thermal resistivity (ER), and Hall coefficient (RH) of La2/3Ca1/3MnO3 has been examined. The findings indicate that ER decreases with increasing temperature for all samples, while RH rises with temperature variations. It was observed that both silver and indium doping alter the Curie temperature (TC), enhance the critical current density (JC), and increase the pinning power concentration (FP). At low temperatures, the silver-doped samples exhibit superior JC compared to the indium-doped samples, though the latter demonstrate higher values at elevated temperatures. These observations are attributed to the differing effects of silver and indium ions on the microstructure and their influence on the density of oxygen vacancies. This research received support from the National Natural Science Foundation of China under Grant No. 50571040. We extend our gratitude to Prof. Y. M. Wu for his assistance throughout this study. \n\nAbstract: In this investigation, we developed two sequences of polycrystalline composite materials: La2/3Ca1/3MnO3:Ag and La2/3Ca1/3MnO3:In, utilizing a solid-state processing method. X-ray powder diffraction patterns confirmed a single-phase structure with no detectable impurity peaks. We calculated structural parameters such as lattice constant, unit cell size, and bond length from the XRD data. DC magnetization measurements demonstrated that the Curie temperature (TC), critical current density (JC), and pinning power concentration (FP) decrease with varying levels of silver or indium content.",
        "ori-fast-z-score": 0.8081220356417685,
        "water-fast-z-score": 7.677159338596802,
        "rewrite-fast-z-score": 1.6915632233569815
    },
    {
        "original_text": "We present the results of our investigation on semiclassical scalar propagator in curved space-time, which is based on the WKB approximation to the wave function. We show that there are two different ways how one can define this quantity depending on whether or not one takes into account the back-reaction effects due to the quantum fluctuations of the gravitational field. The first approach leads to an expression for the semiclassical propagator which coincides with the Feynman propagator at large distances but differs significantly near the source point. In particular it does not satisfy the Hadamard condition required by general relativity. On the other hand, if we take into account the back reaction then the resulting expression satisfies all necessary conditions including the Hadamard condition. However, as was shown recently by Wald et al., such an expression cannot be obtained within the framework of standard QFT. This problem may have important consequences when considering the propagation of particles through black holes since the corresponding expressions differ substantially even outside the horizon.",
        "watermark_text": "We present the conclusion of our analysis on semiclassical scalar propagator in curved space - time , which is based on the WKB approximation to the wave function . We see that there are two different ways how one can define this quantity based on whether or not one takes into consideration the back - reaction effects due to the quantum fluctuations of the gravitational field .The first method results to an definition for the semiclassical propagator which coincides with the Feynman propagator at large distances but varies dramatically near the origin point . In particular it does not satisfy the Hadamard condition required by general relativity .On the other hand , if we took into consideration the back response then the resulting expression satisfies all necessary circumstances including the Hadamard condition . However , as was shown lately by Wald et al . , such an form cannot be obtained within the framework of standard QFT .This problem could have important implications when examining the propagation of particles through black holes since the equivalent definitions differ substantially even outside the horizon .",
        "rewrite_text": "We present the findings of our analysis on the semiclassical scalar propagator in curved spacetime, which employs the WKB approximation for the wave function. Our investigation reveals two distinct methods for defining this quantity, depending on whether the back-reaction effects from quantum fluctuations of the gravitational field are taken into account. The first method yields a definition for the semiclassical propagator that aligns with the Feynman propagator at large distances but exhibits significant variations near the origin. Notably, this approach does not satisfy the Hadamard condition mandated by general relativity. Conversely, when the back-reaction is considered, the resulting expression meets all the necessary criteria, including compliance with the Hadamard condition. However, as recent work by Wald et al. has demonstrated, such a form cannot be derived within the standard framework of quantum field theory. This issue may have critical implications for understanding particle propagation in the vicinity of black holes, since the alternative definitions yield substantially different results even outside the event horizon.",
        "ori-fast-z-score": 0.5698028822981898,
        "water-fast-z-score": 5.128225940683707,
        "rewrite-fast-z-score": 1.2074068598865937
    },
    {
        "original_text": "In this work, we propose an evolutionary algorithm to evolve ensemble classifiers in the context of multi-class classification problems. The proposed approach is based on the combination of two well-known techniques: genetic algorithms and bagging. We have conducted experiments using several datasets taken from UCI Machine Learning Repository. Our results show that our method outperforms other state-of-the-art methods such as Bagging or Random Forests. In addition, it has been shown that the use of ensembles can improve the performance of single models evolved by Genetic Programming (GP). This fact suggests that GP could be used not only to evolve individual solutions but also to evolve whole ensembles of solutions. Keywords: Ensemble learning, Multi-Class Classification, Genetic Algorithm, Bagging. 1 Introduction Ensembles are collections of multiple base learners whose outputs are combined into one final prediction  1  . They are widely used because they often provide better accuracy than any of their constituent members  2  .\nThe most popular approaches to combine predictions include voting schemes  3  , stacking  4  , boosting  5  , and blending  6  . However, these approaches require some knowledge about how to combine the output of each member of the ensemble  7?   . For example, if there are three classes, then the simplest way would be to assign equal weights to all the classifiers; however, this may lead to poor performance when dealing with imbalanced data  8  . Other more sophisticated ways involve assigning different weights according to the confidence level of each classifier  9  ; however, finding optimal values for those parameters requires additional effort  10  .\nRecently, researchers have started exploring new ways to automatically generate ensembles without requiring prior information  11  . One of them involves combining genetic algorithms  12  and bagging  13  . These two techniques were first applied separately  14, 15  , but later they were integrated together  16  .",
        "watermark_text": "In this research , we propose an phylogenetic algorithm to evolve ensemble classifiers in the context of multi - class classification difficulties . The proposed approach is based on the combination of two well - famous strategies : genetic methods and bagging .We have done research utilizing multiple datasets taken from UCI Machine Learning Repository . Our results show that our technique outperforms other state - of - the - art methods such as Bagging or Random Forests .In addition , it has been shown that the using of ensembles can increase the performance of single models adapted by Genetic Programming ( GP ) . This fact suggests that GP may be used not only to evolve individual solutions but also to evolve entire groups of solutions .Keywords : Ensemble learning , Multi - Class Classification , Genetic Algorithm , Bagging . 1 Introduction Ensembles are collections of multiple base learners whose outputs are united into one finished prediction 1 .They are widely using because they frequently provide better precision than any of their constituent groups 2 . The most popular methods to mix predictions include voting strategies 3 , stacking 4 , boosting 5 , and blending 6 .However , these perspectives need some understanding about how to mix the output of each member of the group 7 ? .For instance , if there are three categories , then the simplest manner might be to give equivalent weights to all the classifiers ; however , this might lead to bad performance when dealing with imbalanced data 8 . Other more sophisticated ways include assigning multiple weights based to the confidence rate of each classifier 9 ; however , finding ideal values for those variables requires added effort 10 .Recently , researchers have started researching new ways to automatically generate ensembles without using prior information 11 . One of them requires merging genetic methods 12 and bagging 13 .These two procedures were first applied separately 14 , 15 , but later they were integrated together 16 .",
        "rewrite_text": "In this study, we present a phylogenetic algorithm designed to evolve ensemble classifiers for addressing multi-class classification challenges. Our proposed method combines two well-established strategies: genetic algorithms and bagging techniques. We conducted experiments using several datasets from the UCI Machine Learning Repository, and our findings indicate that our approach outperforms leading methods such as Bagging and Random Forests. Furthermore, our results demonstrate that employing ensembles can enhance the performance of individual models optimized by Genetic Programming (GP). This suggests that GP can be utilized not only to evolve singular solutions but also to develop entire groups of solutions. \n\n**Keywords:** Ensemble learning, Multi-Class Classification, Genetic Algorithm, Bagging.\n\n1. **Introduction**  \nEnsembles are collections of multiple base learners whose predictions are integrated into a single final prediction. They are widely adopted because they often yield greater accuracy than any individual model. Common methods for combining predictions include voting strategies, stacking, boosting, and blending. However, these approaches require an understanding of how to effectively combine the outputs of each ensemble member. For example, in a scenario with three categories, a straightforward method might assign equal weights to all classifiers; however, this can result in poor performance when dealing with imbalanced datasets. More sophisticated approaches involve assigning varying weights based on the confidence level of each classifier, but determining the optimal values for these weights can be labor-intensive. Recently, researchers have begun exploring new automated methods for generating ensembles without relying on prior knowledge. One approach integrates genetic methods with bagging, which were historically applied independently but have since been combined to enhance performance.",
        "ori-fast-z-score": -0.42717882885838043,
        "water-fast-z-score": 8.397070403831712,
        "rewrite-fast-z-score": 1.4967665407535604
    },
    {
        "original_text": "In this note we present some comments on the examples given in  1  and  2  . We show that these examples are not counterexamples to the generalized Jacobian conjecture, as stated by M. Laurent (see  3  ). In fact they do not even contradict the weaker statement made by J.-P. Serre  4  , which is equivalent to the Jacobian conjecture for curves over finite fields. Finally we give an example showing how one can construct counterexamples to the generalized Jacobi conjecture using our method. Let k be any field with char(k) = p > 0. For every integer n ≥ 1 let Xn denote the smooth projective curve defined over k by y n + a1yn−1 + · · · + anny0 = xn+1,\nwhere ai ∈ k * . It was shown by A. N. Parshin  5  that if char(k) = 2 then there exists a positive integer m such that the jacobian variety JacXm has complex multiplication. This implies that the jacobian varieties JacXn have complex multiplication for all integers n ≡ ±1 mod m. If char(k) = 3 it follows from  6  that JacX3 does not have complex multiplication. However, it still remains open whether or not JacX4 has complex multiplication.",
        "watermark_text": "In this note we present some remarks on the examples given in 1 and 2 . We see that these objects are not counterexamples to the generalized Jacobian conjecture , as described by M . Laurent ( saw 3 ) .In reality they do not even contradict the weaker statement provided by J . - P . Serre 4 , which is analogous to the Jacobian conjecture for curves over finite fields . Finally we give an instance demonstrating how one can build counterexamples to the generalized Jacobi theorem using our technique .Let k be any field with char ( p ) = p > 0 . For every integer n ≥ 1 let Xn represent the smooth projective curve defined over k by y n + a1yn−1 + · · · + anny0 = xn + 1 , where ai ∈ k * .It was shown by A . N . Parshin 5 that if char ( k ) = 2 then there exists a positive integer m such that the jacobian variety JacXm has complex multiplication . This implies that the jacobian varieties JacXn have complex multiplication for all numbers n ≡ ±1 mod m . If char ( k ) = 3 it appears from 6 that JacX3 does not have complex multiplication .However, it still remains open whether or not JacX4 has complex multiplication.",
        "rewrite_text": "In this note, we provide some observations on the examples discussed in sections 1 and 2. We establish that these examples do not serve as counterexamples to the generalized Jacobian conjecture, as articulated by M. Laurent (see 3). In fact, they do not even contradict the more lenient assertion made by J.-P. Serre (4), which parallels the Jacobian conjecture for curves over finite fields. Additionally, we present an example illustrating how our method can be employed to construct counterexamples to the generalized Jacobi theorem. Let \\( k \\) be any field with characteristic \\( p \\) where \\( p > 0 \\). For every integer \\( n \\geq 1 \\), let \\( X_n \\) denote the smooth projective curve defined over \\( k \\) by the equation \\( y^n + a_1y^{n-1} + \\ldots + a_ny^0 = x^n + 1 \\), with \\( a_i \\in k^* \\). A. N. Parshin (5) demonstrated that if \\( \\text{char}(k) = 2 \\), then there exists a positive integer \\( m \\) such that the Jacobian variety \\( \\text{Jac} X_m \\) features complex multiplication. This indicates that the Jacobian varieties \\( \\text{Jac} X_n \\) exhibit complex multiplication for all \\( n \\equiv \\pm 1 \\mod m \\). However, if \\( \\text{char}(k) = 3 \\), it appears from (6) that \\( \\text{Jac} X_3 \\) lacks complex multiplication. Nonetheless, it remains uncertain whether \\( \\text{Jac} X_4 \\) possesses complex multiplication.",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 5.497624996033735,
        "rewrite-fast-z-score": 2.038098661460272
    },
    {
        "original_text": "We present an improved abundance determination for the black hole binary nova Sco X-1, based on high-resolution optical spectroscopy obtained with UVES at VLT-UT2 in November 2004 and January 2005. The new data are combined with previously published results to derive abundances for CNO elements as well as FeI and FeII lines. We find that our best-fit model is consistent with previous studies within their uncertainties. However, we obtain significantly lower values for carbon and oxygen than those reported by Gies & Bolton (1986) . This discrepancy may be due to differences between the adopted atmospheric models or atomic data used in these two analyses. \n \n Keywords: Black holes - Abundance ratios - X-ray binaries - Spectroscopy - Ultraviolet space observatories - Variability - Velocity fields - Stellar winds - Mass transfer -X-ray emission - Accretion disks - Novae - Supernovae",
        "watermark_text": "We report an updated abundance calculation for the dark hole binary nova Sco X - 1 , using on high - resolution optical spectroscopy achieved with UVES at VLT - UT2 in November 2004 and January 2005 . The revised data are coupled with former reported results to derive abundances for CNO objects as well as FeI and FeII lines .We see that our better - fitting model is compatible with previous research within their uncertainties . However , we obtain significantly reduced estimates for carbon and oxygen than those observed by Gies & Bolton ( 1986 ) .This discrepancy may be due to differences between the preferred atmospheric models or atomic data used in these two analyses . Keywords : Black holes - Abundance ratios - X - ray binaries - Spectroscopy - Ultraviolet space observatories - Variability - Velocity fields - Stellar weather - Mass transmission - X - ray radiation - Accretion disks - Novae - Supernovae",
        "rewrite_text": "We present an updated abundance calculation for the black hole binary Nova Sco X-1, utilizing high-resolution optical spectroscopy obtained with UVES at VLT-UT2 in November 2004 and January 2005. This new data, combined with previously reported results, allows us to determine the abundances for CNO elements as well as FeI and FeII lines. Our improved model aligns with earlier studies within their uncertainties. However, we find significantly lower estimates for carbon and oxygen compared to the results reported by Gies & Bolton (1986). This difference may stem from variations in the atmospheric models or atomic data utilized in the two analyses. \nKeywords: Black holes, abundance ratios, X-ray binaries, spectroscopy, ultraviolet space observatories, variability, velocity fields, stellar weather, mass transmission, X-ray radiation, accretion disks, novae, supernovae.",
        "ori-fast-z-score": -0.7878385971583353,
        "water-fast-z-score": 5.3452248382484875,
        "rewrite-fast-z-score": -0.3841106397986879
    },
    {
        "original_text": "We present new results on the incidence and properties of intervening absorbers along the sightline towards GRB 080913, based on high-resolution spectroscopy obtained with X-shooter at VLT-UT2 (ESO program ID 080.A-9007). We detect two strong absorption systems in the spectrum of this burst, one associated with an intervening galaxy at z = 1.5394 ± 0.0002, and another system at z = 2.084 ± 0.001 that is likely due to a damped Lyman alpha absorber. The latter has been previously detected by Fynbo et al. (2009) using low resolution spectra taken with FORS-2/VLT. Our analysis shows that both these systems are rich in metals, including Si II, Mg II, Fe II, Al III, O I, N V, and possibly also C IV. In addition we find evidence for several weaker metal lines which may be associated with either or both of these systems.",
        "watermark_text": "We report new data on the incidence and properties of intervening absorbers along the sightline towards GRB 080913 , using on wide - resolution spectroscopy acquired with X - shooter at VLT - UT2 ( ESO program ID 080 . A - 9007 ) . We detect two strong absorption complexes in the spectrum of this burst , one linked with an intervening galaxy at z = 1 . 5394 ± 0 . 0002 , and another system at z = 2 . 084 ± 0 . 001 that is probably due to a damped Lyman alpha absorber .The latter has been previously observed by Fynbo et al . ( 2009 ) using small resolution spectra made with FORS - 2 / VLT .Our study shows that both these systems are rich in metals , notably Si II , Mg II , Fe II , Al III , O I , N V , and maybe also C IV . In addition we find proof for numerous smaller metal bands which may be identified with either or both of these systems .",
        "rewrite_text": "We present new findings on the incidence and characteristics of intervening absorbers along the sightline to GRB 080913, utilizing high-resolution spectroscopy obtained with X-shooter at VLT-UT2 (ESO program ID 080.A-9007). Our analysis reveals two prominent absorption complexes in the spectrum of this burst: one associated with an intervening galaxy at redshift z = 1.5394 ± 0.0002, and another likely linked to a damped Lyman alpha absorber at z = 2.084 ± 0.001. The latter system had been previously identified by Fynbo et al. (2009) using lower resolution spectra from FORS-2/VLT. Our research indicates that both of these systems are metal-rich, containing elements such as Si II, Mg II, Fe II, Al III, O I, N V, and possibly C IV. Furthermore, we have identified several smaller metal absorption features that may correspond to one or both of these systems.",
        "ori-fast-z-score": -1.6641005886756874,
        "water-fast-z-score": 3.6055512754639896,
        "rewrite-fast-z-score": -1.979898987322333
    },
    {
        "original_text": "We report infrared (IR) spectroscopic studies on the formation and evolution of formic acid, HCOOH, in ices under simulated astrophysical conditions. The experiments were performed by exposing pure water or mixtures of H2O with CH3OH to vacuum ultraviolet radiation at 10 K for different periods up to 100 hours. IR spectra show that the amount of HCOOH increases as a function of irradiation time. We also find evidence for the presence of other species such as CO2, CO, CH4, NH3, H2S, SO2, and OCS. These results are discussed within the context of astrochemical models. Formic acid is one of the most abundant organic molecules found in space. It has been detected towards comets, protostars, and evolved stars. In particular, it was observed in comet 67P/Churyumov-Gerasimenko during its flyby of the Rosetta spacecraft. However, despite this ubiquity, our understanding about how formic acid forms in space remains limited. Here we present laboratory investigations into the formation pathways of formic acid in icy environments using infrared spectroscopy.",
        "watermark_text": "We report imaging ( IR ) spectroscopic studies on the formation and evolution of formic acid , HCOOH , in ices under modeled astrophysical conditions . The studies were performed by exposing pure water or mixtures of H2O with CH3OH to vacuum ultraviolet radiation at 10 K for different times up to 100 hours .IR spectra show that the quantity of HCOOH changes as a function of irradiation time . We additionally find proof for the presence of other species such as CO2 , CO , CH4 , NH3 , H2S , SO2 , and OCS .These data are discussed within the context of astrochemical models . Formic acid is one of the most abundant chemical molecules seen in space .It has been detected towards comets , protostars , and evolved planets . In particular , it was seen in comet 67P / Churyumov - Gerasimenko during its flyby of the Rosetta spacecraft .However , despite this ubiquity , our knowing about how formic oxide occurs in space remains restricted . Here we present lab studies into the formation routes of formic ethanol in icy environments using infrared spectroscopy .",
        "rewrite_text": "We present imaging (IR) spectroscopic studies focused on the formation and evolution of formic acid (HCOOH) in ices under simulated astrophysical conditions. Our investigations involved subjecting pure water or mixtures of H2O and CH3OH to vacuum ultraviolet radiation at 10 K for varying durations, up to 100 hours. The IR spectra reveal that the concentration of HCOOH varies with the duration of irradiation. Additionally, we provide evidence for the presence of other species, including CO2, CO, CH4, NH3, H2S, SO2, and OCS. These findings are analyzed within the framework of astrochemical models. Formic acid is one of the most prevalent chemical compounds detected in space, having been observed in comets, protostars, and evolved planets. Notably, it was identified in comet 67P/Churyumov-Gerasimenko during the Rosetta spacecraft's flyby. Despite its widespread presence, our understanding of how formic acid forms in space remains limited. In this study, we investigate the pathways for the formation of formic acid in icy environments using infrared spectroscopy.",
        "ori-fast-z-score": 0.3779644730092272,
        "water-fast-z-score": 5.5,
        "rewrite-fast-z-score": 1.0327955589886444
    },
    {
        "original_text": "We describe an infrared cloud monitor that has been developed to detect clouds in the atmosphere above the Magellan Observatory on Mt. Haleakala, Hawaii. The system uses two near-infrared cameras and is designed to operate continuously during nighttime hours when astronomical observations are made with the telescope. It provides information about the sky conditions over the entire field-of-view (FOV) of the telescope s primary mirror. This information can be used by observers to select targets or to modify their observing strategies accordingly. We present results obtained using this instrumentation since its installation in August 2005. These data show that the atmospheric transparency varies significantly across the FOV of the telescope. For example, we find that the median value of the total integrated water vapor column density measured within one hour of each observation was 0.5 mm H2O for the northern part of the FOV but 1.1 mm H2O for the southern portion. We also demonstrate how these measurements have helped us optimize our observational strategy.",
        "watermark_text": "We describe an infrared cloud monitor that has been created to identify clouds in the atmosphere above the Magellan Observatory on Mt . Haleakala , Hawaii .The system utilizes two near - infrared lenses and is designed to run constantly during nighttime days when scientific measurements are making with the observatory . It provides information about the sky conditions over the entire field - of - view ( FOV ) of the observatory s primary mirror .This knowledge can be used by observers to select locations or to modify their viewing strategies accordingly . We report findings obtained using this apparatus since its installation in August 2005 .These data demonstrate that the atmospheric stability differs greatly across the FOV of the observatory . For instance , we find that the average value of the total integrated water vapor column density measured within one minute of each measurement was 0 . 5 mm H2O for the northern part of the FOV but 1 . 1 mm H2O for the southern portion .We additionally prove how these measurements have aided us optimize our observational strategy .",
        "rewrite_text": "We present an infrared cloud monitor developed to detect clouds in the atmosphere over the Magellan Observatory on Mt. Haleakala, Hawaii. This system employs two near-infrared lenses and is designed to operate continuously during the nighttime hours when scientific measurements are being conducted at the observatory. It offers insights into sky conditions across the entire field of view (FOV) of the observatory's primary mirror, enabling observers to choose locations or adjust their viewing strategies accordingly. We share findings collected since the installation of the device in August 2005. The data reveals significant variations in atmospheric stability throughout the observatory's FOV. For example, the average total integrated water vapor column density measured within one minute of each observation was 0.5 mm H2O in the northern section of the FOV compared to 1.1 mm H2O in the southern section. Moreover, we demonstrate how these measurements have helped us enhance our observational approach.",
        "ori-fast-z-score": -1.3764944032233704,
        "water-fast-z-score": 5.735393346764043,
        "rewrite-fast-z-score": 2.092457497388747
    },
    {
        "original_text": "Graphene nanoribbons (GNRs) are promising candidates for future nanoelectronic devices due to their unique electronic properties and high carrier mobility at room temperature. However, the scaling behaviors of GNRFETs have not been fully understood yet because of the difficulty in simulating realistic device structures with atomistic details using conventional approaches such as density functional theory or tight-binding method. In this work, we perform large-scale quantum transport simulations on GNR-FETs by solving the nonequilibrium Green s function equations within an effective mass approximation. We find that the subthreshold swing decreases rapidly when the channel length is reduced below 10 nm while it increases slowly beyond 20 nm. The ON/OFF current ratio also shows similar trends but its value becomes saturated around 100 nm. These results suggest that the optimal channel length should be between 10-20 nm depending on the required performance parameters. Our findings can provide useful guidelines for designing practical graphene-based transistors.",
        "watermark_text": "Graphene nanoribbons ( GNRs ) are promising candidates for future nanoelectronic devices owing to their distinct mechanical behavior and large carrier movement at room temperature . However , the scaling interactions of GNRFETs have not been totally understood yet because of the difficulty in simulating realistic device designs with atomistic features using conventional approaches such as density functional theory or tight - binding method .In this research , we perform large - scale quantum carrier simulations on GNR - FETs by solving the nonequilibrium Green s function equations within an effective mass approximation . We see that the subthreshold swing decreases quickly when the channel length is decreased below 10 nm while it rises steadily beyond 20 nm .The ON / OFF present ratio therefore displays similar trends but its value gets saturated around 100 nm . These data suggest that the ideal network duration should be between 10 - 20 mm depending on the necessary performance parameters .Our findings can provide useful guidelines for constructing practical graphene - based transistors .",
        "rewrite_text": "Graphene nanoribbons (GNRs) are promising candidates for future nanoelectronic devices due to their unique mechanical properties and high carrier mobility at room temperature. However, the scaling interactions of GNR field-effect transistors (GNRFETs) remain inadequately understood, largely due to the challenges associated with simulating realistic device designs that incorporate atomistic features using traditional methods like density functional theory or the tight-binding approach. In this study, we conduct extensive quantum carrier simulations on GNRFETs by solving the nonequilibrium Green's function equations under an effective mass approximation. Our results show that the subthreshold swing decreases rapidly when the channel length is reduced to below 10 nm, while it increases steadily for lengths greater than 20 nm. Consequently, the ON/OFF current ratio exhibits similar patterns, but saturates around 100 nm. These findings indicate that an optimal channel length should fall between 10 and 20 nm based on the desired performance metrics. Our results provide valuable insights for the development of practical graphene-based transistors.",
        "ori-fast-z-score": 0.8834522085987723,
        "water-fast-z-score": 6.184165460191406,
        "rewrite-fast-z-score": 1.193117518002609
    },
    {
        "original_text": "We present new measurements of 3 He+ and 3 He++ column densities toward eight nearby stars, using data obtained with the Far Ultraviolet Spectroscopic Explorer (FUSE). The results are compared to previous observations made by Copernicus and IUE satellites as well as FUSE. We find that our values for N(3 He+)/N(H+), which range between 0.0015-0.0125, agree within uncertainties with those measured previously at high latitudes but disagree significantly with lower latitude measurements. Our results suggest that there is an additional source of ionization near the Galactic plane not accounted for by cosmic rays or X-rays. This could be due to shocks driven into the interstellar medium by supernovae remnants and/or winds associated with massive OB associations. \n \n Keywords: Helium abundance, Interstellar medium, Shocks, Supernova remnant, Winds, Cosmic ray",
        "watermark_text": "We present new surveys of 3 He + and 3 He + + column densities toward eight distant stars , using data acquired with the Far Ultraviolet Spectroscopic Explorer ( FUSE ) . The results are compared to previous images conducted by Copernicus and IUE missions as well as FUSE .We see that our values for N ( 3 He + ) / N ( H + ) , which range between 0 . 0015 - 0 . 0125 , agree within uncertainties with those observed previously at high latitudes but disagree significantly with higher latitude observations . Our results propose that there is an additional source of ionization near the Galactic jet not accounted for by cosmic rays or X - radiation .This might be due to shocks driven into the interstellar medium by supernovae fragments and / or winds related with massive OB interactions . Keywords : Helium abundance , Interstellar medium , Shocks , Supernova remnant , Winds , Cosmic ray",
        "rewrite_text": "We present new surveys of the column densities of 3 He + and 3 He + + toward eight distant stars, utilizing data from the Far Ultraviolet Spectroscopic Explorer (FUSE). Our findings are compared with earlier observations from the Copernicus and IUE missions, alongside previous FUSE data. The measured ratios of N(3 He +) / N(H +), which range from 0.0015 to 0.0125, show good agreement within uncertainties with previously obtained measurements at high latitudes, but display significant discrepancies with observations at higher latitudes. These results suggest the presence of an additional ionization source near the Galactic jet that is not explained by cosmic rays or X-radiation. This additional ionization may result from shocks in the interstellar medium caused by remnants of supernova explosions and/or winds associated with massive OB star interactions. \nKeywords: Helium abundance, interstellar medium, shocks, supernova remnant, winds, cosmic rays.",
        "ori-fast-z-score": -0.42857142857142855,
        "water-fast-z-score": 4.428571428571429,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We present the results for charged hadron multiplicity density and transverse momentum fluctuations obtained by using the AMPT model with string melting mechanism at RHIC energies. The effect of initial parton distribution is studied by varying the initial temperature T0, which controls the initial entropy content of the system. We find that both the mean value and fluctuation of the multiplicity density increase as we decrease the initial temperature T0. This indicates that the initial state fluctuations play an important role in determining the final observables. It has been observed experimentally that the ratio of variance to mean square (V /M) increases with decreasing beam energy. In our study also it is found that V /M decreases with increasing initial temperature T0. However, this trend changes when we include the contribution due to resonance decays. Finally, we have calculated the scaled variances S2/S1 and S3/S2 for different values of T0.",
        "watermark_text": "We present the results for charged hadron multiplicity density and longitudinal momentum fluctuations derived by using the AMPT theory with string melting system at RHIC intensity . The impact of initial parton distribution is studied by varying the first temperature T0 , which influences the first entropy concentration of the system .We see that both the mean value and fluctuation of the multiplicity density increase as we decrease the initial temperature T0 . This implies that the first state fluctuations play an important role in determining the finished observables .It has been observed experimentally that the proportion of variance to mean square ( V / M ) increases with decreasing beam energy . In our research also it is found that V / M decreases with expanding initial temperature T0 .However , this decline changes when we include the contribution owing to resonance decays . Finally , we have adjusted the scaled variances S2 / S1 and S3 / S2 for different values of T0 .",
        "rewrite_text": "We present our findings on charged hadron multiplicity density and longitudinal momentum fluctuations based on the AMPT theory utilizing a string-melting approach at RHIC intensity. We investigate the effect of the initial parton distribution by varying the initial temperature \\( T_0 \\), which affects the system's initial entropy concentration. Our results indicate that both the mean value and fluctuations of the multiplicity density increase as \\( T_0 \\) decreases. This suggests that fluctuations in the initial state significantly impact the resultant observables. Experimental data show that the variance-to-mean square ratio (V/M) rises as beam energy decreases, and our study similarly reveals that V/M diminishes with an increase in the initial temperature \\( T_0 \\). However, this trend shifts when accounting for contributions from resonance decays. Lastly, we have calibrated the scaled variances \\( S_2/S_1 \\) and \\( S_3/S_2 \\) for various \\( T_0 \\) values.",
        "ori-fast-z-score": -1.5882027766319677,
        "water-fast-z-score": 3.542913886332851,
        "rewrite-fast-z-score": 0.12803687993289598
    },
    {
        "original_text": "The Minimal Supersymmetric Standard Model (nuMSM) is an extension of the SM with three right-handed neutrinos and one additional Higgs doublet, which can explain simultaneously all known phenomena in particle physics. In this model there are two new particles - neutral leptons N_1 and N_2 that have not been observed yet experimentally. The aim of our work was to study possible production mechanisms for these particles at LHC energies. \nWe considered pair production of neutral leptons via Drell-Yan mechanism as well as single production through s-channel W-boson exchange or t-channel chargino/neutralino exchanges. We performed numerical calculations using CalcHEP package. \n \n For the case of pair production we found that cross sections decrease rapidly when masses of neutral leptons increase. This fact makes it difficult to detect such particles at LHC experiments even if their mass difference is small. On the other hand, single production processes give much higher values of cross section than those obtained for pair production. However, they also depend strongly on the value of mixing angle between left- and righthanded neutrinos.",
        "watermark_text": "The Minimal Supersymmetric Standard Model ( nuMSM ) is an extension of the SM with three right - handed neutrinos and one additional Higgs doublet , which can describe concurrently all known phenomena in particle physics . In this model there are two new ions - neutral leptons N _ 1 and N _ 2 that have not been observed yet experimentally .The goal of our work was to study possible generation pathways for these particles at LHC energies . We considered pair production of neutral leptons via Drell - Yan system as also as single production through s - channel W - boson exchange or t - channel chargino / neutralino exchanges .We conducted numerical measurements using CalcHEP package . For the case of pair production we reported that cross sections decrease rapidly when masses of neutral leptons increase .This fact makes it difficult to identify such particles at LHC observations even if their density difference is tiny . On the other hand , single production mechanisms offer significantly greater values of cross section than those achieved for pair production .However , they still depend greatly on the value of mixing angle between left - and righthanded neutrinos .",
        "rewrite_text": "The Minimal Supersymmetric Standard Model (nuMSM) extends the Standard Model by incorporating three right-handed neutrinos and an additional Higgs doublet, allowing it to simultaneously account for all known phenomena in particle physics. This model introduces two new particles—neutral leptons N_1 and N_2—that have yet to be experimentally observed. Our research aimed to explore potential production pathways for these particles at LHC energies. We examined pair production of neutral leptons through the Drell-Yan process, as well as single production via s-channel W-boson exchange or t-channel chargino/neutralino interactions. Using the CalcHEP package for numerical calculations, we found that the cross sections for pair production decrease rapidly as the masses of the neutral leptons increase, making detection difficult at the LHC, even with minimal density differences. Conversely, single production mechanisms yield significantly higher cross section values compared to pair production; however, they remain highly sensitive to the mixing angle between left- and right-handed neutrinos.",
        "ori-fast-z-score": 0.5488212999484517,
        "water-fast-z-score": 4.58257569495584,
        "rewrite-fast-z-score": 0.2182178902359924
    },
    {
        "original_text": "The purpose of this article is to give an overview of the theory of weight structures on triangulated categories developed by A. Bondal and M. Kapranov.  We will explain how it can be applied to construct new cohomology theories for algebraic varieties over finite fields or number fields.   In particular we will discuss the construction of motivic cohomology using weight structures on derived categories of mixed Tate motives.    The main results are due to J. Ayoub, D. Gaitsgory, R. Hain, S. Katzarkov, V. Lafforgue, C. Soulé, B. Stienstra, and others. This article was written as part of the author s Ph.D thesis at Utrecht University under supervision of Prof. Dr. Wim van der Kallen. It has been published online by the author with permission of the supervisor. For more information about the content see the introduction below.",
        "watermark_text": "The purpose of this page is to give an overview of the notion of weight spaces on triangulated categories established by A . Bondal and M . Kapranov . We will explain how it can be applied to build modern cohomology theories for algebraic fields over arbitrary fields or number fields .In particular we will explore the formation of motivic cohomology involving weight forms on derived categories of mixed Tate motives . The main results are due to J . Ayoub , D . Gaitsgory , R . Hain , S . Katzarkov , V . Lafforgue , C . Soulé , B . Stienstra , and others .This page was written as part of the writer s Ph . D degree at Utrecht University under supervision of Prof . Dr . Wim van der Kallen . It has been publication online by the writer with authorization of the supervisor .For more information about the content read the introduction below .",
        "rewrite_text": "This page aims to provide an overview of the concept of weight spaces within triangulated categories, as developed by A. Bondal and M. Kapranov. We will discuss how this idea can be utilized to create contemporary cohomology theories for algebraic fields over arbitrary fields or number fields. Specifically, we will investigate the construction of motivic cohomology that involves weight forms in the derived categories of mixed Tate motives. The principal findings in this area are attributed to J. Ayoub, D. Gaitsgory, R. Hain, S. Katzarkov, V. Lafforgue, C. Soulé, B. Stienstra, among others. This page is part of the author's Ph.D. research at Utrecht University, supervised by Prof. Dr. Wim van der Kallen, and has been published online with the supervisor's permission. For further details on the topic, please refer to the introduction below.",
        "ori-fast-z-score": -0.42008402520840293,
        "water-fast-z-score": 4.900980294098034,
        "rewrite-fast-z-score": 0.7001400420140048
    },
    {
        "original_text": "The possibility that an asteroid could hit the Earth is not new.  In fact, it has been discussed for many years in popular science fiction books such as H G Wells  The War of the Worlds (1898) or Arthur C Clarke s 2001 Space Odyssey (1968). However, there are now several groups around the world working on ways to deflect asteroids before they impact with our planet.   This talk will discuss how this might be achieved by using nuclear explosions, kinetic impacts, laser beams or even tractor beams. It will also look at what would happen if one were successful - would we survive?  Would life return to normal?\nThis talk was given at the University of Southampton on 24th February 2015. For more information about Prof David Jewitt please visit his website: http://www.astro.su.se/~david/ . \nProf David Jewitt is Professor of Planetary Science at the University of Southampton. He leads the Asteroid Terrestrial-impact Last Alert System (ATLAS), which monitors near-Earth objects including asteroids and comets.",
        "watermark_text": "The possibility that an asteroid could struck the Earth is not new . In reality , it has been discussed for numerous years in popular science novel publications such as H G Wells The War of the Worlds ( 1898 ) or Arthur C Clarke s 2001 Space Odyssey ( 1968 ) .However , there are now various groups around the world thinking on techniques to deflect asteroids before they impact with our planet . This discussion will explore how this might be accomplish by using nuclear explosions , kinetic crashes , laser beams or maybe tractor beams .It will also glance at what would happen if one were successful - would we survive ? Would life recover to normal ?This discussion was given at the University of Southampton on 24th February 2015 . For more information about Prof David Jewitt please visit his page : www : / / www . astro . su . se / ~ david / .Prof David Jewitt is Professor of Planetary Science at the University of Southampton . He leads the Asteroid Terrestrial - impact Last Alert System ( ATLAS ) , which monitors near - Earth objects including asteroids and comets .",
        "rewrite_text": "The concept of an asteroid striking Earth is not a recent development. In fact, it has been a topic of discussion for many years in popular science fiction, with notable works like H.G. Wells' *The War of the Worlds* (1898) and Arthur C. Clarke's *2001: A Space Odyssey* (1968). Today, various organizations around the globe are exploring methods to deflect asteroids before they collide with our planet. This discussion will examine potential techniques such as nuclear explosions, kinetic impactors, laser beams, and possibly even tractor beams. It will also consider the implications of successfully averting an asteroid strike: would we survive, and could life return to normal afterwards? This talk was presented at the University of Southampton on February 24, 2015. For more information about Prof. David Jewitt, please visit his webpage: www.astro.su.se/~david/. Prof. David Jewitt is a Professor of Planetary Science at the University of Southampton and leads the Asteroid Terrestrial-impact Last Alert System (ATLAS), which monitors near-Earth objects, including asteroids and comets.",
        "ori-fast-z-score": -0.762000762001143,
        "water-fast-z-score": 4.572004572006858,
        "rewrite-fast-z-score": 0.8682431421244593
    },
    {
        "original_text": "We present the results of our second survey to find very low mass binaries using lucky imaging with the Palomar Observatory 1.2 m telescope and the PALM-3000 camera. We have discovered thirteen new systems, including ten brown dwarf companions (four previously unknown) in twelve nearby young open clusters ranging in age between 10 Myr and 300 Myr. The masses range from 0.03-0.10 M . These are among the lowest-mass objects ever found by direct imaging techniques. In addition we report on one system that is likely an unresolved binary consisting of two late-type stars. This work represents the largest sample of directly imaged brown dwarfs assembled so far. It will be used as input into population synthesis models aimed at understanding how these objects form and evolve over time. \n \n Keywords: Brown Dwarf, Open Cluster, Direct Imaging, Lucky Imaging, Nearby Stars",
        "watermark_text": "We present the results of our second survey to find very low weight binaries using lucky imaging with the Palomar Observatory 1 . 2 m camera and the PALM - 3000 sensor . We have discovered thirteen new systems , including ten brown giant companions ( four originally unknown ) in twelve nearby young open complexes ranging in age between 10 Myr and 300 Myr .The masses range from 0 . 03 - 0 . 10 M . These are among the smallest - weight objects ever found by direct observation techniques .In addition we publish on one system that is probably an unresolved binary composed of two late - class stars . This project represents the greatest sample of specifically imaged brown dwarfs assembled so far .It will be used as input into population analysis models targeted at studying how these objects formation and evolve over time . Keywords : Brown Dwarf , Open Cluster , Direct Imaging , Lucky Imaging , Nearby Stars",
        "rewrite_text": "We present the findings from our second survey aimed at identifying very low-mass binaries through lucky imaging with the 1.2 m camera at Palomar Observatory and the PALM-3000 sensor. Our efforts have led to the discovery of thirteen new systems, which include ten brown dwarf companions—four of which were previously unknown—located within twelve nearby young open clusters aged between 10 million and 300 million years. These companions have masses ranging from 0.03 to 0.10 solar masses, making them some of the lightest objects identified through direct observation techniques. Additionally, we report on one system that is likely an unresolved binary consisting of two late-type stars. This project has yielded the largest sample of directly imaged brown dwarfs to date, providing valuable data for population analysis models aimed at understanding the formation and evolution of these objects over time. Keywords: Brown Dwarf, Open Cluster, Direct Imaging, Lucky Imaging, Nearby Stars.",
        "ori-fast-z-score": -0.8551861104941365,
        "water-fast-z-score": 5.497624996033735,
        "rewrite-fast-z-score": -1.0533703247651751
    },
    {
        "original_text": "We present the results for the k-dependent SU(4) Hubbard model in two dimensions at half-filling, which is known to be equivalent to the t-J model with J = 4t2/U . We solve this problem by using the method developed recently by one of us (S.M.) based on the exact diagonalization combined with the density-matrix renormalization group technique. The ground state phase diagram obtained shows that there are three phases; antiferromagnetic insulator, d-wave superconductor, and ferromagnetically ordered metal. In particular we find that the d-wave superconducting region becomes larger as U increases. This result suggests that the strong-coupling limit may give rise to an exotic pairing mechanism different from the weak-coupling BCS theory. Finally we discuss possible relevance of our results to the cuprate hightemperature superconductors. PACS: 71.10.Fd",
        "watermark_text": "We present the results for the k - dependent SU ( 4 ) Hubbard theory in two dimensions at half - filling , which is known to be analogous to the t - J model with J = 4t2 / U . We answer this situation by using the method developed lately by one of us ( S . M . )based on the exact diagonalization combined with the density - vector renormalization group technique . The ground state phase diagram obtained shows that there are three stages ; antiferromagnetic insulator , d - wave superconductor , and ferromagnetically ordered metal .In particular we find that the d - wave superconducting area gets wider as U rises . This result suggests that the strong - interaction limit might give rise to an interesting pairing structure different from the strong - pairing BCS theory .Finally we explain potential significance of our findings to the cuprate hightemperature superconductors . PACS : 71 . 10 . Fd",
        "rewrite_text": "We present our findings on the k-dependent SU(4) Hubbard model in two dimensions at half-filling, which shares similarities with the t-J model with J = 4t²/U. Our analysis employs a recently developed method by one of the authors (S.M.), which integrates exact diagonalization with density-vector renormalization group techniques. The resulting ground state phase diagram reveals three distinct phases: an antiferromagnetic insulator, a d-wave superconductor, and a ferromagnetically ordered metal. Notably, we observe that the region of d-wave superconductivity expands as U increases. This outcome suggests that in the strong-interaction limit, an intriguing pairing mechanism may emerge, differing from the conventional strong-pairing BCS theory. Lastly, we discuss the potential implications of our results for high-temperature superconductors in the cuprate family. PACS: 71.10.Fd",
        "ori-fast-z-score": 0.2626128657194451,
        "water-fast-z-score": 5.938574464184706,
        "rewrite-fast-z-score": -0.9113223768657671
    },
    {
        "original_text": "We report on the observation and characterization of two-dimensional defect modes in optically-induced photonic crystals (OIPCs). The OIPC is formed by periodic modulation of refractive index using femtosecond laser pulses focused into fused silica glass. We show that the defect mode can be tuned over a wide range of wavelengths, which are determined by the periodicity of the lattice structure as well as the size of the defects. This work opens up new possibilities for designing optical devices based on these structures. \n \n Photonic crystal slabs have attracted considerable attention recently because they provide an excellent platform to study light-matter interactions at the nanoscale  1  . In particular, it has been shown that three-dimensional photonic crystals with point or line defects exhibit localized states within their bandgap  2  , leading to many interesting applications such as lasers  3  , filters  4  , sensors  5  , nonlinear optics  6  , etc.. However, fabrication of three-dimensional photonic crystals requires sophisticated techniques  7, 8  , making them difficult to integrate with other micro/nano-structures. Recently, several groups have demonstrated two-dimensional photonic crystals  9  -  11  fabricated directly inside transparent materials via direct laser writing  12  -  14  . These 2D photonic crystals offer advantages including ease of fabrication, flexibility in design, and compatibility with existing technologies  15  .\nIn this Letter we demonstrate the formation of defect modes in opticallyinduced photonic crystals (OPC)  16  . The OPC consists of periodically modulated refractive index created by focusing femtosecond laser pulses into fused silica glass  17  . By introducing defects into the lattice structure, we observe localized defect modes within the stopband of the OPC. Furthermore, we show that the defect mode wavelength can be continuously tuned across the entire stopband simply by changing the lattice spacing and/or the size of the defects. \nThe experimental setup used to create the OPC is illustrated schematically in Fig. 1(a) . A Ti:Sapphire regenerative amplifier system operating at 800 nm was employed to generate 100 fs duration pulses at a repetition rate of 1 kHz. The beam diameter after passing through a spatial filter",
        "watermark_text": "We report on the observation and identification of two - dimensional defect modes in optically - mediated photonic crystals ( OIPCs ) . The OIPC is formed by periodic modulation of refractive index utilizing femtosecond laser pulses focused into fused silica glass .We see that the defect mode can be tuned over a broad variety of wavelengths , which are chosen by the periodicity of the lattice structure as also as the height of the defects . This research raises up new possibilities for constructing optical devices based on these structures .Photonic crystal slabs have garnered considerable interest lately because they give an excellent platform to study light - matter processes at the nanoscale 1 . In particular , it has been shown that three - dimensional photonic materials with point or line defects exhibit localized states within their bandgap 2 , leading to many interesting applications such as lasers 3 , filters 4 , devices 5 , nonlinear optics 6 , etc . .However , fabrication of three - dimensional photonic particles needs specialized techniques 7 , 8 , making them harder to integrate with other micro / nano - materials . Recently , various groups have demonstrated two - dimensional photonic particles 9 - 11 fabricated fully inside transparent materials via continuous optical writing 12 - 14 .These 2D photonic materials provide advantages including ease of fabrication , simplicity in design , and compatibility with existing devices 15 . In this Letter we prove the formation of defect modes in opticallyinduced photonic materials ( OPC ) 16 .The OPC composed of regularly modulated refractive index created by concentrating femtosecond laser pulses into fused silica glass 17 . By introducing defects into the lattice structure , we perceive localized failure modes within the stopband of the OPC .Furthermore , we find that the failure mode wavelength can be continuously tuned across the entire stopband solely by varying the crystal spacing and / or the size of the defects . The empirical setup used to create the OPC is depicted schematically in Fig .1 ( a ) . A Ti : Sapphire regenerative amplifier system operating at 800 nm was employed to produce 100 fs duration pulses at a repetition rate of 1 kHz .The beam diameter after passing through a spatial filter",
        "rewrite_text": "We present our findings on the observation and identification of two-dimensional defect modes within optically-induced photonic crystals (OIPCs). These OIPCs are created by periodically modulating the refractive index through femtosecond laser pulses focused into fused silica glass. Our experiments demonstrate that the defect modes can be tuned across a wide range of wavelengths, determined by the periodicity of the lattice structure and the height of the defects. This research opens new avenues for the development of optical devices based on these structures. Recently, photonic crystal slabs have gained significant attention because they provide an excellent platform to investigate light-matter interactions at the nanoscale. In particular, it has been observed that three-dimensional photonic materials with point or line defects can exhibit localized states within their bandgap, leading to a variety of fascinating applications such as lasers, filters, and nonlinear optics. However, the fabrication of three-dimensional photonic structures requires specialized techniques, making their integration with other micro/nano materials more challenging. In recent advancements, various groups have successfully demonstrated the creation of two-dimensional photonic particles fabricated entirely within transparent materials through continuous optical writing. These 2D photonic materials offer several advantages, including easier fabrication, straightforward design, and compatibility with existing devices. In this Letter, we confirm the formation of defect modes in optically-induced photonic materials (OPCs). The OPCs feature a regularly modulated refractive index made possible by focusing femtosecond laser pulses into fused silica glass. By incorporating defects into the lattice, we observe localized defect modes within the stopband of the OPC. Furthermore, we find that the wavelength of these defect modes can be continuously tuned throughout the entire stopband by adjusting either the crystal spacing or the size of the defects. The experimental setup used to create the OPC is illustrated schematically in Fig. 1(a). We utilized a Ti:sapphire regenerative amplifier operating at 800 nm to produce 100 fs duration pulses at a repetition rate of 1 kHz, with the beam diameter after passing through a spatial filter...",
        "ori-fast-z-score": -0.3223291856101521,
        "water-fast-z-score": 7.526023228839096,
        "rewrite-fast-z-score": 2.5062014587087744
    },
    {
        "original_text": "The design and kinematics analysis of parallel kinematic machine tools (PKMTs) is presented in this work using kinetic-static performance criteria. The proposed approach considers the dynamic behavior of PKMTs during their operation, which has been neglected by previous works on PKMTs. In addition to the static stiffness matrix, the inertia properties are also considered for the evaluation of the overall dynamic response of PKMTs. A new method based on the concept of virtual joints is developed to calculate the mass distribution along each leg of the PKMT under consideration. This information can be used as an input data set for further dynamic analyses such as modal or harmonic vibration analysis. Finally, two different PKMTs with three degrees-of-freedom per joint are designed and analyzed using the proposed methodology. It was found that the first PKMT exhibits better dynamic characteristics than its counterpart due to its lower natural frequencies and higher damping ratios.",
        "watermark_text": "The design and kinematics analysis of parallel kinematic machine tools ( PKMTs ) is detailed in this work using kinetic - static performance criteria . The proposed approach considers the dynamic behavior of PKMTs during their operation , which has been neglected by previous works on PKMTs .In addition to the static stiffness matrix , the inertia characteristics are also considered for the evaluation of the overall dynamic response of PKMTs . A modern algorithm based on the idea of virtual joints is developed to estimate the mass distribution along each leg of the PKMT under consideration .This knowledge can be used as an input data set for further dynamic analyses such as modal or harmonic vibration analysis . Finally , two different PKMTs with three degrees - of - independence per joint are built and evaluated using the suggested methodology .It was shown that the first PKMT displays better dynamic characteristics than its predecessor due to its lower natural bandwidth and larger damping ratios .",
        "rewrite_text": "This work presents a comprehensive analysis of the design and kinematics of parallel kinematic machine tools (PKMTs) through kinetic-static performance criteria. Unlike previous studies, this approach incorporates the dynamic behavior of PKMTs during operation. In addition to the static stiffness matrix, the evaluation of the overall dynamic response of PKMTs also accounts for inertia characteristics. A novel algorithm based on the concept of virtual joints has been developed to estimate the mass distribution along each leg of the examined PKMT. This information serves as a foundational dataset for further dynamic analyses, such as modal or harmonic vibration assessments. Ultimately, two different PKMTs, each with three degrees of freedom per joint, were constructed and assessed using the proposed methodology. The results indicated that the first PKMT exhibited superior dynamic characteristics over its predecessor, characterized by a lower natural bandwidth and higher damping ratios.",
        "ori-fast-z-score": 1.6059101370939322,
        "water-fast-z-score": 5.27656187902292,
        "rewrite-fast-z-score": 0.7071067811865476
    },
    {
        "original_text": "We present new spectroscopic observations for eight red giant stars in the nearby dwarf spheroidal galaxy, Leo II (D = 3 Mpc). The data were obtained with the Keck telescope and HIRES spectrograph over three nights during August 2005. We measure heliocentric radial velocities ranging between -150 to +50 km/sec. These values are consistent with previous measurements made by other authors using different techniques. Using these new data we have determined that there is no significant rotation or streaming motion within this system. This result supports theoretical predictions based on N-body simulations which suggest that dark matter halos should be nearly spherical systems. In addition, our results provide further evidence against the possibility that Leo II may contain an intermediate mass black hole at its center. \n \n Keywords: Dwarf galaxies; Black holes; Dark Matter Halos; Rotation Curves; Stellar Kinematics; Spherical Symmetry",
        "watermark_text": "We report new spectroscopic observations for eight red giant galaxies in the nearby dwarf spheroidal galaxy , Leo II ( D = 3 Mpc ) . The data were obtained with the Keck camera and HIRES spectrograph over three nights during August 2005 .We estimate heliocentric radial velocities ranging between - 150 to + 50 km / sec . These measurements are compatible with previous measurements made by other researchers using separate techniques .Using these new data we have concluded that there is no considerable rotation or streaming motion within this system . This result provides theoretical estimates based on N - bodies simulations which propose that dark matter halos should be nearly spherical systems .In addition , our findings provide further evidence against the suggestion that Leo II may contain an intermediate mass black hole at its core . Keywords : Dwarf galaxies ; Black holes ; Dark Matter Halos ; Rotation Curves ; Stellar Kinematics ; Spherical Symmetry",
        "rewrite_text": "We present new spectroscopic observations of eight red giant galaxies in the nearby dwarf spheroidal galaxy Leo II (D = 3 Mpc). The data were collected with the Keck camera and HIRES spectrograph over three nights in August 2005. Our estimated heliocentric radial velocities range from -150 to +50 km/sec, aligning with previous measurements obtained by other researchers using different methods. These new observations lead us to conclude that there is no significant rotation or streaming motion within the system. This finding supports theoretical predictions from N-body simulations, which suggest that dark matter halos should have a nearly spherical shape. Additionally, our results offer further evidence against the hypothesis that Leo II harbors an intermediate-mass black hole at its center. Keywords: Dwarf galaxies; Black holes; Dark Matter Halos; Rotation Curves; Stellar Kinematics; Spherical Symmetry.",
        "ori-fast-z-score": 1.2909944487358056,
        "water-fast-z-score": 6.273807116711903,
        "rewrite-fast-z-score": 1.6035674514745464
    },
    {
        "original_text": "The authors present an analysis of the stochasticity inherent to biochemical reactions, and its effects on metabolic networks. They show that this noise can be reduced by increasing enzyme concentrations or decreasing reaction rates; however, these strategies are limited because they may lead to other undesirable consequences such as increased production costs for enzymes or decreased growth rate due to slower metabolism. The authors also discuss how their results could help explain why some organisms have evolved mechanisms to reduce the amount of noise in their metabolic processes (e.g., gene regulation). Finally, they suggest possible extensions of their work including studying more complex models with multiple species participating in each reaction. This article is available from: http://arxiv.org/abs/1306.5481 . Stochastic fluctuations in metabolic pathways  Authors: Yi-Chun Chen , Shih-Chieh Hwang , Chia-Hui Wu , Yu-Ting Lin , Ming-Jerng Wang , Wen-Yuan Lee , Jyh-Ming Huang , Chin-Lung Chang , Yuan-Chao Tsai , Wei-Hsien Yang , Kuo-Feng Yeh , Chung-I Wu , Tzi-Chin Chan , Cheng-Yang Liu , Chao-Kuang Chiang , Chien-Nan Chu , Chien-Wen Lu , Chien-Chi Lai , Chien-Shuu Chen , Chien-Chi Hsieh , Chien-Chi Wu , Chien-Chi Hung , Chien-Chi Li , Chien-Chi Su , Chien-Chi Liao , Chien-Chi Chen , Chien-Chiang Wu , Chien-Chiang Tai , Chien-Chiang Liang , Chien-Chiang Sun , Chien-Chiang Wei , Chien-Chiang Chen , Chien-Chang Wu , Chien-Chang Tai , Chien-Chang Liang , Chien-Chang Sun , Chien-Chang Wei , Chien-Chang Chen , Chien-Cheng Wu , Chien-Cheng Tai , Chien-Cheng Liang , Chien-Cheng Sun , Chien-Cheng Wei , Chien-Cheng Chen , Chien-Ch",
        "watermark_text": "The authors present an assessment of the stochasticity inherent to biochemical reactions , and its consequences on metabolic networks . They show that this noise can be reduced by expanding substrate concentrations or decreasing reaction rates ; however , these schemes are limited because they may contribute to other undesirable consequences such as reduced production expenses for enzymes or improved development pace leading to slower metabolism .The authors additionally discuss how their results could assist explain why some organisms have adapted processes to reduce the quantity of noise in their metabolic processes ( e . g . , gene control ) . Finally , they propose could extend of their studies namely studying more sophisticated models with many taxa participating in each synthesis .This page is accessible from : www : / / arxiv . org / abs / 1306 . 5481 . Stochastic fluctuations in metabolic mechanisms Authors : Yi - Chun Chen , Shih - Chieh Hwang , Chia - Hui Wu , Yu - Ting Lin , Ming - Jerng Wang , Wen - Yuan Lee , Jyh - Ming Huang , Chin - Lung Chang , Yuan - Chao Tsai , Wei - Hsien Yang , Kuo - Feng Yeh , Chung - I Wu , Tzi - Chin Chan , Cheng - Yang Liu , Chao - Kuang Chiang , Chien - Nan Chu , Chien - Wen Lu , Chien - Chi Lai , Chien - Shuu Chen , Chien - Chi Hsieh , Chien - Chi Wu , Chien - Chi Hung , Chien - Chi Li , Chien - Chi Su , Chien - Chi Liao , Chien - Chi Chen , Chien - Chiang Wu , Chien - Chiang Tai , Chien - Chiang Liang , Chien - Chiang Sun , Chien - Chiang Wei , Chien - Chiang Chen , Chien - Chang Wu , Chien - Chang Tai , Chien - Chang Liang , Chien - Chang Sun , Chien - Chang Wei , Chien - Chang Chen , Chien - Cheng Wu , Chien - Cheng Tai , Chien - Cheng Liang , Chien - Cheng Sun , Chien - Cheng Wei , Chien - Cheng Chen , Chien - Ch",
        "rewrite_text": "The authors provide an analysis of the inherent stochasticity in biochemical reactions and its effects on metabolic networks. They demonstrate that this noise can be mitigated by either increasing substrate concentrations or lowering reaction rates. However, these approaches come with limitations, as they may also lead to unwanted outcomes, such as decreased enzyme production costs or an accelerated developmental pace, which could result in a slower metabolism. Furthermore, the authors explore how their findings may help clarify why certain organisms have evolved mechanisms to minimize noise in their metabolic functions, such as through gene regulation. Lastly, they suggest the possibility of extending their research to include more complex models that involve multiple taxa in each synthetic process. For more information, visit: www:/ / arxiv.org/abs/1306.5481. \n\nStochastic Fluctuations in Metabolic Mechanisms  \nAuthors: Yi-Chun Chen, Shih-Chieh Hwang, Chia-Hui Wu, Yu-Ting Lin, Ming-Jerng Wang, Wen-Yuan Lee, Jyh-Ming Huang, Chin-Lung Chang, Yuan-Chao Tsai, Wei-Hsien Yang, Kuo-Feng Yeh, Chung-I Wu, Tzi-Chin Chan, Cheng-Yang Liu, and others.",
        "ori-fast-z-score": 1.0392304845413263,
        "water-fast-z-score": 8.075839156533009,
        "rewrite-fast-z-score": 0.7071067811865476
    },
    {
        "original_text": "In this work, we consider the problem of optimizing the performance of multi-hop wireless mesh networks (WMNs) in which each node is equipped with multiple antennas and uses vector broadcast channels to communicate with its neighbors. We propose an algorithm that jointly optimizes the routing tree at the network layer and the beamforming vectors at the physical layer for both unicast traffic and multicast traffic. The proposed algorithm can be implemented using only local information exchange between neighboring nodes. Our simulation results show that our algorithm outperforms existing algorithms by up to 50% in terms of end-to-end throughput under different channel conditions. Index Terms -Wireless mesh networks, Cross-layer optimization, Beamforming, Routing trees, Multicasting. 1 Introduction Wireless mesh networks are becoming increasingly popular due to their low cost and ease of deployment  1  . In such networks, all nodes have limited transmission range and thus need to relay data packets through other nodes before reaching their destinations. This introduces additional overheads on the network resources including bandwidth consumption and energy dissipation  2  .\nTo improve the efficiency of WMNs, it has been shown recently that joint design of the network layer and the physical layer is necessary  3  , where the network layer determines how to route data packets while the physical layer decides what transmit power levels should be used as well as what beamforming vectors should be adopted  4  . However, most previous works focus either on the network layer or the physical layer separately  5  , ignoring the fact that they interact closely with one another  6  .",
        "watermark_text": "In this research , we investigate the issue of optimizing the performance of dual - hop wireless mesh connections ( WMNs ) in which each node is furnished with many antennas and using vector broadcast channels to connect with its friends . We suggest an algorithm that collectively optimizes the routing tree at the channel layer and the beamforming vectors at the physical layer for both unicast transport and multicast transport .The proposed algorithm can be executed using only local information transfer between neighboring vertices . Our model results show that our algorithm outperforms previous algorithms by up to 50 % in terms of end - to - end throughput under various network conditions .Index Terms - Wireless mesh connections , Cross - layer optimization , Beamforming , Routing trees , Multicasting . 1 Introduction Wireless mesh connections are gaining increasingly popular due to their low cost and ease of deployment 1 .In such connections , all nodes have limited transmission range and therefore need to relay data packets through other connections before reaching their destinations . This creates additional overheads on the network infrastructure including frequency expenditure and energy dissipation 2 .To increase the performance of WMNs , it has been shown lately that cooperative architecture of the communications layer and the physical layer is required 3 , where the network layer determines how to transport data packets while the physical layer decides what receive power rates should be used as well as what beamforming vectors should be adopted 4 . However , most prior efforts focus either on the wireless layer or the physical layer individually 5 , avoiding the fact that they interact tightly with one another 6 .",
        "rewrite_text": "In this study, we explore the optimization of dual-hop wireless mesh networks (WMNs) where each node is equipped with multiple antennas and utilizes vector broadcast channels to communicate with its peers. We propose an algorithm that simultaneously optimizes the routing tree at the channel layer and the beamforming vectors at the physical layer for both unicast and multicast transmissions. This algorithm operates using only local information sharing among neighboring nodes. Our model demonstrates that this approach can enhance end-to-end throughput by up to 50% compared to existing algorithms, across various network conditions. \n\n**Keywords:** Wireless mesh networks, Cross-layer optimization, Beamforming, Routing trees, Multicasting.\n\n1. **Introduction**  \nWireless mesh networks are becoming increasingly popular due to their affordability and ease of implementation. In these networks, each node has a limited transmission range and must forward data packets through other nodes before reaching their intended destinations. This relaying process adds extra burdens on the network infrastructure, leading to increased frequency usage and energy consumption. Recent research has highlighted the necessity of a cooperative approach that integrates both the communication and physical layers to enhance WMN performance. The network layer is responsible for determining the data packet transport methods, while the physical layer is tasked with selecting appropriate receive power levels and beamforming vectors. However, most previous studies have concentrated either on the wireless layer or the physical layer in isolation, overlooking their significant interdependencies.",
        "ori-fast-z-score": -1.5085060660073935,
        "water-fast-z-score": 7.897472933803413,
        "rewrite-fast-z-score": 0.8980265101338746
    },
    {
        "original_text": "We present new theoretical evolutionary tracks for the mass range 1.8 to 2.5 M⊙, which are based on an improved treatment of convection in stellar interiors. We use these tracks as input into our seismic modelling code CESAM2k to compute synthetic seismograms for two different sets of observed frequencies (from COROT) corresponding to two possible values of the inclination angle i = 90° or 60° . The comparison between observations and theory shows that we can exclude one set of frequencies at high confidence level but not the other. This is due to the fact that the frequency differences between ℓ=0 and ℓ=2 modes depend strongly on the inclination angle. In addition, we find that the best fit model has a radius R=1.95R⊙ , which agrees well with the value inferred by asteroseismology using only ℓ=0 modes. Finally, we show how this result could be used to determine the age of the star.  Keywords: Seismic modelling",
        "watermark_text": "We create additional theoretical evolutionary tracks for the mass range 1 . 8 to 2 . 5 [UNK] , which are based on an improved treatment of convection in stellar interiors . We use these tracks as input into our seismic modelling code CESAM2k to compute synthetic seismograms for two different sets of observed frequencies ( from COROT ) corresponding to two possible values of the inclination angle i = 90° or 60° .The comparison between observations and theory indicates that we can eliminate one group of frequencies at high confidence rate but not the other . This is due to the fact that the frequency differences between ℓ = 0 and ℓ = 2 modes differ highly on the inclination orientation .In addition , we find that the best fit model has a radius R = 1 . [UNK] , which agrees well with the value inferred by asteroseismology using only ℓ = 0 modes . Finally , we show how this result could be used to determine the age of the star .Keywords: Seismic modelling",
        "rewrite_text": "We develop new theoretical evolutionary tracks for stars with masses ranging from 1.8 to 2.5 solar masses, incorporating an enhanced approach to convection in stellar interiors. These tracks serve as input for our seismic modeling software, CESAM2k, to generate synthetic seismograms based on two sets of observed frequencies from COROT, corresponding to inclination angles of i = 90° and i = 60°. Our comparison of theoretical predictions with observations allows us to confidently rule out one set of frequency data, while uncertainty remains with the other. This discrepancy arises from significant differences in frequency patterns between ℓ = 0 and ℓ = 2 modes, which are influenced by the inclination angle. Additionally, we determine that the model yielding the best fit has a radius of R = 1.0 solar radii, closely aligning with values derived from asteroseismology that consider only ℓ = 0 modes. Ultimately, we discuss how these findings can aid in estimating the star's age. Keywords: Seismic modeling.",
        "ori-fast-z-score": 1.212678125181665,
        "water-fast-z-score": 2.80989722019502,
        "rewrite-fast-z-score": -1.1952286093343936
    },
    {
        "original_text": "We report the discovery of a new satellite galaxy, dubbed  A pair of bootes  (ApoBootes), orbiting around our Galaxy at a distance of about 300 kpc in projection and with an estimated mass of 1.5 x 10^10 M_sun . ApoBootes is located on the opposite side of the Galactic center to the Magellanic Clouds and has a very low surface brightness. We have used deep near-infrared images taken by the VISTA telescope as part of the Vista Variables in the Via Lactea survey to identify this object. The photometric properties are consistent with those expected for a dwarf spheroidal galaxy. This work was supported by the Australian Research Council Discovery Project funding scheme under grant DP130104011. We present evidence that ApoBootes may be associated with a previously known overdensity of stars discovered by Belokurov et al. (2007) using SDSS data.",
        "watermark_text": "We report the discovery of a new satellite galaxy , nicknamed A couple of bootes ( ApoBootes ) , orbiting around our Galaxy at a distance of about 300 kpc in projection and with an estimated mass of 1 . 5 x 10 ^ 10 M _ sun . ApoBootes is situated on the opposite end of the Galactic center to the Magellanic Clouds and has a very low exterior brightness .We have utilized deep near - infrared images obtained by the VISTA telescope as part of the Vista Variables in the Via Lactea survey to identify this body . The photometric properties are compatible with those expected for a dwarf spheroidal galaxy .This research was supported by the Australian Research Council Discovery Project grant program under grant DP130104011 . We present evidence that ApoBootes might be identified with a previously known overdensity of stars found by Belokurov et al .( 2007 ) used SDSS information .",
        "rewrite_text": "We announce the discovery of a new satellite galaxy, referred to as ApoBootes, which orbits our Galaxy at an approximate projected distance of 300 kpc and is estimated to have a mass of 1.5 x 10^10 M_sun. ApoBootes is located on the opposite side of the Galactic center from the Magellanic Clouds and exhibits very low surface brightness. This discovery was made using deep near-infrared images collected by the VISTA telescope as part of the Vista Variables in the Via Lactea survey. The photometric characteristics of ApoBootes align with those anticipated for a dwarf spheroidal galaxy. This research was supported by the Australian Research Council through the Discovery Project grant program (grant DP130104011). We also present evidence suggesting that ApoBootes may correspond to a previously identified stellar overdensity reported by Belokurov et al. (2007) using SDSS data.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.437601569801833,
        "rewrite-fast-z-score": 0.674199862463242
    },
    {
        "original_text": "We study the phenomenological consequences of supersymmetric models with gauge-mediated breaking, in which the Standard Model is extended by adding new vector-like matter fields and extra dimensions. We show that these models can be constructed such that they are free of any unnatural fine-tuning problems associated with the Higgs mass or flavor-changing neutral currents. In particular we find that:  1) The lightest scalar superpartner (the  Higgs  boson) has a mass at most around 300 GeV.  2) Flavor changing neutral current effects are suppressed to an acceptable level for generic values of parameters.  3) Gauge coupling unification occurs naturally within experimental uncertainties. 4) There exists a large parameter space where all sparticles have masses above 1 TeV while still satisfying constraints on electroweak symmetry breaking. 5) These models provide a natural explanation for why there may not yet exist evidence for supersymmetry at accelerator experiments.",
        "watermark_text": "We research the phenomenological consequences of supersymmetric theories with gauge - mediated breaking , in which the Standard Model is extended by added new vector - like matter fields and extra dimensions . We see that these models can be built such that they are free of any strange fine - tuned flaws associated with the Higgs mass or flavor - changing neutral currents .In particular we find that : 1 ) The lightest scalar superpartner ( the Higgs boson ) has a mass at most approximately 300 GeV . 2 ) Flavor shifting neutral current effects are suppressed to an acceptable level for generic values of values .3 ) Gauge coupling unification happens easily within experimental uncertainties . 4 ) There exists a large parameter room where all sparticles have masses above 1 TeV while already satisfying constraints on electroweak symmetry breaking .5 ) These models represent a natural explanation for why there may not already exist evidence for supersymmetry at accelerator studies .",
        "rewrite_text": "We investigate the phenomenological implications of supersymmetric theories characterized by gauge-mediated breaking, which entail an extension of the Standard Model through the introduction of new vector-like matter fields and additional dimensions. Our analysis demonstrates that these models can be constructed to avoid the peculiar fine-tuning issues often associated with the Higgs mass and flavor-changing neutral currents. Specifically, we discover the following: 1) The lightest scalar superpartner (the Higgs boson) has a mass that is at most around 300 GeV. 2) Effects of flavor-changing neutral currents are suppressed to an acceptable degree for typical parameter values. 3) Gauge coupling unification occurs smoothly within the bounds of experimental uncertainties. 4) There exists a significant parameter space where all superpartners have masses exceeding 1 TeV while still adhering to the constraints imposed by electroweak symmetry breaking. 5) These models offer a natural explanation for the lack of observed evidence for supersymmetry in accelerator experiments.",
        "ori-fast-z-score": 0.7385489458759964,
        "water-fast-z-score": 5.908391567007971,
        "rewrite-fast-z-score": -0.5933908290969266
    },
    {
        "original_text": "We present the second part of our study on non-metric gravity theory in which we find that there is no missing mass problem for quasars as claimed by some authors.  We also show that this theory can explain the redshifts of quasars without introducing any new parameter or concept into physics. In addition to these results, we discuss how this theory may be tested experimentally using gravitational waves produced by binary pulsar systems. The first part of this work has been published recently  1  . \nI. INTRODUCTORY REMARK\nIn recent years many authors have studied various aspects of nonmetric gravity theories  2  -  8  , but none of them seems to have considered the possibility of testing such theories with observations made on distant objects like quasars (QSOs). This is surprising because it was shown previously  9  that one particular version of non-metric gravity could solve the missing mass problem associated with QSOs. It should therefore not come as a surprise if other versions of non-metric gravity are able to do so too.",
        "watermark_text": "We present the second part of our research on non - metric gravity concept in which we find that there is no missing mass problem for quasars as asserted by some researchers . We also demonstrate that this theory can describe the redshifts of quasars without putting any new parameter or notion into physics .In addition to these results , we talk how this theory could be evaluated experimentally utilizing gravitational waves produced by binary pulsar systems . The first part of this research has been printed recently 1 .I . INTRODUCTORY REMARK In past decades several authors have researched several elements of nonmetric gravity fields 2 - 8 , but none of them appears to have thought the prospect of testing such theories with observations made on remote bodies like quasars ( QSOs ) .This is surprising because it was shown previously 9 that one certain version of non - metric gravity could answer the missing mass problem associated with QSOs . It should therefore not come as a surprise if other variants of non - metric gravity are able to do so too .",
        "rewrite_text": "In this second installment of our research on the non-metric gravity concept, we assert that the issue of missing mass in quasars, as claimed by some researchers, does not exist. Furthermore, we show that this theory accounts for the redshifts of quasars without introducing any new parameters or concepts into physics. Alongside these findings, we discuss the potential for experimental validation of this theory through the observation of gravitational waves generated by binary pulsar systems. The first part of this research has been published recently. \n\nIn the introductory section, we note that over the past few decades, several researchers have explored various aspects of non-metric gravity fields. However, none seem to have considered the potential of testing these theories using observations from distant objects like quasars (QSOs). This oversight is notable, especially given that prior studies have demonstrated that a specific version of non-metric gravity could address the missing mass issue related to QSOs. Thus, it stands to reason that other formulations of non-metric gravity may also provide solutions.",
        "ori-fast-z-score": 0.3333333333333333,
        "water-fast-z-score": 7.0,
        "rewrite-fast-z-score": 0.9434563530497265
    },
    {
        "original_text": "The authors have studied the growth rate and its fluctuations for different types of human cancer cells grown under controlled conditions, using an automated image analysis system to measure their size over time.  The results show that there is considerable variation between individual clones within each type of cell line as well as between different types of cell lines. This suggests that it may be possible to use this information to classify tumours into subtypes with distinct biological properties. In addition, they find evidence that the growth rates are correlated across generations of daughter cells, which could provide insight into how these correlations arise during tumorigenesis. Finally, by comparing the growth characteristics of normal and transformed cells, they conclude that transformation leads to increased heterogeneity among daughter cells. Cancer is characterized by uncontrolled proliferation of abnormal cells. Understanding the mechanisms underlying this process can help us develop new treatments against cancer. However, studying the dynamics of cancerous cell populations has been challenging because of difficulties associated with tracking large numbers of single cells simultaneously. Here we report our recent work on characterizing the growth behavior of thousands of individual cancer cells growing in culture dishes  1  . We used an automated imaging system to track the sizes of hundreds of thousands of cells belonging to several different types of human cancer cell lines ( Figure 1 ). Our results reveal significant differences in both average growth rates and growth fluctuations between different types of cell lines: some grow faster than others while also exhibiting larger fluctuations around their mean values  2  .\nWe found that the growth rates were highly variable even when measured at the level of individual clones derived from a common parent population  3  , suggesting that the observed phenotypic diversity might reflect genetic or epigenetic variations present in the original parental population  4  .  These findings suggest that it should be possible to use such measurements to classify tumors into subtypes based on their growth characteristics  5  .",
        "watermark_text": "The authors have researched the development time and its fluctuations for different kinds of human tumor tissues grown under regulated conditions , using an automated photo processing program to measure their size over time . The results show that there is substantial variation between individual clones within each type of cell line as well as between various types of cell lines .This shows that it could be possible to use this data to classify tumours into subtypes with distinct bio properties . In addition , they discover proof that the development rates are correlated across generations of daughter cells , which could give insight into how these correlations occur during tumorigenesis .Finally , by comparing the development patterns of normal and transformed tissue , they conclude that transformation results to greater heterogeneity among sister cells . Cancer is characterized by uncontrolled proliferation of irregular cells .Understanding the mechanisms governing this process can help us discover new therapy against disease . However , studying the dynamics of cancerous cell groups has been challenging because of delays associated with measuring large numbers of single cells simultaneously .Here we document our latest work on characterizing the development habits of tens of individual cancer cells growing in culture dishes 1 . We utilized an automated imaging technology to track the sizes of tens of hundred of cells belonging to several different kinds of human tumor tissue lines ( Figure 1 ) .Our results show considerable variations in both average growth rates and growth fluctuations between various types of cell lines : some develop longer than others while also displaying greater fluctuations around their average values 2 . We showed that the development rates were extremely varied even when measured at the level of individual clones originating from a common parent population 3 , showing that the reported phenotypic diversity could reflect genetic or epigenetic changes found in the original parental generation 4 .These studies propose that it should be possible to use such measurements to classify cancer into subtypes based on their growth parameters 5 .",
        "rewrite_text": "The authors conducted a study on the development times and their variations across different types of human tumor tissues cultivated under controlled conditions, employing an automated image processing program to track their growth over time. The findings reveal significant differences in growth characteristics among individual clones within each cell line, as well as across various cell lines. This indicates the potential to categorize tumors into subtypes based on distinct biological properties. Additionally, the research provides evidence that growth rates are consistent across generations of daughter cells, offering insights into the factors that influence these correlations during tumor development. Furthermore, by analyzing the growth patterns of normal versus transformed tissues, the authors conclude that transformation increases heterogeneity among sister cells. Given that cancer is defined by the uncontrolled proliferation of abnormal cells, understanding the mechanisms behind this process could pave the way for new therapeutic strategies. However, investigating the dynamics of cancer cell groups has been difficult due to the challenges of simultaneously measuring large numbers of individual cells. In this study, we detail our recent advancements in characterizing the growth behaviors of numerous individual cancer cells in culture dishes. We utilized automated imaging technology to monitor the sizes of hundreds of cells from various human tumor tissue lines. Our results indicate substantial variations in both average growth rates and growth fluctuations among different cell lines, with some exhibiting longer growth durations and greater variability around their mean rates. We also observed that growth rates showed considerable variation even at the level of individual clones derived from a common parent population, suggesting that the observed phenotypic diversity may be linked to genetic or epigenetic modifications in the originating parental generation. These findings suggest that it may be possible to classify cancer into subtypes based on their growth characteristics.",
        "ori-fast-z-score": -1.6678156958735875,
        "water-fast-z-score": 9.146740246823299,
        "rewrite-fast-z-score": 1.2199885626608373
    },
    {
        "original_text": "We present novel examples of tree-level stable non-BPS D-branes in string theory, which are not associated with spacetime fermion zero modes and thus do not require the presence of orientifolds or other sources for tadpole cancellation. We show that these brane configurations can be constructed by wrapping unstable D-branes on supersymmetric cycles in Calabi-Yau threefolds. The resulting BPS states preserve half of the original supersymmetry but carry no net charge under any gauge group factor. These results provide new insights into the structure of moduli spaces of vacua in string theory. Introduction: In recent years there has been considerable interest in studying non-BPS D-brane (NBD) configurations in type II string theories  1  . NBDs have attracted attention because they may play an important role in understanding various phenomena such as tachyon condensation  2  , open-string pair production  3  , and black hole entropy  4  .\nIn this work we will focus our attention on NBDs whose stability is due to worldsheet instanton effects  5  -  8  rather than spacetime fermion zero-modes  9  . Such NBDs were first studied in  10  where it was shown that certain wrapped D3-branes could become stable at one-loop order without requiring the presence of orientifold planes  11  . Subsequently, several authors  12  -  16  have considered similar constructions involving different types of D-branes and compactifications. However, all of these works required some form of tadpole cancellation  17  so that the total RR-charge carried by the configuration vanishes. Tadpole cancellation conditions place strong constraints on the allowed values of fluxes and charges in the background geometry  18  . It would therefore be interesting if one could find examples of stable NBDs which did not require the presence of additional sources for tadpole cancellations.",
        "watermark_text": "We introduce novel instances of forest - level stable non - BPS D - branes in string theory , which are not associated with spacetime fermion zero configurations and therefore do not require the presence of orientifolds or other sources for tadpole cancellation . We see that these brane configurations can be built by wrapping unstable D - branes on supersymmetric cycles in Calabi - Yau threefolds .The resulting BPS states preserve half of the former supersymmetry but hold no net charge under any gauge group factor . These data provide fresh insights into the formation of moduli spaces of vacua in string theory .Introduction : In recent years there has been substantial interest in investigating non - BPS D - brane ( NBD ) arrangements in type II string theories 1 . NBDs have garnered attention because they may play an important role in understanding various phenomena such as tachyon condensation 2 , empty - string pair production 3 , and dark hole entropy 4 .In this research we will focus our focus on NBDs whose stability is due to worldsheet instanton interaction 5 - 8 instead than spacetime fermion zero - modes 9 . Such NBDs were first investigated in 10 where it was shown that particular tangled D3 - branes might remain stable at one - ring order without requiring the presence of orientifold planes 11 .Subsequently , various scientists 12 - 16 have thought equivalent constructions concerning diverse kinds of D - branes and compactifications . However , all of these works involved some kind of tadpole cancellation 17 so that the total RR - charge dropped by the configuration vanishes .Tadpole cancellation conditions place powerful restrictions on the allowed parameters of fluxes and charges in the background geometry 18 . It would therefore be attractive if one could discover examples of stable NBDs which did not require the presence of additional sources for tadpole cancellations .",
        "rewrite_text": "We present new instances of forest-level stable non-BPS D-branes in string theory that are not linked to spacetime fermion zero configurations, eliminating the need for orientifolds or other sources for tadpole cancellation. These brane configurations can be constructed by wrapping unstable D-branes around supersymmetric cycles in Calabi-Yau threefolds. The resulting BPS states retain half of the original supersymmetry while exhibiting no net charge under any gauge group factor. This research offers new perspectives on the formation of moduli spaces of vacua in string theory. \n\nIntroduction: Recently, there has been significant interest in exploring non-BPS D-brane (NBD) configurations in type II string theories. NBDs have become a focal point due to their potential role in understanding various phenomena such as tachyon condensation, empty-string pair production, and dark hole entropy. Our study will specifically examine NBDs whose stability arises from worldsheet instanton interactions rather than spacetime fermion zero modes. The initial investigation of such NBDs highlighted that certain tangled D3-branes could remain stable at one-ring order without the need for orientifold planes. Following this, several researchers have explored similar constructions involving various types of D-branes and compactifications. However, all previous work required some form of tadpole cancellation to ensure that the total RR-charge associated with the configuration sums to zero. These tadpole cancellation conditions impose stringent limitations on the permissible parameters for fluxes and charges in the underlying geometry. Thus, it would be beneficial to identify examples of stable NBDs that do not necessitate additional sources for tadpole cancellation.",
        "ori-fast-z-score": -1.247219128924647,
        "water-fast-z-score": 7.0101164243872995,
        "rewrite-fast-z-score": 1.6431676725154982
    },
    {
        "original_text": "We present the results of our analysis of pulsar data obtained with the LOFAR telescope in the Netherlands, which is part of the Low Frequency Array (LOFAR). The observations were carried out at frequencies between 10 MHz and 120 MHz using the High Band Antenna (HBA) system. We have detected two new types of pulsars - one that emits bursts of radio waves lasting several seconds and another whose pulses are modulated by an additional signal. In addition to these discoveries we also report on the detection of previously unknown phenomena associated with known pulsars. \n \n Pulsars are rapidly rotating neutron stars emitting beams of electromagnetic radiation across the entire visible universe. They can be observed over many decades as they spin down due to their magnetic dipole field losing energy into space. This causes them to slow down gradually until they stop completely after about ten billion years. As well as being extremely stable clocks for measuring time intervals, pulsars provide information about fundamental physics such as gravity, quantum electrodynamics and general relativity.",
        "watermark_text": "We present the conclusion of our analysis of pulsar information obtained with the LOFAR observatory in the Netherlands , which is part of the Low Frequency Array ( LOFAR ) . The surveys were carried out at speeds between 10 MHz and 120 MHz use the High Band Antenna ( HBA ) scheme .We have discovered two new types of pulsars - first that emits flashes of radio beams lasting several seconds and another whose pulses are modulated by an additional signal . In addition to these discoveries we also report on the discovery of previously unidentified behaviour associated with reported pulsars .Pulsars are rapidly spinning neutron stars emitting waves of electromagnetic radiation across the entire visible world . They can be viewed over numerous centuries as they rotate down due to their magnetic dipole field losing power into space .This forces them to halt down gradually until they stop completely after about ten billion decades . As well as being extremely reliable clocks for determining time periods , pulsars provide information about basic physics such as gravity , quantum electrodynamics and general relativity .",
        "rewrite_text": "We conclude our analysis of pulsar data collected from the LOFAR observatory in the Netherlands, part of the Low Frequency Array (LOFAR). The surveys were conducted at frequencies ranging from 10 MHz to 120 MHz using the High Band Antenna (HBA) system. We have identified two new types of pulsars: one type emits bursts of radio waves that last several seconds, while the other exhibits pulsations modulated by an additional signal. Furthermore, we report the discovery of previously unrecognized behaviors associated with known pulsars. Pulsars are rapidly rotating neutron stars that emit electromagnetic radiation across the entire spectrum. They can be observed for centuries as they gradually slow down due to the loss of energy from their magnetic dipole fields, eventually halting completely after around ten billion years. In addition to serving as exceptionally precise timekeepers, pulsars also provide insights into fundamental physics, including gravity, quantum electrodynamics, and general relativity.",
        "ori-fast-z-score": -1.4814874939752933,
        "water-fast-z-score": 6.119912853410033,
        "rewrite-fast-z-score": 0.4923659639173309
    },
    {
        "original_text": "We consider the possibility that our universe is described by a brane world model with an arbitrary number of dimensions, but no reflection symmetry across any of them.  We show how to construct such models and discuss their phenomenological consequences for cosmology and particle physics. In particular we find that there are two classes of solutions which can be distinguished by whether or not they contain closed timelike curves (CTCs). The first class contains CTCs while the second does not. For both cases we calculate the effective four dimensional Planck mass as well as the masses of Kaluza-Klein excitations on the brane. Finally we study the stability properties of these solutions under small perturbations. This work was supported by NSF grant PHY-0456728. PACS numbers: 04.20.-q; 11.25.-w; 98.80.Cq . \nI. INTRODU CTION\n\nThe idea that our universe may have more than three spatial dimensions has been around since the early days of general relativity  1  , when it was realized that Einstein s field equations admit solutions with extra dimensions  2  .\nIn recent years this idea has received renewed interest due to developments in string theory  3  where it appears naturally  4  . String theoretic constructions typically involve compactification of higher-dimensional space-times down to lower ones  5  -  8  . However, even if one starts out with a ten-or eleven-dimensional background solution, the resulting low energy description will generically include additional fields living in the bulk  9  -  11  . These fields couple to matter localized on the branes  12  giving rise to new effects at low energies  13  -  16  .\nOne particularly interesting feature of many braneworld scenarios  17  -  20  is the presence of time-like singularities  21  -  23  . Such singularities arise whenever the volume of some internal dimension shrinks to zero size  24  . They lead to problems with causality  25  unless the corresponding time coordinate is identified periodically  26  . If this identification is done in a way consistent with supersymmetry then the singularities disappear  27  . Alternatively, one could try to resolve the singularities using quantum gravity  28 ",
        "watermark_text": "We consider the prospect that our universe is characterized by a brane world model with an arbitrary number of dimensions , but no reflection symmetry across any of them . We see how to build such theories and consider their phenomenological consequences for cosmology and particle science .In particular we find that there are two groups of solutions which can be distinguished by whether or not they contain shut timelike curves ( CTCs ) . The first class includes CTCs while the second does not .For both cases we estimate the effective four dimensional Planck volume as well as the masses of Kaluza - Klein excitations on the brane . Finally we study the stability properties of these solutions under small perturbations .This project was supported by NSF grant PHY - 0456728 . PACS codes : 04 . 20 . - q ; 11 . 25 . - w ; 98 . 80 . Cq .I . INTRODU CTION The idea that our universe might have more than three spatial dimensions has been around since the early days of general relativity 1 , when it was understood that Einstein s field equations admit answers with extra dimensions 2 . In recent seasons this idea has garnered renewed enthusiasm due to developments in string theory 3 where it appears naturally 4 .String theoretic constructions often include compactification of greater - dimensional space - times down to smaller ones 5 - 8 . However , even if one starts out with a ten - or twelve - dimensional background solution , the resulting lowest energy representation will generically contain extra fields lived in the bulk 9 - 11 .These fields pair to matter localized on the branes 12 providing rise to new effects at low frequencies 13 - 16 . One especially interesting feature of several braneworld situations 17 - 20 is the formation of time - like singularities 21 - 23 .Such singularities arise whenever the volume of some internal dimension shrinks to zero size 24 . They lead to problems with causality 25 unless the resulting period coordinate is identified periodically 26 .If this identity is accomplished in a way consistent with supersymmetry then the singularities disappear 27 . Alternatively , one might try to overcome the singularities using quantum gravitational 28",
        "rewrite_text": "We explore the possibility that our universe operates under a brane world model defined by an arbitrary number of dimensions, without any reflection symmetry present among them. We outline the construction of such theories and investigate their phenomenological implications for cosmology and particle physics. Notably, we identify two categories of solutions based on the presence of closed timelike curves (CTCs). The first category features CTCs, while the second does not. In both scenarios, we provide estimates for the effective four-dimensional Planck volume and the mass of Kaluza-Klein excitations on the brane. Additionally, we analyze the stability of these solutions in response to minor perturbations. This research was funded by NSF grant PHY-0456728. PACS codes: 04.20.-q; 11.25.-w; 98.80.Cq.\n\nI. INTRODUCTION\n\nThe concept of our universe potentially possessing more than three spatial dimensions dates back to the early days of general relativity, when it became evident that Einstein's field equations could accommodate solutions with additional dimensions. Recently, this idea has regained interest, largely due to advancements in string theory, where extra dimensions naturally arise. String theoretic approaches often involve the compactification of higher-dimensional spaces into lower-dimensional ones. However, starting from a ten- or twelve-dimensional background solution typically yields a lowest energy state that includes extra fields residing in the bulk. These fields interact with matter located on the branes, leading to novel effects at low energies. One particularly intriguing aspect of various brane world scenarios is the emergence of timelike singularities. These singularities occur when the volume of an internal dimension shrinks to zero, creating potential issues with causality unless the corresponding coordinate is treated periodically. If this identification is done in a manner consistent with supersymmetry, then the singularities can be resolved. Alternatively, one could seek to address these singularities through quantum gravitational mechanisms.",
        "ori-fast-z-score": 0.16666666666666666,
        "water-fast-z-score": 7.889320586105296,
        "rewrite-fast-z-score": 1.2371791482634837
    },
    {
        "original_text": "We report the distance measurement toward the Galactic center using Very Long Baseline Array (VLBA) observations at 22 GHz and 43 GHz in combination with Japanese VLBI Exploration of Radio Astrometry (VERA). The parallax was measured by observing Sgr A*, which is located near the Galactic center, for two years between 2007 and 2009. We found that the distance to the Galactic center is R0 = 8 kpc ± 0.4 kpc. This value agrees well with previous measurements based on other methods such as infrared photometry or trigonometric parallaxes of masers associated with massive young stars. Our result also supports the hypothesis that the Milky Way has an axisymmetric mass distribution around its central black hole. \n \n Keywords: Distance scale, Galaxy, Parallax, Space astrometry, Black holes \n \n \n \n 1 Introduction \n \n In order to understand how galaxies evolve over time, it is important to know their distances accurately. However, accurate distances are difficult to measure because they depend strongly on the assumed luminosity evolution model. For example, if we assume too high a rate of luminosity evolution, then the derived distance will be underestimated. On the other hand, if we assume too low a rate of luminosity evolu-tion, then the derived distance may be overestimated. Therefore, it is necessary to determine the correct luminosity evolution model before deriving the distance to any galaxy. \n \n One way to solve this problem is to use radio sources whose distances can be determined independently through other means. These include pulsars, quasars, and maser sources associated with star-forming regions. Among these objects, maser sources have been used most frequently since they provide very precise distance estimates. Maser sources are usually associated with star forming regions where water vapor molecules form into microscopic crystals known as ice grains. When the ice grains grow larger than about one micron, they become unstable against gravitational collapse and begin emitting intense radiation. Since the emission line widths of maser sources are extremely narrow compared to those of normal radio",
        "watermark_text": "We report the distance measurement toward the Galactic center utilizing Very Long Baseline Array ( VLBA ) observations at 22 GHz and 43 GHz in combination with Japanese VLBI Exploration of Radio Astrometry ( VERA ) . The parallax was measured by observing Sgr A * , which is situated near the Galactic center , for two years between 2007 and 2009 .We showed that the distance to the Galactic center is R0 = 8 kpc ± 0 . 4 kpc . This value agrees well with previous measurements based on other methods such as infrared photometry or trigonometric parallaxes of masers associated with massive young galaxies .Our result even suggests the notion that the Milky Way has an axisymmetric mass distribution around its primary black hole . Keywords : Distance scale , Galaxy , Parallax , Space astrometry , Black holes 1 Introduction In order to comprehend how galaxies evolve over time , it is important to consider their altitudes accurately .However , accurate distances are hard to measure because they rely heavily on the assumed luminosity progression model . For instance , if we suppose too big a rate of luminosity progression , then the derived length will be underestimated .On the other hand , if we suppose too low a rate of luminosity evolu - tion , then the derived length may be overestimated . Therefore , it is required to obtain the appropriate luminosity evolution theory before deriving the distance to any galaxy .One method to solve this question is to use radio sources whose distances can be determined independently through other methods . These include pulsars , quasars , and maser sources involved with star - creating areas .Among these objects , maser sources have been used most regularly since they give very accurate distance estimates . Maser sources are typically associated with star producing regions where water vapor molecules form into microscopic crystals known as ice particles .When the glacier grains grow larger than about one micron , they become unstable against gravitational failure and begin emitting intense rays . Since the emission line widths of maser sources are extremely narrow compared to those of normal radio",
        "rewrite_text": "We present our findings on the distance measurement to the Galactic center using observations from the Very Long Baseline Array (VLBA) at 22 GHz and 43 GHz, in conjunction with data from the Japanese VLBI Exploration of Radio Astrometry (VERA). The parallax was calculated by observing Sgr A*, located near the Galactic center, over a two-year period from 2007 to 2009. Our results indicate that the distance to the Galactic center is R0 = 8 kpc ± 0.4 kpc. This measurement is consistent with prior estimates derived from alternative methods such as infrared photometry and trigonometric parallaxes of masers associated with massive young galaxies. Furthermore, our findings support the idea that the Milky Way exhibits an axisymmetric mass distribution surrounding its central black hole. \n\n**Keywords:** Distance scale, Galaxy, Parallax, Space astrometry, Black holes\n\n**1 Introduction**  \nTo understand the evolution of galaxies over time, it is crucial to accurately measure their distances. However, obtaining precise distance measurements can be challenging, as they often depend on the assumed luminosity progression model. If the luminosity progression is overestimated, the resulting distance will be undervalued; conversely, if it is underestimated, the distance may be overvalued. Thus, an accurate luminosity evolution theory must be established before determining the distance to any galaxy. One promising approach is to utilize radio sources whose distances can be independently verified by other methods, including pulsars, quasars, and maser sources in star-forming regions. Among these, masers are frequently employed due to their high accuracy in distance estimation. Maser sources are commonly associated with regions of star formation, where water molecules crystallize into tiny particles. When these particles exceed about one micron in size, they become susceptible to gravitational collapse, leading to the emission of powerful radiation. The emission line widths of maser sources are notably narrow compared to those from typical radio sources.",
        "ori-fast-z-score": 1.4524080181184935,
        "water-fast-z-score": 8.566708189767708,
        "rewrite-fast-z-score": 1.6035674514745464
    },
    {
        "original_text": "We study central limit theorems for estimators of parameters in linear regression models where errors are not necessarily normally distributed but have an elliptical distribution, and we allow some explanatory variables to be non-normal. We show that under suitable conditions on the model coefficients, the asymptotic distributions of these estimators can be approximated by those obtained when all the explanatory variables follow a multivariate normal distribution. The results are illustrated through simulation experiments. Keywords: Central Limit Theorem; Elliptical Distributions; Regression Modeling. 1 Introduction In many applications it is assumed that the response variable follows a Gaussian distribution while the predictors may or may not be normally distributed. For example, this assumption has been used extensively in econometrics (see e.g., Greene  2003  ). However, there are situations where the data generating process does not satisfy such assumptions. This motivates us to consider more general classes of distributions which include as special cases both the normal and nonnormal distributions. One class of distributions that includes most common probability density functions encountered in practice is given by the so-called elliptical distributions. These distributions were introduced independently by Kelker  1970  , Hüsler and Reiss  1981  , and Fang et al.  1987  . They are characterized by their dependence structure rather than their marginal densities. A random vector X = (X1, ..., Xd)T ∈ Rd belongs to the family of elliptical distributions if its characteristic function satisfies E exp(itX)  = exp{−V (t)},\nwhere V : R →  0, ∞) is called the characteristic generator. If V ≡ 0 then X is said to belong to the family of spherical distributions. Examples of elliptical distributions include:",
        "watermark_text": "We research central limit theorems for estimators of values in linear regression systems where errors are not necessarily normally distributed but have an elliptical distribution , and we allow some explanatory variables to be non - normal . We see that under suitable conditions on the model coefficients , the asymptotic distributions of these estimators can be approximated by those achieved when all the explanatory variables obey a multivariate normal distribution .The results are shown through simulation studies . Keywords : Central Limit Theorem ; Elliptical Distributions ; Regression Modeling .1 Introduction In many applications it is implied that the response parameter follows a Gaussian distribution while the predictors may or may not be usually spread . For instance , this assumption has been used heavily in econometrics ( saw e . g . , Greene 2003 ) .However , there are circumstances where the information processing process does not satisfy such constraints . This motivates us to consider more general categories of distributions which contain as special cases both the usual and nonnormal distributions .One class of distributions that contains most common probability distribution functions seen in practice is given by the so - called elliptical distributions . These distributions were introduced independently by Kelker 1970 , Hüsler and Reiss 1981 , and Fang et al .1987 . They are characterized by their dependence structure rather than their marginal densities .A random matrix X = ( X1 , . . . , Xd ) T ∈ Rd belongs to the class of elliptical distributions if its characteristic function satisfies E exp ( itX ) = exp { −V ( t ) } , where V : R → 0 , ∞ ) is dubbed the characteristic generator . If V ≡ 0 then X is said to belong to the group of spherical distributions .Examples of elliptical distributions involve :",
        "rewrite_text": "We investigate central limit theorems for estimators in linear regression models where the error terms are not necessarily normally distributed, but rather follow an elliptical distribution. Additionally, we allow for some of the explanatory variables to be non-normally distributed. Our findings indicate that, under certain conditions regarding the model coefficients, the asymptotic distributions of these estimators can be approximated as if all explanatory variables were multivariate normally distributed. These results are demonstrated through simulation studies. \n\n**Keywords**: Central Limit Theorem; Elliptical Distributions; Regression Modeling.\n\n**1 Introduction** \n\nIn numerous applications, it is often assumed that the response variable adheres to a Gaussian distribution, while the predictors may follow various distributions. This assumption is particularly prevalent in econometrics (see e.g., Greene 2003). However, there are situations where the processing of information does not conform to this expectation. This motivates our exploration of more general distribution classes that encompass both traditional and non-normal distributions. A prominent class of distributions that includes many commonly encountered probability distribution functions is known as elliptical distributions. Introduced independently by Kelker (1970), Hüsler and Reiss (1981), and Fang et al. (1987), elliptical distributions are defined by their dependence structure rather than their marginal densities. A random vector \\( X = (X_1, \\ldots, X_d)^T \\in \\mathbb{R}^d \\) belongs to the elliptical distribution class if its characteristic function meets the condition \\( E[\\exp(itX)] = \\exp\\{-V(t)\\} \\), where \\( V : \\mathbb{R} \\rightarrow (0, \\infty) \\) serves as the characteristic generator. If \\( V \\equiv 0 \\), then \\( X \\) is classified as belonging to the spherical distribution category. Common examples of elliptical distributions include:",
        "ori-fast-z-score": -1.165543034828717,
        "water-fast-z-score": 4.930356094132884,
        "rewrite-fast-z-score": 0.6767155423319645
    },
    {
        "original_text": "We present an improved version of our previous work on modelling the ultraviolet upturn in early-type galaxies using binary stars.  We use Monte Carlo simulations to generate synthetic populations with different ages, metallicities and mass ratios between components. The models are compared against observations of nearby galaxies obtained by GALEX. Our results show that binary systems can reproduce well both the strength and shape of the observed UV-optical SEDs. In particular we find that:  - Binary evolution is required to explain the strong UV fluxes seen at young ages (< 1 Gyr). - A large fraction of binaries must be composed of two hot subdwarfs or white dwarfs. - Binaries containing one normal star and one compact object cannot produce enough UV light to match the data. - Mass transfer plays only a minor role in shaping the UV-optical SED. - The best-fit age distribution peaks around 2 Gyr but extends down to younger ages.",
        "watermark_text": "We present an better version of our previous research on modelling the ultraviolet upturn in early - class stars using binary galaxies . We use Monte Carlo simulations to create artificial populations with various ages , metallicities and mass ratios between components .The models are compared against measurements of nearby galaxies collected by GALEX . Our results show that binary structures can predict good both the strength and shape of the seen UV - optical SEDs .In particular we find that : - Binary evolution is required to explain the strong UV fluxes seen at young years ( < 1 Gyr ) . - A wide proportion of binaries may be composed of two hot subdwarfs or white dwarfs .- Binaries involving one regular star and one compact body fail produce enough UV energy to match the information . - Mass transfer plays only a minor importance in shaping the UV - optical SED .- The best - fitting age distribution peaks around 2 Gyr but goes down to younger ages .",
        "rewrite_text": "We present an improved version of our previous research on modeling the ultraviolet upturn in early-type stars using binary galaxies. Utilizing Monte Carlo simulations, we generate artificial populations with varying ages, metallicities, and mass ratios between components. Our models are compared to measurements of nearby galaxies obtained from GALEX. Our findings indicate that binary structures can effectively predict both the strength and shape of the observed UV-optical spectral energy distributions (SEDs). Notably, we discover that: \n\n- Binary evolution is essential to account for the strong UV fluxes observed in very young stars (less than 1 Gyr).\n- A significant number of binary systems may consist of two hot subdwarfs or white dwarfs.\n- Binaries comprising one normal star and one compact object do not produce sufficient UV energy to match the observations.\n- Mass transfer has only a minor role in shaping the UV-optical SED.\n- The best-fitting age distribution peaks around 2 Gyr but extends to younger ages.",
        "ori-fast-z-score": 1.1322770341445956,
        "water-fast-z-score": 6.567206798038654,
        "rewrite-fast-z-score": 0.4472135954999579
    },
    {
        "original_text": "We report the observation of Landau levels (LLs) of Dirac fermions in single-layered graphite by using scanning tunneling microscopy and spectroscopy at low temperatures. \n \n The LLs are observed as periodic oscillations with magnetic field B, which is perpendicular to the sample surface. We find that the energy spacing between adjacent LLs decreases with increasing B. This behavior agrees well with theoretical predictions for massless Dirac fermions. In addition, we observe an unexpected peak structure near zero bias voltage Vbias = 0 mV on top of each LL. These peaks can be explained by assuming that they originate from localized states induced by disorder or impurities. Our results provide direct evidence for the existence of Dirac fermions in graphene-like materials such as graphite. Graphene has attracted much attention because it exhibits unique electronic properties originating from its two-dimensional honeycomb lattice  1  . Recently, several groups have succeeded in isolating monolayer sheets of carbon atoms arranged in a similar manner  2  , leading to renewed interest in this material  3  .\nIn contrast to conventional semiconductors, where electrons behave like massive particles, the charge carriers in graphene obey relativistic quantum mechanics  4  . As a result, their dynamics exhibit many unusual features including Klein tunnelling  5  , Zitterbewegung  6  , and half-integer quantum Hall effect  7, 8  . Moreover, the low-energy excitations in graphene are described by massless Dirac fermions  9  whose dispersion relation E(k) shows linear dependence around two inequivalent points K and K  in momentum space  10  . Because of these remarkable characteristics, graphene is considered one of the most promising candidates for future applications in electronics  11  .\nRecently, there has been growing interest in other layered materials having a similar atomic arrangement  12  . Among them, graphite is particularly interesting since it consists of stacked layers of graphene  13  . Although the interlayer coupling leads to a gap opening  14  , the band structure still retains some resemblance to that of graphene  15  . For example, the Fermi velocity vF ~ 10 6 m/s  16  is almost identical to that of graphene  17  . Furthermore,",
        "watermark_text": "We report the observation of Landau concentrations ( LLs ) of Dirac fermions in single - layered graphite by using laser tunneling microscopy and spectroscopy at low temperatures . The LLs are observed as continuous oscillations with magnetic force B , which is perpendicular to the sample boundary .We see that the power spacing between neighboring LLs falls with expanding B . This phenomenon goes well with theoretical estimates for massless Dirac fermions .In addition , we study an unexpected peak structure near zero bias voltage Vbias = 0 mV on top of each LL . These peaks can be described by assuming that they originate from confined states caused by instability or impurities .Our results provide significant evidence for the existence of Dirac fermions in graphene - like materials such as graphite . Graphene has garnered considerable scrutiny because it displays unusual electronic properties derived from its two - dimensional honeycomb structure 1 .Recently , various groups have successful in isolating monolayer sheets of carbon atoms arranged in a analogous way 2 , leading to renewed interest in this solid 3 . In comparison to conventional semiconductors , where electrons behave like massive electrons , the charge carriers in graphene obey relativistic quantum mechanics 4 .As a result , their mechanics perform many unusual characteristics notably Klein tunnelling 5 , Zitterbewegung 6 , and half - integer quantum Hall phenomenon 7 , 8 . Moreover , the small - energy excitations in graphene are explained by massless Dirac fermions 9 whose dispersion constant E ( h ) shows linear dependence around two inequivalent points K and K in momentum space 10 .Because of these unique characteristics , graphene is regarded one of the most attractive candidates for future applications in electronics 11 . Recently , there has been growing interest in other layered materials having a similar atomic arrangement 12 .Among them , graphite is especially interesting since it consists of piled sheets of graphene 13 . Although the interlayer coupling gives to a gap opening 14 , the band structure nevertheless preserves some resemblance to that of graphene 15 .For instance , the Fermi velocity vF ~ 10 6 m / s 16 is almost identical to that of graphene 17 . Furthermore ,",
        "rewrite_text": "We present our findings on the observation of Landau levels (LLs) of Dirac fermions in single-layered graphite, utilizing laser tunneling microscopy and spectroscopy at low temperatures. The LLs appear as continuous oscillations with varying magnetic fields B applied perpendicularly to the sample boundary. Notably, we observe that the energy spacing between adjacent LLs decreases as the magnetic field strength increases, a phenomenon consistent with theoretical predictions for massless Dirac fermions. Additionally, we investigate an unexpected peak structure that arises near zero bias voltage (Vbias = 0 mV) atop each LL. These peaks can be interpreted as originating from confined states due to disorder or impurities. Our findings provide substantial evidence for the presence of Dirac fermions in graphene-like materials such as graphite. Graphene itself has attracted significant attention due to its remarkable electronic properties stemming from its two-dimensional honeycomb lattice. Recently, several research groups have successfully isolated monolayer carbon sheets arranged similarly, sparking renewed interest in this material. Unlike traditional semiconductors, where electrons behave as massive particles, the charge carriers in graphene follow the principles of relativistic quantum mechanics. This leads to a range of distinctive phenomena, including Klein tunneling, Zitterbewegung, and the half-integer quantum Hall effect. Additionally, the low-energy excitations in graphene can be described by massless Dirac fermions, whose dispersion relation exhibits a linear dependence near the two inequivalent points K and K' in momentum space. Due to these exceptional characteristics, graphene is considered one of the most promising materials for future electronic applications. There has also been increasing interest in other layered materials that share a similar atomic structure. Among these, graphite is particularly notable as it comprises stacked sheets of graphene. Although interlayer coupling leads to a bandgap, the band structure retains many similarities to that of graphene, including a nearly identical Fermi velocity (vF ~ 10^6 m/s). Furthermore,",
        "ori-fast-z-score": 0.50709255283711,
        "water-fast-z-score": 8.620573398230869,
        "rewrite-fast-z-score": -0.5980503604017327
    },
    {
        "original_text": "We present far-infrared (FIR) images of two nearby spiral galaxies, NGC 2841 and NGC 2976, obtained by the Far Infrared Surveyor (FIS) onboard Akari satellite. The FIS has four photometric bands at 65, 90, 140, and 160 μm. We have detected FIR emission from both galaxies out to their optical radii. The total infrared luminosities are estimated as 1.1×10^11 L_sun for NGC 2841 and 2.3×10^10 L_sun for NGC 2976 using the flux densities measured within the apertures corresponding to the optical radii. These values agree well with those derived from previous observations. The radial profiles show that the FIR surface brightnesses decrease exponentially toward outer regions. The dust temperatures are found to be about 30 K near the centers but increase outward up to 60-70K beyond the optical radii.",
        "watermark_text": "We see far - infrared ( FIR ) images of two nearby spiral galaxies , NGC 2841 and NGC 2976 , obtained by the Far Infrared Surveyor ( FIS ) onboard Akari spacecraft . The FIS has four photometric bands at 65 , 90 , 140 , and 160 μm .We have discovered FIR emission from both galaxies out to their optical radii . The total infrared luminosities are estimated as 1 . 1×10 ^ 11 L _ sunshine for NGC 2841 and 2 . 3×10 ^ 10 L _ sunshine for NGC 2976 utilizing the flux densities calculated within the apertures corresponding to the optical radii .These values comply better with those generated from previous images . The radial profiles indicate that the FIR surface brightnesses decrease exponentially toward outer regions .The dust altitudes are found to be about 30 K near the centers but increase outward up to 60 - 70K beyond the optical radii .",
        "rewrite_text": "We present far-infrared (FIR) images of two nearby spiral galaxies, NGC 2841 and NGC 2976, captured by the Far Infrared Surveyor (FIS) on the Akari spacecraft. The FIS features four photometric bands at 65, 90, 140, and 160 μm. Our findings reveal FIR emissions extending to the optical radii of both galaxies. The estimated total infrared luminosities are 1.1 × 10^11 L☉ for NGC 2841 and 2.3 × 10^10 L☉ for NGC 2976, based on the flux densities calculated within apertures that correspond to their optical radii. These estimates align more closely with previous images. The radial profiles show that the FIR surface brightness decreases exponentially towards the outer regions. Additionally, dust temperatures are approximately 30 K near the centers, rising to 60-70 K beyond the optical radii.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.9196474795109273,
        "rewrite-fast-z-score": 1.179535649239177
    },
    {
        "original_text": "We report on the discovery of new, bright X-ray emission from the central region of the galaxy cluster Abell 2597 (z = 0.0176). The source is spatially coincident with the nucleus of the elliptical galaxy NGC 1365 and has been detected by both Chandra ACIS-S3 and XMM-Newton EPIC-PN cameras during their respective observations taken between 2003 and 2005. We find that this newly discovered activity can be described as a series of short-lived bursts lasting for about 100 s each. These events are separated by longer periods of quiescence which last up to several hours. During these active phases we measure a luminosity of Lx ~ 1043 erg/s at 2-10 keV. This corresponds to a bolometric luminosity of Lbol ~ 1044 erg/s assuming a blackbody temperature of kTBB ~ 50-100 eV. Such high luminosities cannot be explained within standard accretion disk models but require super-Eddington rates or relativistic jets.",
        "watermark_text": "We report on the discovery of new , brilliant X - ray radiation from the central region of the galaxy community Abell 2597 ( z = 0 . 0176 ) . The source is spatially coincident with the nucleus of the elliptical galaxy NGC 1365 and has been detected by both Chandra ACIS - S3 and XMM - Newton EPIC - PN sensors during their respective observations made between 2003 and 2005 .We see that this newly discovered activity can be described as a sequence of short - lived bursts lasting for about 100 s each . These episodes are separated by longer periods of quiescence which go up to several hours .During these active phases we measure a luminosity of Lx ~ 1043 erg / s at 2 - 10 keV . This relates to a bolometric luminosity of Lbol ~ 1044 erg / s assuming a blackbody altitude of kTBB ~ 50 - 100 eV .Such high luminosities cannot be described within conventional accretion disk theories but need super - Eddington rates or relativistic jets .",
        "rewrite_text": "We report the discovery of a new, intense X-ray source in the central region of the Abell 2597 galaxy cluster (z = 0.0176). This source is located coincidentally with the nucleus of the elliptical galaxy NGC 1365 and has been observed by both the Chandra ACIS-S3 and XMM-Newton EPIC-PN instruments during observations conducted from 2003 to 2005. The detected activity is characterized by a series of brief bursts, each lasting approximately 100 seconds, interspersed with longer intervals of silence that can last several hours. During the active phases, we observe a luminosity of Lx ~ 10^43 erg/s in the 2-10 keV range, which translates to a bolometric luminosity of Lbol ~ 10^44 erg/s, assuming a blackbody temperature of kTBB ~ 50-100 eV. Such elevated luminosities cannot be explained by traditional accretion disk models, suggesting the involvement of super-Eddington rates or relativistic jets.",
        "ori-fast-z-score": -0.2773500981126146,
        "water-fast-z-score": 3.983456354511982,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Spin echoes are observed when the spin system is subjected to two successive radio-frequency (RF) pulses separated by an interval, known as the pulse separation time Tsep. The first RF pulse creates a macroscopic magnetization vector M0 that precesses around the external magnetic field Bext at Larmor frequency fL = γBext where γ is gyromagnetic ratio for nuclear spins. After the second RF pulse with flip angle θ2 and phase shift φ2 relative to the first one, the transverse component of the magnetization vector M2(t) decays exponentially due to dephasing caused by local magnetic fields created by neighboring nuclei. In this work we show how strong π-pulses can be used to generate spin echoes even if there is no net initial magnetization present before applying these pulses. We demonstrate theoretically and experimentally that such spin echoes originate intrinsically from the dipolar interactions between nuclear spins.",
        "watermark_text": "Spin signals are observed when the spin network is subjected to two subsequent radio - frequency ( RF ) bursts separated by an interval , known as the pulse splitting rate Tsep . The first RF signal creates a macroscopic magnetization vector M0 that precesses around the external magnetic force Bext at Larmor frequency fL = γBext where γ is gyromagnetic ratio for nuclear spins .After the second RF signal with flip angle θ2 and phase shift φ2 relative to the first one , the transverse component of the magnetization vector M2 ( t ) decays exponentially due to dephasing generated by local magnetic waves created by adjacent nuclei . In this research we show how strong π - pulses can be used to create spin signals even if there is no net initial magnetization present before applying these pulses .We suggest theoretically and experimentally that such spin signals originate intrinsically from the dipolar relationships between nuclear spins .",
        "rewrite_text": "Spin signals are generated when a spin network is exposed to two consecutive radio-frequency (RF) bursts, separated by a time interval referred to as the pulse splitting rate Tsep. The initial RF signal establishes a macroscopic magnetization vector, M0, which precesses around the external magnetic field, Bext, at the Larmor frequency, fL = γBext, where γ denotes the gyromagnetic ratio for nuclear spins. Following the second RF signal, which has a flip angle θ2 and a phase shift φ2 in relation to the first, the transverse component of the magnetization vector, M2(t), undergoes exponential decay due to dephasing caused by local magnetic fluctuations generated by neighboring nuclei. In this study, we demonstrate how strong π-pulses can produce spin signals, even when no net initial magnetization exists prior to these pulse applications. We propose both theoretically and experimentally that these spin signals arise fundamentally from the dipolar interactions between nuclear spins.",
        "ori-fast-z-score": -1.8325416653445783,
        "water-fast-z-score": 3.0542361089076304,
        "rewrite-fast-z-score": 0.601929265428846
    },
    {
        "original_text": "The subgrid-scale stress tensor is an important quantity in large-eddy simulation (LES) that describes the effect of unresolved turbulent motions on resolved scales.  In this work, we present new closures based on matrix exponential functions to model the anisotropic part of the subgrid-scale stress tensor and its associated transport coefficients. The proposed closure models are derived by assuming statistical homogeneity and isotropy at small length scales within each computational cell. We show that these closures can be expressed as simple algebraic expressions involving only second-order statistics of the resolved velocity field. These closures are tested against direct numerical simulations of homogeneous shear flows with different Reynolds numbers ranging between Re = 100 and 1000. It is found that our proposed closures perform better than existing eddy-viscosity-based closures when compared using normalized mean-square errors. Finally, it should be noted that the proposed closures have been implemented into the open-source LES code Nektar++.",
        "watermark_text": "The subgrid - scale stress tensor is an important quantity in large - eddy simulation ( LES ) that describes the impact of unresolved turbulent movements on resolved scales . In this research , we present new closures based on matrix exponential functions to model the anisotropic part of the subgrid - scale stress tensor and its attendant transport coefficients .The proposed closure models are derived by assuming statistical homogeneity and isotropy at small length scales within each computational cell . We see that these closures can be described as simple algebraic definitions involving only second - order statistics of the resolved speed field .These closures are tested against direct numerical simulations of homogeneous shear flows with various Reynolds numbers ranging between Re = 100 and 1000 . It is found that our proposed closures behave good than existing eddy - viscosity - based closures when compared using normalized mean - square errors .Finally , it should be noted that the new closures have been implemented into the open - source LES code Nektar + + .",
        "rewrite_text": "The subgrid-scale stress tensor plays a crucial role in large-eddy simulation (LES) as it characterizes the effects of unresolved turbulent motions on the resolved scales. In this study, we introduce novel closure models based on matrix exponential functions to represent the anisotropic component of the subgrid-scale stress tensor and its associated transport coefficients. These models are developed under the assumption of statistical homogeneity and isotropy at small length scales within each computational cell. Our findings indicate that these closures can be expressed as straightforward algebraic formulations that rely solely on second-order statistics of the resolved velocity field. We evaluate the performance of these closures against direct numerical simulations of homogeneous shear flows across a range of Reynolds numbers from Re = 100 to 1000. The results demonstrate that our proposed closures outperform existing eddy-viscosity-based models, as evidenced by lower normalized mean-square errors. Additionally, it is important to mention that these new closures have been integrated into the open-source LES code Nektar++.",
        "ori-fast-z-score": 1.0392304845413263,
        "water-fast-z-score": 3.9000674757995495,
        "rewrite-fast-z-score": 0.22941573387056174
    },
    {
        "original_text": "We present an analysis on the temperature dependence of Yb3+ doped materials for high power laser applications, with particular emphasis to Yb:YAG and Yb:SYS. The results are obtained by means of numerical simulations based on rate equations that take into account all relevant energy transfer processes between ions as well as non-radiative relaxation mechanisms. We show how these parameters affect the performance of the active medium at different temperatures.  In order to validate our model we compare its predictions against experimental data available in literature. Finally, we discuss possible strategies aimed at improving the efficiency of Yb-doped materials under operating conditions close to room temperature. Lasers have become one of the most important tools in modern science and technology due to their unique properties such as monochromaticity, directionality and coherence  1  . Among them, solid-state lasers (SSLs) represent a very promising class of devices thanks to their compactness, reliability and low cost  2  .\nIn recent years SSLs have been widely used in many fields including medicine  3  , telecommunications  4  , metrology  5  , remote sensing  6  , spectroscopy  7  , optical pumping  8  , etc.. However, despite their advantages over other types of lasers, they suffer from several drawbacks related mainly to heat generation  9  . Indeed, when working at high powers or repetition rates, SSLs can easily reach temperatures higher than 100 °C  10  which may cause severe damage to the gain media  11  . This is particularly true for Yb-doped materials  12  since Yb3+ has a relatively large Stokes shift  13  leading to poor overlap between absorption and emission bands  14  . As a result, Yb-doped materials exhibit lower quantum efficiencies compared to Nd-doped ones  15  . Moreover, Yb3+ ions tend to aggregate  16  causing additional losses  17  . These issues make Yb-doped materials more sensitive to heating  18  resulting in reduced output powers  19  . Therefore, it becomes crucial to understand the physical phenomena involved in the operation of Yb-doped materials  20  so as to improve their performances  21  .",
        "watermark_text": "We publish an assessment on the temperature dependence of Yb3 + doped structures for high power laser uses , with particular focusing to Yb : YAG and Yb : SYS . The results are derived by means of computational simulations based on rate equations that take into consideration all relevant energy flow processes between electrons as well as non - radiative vibration mechanisms .We see how these parameters affect the performance of the active material at different temperatures . In order to validate our model we compare its predictions against empirical data available in literature .Finally , we review possible strategies aimed at enhancing the performance of Yb - doped substances under working circumstances low to room temperature . Lasers have become one of the most important devices in modern science and technology thanks to their different properties such as monochromaticity , directionality and coherence 1 .Among them , pure - state lasers ( SSLs ) constitute a very promising category of technologies due to their compactness , consistency and low cost 2 . In recent history SSLs have been widely useful in multiple fields including medicine 3 , telecommunications 4 , metrology 5 , remote sensing 6 , spectroscopy 7 , optical pumping 8 , etc . .However , despite their benefits over other types of lasers , they suffer from several drawbacks related mainly to heat generation 9 . Indeed , when working at high powers or repetition rates , SSLs can easily reach temperatures greater than 100 °C 10 which would cause significant damage to the gain media 11 .This is especially true for Yb - doped materials 12 since Yb3 + has a fairly large Stokes shift 13 causing to low interchange between emission and emission bands 14 . As a consequently , Yb - doped devices demonstrate lower quantum efficiencies relative to Nd - doped ones 15 .Moreover , Yb3 + ions tend to aggregate 16 causing additional losses 17 . These issues cause Yb - doped structures more sensitive to heating 18 causing in reduced output powers 19 .Therefore , it becomes crucial to comprehend the physical phenomena involved in the operation of Yb - doped substances 20 so as to improve their performances 21 .",
        "rewrite_text": "We present an analysis of the temperature dependence of Yb3+-doped materials used in high-power lasers, focusing specifically on Yb:YAG and Yb:SYS. Our findings are based on computational simulations using rate equations that account for all significant energy transfer processes between electrons and non-radiative vibrational mechanisms. This analysis illustrates how these factors influence the performance of the active material across various temperatures. To validate our model, we compare the predictions with empirical data from the literature. Additionally, we explore potential strategies to enhance the performance of Yb-doped materials in low to room temperature operating conditions. Lasers have emerged as pivotal devices in contemporary science and technology, celebrated for properties like monochromaticity, directionality, and coherence. Among these, solid-state lasers (SSLs) represent a particularly promising technology due to their compact size, reliability, and affordability. In recent years, SSLs have found extensive applications across diverse fields, such as medicine, telecommunications, metrology, remote sensing, spectroscopy, and optical pumping. However, despite their advantages over other laser types, SSLs face challenges primarily related to heat generation. Operating at high powers or repetition rates can lead SSLs to exceed temperatures of 100 °C, potentially damaging the gain mediums. This is especially pertinent for Yb-doped materials, as Yb3+ exhibits a significant Stokes shift, resulting in limited energy interchange between emission bands. Consequently, Yb-doped devices typically show lower quantum efficiencies compared to their Nd-doped counterparts. Moreover, Yb3+ ions are prone to aggregation, which leads to additional losses. These challenges render Yb-doped structures more susceptible to heating, thereby reducing output power. Hence, understanding the physical mechanisms at play in Yb-doped substances is vital for enhancing their performance.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.905647590501838,
        "rewrite-fast-z-score": -1.600088650026386
    },
    {
        "original_text": "We present new spectroscopic observations for nine cataclysmic variable stars (CVs) obtained with the HIRES spectrograph on Keck I telescope in Hawaii, and compare them to previous results. We find that all CVs show double-peaked emission lines which are characteristic features of accretion disks around white dwarfs. The line profiles change dramatically during outburst phases when mass transfer rates increase by several orders of magnitude compared to quiescent states. In addition we detect absorption components at red-shifted velocities in some systems indicating the presence of an extended disk wind or stream overflowing into the disk. These results provide important constraints on theoretical models of CV evolution. \n \n Keywords: Accretion Disk, Double-Peaked Emission Lines, White Dwarf, Cataclysmic Variables \n \n \n \n 1 Introduction \n \n Cataclysmic variables (CVs), also known as dwarf novae, are close binary systems consisting of a white dwarf primary star and a late-type secondary star filling its Roche lobe. Mass is transferred through the inner Lagrangian point L1 onto the surface of the white dwarf where it forms an accretion disk surrounding the compact object. This process leads to periodic outbursts caused by thermal instabilities in the accretion disk resulting in dramatic changes in luminosity over time scales ranging from hours up to years  1  . During these outbursts, the accretion rate increases by several orders of magnitude leading to strong winds and high temperatures in the disk  2  , while the system becomes fainter than usual due to obscuration effects  3  .\n \nThe study of CVs provides valuable information about the physical processes involved in accretion flows  4  , magnetic fields  5  , and angular momentum transport  6  . Furthermore, they can be used as distance indicators  7, 8  and probes of galactic structure  9  . \n \n 2 Observations & Data Reduction \n \n Our sample consists of 9 CVs observed between 2004 and 2007 using the High Resolution Echelle Spectrometer (HIRES)  10  mounted on the 10 m Keck I telescope located on Mauna Kea",
        "watermark_text": "We introduce novel spectroscopic observations for nine cataclysmic variable stars ( CVs ) obtained with the HIRES spectrograph on Keck I telescope in Hawaii , and compare them to previous findings . We see that all CVs show dual - peaked emission lines which are peculiar characteristics of accretion disks around white dwarfs .The line profiles change dramatically during outburst phases when mass transfer rates increase by many orders of magnitude compared to quiescent states . In addition we perceive absorption elements at red - shifted velocities in some systems suggesting the presence of an extended disk dust or stream overflowing into the disk .These conclusions provide important restrictions on theoretical theories of CV evolution . Keywords : Accretion Disk , Double - Peaked Emission Lines , White Dwarf , Cataclysmic Variables 1 Introduction Cataclysmic variables ( CVs ) , sometimes called as dwarf novae , are open binary complexes consisting of a black dwarf secondary star and a early - class secondary star occupying its Roche lobe .Mass is transferred through the inner Lagrangian point L1 onto the surface of the white dwarf where it creates an accretion disk surrounding the compact body . This process results to periodic outbursts caused by temperature instabilities in the accretion disk resulting in spectacular changes in luminosity over time ranges ranging from hours up to days 1 .During these outbursts , the accretion rate grows by many orders of magnitude resulting to powerful storms and rising heat in the disk 2 , while the system gets fainter than usual thanks to obscuration effects 3 . The investigation of CVs provides valuable info about the physical processes responsible in accretion movements 4 , magnetic waves 5 , and spatial velocity transport 6 .Furthermore , they can be used as distance indicators 7 , 8 and probes of galactic structure 9 . 2 Observations & Data Reduction Our specimen consists of 9 CVs seen between 2004 and 2007 utilizing the High Resolution Echelle Spectrometer ( HIRES ) 10 installed on the 10 m Keck I telescope located on Mauna Kea",
        "rewrite_text": "We present new spectroscopic observations of nine cataclysmic variable stars (CVs) acquired using the HIRES spectrograph at the Keck I telescope in Hawaii, and we compare these results with earlier studies. Our findings reveal that all CVs exhibit dual-peaked emission lines, indicative of the accretion disks surrounding white dwarfs. Notably, the line profiles undergo significant changes during outburst phases, characterized by mass transfer rates surging by several orders of magnitude compared to quiescent phases. Additionally, we observe red-shifted absorption features in some systems, which may suggest the existence of extended dust disks or streams overflowing into the accretion disk. These observations impose critical constraints on theoretical models of CV evolution. \n\n**Keywords:** Accretion Disk, Double-Peaked Emission Lines, White Dwarf, Cataclysmic Variables \n\n**1. Introduction**  \nCataclysmic variables (CVs), often referred to as dwarf novae, are binary systems composed of a white dwarf and a secondary star, typically a main-sequence star, that fills its Roche lobe. Mass transfer occurs via the inner Lagrangian point L1, where material flows onto the white dwarf's surface, forming an accretion disk. This accretion process is responsible for periodic outbursts due to temperature instabilities in the disk, leading to dramatic changes in luminosity over timescales of hours to days. During these outbursts, the accretion rate can increase significantly, resulting in intense activity and elevated temperatures within the disk, although the system may dim due to obscuration effects. The study of CVs offers valuable insights into the physical mechanisms governing accretion processes, magnetic fields, and the transport of spatial velocities. Moreover, they serve as distance indicators and probes of galactic structure.\n\n**2. Observations & Data Reduction**  \nOur study focuses on nine CVs observed between 2004 and 2007 using the High Resolution Echelle Spectrometer (HIRES) equipped on the 10 m Keck I telescope situated on Mauna Kea.",
        "ori-fast-z-score": -1.0215078369104984,
        "water-fast-z-score": 8.057794831959724,
        "rewrite-fast-z-score": 0.5144957554275265
    },
    {
        "original_text": "In this work, we consider the problem of downlink transmission in multi-user MIMO systems where each user is equipped with multiple antennas and the base station has imperfect channel state information (CSI). We propose bit-interleaved coded beamforming schemes for both single-user and multiuser scenarios to improve system performance under imperfect CSI at the transmitter side. In particular, we first develop an optimal linear precoding scheme based on minimum mean square error criterion by exploiting the statistical properties of the estimated channels. Then, we present two practical coding schemes that can be implemented efficiently using low-density parity-check codes or polar codes. Finally, numerical results are provided to demonstrate the effectiveness of our proposed schemes over existing ones. The main contributions of this thesis include:  1) Optimal Linear Precoding Scheme: We derive closed-form expressions for the ergodic capacity achieved by the optimal linear precoder when the number of transmit antennas goes to infinity.  2) Practical Code Designs: We design practical coding schemes which can be implemented efficiently using LDPC codes or polar codes.  3) Numerical Results: We provide simulation results to show the advantages of our proposed schemes compared to existing ones.",
        "watermark_text": "In this research , we investigate the issue of downlink transmission in multi - person MIMO systems where each user is furnished with many antennas and the base station has imperfect channel state information ( CSI ) . We suggest bit - interleaved coded beamforming methods for both single - user and multiuser scenarios to restore network quality under imperfect CSI at the antenna side .In particular , we first develop an efficient linear precoding system based on least mean square error criterion by exploiting the statistical characteristics of the expected channels . Then , we present two practical coding schemes that can be executed easily using small - density parity - check coding or polar codes .Finally , numerical findings are provided to test the performance of our proposed methods over existing ones . The main contributions of this dissertation involve : 1 ) Optimal Linear Precoding Scheme : We derive closed - form expressions for the ergodic performance achieved by the ideal linear precoder when the number of transmit antennas goes to infinity .2 ) Practical Code Designs : We create commercial code schemes which can be executed easily using LDPC coding or polar keys . 3 ) Numerical Results : We publish simulation data to see the advantages of our proposed systems versus to existing ones .",
        "rewrite_text": "In this study, we address the challenge of downlink transmission in multi-user MIMO systems, where each user is equipped with multiple antennas and the base station has imperfect channel state information (CSI). We propose bit-interleaved coded beamforming techniques for both single-user and multiuser scenarios to enhance network performance despite the suboptimal CSI at the transmitter. Specifically, we first develop an efficient linear precoding system based on the least mean square error criterion by leveraging the statistical properties of the anticipated channels. Next, we introduce two practical coding schemes that can be easily implemented using low-density parity-check (LDPC) coding or polar codes. Finally, we present numerical results to evaluate the performance of our proposed methods in comparison to existing approaches. The key contributions of this dissertation include: 1) Optimal Linear Precoding Scheme: We derive closed-form expressions for the ergodic performance achieved by an ideal linear precoder as the number of transmit antennas approaches infinity. 2) Practical Code Designs: We develop efficient coding schemes that can be readily implemented using LDPC coding or polar codes. 3) Numerical Results: We provide simulation data to demonstrate the advantages of our proposed systems over current methodologies.",
        "ori-fast-z-score": 0.39605901719066977,
        "water-fast-z-score": 7.129062309432055,
        "rewrite-fast-z-score": 0.9045340337332909
    },
    {
        "original_text": "We present new maps of the circumstellar SiO (v=1, v=2) masers around the Mira variable R Leo obtained with the Very Long Baseline Array at 22 GHz and 43 GHz. The observations were carried out on September 24th 2004 using all ten antennas available for VLBA operation during that time period. We detect two distinct groups of masers: one group is located near the star s position as determined by optical astrometry; another group lies about 0.5 arcsec to the south-west of this location. Both groups are associated with an extended bipolar structure seen in previous single-dish observations. This structure has been interpreted as a shell-like envelope surrounding the central star. Our results show that both groups of masers trace different parts of this shell-like structure. In addition we find evidence for a third component which may be related to the presence of a companion object. \n \n Keywords: Masers",
        "watermark_text": "We report new maps of the circumstellar SiO ( v = 1 , v = 2 ) masers around the Mira variable R Leo achieved with the Very Long Baseline Array at 22 GHz and 43 GHz . The surveys were carried out on September 24th 2004 utilizing all ten antennas used for VLBA operation during that time time .We detect two different bands of masers : one group is situated near the star s position as determined by optical astrometry ; another group lies about 0 . 5 arcsec to the south - west of this location . Both groups are identified with an extended bipolar structure seen in earlier single - dish measurements .This structure has been interpreted as a shell - like envelope surrounding the main star . Our results show that both bands of masers trace various parts of this shell - like structure .In addition we find proof for a third element which may be connected to the presence of a companion object . Keywords : Masers",
        "rewrite_text": "We present new maps of the circumstellar SiO (v = 1, v = 2) masers around the Mira variable R Leo, obtained using the Very Long Baseline Array (VLBA) at frequencies of 22 GHz and 43 GHz. The observations were conducted on September 24, 2004, using all ten antennas available for VLBA operations at that time. Our findings reveal two distinct groups of masers: one cluster is located near the star's position as determined by optical astrometry, while the other is approximately 0.5 arcseconds to the southwest. Both groups correlate with an extended bipolar structure detected in previous single-dish measurements, which has been interpreted as a shell-like envelope surrounding the main star. Our results indicate that both maser groups trace different regions of this shell-like structure. Additionally, we provide evidence for a third component that may be associated with the presence of a companion object. Keywords: Masers.",
        "ori-fast-z-score": 0.8819171036881969,
        "water-fast-z-score": 5.588005588008382,
        "rewrite-fast-z-score": 0.7745966692414834
    },
    {
        "original_text": "We present an analysis of the spatial correlation between galaxy clusters and active galactic nuclei (AGNs) detected by the ROSAT North Ecliptic Pole Survey (NEP). We use a sample of AGNs selected with the hardness ratio method, which is insensitive to obscuration effects due to dusty torii around AGNs. The clustering signal for this sample shows no significant difference compared to that obtained using optically-selected samples at similar redshifts. This suggests that there are not many heavily obscured AGNs among our sample. Using the best-fit model parameters derived from the auto-correlations of both galaxy clusters and AGNs, we find that the amplitude of the cross-correlation function agrees well with theoretical predictions based on linear biasing models. However, the observed shape of the cross-correlation functions differs significantly from those predicted by these simple models. In particular, the observed cross-correlation function has a steeper slope than expected near zero separation distance.",
        "watermark_text": "We present an assessment of the spatial correlation between galaxy regions and active galactic nuclei ( AGNs ) detected by the ROSAT North Ecliptic Pole Survey ( NEP ) . We use a sample of AGNs chosen with the hardness factor method , which is insensitive to obscuration effects due to dusty torii around AGNs .The clustering signal for this specimen shows no major variation compared to that obtained using optically - selected samples at comparable redshifts . This implies that there are not many heavily distorted AGNs among our sample .Using the best - fitting model factors obtained from the auto - correlations of both galaxy galaxies and AGNs , we find that the frequency of the cross - correlation function agrees well with theoretical estimates based on linear biasing models . However , the known size of the cross - correlation functions differs greatly from those predicted by these simple theories .In particular , the seen cross - correlation function has a steeper gradient than expected near zero separation distance .",
        "rewrite_text": "We provide an analysis of the spatial relationship between regions of galaxies and active galactic nuclei (AGNs) identified in the ROSAT North Ecliptic Pole Survey (NEP). Our study utilizes a sample of AGNs selected using the hardness factor method, which is unaffected by obscuration due to dusty toroidal structures surrounding the AGNs. The clustering signal from this sample shows little variation when compared to optically-selected samples at similar redshifts, indicating a scarcity of heavily obscured AGNs in our dataset. By applying the best-fitting model parameters derived from the auto-correlations of both galaxies and AGNs, we observe that the frequency of the cross-correlation function aligns closely with theoretical predictions based on linear biasing models. However, the actual size of the cross-correlation functions significantly deviates from those predicted by these basic theories, particularly exhibiting a steeper gradient than anticipated at near-zero separation distances.",
        "ori-fast-z-score": 0.46499055497527714,
        "water-fast-z-score": 5.658032638058332,
        "rewrite-fast-z-score": 1.3438638879193574
    },
    {
        "original_text": "We present new observations in the optical, infrared (IR), and ultraviolet (UV) spectral ranges for the symbiotic binary system H1-36. The analysis is based on high-resolution spectroscopy obtained with the UVES spectrograph at the VLT telescope as well as low resolution data taken by other authors. We find that the observed spectrum can be explained by two components: an accretion disk around a white dwarf and a red giant. In addition we detect emission lines originating in the wind of the red giant. Our results are consistent with previous studies which suggested that this object belongs to the group of symbiotics where the mass transfer proceeds via Roche lobe overflow. \n \n Keywords: Symbiosis, Binary systems, Red giants, Accreting binaries, Winds, Mass loss, Spectroscopy, Ultraviolet radiation, White dwarfs, Emission lines, Stellar winds",
        "watermark_text": "We present new images in the optical , infrared ( IR ) , and ultraviolet ( UV ) spectral regions for the symbiotic binary system H1 - 36 . The comparison is based on wide - resolution spectroscopy acquired with the UVES spectrograph at the VLT telescope as well as low resolution data taken by other researchers .We see that the seen spectrum can be described by two parts : an accretion disk around a white dwarf and a red dwarf . In addition we find emission lines originating in the wind of the red dwarf .Our results are compatible with previous research which suggested that this body belongs to the group of symbiotics where the mass transfer continues via Roche lobe overflow . Keywords : Symbiosis , Binary systems , Red giants , Accreting binaries , Winds , Mass loss , Spectroscopy , Ultraviolet radiation , White dwarfs , Emission lines , Stellar winds",
        "rewrite_text": "We present new optical, infrared (IR), and ultraviolet (UV) images of the symbiotic binary system H1-36. Our comparison utilizes high-resolution spectroscopy obtained with the UVES spectrograph at the VLT telescope, along with lower-resolution data from other researchers. The spectra reveal two distinct components: an accretion disk surrounding a white dwarf and a red dwarf star. Additionally, we observe emission lines that appear to originate from the wind of the red dwarf. Our findings align with previous studies suggesting that this system is part of the class of symbiotic binaries where mass transfer occurs through Roche lobe overflow. Keywords: Symbiosis, Binary systems, Red giants, Accreting binaries, Winds, Mass loss, Spectroscopy, Ultraviolet radiation, White dwarfs, Emission lines, Stellar winds.",
        "ori-fast-z-score": -0.9271726499455306,
        "water-fast-z-score": 3.3113308926626095,
        "rewrite-fast-z-score": -0.816496580927726
    },
    {
        "original_text": "The segmentation clock is an oscillatory gene regulatory network that controls the periodic formation of segments in vertebrates, such as vertebrae and ribs.  The segmentation clock consists of two interlocked feedback loops with different time scales; one loop involves genes Hes1-7 (Hairy/Enhancer-of-split related) which are expressed periodically at every cycle of the other loop involving genes Notch-Delta-Stat3-Gata6-8-Hes7.  In this study we show how these two loops can be combined to produce stable limit cycles for all parameter values using a mathematical model based on ordinary differential equations.  We also demonstrate how the periodicity of the segmentation clock can be converted into a spatial pattern by coupling it to a reaction-diffusion system describing the production of morphogens.  Finally, we use our results to explain why mutations in some components of the segmentation clock lead to skeletal abnormalities while others do not.",
        "watermark_text": "The segmentation clock is an oscillatory gene regulatory network that influences the periodic formation of segments in vertebrates , such as vertebrae and ribs . The segmentation clock contains of two interlocked feedback loops with various time ranges ; one loop includes genes Hes1 - 7 ( Hairy / Enhancer - of - split related ) which are expressed periodically at every cycle of the other loop comprising genes Notch - Delta - Stat3 - Gata6 - 8 - Hes7 .In this study we study how these two loops can be merged to produce stable limit patterns for all parameter values utilizing a mathematical description based on ordinary differential equations . We additionally demonstrate how the periodicity of the segmentation clock can be turned into a spatial pattern by bonding it to a reaction - diffusion system describing the production of morphogens .Finally , we utilize our findings to explain why mutations in some components of the segmentation clock lead to skeletal abnormalities while many do not .",
        "rewrite_text": "The segmentation clock is a pulsating gene regulatory network that plays a crucial role in the rhythmic development of segments in vertebrates, including structures like vertebrae and ribs. This clock consists of two interconnected feedback loops with different time scales; one loop features periodically expressed genes Hes1-7 (related to Hairy/Enhancer-of-split) that operate in sync with another loop comprising genes Notch, Delta, Stat3, Gata6, Gata8, and Hes7. In this study, we explore how these two loops can be integrated to generate stable limit patterns across all parameter values through a mathematical framework based on ordinary differential equations. Furthermore, we show how the periodicity of the segmentation clock can be translated into a spatial pattern by linking it to a reaction-diffusion system that describes morphogen production. Finally, we use our findings to elucidate why mutations in certain components of the segmentation clock can result in skeletal abnormalities, while many others do not.",
        "ori-fast-z-score": -0.6201736729460423,
        "water-fast-z-score": 3.4465617474213164,
        "rewrite-fast-z-score": 1.0834726777719228
    },
    {
        "original_text": "We present the results of an analysis of the 2 Micron All Sky Survey (2MASS) data for quasars with broad absorption lines (BALQSOs). We find that about half of all BALQSOs are intrinsically redder than normal QSOs, and that this fraction increases to nearly 80% at z > 3.5. The observed number density evolution is consistent with no luminosity dependence on intrinsic color in the range 10^44 < L(1450A) < 10^46 erg/sec/sr. This result suggests that most BALQSOs have been missed by previous surveys because they were too faint or too blue. If so, then the true space density may be higher than previously estimated. \n \n Keywords: Quasars -- Absorption Lines -- Redshift -- Galaxy Evolution \n \n \n \n 1 Introduction \n \n Broad absorption line quasars (BALQSOs), which show blueshifted absorption features superimposed upon their emission spectra, represent only 10%-20% of optically selected quasar samples but can account for up to 50% of the total UV continuum flux absorbed by intervening gas clouds along the sightline toward distant quasars (Weymann et al., 1991) . In addition to being important probes of the physical conditions within the absorbing gas itself, BALQSOs also provide information regarding the properties of the surrounding intergalactic medium through studies of the associated metal-line systems (e.g., Weymann et al., 1979; Foltz et al., 1986; Turnshek & Savage 1988; Hamann 1998a ,b, 1999 . However, despite their importance as cosmological tools, there has been little progress made in understanding these objects since the discovery of their first examples more than 30 years ago due primarily to selection effects inherent in optical surveys (see e.g., Hewett & Foltz 2003 ) . \n \n Recently, several authors have suggested that many BALQSOs could be found among infrared-selected sources using large-area near-infrared sky surveys such as the Two-Micron All-Sky Survey (2MASS) (Cutri et",
        "watermark_text": "We present the conclusion of an assessment of the 2 Micron All Sky Survey ( 2MASS ) statistics for quasars with broad absorption patterns ( BALQSOs ) . We see that about half of all BALQSOs are intrinsically redder than usual QSOs , and that this amount rises to approximately 80 % at z > 3 . 5 .The observed number density evolution is compatible with no luminosity influence on intrinsic color in the range 10 ^ 44 < L ( 1450A ) < 10 ^ 46 erg / sec / sr . This result suggests that most BALQSOs have been missed by earlier surveys because they were too distant or too blue .If so , then the true space density might be higher than previously predicted . Keywords : Quasars - - Absorption Lines - - Redshift - - Galaxy Evolution 1 Introduction Broad absorption line quasars ( BALQSOs ) , which show blueshifted emission elements superimposed upon their absorption spectra , constitute only 10 % - 20 % of optically selected quasar samples but can provide for up to 50 % of the total UV continuum flux reflected by intervening gas clouds along the sightline toward distant quasars ( Weymann et al . , 1991 ) .In addition to being important probes of the physical conditions within the absorbing gas itself , BALQSOs additionally offer information regarding the properties of the nearby intergalactic medium through analyses of the associated metal - line systems ( e . g . , Weymann et al . , 1979 ; Foltz et al . , 1986 ; Turnshek & Savage 1988 ; Hamann 1998a , b , 1999 . However , despite their importance as cosmological tools , there has been limited progress made in understanding these objects since the discovery of their early instance more than 30 weeks ago due primarily to selection effects inherent in optical searches ( saw e . g . , Hewett & Foltz 2003 ) .Recently , various published have suggested that several BALQSOs might be found among infrared - selected sources using big - area near - infrared sky observations such as the Two - Micron All - Sky Survey ( 2MASS ) ( Cutri et",
        "rewrite_text": "We conclude our assessment of the 2 Micron All Sky Survey (2MASS) statistics concerning quasars with broad absorption lines (BALQSOs). Our findings indicate that approximately half of all BALQSOs exhibit an intrinsic reddening compared to typical QSOs, with this percentage increasing to around 80% for those at redshifts greater than 3.5. The observed evolution in number density aligns with the notion that intrinsic color is unaffected by luminosity within the range of \\(10^{44} < L(1450\\text{Å}) < 10^{46} \\text{erg/sec/sr}\\). This implies that earlier surveys may have overlooked a significant number of BALQSOs due to their distance or blueness, suggesting that the actual space density could be greater than previously estimated. \n\n**Keywords**: Quasars - Absorption Lines - Redshift - Galaxy Evolution\n\n**1 Introduction**: Broad absorption line quasars (BALQSOs), characterized by blueshifted emission lines within their absorption spectra, represent only 10% to 20% of optically selected quasar samples. However, they can account for up to 50% of the total UV continuum flux reflected by intervening gas clouds along the line of sight to distant quasars (Weymann et al., 1991). Besides serving as vital indicators of the physical conditions in the absorbing gas, BALQSOs provide insights into the properties of the surrounding intergalactic medium through the analysis of their associated metal-line systems (e.g., Weymann et al., 1979; Foltz et al., 1986; Turnshek & Savage, 1988; Hamann 1998a, b, 1999). Despite their significance as tools for cosmological study, progress in understanding these objects has been limited since their initial discovery over 30 years ago, primarily due to selection biases in optical searches (see, for example, Hewett & Foltz 2003). Recently, various studies have proposed that additional BALQSOs may be identified among infrared-selected sources utilizing extensive near-infrared sky surveys like the Two-Micron All-Sky Survey (2MASS) (Cutri et al.).",
        "ori-fast-z-score": -0.3713906763541037,
        "water-fast-z-score": 6.247782215210102,
        "rewrite-fast-z-score": 0.6311687442672026
    },
    {
        "original_text": "We present an analysis of the final masses of gas giant planets in our Solar System, based on their orbital parameters and compositions inferred by remote sensing observations. We find that Jupiter s mass is consistent with its composition if it formed at 5 AU or less; Saturn s mass can be explained only if it formed beyond 10 AU. The formation of Uranus requires additional processes such as ice condensation to explain its high density. Neptune may have been born more massive than we see today but lost most of its initial mass through photoevaporation driven by intense stellar radiation. Our results suggest that the core accretion model for planet formation cannot fully account for all observed properties of gas giant planets. Keywords: Planet formation, Core accretion theory, Photoevaporation, Mass loss, Stellar radiation, Ice condensation, Orbital evolution, Final mass, Solar system, Remote sensing observation, Compositions, Density",
        "watermark_text": "We present an assessment of the last masses of gas giant planets in our Solar System , relying on their orbital characteristics and compositions inferred by distant sensing measurements . We see that Jupiter s mass is compatible with its composition if it created at 5 AU or smaller ; Saturn s mass can be understood only if it created beyond 10 AU .The formation of Uranus demands extra processes such as ice condensation to explain its high density . Neptune might have been born more massive than we saw nowadays but lost most of its initial mass through photoevaporation driven by intense stellar radiation .Our results show that the core accretion theory for planet development cannot fully account for all observed properties of gas giant worlds . Keywords : Planet structure , Core accretion theory , Photoevaporation , Mass loss , Stellar radiation , Ice condensation , Orbital development , Final mass , Solar system , Remote sensing observation , Compositions , Density",
        "rewrite_text": "We provide an evaluation of the final masses of gas giant planets in our Solar System, based on their orbital dynamics and compositions obtained from remote sensing data. Our findings indicate that Jupiter's mass aligns with its composition if it formed at 5 AU or closer, while Saturn's mass can only be explained if it formed beyond 10 AU. The formation of Uranus requires additional mechanisms, such as ice condensation, to account for its high density. Neptune may have originally formed with a greater mass than we currently observe, having lost a significant portion of its initial mass due to intense stellar radiation-induced photoevaporation. These results suggest that the core accretion theory of planetary formation does not fully explain all the observed characteristics of gas giant planets. \n\n**Keywords:** Planet structure, core accretion theory, photoevaporation, mass loss, stellar radiation, ice condensation, orbital development, final mass, Solar System, remote sensing observations, compositions, density.",
        "ori-fast-z-score": -0.8551861104941365,
        "water-fast-z-score": 4.764608329895903,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "The calibration and data products for GALEX are described in this document, which is intended to be used by astronomers who wish to use these data sets.  The main focus of this document is on describing how to obtain calibrated images (i.e., fluxes) from raw data files produced by GALEX s instruments.   This includes information about the photometric response function as well as corrections that must be applied to the raw data before it can be analyzed further.   ... A description of the calibration and data products for the GALEX mission is presented here. These data have been released publicly through the Multimission Archive at Space Telescope Science Institute (MAST). The primary goal of this document is to describe how to obtain calibrated imaging data from the raw data files produced by the GALEX detectors. In addition, we provide details regarding the photometric response functions and other corrections necessary to produce accurate results when analyzing the data.",
        "watermark_text": "The calibration and information products for GALEX are explained in this report , which is intended to be used by astronomers who desire to use these information sets . The main theme of this statement is on explaining how to obtain calibrated images ( i . e . , fluxes ) from raw data data produced by GALEX s satellites .This contains information about the photometric reply function as also as corrections that must be applied to the raw data before it can be analyzed further . . . . A description of the calibration and information products for the GALEX mission is given here .These data have been released openly through the Multimission Archive at Space Telescope Science Institute ( MAST ) . The main goal of this report is to explain how to obtain calibrated imaging information from the raw data feeds created by the GALEX detectors .In addition , we provide details regarding the photometric reaction functions and other corrections necessary to produce accurate outcomes when examining the information .",
        "rewrite_text": "This report describes the calibration and information products for GALEX, aimed at astronomers seeking to utilize these data sets. It focuses on how to derive calibrated images (i.e., fluxes) from the raw data collected by GALEX satellites. The report includes details about the photometric response functions and the corrections that must be applied to the raw data before further analysis can occur. Calibration and information products related to the GALEX mission are outlined here, with the data being openly available through the Multimission Archive at the Space Telescope Science Institute (MAST). The primary objective of this report is to guide users in extracting calibrated imaging information from the raw data generated by GALEX detectors, while also providing important information on photometric response functions and other necessary corrections to achieve accurate results in data analysis.",
        "ori-fast-z-score": -0.1259881576697424,
        "water-fast-z-score": 7.112007112010668,
        "rewrite-fast-z-score": 1.0504514628777804
    },
    {
        "original_text": "In this work, we propose an energy-efficient modulation scheme for downlink transmission over code division multiple access (CDMA) networks by exploiting the inherent multiuser diversity and delay requirements. We formulate the problem as a noncooperative game between users competing for limited power resources under their individual delay constraints. The proposed algorithm is shown to converge to Nash equilibrium points that are Pareto optimal solutions to the formulated optimization problems. Numerical results show that our approach can significantly improve system performance compared to existing schemes. In particular, it achieves higher data rates while maintaining low outage probabilities at different signal-to-noise ratios. \n \n Keywords: Code Division Multiple Access, Noncooperative Games, Power Allocation, Energy Efficiency, Multiuser Diversity, Delay Constraint. 1 Introduction \n \n With the rapid growth of wireless communication systems such as mobile phones and personal digital assistants, there has been increasing interest in developing efficient resource allocation algorithms to maximize network capacity or minimize total transmit power consumption  1  . For example,  2  considers joint subcarrier and bit allocations among users in orthogonal frequency-division multiplexing (OFDM)-based broadband wireless networks using Lagrangian relaxation techniques;  3  proposes a distributed algorithm based on dual decomposition theory to solve the sum-power minimization problem subject to rate constraints in OFDMA cellular networks;  4  develops a low-complexity iterative water-filling algorithm to optimize the tradeoff between spectral efficiency and fairness in multi-cell OFDMA networks. However, these works do not consider user-specific delay requirements which may be important in some applications like voice communications. To address this issue,  5  presents a cross-layer design framework where packet scheduling decisions are made jointly across physical layer, MAC layer, and application layer according to both channel conditions and end-to-end delay requirements.  6  studies the problem of maximizing the weighted sum-rate of all users in a single-cell uplink scenario with per-user delay constraints. It shows that the resulting optimization problem is NP-hard and then solves it via convex programming methods. Although these works have considered various aspects of resource allocation in wireless networks, they",
        "watermark_text": "In this research , we develop an energy - efficient modulation scheme for downlink transmission over code division multiple entry ( CDMA ) networks by exploiting the intrinsic multiuser complexity and delay requirements . We formulate the issue as a noncooperative contest between operators competing for limited power assets under their individual wait constraints .The proposed strategy is demonstrated to converge to Nash equilibrium points that are Pareto optimal solutions to the formulated optimization problems . Numerical results show that our approach can significantly boost problem performance compared to existing strategies .In particular , it achieves higher data levels while maintaining low outage probabilities at different signal - to - noise ratios . Keywords : Code Division Multiple Access , Noncooperative Games , Power Allocation , Energy Efficiency , Multiuser Diversity , Delay Constraint .1 Introduction With the fast rise of mobile communication devices such as wireless phones and personal digital assistants , there has been growing interest in developing innovative resource allocation algorithms to maximize channel capacity or reduce total broadcast power consumption 1 . For instance , 2 considers joint subcarrier and bit allocations among consumers in orthogonal frequency - unit multiplexing ( OFDM ) - based telecommunications broadband networks employing Lagrangian relaxation techniques ; 3 suggests a distributed algorithm based on double decomposition model to solve the sum - energy minimization problem subject to rate constraints in OFDMA wireless networks ; 4 develops a small - complexity iterative river - filling algorithm to optimize the tradeoff between spectral capacity and fairness in multi - cell OFDMA connections .However , these works do not discuss user - specific delay requirements which sometimes be crucial in some applications like voice communications . To address this question , 5 presents a cross - layer design framework where packet scheduling decisions are making jointly across physical layer , MAC layer , and application layer according to both network conditions and end - to - end delay requirements .6 studies the question of maximizing the weighted sum - frequency of all users in a single - cell uplink situation with per - customer wait constraints . It demonstrates that the resulting algorithm question is NP - hard and then solves it via convex programming algorithms .Although these works have treated numerous elements of resource sharing in wireless networks , they",
        "rewrite_text": "In this study, we introduce an energy-efficient modulation scheme for downlink transmission in code division multiple access (CDMA) networks by leveraging the inherent multiuser complexity and delay requirements. We frame the problem as a noncooperative competition among operators vying for limited power resources while adhering to their individual wait constraints. The proposed approach is shown to converge to Nash equilibrium points that represent Pareto optimal solutions for the optimization problems posed. Our numerical results indicate that this method can substantially enhance performance compared to current strategies, achieving higher data rates while also ensuring low outage probabilities across various signal-to-noise ratios. \n\nKeywords: Code Division Multiple Access, Noncooperative Games, Power Allocation, Energy Efficiency, Multiuser Diversity, Delay Constraint.\n\n1. Introduction: The proliferation of mobile communication devices such as wireless phones and personal digital assistants has sparked interest in developing novel resource allocation algorithms aimed at maximizing channel capacity or minimizing total broadcast power consumption. For example, some research focuses on joint subcarrier and bit allocations among users in orthogonal frequency-division multiplexing (OFDM) networks using Lagrangian relaxation techniques. Others propose distributed algorithms based on a double decomposition model to address sum-energy minimization under rate constraints in OFDMA wireless networks, or develop low-complexity iterative river-filling algorithms to balance spectral capacity and fairness in multi-cell OFDMA scenarios. However, these studies often overlook user-specific delay requirements, which can be crucial for applications like voice communications. To tackle this issue, one framework integrates cross-layer design by making packet scheduling decisions collaboratively across the physical, MAC, and application layers, accommodating both network conditions and end-to-end delay constraints. Another study examines the maximization of the weighted sum-frequency for all users in a single-cell uplink scenario under customer-specific wait restrictions, proving that the resulting optimization problem is NP-hard and solving it through convex programming. Despite these advancements addressing various aspects of resource sharing in wireless networks, they...",
        "ori-fast-z-score": 1.4045204148136883,
        "water-fast-z-score": 10.3209369308428,
        "rewrite-fast-z-score": 2.6457513110645907
    },
    {
        "original_text": "We study the glass transition of an ensemble of adhesive hard spheres with repulsive interactions decaying as 1/r6, where r is distance between particles. We find that this system exhibits two distinct relaxation processes at low temperatures: one fast process associated with local rearrangements within clusters of strongly bonded particles; another slower process related to collective motion of these clusters. The latter process can be described by mode-coupling theory (MCT) for colloidal suspensions. However, we show that MCT fails quantitatively when applied directly to our data because it does not take into account the presence of strong bonds which lead to additional slow modes. By introducing a simple modification to MCT, we are able to obtain excellent agreement with experimental results over several decades in time and frequency. This modified version of MCT also predicts correctly the temperature dependence of the structural relaxation time near Tg. Our work shows how quantitative tests of theoretical predictions may help improve their accuracy and applicability range.",
        "watermark_text": "We test the glass transition of an ensemble of adhesive solid surfaces with repulsive interactions decaying as 1 / r6 , where r is distance between particles . We see that this scheme exhibits two different relaxation processes at low temperatures : one fast process associated with local rearrangements within clusters of highly bonded particles ; another slower process related to collective motion of these complexes .The latter system can be described by mode - coupling theory ( MCT ) for colloidal suspensions . However , we prove that MCT fails quantitatively when applied directly to our information because it does not take into consideration the presence of stable bonds which lead to extra slow modes .By introducing a simple change to MCT , we are able to obtain excellent compliance with experimental results over numerous years in time and frequency . This amended variant of MCT also predicts correctly the temperature dependence of the structural relaxation time near Tg .Our research shows how standardized tests of theoretical estimates may improve improve their accuracy and applicability range .",
        "rewrite_text": "We investigate the glass transition in a set of adhesive solid surfaces that exhibit repulsive interactions varying as 1 / r^6, with r representing the distance between particles. Our findings reveal that this model demonstrates two distinct relaxation processes at low temperatures: a rapid process linked to local rearrangements within clusters of strongly bonded particles, and a slower process associated with the collective motion of these complexes. The latter can be effectively described by mode-coupling theory (MCT) for colloidal suspensions. However, we demonstrate that MCT quantitatively fails when applied directly to our data, as it overlooks the stable bonds that give rise to additional slow modes. By modifying MCT in a straightforward manner, we achieve remarkable congruence with experimental results across various time and frequency scales. This revised version of MCT also accurately predicts the temperature dependence of the structural relaxation time near Tg. Our research illustrates how standardized evaluations of theoretical models can enhance their accuracy and broaden their applicability.",
        "ori-fast-z-score": -0.43133109281375365,
        "water-fast-z-score": 5.965587590013045,
        "rewrite-fast-z-score": 1.6666666666666667
    },
    {
        "original_text": "The background radiation in space is dominated by cosmic rays and their secondary products, such as neutrons and gamma-rays. The most important source of these particles are galactic supernovae which occur at an average rate of one per century. In this work we present results on the background radiation expected to be measured with the pn-CCDs (p-type silicon charge-coupled devices) that will be used in the CERN Axion Solar telescope (CAST). We have simulated the response of CAST s detectors using GEANT4 Monte Carlo simulations. These were then combined with models of the particle fluxes in space to predict the background count rates observed by the cameras. Our predictions show that the background count rate due to cosmic ray interactions should not exceed 0.1 counts s-1 pixel-1 over the entire field-of-view of each camera. This corresponds to less than 1% of the signal expected from axions produced in the Sun s magnetic field.",
        "watermark_text": "The background radiation in space is dominated by gamma radiation and their secondary products , such as neutrons and alpha - rays . The most important source of these ions are galactic supernovae which occur at an estimated rate of one per century .In this research we present results on the background radiation anticipated to be recorded with the pn - CCDs ( p - class silicon charge - coupled devices ) that will be used in the CERN Axion Solar observatory ( CAST ) . We have modelled the response of CAST s detectors using GEANT4 Monte Carlo simulations .These were then combined with models of the particle fluxes in space to predict the background count levels observed by the cameras . Our predictions show that the background count rate due to cosmic ray molecules should not reach 0 . 1 counts s - 1 pixel - 1 over the entire field - of - view of each camera .This corresponds to little than 1 % of the signal expected from axions produced in the Sun s magnetic force .",
        "rewrite_text": "The background radiation in space is primarily composed of gamma radiation and its secondary products, including neutrons and alpha particles. The main source of these ions is galactic supernovae, which are estimated to occur roughly once every century. In this study, we present findings on the background radiation that is expected to be detected by the pn-CCDs (p-class silicon charge-coupled devices) utilized in the CERN Axion Solar Observatory (CAST). We modeled the response of CAST's detectors using GEANT4 Monte Carlo simulations, which were integrated with models of particle fluxes in outer space to forecast the background counts registered by the cameras. Our predictions indicate that the background count rate from cosmic ray interactions should remain below 0.1 counts s^-1 pixel^-1 across the entire field of view of each camera. This represents less than 1% of the signal anticipated from axions generated in the Sun's magnetic field.",
        "ori-fast-z-score": 1.4552137502179978,
        "water-fast-z-score": 5.335783750799325,
        "rewrite-fast-z-score": 0.6108472217815261
    },
    {
        "original_text": "The gamma-ray bursts (GRBs) are the most energetic explosions in the universe, but their origin is still unknown. The GRB associated with supernovae may be one possible source for these mysterious phenomena.  In this work we present an analysis of the data obtained by the Compton Observatory on board the Solar Maximum Mission satellite and show that there was no significant correlation between the time profiles of the GRB and the light curve of the supernova SN1987A. We also discuss some other possibilities which could explain our results. Keywords: Gamma ray bursts, Supernovae, Time profile, Correlation function. 1 Introduction   -Gamma Ray Bursts (GRBs), discovered more than twenty years ago  1  , have been studied extensively since then  2  . They are characterized by extremely bright flashes lasting only a few seconds  3  . Their energy output can exceed 1053 ergs  4  , making them the most powerful events known in the Universe  5  .\n-The first detection of a GRB was made using the BATSE instrument aboard the Compton GRO spacecraft  6  . Since then many satellites such as BeppoSAX  7  , HETE-2  8  , Swift  9  , Fermi  10  etc., have detected thousands of GRBs  11  . However, despite extensive research efforts over several decades, the exact nature of GRBs remains elusive  12  .",
        "watermark_text": "The gamma - ray clusters ( GRBs ) are the most intense explosions in the universe , but their source is already unclear . The GRB associated with supernovae might be one possible cause for these mysterious phenomena .In this research we present an assessment of the information obtained by the Compton Observatory on board the Solar Maximum Mission spacecraft and reveal that there was no major interaction between the period profiles of the GRB and the light curve of the supernova SN1987A . We also discuss some other possibilities which could explain our findings .Keywords : Gamma ray bursts , Supernovae , Time profile , Correlation constant . 1 Introduction - Gamma Ray Bursts ( GRBs ) , detected more than twenty years previously 1 , have been studied thoroughly since then 2 .They are characterized by extremely brilliant flashes lasting only a few seconds 3 . Their energy output can exceed 1053 ergs 4 , making them the most intense objects known in the Universe 5 .- The first measurement of a GRB was done utilizing the BATSE instrument aboard the Compton GRO shuttle 6 . Since then many satellites such as BeppoSAX 7 , HETE - 2 8 , Swift 9 , Fermi 10 etc . , have discovered thousands of GRBs 11 .However , despite extensive research efforts over numerous generations , the exact nature of GRBs remains elusive 12 .",
        "rewrite_text": "Gamma-ray bursts (GRBs) are among the most powerful explosions in the universe, yet their origins remain uncertain. One potential source of these enigmatic events could be the GRBs linked to supernovae. In this study, we present an evaluation of data gathered by the Compton Observatory on the Solar Maximum Mission spacecraft, revealing no significant interaction between the GRB period profiles and the light curve of supernova SN1987A. We also explore alternative explanations for our observations. \n\nKeywords: Gamma-ray bursts, Supernovae, Time profile, Correlation constant. \n\n1. Introduction - Gamma-ray bursts (GRBs), first detected over twenty years ago, have been the subject of extensive research since that time. These phenomena are characterized by extraordinarily bright flashes that last only a few seconds. Their energy output can exceed 10^53 ergs, making them the brightest objects known in the universe. The initial detection of a GRB was accomplished using the BATSE instrument aboard the Compton Gamma Ray Observatory. Since then, multiple satellites, including BeppoSAX, HETE-2, Swift, and Fermi, have uncovered thousands of GRBs. Despite ongoing research efforts across multiple generations, the precise nature of GRBs remains elusive.",
        "ori-fast-z-score": -0.4588314677411235,
        "water-fast-z-score": 5.584068246522259,
        "rewrite-fast-z-score": 1.1470786693528088
    },
    {
        "original_text": "We present new near-infrared (NIR) spectroscopic observations with Keck II/DEIMOS, which cover the entire optical extent of the nearby spiral galaxy M33 out to its last measured isophote at 25 mag arcsec-2 in B-band. We also use archival data obtained by the Infrared Array Camera onboard the Spitzer Space Telescope for our study. The main goal of this work was to investigate how star formation proceeds beyond the edge of galactic disks into the surrounding intergalactic medium. Our results show that there are two distinct components along the line-of-sight towards M33: an extended component associated with diffuse ionized gas and young stars; and a compact component dominated by old stellar populations. Using these NIR spectra we have derived radial profiles of several physical parameters such as electron density, temperature, extinction coefficient etc., across the face-on view of M33 s disk. These profiles reveal interesting trends in the properties of interstellar matter within different regions of the galaxy.",
        "watermark_text": "We use new near - infrared ( NIR ) spectroscopic observations with Keck II / DEIMOS , which cover the entire optical extent of the nearby spiral galaxy M33 out to its last detected isophote at 25 mag arcsec - 2 in B - band . We additionally using archival measurements obtained by the Infrared Array Camera onboard the Spitzer Space Telescope for our research .The main goal of this research was to examine how star formation flows beyond the boundary of galactic disks into the nearby intergalactic medium . Our results show that there are two separate constituents along the line - of - seeing towards M33 : an extended component involved with diffuse ionized gas and older stars ; and a compact component dominated by aged stellar regions .Using these NIR spectra we have derived radial profiles of several physical factors such as electron concentration , temperature , extinction factor etc . , across the face - on vision of M33 s disk . These profiles indicate unusual trends in the properties of interstellar matter within various regions of the universe .",
        "rewrite_text": "We utilized new near-infrared (NIR) spectroscopic observations from Keck II/DEIMOS, which encompass the full optical extent of the nearby spiral galaxy M33, reaching its last detected isophote at 25 mag arcsec^-2 in the B-band. In addition, we incorporated archival data from the Infrared Array Camera aboard the Spitzer Space Telescope for our analysis. The primary objective of this research was to investigate how star formation extends beyond the boundaries of galactic disks into the neighboring intergalactic medium. Our findings reveal two distinct components along the line of sight toward M33: an extended component associated with diffuse ionized gas and older stars, and a compact component primarily consisting of aged stellar regions. Using these NIR spectra, we have derived radial profiles for various physical parameters, including electron density, temperature, and extinction factor, across the face-on view of M33's disk. These profiles reveal intriguing patterns in the properties of interstellar matter across different regions of the universe.",
        "ori-fast-z-score": 0.3511234415883917,
        "water-fast-z-score": 6.50986776965388,
        "rewrite-fast-z-score": 2.3570226039551585
    },
    {
        "original_text": "We study the dynamics of two interacting bosonic species confined to an optical lattice, with one species being initially prepared as a coherent state at each site while the other is initially prepared as a thermal cloud. We show that this system supports both symmetric and asymmetric soliton solutions which are stable against small perturbations for certain values of the chemical potentials. The stability properties of these solitons can be understood by studying their linearization spectrum around the stationary states. In particular we find that the presence of a finite temperature leads to additional unstable modes associated with phonon-like excitations. Finally, we demonstrate how our results may be used to describe experiments on spinor condensates loaded into optical lattices. Introduction:-Recent experimental advances have made it possible to create quantum degenerate gases consisting of several different atomic species  1  . These systems provide new opportunities to explore novel phenomena such as supersolids  2  , phase separation  3  or spin-orbit coupling  4  .\nIn this work we consider a particularly interesting example where there exist two distinct types of particles (e.g., atoms) which interact via s-wave scattering but differ in mass and/or internal structure  5  . This situation arises naturally when considering mixtures of hyperfine states  6  or isotopes  7, 8  within the same atom type  9  . For instance, recent experiments involving 87 Rb and 41 K  10  have demonstrated the formation of a mixture of two different hyperfine states after evaporative cooling  11  . Another possibility would involve using 40 K and 6 Li  12  . Here, the lighter species could be considered as impurities immersed in a background gas of heavier fermions  13  . Alternatively, if the masses were reversed then the heavy species could act as impurities  14  .",
        "watermark_text": "We research the dynamics of two interacting bosonic species confined to an optical lattice , with one species being initially made as a coherent state at each site while the other is initially prepared as a heat bubble . We see that this scheme holds both symmetric and asymmetric soliton solutions which are stable against small perturbations for particular values of the chemical potentials .The stability properties of these solitons can be understood by examining their linearization spectrum around the stationary states . In particular we find that the presence of a finite temperature leads to extra weak modes associated with phonon - like excitations .Finally , we prove how our findings may be used to explain studies on spinor condensates stacked into optical lattices . Introduction : - Recent research developments have enabled it able to create quantum degenerate gases composed of several different atomic species 1 .These systems present new opportunities to examine novel processes such as supersolids 2 , phase splitting 3 or spin - orbit resonance 4 . In this research we imagine a particularly exciting example where there exist two different kinds of atoms ( e . g . , atoms ) which interact via s - wave scattering but differ in mass and / or internal structure 5 .This condition occurs naturally when examining mixtures of hyperfine states 6 or isotopes 7 , 8 within the same atom type 9 . For instance , recent experiments concerning 87 Rb and 41 K 10 have demonstrated the formation of a mixture of two different hyperfine states after evaporative cooling 11 .Another possibility would include utilizing 40 K and 6 Li 12 . Here , the softer species may be regarded as impurities immersed in a background gas of heavier fermions 13 .Alternatively , if the masses were reversed then the heavy species may function as impurities 14 .",
        "rewrite_text": "We investigate the interactions between two bosonic species confined in an optical lattice, with one species initialized in a coherent state at each lattice site while the other is set up as a heat bubble. Our findings reveal that this configuration supports both symmetric and asymmetric soliton solutions, which remain stable against minor perturbations for specific chemical potential values. The stability characteristics of these solitons can be elucidated by analyzing their linearization spectrum around the stationary states. Notably, we observe that finite temperature introduces additional weak modes linked to phonon-like excitations. Ultimately, we demonstrate how our results can provide insights into research on spinor condensates arranged within optical lattices. \n\nIntroduction: Recent advancements in research have facilitated the creation of quantum degenerate gases composed of various atomic species. Such systems present unique avenues for exploring new phenomena, including supersolids, phase separation, and spin-orbit resonance. In particular, we focus on an intriguing scenario involving two distinct types of atoms that interact through s-wave scattering and differ in their mass and/or internal structure. This situation naturally arises when analyzing mixtures of hyperfine states or isotopes within a single atomic type. For instance, recent experiments with 87Rb and 41K have shown the formation of a mixture of two different hyperfine states after evaporative cooling. Another potential combination could be 40K and 6Li, where the lighter species acts as impurities in a background of heavier fermions. Conversely, if the species were reversed in mass, the heavier species could serve as the impurities.",
        "ori-fast-z-score": -0.3481553119113957,
        "water-fast-z-score": 6.5033247714309,
        "rewrite-fast-z-score": 1.6570343122169822
    },
    {
        "original_text": "We present the results of our investigation into how stellar evolution models are affected by individual element abundances in stars, focusing on the sensitivity to changes in helium abundance (Y). We use two different sets of evolutionary tracks with varying Y values for masses between 0.8 M⊙ and 8 M⊙ at solar metallicity. The first set is based on the Padova code while the second one uses the Geneva code. For each track we calculate synthetic spectra using the SPECTRUM code. These synthetic spectra are then used as input to determine the best-fit parameters of observed high-resolution optical spectra of Galactic open clusters. Our analysis shows that both codes produce similar results when fitting these cluster data. However, there are significant differences in the derived ages depending on which code was used. This discrepancy can be explained by the fact that the Padova tracks have been calculated without convective overshooting whereas the Geneva tracks include this effect.",
        "watermark_text": "We present the conclusion of our inquiry into how stellar evolution models are influenced by individual atom abundances in stars , concentrating on the sensitivity to changes in helium abundance ( Y ) . We use two different series of evolutionary tracks with varying Y readings for masses between 0 . 8 [UNK] and 8 [UNK] at solar metallicity .The first setting is based on the Padova code while the second one uses the Geneva code . For each track we estimate synthetic spectra using the SPECTRUM code .These synthetic spectra are then utilized as input to obtain the best - fitting characteristics of known high - resolution optical spectra of Galactic open clusters . Our study shows that both codes produce comparable results when fitting these cluster data .However , there are significant variations in the derived ages varying on which coding was used . This discrepancy can be reason by the fact that the Padova lines have been measured without convective overshooting whereas the Geneva tracks include this effect .",
        "rewrite_text": "We conclude our investigation into the impact of individual atomic abundances in stars on stellar evolution models, with a particular focus on the sensitivity to variations in helium abundance (Y). Our study employs two distinct series of evolutionary tracks with different Y values for stellar masses ranging from 0.8 M⊙ to 8 M⊙ at solar metallicity. The first set of tracks is derived from the Padova code, while the second set is based on the Geneva code. For each evolutionary track, we generate synthetic spectra using the SPECTRUM code. These synthetic spectra then serve as input for deriving the best-fitting characteristics of existing high-resolution optical spectra from Galactic open clusters. Our results indicate that both codes yield comparable outcomes when fitting the cluster data; however, there are notable differences in the estimated ages depending on the code employed. This variation can be attributed to the fact that the Padova tracks are measured without accounting for convective overshooting, whereas the Geneva tracks include this consideration.",
        "ori-fast-z-score": 1.7556172079419585,
        "water-fast-z-score": 6.50986776965388,
        "rewrite-fast-z-score": 1.2222222222222223
    },
    {
        "original_text": "We study the resonance phenomenon for an open-loop control problem in a nonlinear stochastic model describing interactions between phytoplankton (plants) and zooplankton (animals). The main goal is to find optimal values of parameters characterizing external periodic forcing, which maximize the growth rate of planktons. We show that this optimization problem can be reduced to finding solutions of some algebraic equations. In particular, we prove that there exists only one solution corresponding to maximum value of the objective function. Moreover, it turns out that the obtained results are robust with respect to small perturbations of initial conditions. Finally, numerical simulations illustrate our theoretical findings. \n \n Keywords: Stochastic differential equation, Periodic forcing, Resonance, Optimization problems, Nonlinear dynamics \n \n 1 Introduction \n \n Interactions among different species play important role in many natural ecosystems. For example, phytoplankton (algae or plants), living at the base of food chain, provide energy source for other organisms such as zooplankton (fishes or animals). Therefore, understanding how these two populations interact may help us better understand ecosystem functioning. Recently, several mathematical models have been proposed to describe population dynamics of phytoplankton- zooplankton systems  1–3  . These models include deterministic terms representing intrinsic growth rates of both populations and their interaction effects, as well as random fluctuations due to environmental factors. It has been shown that under certain assumptions on the coefficients of the model, its long-term behavior exhibits chaotic attractor  4  , which makes analysis of the system very difficult. On the other hand, if the effect of random fluctuations is neglected then the resulting deterministic model becomes much easier to analyze  5–7  .\n \nIn  8  , authors studied the following model:\n \n \n \n dX(t) = rX(t)(1 - X(t))dt + fX(t)sin(wt)dW(t),\n dY(t) = rY(t)(1 - Y(t))dt + fy(t)sin(w0t)dW(t).\n \n(",
        "watermark_text": "We research the resonance phenomenon for an open - loop control problem in a nonlinear stochastic model explaining interactions between phytoplankton ( plants ) and zooplankton ( animals ) . The main goal is to find optimal values of values characterizing external periodic forcing , which maximize the development time of planktons .We see that this optimization problem can be reduced to finding solutions of some algebraic equations . In particular , we prove that there exists only one solve corresponding to maximum value of the objective function .Moreover , it turns out that the achieved findings are robust with regard to small perturbations of initial conditions . Finally , numerical simulations highlight our theoretical results .Keywords : Stochastic integral equation , Periodic forcing , Resonance , Optimization problems , Nonlinear dynamics 1 Introduction Interactions among different species play attractive role in different biological environments . For instance , phytoplankton ( algae or plants ) , live at the base of eat chain , provide energy source for other species such as zooplankton ( fishes or organisms ) .Therefore , studying how these two communities interact may assist us better understand ecological functioning . Recently , various computational models have been proposed to explain population behavior of phytoplankton - zooplankton communities 1 – 3 .These models include deterministic terms representing intrinsic development rates of both populations and their interaction influences , as also as random fluctuations owing to environmental factors . It has been shown that under certain assumptions on the coefficients of the model , its long - term behavior presents dynamic attractor 4 , which makes study of the system very difficult .On the other hand , if the impact of random fluctuations is neglected then the resulting deterministic model seems far easy to analyze 5 – 7 . In 8 , authors explored the following model : dX ( t ) = rX ( t ) ( 1 - X ( t ) ) dt + fX ( t ) sin ( wt ) dW ( t ) , dY ( t ) = rY ( t ) ( 1 - Y ( t ) ) dt + fy ( t ) sin ( w0t ) dW ( t ) .(",
        "rewrite_text": "We investigate the resonance phenomenon in an open-loop control scenario within a nonlinear stochastic model that describes the interactions between phytoplankton (plants) and zooplankton (animals). Our primary objective is to identify the optimal parameters that characterize external periodic forcing in order to maximize the growth period of these plankton communities. We demonstrate that this optimization problem can be simplified to finding solutions to certain algebraic equations. Specifically, we establish that there is a unique solution corresponding to the maximum value of the objective function. Additionally, our results are shown to be resilient to minor variations in initial conditions. Lastly, numerical simulations corroborate our theoretical findings.\n\n**Keywords:** Stochastic integral equation, Periodic forcing, Resonance, Optimization problems, Nonlinear dynamics  \n\n**1 Introduction**  \nInteractions among different species play a crucial role in various biological environments. For instance, phytoplankton (algae or plants), which sit at the base of the food chain, serve as an energy source for other species, such as zooplankton (fish or organisms). Consequently, examining the interactions between these two communities can enhance our understanding of ecological dynamics. Recently, numerous computational models have been developed to explain the population behaviors of phytoplankton-zooplankton communities. These models incorporate deterministic elements that capture the intrinsic growth rates of both populations, as well as their interaction effects, along with random fluctuations caused by environmental factors. It has been demonstrated that under certain assumptions regarding the model coefficients, the long-term behavior of the system exhibits dynamic attractors, which complicates the analysis of the system. Conversely, neglecting the effects of random fluctuations results in a deterministic model that is significantly easier to analyze. The authors in reference 8 examined the following model: \ndX(t) = rX(t)(1 - X(t))dt + fX(t)sin(wt)dW(t), \ndY(t) = rY(t)(1 - Y(t))dt + fy(t)sin(w0t)dW(t).",
        "ori-fast-z-score": 2.482817665807104,
        "water-fast-z-score": 8.877545314489295,
        "rewrite-fast-z-score": 2.7240208984279954
    },
    {
        "original_text": "We study the gravitational collapse of spherically-symmetric, electrically charged perfect fluids with pressure anisotropy and heat flow in general relativity. We find that for sufficiently large initial data there is no black hole formation but rather an asymptotically flat end state which can be interpreted as a naked singularity or a regular star-like object depending on whether the fluid has positive or negative radial pressure at spatial infinity respectively. The results are obtained by solving numerically the full set of coupled nonlinear partial differential equations governing the evolution of the system using a high-resolution shock-capturing scheme based on the method of lines combined with adaptive mesh refinement techniques. In addition to confirming previous numerical studies we also show how our approach allows us to obtain new insights into the dynamics of these systems such as the existence of multiple solutions corresponding to different final states. This work was supported by the Australian Research Council (ARC) Discovery Project DP130103137.",
        "watermark_text": "We explore the gravitational collapse of spherically - symmetric , electrically charged perfect fluids with force anisotropy and heat flow in general relativity . We see that for enough large initial evidence there is no black hole formation but rather an asymptotically flat end state which can be interpreted as a naked singularity or a regular star - like body depending on whether the liquid has negative or negative radial tension at spatial infinity respectively .The results are derived by solving numerically the full set of coupled nonlinear partial differential equations governing the evolution of the system using a high - resolution shock - capturing scheme using on the method of lines together with adaptive mesh refinement techniques . In addition to proving earlier numerical studies we also demonstrate how our approach allows us to obtain new understanding into the dynamics of these systems such as the existence of multiple answers corresponding to different initial states .This project was supported by the Australian Research Council ( ARC ) Discovery Project DP130103137 .",
        "rewrite_text": "We investigate the gravitational collapse of spherically symmetric, electrically charged perfect fluids characterized by force anisotropy and heat flow within the framework of general relativity. Our findings indicate that for sufficiently large initial conditions, black hole formation does not occur; instead, the system evolves into an asymptotically flat end state. This state can be interpreted as either a naked singularity or a regular star-like object, depending on whether the fluid exhibits negative or positive radial tension at spatial infinity. The results were obtained by numerically solving the complete set of coupled nonlinear partial differential equations that describe the system's evolution, employing a high-resolution shock-capturing approach based on the method of lines in conjunction with adaptive mesh refinement techniques. In addition to confirming previous numerical studies, we also show how our methodology provides new insights into the dynamics of these systems, revealing the existence of multiple solutions corresponding to different initial conditions. This research was supported by the Australian Research Council (ARC) Discovery Project DP130103137.",
        "ori-fast-z-score": 1.9409899176618914,
        "water-fast-z-score": 6.685631938613182,
        "rewrite-fast-z-score": 1.0425720702853738
    },
    {
        "original_text": "We have performed ab initio molecular dynamics simulations to study the in-plane structure, order parameters, and surface tension of liquid Na(l) in contact with vacuum or solid NaCl (001). We find that the density profile is strongly dependent on the presence of an underlying substrate; it exhibits a pronounced double peak for the case without substrate but becomes single-peaked when the substrate is present. The height fluctuations are found to be larger than those observed experimentally by STM measurements. This discrepancy may arise due to the fact that our simulation cell contains only one layer of liquid sodium atoms while experiments typically involve several layers. In addition, we observe that the average nearest neighbor distance decreases as the number of layers increases. Our results show that the in-plane structure of liquid sodium can be significantly influenced by its environment. Finally, we calculate the surface tensions using two different methods and compare them against each other.",
        "watermark_text": "We have done ab initio polymer mechanics simulations to study the in - plane structure , order variables , and surface tension of liquid Na ( l ) in contact with vacuum or solid NaCl ( 001 ) . We see that the density profile is strongly dependent on the presence of an underlying substrate ; it displays a noticeable double peak for the case without substrate but appears single - peaked when the substrate is present .The altitude fluctuations are found to be larger than those observed experimentally by STM observations . This discrepancy may arise due to the fact that our modeling room contains only one layer of liquid sodium atoms while tests usually require many layers .In addition , we find that the average closest neighbor distance tends as the number of thickness increases . Our results show that the in - plane structure of liquid sodium can be greatly altered by its surroundings .Finally , we estimate the surface tensions use two different methods and contrast them against each other .",
        "rewrite_text": "We conducted ab initio polymer mechanics simulations to examine the in-plane structure, order parameters, and surface tension of liquid sodium (Na(l)) in contact with either vacuum or solid NaCl (001). Our findings indicate that the density profile is significantly influenced by the underlying substrate; without a substrate, it exhibits a distinct double peak, whereas it appears single-peaked in the presence of the substrate. Additionally, we observed that altitude fluctuations in our simulations were greater than those reported in experimental STM observations. This variation may stem from our model, which considers only a single layer of liquid sodium atoms, while experiments typically involve multiple layers. Furthermore, we noted that the average nearest neighbor distance tends to increase with the thickness of the liquid layer. Overall, our results suggest that the surroundings of liquid sodium can substantially modify its in-plane structure. Finally, we estimated surface tensions using two different methods and compared the results.",
        "ori-fast-z-score": 0.3333333333333333,
        "water-fast-z-score": 6.405028512341099,
        "rewrite-fast-z-score": 1.4269353798659745
    },
    {
        "original_text": "The equivalence principle is one of the most important concepts in general relativity, and it states that all physically equivalent solutions to Einstein s field equations are locally indistinguishable.  In this article we show how the concept can be extended to three dimensions by considering two different classes of exact solutions to the vacuum Einstein field equations with cosmological constant.   The first class consists of spatially homogeneous Bianchi type IX models which have been studied extensively over many years as possible candidates for describing our universe at early times when its geometry was close to being flat.   We prove that these models are globally diffeomorphic (homeomorphic) if their spatial volume forms agree up to sign.   ... This article shows how the concept of local physical equivalence between solutions to Einstein s field equation can be extended to three-dimensions. Two different classes of exact solutions are considered; spatially homogeneous Bianchi Type IX models and spherically symmetric Schwarzschild-de Sitter solutions. It is shown that both types of solution are globally diffeomorphic under certain conditions on their respective volume forms.",
        "watermark_text": "The equivalence principle is one of the most important concepts in general relativity , and it states that all physically equivalent solutions to Einstein s field equations are locally indistinguishable . In this paragraph we give how the notion can be enlarged to three dimensions by analyzing two different categories of precise solutions to the vacuum Einstein field equations with cosmological constant .The first class consists of spatially homogeneous Bianchi class IX models which have been studied frequently over numerous years as possible candidates for describing our universe at early days when its topology was close to being flat . We assume that these models are globally diffeomorphic ( homeomorphic ) if their temporal volume shapes accord up to sign .. . . This section demonstrates how the notion of local physical equivalence between solutions to Einstein s field function can be generalized to three - dimensions .Two different categories of precise solutions are considered ; spatially homogeneous Bianchi Type IX models and spherically spherical Schwarzschild - de Sitter systems . It is demonstrated that both types of solution are globally diffeomorphic under certain conditions on their respective volume shapes .",
        "rewrite_text": "The equivalence principle is a fundamental concept in general relativity, asserting that all physically equivalent solutions to Einstein's field equations are locally indistinguishable. In this paragraph, we explore how this principle can be extended to three dimensions by examining two distinct categories of exact solutions to the vacuum Einstein field equations with a cosmological constant. The first category includes spatially homogeneous Bianchi class IX models, which have been extensively studied over the years as potential explanations for the early universe when its topology was nearly flat. We propose that these models are globally diffeomorphic (or homeomorphic) if their temporal volume shapes correspond up to sign. This section illustrates how the idea of local physical equivalence between solutions to Einstein's field equations can be generalized to three dimensions, considering both the spatially homogeneous Bianchi Type IX models and the spherically symmetric Schwarzschild-de Sitter solutions. It is shown that both types of solutions can be globally diffeomorphic under certain conditions related to their volume shapes.",
        "ori-fast-z-score": -1.462614271203831,
        "water-fast-z-score": 4.837877973981903,
        "rewrite-fast-z-score": 1.4342743312012722
    },
    {
        "original_text": "The rapidity and transverse momentum (pT) dependences of the electric charge correlation functions are studied for central Au+Au, d+Au and p+p collisions at RHIC and LHC energies using the AMPT model with string melting mechanism. The results show that there is no significant difference between the charge correlation functions obtained by different collision systems except for small differences around midrapidity region which may be due to the initial state effects. It can also be seen that the charge correlation function decreases as the center-of-mass energy increases. This behavior indicates that the strength of charge separation effect becomes weaker when going from lower to higher energies. Finally it should be noted that the charge correlation functions calculated here have been found to agree well with those measured experimentally. PACS numbers: 25.75.-q, 11.15.-x, 12.38.Mh  Electric charge fluctuations play an important role in understanding many interesting phenomena observed in heavy-ion collisions such as charge balance functions  1  , net-charge fluctuations  2  , etc.. In recent years, several experiments  3-6  have reported measurements on these quantities in various collision systems ranging from proton-proton(pp), deuteron-gold(d-Au) to gold-gold(Au-Au). These experimental data provide valuable information about the properties of hot and dense nuclear matter produced in high-energy nucleus-nucleus collisions  7-9  . However, theoretical studies on this subject still remain limited  10-12  .\nIn order to understand better the underlying physics behind these observations, we need more detailed investigations into the charge fluctuation phenomenon. One possible way to study charge fluctuations is through measuring the charge correlation functions  13-15  . Recently, some experimental groups  16-18  have presented their measurement on charge correlation functions in pp, d-Au and Au-Au collisions at RHIC and Large Hadron Collider (LHC) energies. On the other hand, the relativistic quantum molecular dynamics (RQMD)  19  and the parton-hadron-string dynamics (PHSD)  20  models predict that the charge correlation functions decrease rapidly towards zero",
        "watermark_text": "The rapidity and transverse momentum ( pT ) dependences of the electric charge interaction functions are studied for central Au + Au , d + Au and p + p collisions at RHIC and LHC energies using the AMPT theory with string melting system . The results show that there is no considerable difference between the charge correlation functions obtained by various collision systems except for little differences around midrapidity region which may be due to the early state effects .It can also be shown that the charge correlation function decreases as the center - of - mass momentum increases . This phenomenon suggests that the strength of mass separation effect gets smaller when going from lower to higher energies .Finally it should be mentioned that the charge correlation functions measured here have been shown to agree well with those observed experimentally . PACS codes : 25 . 75 . - q , 11 . 15 . - x , 12 . 38 . Mh Electric charge fluctuations play an important role in understanding several interesting phenomena observed in heavy - ion collisions such as charge balance tables 1 , net - charge fluctuations 2 , etc . .In past times , various study 3 - 6 have reported measurements on these quantities in different collision systems ranging from proton - proton ( pp ) , deuteron - platinum ( d - Au ) to platinum - silver ( Au - Au ) . These observation information provide valuable info about the properties of hot and dense nuclear material created in high - energy nucleus - nucleus collisions 7 - 9 .However , theoretical experiments on this question also remain limited 10 - 12 . In order to realize well the fundamental theory behind these observations , we require more precise studies into the charge fluctuation process .One could way to study charge fluctuations is through study the charge relationship values 13 - 15 . Recently , some experimental groups 16 - 18 have published their observation on charge correlation functions in pp , d - Au and Au - Au collisions at RHIC and Large Hadron Collider ( LHC ) frequencies .On the other hand , the relativistic quantum molecular mechanics ( RQMD ) 19 and the parton - hadron - string theory ( PHSD ) 20 models predict that the charge interaction functions decline rapidly towards zero",
        "rewrite_text": "The study examines the rapidity and transverse momentum (pT) dependencies of electric charge interaction functions in central Au + Au, d + Au, and p + p collisions at RHIC and LHC energies, utilizing the AMPT model with string melting. The findings reveal little significant variation between the charge correlation functions across different collision systems, with minor discrepancies in the midrapidity region likely attributed to early state effects. It is also observed that the charge correlation function decreases as the center-of-mass momentum increases, indicating that the strength of the mass separation effect diminishes as energy increases. Notably, the charge correlation functions obtained in this study align well with those observed in experimental settings. PACS codes: 25.75.-q, 11.15.-x, 12.38.Mh. Electric charge fluctuations are crucial for understanding various intriguing phenomena in heavy-ion collisions, such as charge balance tables and net-charge fluctuations. Previous research has reported measurements of these quantities across a range of collision systems—including proton-proton (pp), deuteron-gold (d-Au), and gold-gold (Au-Au). These observations provide important insights into the properties of the hot and dense nuclear matter produced in high-energy nucleus-nucleus collisions. However, theoretical investigations remain limited. To deepen our understanding of the fundamental theories underlying these observations, further precise studies on charge fluctuation processes are essential. One effective approach to studying charge fluctuations is through the analysis of charge relationship values. Recently, various experimental groups have reported their findings on charge correlation functions in pp, d-Au, and Au-Au collisions at RHIC and the Large Hadron Collider (LHC). Conversely, models such as relativistic quantum molecular dynamics (RQMD) and parton-hadron-string dynamics (PHSD) suggest that charge interaction functions rapidly approach zero.",
        "ori-fast-z-score": -0.3104602102825331,
        "water-fast-z-score": 7.869470848066687,
        "rewrite-fast-z-score": 2.3757725695052176
    },
    {
        "original_text": "We present the results of an all-sky survey for galaxy clusters using data obtained with the Sunyaev-Zel dovich effect (SZE) by the Planck satellite, complemented at low redshifts by X-ray observations made with XMM-Newton and Chandra satellites. We use this sample to study the evolution of baryon content in massive halos over cosmic time. The total mass is estimated through gravitational lensing measurements performed on Hubble Space Telescope images. Our main findings are as follows:  1. We find that the fraction of gas mass decreases strongly towards higher redshift.  2. At z < 0.5 we measure fgas = Mgas/Mtot = 0.11 ± 0.01(stat.) ±0.02(sys.), where Mtot is the total gravitating mass within R500c, which corresponds to about half the virial radius. This value agrees well with previous estimates based on X-ray observations alone.  3. For our full cluster sample spanning the range 0.1 < z < 1.3, we obtain fgas = 0.09 ± 0.01(±stat.).",
        "watermark_text": "We present the conclusion of an all - skies study for galaxy galaxies using data acquired with the Sunyaev - Zel dovich impact ( SZE ) by the Planck rocket , complemented at low redshifts by X - ray observations made with XMM - Newton and Chandra satellites . We use this specimen to study the evolution of baryon concentration in massive halos over cosmic time .The total mass is calculated through gravity lensing observations performed on Hubble Space Telescope images . Our main results are as follows : 1 .We see that the fraction of gas mass decreases strongly towards higher redshift . 2 .At z < 0 . 5 we measure fgas = Mgas / Mtot = 0 . 11 ± 0 . 01 ( stat . ) ±0 . 02 ( sys .) , where Mtot is the total gravitating mass within R500c , which equals to about half the virial diameter . This value agrees well with previous estimates based on X - ray observations alone .3 . For our entire cluster sample spanning the range 0 . 1 < z < 1 . 3 , we obtain fgas = 0 . 09 ± 0 . 01 ( ±stat .).",
        "rewrite_text": "We present the conclusions of a comprehensive study of galaxy clusters utilizing data obtained from the Sunyaev-Zel'dovich effect (SZE) measured by the Planck satellite, supplemented by X-ray observations from the XMM-Newton and Chandra satellites at lower redshifts. This dataset allows us to investigate the evolution of baryon concentration in massive halos across cosmic time. The total mass of the clusters is determined through gravitational lensing observations made with images from the Hubble Space Telescope. Our key findings are as follows: 1. We observe a significant decline in the gas mass fraction with increasing redshift. 2. For redshifts less than 0.5, we measure the gas mass fraction as fgas = Mgas / Mtot = 0.11 ± 0.01 (statistical) ± 0.02 (systematic), where Mtot represents the total gravitating mass within R500c, approximately half of the virial diameter. This measurement is consistent with prior estimates derived solely from X-ray observations. 3. For our complete sample of clusters, which spans the redshift range of 0.1 < z < 1.3, we find fgas = 0.09 ± 0.01 (statistical).",
        "ori-fast-z-score": 2.3566599571949607,
        "water-fast-z-score": 6.646940512883967,
        "rewrite-fast-z-score": 1.3949716649258315
    },
    {
        "original_text": "We study the supersymmetry breaking patterns for vector multiplets transforming under non-adjoint representations of SO(N). We find that there are two distinct classes of theories, depending on whether or not the representation is real. In particular we show how to construct explicit examples with N = 1 and N = 2 supersymmetries which break all their supersymmetries spontaneously. Theories with adjoint matter fields can be obtained as special cases by taking appropriate limits. This work was supported in part by NSF grant PHY-0456735. Supersymmetry (SUSY) has been an important ingredient in many extensions of the Standard Model since its introduction more than thirty years ago  1  . It provides a natural solution to the hierarchy problem between the weak scale and the Planck scale  2  , while at the same time offering new ways to understand gauge coupling unification  3  .\nIn recent years it has become clear that SUSY must be broken if one wants to make contact with experiment  4  . However, despite much effort over several decades  5  -  8  , no fully satisfactory mechanism for spontaneous SUSY breaking exists yet  9  . One promising approach involves using supergravity  10  -  12  to generate soft terms  13  -  15  which then trigger SUSY breakdown  16  -  18  . Another possibility is to use extra dimensions  19  -  21  where SUSY is broken either explicitly  22  -  24  or spontaneously  25  -  27  via boundary conditions  28  -  30  . A third option is to consider models based on local symmetries  31  -  33  such as gauged  34  -  37  or global  38  -  41  SUSY.",
        "watermark_text": "We research the supersymmetry broken schemes for vector multiplets transforming under non - adjoint representations of SO ( N ) . We see that there are two different categories of theories , depending on whether or not the representation is real .In particular we prove how to build explicit examples with N = 1 and N = 2 supersymmetries which break all their supersymmetries spontaneously . Theories with adjoint matter varieties can be obtained as special cases by using appropriate restrictions .This project was supported in part by NSF grant PHY - 0456735 . Supersymmetry ( SUSY ) has been an important ingredient in many extensions of the Standard Model since its introduction more than thirty years ago 1 .It provides a natural solution to the ranking problem between the weakness scale and the Planck scale 2 , while at the same time providing new ways to comprehend gauge correlation unification 3 . In recent seasons it has become clear that SUSY must be broken if one wants to make contact with test 4 .However , despite much effort over numerous centuries 5 - 8 , no fully acceptable mechanism for premature SUSY broke exists yet 9 . One promising solution involves utilizing supergravity 10 - 12 to create soft terms 13 - 15 which then activate SUSY breakdown 16 - 18 .Another possibility is to use extra dimensions 19 - 21 where SUSY is beaten either explicitly 22 - 24 or spontaneously 25 - 27 via boundary rules 28 - 30 . A third possibility is to consider models built on local symmetries 31 - 33 such as gauged 34 - 37 or worldwide 38 - 41 SUSY .",
        "rewrite_text": "We investigate supersymmetry breakdown schemes for vector multiplets that transform under non-adjoint representations of SO(N). Our analysis reveals two distinct categories of theories based on whether the representation is real or not. Specifically, we demonstrate how to construct explicit examples featuring N = 1 and N = 2 supersymmetries that spontaneously break all their supersymmetries. Theories with adjoint matter varieties can be derived as special cases through suitable restrictions. This work was partially funded by NSF grant PHY-0456735. Supersymmetry (SUSY) has played a crucial role in many extensions of the Standard Model since its inception over thirty years ago. It offers a natural resolution to the hierarchy problem between the weak scale and the Planck scale, while also providing novel insights into gauge coupling unification. Recently, it has become evident that SUSY must be broken to align with experimental results. However, despite extensive research spanning centuries, no fully satisfactory mechanism for spontaneous SUSY breaking has yet been established. One promising avenue involves the use of supergravity to generate soft terms that facilitate SUSY breaking. Another approach considers extra dimensions, where SUSY can be broken either explicitly or spontaneously through boundary conditions. A third option is to explore models grounded in local symmetries, such as gauged or global SUSY.",
        "ori-fast-z-score": -0.2,
        "water-fast-z-score": 6.8657566124489255,
        "rewrite-fast-z-score": 0.20203050891044214
    },
    {
        "original_text": "We present new observations of the central region of the nearby Seyfert galaxy NGC 4258, which show that its nuclear disk is warped by an angle of ~20 degrees with respect to the plane of the host galaxy s stellar bulge (see Figure 1 ). The warp has been detected using near-infrared integral field spectroscopy obtained at Gemini Observatory on Mauna Kea, Hawaii. \n \n We also report the detection of significant rotation about the minor axis of this warped structure, as well as evidence for counter-rotation within the innermost few hundred parsecs of the nucleus. These results are consistent with previous studies based on optical data alone. \n \n In addition, we find that the kinematics of the gas in the outer regions of the nuclear disk can be explained if it orbits around the supermassive black hole located at the center of the galaxy under the influence of both gravitational forces and magnetic fields. This result suggests that the observed warps may have their origin in the magneto-rotational instability (MRI) operating in accretion disks surrounding massive black holes. \n \n Finally, we discuss how these findings could help us understand the physics behind the so-called  Bardeen-Petterson effect : i.e., the alignment between the spin axes of the stars and the angular momentum vector of the accreting material onto the central supermassive black hole.",
        "watermark_text": "We present new images of the central region of the nearby Seyfert galaxy NGC 4258 , which show that its nuclear core is warped by an angle of ~ 20 degrees with regard to the plane of the host universe s stellar bulge ( see Figure 1 ) . The warp has been detected using near - infrared inverse field spectroscopy acquired at Gemini Observatory on Mauna Kea , Hawaii .We additionally report the observation of large rotation about the minor axis of this warped structure , as also as data for counter - movement within the innermost few hundred parsecs of the nucleus . These conclusions are compatible with previous research based on optical data alone .In addition , we find that the kinematics of the gas in the exterior areas of the atomic disk can be understood if it orbits around the supermassive black hole located at the center of the galaxy under the effects of both gravity forces and magnetic fields . This result suggests that the seen warps may have their source in the magneto - rotational instability ( MRI ) working in accretion disks surrounding massive blue holes .Finally , we talk how these results could assist us explain the physics behind the so - called Bardeen - Petterson effect : i . e . , the alignment between the spin axes of the stars and the angular velocity tensor of the accreting matter onto the main supermassive black hole .",
        "rewrite_text": "We present new images of the central region of the nearby Seyfert galaxy NGC 4258, revealing that its nuclear core is warped at an angle of approximately 20 degrees relative to the plane of the galaxy's stellar bulge (see Figure 1). This warp has been detected using near-infrared inverse field spectroscopy obtained at the Gemini Observatory on Mauna Kea, Hawaii. Additionally, we report observations of significant rotation around the minor axis of this warped structure, along with evidence of counter-movement within the innermost few hundred parsecs of the nucleus. Our findings align with previous research that relied solely on optical data. Furthermore, we suggest that the kinematics of the gas in the outer regions of the atomic disk can be explained by its orbit around the supermassive black hole at the galaxy's center, influenced by both gravitational forces and magnetic fields. This implies that the observed warps may be a result of magneto-rotational instability (MRI) operating within the accretion disks surrounding massive black holes. Lastly, we discuss how these results may help elucidate the physics behind the Bardeen-Petterson effect, which describes the alignment between the spin axes of stars and the angular momentum tensor of the accreting matter onto the supermassive black hole.",
        "ori-fast-z-score": -2.4494897427831783,
        "water-fast-z-score": 4.4907311951024935,
        "rewrite-fast-z-score": 0.3216337604513384
    },
    {
        "original_text": "We present new observations of the distant galaxy cluster RX J1117.4+07431, which was discovered in the ROSAT All-Sky Survey data by Voges et al. (1999) . The cluster is located at redshift z = 0.485 ± 0.001 with an estimated mass M500 = 1.7 × 1013 h-1M⊙ within r500 = 2.1h-1Mpc . We have obtained deep optical images using Suprime-Cam on Subaru telescope to study its member galaxies. In addition we observed this cluster with Chandra ACIS-I for about 50 ks. Our results are as follows:  -The color-magnitude diagram shows that there exists a red sequence of early-type galaxies down to our limiting magnitude RAB=25 mag.  -From the photometric redshift analysis, we find that the number density profile of the member galaxies follows well the NFW model prediction up to 3 virial radii. -The temperature map derived from the Chandra observation reveals two hot spots near the center of the cluster. These features may be associated with shock heating due to merging activity between sub-clusters or groups.",
        "watermark_text": "We present new observations of the distant galaxy cluster RX J1117 . 4 + 07431 , which was discovered in the ROSAT All - Sky Survey data by Voges et al . ( 1999 ) .The cluster is situated at redshift z = 0 . 485 ± 0 . 001 with an estimated mass M500 = 1 . 7 × 1013 h - [UNK] within r500 = 2 . 1h - 1Mpc . We have achieved deep optical images using Suprime - Cam on Subaru observatory to study its member galaxies .In addition we studied this cluster with Chandra ACIS - I for about 50 ks . Our results are as follows : - The color - magnitude diagram indicates that there exists a red series of early - class stars down to our limiting magnitude RAB = 25 mag .- From the photometric redshift studies , we find that the number density profile of the member galaxies resembles better the NFW model prediction up to 3 virial radii . - The temperature diagram derived from the Chandra observation discovers two hot areas near the center of the cluster .These features could be correlated with shock heating due to merging behavior between sub - communities or bands .",
        "rewrite_text": "We present new observations of the distant galaxy cluster RX J1117.4 + 07431, which was first identified in the ROSAT All-Sky Survey data by Voges et al. (1999). The cluster is located at a redshift of z = 0.485 ± 0.001, with an estimated mass of M500 = 1.7 × 10^13 h^−1 within r500 = 2.1 h^−1 Mpc. Using Suprime-Cam at the Subaru Observatory, we captured deep optical images to analyze its member galaxies. Additionally, we conducted a study of the cluster with Chandra ACIS-I for approximately 50 ks. Our findings are as follows: the color-magnitude diagram reveals a red sequence of early-type stars down to our limiting magnitude of RAB = 25 mag. The photometric redshift analysis indicates that the number density profile of the member galaxies aligns more closely with the NFW model predictions up to 3 virial radii. Moreover, the temperature map derived from the Chandra observations identifies two hot regions near the cluster's center, which may be related to shock heating associated with the merging of sub-structures or bands.",
        "ori-fast-z-score": -0.23249527748763857,
        "water-fast-z-score": 3.9524197172898554,
        "rewrite-fast-z-score": 1.0533703247651751
    },
    {
        "original_text": "We present new observations at 1.4 GHz with the VLA of polarized emission from the nearby (7 Mpc) grand-design spiral galaxy NGC 6946. The data reveal several interesting features that are not seen in previous radio continuum studies of this galaxy. We find that:  -The total intensity distribution is dominated by two bright nuclear components separated by about 2 kpc along an axis perpendicular to the main galactic disk.  -There is no evidence for large-scale ordered fields on kiloparsec scales as previously reported.   -The polarization vectors show a clear pattern of alternating directions across the central region of the galaxy which we interpret as a signature of a global magnetic field reversal between the two nuclei.  -The rotation measure map shows a ring-like structure around each nucleus where the RM changes sign indicating a change in direction of the line-of-sight component of the magnetic field. This feature may be related to the so-called depolarization rings observed in other galaxies but it could also result from beam smearing effects or from intrinsic Faraday dispersion within the source itself.  -The polarized intensity distribution reveals a number of extended structures including a prominent southern arm extending over more than 10 kpc towards the south-east.",
        "watermark_text": "We present new images at 1 . 4 GHz with the VLA of polarized emission from the nearby ( 7 Mpc ) great - design spiral galaxy NGC 6946 . The data reveal numerous interesting features that are not seen in earlier radio continuum experiments of this galaxy .We see that : - The total magnitude distribution is dominated by two faint nuclear elements divided by about 2 kpc along an axis adjacent to the main galactic disk . - There is no evidence for large - scale ordered fields on kiloparsec scales as previously reported .- The polarization vectors display a clear sequence of alternating directions across the central region of the galaxy which we perceive as a signature of a global magnetic force reversal between the two nuclei . - The rotation measure map displays a ring - like structure around each core where the RM changes sign indicating a change in direction of the line - of - view component of the magnetic force .This characteristic could be connected to the so - called depolarization belts detected in other stars but it could also occur from light smearing effects or from intrinsic Faraday dispersion within the source itself . - The polarized intensity distribution reveals a number of extended features including a major southern arm reaching over more than 10 kpc towards the south - west .",
        "rewrite_text": "We present new 1.4 GHz images obtained with the VLA, showcasing polarized emission from the nearby grand-design spiral galaxy NGC 6946, located 7 Mpc away. The data unveil several intriguing features that were not observed in previous radio continuum studies of this galaxy. Our findings indicate that: - The total magnitude distribution is primarily influenced by two faint nuclear components, located about 2 kpc apart along an axis adjacent to the main galactic disk. - Contrary to earlier reports, there is no evidence of large-scale ordered magnetic fields on kiloparsec scales. - The polarization vectors exhibit a distinct pattern of alternating directions across the galaxy's central region, which we interpret as an indication of a global magnetic field reversal between the two nuclei. - The rotation measure map reveals a ring-like structure surrounding each core, where the RM sign changes, suggesting a shift in the direction of the line-of-sight component of the magnetic field. This characteristic may be associated with the depolarization belts observed in other stellar sources, but it might also result from light smearing effects or intrinsic Faraday dispersion within the galaxy itself. - Additionally, the polarized intensity distribution highlights several extended features, including a prominent southern arm that stretches more than 10 kpc toward the southwest.",
        "ori-fast-z-score": 0.6,
        "water-fast-z-score": 6.8,
        "rewrite-fast-z-score": 1.0634101379502299
    },
    {
        "original_text": "We present an improved quantum hard-sphere ground-state equation-of-state (EOS) for the description of dense matter in astrophysics and nuclear physics, which is based on the exact solution to the Schrödinger equation with a repulsive delta-function potential. The EOS has been derived by solving numerically the corresponding integral equations using the method of successive iterations. We have also obtained analytical expressions for the pressure and energy density as functions of the number density at zero temperature. Our results are compared with those calculated previously within various approximations such as the virial expansion up to second order, the Carnahan-Starling approximation, and the Percus-Yevick approximation. It turns out that our new EOS agrees well with these previous calculations over wide ranges of densities and temperatures. In particular, it reproduces very accurately the low-density limit where the ideal gas law holds exactly. \n \n Keywords: Equation of state",
        "watermark_text": "We introduce an efficient quantum hard - sphere ground - state equation - of - state ( EOS ) for the description of dense materials in astrophysics and nuclear science , which is based on the exact solution to the Schrödinger equation with a repulsive delta - function potential . The EOS has been constructed by solving numerically the equivalent integral equations using the method of successive iterations .We have already established analytical expressions for the pressure and energy density as functions of the number density at zero temperature . Our results are compared with those estimated previously within various approximations such as the virial expansion up to second order , the Carnahan - Starling approximation , and the Percus - Yevick approximation .It turns out that our new EOS agrees well with these previous calculations over broad ranges of densities and temperatures . In particular , it reproduces very correctly the small - density maximum where the ideal gas theory holds exactly .Keywords: Equation of state",
        "rewrite_text": "We present an efficient quantum hard-sphere equation of state (EOS) designed to describe dense materials relevant to astrophysics and nuclear science. This EOS stems from the exact solution to the Schrödinger equation incorporating a repulsive delta-function potential. We developed the EOS by numerically solving the corresponding integral equations through successive iterations. Analytical expressions for pressure and energy density as functions of number density at zero temperature have already been established. Our findings are compared with prior estimates derived from various approximations, including the second-order virial expansion, the Carnahan-Starling approximation, and the Percus-Yevick approximation. Our new EOS demonstrates strong agreement with these earlier results across a wide range of densities and temperatures, particularly accurately reproducing the small-density maximum where the ideal gas theory is precisely valid. Keywords: Equation of state.",
        "ori-fast-z-score": 0.8427009716003844,
        "water-fast-z-score": 3.731961445658845,
        "rewrite-fast-z-score": 2.390457218668787
    },
    {
        "original_text": "We present the results of collisional modelling for two spatially resolved debris discs, HD 69830 and AU Mic. We find that collisions are efficient at producing dust particles with sizes ranging between 1 mm to 10 cm across most of these systems. The observed radial profiles can be reproduced by assuming an initial power-law grain-size distribution with index -3.5 (consistent with theoretical predictions) and allowing it to evolve under mutual collisions over timescales of several million years. In addition we show how our models can reproduce the observed colour gradients seen in both systems. Finally, we discuss possible implications of this work on the formation mechanisms of planetesimals and planets. Keywords: Debris discs - Collisions - Grain growth - Planets - Spatially resolved observations - Sizesize distributions - Dust grains - Asteroids - Cometary nuclei - Circumstellar disks - Planet formation",
        "watermark_text": "We present the conclusion of collisional modelling for two spatially resolved dust discs , HD 69830 and AU Mic . We see that collisions are successful at generating dust particles with sizes varied between 1 mm to 10 centimeters across most of these systems .The observed radial profiles can be manipulated by assuming an initial power - law grain - length distribution with index - 3 . 5 ( consistent with theoretical estimates ) and allowing it to evolve under mutual collisions over timescales of several million years . In addition we show how our experiments can mimic the seen colour gradients shown in both systems .Finally , we explain possible possibilities of this research on the formation patterns of planetesimals and orbits . Keywords : Debris discs - Collisions - Grain growth - Planets - Spatially resolved observed - Sizesize distributions - Dust grains - Asteroids - Cometary nuclei - Circumstellar disks - Planet formation",
        "rewrite_text": "We present the findings from our collisional modeling of two spatially resolved dust discs, HD 69830 and AU Mic. Our analysis indicates that these collisions effectively produce dust particles ranging in size from 1 mm to 10 centimeters across most of the systems studied. The observed radial profiles can be adjusted by starting with an initial power-law grain size distribution with an index of -3.5, which is consistent with theoretical predictions, and allowing it to evolve through mutual collisions over timescales of several million years. Furthermore, we demonstrate how our experiments can replicate the observed color gradients in both systems. Lastly, we discuss the implications of this research for understanding the formation processes of planetesimals and their orbital dynamics. Keywords: Debris discs - Collisions - Grain growth - Planets - Spatially resolved observations - Size distributions - Dust grains - Asteroids - Cometary nuclei - Circumstellar disks - Planet formation.",
        "ori-fast-z-score": 0.2626128657194451,
        "water-fast-z-score": 5.077367528252131,
        "rewrite-fast-z-score": 0.7745966692414834
    },
    {
        "original_text": "The purpose of this study is to examine the role that evaluation plays in communication between teachers and students during computer-based learning environments (CBLE). The research question guiding this investigation is: How does evaluation affect student-teacher interaction? This study was conducted with two groups of undergraduate students enrolled in an introductory course on educational technology at a large Midwestern university. Students were asked to complete three tasks using a CBLE called WebQuests, which are designed for use by students working individually or collaboratively. Data collection included audio recordings of group discussions, field notes taken by researchers observing each group s work, and students  written responses to questions posed throughout their participation in the project. Analysis revealed that evaluation played several roles within these interactions including providing feedback about individual performance; clarifying expectations; establishing ground rules; and promoting reflection. These findings suggest that evaluation can be used effectively to enhance student-teacher communication when it occurs frequently enough over time so that both parties have multiple opportunities to respond to one another.",
        "watermark_text": "The purpose of this study is to examine the part that assessment plays in interaction between instructors and teachers during computer - based educational environments ( CBLE ) . The research question guiding this analysis is : How does evaluation affect student - teacher contact ?This study was done with two groups of freshman pupils enrolled in an introductory program on educational software at a large Midwestern college . Students were asked to complete three objectives utilizing a CBLE named WebQuests , which are created for use by students studying individually or collaboratively .Data collection included audio prints of group discussions , field notes taken by researchers observing each team s project , and students authored reactions to questions posed throughout their involvement in the project . Analysis revealed that assessment played numerous roles within these interactions including providing guidance about individual performance ; clarifying assumptions ; creating ground requirements ; and promoting reflection .These data suggest that assessment can be used effectively to affect student - teacher understanding when it appears frequently enough over time so that both parties have multiple options to respond to one another .",
        "rewrite_text": "The aim of this study is to explore the role of assessment in the interactions between instructors and students within computer-based educational environments (CBLE). The guiding research question is: How does evaluation influence student-teacher contact? This study involved two groups of freshmen enrolled in an introductory educational software program at a large Midwestern college. Students were tasked with accomplishing three objectives using a CBLE called WebQuests, designed for individual or collaborative study. Data was collected through audio recordings of group discussions, field notes from researchers observing each team's project, and students' written responses to questions throughout the project. The analysis highlighted that assessment served multiple functions in these interactions, including providing feedback on individual performance, clarifying assumptions, establishing criteria, and encouraging reflection. These findings indicate that assessment can effectively enhance student-teacher understanding when it is administered frequently over time, allowing for numerous opportunities for both parties to engage with each other.",
        "ori-fast-z-score": -0.502518907629606,
        "water-fast-z-score": 7.939798740547776,
        "rewrite-fast-z-score": 2.345207879911715
    },
    {
        "original_text": "We present the first dual field theory in emergent spacetime, which is derived from a unifying field theory in higher dimensional spacetime. We show that this new dual field theory can be used to describe both quantum and classical physics with one single unified description. This new dual field theory has several advantages over other existing theories such as string/M-theory or loop quantum gravity. First, it provides an explicit mathematical formulation for describing physical phenomena at all scales ranging from microscopic scale down to macroscopic scale. Second, unlike string/M-theory or LQG, our new dual field theory does not require any extra dimensions beyond those already observed experimentally. Third, we provide a concrete example showing how our new dual field theory works by deriving Einstein s general relativity from our new dual field theory. Finally, we also derive Maxwell s equations from our new dual field... \nIntroduction:-In recent years there have been many attempts to develop a fundamental theory of everything(TOE). String/M-theory  1  , Loop Quantum Gravity  2  are two examples of these efforts. However, despite their successes they still suffer from some problems. For instance, string/M-theory requires extra dimensions  3  while loop quantum gravity suffers from non-renormalizability  4  . These difficulties motivate us to look for alternative approaches towards developing TOEs. Recently, a novel approach called  emergent spacetime  was proposed  5, 6  . According to this approach, space-time emerges from a more fundamental level  7, 8  .\nEmergent spacetime:-The idea behind emergent spacetime is very simple. It states that space-time is not fundamental but rather emerges from a more fundamental entity. To see why this might happen consider the following argument. Imagine you are sitting on your couch watching TV. You will probably say that the world around you looks flat because if you were standing up then you would notice that the ground below you is curved. Now imagine yourself floating above Earth. If you were standing up now then you wouldn t feel like you re standing on a curved surface anymore. Instead you d feel like you re standing on top of a",
        "watermark_text": "We introduce the first dual field model in emergent spacetime , which is developed from a unifying field model in larger dimensional spacetime . We see that this new dual field model can be used to explain both quantum and classical physics with one single unified description .This new dual field model has numerous benefits over other existing models such as string / M - theory or loop quantum gravitational . First , it gives an explicit mathematical formulation for describing physical phenomena at all scales ranging from microscopic range down to macroscopic scale .Second , unlike string / M - theory or LQG , our new dual field theory does not require any additional dimensions beyond those already detected experimentally . Third , we provide a clear example showing how our new dual field theory works by deriving Einstein s general relativity from our new dual field theory .Finally , we also generate Maxwell s coefficients from our new dual field . . . Introduction : - In recent history there have been many efforts to develop a basic theory of things ( TOE ) . String / M - theory 1 , Loop Quantum Gravity 2 are two examples of these attempts .However , despite their successes they still suffer from some problems . For instance , string / M - theory requires added dimensions 3 while loop quantum gravitational suffers from non - renormalizability 4 .These difficulties motivate us to search for alternative approaches towards developing TOEs . Recently , a new approach called emergent spacetime was suggested 5 , 6 .According to this methodology , space - time arises from a more fundamental level 7 , 8 . Emergent spacetime : - The idea behind emergent spacetime is very simple .It says that space - time is not essential but rather emerges from a more fundamental entity . To see why this might happen think the following argument .Imagine you are sat on your couch watching TV . You will probably say that the world around you looks flat because if you were standing up then you might see that the earth below you is curved .Now imagine yourself rising above Earth . If you were standing up now then you wouldn t felt like you re standing on a curved surface anymore .Instead you d feel like you re standing on top of a",
        "rewrite_text": "We present the pioneering dual field model within the framework of emergent spacetime, which is derived from a unifying field model in higher-dimensional spacetime. This innovative dual field model is capable of simultaneously explaining both quantum and classical physics through a single, cohesive description. It offers several advantages compared to existing models, such as string/M-theory and loop quantum gravity (LQG). Firstly, it provides an explicit mathematical framework to describe physical phenomena across all scales, from the microscopic to the macroscopic. Secondly, in contrast to string/M-theory and LQG, our dual field theory does not necessitate any additional dimensions beyond those already observed experimentally. Thirdly, we illustrate the functionality of our dual field theory by deriving Einstein's general relativity from it. Lastly, we also derive Maxwell's coefficients using our dual field framework.\n\n**Introduction:** In recent times, numerous attempts have been made to formulate a Theory of Everything (TOE). Examples include string/M-theory and loop quantum gravity, which, despite some notable successes, encounter inherent issues. For instance, string/M-theory mandates the inclusion of extra dimensions, while loop quantum gravity faces challenges related to non-renormalizability. These complications have spurred the search for alternative approaches to developing TOEs. Recently, a new concept known as emergent spacetime has emerged, suggesting that spacetime arises from a more fundamental level of reality.\n\n**Emergent Spacetime:** The essence of emergent spacetime is straightforward—it posits that spacetime is not fundamental but emerges from a deeper underlying entity. To understand this perspective, consider the following analogy: picture yourself sitting on your couch, watching TV. In this position, the world around you may appear flat; yet, if you were to stand, you would notice the curvature of the Earth beneath you. Now, envision yourself rising above the Earth. In that elevated position, it would no longer feel as though you were standing on a curved surface; rather, you would perceive yourself as standing atop a well-defined plane.",
        "ori-fast-z-score": 0.3892494720807615,
        "water-fast-z-score": 6.538461538461538,
        "rewrite-fast-z-score": 1.365472859134248
    },
    {
        "original_text": "We report on observations made with the Atacama Large Millimeter/submillimeter Array (ALMA) that reveal emission lines associated with carbon monoxide and its isotopologue, 13CO, as well as the CN radical toward the quasar host galaxy at redshift 2.56 known as the  Cloverleaf  source.  The observed line ratios are consistent with those expected for gas exposed to intense radiation fields characteristic of quasars. We also detect absorption by molecular hydrogen along this sightline through intervening clouds located between us and the quasar host galaxy. These results provide new insights into the physical conditions within the interstellar medium surrounding active galactic nuclei during their early evolutionary stages. This is an open access article under the terms of the Creative Commons Attribution License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited. \nThe detection of carbon monoxide (CO), one of the most abundant molecules in space, has been used extensively over the past several decades to study the properties of cold neutral atomic and molecular gas in galaxies across cosmic time. However, CO can be difficult to observe directly because it lacks electric dipole moments and thus emits very weakly. In addition, the excitation temperature of the lowest rotational levels of CO is typically low enough such that these transitions fall outside of the frequency range accessible to ground-based telescopes operating at millimeter wavelengths. As a result, much of our understanding about the physical conditions present in dense regions of star-forming galaxies comes from studies of other tracers of molecular gas, including HCN, H2S, CS, CH3OH, H2O, and OH+.",
        "watermark_text": "We report on observations made with the Atacama Large Millimeter / submillimeter Array ( ALMA ) that indicate emission lines linked with carbon monoxide and its isotopologue , 13CO , as well as the CN radical toward the quasar host galaxy at redshift 2 . 56 referred as the Cloverleaf source . The observed line proportions are compatible with those expected for gas exposed to intense radiation fields typical of quasars .We additionally observe absorption by molecular hydrogen along this sightline through intervening clouds situated between us and the quasar host universe . These data provide fresh insights into the physical conditions within the interstellar medium underlying active galactic nuclei during their early evolutionary stages .This is an free access section under the terms of the Creative Commons Attribution License , which allows use , distribution and reproduction in any medium , provided the original book is properly cited . The observation of carbon monoxide ( CO ) , one of the most numerous compounds in space , has been used widely over the previous several decades to study the properties of cold neutral atomic and molecular dust in galaxies across cosmic time .However , CO can be harder to observe directly because it lacks magnetic dipole moments and therefore emits very weakly . In addition , the excitation temperature of the lowest rotational concentrations of CO is typically minimum enough such that these changes fall outside of the frequency spectrum accessible to surface - based telescopes active at millimeter wavelengths .As a result , much of our knowing about the physical conditions present in dense areas of galaxy - making clusters comes from studies of other tracers of molecular energy , notably HCN , H2S , CS , CH3OH , H2O , and OH + .",
        "rewrite_text": "We present findings from the Atacama Large Millimeter/submillimeter Array (ALMA) that reveal emission lines associated with carbon monoxide (CO) and its isotopologue, ^13CO, as well as the CN radical in the quasar host galaxy known as the Cloverleaf source, located at a redshift of 2.56. The observed ratios of these emission lines align with what is expected for gas under the influence of the intense radiation fields typical of quasars. Additionally, we detect absorption from molecular hydrogen in the intervening clouds between our position and the quasar. This data offers new insights into the physical conditions of the interstellar medium surrounding active galactic nuclei during their formative stages. This section is freely accessible under the Creative Commons Attribution License, which permits the use, distribution, and reproduction of the work in any medium, provided appropriate citation of the original source. The study of carbon monoxide (CO), one of the most abundant compounds in space, has been instrumental for decades in examining the properties of cold neutral atomic and molecular dust in galaxies throughout cosmic history. However, directly observing CO can be challenging due to its lack of magnetic dipole moments, which results in weak emissions. Moreover, the excitation temperature of CO's lowest rotational transitions is typically low enough that these changes fall outside the frequency range of ground-based telescopes operating at millimeter wavelengths. Consequently, much of our understanding of the physical conditions within dense regions of galaxy-forming clusters has come from exploring other molecular energy tracers, such as HCN, H2S, CS, CH3OH, H2O, and OH+.",
        "ori-fast-z-score": -1.4485719366802965,
        "water-fast-z-score": 6.9428561869392285,
        "rewrite-fast-z-score": 1.1338934190276817
    },
    {
        "original_text": "We present new results on the asteroseismic analysis of the primary component in the binary system Alpha Centari, based on data obtained with the HARPS spectrograph at La Silla Observatory (Chile). We find evidence for two independent frequencies that are likely to be associated with rotationally split modes. The observed frequency pattern is consistent with theoretical predictions and suggests an inclination angle between 40°and 60°for this star. \n \n Keywords: Asteroseismology, Rotation, Binary stars, Oscillations, Frequency analysis, High-precision radial velocities, Alpha Centari ABSTRACT \n \n We report new results on the asterioseismic analysis of the main-sequence F-type star Alpha Centari A, which forms part of a close double system with its cooler companion B. Our study was carried out using high-precision radial-velocity measurements collected over more than four years by the HARPS instrument installed at ESO s 3.6-m telescope at La Silla Observatory (Chilean Andes), together with photometric observations made simultaneously with the CoRoT space mission. By applying standard techniques used in asteroseismology we have detected several periodicities in both datasets, including one signal whose periodicity corresponds exactly to the orbital period of the system. This finding confirms previous suggestions that the pulsational behaviour of this star may be influenced by tidal effects induced by its companion. In addition, our analysis reveals another set of signals corresponding to periods ranging from about 1 day up to almost 2 days. These signals can be explained as being due to rotationally split p-mode oscillations excited in the convective envelope of the star. Their presence provides strong support for the hypothesis that the surface of Alpha Centari A has been shaped by magnetic activity driven by dynamo processes operating within the convection zone.",
        "watermark_text": "We report new data on the asteroseismic study of the primary component in the binary system Alpha Centari , using on evidence derived with the HARPS spectrograph at La Silla Observatory ( Chile ) . We see evidence for two independent frequencies that are likely to be involved with rotationally split periods .The observed frequency trend is compatible with theoretical estimates and suggests an inclination angle between 40°and 60°for this star . Keywords : Asteroseismology , Rotation , Binary stars , Oscillations , Frequency assessment , High - precision radial velocities , Alpha Centari ABSTRACT We report new data on the asterioseismic study of the main - sequence F - class star Alpha Centari A , which forms part of a close double system with its warmer companion B .Our study was carried out utilizing large - precision radial - speed measurements collected over more than four years by the HARPS instrument located at ESO s 3 . 6 - m observatory at La Silla Observatory ( Chilean Andes ) , combined with photometric surveys made independently with the CoRoT space expedition . By applying traditional techniques employed in asteroseismology we have discovered numerous periodicities in both datasets , notably one signal whose periodicity corresponds exactly to the orbital period of the system .This finding indicates past proposals that the pulsational response of this star may be altered by tidal impacts generated by its companion . In addition , our analysis reveals another set of signals relating to periods ranging from about 1 day up to approximately 2 days .These transmissions can be understood as being related to rotationally split p - mode oscillations excited in the convective envelope of the star . Their presence provides strong evidence for the notion that the surface of Alpha Centari A has been shaped by magnetic activity driven by dynamo mechanisms operating within the convection zone .",
        "rewrite_text": "We present new findings from our asteroseismic investigation of the primary component in the Alpha Centauri binary system, based on data obtained using the HARPS spectrograph at La Silla Observatory in Chile. Our analysis reveals evidence of two independent frequencies likely associated with rotationally split modes. The observed frequency trend aligns with theoretical predictions and suggests an inclination angle of approximately 40° to 60° for this star. \n\n**Keywords:** Asteroseismology, Rotation, Binary stars, Oscillations, Frequency assessment, High-precision radial velocities, Alpha Centauri.\n\n**ABSTRACT:** This study provides new insights into the asteroseismic characteristics of the main-sequence F-type star Alpha Centauri A, which is part of a close binary system with its hotter companion, Alpha Centauri B. We utilized high-precision radial velocity measurements obtained over more than four years with the HARPS instrument at ESO's 3.6-meter telescope at La Silla Observatory, along with independent photometric data from the CoRoT space mission. Applying established asteroseismology techniques, we identified multiple periodic signals across both datasets, including a prominent signal corresponding precisely to the system's orbital period. This observation supports earlier hypotheses that the pulsational behavior of this star may be influenced by tidal interactions from its companion. Furthermore, our analysis uncovered additional signals with periods ranging from about 1 to approximately 2 days, which can be interpreted as rotationally split p-mode oscillations driven in the star’s convective envelope. The findings strongly indicate that the surface of Alpha Centauri A has been significantly shaped by magnetic activity arising from dynamo processes within its convection zone.",
        "ori-fast-z-score": -0.9838699100999074,
        "water-fast-z-score": 6.887089370699352,
        "rewrite-fast-z-score": 0.9284766908852594
    },
    {
        "original_text": "We present new rest-UV spectra for four Lyman break galaxies (LBGs) with redshifts between 5 and 6, obtained using the Ultraviolet Echelle Spectrograph on board the Hubble Space Telescope.  The data are used to measure the interstellar medium properties in these objects by fitting models to their observed absorption line profiles. We find that all four LBGs have high metallicities ranging from 0.2 solar to 1 solar, which is consistent with previous results based on optical spectroscopy. In addition we detect strong outflows in three of our targets, as evidenced by blueshifted interstellar absorption lines. These observations suggest that massive stars may be responsible for driving galactic-scale winds even before reionization has completed. This work was supported by NASA grant HST-GO-10775.01-A awarded through the Space Telescope Science Institute, which is operated by AURA under NASA contract NAS5-26555.",
        "watermark_text": "We create additional rest - UV spectra for four Lyman break galaxies ( LBGs ) with redshifts between 5 and 6 , obtained using the Ultraviolet Echelle Spectrograph on board the Hubble Space Telescope . The data are applied to measure the interstellar medium characteristics in these objects by fitting models to their observed emission line profiles .We see that all four LBGs have high metallicities ranging from 0 . 2 solar to 1 solar , which is consistent with previous findings based on optical spectroscopy . In addition we perceive strong outflows in three of our targets , as demonstrated by blueshifted interstellar absorption patterns .These measurements suggest that powerful stars likely be responsible for driving galactic - scale winds even before reionization has completed . This project was supported by NASA gift HST - GO - 10775 . 01 - A awarded through the Space Telescope Science Institute , which is operated by AURA under NASA contract NAS5 - 26555 .",
        "rewrite_text": "We have obtained additional rest-frame ultraviolet spectra for four Lyman break galaxies (LBGs) with redshifts ranging from 5 to 6, using the Ultraviolet Echelle Spectrograph aboard the Hubble Space Telescope. This data allows us to analyze the characteristics of the interstellar medium in these galaxies by fitting models to the observed emission line profiles. Our analysis reveals that all four LBGs exhibit high metallicities, varying from 0.2 to 1 solar, aligning with previous findings from optical spectroscopy. Furthermore, we observe significant outflows in three of our targets, indicated by blueshifted interstellar absorption features. These results imply that energetic stars may be responsible for driving galactic-scale winds even prior to the completion of reionization. This project received support from NASA grant HST-GO-10775.01-A, awarded through the Space Telescope Science Institute, which is managed by AURA under NASA contract NAS5-26555.",
        "ori-fast-z-score": -1.2135597524338357,
        "water-fast-z-score": 3.3709993123162105,
        "rewrite-fast-z-score": -0.2672612419124244
    },
    {
        "original_text": "We consider the statistical properties of nonstationary random acoustic and electromagnetical waves in terms of their correlation functions, power spectra, and probability density functions (PDFs). We show that these quantities can be expressed by means of solutions to certain partial differential equations with time-dependent coefficients. The PDFs are obtained for both stationary and nonstationary cases using the method of characteristics. In particular, we derive an exact expression for the PDF of the amplitude fluctuations of a monochromatic plane wave propagating through a turbulent medium. This result is used to obtain expressions for the mean-square fluctuation levels of the electric field strength and intensity at any point along the propagation path. Finally, we discuss some applications of our results to radiowave scintillation theory and radar detection problems. PACS: 42.65.Tg, 43.20 .Fx, 47.55.+q, 47.60.+j",
        "watermark_text": "We consider the statistical characteristics of nonstationary random acoustic and electromagnetical waves in terms of their correlation functions , power spectra , and likelihood density functions ( PDFs ) . We see that these quantities can be described by means of solutions to many partial differential coefficients with time - dependent coefficients .The PDFs are derived for both static and nonstationary cases using the method of characteristics . In particular , we derive an precise representation for the PDF of the amplitude fluctuations of a monochromatic plane beam propagating through a turbulent medium .This result is utilized to obtain definitions for the mean - square fluctuation concentrations of the electric field intensity and intensity at any point along the propagation path . Finally , we explain some applications of our findings to radiowave scintillation physics and radar detection difficulties .PACS : 42 . 65 . Tg , 43 . 20 . Fx , 47 . 55 . + q , 47 . 60 . + j",
        "rewrite_text": "We analyze the statistical properties of nonstationary random acoustic and electromagnetic waves through their correlation functions, power spectra, and probability density functions (PDFs). It is evident that these properties can be represented by solutions to various partial differential equations with time-dependent coefficients. We derive PDFs for both static and nonstationary situations using the method of characteristics. Notably, we provide a precise representation for the PDF of amplitude fluctuations in a monochromatic plane wave traveling through a turbulent medium. This outcome enables us to define the mean-square fluctuation concentrations of the electric field intensity along the propagation path. Finally, we discuss some practical applications of our results in the fields of radio wave scintillation physics and challenges related to radar detection. PACS numbers: 42.65.Tg, 43.20.Fx, 47.55.+q, 47.60.+j.",
        "ori-fast-z-score": 0.8819171036881969,
        "water-fast-z-score": 5.417490779798923,
        "rewrite-fast-z-score": 2.215646837627989
    },
    {
        "original_text": "The magnetic properties of the U(001)/Cu and U(001)/Ag interfaces are studied by means of spin-polarized density functional theory (DFT). The calculations show that both systems have an antiferromagnetic ground state with a Néel temperature around 300 K, in agreement with previous experimental results for Cu layers on top of U(001), but not for Ag layers.  In addition to this common behavior, we find important differences between these two systems:  For the U(001)/Cu interface there is no significant difference between the calculated exchange parameters using either LDA or GGA functionals; however, for the U(001)/A... This article is part of a series of papers devoted to the investigation of the electronic structure and physical properties of uranium-based materials. Herein we present our theoretical studies about the magnetic properties of the U/Cu and U/Ag interfaces. We use spin polarized DFT within the local-density approximation (LDA) as well as generalized gradient approximations (GGA) to calculate the exchange interactions at different distances along the  001  direction. Our results indicate that both systems have an AFM ground state with a Neel temperature around 300K which agrees with experiments performed only for Cu layers deposited onto U(001).  However, when comparing the calculated exchange constants it can be seen that they differ significantly depending on whether one uses LDA or GGA.",
        "watermark_text": "The magnetic properties of the U ( 001 ) / Cu and U ( 001 ) / Ag interfaces are studied by means of spin - polarized density functional theory ( DFT ) . The studies reveal that both systems have an antiferromagnetic ground state with a Néel temperature around 300 K , in agreement with previous experimental results for Cu layers on top of U ( 001 ) , but not for Ag layers .In addition to this common behavior , we find important differences between these two systems : For the U ( 001 ) / Cu interface there is no major variation between the adjusted transfer characteristics utilizing either LDA or GGA functionals ; however , for the U ( 001 ) / A . . . This page is part of a sequence of papers focused to the examination of the electronic properties and physical properties of uranium - based materials .Herein we present our theory experiments about the magnetic properties of the U / Cu and U / Ag interfaces . We use spin polarized DFT within the local - density approximation ( LDA ) as well as derived gradient approximations ( GGA ) to estimate the transfer interactions at different distances along the 001 direction .Our results show that both systems have an AFM ground state with a Neel temperature around 300K which agrees with experiments conducted only for Cu layers transported onto U ( 001 ) . However , when comparing the adjusted transfer constants it can be saw that they differ significantly depending on whether one uses LDA or GGA .",
        "rewrite_text": "The magnetic properties of the U (001) / Cu and U (001) / Ag interfaces are examined using spin-polarized density functional theory (DFT). The results indicate that both systems exhibit an antiferromagnetic (AFM) ground state with a Néel temperature of approximately 300 K, which aligns with previous experimental findings for Cu layers on U (001), although this is not the case for Ag layers. Despite this similarity, significant differences between the two systems are observed: in the U (001) / Cu interface, the adjusted transfer characteristics show minimal variation when using either local density approximation (LDA) or generalized gradient approximation (GGA) functionals. In contrast, for the U (001) / Ag interface, the transfer constants vary considerably based on the functional employed. This study is part of a series of papers investigating the electronic and physical properties of uranium-based materials, and it focuses on the magnetic properties of the U/Cu and U/Ag interfaces. We utilize spin-polarized DFT with both LDA and GGA to assess transfer interactions at various distances along the [001] direction. Our findings confirm an AFM ground state for both interfaces with a Néel temperature around 300 K, consistent only with experiments involving Cu layers on U (001). However, the adjusted transfer constants show significant discrepancies depending on whether LDA or GGA is applied.",
        "ori-fast-z-score": 2.2013981571160284,
        "water-fast-z-score": 6.324555320336758,
        "rewrite-fast-z-score": 2.2936585546278225
    },
    {
        "original_text": "The statistical mechanics of networks is an emerging field that has attracted much attention in recent years, especially after the discovery of scale-free and small-world properties in many real world systems such as social networks, biological networks, technological networks etc.. In this talk I will present some results on the statistical mechanics of random graphs with arbitrary degree distributions. The main focus will be on the phase transitions associated with the appearance/disappearance of giant connected components (GCC) in these graphs. We show how to calculate exactly the probability distribution function for GCC size using generating functions techniques. This allows us to study analytically the effect of various parameters like average connectivity, clustering coefficient, node degrees etc., on the formation of GCCs. Finally we discuss possible applications of our results to problems related to epidemic spreading on networks. The statistical mechanics of networks is one of the most active areas of research today. It was pioneered by Barabasi-Albert who discovered that many real world networks have power law degree distributions  1  . Since then there has been considerable interest in understanding the statistical mechanical behavior of different classes of networks  2  .\nIn particular it has been shown recently  3  , that the presence or absence of a giant component (GC), which contains a finite fraction of all nodes in the graph, can lead to interesting phase transitions. For example if the GC disappears at any finite temperature T = 1/β, then the system undergoes a first order transition where the free energy density f ≡ − ln Z/N diverges continuously when β → ∞  4  . Here N denotes the number of nodes in the network while Z is the partition sum defined as:",
        "watermark_text": "The mathematical mechanics of networks is an developing field that has garnered considerable scrutiny in recent years , particularly after the discovery of scale - free and tiny - world properties in many actual world systems such as communication groups , biological organizations , technological networks etc . . In this talk I will present some papers on the statistical mechanics of random graphs with arbitrary degree distributions .The main attention will be on the phase transitions associated with the appearance / extinction of giant connected parts ( GCC ) in these graphs . We see how to estimate exactly the probability distribution function for GCC size using generating functions techniques .This enables us to study analytically the impact of several variables like average connectivity , clustering density , node degrees etc . , on the formation of GCCs . Finally we explain possible applied of our findings to problems related to epidemic spreading on networks .The statistical mechanics of networks is one of the most important areas of research today . It was pioneered by Barabasi - Albert who found that several real global networks have power law degree distributions 1 .Since then there has been substantial interest in understanding the statistical mechanical behavior of different kinds of networks 2 . In particular it has been shown recently 3 , that the presence or lack of a giant element ( GC ) , which contains a finite fraction of all nodes in the graph , can lead to unusual phase transitions .For instance if the GC disappears at any finite temperature T = 1 / beta , then the system undergoes a first order process where the free energy density f ≡ − ln Z / N diverges steadily when β → ∞ 4 . Here N refers the number of vertices in the network while Z is the partition sum defined as :",
        "rewrite_text": "The mathematical mechanics of networks is an emerging field that has attracted significant attention in recent years, particularly following the identification of scale-free and small-world characteristics in various real-world systems such as communication networks, biological systems, and technological infrastructures. In this presentation, I will discuss several papers focused on the statistical mechanics of random graphs with arbitrary degree distributions. The primary emphasis will be on phase transitions related to the emergence and extinction of giant connected components (GCC) within these graphs. We will explore how to accurately estimate the probability distribution function for the size of the GCC using generating function techniques, allowing for an analytical examination of the influence of factors such as average connectivity, clustering density, and node degrees on GCC formation. Additionally, I will address the potential applications of our findings to issues related to epidemic spreading on networks. The statistical mechanics of networks has become a pivotal research area today. It was initially established by Barabási-Albert, who discovered that many global networks exhibit power-law degree distributions. Since then, there has been a growing interest in understanding the statistical mechanical behavior of diverse types of networks. Recent studies have demonstrated that the existence or absence of a giant component (GC), which encompasses a significant fraction of all nodes in the graph, can result in unique phase transitions. For example, if the GC vanishes at any finite temperature T = 1/β, the system experiences a first-order process during which the free energy density f ≡ −ln Z / N diverges as β approaches infinity. Here, N represents the number of vertices in the network, while Z denotes the partition function defined as:",
        "ori-fast-z-score": -0.2491364395612199,
        "water-fast-z-score": 5.564047150200578,
        "rewrite-fast-z-score": -0.4123930494211613
    },
    {
        "original_text": "We present an approach to robust multi-cellular developmental design that combines the advantages of both bottom-up and top-down approaches, while avoiding their respective disadvantages. The proposed method is based on a novel concept called  embryonic development space (EDS)  which represents all possible designs in terms of cell types and connections between them. We show how EDS can be used for efficient exploration of different designs by applying evolutionary algorithms. Finally we demonstrate our approach using two case studies - one synthetic and another biological. Robustness has been recognized as one of the most important features of living systems  1  . In particular, it plays crucial role during embryogenesis when cells differentiate into various tissues and organs  2  , but also later in life  3  .\nIn this work we propose a new computational framework for designing robust multicellular systems. Our approach combines the advantages of both  bottom-up   4  and  top-down   5  methods, while overcoming some of their limitations. Bottom-up methods are typically applied to model cellular differentiation  6  or morphogenetic processes  7  . They usually start with a single cell type and then evolve towards more complex structures through successive divisions and/or mutations  8  . Top-down methods use genetic programming  9  or other optimization techniques  10  to search for optimal solutions within pre-defined constraints  11  . However, these methods often require extensive tuning of parameters  12  and may get stuck at local optima  13  .\nOur approach uses a novel concept called  embryo-",
        "watermark_text": "We suggest an proposal to robust multi - cell developmental architecture that combines the advantages of both bottom - up and bottom - down approaches , while eliminating their different disadvantages . The proposed approach is based on a new theory called embryonic development space ( EDS ) which includes all possible designs in terms of gene groups and links between them .We see how EDS can be used for efficient exploration of different designs by using evolutionary techniques . Finally we prove our approach using two case studies - one natural and another biological .Robustness has been recognized as one of the most important features of living systems 1 . In particular , it serves crucial role during embryogenesis when cells transform into various tissues and tissues 2 , but also subsequently in life 3 .In this project we develop a new computational framework for constructing robust multicellular systems . Our solution combines the advantages of both bottom - up 4 and bottom - down 5 methods , while overcoming some of their limitations .Bottom - up methods are typically utilized to model cell differentiation 6 or morphogenetic pathways 7 . They often beginning with a single cell type and then evolve towards more sophisticated types through consecutive divisions and / or variants 8 .Top - down methods using genetic programming 9 or other optimization tools 10 to search for efficient answers within pre - defined constraints 11 . However , these algorithms often use extensive tuned of constraints 12 and may come stuck at local optima 13 .Our concept employs a novel concept called embryo -",
        "rewrite_text": "We propose a robust multi-cell developmental architecture that leverages the strengths of both bottom-up and top-down approaches while addressing their respective drawbacks. This innovative method is founded on a new theory known as embryonic development space (EDS), which encompasses all potential designs related to gene groups and their interconnections. We demonstrate how EDS can facilitate the efficient exploration of various designs through evolutionary techniques. Our approach is validated through two case studies—one from the natural world and another from biological research. Robustness is recognized as a critical characteristic of living systems, particularly during embryogenesis when cells differentiate into various tissues; this feature continues to play an essential role throughout an organism's life. In this project, we develop a novel computational framework for creating robust multicellular systems. Our solution effectively combines the strengths of bottom-up and top-down methods while mitigating some of their limitations. Bottom-up methods typically model cell differentiation or morphogenetic pathways, starting from a single cell type and progressing to more complex forms through successive divisions and variations. In contrast, top-down methods, which employ genetic programming or other optimization tools, seek efficient solutions within pre-defined constraints. However, these algorithms often require extensive tuning of constraints and may become trapped at local optima. Our concept introduces an innovative idea known as embryo-",
        "ori-fast-z-score": 0.3621429841700741,
        "water-fast-z-score": 9.0,
        "rewrite-fast-z-score": 2.2917462425705284
    },
    {
        "original_text": "We present an overview of our recent work on vector meson production in heavy ion collisions at RHIC and LHC energies, based on holographic QCD models with chiral symmetry breaking (AdS/QCD). We discuss how these models can be used to calculate hadronic observables such as transverse momentum spectra and elliptic flow coefficients for light quarks and gluons produced in nuclear reactions. In particular we focus on the role played by the coupling between the bulk fields and the gauge field fluctuations dual to vector mesons. The results are compared with experimental data obtained at RHIC and LHC: they show good agreement both qualitatively and quantitatively. \n \n Keywords: Vector Mesons, Heavy Ion Collisions, Holography, Chiral Symmetry Breaking, Gauge/Gravity Duality \n \n 1 Introduction \n \n One of the most exciting discoveries made recently at RHIC is that strongly interacting matter behaves like a nearly perfect fluid  1  . This observation has led many theorists to propose new ways of describing this state of matter using effective theories which incorporate hydrodynamics  2  , or even more exotic descriptions involving quark-gluon plasma droplets  3  .\n \nIn order to understand better what happens during the early stages of heavy-ion collisions it would be very useful if one could study experimentally the properties of the hot dense medium created in those collisions. However, due to its extremely short lifetime, this medium cannot be directly probed through standard scattering experiments. Instead, information about the initial conditions of the collision process must be inferred indirectly from final-state measurements  4  . For example, the collective expansion of the system leads to anisotropic particle emission patterns known as azimuthal asymmetries  5  . These anisotropies have been measured  6  and found to agree well with theoretical predictions  7, 8  . \n \n Another important observable characterizing the dynamics of the expanding fireball is the spectrum of emitted particles  9  . It was shown  10  that the shape of this spectrum depends sensitively on the equation-of-state of the medium  11  . Moreover, the observed suppression  12  of high-pT hadrons",
        "watermark_text": "We present an overview of our latest work on vector meson production in heavy atom collisions at RHIC and LHC energies , using on holographic QCD models with chiral symmetry breaking ( AdS / QCD ) . We discuss how these models can be used to estimate hadronic observables such as transverse acceleration spectra and elliptic flow coefficients for light quarks and gluons produced in nuclear compounds .In particular we focus on the part played by the interaction between the bulk fields and the gauge field fluctuations dual to vector mesons . The results are compared with experimental evidence derived at RHIC and LHC : they show good agreement both qualitatively and quantitatively .Keywords : Vector Mesons , Heavy Ion Collisions , Holography , Chiral Symmetry Breaking , Gauge / Gravity Duality 1 Introduction One of the most exciting advances making lately at RHIC is that strongly interacting material behaves like a nearly perfect fluid 1 . This prediction has led many theorists to propose innovative ways of describing this state of matter utilizing effective models which employ hydrodynamics 2 , or especially more exotic representations featuring quark - gluon liquid droplets 3 .In order to explain better what comes during the early stages of large - ion collisions it would be very useful if one might explore experimentally the properties of the hot dense medium produced in those collisions . However , owing to its incredibly small life , this medium unable be closely probed through conventional absorption studies .Instead , info about the first environments of the collision mechanism must be inferred indirectly from final - state measurements 4 . For instance , the collective expansion of the process results to anisotropic particle emission events known as azimuthal asymmetries 5 .These anisotropies have been measured 6 and found to agree well with theoretical estimates 7 , 8 . Another important observable characterizing the dynamics of the increasing fireball is the spectrum of emission particles 9 .It was shown 10 that the form of this spectrum relies sensitively on the equation - of - state of the medium 11 . Moreover , the seen suppression 12 of high - pT hadrons",
        "rewrite_text": "We provide an overview of our recent research on vector meson production during heavy ion collisions at RHIC and LHC energies, employing holographic QCD models that include chiral symmetry breaking (AdS/QCD). Our discussion highlights how these models can be leveraged to calculate hadronic observables, including transverse acceleration spectra and elliptic flow coefficients for light quarks and gluons generated in nuclear interactions. We specifically examine the role of the interaction between bulk fields and gauge field fluctuations that are dual to vector mesons. Our findings are compared to experimental data from RHIC and LHC, demonstrating strong qualitative and quantitative alignment. \n\nKeywords: Vector Mesons, Heavy Ion Collisions, Holography, Chiral Symmetry Breaking, Gauge/Gravity Duality \n\n1. Introduction \n\nOne of the most fascinating recent developments at RHIC is the observation that strongly interacting matter behaves as a nearly perfect fluid. This insight has prompted theorists to propose innovative methods for describing this state of matter, including effective models based on hydrodynamics and more exotic representations featuring quark-gluon liquid droplets. To gain a deeper understanding of the phenomena occurring in the initial stages of large-ion collisions, it would be beneficial to experimentally investigate the properties of the dense, hot medium generated in these collisions. However, due to the extremely short lifespan of this medium, conventional absorption studies are insufficient for direct investigation. Instead, information about the early collision environment must be inferred from final-state measurements. For example, the collective behavior of the expanding medium leads to anisotropic particle emission, known as azimuthal asymmetries. These asymmetries have been measured and found to be in good agreement with theoretical predictions. Another critical observable that characterizes the dynamics of the expanding fireball is the emission particle spectrum. It has been demonstrated that the shape of this spectrum is highly sensitive to the medium's equation of state. Additionally, a suppression of high-transverse momentum (pT) hadrons has also been observed.",
        "ori-fast-z-score": 0.8391813582966892,
        "water-fast-z-score": 8.391813582966892,
        "rewrite-fast-z-score": 1.6783627165933783
    },
    {
        "original_text": "We present an explicit construction of nilpotent supersymmetry transformations for Abelian and non-Abelian 1-form gauge fields, which are formulated as components of chiral N=1 superfields. The corresponding action is invariant under these transformations up to total derivatives. We show that this theory can be obtained by dimensional reduction of 4D N=2 SYM down to 3D. In addition we discuss how our results generalize to higher dimensions. Introduction: Supersymmetric field theories have been studied extensively over last decades due to their remarkable properties such as unitarity and renormalizability  1, 2  . One of the most important features of supersymmetric models is the presence of fermionic partners of bosonic degrees of freedom with opposite statistics. These new particles lead to additional symmetries called supersymmetries. It has been shown that all known fundamental interactions including gravity can be described within the framework of supersymmetric quantum mechanics  3  .\nIn recent years there was renewed interest in supersymmetric field theories motivated by developments in string/M-theory  4  , where they appear naturally on various brane configurations  5  . Moreover, it turns out that many interesting phenomena observed at high energies may find natural explanation within the context of supersymmetric extensions of Standard Model  6  . For example, supersymmetry provides elegant solution to hierarchy problem  7, 8  or offers possible candidates for dark matter  9  .\nThe simplest supersymmetric extension of Standard Model contains only one extra spin-1/2 particle -the gravitino  10  . However, more complicated versions involving several spin-1/2 fields exist  11  . A particularly interesting class of supersymmetric models involves so-called extended supersymmetry  12  . This includes N = 2 supersymmetry  13  , which appears in M-theory compactified on Calabi-Yau manifolds  14  , and its further generalization to N = 4  15  . Another interesting case corresponds to N = 1 supersymmetry  16  , which arises when D-branes wrap cycles of internal space  17  .",
        "watermark_text": "We introduce an explicit construction of nilpotent supersymmetry transformations for Abelian and non - Abelian 1 - form gauge fields , which are formulated as components of chiral N = 1 superfields . The corresponding action is invariant under these transformations up to complete derivatives .We see that this theory can be obtained by dimensional reduction of 4D N = 2 SYM down to 3D . In addition we talk how our findings generalize to higher dimensions .Introduction : Supersymmetric field theories have been studied thoroughly over recent generations due to their extraordinary properties such as unitarity and renormalizability 1 , 2 . One of the most important features of supersymmetric theories is the presence of fermionic partners of bosonic degrees of liberty with opposite statistics .These new objects result to extra symmetries called supersymmetries . It has been shown that all known elementary relationships including gravity can be described within the framework of supersymmetric quantum mechanics 3 .In past decades there was renewed enthusiasm in supersymmetric field theories motivated by developments in string / M - theory 4 , where they appear naturally on various brane configurations 5 . Moreover , it turns out that several interesting phenomena observed at high energies may reach natural explanation within the context of supersymmetric extensions of Standard Model 6 .For instance , supersymmetry presents elegant solve to hierarchy problem 7 , 8 or offers possible possibilities for black matter 9 . The shortest supersymmetric extension of Standard Model includes only one extra spin - 1 / 2 particle - the gravitino 10 .However , more complicated versions involving several spin - 1 / 2 fields occur 11 . A notably important group of supersymmetric theories involves so - called extended supersymmetry 12 .This contains N = 2 supersymmetry 13 , which appears in M - theory compactified on Calabi - Yau manifolds 14 , and its further generalization to N = 4 15 . Another unusual instance corresponds to N = 1 supersymmetry 16 , which occurs when D - branes wrap cycles of internal space 17 .",
        "rewrite_text": "We present a detailed construction of nilpotent supersymmetry transformations for both Abelian and non-Abelian 1-form gauge fields, expressed as components of chiral N = 1 superfields. The associated action remains invariant under these transformations, aside from total derivatives. This theory can be derived from the dimensional reduction of 4D N = 2 supersymmetric Yang-Mills down to 3D. Additionally, we discuss how our results can be extended to higher dimensions. \n\nIntroduction: Supersymmetric field theories have been extensively explored in recent decades due to their remarkable characteristics, including unitarity and renormalizability. A key aspect of supersymmetric theories is the existence of fermionic partners corresponding to bosonic degrees of freedom, which possess opposite statistics. These new entities lead to additional symmetries known as supersymmetries. It has been established that all known fundamental interactions, including gravity, can be framed within the context of supersymmetric quantum mechanics. In recent years, there has been a resurgence of interest in supersymmetric field theories, largely driven by advancements in string and M-theory, where they arise naturally in various brane setups. Furthermore, several intriguing phenomena observed at high energies find more natural explanations within supersymmetric extensions of the Standard Model. For example, supersymmetry provides an elegant solution to the hierarchy problem and offers insights into the nature of dark matter. The simplest supersymmetric extension of the Standard Model introduces only one additional spin-1/2 particle—the gravitino. However, more complex versions involving multiple spin-1/2 fields also exist. A particularly significant category of supersymmetric theories is centered around extended supersymmetry, which includes N = 2 supersymmetry that emerges in M-theory compactifications on Calabi-Yau manifolds and its further extension to N = 4. Additionally, an interesting case of N = 1 supersymmetry arises when D-branes wrap around cycles of internal space.",
        "ori-fast-z-score": 2.2011272658140597,
        "water-fast-z-score": 8.474929349612067,
        "rewrite-fast-z-score": -1.5787044347526527
    },
    {
        "original_text": "We present new near-infrared (NIR) observations for four Galactic bulge globular clusters: Terzan 5, Lilll1, UKS 1, and Terzan 4 obtained with the Near Infrared Camera and Multi-Object Spectrometer (NICMOS). The data were taken in two filters F160W and F222M during three orbits each at the Hubble Space Telescope (HST), as part of program GO-10775. We use these NIR images to derive accurate distances to all four clusters by comparing their observed magnitudes with those predicted using theoretical isochrones. Our results are consistent within uncertainties with previous distance estimates derived from optical photometric studies. For Terzan 5 we find d = 8.2 ± 0.3 kpc; for Liller 1: d = 7.7 ± 0.4 kpc; for UKS 1: d = 6.8 ± 0.5 kpc; and for Terzan 4: d = 9.0 ± 0.6 kpc.",
        "watermark_text": "We report new near - infrared ( NIR ) observations for four Galactic bulge globular complexes : Terzan 5 , Lilll1 , UKS 1 , and Terzan 4 obtained with the Near Infrared Camera and Multi - Object Spectrometer ( NICMOS ) . The data were took in two filters F160W and F222M during three orbits each at the Hubble Space Telescope ( HST ) , as part of series GO - 10775 .We use these NIR observations to derive exact distances to all four clusters by testing their observed magnitudes with those predicted using theoretical isochrones . Our results are compatible within uncertainties with previous diameter calculations derived from optical photometric studies .For Terzan 5 we find d = 8.2 ± 0.3 kpc; for Liller 1: d = 7.7 ± 0.4 kpc; for UKS 1: d = 6.8 ± 0.5 kpc; and for Terzan 4: d = 9.0 ± 0.6 kpc.",
        "rewrite_text": "We present new near-infrared (NIR) observations for four globular clusters in the Galactic bulge: Terzan 5, Liller 1, UKS 1, and Terzan 4, which were acquired using the Near Infrared Camera and Multi-Object Spectrometer (NICMOS). The data were collected in two filters, F160W and F222M, during three orbital sessions on the Hubble Space Telescope (HST) as part of program GO-10775. Using these NIR observations, we determine precise distances for all four clusters by comparing their observed magnitudes to those predicted by theoretical isochrones. Our findings are consistent within the uncertainties with previous distance estimates obtained from optical photometry. The determined distances are: Terzan 5 at d = 8.2 ± 0.3 kpc, Liller 1 at d = 7.7 ± 0.4 kpc, UKS 1 at d = 6.8 ± 0.5 kpc, and Terzan 4 at d = 9.0 ± 0.6 kpc.",
        "ori-fast-z-score": 1.6666666666666667,
        "water-fast-z-score": 4.666666666666667,
        "rewrite-fast-z-score": 2.0
    },
    {
        "original_text": "We present new near-infrared (NIR) observations for the radio-loud elliptical galaxy NGC 4261, obtained with the Subaru telescope. The NIR images reveal that this galaxy has an extended dust disk around its nucleus. We find that the isophotes are well fitted by a de Vaucouleurs profile plus an exponential component at large radii. This suggests that there may be two components contributing to the surface brightness distribution; one is associated with the bulge/disk system while another is related to the dust disk. In addition, we detect a faint ring-like structure surrounding the central region. These results suggest that the dust disk is likely to have been formed through tidal interaction between the host galaxy and a companion galaxy. Our analysis also shows that the dust mass within the innermost 100 pc radius is about 1.5 x 10^6 M_sol. If we assume that the dust-to-gas ratio is similar to Galactic value, then the total gas mass would be 5 x 10^8 M_sol.",
        "watermark_text": "We report new near - infrared ( NIR ) observations for the radio - loud elliptical galaxy NGC 4261 , obtained with the Subaru observatory . The NIR observations indicate that this star has an extended dust disk around its core .We see that the isophotes are better fitted by a de Vaucouleurs profile plus an exponential component at large radii . This implies that there may be two variables contributing to the surface brightness distribution ; one is associated with the bulge / disk system while another is related to the dust disk .In addition , we find a weak ring - like structure surrounding the main region . These data suggest that the dust disk is probably to have been formed through tidal association between the host star and a companion galaxy .Our study also shows that the dust mass within the innermost 100 pc radius is about 1 . 5 x 10 ^ 6 M _ sol . If we suppose that the dust - to - gas ratio is identical to Galactic value , then the total gas mass would be 5 x 10 ^ 8 M _ sol .",
        "rewrite_text": "We present new near-infrared (NIR) observations of the radio-loud elliptical galaxy NGC 4261, obtained using the Subaru Observatory. These NIR observations reveal an extended dust disk surrounding the core of the galaxy. Analysis of the isophotes indicates that they are better described by a combination of a de Vaucouleurs profile and an exponential component at larger radii. This suggests that two components contribute to the surface brightness distribution: one linked to the bulge/disk system and the other associated with the dust disk. Additionally, we observe a faint ring-like structure encircling the central region. Our findings imply that the dust disk likely formed through tidal interactions between the host galaxy and a companion. The dust mass within the inner 100 parsecs is estimated to be approximately 1.5 x 10^6 M⊙. Assuming the dust-to-gas ratio is comparable to that of the Milky Way, the total gas mass would be around 5 x 10^8 M⊙.",
        "ori-fast-z-score": 1.2874526191574363,
        "water-fast-z-score": 6.4372630957871815,
        "rewrite-fast-z-score": 2.7688746209726918
    },
    {
        "original_text": "We present the results of our numerical simulations of accretion disk annuli in which radiation pressure is comparable to gas pressure, but not dominant.  We find that for such disks there are two distinct regimes depending on whether or not the luminosity is dominated by advection (i.e., Ladv/Lvisc ≫ 1). In one regime we find that the temperature profile has a power-law form T ∝ r^{-(3/2)}, while in another it follows a more complicated dependence on radius. The latter case occurs when the luminosity is dominated either by viscous dissipation or by advection. For both cases, however, the radial velocity profiles have similar shapes. Finally, we show how these results can be used to explain observed properties of X-ray binaries. Subject headings: Black holes -accretion disks -X-ray binaries: general -Accretion, accretion disks",
        "watermark_text": "We present the results of our numerical simulations of accretion cone annuli in which radiation volume is analogous to liquid temperature , but not dominant . We see that for such disks there are two different regimes depending on whether or not the luminosity is dominated by advection ( i . e . , Ladv / Lvisc [UNK] 1 ) .In one regime we find that the temperature profile has a power - law form T [UNK] r ^ { - ( 3 / 2 ) } , while in another it takes a more complicated dependence on radius . The latter example happens when the luminosity is dominated either by viscous dissipation or by advection .For both cases , however , the radial speed profiles have parallel patterns . Finally , we show how these results can be used to explain observed properties of X - ray binaries .Subject headings : Black holes - accretion disks - X - ray binaries : general - Accretion , accretion disks",
        "rewrite_text": "We present the findings from our numerical simulations of accretion cone annuli, where the radiation volume behaves similarly to liquid temperature, although it does not play a dominant role. Our results indicate that there are two distinct regimes based on whether the luminosity is primarily influenced by advection (i.e., when Ladv / Lvisc is significantly greater than 1). In one regime, we observe that the temperature profile follows a power-law relationship, represented as T ∝ r^(-3/2). In contrast, the other regime exhibits a more complex dependence on the radius, occurring when luminosity is predominantly governed by either viscous dissipation or advection. Despite these differences, both cases reveal similar patterns in the radial speed profiles. Ultimately, we demonstrate how these findings can be applied to elucidate the observed characteristics of X-ray binaries. Key topics include black holes, accretion disks, and general aspects of X-ray binaries and accretion mechanisms.",
        "ori-fast-z-score": -0.2773500981126146,
        "water-fast-z-score": 2.6605321596532185,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We present new observations of the molecular gas in the central region of the nearby galaxy NGC 891, obtained with the IRAM 30m telescope at 1mm and 3mm wavelengths. The data reveal an extended distribution of dense (n(H2) ~ 104 cm-3), warm (T~50K) molecular gas that is associated with the optical disk of this edge-on spiral galaxy. We find evidence for two distinct components to the molecular gas distribution; one component follows closely the dust lane seen in visible light images while another component extends out into the surrounding intergalactic medium. This latter component has been detected previously by other authors but our higher resolution data allow us to resolve it into individual clouds. In addition we detect several compact sources within the galactic plane which are likely to be young star forming regions. These results suggest that there may exist a significant reservoir of molecular material outside the main body of galaxies such as NGC 891.",
        "watermark_text": "We present new images of the molecular gas in the central region of the nearby galaxy NGC 891 , obtained with the IRAM 30m telescope at 1mm and 3mm wavelengths . The data reveal an extended distribution of dense ( n ( H2 ) ~ 104 mm - 3 ) , warm ( T ~ 50K ) molecular dust that is associated with the optical disk of this edge - on spiral galaxy .We see evidence for two different components to the molecular gas distribution ; one element follows tightly the dust track seen in apparent light photographs while another component moves out into the nearby intergalactic medium . This latter component has been detected earlier by other researchers but our higher resolution data enable us to separate it into single clouds .In addition we locate many compact sources within the galactic plane which are likely to be young galaxy producing regions . These data suggest that there may contain a substantial pool of molecular matter outside the main bodies of stars such as NGC 891 .",
        "rewrite_text": "We present new images of the molecular gas in the central region of the nearby galaxy NGC 891, captured using the IRAM 30m telescope at 1mm and 3mm wavelengths. Our data reveals an extensive distribution of dense (n(H2) ~ 10^4 mm^-3), warm (T ~ 50K) molecular dust associated with the optical disk of this edge-on spiral galaxy. We identify two distinct components within the molecular gas distribution; one tightly follows the dust track observed in optical photographs, while the other extends into the surrounding intergalactic medium. Although this latter component has been previously detected by others, our higher-resolution images allow us to resolve it into individual clouds. Additionally, we identify several compact sources within the galactic plane, likely representing regions of active galactic star formation. This data indicates a significant reservoir of molecular matter exists beyond the main stellar bodies of NGC 891.",
        "ori-fast-z-score": -1.6666666666666667,
        "water-fast-z-score": 6.260990336999411,
        "rewrite-fast-z-score": 1.2535663410560174
    },
    {
        "original_text": "We show that the problem of approximating Nash equilibria in two-player zero-sum entangled games is NP-hard, even if one restricts attention to pure strategies and exact equilibria.  We also prove an analogous result for mixed-strategy equilibria. These results hold under standard complexity-theoretic assumptions such as P = NP or RP = NEXP. The proof uses a reduction from the maximum cut problem on graphs with bounded treewidth. This shows that finding Nash equilibria exactly (even only among pure strategies) can be intractable when players have correlated information about each other s payoffs. Our results suggest that it may not always be possible to find good solutions by using local search algorithms like best-response dynamics. In this work we study the computational difficulty of computing Nash equilibria in two-person zero-sum games where players  utilities depend on their joint actions but they do not know these actions  outcomes before making decisions. Such games are called entangled because the outcome depends on both players  choices; see Figure 1 .",
        "watermark_text": "We see that the question of approximating Nash equilibria in two - player zero - sum entangled players is NP - hard , even if one restricts focus to pure strategies and exact equilibria . We also prove an analogous result for mixed - strategy equilibria .These results hold under standard complexity - theoretic conditions such as P = NP or RP = NEXP . The proof uses a reduction from the maximum cut question on graphs with bounded treewidth .This shows that finding Nash equilibria precisely ( even only among true schemes ) can be intractable when participants have correlated information about each other s payoffs . Our results show that it could not always be possible to find good answers by using local search methods like first - response dynamics .In this research we study the theoretical problem of computing Nash equilibria in two - person zero - sum games where players utilities depend on their joint actions but they do not understand these actions outcomes before thinking decisions . Such matches are called entangled because the result relies on both participants decisions ; use Figure 1 .",
        "rewrite_text": "We establish that approximating Nash equilibria in two-player zero-sum games with entangled players is NP-hard, even when limiting the analysis to pure strategies and exact equilibria. We also demonstrate a similar result for mixed-strategy equilibria. These findings hold under standard complexity-theoretic assumptions, such as P = NP or RP = NEXP. Our proof employs a reduction from the maximum cut problem on graphs with bounded treewidth, highlighting that precisely determining Nash equilibria (even with genuine payoff schemes) can be intractable when players possess correlated information regarding each other's payoffs. Our findings suggest that local search methods, such as first-response dynamics, may not always yield satisfactory results. In this study, we examine the theoretical challenge of computing Nash equilibria in two-person zero-sum games where players' utilities are influenced by their joint actions, yet they lack knowledge of the outcomes of these actions prior to making decisions. Such matches are termed entangled, as their results depend on the decisions made by both participants; refer to Figure 1.",
        "ori-fast-z-score": 0.6708203932499369,
        "water-fast-z-score": 5.813776741499453,
        "rewrite-fast-z-score": 1.5275252316519468
    },
    {
        "original_text": "We present results for two-flavor lattice QCD with Wilson fermions at pion masses down to 135 MeV, using an improved staggered quark action as input for the determination of the low-energy constants (LECs) entering the effective theory describing the lightest pseudoscalar mesons. We use the so-called epsilon regime where we can perform simulations close to the physical point without being affected by finite volume effects or excited state contamination. The LECs are determined simultaneously with the decay constant fK  ̄and the kaon B-parameterB K . In order to obtain these quantities on the same footing, we employ the method proposed in Ref.  Phys. Rev. D 87, 074010  which allows us to determine both observables directly from the correlation functions measured on our lattices. Our final values read fK = 156(3)(5)MeV , BK = 1.55(4)(6) , \nwhere the first error is statistical and the second one systematic. These results agree well within errors with those obtained previously in other approaches such as continuum extrapolations based on ChPT or phenomenological determinations.",
        "watermark_text": "We report findings for two - flavor lattice QCD with Wilson fermions at pion masses down to 135 MeV , using an modified staggered quark operation as input for the determination of the small - energy constants ( LECs ) entering the effective theory representing the lightest pseudoscalar mesons . We use the so - called epsilon regime where we can conduct simulations nearly to the physical point without being affected by finite quantity effects or excited state contamination .The LECs are determined simultaneously with the decay variable fK [UNK] the kaon B - parameterB K . In order to obtain these quantities on the same footing , we utilize the method established in Ref .Phys.Rev.D 87 , 074010 which allows us to predict both observables directly from the correlation functions measured on our lattices . Our last estimates read fK = 156 ( 3 ) ( 5 ) MeV , BK = 1 . 55 ( 4 ) ( 6 ) , where the first error is empirical and the second one systematic .These conclusions agree well within errors with those achieved prior in other methods such as continuum extrapolations based on ChPT or phenomenological determinations .",
        "rewrite_text": "We present our findings from a two-flavor lattice QCD study utilizing Wilson fermions with pion masses as low as 135 MeV. Our approach incorporates a modified staggered quark operation to determine the low-energy constants (LECs) relevant to the effective theory describing the lightest pseudoscalar mesons. We operate within the so-called epsilon regime, which enables simulations that approach the physical point while minimizing the impacts of finite volume effects and excited state contamination. The LECs are calculated concurrently with the decay constant \\( f_K \\) and the kaon B-parameter \\( B_K \\). To ensure consistency in obtaining these quantities, we apply the methodology outlined in Phys. Rev. D 87, 074010, which allows us to derive both observables directly from the correlation functions obtained from our lattice simulations. Our final results are \\( f_K = 156(3)(5) \\) MeV and \\( B_K = 1.55(4)(6) \\), where the first error reflects statistical uncertainty and the second indicates systematic uncertainty. These results are in good agreement with previous estimates obtained through other methodologies, such as continuum extrapolations based on Chiral Perturbation Theory (ChPT) and phenomenological analyses.",
        "ori-fast-z-score": 0.12403473458920847,
        "water-fast-z-score": 4.341215710622296,
        "rewrite-fast-z-score": 0.46499055497527714
    },
    {
        "original_text": "We study the critical behavior of the 3D RFIM with Gaussian distributed disorder by means of Monte Carlo simulations and finite-size scaling analysis. We find that the system undergoes a continuous phase transition at zero temperature, which is characterized by an infinite correlation length but no divergent susceptibility. The results are compared to those obtained for the pure 3D Ising model as well as other models with quenched disorder. In particular we show how our findings can be understood within the framework of the droplet picture. \nPACS numbers: 64.60.Cn, 64.60.J-, 64.60.Nz \nI. INTRODUCTORY REMARkS\nThe Random Field Ising Model (RFIM) has been introduced more than 50 years ago  1  . It describes a ferromagnetic material where each spin interacts only with its nearest neighbors via exchange interactions J ij , while it also feels an external magnetic field h i randomly oriented on different sites  2  .\nIn recent years there have been many studies devoted to this problem both experimentally  3  -  6  and theoretically  7  -  12  . This interest was triggered mainly by the fact that the RFIM shares some features with real systems such as diluted antiferromagnets or spin-glasses  13  -  15  . For example, the presence of quenched disorder leads to frustration effects  16  similar to those observed in spin-glass materials  17  . Moreover, the RFIM displays a rich variety of phases depending on the strength of the applied magnetic field  18  . At low fields one finds a paramagnetic phase, whereas above a certain threshold value H c = O(J), the spins align along the direction of the local magnetic field leading to a ferromagnetic state  19  . Finally, if the magnitude of the external field exceeds another threshold value H t > H c , the magnetization becomes discontinuous  20  . These three regimes are separated by two second-order transitions occurring at T c1 < 0 and T c2 > 0  21  . However, despite these analogies between the RFIM and experimental systems  22  , the exact nature of the phase diagram remains controversial  23  .",
        "watermark_text": "We research the significant behavior of the 3D RFIM with Gaussian distributed disorder by means of Monte Carlo simulations and finite - length scaling processing . We see that the system undergoes a continuous phase shift at zero temperature , which is characterized by an endless correlation length but no divergent susceptibility .The results are compared to those achieved for the pure 3D Ising model as well as other models with quenched disease . In particular we show how our findings can be understood within the framework of the droplet picture .PACS codes : 64 . 60 . Cn , 64 . 60 . J - , 64 . 60 . Nz I . INTRODUCTORY REMARkS The Random Field Ising Model ( RFIM ) has been proposed more than 50 centuries earlier 1 .It describes a ferromagnetic material where each spin interacts only with its closest neighbors via transfer interactions J ij , while it also feels an external magnetic force h i randomly oriented on various places 2 . In recent seasons there have been many research devoted to this question both experimentally 3 - 6 and theoretically 7 - 12 .This interest was sparked mainly by the fact that the RFIM shares some features with real systems such as diluted antiferromagnets or spin - glasses 13 - 15 . For instance , the presence of quenched instability leads to frustration effects 16 comparable to those observed in spinning - glass materials 17 .Moreover , the RFIM displays a rich multitude of components varying on the strength of the applied magnetic force 18 . At small fields one gets a paramagnetic phase , whereas above a certain threshold factor H c = O ( J ) , the spins align along the direction of the local magnetic force leading to a ferromagnetic state 19 .Finally , if the magnitude of the external field exceeds another threshold quantity H t > H c , the magnetization becomes discontinuous 20 . These three regimes are split by two second - order transitions happening at T c1 < 0 and T c2 > 0 21 .However , despite these analogies between the RFIM and experimental systems 22 , the exact structure of the phase diagram remains disputed 23 .",
        "rewrite_text": "We investigate the behavior of the three-dimensional Random Field Ising Model (RFIM) with Gaussian-distributed disorder using Monte Carlo simulations and finite-length scaling techniques. Our findings indicate that the system experiences a continuous phase transition at zero temperature, characterized by an infinite correlation length, yet without a diverging susceptibility. We compare these results with those obtained from the pure three-dimensional Ising model and other models exhibiting quenched disorder. Notably, we relate our findings to the droplet picture framework. \n\n**PACS codes:** 64.60.Cn, 64.60.J-, 64.60.Nz\n\n**I. INTRODUCTORY REMARKS**  \nThe Random Field Ising Model (RFIM) was introduced more than fifty years ago. It models a ferromagnetic material in which each spin interacts solely with its nearest neighbors through transfer interactions \\( J_{ij} \\) and is subjected to a randomly oriented external magnetic field \\( h_i \\). Over recent years, considerable research has focused on this model, both experimentally and theoretically, reflecting its significance due to the shared characteristics it has with real-world systems, such as diluted antiferromagnets and spin glasses. For example, the presence of quenched disorder leads to frustration effects similar to those found in spin-glass materials. Furthermore, the RFIM reveals a diverse array of behaviors depending on the strength of the external magnetic field: at low fields, the system remains in a paramagnetic phase, but above a critical field strength \\( H_c = O(J) \\), spins align with the local magnetic field, resulting in a ferromagnetic state. Additionally, if the external field exceeds another critical value \\( H_t > H_c \\), the magnetization exhibits a discontinuous behavior. These three regions are separated by two second-order phase transitions occurring at temperatures \\( T_{c1} < 0 \\) and \\( T_{c2} > 0 \\). Despite the resemblances between the RFIM and experimental systems, the precise nature of the phase diagram remains a topic of considerable debate.",
        "ori-fast-z-score": -0.7986208584745025,
        "water-fast-z-score": 7.0164641544562345,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We present the results of cosmological simulations that follow the growth of supermassive black holes (SMBHs) by stochastic gas inflow, including radiative feedback effects on their surroundings. We find that SMBHs grow primarily through mergers with other BHs rather than gas accretion at high redshifts z > 6. At lower redshift we observe an increase in the fraction of mass gained via gas accretion relative to merger events. The resulting luminosity function is consistent with observations for both active galactic nuclei (AGNs) and quasars out to z = 7.5. Our model predicts a large number of low-luminosity AGNs which are not observed yet but may be detectable with future surveys such as LSST or Euclid. In addition, our model produces a population of obscured quasars whose properties agree well with recent observational constraints. Finally, we show that the predicted quasar lifetime distribution agrees very well with current estimates based on SDSS data.",
        "watermark_text": "We present the conclusion of cosmological simulations that follow the development of supermassive black holes ( SMBHs ) by stochastic gas inflow , particularly radiative feedback effects on their environment . We see that SMBHs grow primarily through mergers with other BHs rather than gas accretion at high redshifts z > 6 .At lower redshift we study an increase in the fraction of mass gained via gas accretion compared to merger reactions . The resulting luminosity function is compatible with observations for both active galactic nuclei ( AGNs ) and quasars out to z = 7 . 5 .Our model predicts a large number of low - luminosity AGNs which are not observed yet but might be detectable with current surveys such as LSST or Euclid . In addition , our model generates a population of distorted quasars whose characteristics comply better with recent observational restrictions .Finally , we prove that the expected quasar lifetime spread agrees very best with current estimates based on SDSS information .",
        "rewrite_text": "We present the findings from our cosmological simulations that explore the formation of supermassive black holes (SMBHs) through stochastic gas inflow, with a particular focus on the radiative feedback effects on their surroundings. Our results indicate that at high redshifts (z > 6), SMBHs primarily grow through mergers with other black holes rather than through gas accretion. As we move to lower redshifts, we observe an increase in the proportion of mass acquired via gas accretion relative to merger events. The luminosity function derived from our model aligns with observations of both active galactic nuclei (AGNs) and quasars up to z = 7.5. Additionally, our model predicts a significant number of low-luminosity AGNs that have not yet been detected, but may be identified through current surveys such as LSST or Euclid. Furthermore, we find that our model produces a population of distorted quasars whose properties are more consistent with recent observational constraints. Finally, we demonstrate that the expected variability in quasar lifetimes is well-aligned with current estimates based on SDSS data.",
        "ori-fast-z-score": 0.8819171036881969,
        "water-fast-z-score": 5.75,
        "rewrite-fast-z-score": 1.212678125181665
    },
    {
        "original_text": "We study the effect of confinement on the structure and dynamics of a simple model system, namely an ensemble of N identical particles interacting via repulsive pair potentials confined in a volume V by two parallel impenetrable walls at distance L apart.  We use Monte Carlo simulations to calculate the density profiles for different values of the wall separation L and particle number N . The results show that the density profile is not affected significantly when increasing the wall separation beyond a certain value which depends on both the temperature T and the particle number N .  In addition we find that the self-diffusion coefficient D decreases with decreasing wall separation but increases again if one further reduces the wall separation below some critical value depending on the temperature T .\nThe observed behavior can be explained within the framework of mode-coupling theory (MCT) using a generalized version of MCT developed recently by us  Physica A, vol. 315, no. 1, pp. 39-48, (2003), Physica A, vol. 320, no. 3, pp. 633-646, (2004) .",
        "watermark_text": "We research the impact of confinement on the composition and dynamics of a simple model network , namely an ensemble of N identical particles interacting via repulsive pair potentials restricted in a volume V by two connected impenetrable walls at distance L apart . We use Monte Carlo simulations to estimate the density characteristics for different values of the wall separation L and electron number N .The results show that the density profile is not affected greatly when increasing the wall separation beyond a certain value which depends on both the temperature T and the particle number N . In addition we find that the self - diffusion coefficient D reduces with decreasing wall separation but grows again if one further decreases the wall separation below some significant value depending on the temperature T .The observed behavior can be described within the framework of mode - correlation theory ( MCT ) using a generalized version of MCT created recently by us Physica A , vol . 315 , no .1 , pp . 39 - 48 , ( 2003 ) , Physica A , vol .320 , no . 3 , pp .633-646, (2004) .",
        "rewrite_text": "We investigate how confinement influences the composition and dynamics of a simple model network, specifically an ensemble of N identical particles that interact through repulsive pair potentials and are constrained within a volume V by two connected impenetrable walls separated by a distance L. Using Monte Carlo simulations, we evaluate the density characteristics for varying wall separations L and particle numbers N. Our findings indicate that the density profile remains largely unchanged when the wall separation exceeds a certain threshold, which is dependent on both temperature T and the number of particles N. Additionally, we observe that the self-diffusion coefficient D decreases as the wall separation decreases, but increases again if the wall separation is reduced below a certain significant value that is also temperature-dependent. This behavior can be explained using mode-coupling theory (MCT), employing a generalized version of MCT recently developed by us, as detailed in Physica A, vol. 315, no. 1, pp. 39-48 (2003) and Physica A, vol. 320, no. 3, pp. 633-646 (2004).",
        "ori-fast-z-score": 0.45291081365783825,
        "water-fast-z-score": 4.98201895023622,
        "rewrite-fast-z-score": 0.45291081365783825
    },
    {
        "original_text": "We present the results of three-dimensional MHD simulations that show how magnetic fields can be amplified by shocks in molecular clouds, and lead to the formation of dense filaments with high mass-to-flux ratios. The initial conditions are based on observations of nearby star-forming regions. We find that shock compression leads to an increase in density and temperature at the post-shock region. This causes the gas pressure gradient across the shock front to decrease rapidly as time progresses. As a result, the field lines become more tangled due to turbulent motions induced by the shock wave. In addition, we observe that the magnetic energy is transferred into kinetic energy through Alfvén waves generated behind the shock fronts. Finally, we demonstrate that these processes cause the magnetic flux-to-mass ratio to increase significantly within the shocked region. \n \n Keywords: Magnetic fields, Shocks, Star formation, Turbulence \n \n 1. Introduction \n \n Molecular clouds play important roles in star formation (SF) because they provide the material for stars to form out of. However, it remains unclear what physical mechanisms drive SF inside molecular clouds. One possible mechanism involves supersonic turbulence driven by supernovae explosions or stellar winds (Mac Low & Klessen 2004). Another possibility is that large-scale gravitational collapse may trigger localised fragmentation leading to the formation of dense cores which then evolve into protostars (Larson 1978; Bonnell et al. 1997) . It has been suggested that both scenarios could operate simultaneously during different stages of evolution of molecular clouds (Krumholz 2014). \n \n Recent observational studies have shown that many young massive stars are associated with filamentary structures observed in infrared dust emission maps (André et al. 2010; Peretto et al. 2013 ). These filaments often appear to be aligned along magnetic field directions inferred from polarisation measurements (Chapman et al. 2011) , suggesting that magnetic fields might play an important role in regulating the dynamics of such systems. Indeed, theoretical models suggest that magnetic fields can affect the stability properties of self-gravitating clouds against global collapse (Mouschovias 1976; Tomis",
        "watermark_text": "We present the conclusion of three - dimensional MHD simulations that demonstrate how magnetic waves can be amplified by shocks in molecular clouds , and lead to the formation of dense filaments with high mass - to - flux proportions . The initial conditions are based on observations of nearby star - creating areas .We see that shock compression contributes to an increase in volume and heat at the post - shock zone . This leads the gas pressure slope across the shock front to reduce rapidly as time progresses .As a result , the field lines become more twisted due to chaotic motions created by the shock wave . In addition , we determine that the magnetic energy is transferred into kinetic power through Alfvén currents produced behind the shock fronts .Finally , we prove that these mechanisms create the magnetic flux - to - mass ratio to expand significantly within the shocked region . Keywords : Magnetic fields , Shocks , Star formation , Turbulence 1 .Introduction Molecular clouds play crucial roles in star formation ( SF ) because they provide the material for stars to form out of . However , it remains unsure what physical mechanisms drive SF inside molecular clouds .One potential mechanism involves supersonic turbulence driven by supernovae explosions or stellar winds ( Mac Low & Klessen 2004 ) . Another possibility is that high - scale gravitational failure may generate localised fragmentation leading to the formation of dense cores which then evolve into protostars ( Larson 1978 ; Bonnell et al .1997 ) . It has been proposed that both scenarios could operate simultaneously during various phases of evolved of molecular clouds ( Krumholz 2014 ) .Recent observational investigations have shown that several young massive stars are related with filamentary structures discovered in infrared dust emission images ( André et al . 2010 ; Peretto et al .2013 ) . These filaments often seem to be aligned along magnetic force directions inferred from polarisation observations ( Chapman et al .2011 ) , showing that magnetic waves might play an important role in controlling the dynamics of such systems . Indeed , theoretical theories indicate that magnetic waves can affect the stability properties of self - gravitating clouds against global failure ( Mouschovias 1976 ; Tomis",
        "rewrite_text": "We summarize the findings from our three-dimensional magnetohydrodynamics (MHD) simulations, which illustrate how magnetic waves can be enhanced by shocks within molecular clouds, facilitating the creation of dense filaments characterized by high mass-to-flux ratios. The initial conditions for these simulations are informed by observations of nearby star-forming regions. Our results indicate that shock compression increases both the volume and temperature in the post-shock zone, causing a rapid decrease in the gas pressure gradient across the shock front over time. Consequently, the magnetic field lines become increasingly twisted due to the chaotic motions induced by the shock wave. Furthermore, we find that magnetic energy is converted into kinetic energy through Alfvén currents generated behind the shock fronts. Ultimately, our analysis confirms that these processes significantly enhance the magnetic flux-to-mass ratio in the shocked region.\n\nKeywords: Magnetic fields, Shocks, Star formation, Turbulence.\n\n1. Introduction  \nMolecular clouds are fundamental to the star formation (SF) process, as they supply the necessary material for star creation. However, the physical mechanisms that drive SF within these clouds remain uncertain. One potential mechanism is the presence of supersonic turbulence, which may be triggered by supernova explosions or stellar winds (Mac Low & Klessen 2004). Alternatively, large-scale gravitational instabilities might cause localized fragmentation that leads to the formation of dense cores that can evolve into protostars (Larson 1978; Bonnell et al. 1997). It is posited that both scenarios could function concurrently during different stages of molecular cloud evolution (Krumholz 2014). Recent observational studies have revealed a correlation between several young massive stars and filamentary structures noted in infrared dust emission images (André et al. 2010; Peretto et al. 2013). These filaments frequently appear to align with the directions of magnetic forces inferred from polarization observations (Chapman et al. 2011), suggesting that magnetic waves may significantly influence the dynamics of these systems. Theoretical models indicate that magnetic waves can impact the stability of self-gravitating clouds against global collapse (Mouschovias 1976; Tomisaka 2002).",
        "ori-fast-z-score": 0.07602859212697055,
        "water-fast-z-score": 7.732600044504815,
        "rewrite-fast-z-score": 1.934558081335342
    },
    {
        "original_text": "We report near-infrared coronagraphic observations of the young binary system UY Aurigae (=V773 Tau) obtained with the Subaru Telescope in December 2005 and January 2006, using the newly installed HiCIAO instrument equipped with an occulting mask. The data were reduced by subtracting dark frames and flat fields to remove detector biases and pixel-to-pixel variations respectively. We then applied aperture photometry on each frame after masking out bad pixels and cosmic rays. Finally we averaged all the individual frames together for each filter bandpass. Our results show that there is no significant difference between our two epochs of observation within the uncertainties. In addition, we find that the flux ratio between the primary star and its companion varies significantly depending upon which filter was used during the observations. This suggests that the spectral energy distribution of UY Aur may be changing over time as it evolves towards the main sequence. \n \n Keywords: Young stars",
        "watermark_text": "We report near - infrared coronagraphic observations of the young binary system UY Aurigae ( = V773 Tau ) obtained with the Subaru Telescope in December 2005 and January 2006 , using the newly installed HiCIAO object fitted with an occulting mask . The data were reduced by subtracting bright frames and flat fields to remove detector biases and pixel - to - pixel differences respectively .We then added aperture photometry on each frame after masking out bad pixels and cosmic rays . Finally we combined all the different images together for each filter bandpass .Our results show that there is no considerable difference between our two epochs of observation within the uncertainties . In addition , we find that the flux ratio between the primary star and its companion vary significantly depending upon which filter was used during the surveys .This implies that the spectral power distribution of UY Aur may be changing over time as it evolves towards the main sequence . Keywords : Young stars",
        "rewrite_text": "We present near-infrared coronagraphic observations of the young binary system UY Aurigae (V773 Tau), collected with the Subaru Telescope in December 2005 and January 2006, utilizing the newly installed HiCIAO equipped with an occulting mask. The data were processed by subtracting bright frames and applying flat field corrections to eliminate detector biases and pixel-to-pixel variations, respectively. We performed aperture photometry on each frame after excluding bad pixels and cosmic ray impacts. Finally, we combined the various images for each filter bandpass. Our findings indicate no significant differences between the two observation epochs within the uncertainties. Furthermore, we observed that the flux ratio between the primary star and its companion varies considerably based on the filter used during the observations. This variation suggests that the spectral power distribution of UY Aur may be evolving over time as it approaches the main sequence. Keywords: Young stars.",
        "ori-fast-z-score": 1.270001270001905,
        "water-fast-z-score": 4.993438317382943,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We report on our analysis of the Suzaku observation of the z = 1.55 quasar, RBS 315 (RA=00h45m53.6s; DEC=-36d19 59.6 ). The source is detected with an average 2-10 keV flux of 4 x 10^-13 erg cm-2 s-1 corresponding to a luminosity of 3 x 10^44 erg s-1 at this redshift. We find that the spectrum can be well fitted by a power law model modified by Galactic absorption plus reflection component using pexrav model in XSPEC. This gives photon index Γ=1.9 +0.2 -0.1 , reflection fraction f=0.7 +1.0 -1.3 . The observed 0.5-7 keV band luminosity is found to be 5x10^43 erg/sec which corresponds to Eddington ratio L/L edd =0.01-0.03 assuming black hole mass M BH ~10 9 M sun .",
        "watermark_text": "We report on our analysis of the Suzaku observation of the z = 1 . 55 quasar , RBS 315 ( RA = 00h45m53 . 6s ; DEC = - 36d19 59 . 6 ) . The source is detected with an estimated 2 - 10 keV flux of 4 x 10 ^ - 13 erg centimetres - 2 s - 1 resulting to a luminosity of 3 x 10 ^ 44 erg s - 1 at this redshift .We see that the spectrum can be well fitted by a power law theory derived by Galactic absorption plus reflection factor used pexrav system in XSPEC . This gives photon index Γ = 1 . 9 + 0 . 2 - 0 . 1 , absorption proportion f = 0 . 7 + 1 . 0 - 1 . 3 .The observed 0 . 5 - 7 keV band luminosity is found to be 5x10 ^ 43 erg / sec which equals to Eddington ratio L / L edd = 0 . 01 - 0 . 03 assuming black hole weight M BH ~ 10 9 M sun .",
        "rewrite_text": "We present our analysis of the Suzaku observation of the quasar RBS 315, located at a redshift of z = 1.55 (RA = 00h45m53.6s; DEC = -36d19m59.6s). The source was detected with an estimated flux in the 2-10 keV range of 4 x 10^-13 erg cm^-2 s^-1, translating to a luminosity of 3 x 10^44 erg s^-1 at this redshift. The spectrum is well-represented by a power-law model, incorporating Galactic absorption and using the pexrav model in XSPEC for reflection. This analysis yields a photon index of Γ = 1.9 +0.2 -0.1 and an absorption fraction of f = 0.7 +1.0 -1.3. Additionally, we find that the observed luminosity in the 0.5-7 keV band is 5 x 10^43 erg/s, which corresponds to an Eddington ratio of L / L_edd = 0.01 - 0.03, assuming a black hole mass of M_BH ~ 10^9 M☉.",
        "ori-fast-z-score": -0.31622776601683794,
        "water-fast-z-score": 2.846049894151541,
        "rewrite-fast-z-score": -0.9486832980505138
    },
    {
        "original_text": "We propose an information processing system based on spin wave bus and inductive coupling between circuits. The proposed circuit is composed of two types of elements, the first one being a conventional semiconductor device which can be used as a logic gate or memory cell, while the second element consists in a magnetic insulator layer sandwiched by two ferromagnetic layers that are connected to each other via tunneling magnetoresistance (TMR) effect. We show how this structure allows us to perform both logic operations and data transmission using spin waves. Finally we discuss some possible applications of our proposal such as quantum computing architectures and neuromorphic systems. This article is available from: http://arxiv.org/abs/1601.00571. Inductively coupled circuits have been widely studied recently because they offer several advantages over their classical counterparts  1  . For example, these devices allow high speed operation  2  , low power consumption  3  , and reduced crosstalk  4  .\nIn addition, it has been shown theoretically  5  and experimentally  6  that inductive coupling could also lead to new functionalities like nonlocal gates  7, 8  and entanglement generation  9  . However, most of the studies performed so far were focused only on electronic components  10  . Here, we consider instead spin-wave-based circuits  11  where information is coded into propagating spin-waves  12  . These spin waves can be generated electrically  13  or optically  14  and propagate through different media  15  including semiconductors  16  , metals  17  , and insulators  18  . They can even travel across vacuum  19  . Therefore, spin waves provide a promising alternative to electrons  20  since they do not suffer from Coulomb interactions  21  nor scattering  22  . Moreover, spin waves can carry much more information than electrons  23  due to their higher density  24  .",
        "watermark_text": "We suggest an information processing network based on spin wave bus and inductive coupling between electronics . The proposed system is composed of two forms of elements , the first one being a traditional semiconductor device which can be used as a logic gate or memory cell , while the second element consists in a magnetic insulator layer sandwiched by two ferromagnetic layers that are connected to each other via tunneling magnetoresistance ( TMR ) effect .We see how this form enables us to conduct both logic operations and information transmission using spinning waves . Finally we explain some possible users of our proposal such as particle computing architectures and neuromorphic networks .This section is accessible from : www : / / arxiv . org / abs / 1601 . 00571 . Inductively coupled devices have been widely examined lately because they give numerous benefits over their classical counterparts 1 .For instance , these systems allow large speed operation 2 , low power consumption 3 , and low crosstalk 4 . In addition , it has been shown theoretically 5 and experimentally 6 that inductive coupling could also lead to novel functionalities like nonlocal gates 7 , 8 and entanglement generation 9 .However , most of the experiments conducted so far were focused only on electronic elements 10 . Here , we find instead spin - wave - based circuits 11 where information is coded into propagating spin - pulses 12 .These spin signals can be induced electrically 13 or optically 14 and propagate through different materials 15 including semiconductors 16 , metals 17 , and insulators 18 . They can even travel across vacuum 19 .Therefore , spin beams provide a popular alternative to ions 20 since they do not suffer from Coulomb bonding 21 nor scattering 22 . Moreover , spin beams can carry far more information than electrons 23 thanks to their higher mobility 24 .",
        "rewrite_text": "We propose an information processing network that utilizes a spin wave bus and inductive coupling between electronic components. The system consists of two types of elements: the first is a conventional semiconductor device, which serves as either a logic gate or a memory cell, and the second consists of a magnetic insulator layer sandwiched between two ferromagnetic layers that are connected through the tunneling magnetoresistance (TMR) effect. This design allows for both logic operations and information transmission via spin waves. We also discuss potential applications for our concept, including particle computing architectures and neuromorphic networks. Further details can be found at: www: // arxiv. org / abs / 1601 . 00571. Recent studies have extensively explored inductively coupled devices, as they offer several advantages over traditional systems, including higher operational speeds, reduced power consumption, and minimized crosstalk. Additionally, theoretical and experimental work has suggested that inductive coupling may enable new functionalities, such as nonlocal gates and entanglement generation. However, most existing experiments have focused primarily on electronic elements. In contrast, we investigate spin-wave-based circuits, where information is encoded in propagating spin pulses. These spin signals can be generated either electrically or optically and can propagate through various materials, including semiconductors, metals, and insulators, and even across a vacuum. Consequently, spin waves present a viable alternative to ions, as they are not affected by Coulomb interactions or scattering. Furthermore, spin waves have the potential to transmit significantly more information than electrons due to their enhanced mobility.",
        "ori-fast-z-score": -0.08873565094161139,
        "water-fast-z-score": 8.540373791358551,
        "rewrite-fast-z-score": 0.811502671200689
    },
    {
        "original_text": "The relationship between Einstein s work in physics, his personal life, and the cultural milieu of the time is examined through an analysis of his correspondence with Max Born (1882-1970). The letters reveal that Einstein was interested not only in science but also in literature, music, theatre, and other forms of culture. In particular, they show how he came to appreciate modernist artists such as Wassily Wassilyevich Kandinsky, Paul Klee, and Pablo Picasso. They also provide insight into Einstein s attitude towards society at large during this period. This article examines the relationship between Einstein s work on relativity theory, his private life, and the cultural context of the times by analyzing his correspondence with Max Born . It shows that Einstein was interested not just in science but also in various forms of culture including literature, music, theater, and painting. Particularly important are his letters about modernist artists like Wassily Wassilyevicth Kandinsky , Paul Klee , and Pablo Picasso . These documents shed light on Einstein  s attitude toward society at large during these years .",
        "watermark_text": "The relationship between Einstein s study in science , his personal life , and the cultural milieu of the period is investigated through an assessment of his letters with Max Born ( 1882 - 1970 ) . The letters prove that Einstein was fascinated not only in science but also in literature , music , theatre , and other types of literature .In particular , they show how he came to admire modernist artists such as Wassily Wassilyevich Kandinsky , Paul Klee , and Pablo Picasso . They especially offer insight into Einstein s approach towards society at large during this era .This page discusses the relationship between Einstein s study on relativity hypothesis , his private life , and the cultural context of the days by analyzing his letters with Max Born . It demonstrates that Einstein was fascinated not just in science but also in different kinds of literature namely writers , music , theater , and painting .Particularly interesting are his letters about modernist artists like Wassily Wassilyevicth Kandinsky , Paul Klee , and Pablo Picasso . These documents cast light on Einstein s feelings toward people at large during these days .",
        "rewrite_text": "The exploration of the connection between Einstein's scientific inquiry, his personal life, and the cultural environment of his time is undertaken through an examination of his correspondence with Max Born (1882-1970). These letters reveal that Einstein's interests extended beyond science to include literature, music, theater, and various forms of art. Notably, they illustrate his admiration for modernist artists such as Wassily Kandinsky, Paul Klee, and Pablo Picasso. Additionally, the correspondence provides valuable insight into Einstein's perspectives on society during this period. This analysis delves into the interplay between Einstein's work on the theory of relativity, his private life, and the cultural backdrop of his era, highlighting his diverse fascinations and sentiments towards the broader human experience.",
        "ori-fast-z-score": -2.1514114968019085,
        "water-fast-z-score": 5.498051602938211,
        "rewrite-fast-z-score": -0.9801960588196068
    },
    {
        "original_text": "We present an improved version of our previous calculation for the nuclear matter properties and the single-particle energies in spherical nuclei based on the covariant density functional theory with the tensor terms included. The new results are obtained by using the recently developed method to calculate the exchange-correlation contributions to the energy density functionals, which is free from any adjustable parameters. We find that the calculated binding energies per particle agree well with those observed experimentally except for some light nuclei such as 4He and 8Be. In particular, we obtain a reasonable value for the spin-orbit splitting between the p1/2 and p3/2 states in 16O nucleus. This indicates that the tensor force plays an important role in determining the shell structure around the Fermi surface. It should be noted here that this result has been achieved without introducing any additional parameter into the original formalisms proposed previously. \n \n Keywords: Tensor force, Energy density functional",
        "watermark_text": "We present an updated form of our previous measurement for the atomic matter properties and the single - nucleus energies in spherical nuclei using on the covariant density functional theory with the tensor terms included . The revised conclusions are derived by using the recently advanced method to estimate the transfer - correlation contributions to the power density functionals , which is free from any adjustable parameters .We see that the derived binding temperatures per particle comply better with those observed experimentally except for some light nuclei such as 4He and 8Be . In particular , we obtain a suitable value for the spin - orbit dividing between the p1 / 2 and p3 / 2 states in 16O nucleus .This implies that the tensor force plays an important role in determining the shell structure around the Fermi boundary . It should be mentioned here that this consequence has been achieved without removing any additional parameter into the previous formalisms proposed earlier .Keywords : Tensor force , Energy density functional",
        "rewrite_text": "We present an updated version of our previous measurements regarding the properties of atomic matter and the energies of single nuclei in spherical configurations, utilizing covariant density functional theory that incorporates tensor terms. Our revised conclusions stem from an advanced method for estimating the contributions of transfer correlations to power density functionals, which is free from adjustable parameters. Notably, the binding temperatures per particle we calculated align more closely with experimental observations, with the exception of certain light nuclei, such as 4He and 8Be. Specifically, we determined an appropriate value for the spin-orbit splitting between the p1/2 and p3/2 states in the 16O nucleus. This finding suggests that the tensor force plays a crucial role in shaping the shell structure near the Fermi surface. Importantly, these results were obtained without introducing any additional parameters into the prior theoretical frameworks.  \nKeywords: Tensor force, Energy density functional.",
        "ori-fast-z-score": -1.0392304845413263,
        "water-fast-z-score": 5.427092530382482,
        "rewrite-fast-z-score": 0.819288030372914
    },
    {
        "original_text": "We present an algorithm for solving the Graph Isomorphism Problem (GIP) based on Quantum Walks and Grover s search algorithm. The proposed method is inspired by the classical algorithms that use random walks, but it uses Grover s operator instead of the Hadamard matrix in order to speed up the process. We show how this new technique can be used to solve GIP with high probability when the number of vertices in both graphs are equal or differ at most one unit. Finally we compare our results against other state-of-the-art methods. In recent years there has been growing interest in developing efficient solutions to problems related to computational complexity theory such as the Graph Isomorphism Problem(GIP). This problem consists of determining whether two given graphs are isomorphic or not; i.e., if they have the same structure regardless of their labels. \n \n Classical approaches to solve GIP usually rely on Random Walks techniques combined with some heuristics. However these methods require exponential time in the worst case scenario. On the other hand, Quantum Algorithms provide polynomial-time solutions to many NP-complete problems including GIP. These algorithms exploit the superposition principle which allows them to explore all possible states simultaneously. For example, Shor s Algorithm solves integer factorization in polynomial time while Grover s Search finds any item within a database in quadratic time.",
        "watermark_text": "We present an algorithm for solving the Graph Isomorphism Problem ( GIP ) based on Quantum Walks and Grover s search algorithm . The proposed approach is influenced by the classical techniques that use random walks , but it utilizes Grover s operator rather of the Hadamard vector in order to faster up the process .We see how this new technique can be used to solve GIP with high chance when the number of vertices in both graphs are equal or differ at most one unit . Finally we compare our findings against other state - of - the - art methods .In recent years there has been growing interest in pursuing efficient answers to problems related to computational complexity analysis such as the Graph Isomorphism Problem ( GIP ) . This problem consists of determining whether two given graphs are isomorphic or not ; i . e . , if they have the same structure regardless of their labels .Classical approaches to solve GIP usually relies on Random Walks techniques combined with some heuristics . However these algorithms involve exponential time in the worst case situations .On the other hand , Quantum Algorithms provide polynomial - time solutions to many NP - perfect issues including GIP . These methods incorporate the superposition concept which allows them to examine all possible states simultaneously .For instance , Shor s Algorithm solves integer factorization in polynomial time while Grover s Search finds any element within a database in quadratic time .",
        "rewrite_text": "We introduce a novel algorithm for tackling the Graph Isomorphism Problem (GIP) using Quantum Walks and Grover's search algorithm. Our approach draws inspiration from classical methods that employ random walks, but it innovatively replaces the Hadamard operator with Grover's operator to increase efficiency. This new technique demonstrates a high probability of successfully solving GIP, particularly when the number of vertices in the two graphs is either equal or differs by just one. Additionally, we compare our results with other leading methods in the field. Recently, there has been a heightened interest in finding efficient solutions to computational complexity problems, including GIP, which aims to determine whether two graphs are isomorphic—that is, whether they share the same structure irrespective of their vertex labels. Traditional solutions to GIP typically rely on random walk strategies combined with various heuristics, yet these often lead to exponential time complexity in the worst-case scenarios. In contrast, quantum algorithms can provide polynomial-time solutions for many NP-complete problems, including GIP, leveraging the principle of superposition to explore multiple states simultaneously. For example, Shor's algorithm offers a polynomial-time solution for integer factorization, while Grover's search algorithm can locate an element within a database in quadratic time.",
        "ori-fast-z-score": -0.10050378152592121,
        "water-fast-z-score": 4.975196209154734,
        "rewrite-fast-z-score": 1.2935483472729858
    },
    {
        "original_text": "We study the advantages and disadvantages of composite Higgs models in four dimensions (4D) versus five dimensions (5D). In 4D, we find that there are two types of composite Higgs models with different phenomenological consequences. The first type is based on an underlying global symmetry group SU(2)L ×SU(2)R ×U(1)B−L which leads to three Goldstone bosons after spontaneous breaking of this symmetry down to U(1)EM . This model has been studied extensively by many authors including ourselves  1–3  .\nThe second type is based on an extended gauge symmetry group SU(3)C ×SU(2)L ×U(1)Y ×Z′ where Z′ is a new abelian gauge factor associated with extra spatial dimension  4–6  . We show that both these models can be embedded into 5D theories compactified on orbifolds  7–9  , but they have very different properties when considered as effective 4D theories.",
        "watermark_text": "We research the advantages and disadvantages of composite Higgs systems in four dimensions ( 4D ) vs five dimensions ( 5D ) . In 4D , we find that there are two forms of composite Higgs theories with varying phenomenological consequences .The first class is based on an underlying global symmetry class SU ( 2 ) L ×SU ( 2 ) R ×U ( 1 ) B−L which results to three Goldstone bosons after spontaneous breaking of this symmetry down to U ( 1 ) EM . This theory has been studied frequently by many writers including ourselves 1 – 3 .The second kind is based on an extended gauge symmetry class SU ( 3 ) C ×SU ( 2 ) L ×U ( 1 ) Y ×Z ′ where Z ′ is a new abelian gauge parameter identified with extra spatial dimension 4 – 6 . We see that both these models can be embedded into 5D theories compactified on orbifolds 7 – 9 , but they have very different properties when considered as efficient 4D theories .",
        "rewrite_text": "We investigate the pros and cons of composite Higgs systems in four dimensions (4D) compared to five dimensions (5D). In 4D, we identify two types of composite Higgs theories, each with distinct phenomenological implications. The first type is founded on a global symmetry group, SU(2)L × SU(2)R × U(1)B−L, which leads to the emergence of three Goldstone bosons following the spontaneous breaking of this symmetry down to U(1)EM. This particular theory has been extensively analyzed by various researchers, including ourselves. The second type is based on an extended gauge symmetry SU(3)C × SU(2)L × U(1)Y × Z', where Z' represents a new abelian gauge parameter associated with an extra spatial dimension. We note that both models can be incorporated into 5D theories that are compactified on orbifolds; however, they exhibit significantly different characteristics when examined as effective 4D theories.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.543441112511214,
        "rewrite-fast-z-score": -0.39735970711951313
    },
    {
        "original_text": "We report on new spectroscopic observations of the eclipsing binary system HAT-TR-205-1013, which was discovered by the Hungarian Automated Telescope (HAT) survey for transiting exoplanets. The light curve shows two partial eclipses with an orbital period of 1.8 days. We find that this is most likely caused by reflection effects rather than occultation events due to the presence of a third body. Using our radial velocity measurements we determine the mass function f(m) = 0.0027 ± 0.0007M⊙, where m is the mass of the unseen companion star. Assuming circular orbits, we derive the minimum masses of both components as M1 sin i = 0.84 ± 0.04M⊙ and M2 sin i = 0.16 ± 0.02M⊙. From these values we estimate the radius ratio between the primary and secondary component as q = 0.53 ± 0.06.",
        "watermark_text": "We report on new spectroscopic observations of the eclipsing binary system HAT - TR - 205 - 1013 , which was discovered by the Hungarian Automated Telescope ( HAT ) study for transiting exoplanets . The light curve shows two partial eclipses with an orbital period of 1 . 8 days .We see that this is most likely due by reflection influences rather than occultation processes due to the presence of a third body . Using our radial speed measurements we determine the mass function f ( m ) = 0 . 0027 ± 0 . [UNK] , where m is the mass of the unseen companion star .Assuming circular orbits , we derive the minimum masses of both components as M1 sin i = 0 . 84 ± 0 . [UNK] and M2 sin i = 0 . 16 ± 0 . [UNK] . From these values we estimate the radius ratio between the primary and secondary component as q = 0 . 53 ± 0 . 06 .",
        "rewrite_text": "We present new spectroscopic observations of the eclipsing binary system HAT-TR-205-1013, which was identified through the Hungarian Automated Telescope (HAT) project focused on transiting exoplanets. The light curve reveals two partial eclipses with an orbital period of 1.8 days. Our analysis suggests that these eclipses are primarily influenced by reflection effects rather than occultation processes caused by a third body. From our radial velocity measurements, we calculate the mass function f(m) = 0.0027 ± 0. [UNK], where m represents the mass of the unseen companion star. Assuming circular orbits, we derive the minimum masses of the two components as M1 sin i = 0.84 ± 0. [UNK] and M2 sin i = 0.16 ± 0. [UNK]. Based on these values, we estimate the radius ratio of the primary to secondary component as q = 0.53 ± 0.06.",
        "ori-fast-z-score": 0.6401843996644799,
        "water-fast-z-score": 2.1766269588592317,
        "rewrite-fast-z-score": -1.0327955589886444
    },
    {
        "original_text": "We present the results of our analysis of the infrared properties (3.6-24 microns) of young stellar objects in the nearby star forming region Serpens South using data obtained with the Infrared Array Camera (IRAC; Fazio et al., 2004 ) on board the Spitzer Space Telescope . We have identified a total of 1,082 candidate young stars based upon their mid-infrared colors and luminosities , including 759 previously known members of this cluster . Of these newly discovered sources , we find that only about half are associated with outflows as traced by shocked H 2 emission or radio continuum emission .\nThe majority of the remaining new candidates appear to be deeply embedded protostars which lack significant amounts of circumstellar material . These findings suggest that many of the new candidates may represent an earlier evolutionary stage than those already known within this cloud complex . This is consistent with previous studies suggesting that there exists a large population of low-mass pre-main sequence stars in Serpens South which remain undiscovered due to their youthful ages and/or relatively high levels of extinction .",
        "watermark_text": "We publish the conclusion of our analysis of the infrared properties ( 3 . 6 - 24 microns ) of young stellar bodies in the nearby star producing zone Serpens South using data acquired with the Infrared Array Camera ( IRAC ; Fazio et al . , 2004 ) on board the Spitzer Space Telescope . We have discovered a total of 1 , 082 candidate young stars based upon their mid - infrared colors and luminosities , comprising 759 formerly identified members of this cluster .Of these newly discovered sources , we find that only about half are related with outflows as traced by shocked H 2 emission or radio continuum emission . The majority of the remaining new candidates seem to be highly fused protostars which lack considerable portions of circumstellar material .These studies imply that several of the new candidates might represent an earlier evolutionary stage than those already established within this storm complex . This is consistent with previous research indicating that there exists a large colony of low - weight pre - principal sequence stars in Serpens South which survive undiscovered owing to their youthful ages and / or relatively high levels of extinction .",
        "rewrite_text": "We present the findings of our analysis on the infrared characteristics (3.6 - 24 microns) of young stellar objects in the nearby star-forming region of Serpens South, utilizing data from the Infrared Array Camera (IRAC; Fazio et al., 2004) aboard the Spitzer Space Telescope. Our study has identified a total of 1,082 candidate young stars based on their mid-infrared colors and luminosities, including 759 previously recognized members of this cluster. Of these newly identified sources, approximately half are associated with outflows, as evidenced by shocked H2 emission or radio continuum emission. The majority of the remaining candidates appear to be highly evolved protostars that lack significant circumstellar material. These findings suggest that several of the new candidates may represent an earlier evolutionary phase than those already known within this complex. This aligns with prior research indicating a significant population of low-mass pre-main sequence stars in Serpens South, many of which remain unobserved due to their youth and/or the high levels of extinction they experience.",
        "ori-fast-z-score": -0.21320071635561041,
        "water-fast-z-score": 5.822969752985674,
        "rewrite-fast-z-score": -0.44172610429938614
    },
    {
        "original_text": "We study energy density-flux correlations for a free scalar field in 1+1 dimensions, both at finite temperature T and in vacuum (T=0). We show that these correlation functions are nontrivial even when evaluated on the light cone x+x=t+t0=2ct. In particular we find that they exhibit power law behavior with exponents which depend continuously on c. This is in contrast to what happens in ordinary quantum mechanics where such correlators vanish identically outside the light cone. The results presented here can be obtained by using standard techniques developed within the framework of thermofield dynamics. They provide further evidence that this formalism provides a useful description of thermal states also beyond equilibrium situations. Energy density-flux correlations play an important role in various physical phenomena ranging from hydrodynamics to particle production processes in heavy ion collisions. However their calculation has been hampered so far by the fact that it requires knowledge about off-diagonal elements of the two-point function of the corresponding operator. Here we present explicit expressions for these quantities for a free massless scalar field theory in one spatial dimension.",
        "watermark_text": "We work energy density - flux correlations for a free scalar field in 1 + 1 dimensions , both at finite temperature T and in vacuum ( T = 0 ) . We see that these correlation functions are nontrivial even when evaluated on the light cone x + x = t + t0 = 2ct .In particular we find that they undergo force law behavior with exponents which depend continuously on c . This is in comparison to what happens in ordinary quantum mechanics where such correlators vanish identically outside the light cone . The results presented here can be obtained by using conventional methods developed within the framework of thermofield dynamics .They offer further evidence that this formalism gives a helpful description of thermal states especially beyond equilibrium environments . Energy density - flux correlations serve an important role in different mechanical phenomena ranging from hydrodynamics to particle production mechanisms in heavy atom collisions .However their calculation has been hampered so far by the fact that it requires knowledge about off - diagonal elements of the two - point integral of the associated operator . Here we present explicit expressions for these quantities for a free massless scalar field model in one spatial dimension .",
        "rewrite_text": "We investigate energy density-flux correlations for a free scalar field in (1+1) dimensions, considering both finite temperature \\( T \\) and vacuum conditions (\\( T = 0 \\)). Our analysis reveals that these correlation functions are intricate, even when examined along the light cone defined by \\( x + x' = t + t_0 = 2ct \\). Notably, we observe that these functions exhibit force law behavior with exponents that continuously vary with \\( c \\). This contrasts with standard quantum mechanics, where such correlators vanish outside the light cone. The results detailed here can be derived using established techniques from thermofield dynamics, providing further support for the applicability of this framework in describing thermal states, particularly in non-equilibrium contexts. Energy density-flux correlations are crucial in various mechanical phenomena, from hydrodynamics to particle production in heavy ion collisions. Nevertheless, their computation has been challenging due to the need for information about off-diagonal elements of the two-point integral of the relevant operator. In this work, we present explicit expressions for these quantities in the context of a free massless scalar field in one spatial dimension.",
        "ori-fast-z-score": 0.6396021490668313,
        "water-fast-z-score": 5.193989612031165,
        "rewrite-fast-z-score": 1.5275252316519468
    },
    {
        "original_text": "We present the results of an analysis of high-resolution optical spectra obtained with the Subaru Telescope for a sample of young, low-mass (0.5-2 Msun) PMS stars in Orion Nebula Cluster. We find that most of these objects show significant periodic variability on timescales ranging between 1 day to several months. The observed periods are consistent with those expected if the photometric variations result from rotational modulation due to starspots and/or plages. In addition we detect strong Hα emission lines which indicate chromospheric activity. Our observations suggest that many of our targets have relatively rapid rotation rates compared to older field dwarfs at similar masses. This is likely caused by tidal locking during their formation process. Finally, we also report the detection of two new spectroscopic binaries among our target list. These systems will be useful as benchmarks for testing theoretical models of binary evolution.",
        "watermark_text": "We present the conclusion of an assessment of high - resolution optical spectra obtained with the Subaru Telescope for a sample of young , low - weight ( 0 . 5 - 2 Msun ) PMS stars in Orion Nebula Cluster . We see that most of these objects show considerable periodic variability on timescales ranging between 1 day to several months .The observed periods are compatible with those expected if the photometric shifts result from rotational modulation owing to starspots and / or plages . In addition we find strong Hα emission lines which show chromospheric behavior .Our observations suggest that several of our targets have fairly rapid rotation times compared to older field dwarfs at comparable masses . This is probably due by tidal locking during their development process .Finally , we also report the observation of two new spectroscopic binaries among our target list . These systems will be valuable as benchmarks for evaluating theoretical theories of binary evolution .",
        "rewrite_text": "We conclude our assessment of high-resolution optical spectra obtained with the Subaru Telescope for a sample of young, low-mass protostars (0.5 - 2 Msun) in the Orion Nebula Cluster. Our findings indicate that most of these stars exhibit significant periodic variability, with timescales ranging from one day to several months. The observed periods align with those predicted if the photometric variations are due to rotational modulation caused by starspots and/or plages. Additionally, we observe strong Hα emission lines that display chromospheric behavior. Our results suggest that several of our targets have relatively rapid rotation times compared to older field dwarfs of similar masses, likely due to tidal locking during their developmental process. Lastly, we identify two new spectroscopic binaries within our target sample, which will serve as valuable benchmarks for assessing theoretical models of binary evolution.",
        "ori-fast-z-score": -1.8325416653445783,
        "water-fast-z-score": 4.608176875690327,
        "rewrite-fast-z-score": 0.1259881576697424
    },
    {
        "original_text": "We present the first results for a new template family, called SEOBNRv4HM, which is designed to detect gravitational waves (GWs) emitted by comparable mass black hole binaries with total masses between 10 and 100 solar masses. We show that this template family can be used in searches for GW signals from binary black holes at current ground-based detectors such as Advanced LIGO/Virgo and KAGRA. In addition we demonstrate how these templates are useful for parameter estimation studies using simulated data sets. Finally, we discuss possible improvements on our work. Keywords: Binary black hole -Gravitational wave detector -Template family -Parameter estimation -SEOBNRv4HM -Advanced Virgo -LIGO -KAGRA -Black hole -Binary system -Gravitational wave signal -Gravitational wave astronomy -Gravitational wave source -Signal-to-noise ratio -Search algorithm -Simulation",
        "watermark_text": "We present the first findings for a new template family , known SEOBNRv4HM , which is designed to identify gravitational waves ( GWs ) emitted by similar mass black hole binaries with total masses between 10 and 100 solar masses . We see that this template family can be used in searches for GW signals from binary white holes at current ground - based detectors such as Advanced LIGO / Virgo and KAGRA .In addition we explain how these templates are helpful for parameter estimation studies employing simulated evidence sets . Finally , we explain possible advances on our work .Keywords : Binary white hole - Gravitational wave detector - Template family - Parameter estimation - SEOBNRv4HM - Advanced Virgo - LIGO - KAGRA - Black hole - Binary network - Gravitational wave noise - Gravitational wave astronomy - Gravitational wave source - Signal - to - noise ratio - Search algorithm - Simulation",
        "rewrite_text": "We introduce our initial findings from a new template family, named SEOBNRv4HM, specifically created to detect gravitational waves (GWs) generated by black hole binaries with similar masses and total masses ranging from 10 to 100 solar masses. Our results indicate that this template family can be effectively utilized in the search for GW signals from binary white holes using current ground-based detectors like Advanced LIGO, Virgo, and KAGRA. Additionally, we discuss how these templates can enhance parameter estimation studies involving simulated datasets. Lastly, we outline potential future developments related to our research. \n\nKeywords: Binary white hole, gravitational wave detector, template family, parameter estimation, SEOBNRv4HM, Advanced Virgo, LIGO, KAGRA, black hole, binary network, gravitational wave noise, gravitational wave astronomy, gravitational wave source, signal-to-noise ratio, search algorithm, simulation.",
        "ori-fast-z-score": -1.1523319193960637,
        "water-fast-z-score": 3.2547227745205967,
        "rewrite-fast-z-score": 0.4588314677411235
    },
    {
        "original_text": "The gravitational force between two objects is proportional to the product of their masses, and inversely proportional to the square of the distance separating them.  The same relationship holds true for repulsive gravity as well.   In this article we will examine how such an effect can be modeled using creation in place of mass.    Creation is defined by Einstein s field equations as:  G = 8πG/c4T00 where T00 represents the energy density of space-time.  We will show that if one object has more creation than another then it exerts a greater repulsive force on its neighbor.   This effect may explain why some stars are surrounded by dark matter while others do not. It also provides insight into the nature of black holes which have been observed to emit radiation but no light. Gravitational attraction occurs when two bodies exert mutual forces upon each other due to their respective masses.  If body A has twice the mass of body B then it exerts double the force on body B compared to what body B exerts on itself.  Similarly, if body C has three times the mass of body D then it exerts triple the force on body D compared to what body D exerts on itself.  Force is measured in newtons (N) or dynes (dyne).",
        "watermark_text": "The gravitational pressure between two bodies is proportional to the product of their masses , and inversely proportional to the square of the distance separating them . The same relationship holds true for repulsive gravitational as well .In this article we will investigate how such an effect can be described using creation in place of mass . Creation is calculated by Einstein s field equations as : G = 8πG / c4T00 where T00 represents the power concentration of space - time .We will show that if one element has more creation than another then it exerts a greater repulsive force on its neighbor . This phenomenon might explain why some stars are surrounded by black material while many do not .It additionally offers knowledge into the nature of black holes which have been observed to emit radiation but no light . Gravitational attraction occurs when two bodies exert mutual forces upon each other owing to their different masses .If head A has times the mass of bodies B then it exerts double the force on body B contrast to what body B exerts on itself . Similarly , if bodies C has three times the mass of bodies D then it exerts double the force on body D compared to what body D exerts on itself .Force is measured in newtons (N) or dynes (dyne).",
        "rewrite_text": "The gravitational interaction between two objects is directly proportional to the product of their masses and inversely proportional to the square of the distance between them. This same principle applies to repulsive gravitational forces as well. In this article, we will explore how this concept can be framed in terms of \"creation\" instead of mass. According to Einstein's field equations, creation is expressed as G = 8πG / c^4 T00, where T00 denotes the energy density of spacetime. We will demonstrate that if one object has a greater amount of creation than another, it will exert a stronger repulsive force on its neighboring object. This phenomenon might clarify why some stars are surrounded by dark material while others are not. Furthermore, it sheds light on the nature of black holes, which are known to emit radiation but not visible light. Gravitational attraction occurs when two objects exert reciprocal forces on one another due to their differing masses. For instance, if object A has twice the mass of object B, it will exert double the gravitational force on object B compared to the force that B exerts on itself. Similarly, if object C has three times the mass of object D, it will exert thrice the force on object D relative to D's self-exerted force. Force is quantified in newtons (N) or dynes (dyne).",
        "ori-fast-z-score": -0.5488212999484517,
        "water-fast-z-score": 4.638124095143555,
        "rewrite-fast-z-score": 0.44172610429938614
    },
    {
        "original_text": "The authors have studied the stability of the superconducting state by measuring the temperature dependence of the resistance and magnetic susceptibility for single crystals with different oxygen contents (0.5, 0.6, 0.7). The results show that the critical temperatures T_c decrease as the oxygen content decreases. This is explained by an increase in disorder due to the presence of excess oxygen atoms at low oxygen concentrations.  In addition, it was found that the transition widths are larger than those observed previously on polycrystalline samples. It has been shown that this effect can be attributed to the anisotropy of the crystal lattice. Finally, we note that the behavior of the resistivity near Tc does not depend on the oxygen concentration. We believe that these results will help clarify some aspects of the physics of high-temperature superconductors. High-Tc cuprates are known to exhibit two types of electronic states depending on their doping levels: metallic or insulating  1  . At optimal doping levels they display a superconducting phase which persists up to very high temperatures  2  , while underdoped compounds become insulators  3  .\nIn order to understand better the physical properties of these materials, several studies were performed using various techniques such as: transport measurements  4  , neutron scattering  5  , optical spectroscopy  6  , nuclear quadrupole resonance  7  , muon spin rotation  8  , etc.. However, despite all efforts made so far, there still remain many open questions about the nature of the normal and superconducting phases  9  .",
        "watermark_text": "The authors have researched the stability of the superconducting state by examining the temperature dependence of the tolerance and magnetic susceptibility for single crystals with various oxygen contents ( 0 . 5 , 0 . 6 , 0 . 7 ) . The results show that the important temperatures T _ c decrease as the oxygen composition decreases .This is explained by an increase in depression owing to the presence of excess oxygen atoms at low oxygen concentrations . In addition , it was shown that the transition widths are larger than those observed previously on polycrystalline specimens .It has been shown that this effect can be due to the anisotropy of the crystal structures . Finally , we note that the activity of the resistivity near Tc does not depend on the oxygen pressure .We believe that these results will assist clarify some elements of the physics of high - temperature superconductors . High - Tc cuprates are known to contain two forms of electronic states based on their doping rates : metallic or insulating 1 .At optimal doping rates they show a superconducting phase which persists up to very high heats 2 , while underdoped structures become insulators 3 . In order to explain better the physical properties of these structures , various tests were performed using numerous methodology such as : transport measurements 4 , neutron scattering 5 , optical spectroscopy 6 , nuclear quadrupole resonance 7 , muon spin rotation 8 , etc . .However , despite all efforts made so far , there still continue several active issues about the nature of the usual and superconducting phases 9 .",
        "rewrite_text": "The authors investigated the stability of the superconducting state by analyzing how the tolerance and magnetic susceptibility of single crystals with varying oxygen contents (0.5, 0.6, 0.7) change with temperature. Their findings reveal that the crucial temperature, T_c, decreases as the oxygen content diminishes. This decrease is attributed to an increase in depression caused by the presence of excess oxygen atoms at lower concentrations. Furthermore, the study noted that the transition widths in these single crystals are broader than those reported in previous studies of polycrystalline samples, a phenomenon that may be linked to the anisotropic nature of the crystal structures. Additionally, it was observed that the resistivity behavior near T_c is unaffected by oxygen pressure. The authors believe these results will help clarify aspects of high-temperature superconductivity. High-T_c cuprates are recognized for exhibiting two types of electronic states depending on their doping levels: metallic or insulating. At optimal doping levels, they demonstrate a superconducting phase that remains stable at very high temperatures, while underdoped materials typically behave as insulators. To further elucidate the physical properties of these materials, various methodologies, including transport measurements, neutron scattering, optical spectroscopy, nuclear quadrupole resonance, and muon spin rotation, were employed. Despite these efforts, several unresolved questions remain regarding the characteristics of both the normal and superconducting phases.",
        "ori-fast-z-score": 0.09667364890456635,
        "water-fast-z-score": 6.670481774415078,
        "rewrite-fast-z-score": 0.09759000729485333
    },
    {
        "original_text": "We have studied the distribution of the molecular gas along the line-of-sight to the gravitationally lensed radio source B0218+357 using high-resolution millimeter-wave observations at 345 GHz and 1.3 mm with the Submillimeter Array (SMA) on Mauna Kea, Hawaii. The lensing galaxy is located between two images A and C separated by 2.7 arcsec. We detected three compact continuum sources associated with each image component. In addition we found several faint emission lines including CO(3-2), 13CO(3-2), HCN(4-3), CS(5-4), SiO(8-7). From these results we conclude that there are four components contributing to the total flux density; one for each image plus an additional component due to the lensing galaxy. Using our SMA data together with previous single-dish measurements, we derived physical parameters such as mass surface densities, column densities, temperatures, and volume densities for all four components.",
        "watermark_text": "We have researched the spread of the molecular gas along the line - of - view to the gravitationally lensed radio source B0218 + 357 using high - resolution millimeter - wave studies at 345 GHz and 1 . 3 cm with the Submillimeter Array ( SMA ) on Mauna Kea , Hawaii . The lensing galaxy is situated between two images A and C connected by 2 . 7 arcsec .We observed three compact continuum sources related with each image element . In addition we identified numerous distant emission lines including CO ( 3 - 2 ) , 13CO ( 3 - 2 ) , HCN ( 4 - 3 ) , CS ( 5 - 4 ) , SiO ( 8 - 7 ) .From these results we conclude that there are four components contributing to the total flux concentration ; one for each image plus an additional element due to the lensing galaxy . Using our SMA data together with previous single - dish measurements , we derived mechanical parameters such as mass surface densities , column densities , temperatures , and volume densities for all four components .",
        "rewrite_text": "We conducted an investigation into the distribution of molecular gas along the line of sight to the gravitationally lensed radio source B0218+357, utilizing high-resolution millimeter-wave studies at 345 GHz and 1.3 cm with the Submillimeter Array (SMA) on Mauna Kea, Hawaii. The lensing galaxy is positioned between two images, A and C, separated by 2.7 arcseconds. Our observations revealed three compact continuum sources associated with each image. Additionally, we detected numerous distant emission lines, including CO (3-2), 13CO (3-2), HCN (4-3), CS (5-4), and SiO (8-7). Based on these findings, we conclude that four components contribute to the total flux concentration: one for each image and an extra component attributed to the lensing galaxy. By combining our SMA data with previous single-dish measurements, we were able to calculate mechanical parameters, including mass surface densities, column densities, temperatures, and volume densities for all four components.",
        "ori-fast-z-score": -0.13018891098082389,
        "water-fast-z-score": 3.7754784184438925,
        "rewrite-fast-z-score": -0.3841106397986879
    },
    {
        "original_text": "The asteroid 144898 was discovered on September 24, 2004 by the Catalina Sky Survey at an apparent magnitude of 18.7 and is classified as potentially hazardous due to its large size.  The orbit has been determined using astrometric observations made with the US Naval Observatory s 1-meter telescope in Flagstaff Arizona between October 2005 and March 2007.   These data show that this object will not impact Earth during the next 100 years but may be a good candidate for future space mission targets. This work was supported by NASA under grant NNX07AG70G issued through the Planetary Defense Coordination Office. We report here our results of physical investigations carried out on the surface of the asteroid 144898 (2004VD17). Our analysis shows that it is a S-type asteroid with a diameter D = 2.5 ± 0.2 km. Its rotation period P = 3.6 ± 0.1 hours and pole position are also derived.",
        "watermark_text": "The asteroid 144898 was discovered on September 24 , 2004 by the Catalina Sky Survey at an apparent magnitude of 18 . 7 and is categorized as potentially dangerous due to its large size . The orbit has been determined using astrometric observations made with the US Naval Observatory s 1 - meter telescope in Flagstaff Arizona between October 2005 and March 2007 .These data demonstrate that this body will not hit Earth during the last 100 years but might be a better contender for future space flight targets . This effort was supported by NASA under grant NNX07AG70G sent through the Planetary Defense Coordination Office .We report here our findings of physical tests carried out on the surface of the asteroid 144898 ( 2004VD17 ) . Our study shows that it is a S - class asteroid with a diameter D = 2 . 5 ± 0 . 2 km .Its rotation period P = 3 . 6 ± 0 . 1 hours and pole position are also derived .",
        "rewrite_text": "Asteroid 144898 was discovered on September 24, 2004, by the Catalina Sky Survey, at an apparent magnitude of 18.7. It is classified as potentially hazardous due to its significant size. The orbit of the asteroid was determined through astrometric observations conducted with the US Naval Observatory's 1-meter telescope in Flagstaff, Arizona, from October 2005 to March 2007. These observations confirm that this asteroid will not collide with Earth over the next century, making it a more promising candidate for future space exploration. This research was supported by NASA under grant NNX07AG70G through the Planetary Defense Coordination Office. Here, we present our findings from physical tests performed on the surface of asteroid 144898 (2004 VD17). Our study reveals that it is an S-class asteroid with a diameter of D = 2.5 ± 0.2 km. Additionally, we have determined its rotation period to be P = 3.6 ± 0.1 hours and identified its pole position.",
        "ori-fast-z-score": -1.0690449676496976,
        "water-fast-z-score": 4.008918628686366,
        "rewrite-fast-z-score": 1.0886621079036347
    },
    {
        "original_text": "We study the decoherence dynamics of an open quantum system consisting of two-level atoms coupled to a single-mode cavity field in presence of dissipation and driving fields. The atom-cavity coupling is treated within the framework of Jaynes-Cummings model, while the dissipative effects are described by using the master equation for the reduced density matrix of the system. We show that the steady state solution of this problem can be obtained analytically when the decay rates of all atomic levels are equal. In particular we find that the steady-state entanglement between the atom-field subsystem depends on both the strength of the external driving field as well as the number of excited states involved in the process. Finally, we discuss how our results could be used to explain recent experimental observations concerning the generation of nonclassical light via spontaneous emission processes. PACS numbers: 03.67.Mn, 42.50.Vk",
        "watermark_text": "We explore the decoherence dynamics of an open quantum system consisting of two - level atoms connected to a single - mode cavity field in presence of dissipation and driving fields . The atom - cavity coupling is treated within the framework of Jaynes - Cummings model , while the dissipative effects are explained by using the master equation for the reduced density matrix of the system .We see that the stable state solution of this question can be obtained analytically when the decay rates of all atomic levels are equal . In particular we find that the steady - state entanglement between the atom - field subsystem depends on both the strength of the external driving field as well as the quantity of excited states participating in the process .Finally , we explain how our findings may be used to explain latest experimental discoveries involving the generation of nonclassical light via spontaneous emission mechanisms . PACS codes : 03 . 67 . Mn , 42 . 50 . Vk",
        "rewrite_text": "We investigate the decoherence dynamics of an open quantum system composed of two-level atoms coupled to a single-mode cavity field, considering the effects of dissipation and external driving fields. The atom-cavity interaction is analyzed using the Jaynes-Cummings model, while dissipative influences are addressed through the master equation governing the reduced density matrix of the system. Our results indicate that an analytical solution for the stable state can be found when the decay rates of all atomic levels are identical. Notably, we discover that the steady-state entanglement between the atom-field subsystem is influenced by both the intensity of the external driving field and the number of excited states involved in the interaction. Ultimately, we discuss how our findings can elucidate recent experimental results related to the generation of nonclassical light through spontaneous emission processes. PACS codes: 03.67.Mn, 42.50.Vk.",
        "ori-fast-z-score": 1.0392304845413263,
        "water-fast-z-score": 4.358898943540673,
        "rewrite-fast-z-score": 0.11704114719613057
    },
    {
        "original_text": "We present new Chandra observations of the brightest cluster galaxy (BCG) in Abell 3395 (z=0.084). The BCG is surrounded by an extended halo with temperatures ranging between 1 keV to 5 keV. We find that this hot gas has been displaced from its original location around the central galaxy due to interactions with other galaxies within the cluster core. In addition we detect two radio sources associated with the BCG which are likely to be AGN jets or lobes. Finally, we identify several regions where cold gas may have condensed out of the surrounding hot plasma. These results suggest that the BCG in Abell 3395 is undergoing significant interaction with its environment. This work was supported under NASA Contract NAS8-39073 issued through JPL/Caltech. The data presented herein were obtained at the Chandra Observatory, operated by the Smithsonian Astrophysical Observatory for and on behalf of NASA under contract NAS8-03060.",
        "watermark_text": "We present new Chandra observations of the brightest cluster galaxy ( BCG ) in Abell 3395 ( z = 0 . 084 ) . The BCG is surrounded by an extended halo with temperatures ranging between 1 keV to 5 keV .We see that this hot gas has been displaced from its initial site around the main galaxy owing to interactions with other stars within the cluster core . In addition we locate two radio sources related with the BCG which are likely to be AGN jets or lobes .Finally , we identify several regions where cold vapor possibly have condensed out of the nearby hot plasma . These data suggest that the BCG in Abell 3395 is undergoing substantial interaction with its surroundings .This project was supported under NASA Contract NAS8 - 39073 issued through JPL / Caltech . The data given herein were obtained at the Chandra Observatory , operated by the Smithsonian Astrophysical Observatory for and on behalf of NASA under contract NAS8 - 03060 .",
        "rewrite_text": "We present new observations from Chandra of the brightest cluster galaxy (BCG) in Abell 3395 (z = 0.084). This BCG is enveloped by an extensive halo with temperatures that range from 1 keV to 5 keV. Our findings indicate that this hot gas has been displaced from its original location around the main galaxy due to interactions with other stars within the cluster core. Additionally, we have identified two radio sources associated with the BCG, which are likely related to AGN jets or lobes. We also pinpoint several regions where cold vapor may have condensed out of the surrounding hot plasma. These observations imply that the BCG in Abell 3395 is experiencing significant interaction with its environment. This research was supported under NASA Contract NAS8-39073, issued through JPL/Caltech. The data presented here were obtained at the Chandra Observatory, which is operated by the Smithsonian Astrophysical Observatory on behalf of NASA under contract NAS8-03060.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.449719092257398,
        "rewrite-fast-z-score": 0.674199862463242
    },
    {
        "original_text": "We study the electrical excitation of nonlinear waves in a 2D channel with an applied voltage bias between two parallel metal plates separated by a dielectric layer. We show that, depending on the parameters of the system (the thickness of the dielectric layer, the density of electrons), different types of nonlinear waves can be excited. In particular, we find that for certain values of these parameters solitary wave solutions exist which are similar to those found earlier in 1D systems. \n \n The existence of such solitary waves is confirmed experimentally using time-resolved optical reflectivity measurements performed at room temperature on samples consisting of GaAs/AlGaAs quantum wells grown by molecular beam epitaxy. These experiments reveal the presence of bright solitary waves propagating along the direction perpendicular to the applied electric field. Their propagation velocities agree well with theoretical predictions based on numerical simulations of the underlying equations. \nThe results presented here may have important applications in semiconductor devices where it has been shown recently that the generation of solitary waves leads to improved performance characteristics.",
        "watermark_text": "We test the electrical excitation of nonlinear waves in a 2D channel with an applied voltage bias between two connected metal plates connected by a dielectric layer . We see that , depending on the variables of the device ( the length of the dielectric layer , the density of atoms ) , different kinds of nonlinear waves can be excited .In particular , we find that for particular values of these parameters solitary wave systems occur which are comparable to those shown previous in 1D solutions . The existence of such solitary waves is demonstrated experimentally using period - resolved laser reflectivity surveys performed at room temperature on samples consisting of GaAs / AlGaAs quantum wells produced by molecular beam epitaxy .These studies reveal the presence of bright solitary waves propagating along the direction perpendicular to the introduced electric field . Their propagation velocities agree well with theoretical estimates based on numerical simulations of the underlying equations .The results presented here possibly have important use in semiconductor devices where it has been shown lately that the generation of solitary waves gives to improved performance qualities .",
        "rewrite_text": "We investigate the electrical excitation of nonlinear waves in a two-dimensional channel featuring an applied voltage bias between two metal plates separated by a dielectric layer. Our observations reveal that various types of nonlinear waves can be excited, depending on device parameters such as the dielectric layer's length and atomic density. Notably, we identify solitary wave systems at specific parameter values that resemble those previously observed in one-dimensional solutions. The existence of these solitary waves is empirically validated through period-resolved laser reflectivity measurements conducted at room temperature on GaAs/AlGaAs quantum well samples fabricated via molecular beam epitaxy. These experiments demonstrate the presence of bright solitary waves propagating in a direction perpendicular to the applied electric field, with their propagation velocities aligning closely with theoretical predictions from numerical simulations of the governing equations. The findings presented here may have significant implications for semiconductor devices, particularly as recent studies have indicated that solitary wave generation can enhance performance characteristics.",
        "ori-fast-z-score": -0.10482848367219183,
        "water-fast-z-score": 5.692099788303083,
        "rewrite-fast-z-score": 2.1320071635561044
    },
    {
        "original_text": "We present new spectroscopic observations for two globular clusters (GCs) in the nearby galaxy NGC 5128, which is known as Centaurus A. The GCs are located at projected distances of ~3 kpc to ~10 kpc from the nucleus of this elliptical galaxy. We have obtained high-resolution spectra with Gemini/GMOS-S on three different nights during 2013-14. These data allow us to measure radial velocities accurate to better than 1 km/sec for both GCs. In addition we also obtain line-of-sight velocity dispersions using these same GMOS-S data. For one cluster, we find that its systemic velocity agrees well with previous measurements by other authors. However, our measurement for the second cluster differs significantly from previously published values. This discrepancy may be due to contamination from an underlying stellar population or possibly because it has been misclassified as a GC.",
        "watermark_text": "We present new spectroscopic observations for two globular complexes ( GCs ) in the nearby galaxy NGC 5128 , which is known as Centaurus A . The GCs are situated at projected speeds of ~ 3 kpc to ~ 10 kpc from the nucleus of this elliptical galaxy .We have achieved high - resolution spectra with Gemini / GMOS - S on three different nights during 2013 - 14 . These data enable us to measure radial velocities accurate to well than 1 km / sec for both GCs .In addition we also obtain line - of - view velocity dispersions using these same GMOS - S data . For one cluster , we find that its chronic velocity agrees well with previous measurements by other studies .However , our observations for the second cluster differs greatly from prior released estimates . This discrepancy may be due to poisoning from an underlying stellar community or possibly because it has been misclassified as a GC .",
        "rewrite_text": "We present new spectroscopic observations of two globular clusters (GCs) in the nearby galaxy NGC 5128, also known as Centaurus A. These clusters are located at projected distances ranging from approximately 3 kpc to 10 kpc from the center of this elliptical galaxy. We obtained high-resolution spectra using the GMOS-S instrument on the Gemini Observatory over three nights in 2013 and 2014. This data allows us to measure radial velocities with an accuracy better than 1 km/s for both GCs. Additionally, we derived line-of-sight velocity dispersions from the same GMOS-S observations. For one of the clusters, our measured velocity aligns well with previous findings from other studies. However, our results for the second cluster significantly diverge from earlier estimates. This variance may be attributed to contamination from an underlying stellar population or could indicate that it has been misclassified as a globular cluster.",
        "ori-fast-z-score": -0.6622661785325219,
        "water-fast-z-score": 3.9391929857916765,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We present the results of an analysis of globular cluster (GC) systems in four massive elliptical galaxies, NGC 4889, NGC 4636, NGC 5846 and NGC 6166, using deep Hubble Space Telescope imaging data obtained with the Advanced Camera for Surveys Wide Field Channel. We find that these GC systems are multimodal; they consist of at least two subpopulations which differ significantly in their color distributions as well as in their spatial distribution within each galaxy. The blue subpopulation is more centrally concentrated than the red one, while both populations show similar radial profiles outside the central regions. These findings suggest that the formation histories of the two subpopulations may be different. In particular, we propose that the blue subpopulation formed during major mergers between gas-rich disk galaxies, whereas the red subpopulation was assembled through minor mergers and/or accretion events involving dwarf galaxies or low-mass ellipticals.",
        "watermark_text": "We present the conclusion of an assessment of globular cluster ( GC ) complexes in four large elliptical galaxies , NGC 4889 , NGC 4636 , NGC 5846 and NGC 6166 , using deep Hubble Space Telescope imaging information obtained with the Advanced Camera for Surveys Wide Field Channel . We see that these GC systems are multimodal ; they consist of at least two subpopulations which varies dramatically in their color distributions as well as in their temporal distribution within each galaxy .The blue subpopulation is more centrally focused than the red one , while both populations display corresponding radial profiles outside the main regions . These studies imply that the formation histories of the two subpopulations might be different .In particular , we propose that the blue subpopulation formed during major mergers between gas - rich disk galaxies , whereas the red subpopulation was assembled through minor mergers and / or accretion events concerning dwarf stars or low - mass ellipticals .",
        "rewrite_text": "We present the findings from our assessment of globular cluster (GC) complexes in four large elliptical galaxies: NGC 4889, NGC 4636, NGC 5846, and NGC 6166. Utilizing deep imaging data from the Hubble Space Telescope's Advanced Camera for Surveys Wide Field Channel, we observe that these GC systems are multimodal, comprising at least two subpopulations that exhibit significant differences in color distributions and their temporal characteristics within each galaxy. The blue subpopulation is more concentrated towards the center compared to the red subpopulation, although both groups show similar radial profiles beyond the primary regions. Our studies suggest that the formation histories of these two subpopulations may differ. Specifically, we propose that the blue subpopulation originated from major mergers of gas-rich disk galaxies, while the red subpopulation likely formed through minor mergers or accretion involving dwarf galaxies or low-mass ellipticals.",
        "ori-fast-z-score": -0.7878385971583353,
        "water-fast-z-score": 4.464418717230567,
        "rewrite-fast-z-score": 0.9271726499455306
    },
    {
        "original_text": "The Coulomb drag effect is the phenomenon where one charge carrier can transfer energy to another by exchanging virtual phonons, leading to an electric current in the second carrier that opposes its own motion.  In this work we study the Coulomb drag between two graphene sheets separated by a dielectric spacer layer and subject to different gate voltages. We find that for small separation distances (less than 10 nm) there are significant deviations from the predictions based on the standard theory developed for bulk materials. These deviations arise due to the presence of evanescent modes which couple strongly with the carriers at low energies. For larger separations these effects become negligible as expected. The results presented here provide useful information about how to design devices such as transistors or thermoelectric generators using graphene layers. \nI. INTRODUCTIO N\nGraphene has attracted considerable attention recently because it exhibits unique electronic properties  1  . It consists of carbon atoms arranged into a honeycomb lattice structure and behaves like a two-dimensional electron gas when doped  2  .\nOne interesting property of graphene is the so-called Coulomb drag effect  3  , i.e., the generation of an electric current in a second sheet of electrons moving through a first sheet of electrons even if they do not interact directly  4  . This effect arises because both carriers exchange virtual phonons via their mutual interaction mediated by the substrate  5  . As a result, the current density in the second carrier depends on the velocity of the first carrier  6  . Since the discovery of the Coulomb drag effect in semiconductors  7, 8  many theoretical studies have been performed  9  -  11  . However, only very few experiments were carried out so far  12  -  14  mainly due to difficulties associated with fabricating samples with high quality interfaces  15  . Recently, several groups succeeded in growing high-quality epitaxial graphene  16  -  18  opening up new possibilities for studying the Coulomb drag effect experimentally  19  -  21  .",
        "watermark_text": "The Coulomb drag effect is the situation where one charge carrier can carry energy to another by exchanging virtual phonons , leading to an electric current in the second carrier that opposes its own movement . In this research we study the Coulomb drag between two graphene strands divided by a dielectric spacer coating and subject to different gate voltages .We see that for short separation distances ( fewer than 10 nm ) there are significant deviations from the estimates based on the standard theory created for bulk materials . These deviations occur due to the presence of evanescent modes which couple strongly with the carriers at low energies .For larger separations these changes become negligible as anticipated . The results presented here provide useful details about how to build electronics such as transistors or thermoelectric turbines using graphene layers .I . INTRODUCTIO N Graphene has garnered considerable scrutiny lately because it displays unusual electronic properties 1 . It consists of carbon atoms arranged into a honeycomb lattice structure and behaves like a two - dimensional electron gas when doped 2 .One interesting property of graphene is the so - called Coulomb drag effect 3 , i . e . , the generation of an electric current in a second sheet of electrons moved through a second sheet of electrons even if they do not interact directly 4 . This phenomenon arises because both carriers trade virtual phonons via their mutual interaction mediated by the substrate 5 .As a result , the current density in the second carrier varies on the velocity of the first carrier 6 . Since the discovery of the Coulomb drag effect in semiconductors 7 , 8 numerous conceptual research have been performed 9 - 11 .However , only very few experiments were carried out so far 12 - 14 chiefly due to difficulties related with fabricating samples with high quality interfaces 15 . Recently , various groups helped in growing high - grade epitaxial graphene 16 - 18 opening up new possibilities for studying the Coulomb drag effect experimentally 19 - 21 .",
        "rewrite_text": "The Coulomb drag effect occurs when one charge carrier transfers energy to another by exchanging virtual phonons, resulting in an electric current in the second carrier that opposes its motion. In this study, we investigate the Coulomb drag between two graphene strands separated by a dielectric spacer and subjected to various gate voltages. We observe that at short distances (less than 10 nm), there are notable deviations from predictions made by standard theories formulated for bulk materials. These discrepancies arise from the presence of evanescent modes that couple strongly with the carriers at low energy levels. In contrast, these effects become negligible at greater separations, as expected. The findings presented here offer valuable insights for the development of electronic devices, such as transistors and thermoelectric turbines, utilizing graphene layers. \n\nI. INTRODUCTION\nGraphene has attracted considerable attention recently due to its unique electronic properties. It is composed of carbon atoms arranged in a honeycomb lattice and behaves as a two-dimensional electron gas when doped. One fascinating aspect of graphene is the Coulomb drag effect, which refers to the generation of electric current in a second layer of electrons induced by the motion of a first layer, even in the absence of direct interaction. This phenomenon occurs as both carriers exchange virtual phonons via their mutual interaction, mediated by the substrate. Consequently, the current density in the second carrier depends on the velocity of the first carrier. Since the first discovery of the Coulomb drag effect in semiconductors, numerous theoretical studies have been conducted. However, only a limited number of experiments have been performed, primarily due to challenges in fabricating samples with high-quality interfaces. Recently, various groups have succeeded in growing high-quality epitaxial graphene, creating new opportunities for the experimental study of the Coulomb drag effect.",
        "ori-fast-z-score": 1.7439550769285392,
        "water-fast-z-score": 8.333333333333334,
        "rewrite-fast-z-score": 0.9931270663228415
    },
    {
        "original_text": "We study fluctuations of finite-time Lyapunov exponent (FTLE) for chaotic orbits on the standard map with periodic boundary conditions. We show that FTLE fluctuates around its mean value, which is determined by the largest unstable periodic orbit embedded into the chaotic attractor. The amplitude of these fluctuations decreases exponentially as time increases. In addition to this exponential decay we observe an algebraic tail at large times. This algebraic tail can be explained by the presence of small islands inside the chaotic sea. These results are confirmed numerically using different methods. \nI. INTRODUCTORY REMARK\nThe concept of finite-time Lyapunovexponent(FTLE), introduced by Wolf et al  1  , has been widely used recently  2  -  4  . It describes how fast nearby trajectories diverge or converge during some fixed period of time T . For example, if one considers two neighboring points x 0 = x(t 0 ) and y 0 = x(t 1 ), where t 0 < t 1 , then their separation after time T will be given by: \nwhere λ max > 0 is the maximum Lyapunov exponent characterizing the rate of divergence between nearby trajectories  5  .\nIn order to calculate the FTLE it is necessary to solve the following variational equation:\nwhere J is the Jacobian matrix corresponding to the flow generated by Eq. (1). If the initial condition z 0 = x t0 + εy t0 is close enough to the reference trajectory x t0 , i.e., |ε| ≪ 1, then the solution of Eq.(2) can be written as:\nwhere P n (T ; t 0 , t 1 ) is the nth-order Taylor polynomial expansion of the evolution operator U (T ; t 0 ). Then the FTLE can be calculated from:",
        "watermark_text": "We test fluctuations of finite - time Lyapunov exponent ( FTLE ) for turbulent orbits on the standard mapping with periodic border conditions . We see that FTLE fluctuates around its average value , which is chosen by the greatest chaotic periodic orbit integrated into the chaotic attractor .The amplitude of these fluctuations decreases exponentially as time rises . In addition to this exponential decay we encounter an algebraic tail at large times .This algebraic tail can be described by the formation of tiny islands inside the chaotic water . These conclusions are confirmed numerically using varying methods .I . INTRODUCTORY REMARK The concept of finite - time Lyapunovexponent ( FTLE ) , invented by Wolf et al 1 , has been widely using recently 2 - 4 .It expresses how rapid nearby trajectories diverge or converge during some fixed period of time T . For instance , if one considers two adjacent points x 0 = x ( t 0 ) and y 0 = x ( t 1 ) , where t 0 < t 1 , then their separation after time T will be shown by : where λ max > 0 is the maximum Lyapunov exponent characterizing the frequency of divergence between neighboring trajectories 5 .In order to estimate the FTLE it is required to solve the following variational equation : where J is the Jacobian matrix corresponding to the flow generated by Eq . ( 1 ) .If the first condition x 0 = x t0 + εy t0 is nearest sufficient to the reference trajectory x t0 , i . e . , | ε | [UNK] 1 , then the solve of Eq . ( 2 ) can be written as : where P n ( T ; t 0 , t 1 ) is the nth - order Taylor polynomial expansion of the evolution function U ( T ; t 0 ) .Then the FTLE can be determined from :",
        "rewrite_text": "We investigate the fluctuations of the finite-time Lyapunov exponent (FTLE) for turbulent orbits in the standard mapping with periodic boundary conditions. Our findings indicate that FTLE oscillates around its average value, which is determined by the most chaotic periodic orbit that is integrated into the chaotic attractor. Notably, the amplitude of these fluctuations exponentially decreases over time. Alongside this exponential decay, we also observe an algebraic tail at longer times, which can be attributed to the emergence of small islands within the chaotic region. These observations have been numerically validated through various methods. \n\nI. INTRODUCTORY REMARK\n\nThe finite-time Lyapunov exponent (FTLE), introduced by Wolf et al.1 and recently utilized in numerous studies2-4, quantifies the rate at which nearby trajectories diverge or converge over a specified time period T. For example, if we consider two close points, x0 = x(t0) and y0 = x(t1), where t0 < t1, their separation after time T is given by an expression involving the maximum Lyapunov exponent, λmax > 0, which characterizes the divergence rate of neighboring trajectories5. To estimate the FTLE, one must solve the following variational equation: (equation), where J denotes the Jacobian matrix associated with the flow described by Equation (1). If the initial condition x0 = x(t0) + εy(t0) is sufficiently close to the reference trajectory, meaning |ε| << 1, the solution of Equation (2) can be expressed as: (equation), where Pn(T; t0, t1) represents the nth-order Taylor polynomial expansion of the evolution function U(T; t0). The FTLE can then be calculated from: (equation).",
        "ori-fast-z-score": -2.154554539378824,
        "water-fast-z-score": 5.511351921262151,
        "rewrite-fast-z-score": -0.9332565252573828
    },
    {
        "original_text": "We present an analytical theory for the low-frequency (1/f) spin-noise power spectrum in disordered semiconductor-oxide interfaces, which is dominated by dangling bond spins at the oxide/semiconductor interface. The model takes into account both electron-phonon scattering processes that lead to spin dephasing as well as phonon-assisted tunneling between localized states near the Fermi level. We show that this leads to a characteristic temperature dependence of the 1/ƒ-noise amplitude with two distinct regimes separated by a crossover temperature T*. Below T* we find a linear increase of the noise amplitude with decreasing temperature, while above T* it decreases exponentially. This behavior can be explained within our model using only one fitting parameter, namely the density of dangling bonds at the interface. Our results are consistent with recent experiments on SiO2/Si-interfaces. \n \n Introduction \n \n In recent years there has been growing interest in understanding the origin of the ubiquitous 1/f noise observed in many different physical systems ranging from electronic devices  1  over biological  2  to geological  3  ones. While its microscopic origins remain unclear  4  , several theoretical models have been proposed  5-7  . Among these, the so-called  disordered semiconductor-oxide interface model   8  provides a simple explanation for the experimentally observed universal scaling properties  9  of the noise amplitude A(T), i.e., the fact that A(T) ~ T-1/2 below some crossover temperature T* and decays exponentially above T*  10  . However, so far no detailed quantitative comparison between experiment and theory exists  11  .\n \nIn this Letter we provide such a comparison based on a generalization of the original model  12  taking into account phonon-assisted tunnel transitions between localized states close to the Fermi energy  13  . Using only one free parameter, namely the density nD of dangling bonds at or near the interface, we obtain excellent agreement with experimental data obtained on Si-SiO2 interfaces  14  . \n \n Model description \n \n As shown schematically in Fig. 1a , the basic idea behind the disordered semiconductor-oxide interface model is that the dominant source of",
        "watermark_text": "We present an analytical theory for the small - frequency ( 1 / f ) spinning - noise power spectrum in disordered semiconductor - oxide interfaces , which is dominated by dangling bond spins at the oxide / semiconductor interface . The model takes into consideration both electron - phonon absorption processes that lead to spinning dephasing as well as phonon - aided tunneling between scattered states near the Fermi level .We see that this results to a peculiar temperature dependence of the 1 / ƒ - noise amplitude with two separate regimes separated by a crossover pressure T * . Below T * we find a linear improvement of the noise amplitude with varying temperature , while above T * it decreases exponentially .This phenomenon can be described within our model utilizing only one fit parameter , namely the density of dangling bonds at the interface . Our results are compatible with recent experiments on SiO2 / Si - connections .Introduction In recent years there has been growing interest in understanding the origin of the ubiquitous 1 / f noise observed in multiple diverse physical structures ranging from electronic systems 1 over biological 2 to geological 3 ones . While its microscopic origins seem unclear 4 , various theoretical theories have been proposed 5 - 7 .Among these , the so - called disordered semiconductor - oxide interface study 8 gives a simple explanation for the experimentally seen universal scaling behavior 9 of the noise amplitude A ( T ) , i . e . , the fact that A ( T ) ~ T - 1 / 2 below some crossover pressure T * and decays exponentially above T * 10 . However , so far no comprehensive empirical comparison between experiment and theory exists 11 .In this Letter we provide such a comparison based on a generalization of the previous study 12 taking into consideration phonon - aided tunnel transitions between restricted states close to the Fermi energy 13 . Using only one free parameter , principally the density nD of dangling bonds at or near the interface , we obtain excellent agreement with theoretical data derived on Si - SiO2 interfaces 14 .Model description As seen schematically in Fig . 1a , the fundamental idea behind the disordered semiconductor - oxide interface model is that the dominant source of",
        "rewrite_text": "We introduce an analytical theory for the low-frequency (1/f) spinning noise power spectrum in disordered semiconductor-oxide interfaces, primarily influenced by dangling bond spins located at the oxide/semiconductor boundary. The model accounts for both electron-phonon absorption processes responsible for spin dephasing and phonon-assisted tunneling among scattered states near the Fermi level. This leads to a unique temperature dependence of the 1/f noise amplitude characterized by two distinct regimes, separated by a crossover temperature T*. Below T*, we observe a linear increase in noise amplitude with rising temperature, while above T* the amplitude decreases exponentially. This behavior can be effectively described by our model using just one fitting parameter: the density of dangling bonds at the interface. Our findings align with recent experimental observations in SiO2/Si connections.\n\nIntroduction: In recent years, there has been an increasing interest in uncovering the source of the prevalent 1/f noise found in a variety of physical systems, spanning from electronic devices to biological and geological contexts. Although the microscopic origins of this noise remain elusive, several theoretical frameworks have been proposed. Notably, the exploration of disordered semiconductor-oxide interfaces offers a straightforward explanation for the universally observed scaling behavior of noise amplitude A(T), where A(T) is proportional to T^(-1/2) below a crossover temperature T* and decays exponentially beyond this point. However, a comprehensive empirical validation of the theory against experimental data has not yet been achieved. In this letter, we present such a validation based on a refinement of prior studies, incorporating phonon-assisted tunneling transitions among constrained states near the Fermi energy. Utilizing a single free parameter, specifically the density of dangling bonds (nD) at or near the interface, we find excellent correlation with theoretical models developed for Si-SiO2 interfaces.\n\nModel description: As illustrated schematically in Fig. 1a, the core concept of the disordered semiconductor-oxide interface model is that the prevailing source of...",
        "ori-fast-z-score": 0.08084520834544433,
        "water-fast-z-score": 7.680294792817211,
        "rewrite-fast-z-score": 3.1235807588017885
    },
    {
        "original_text": "We present here the predictions for the decay rates and CP asymmetries in B decays into two vector mesons, based on the assumption that there is no direct coupling between quarks and leptons at low energies.  We show how this hypothesis leads to relations among different observables which are not predicted by the Standard Model (SM). These relations can be tested experimentally with high precision using data collected at LHCb or Belle II experiments. \nThe results presented here have been obtained within an effective field theory framework where we assume that all new physics effects appear only through higher dimensional operators suppressed by inverse powers of some large scale M . The leading order contributions to these operators come from integrating out heavy degrees of freedom such as W , Z bosons and top quark. In our analysis we consider both tree-level and loop-induced processes. Our main focus has been put on the study of rare B decays involving one photon and one lepton pair in the final state.",
        "watermark_text": "We see here the estimates for the decay rates and CP asymmetries in B decays into two matrix mesons , based on the assumption that there is no direct bonding between quarks and leptons at low energies . We see how this assertion leads to connections among different observables which are not anticipated by the Standard Model ( SM ) .These relations can be verified experimentally with high precision using data taken at LHCb or Belle II experiments . The results presented here have been achieved within an efficient field model formulation where we suppose that all new physics phenomena emerge only through higher dimensional operators suppressed by inverse powers of some high scale M .The leading order contributions to these operators come from combining out large degrees of freedom such as W , Z bosons and top quark . In our analysis we treat both tree - level and loop - induced processes .Our main focus has been put on the observation of rare B decays containing one photon and one lepton pair in the finished state .",
        "rewrite_text": "We present estimates for the decay rates and CP asymmetries in B decays into two matrix mesons, predicated on the assumption that there is no direct coupling between quarks and leptons at low energies. This assumption reveals connections among various observables that are not predicted by the Standard Model (SM). These relations can be experimentally verified with high precision, using data from LHCb or Belle II experiments. The results discussed here are derived from an efficient field model framework, where we assume that all new physics phenomena arise solely from higher-dimensional operators that are suppressed by inverse powers of a high energy scale \\( M \\). The leading-order contributions to these operators result from the integration of high degrees of freedom, such as W and Z bosons and the top quark. In our analysis, we address both tree-level and loop-induced processes, with a particular emphasis on the observation of rare B decays that involve one photon and one lepton pair in the final state.",
        "ori-fast-z-score": -1.5428161556520092,
        "water-fast-z-score": 3.916379472039716,
        "rewrite-fast-z-score": 0.601929265428846
    },
    {
        "original_text": "We consider the Standard Model (SM) in 5 dimensions, where one extra dimension is compactified to an orbifold S 1 /Z 2 . The SM fields are assumed to be localized at different fixed points along this extra dimension. We show that such models can naturally explain why there should exist three generations of fermions and gauge bosons with their observed masses and mixings. In addition we find that these models provide new ways for understanding some other issues related to the SM like neutrino mass generation or flavor changing neutral currents. Finally we discuss how our results could be tested experimentally. Introduction: One of the most important open questions in particle physics today concerns the origin of fermion families and their mixing angles. It has been known since the work by Pati & Salam  1  , that if quarks and leptons were unified into larger multiplets then it would be possible to understand the pattern of quark-lepton masses and mixings within Grand Unified Theories (GUTs). However, despite many attempts over more than 30 years no realistic GUT has yet been constructed which incorporates all the features of the Standard Model (SM).\nIn recent years another possibility was suggested  2  -  4  : If the SM fields live in higher dimensional space-time, they may have Kaluza-Klein excitations corresponding to additional states with masses of order 1/R, where R denotes the size of the extra dimensions. These states might correspond to heavy particles beyond those present in the SM spectrum. This idea leads to interesting phenomenological consequences  5  .\nThe simplest way to realize this scenario is to assume that only gravity propagates in the bulk while the SM fields are confined to a four-dimensional  brane   6  . Such theories lead to corrections to the Newtonian potential between two test masses m 1 and m 2 separated by distance r given by: \nwhere M P l = 1/ √ 8πG N ≈ 10 19 GeV is the reduced Planck scale and n i counts the number of extra spatial dimensions accessible to field i. For distances smaller than about 0.1 mm deviations from the inverse square law predicted by general relativity will become",
        "watermark_text": "We consider the Standard Model ( SM ) in 5 dimensions , where one extra dimension is compactified to an orbifold S 1 / Z 2 . The SM fields are expected to be localized at different fixed points along this extra dimension .We see that such theories can naturally explain why there should exist three generations of fermions and gauge bosons with their observed masses and mixings . In addition we find that these models bring fresh ways for explaining some other issues related to the SM like neutrino mass development or color shifting neutral currents .Finally we talk how our findings may be evaluated experimentally . Introduction : One of the most important open questions in particle science today issues the origin of fermion families and their mixing angles .It has been known since the paper by Pati & Salam 1 , that if quarks and leptons were organized into larger multiplets then it would be possible to comprehend the trend of quark - lepton masses and mixings within Grand Unified Theories ( GUTs ) . However , despite many efforts over more than 30 centuries no realistic GUT has already been constructed which includes all the details of the Standard Model ( SM ) .In recent work another possibility was suggested 2 - 4 : If the SM fields reside in larger dimensional space - time , they may have Kaluza - Klein excitations corresponding to extra states with masses of order 1 / R , where R denotes the height of the extra dimensions . These states could belong to heavy ions beyond those present in the SM spectrum .This idea results to useful phenomenological consequences 5 . The shortest way to realize this situation is to assume that only gravitational propagates in the bulk while the SM fields are localized to a four - dimensional brane 6 .Such theories lead to corrections to the Newtonian potential between two test masses m 1 and m 2 separated by distance r given by : where M P l = 1 / √ 8πG N ≈ 10 19 GeV is the reduced Planck scale and n i counts the quantity of added spatial dimensions accessible to field i . For distances smaller than about 0 . 1 mm deviations from the inverse square law predicted by particular relativity will become",
        "rewrite_text": "We examine the Standard Model (SM) in a five-dimensional framework, where one additional dimension is compactified into an S^1/Z_2 orbifold. In this setup, the SM fields are anticipated to be concentrated at various fixed points along this extra dimension. This approach provides a natural explanation for the existence of three generations of fermions and gauge bosons, along with their observed masses and mixing properties. Furthermore, our findings suggest novel avenues for addressing other challenges related to the SM, such as the generation of neutrino masses and the phenomenon of color-changing neutral currents. Finally, we discuss how these insights might be tested through experimental means.\n\n**Introduction:** A key unanswered question in particle physics is the origin of fermion families and their mixing angles. As highlighted in the work by Pati & Salam, organizing quarks and leptons into larger multiplets could help explain the patterns observed in quark-lepton masses and mixings within Grand Unified Theories (GUTs). However, despite extensive efforts over the past three decades, a comprehensive GUT that incorporates all aspects of the Standard Model has yet to be realized. Recent research has proposed an alternative approach: if the SM fields exist in a higher-dimensional spacetime, they could exhibit Kaluza-Klein excitations that correspond to extra states with masses on the order of 1/R, where R is the scale of the extra dimensions. This concept may allow for the existence of heavy particles outside the traditional SM spectrum, leading to valuable phenomenological implications. The simplest way to achieve this is to posit that only gravitational forces propagate in the bulk, while the SM fields are confined to a four-dimensional brane. Such models yield modifications to the Newtonian gravitational potential between two test masses, m₁ and m₂, separated by a distance r, as expressed by: (equation to be provided). Here, Mₚ = 1/√(8πG_N) ≈ 10¹⁹ GeV represents the reduced Planck scale, and n_i denotes the number of additional spatial dimensions accessible to the field i. Deviations from the inverse-square law predicted by general relativity become significant at distances shorter than approximately 0.1 mm.",
        "ori-fast-z-score": 2.685380346549405,
        "water-fast-z-score": 9.115037909077289,
        "rewrite-fast-z-score": 1.7089557634194348
    },
    {
        "original_text": "We have analyzed the spectral and timing properties of Cygnus X-2 using data obtained with the Rossi X-ray Timing Explorer (RXTE). The source was observed for about 100 ks during 1996-1997, when it showed strong aperiodic variability on time scales ranging from milliseconds to hours. We find that the power density spectrum can be described by two components; one is flat below 10 Hz and another has an index of -1 above this frequency. In addition we detect quasi-periodic oscillations at frequencies around 300 Hz which are coherent over several hundred seconds. Using these results as input parameters into our model fitting procedure, we obtain good fits to both the energy spectra and the light curves simultaneously. Our best-fit models show that there exists a correlation between the temperature of the Comptonizing plasma and its optical depth. This result suggests that the hot plasma responsible for the hard X-ray emission may also produce soft photons through thermal bremsstrahlung or synchrotron radiation.",
        "watermark_text": "We have analyzed the spectral and timing qualities of Cygnus X - 2 using data acquired with the Rossi X - ray Timing Explorer ( RXTE ) . The source was seen for about 100 ks during 1996 - 1997 , when it showed strong aperiodic variability on time ranges varied from milliseconds to hours .We see that the power concentration spectrum can be described by two parts ; one is flat below 10 Hz and another has an index of - 1 above this frequency . In addition we perceive pseudo - periodic oscillations at speeds around 300 Hz which are coherent over several hundred moments .Using these results as input parameters into our model matching methodology , we obtain good fits to both the power spectra and the light surfaces simultaneously . Our best - fitting models show that there exists a correlation between the temperature of the Comptonizing plasma and its optical thickness .This result suggests that the hard gas responsible for the hard X - ray radiation may also generate soft photons through cooling bremsstrahlung or synchrotron emission .",
        "rewrite_text": "We conducted an analysis of the spectral and timing characteristics of Cygnus X-2 using data gathered from the Rossi X-ray Timing Explorer (RXTE). The source was monitored for approximately 100 ks between 1996 and 1997, during which it exhibited strong aperiodic variability on timescales ranging from milliseconds to hours. Our findings indicate that the power density spectrum can be divided into two sections: a flat portion below 10 Hz and a segment with an index of -1 above this frequency. We also observed pseudo-periodic oscillations at approximately 300 Hz that maintain coherence over several hundred intervals. By incorporating these findings as input parameters into our model-fitting approach, we achieved good concordance with both the power spectra and the light curves simultaneously. The best-fitting models reveal a relationship between the temperature of the Comptonizing plasma and its optical thickness. This indicates that the hard gas contributing to the hard X-ray emission may also produce softer photons through processes such as cooling bremsstrahlung or synchrotron radiation.",
        "ori-fast-z-score": -0.23904572186687872,
        "water-fast-z-score": 5.5778737935111105,
        "rewrite-fast-z-score": 0.47140452079103173
    },
    {
        "original_text": "We present new results on the structure, rotation profiles, and magnetic activity of main-sequence stars with masses between 1 and 2 solar masses (M_sun). We use high-resolution spectropolarimetric observations obtained at the Canada-France-Hawaii Telescope to study the surface differential rotation of these stars as well as their large-scale magnetic fields. Our sample consists of eight young active stars that are members of open clusters or associations within 100 pc of Earth. The observed rotational periods range from 0.5 days up to several weeks. Using Zeeman-Doppler imaging techniques we reconstruct maps of the stellar surfaces for each star showing both the distribution of the longitudinal component of the magnetic field vector and the local line-of-sight velocity. These maps reveal significant differences among our targets. Some show strong toroidal components while others have more complex structures dominated by poloidal fields. In addition, some objects exhibit large regions where the magnetic field is nearly aligned with the axis of rotation.",
        "watermark_text": "We report new data on the composition , rotation profiles , and magnetic activity of primary - sequence stars with masses between 1 and 2 solar masses ( M _ sun ) . We use large - resolution spectropolarimetric instruments obtained at the Canada - France - Hawaii Telescope to study the surface differential rotation of these stars as also as their large - scale magnetic fields .Our specimen consists of eight young active stellar that are part of open complexes or associations within 100 pc of Earth . The observed rotational intervals varies from 0 . 5 weeks up to several weeks .Using Zeeman - Doppler imaging algorithms we reconstruct mapping of the stars surfaces for each star showing both the distribution of the longitudinal component of the magnetic field vector and the local point - of - view velocity . These maps discover considerable variations among our objectives .Some show strong toroidal components while many have more sophisticated shapes dominated by poloidal fields . In addition , some elements exhibit big regions where the magnetic force is almost oriented with the axis of rotation .",
        "rewrite_text": "We present new findings on the composition, rotation profiles, and magnetic activity of primary-sequence stars with masses ranging from 1 to 2 solar masses (\\(M_{sun}\\)). Utilizing high-resolution spectropolarimetric instruments at the Canada-France-Hawaii Telescope, we investigate the surface differential rotation of these stars, as well as their large-scale magnetic fields. Our sample includes eight young, active stars located within 100 parsecs of Earth, which are part of open clusters or associations. The observed rotation periods vary from 0.5 weeks to several weeks. By employing Zeeman-Doppler imaging algorithms, we create maps of the star surfaces for each specimen, displaying both the distribution of the longitudinal component of the magnetic field vector and the local line-of-sight velocity. These maps reveal significant variations among the stars in our sample. Some exhibit strong toroidal magnetic components, while others have more complex structures dominated by poloidal fields. Additionally, several stars display large areas where the magnetic field closely aligns with the rotation axis.",
        "ori-fast-z-score": -3.0193176496962755,
        "water-fast-z-score": 4.313310928137536,
        "rewrite-fast-z-score": -0.3144854510165755
    },
    {
        "original_text": "We study the dynamical stability properties of rapidly-rotating, axisymmetric neutron star models with different equations of state (EOS). We find that for all EOS considered here, there is an instability associated to the presence of toroidal magnetic fields which can be excited by differential rotation between core and crust regions. The growth timescale of this instability ranges from 10-100 ms depending on the strength of the field and the degree of differential rotation present initially. \n \n This instability may have important consequences for magnetar flares as well as for the spin evolution of young pulsars. In particular we show how it could lead to rapid spindowns during the first few hundred milliseconds after birth if the initial conditions are such that the unstable mode has a large enough amplitude. Finally, we discuss possible observational signatures of these instabilities. Dynamical non-axisymmetric modes in rapidly-rotating relativistic stars",
        "watermark_text": "We explore the dynamical stability properties of quickly - spinning , axisymmetric neutron star scenarios with various equations of state ( EOS ) . We see that for all EOS considered here , there is an instability related to the presence of toroidal magnetic waves which can be excited by differential rotation between core and crust regions .The growth timescale of this instability vary from 10 - 100 ms based on the strength of the field and the degree of differential rotation present initially . This instability may have important implications for magnetar flares as well as for the spin development of young pulsars .In particular we explain how it could lead to rapid spindowns during the first few hundred milliseconds after born if the first environments are such that the unstable mode has a large enough amplitude . Finally , we explain possible observational signatures of these instabilities .Dynamical non - axisymmetric configurations in rapidly - spinning relativistic stars",
        "rewrite_text": "We investigate the dynamical stability characteristics of rapidly spinning, axisymmetric neutron star models using a variety of equations of state (EOS). Our analysis reveals that all EOS examined exhibit an instability associated with toroidal magnetic waves, which can be triggered by differential rotation between the core and crust. The growth timescale for this instability ranges from 10 to 100 milliseconds, depending on the strength of the magnetic field and the initial degree of differential rotation. This instability may have significant implications for magnetar flares and the spin evolution of young pulsars. Specifically, we discuss how it could result in rapid spin-downs within the first few hundred milliseconds after a pulsar's formation, provided the initial conditions allow the unstable mode to reach a sufficiently large amplitude. Finally, we outline potential observational signatures of these instabilities in dynamically non-axisymmetric configurations of rapidly spinning relativistic stars.",
        "ori-fast-z-score": 1.3858697343671664,
        "water-fast-z-score": 5.921443410477893,
        "rewrite-fast-z-score": 0.48507125007266594
    },
    {
        "original_text": "We report on an observation made with the Hinode satellite that shows opposite magnetic polarities for two photospheric spectral lines (Fe I 630 nm and Fe I 525 nm) within one spatial resolution element at disk center. The observed phenomenon is explained by assuming that the line-of-sight component of the velocity field has opposite signs between these two lines, which can be caused by convective motions or by horizontal flows along the solar surface. This finding may have important implications to our understanding of the solar magnetism. \n \n We present observations obtained with the Solar Optical Telescope aboard Hinode (SOT; Tsuneta et al., 2008). In particular we use data taken during the first year of operation of SOT/SP (Solar Photometer), which consists of a spectrograph equipped with a slit scanning system. The SP instrument was designed primarily as a high-resolution imaging spectrometer but it also provides full-disk Stokes profiles of several photospheric lines simultaneously. For this study we used the Fe I 630 nm and FeI 525 nm lines, whose wavelengths are close enough so they appear together in each scan. These lines were scanned over a region of about 1 arcmin square centered around the solar disk center. Each scan took about 20 minutes to complete.",
        "watermark_text": "We report on an observation made with the Hinode satellite that displays parallel magnetic polarities for two photospheric spectral lines ( Fe I 630 nm and Fe I 525 nm ) within one spatial resolution element at disk center . The observed phenomenon is explained by assuming that the line - of - view component of the velocity field has opposite signs between these two lines , which can be caused by convective movements or by horizontal flows along the solar surface .This found may have important implications to our knowing of the thermal magnetism . We present observations collected with the Solar Optical Telescope aboard Hinode ( SOT ; Tsuneta et al . , 2008 ) .In particular we utilize measurements taken during the first year of operation of SOT / SP ( Solar Photometer ) , which consists of a spectrograph equipped with a slit scan system . The SP instrument was built mainly as a high - resolution optical spectrometer but it also provides whole - disk Stokes profiles of several photospheric lines simultaneously .For this study we using the Fe I 630 nm and FeI 525 nm lines , whose wavelengths are close enough so they appear together in each scan . These lines were scanned over a region of about 1 arcmin square centered around the solar disk center .Each scan took about 20 minutes to complete .",
        "rewrite_text": "We present an observation made with the Hinode satellite that reveals parallel magnetic polarities in two photospheric spectral lines (Fe I 630 nm and Fe I 525 nm) within a single spatial resolution element at disk center. This phenomenon can be explained by a velocity field in the line-of-sight component that has opposite signs for the two spectral lines, potentially due to convective activity or horizontal flows on the solar surface. This discovery could significantly enhance our understanding of thermal magnetism. The observations were gathered using the Solar Optical Telescope (SOT) aboard Hinode (Tsuneta et al., 2008). Specifically, we utilized data from the first year of operation of the Solar Photometer (SP), which features a high-resolution spectrograph with a slit scan system. While the SP instrument was primarily designed as a high-resolution optical spectrometer, it also captures whole-disk Stokes profiles of multiple photospheric lines simultaneously. In this study, we focused on the Fe I 630 nm and Fe I 525 nm lines, which are close enough in wavelength to be scanned together in each observation. The scanning was conducted over an area of approximately 1 arcmin² centered around the solar disk, with each scan taking about 20 minutes to complete.",
        "ori-fast-z-score": 2.919201796799047,
        "water-fast-z-score": 5.838403593598094,
        "rewrite-fast-z-score": 1.0425720702853738
    },
    {
        "original_text": "We present the discovery and analysis of two very massive stars (VMS) at z ~ 6, one with M = 260M☉ and another with M = 300M☉ . These are among the most massive known VMSs to date. We use near-infrared integral field spectroscopy obtained with SINFONI on the Very Large Telescope to study their kinematics and chemical composition. The stellar masses inferred for these objects suggest that they may be progenitors of supermassive black holes. This is consistent with our finding that both sources show evidence for outflows driven by radiation pressure. Our results demonstrate how high-redshift galaxies can provide important insights into the formation mechanisms of the first generation of massive stars as well as the growth of supermassive black hole seeds. Keywords: Black Hole Growth; First Stars; Galaxy Evolution; Stellar Population Studies; Supermassive Black Holes; Star Formation",
        "watermark_text": "We present the discovery and investigation of two very huge objects ( VMS ) at z ~ 6 , one with M = 260M☉ and another with M = 300M☉ . These are among the most large reported VMSs to date .We use near - infrared integral field spectroscopy derived with SINFONI on the Very Large Telescope to study their kinematics and chemical composition . The stellar ages inferred for these objects suggest that they may be progenitors of supermassive black holes .This is consistent with our discovery that both sources show proof for outflows driven by radiation stress . Our results show how high - redshift galaxies can provide important knowledge into the formation systems of the first generation of large galaxies as also as the development of supermassive black hole trees .Keywords: Black Hole Growth; First Stars; Galaxy Evolution; Stellar Population Studies; Supermassive Black Holes; Star Formation",
        "rewrite_text": "We report the discovery and examination of two exceptionally massive stars (VMS) at redshift z ~ 6, one with a mass of 260 M☉ and the other with 300 M☉. These objects are among the largest VMS reported to date. Utilizing near-infrared integral field spectroscopy obtained with SINFONI on the Very Large Telescope, we analyze their kinematics and chemical composition. The stellar ages inferred from our observations suggest that these stars could serve as progenitors of supermassive black holes. This finding aligns with our discovery of evidence indicating that both sources exhibit outflows driven by radiation pressure. Our results illuminate how high-redshift galaxies can enhance our understanding of the formation processes of the first generation of large galaxies and the growth of supermassive black holes. \nKeywords: Black Hole Growth; First Stars; Galaxy Evolution; Stellar Population Studies; Supermassive Black Holes; Star Formation.",
        "ori-fast-z-score": -0.565685424949238,
        "water-fast-z-score": 4.525483399593904,
        "rewrite-fast-z-score": 1.414213562373095
    },
    {
        "original_text": "We present the set of equations describing the process of transient enhanced diffusion (TED) in shallow implanted layers, which is important to understand and control dopant profiles during semiconductor device fabrication.  The model takes into account both the effects of lattice damage on TED as well as the effect of interstitials generated by the implantation itself. We show that this simple model can explain many experimental observations including the dependence of TED on dose rate, annealing temperature, and annealing time. Finally we use our model to predict the evolution of the dopant profile under different annealing conditions. Transient enhanced diffusion (TED), i.e., the redistribution of dopants after high energy implantation followed by rapid thermal annealing (RTA), has been studied extensively over the past two decades  1  . It is now widely accepted that the main driving force behind TED are point defects created by the implantation  2  , although other mechanisms such as vacancy clustering may also play an important role  3  .\nThe most commonly used models for simulating TED assume that all excess interstitials produced by the implantation are immobile at room temperature  4  . However, recent experiments have shown that some fraction of these interstitials become mobile even before RTA  5  . This mobility leads to additional dopant redistribution  6  . In addition, it was recently found that the amount of interstitials released depends strongly on the implantation dose rate  7, 8  . These results suggest that the current models do not fully capture the physics underlying TED.",
        "watermark_text": "We present the group of equations explaining the process of transient increased diffusion ( TED ) in superficial implanted layers , which is important to comprehend and control dopant profiles during semiconductor device fabrication . The model takes into consideration both the effects of lattice disruption on TED as well as the impact of interstitials generated by the implantation itself .We see that this straightforward model can describe several experimental phenomena including the dependence of TED on exposure frequency , annealing temperature , and annealing speed . Finally we utilize our model to predict the evolution of the dopant profile under various annealing conditions .Transient increased diffusion ( TED ) , i . e . , the redistribution of dopants after high energy implantation preceded by rapid heat annealing ( RTA ) , has been studied thoroughly over the previous two decades 1 . It is now widely accepted that the main driving force behind TED are point flaws produced by the implantation 2 , although other mechanisms such as vacancy clustering may also play an important role 3 .The most commonly used theories for simulating TED assume that all excess interstitials produced by the implantation are immobile at room temperature 4 . However , recent experiments have shown that some fraction of these interstitials become portable even before RTA 5 .This mobility contributes to extra dopant redistribution 6 . In addition , it was recently found that the quantity of interstitials released depends strongly on the implantation dose rate 7 , 8 .These data suggest that the present theories do not truly capture the physics underlying TED .",
        "rewrite_text": "We present a set of equations that elucidate the process of transient increased diffusion (TED) in superficially implanted layers, which is crucial for understanding and managing dopant profiles during semiconductor device fabrication. Our model accounts for the effects of lattice disruption on TED as well as the influence of interstitials generated by the implantation process itself. Notably, this straightforward model effectively describes various experimental phenomena, including the dependence of TED on exposure frequency, annealing temperature, and annealing speed. Additionally, we apply our model to forecast the evolution of the dopant profile under different annealing conditions. TED—characterized by the redistribution of dopants following high-energy implantation and subsequent rapid thermal annealing (RTA)—has been extensively studied over the past two decades. It is now broadly recognized that point defects generated by implantation serve as the primary driving force behind TED, although mechanisms such as vacancy clustering may also significantly contribute. The prevailing theories for simulating TED typically assume that all excess interstitials created during implantation are immobile at room temperature. However, recent studies indicate that a fraction of these interstitials can move even before RTA, contributing to additional dopant redistribution. Furthermore, it has been discovered that the amount of interstitials released is strongly influenced by the implantation dose rate. These findings imply that existing theories may not fully capture the underlying physics of TED.",
        "ori-fast-z-score": -0.09667364890456635,
        "water-fast-z-score": 6.343350474165466,
        "rewrite-fast-z-score": 1.3862065601673441
    },
    {
        "original_text": "We present an analysis of the linear stability of epitaxially self-assembled quantum dots (QDs) on semiconductor surfaces, which are grown by molecular beam epitaxy under conditions where QDs form spontaneously and in regular arrays. We show that the QD ordering is determined by two competing mechanisms: surface diffusion and strain relaxation. The former tends to smooth out the QD density profile while the latter leads to its steepening. In particular we find that for small values of the QD size dispersion there exists a critical value of the growth rate above which ordered QD arrays cannot be formed. This result explains why it has been so difficult to grow ordered QD arrays with large QD sizes using conventional techniques. \n \n Keywords: Ordering, Strain Relaxation, Surface Diffusion, Quantum Dot Arrays, Stability, Growth Rate, Molecular Beam Epitaxy \n \n 1 Introduction \n \n Semiconductor nanocrystals or quantum dots (QDs), also known as colloidal quantum dots, have attracted considerable attention due to their unique optical properties  1  . They can be used in optoelectronic devices such as light-emitting diodes  2  , lasers  3  , solar cells  4  , photodetectors  5  , etc., and they may even play important roles in biological systems  6  .\n \nThe most common method for growing QDs is based on the so-called Stranski-Krastanov process  7, 8  . It involves depositing a thin layer of material onto a substrate at high temperatures followed by annealing at lower temperatures. Under these conditions islands nucleate randomly over the entire sample area but then evolve into ordered arrays through Ostwald ripening  9  . However, this technique does not allow one to control the position of individual QDs within each array  10  . Recently developed methods  11, 12  enable us to produce highly ordered QD arrays; however, they require very precise temperature control during deposition  13  . \n \n 2 Model Description \n \n Here we consider a model describing the formation of QDs on a two-dimensional lattice. Our starting point is the continuum equation proposed by Tersoff et al.  14  :",
        "watermark_text": "We present an assessment of the linear stability of epitaxially self - assembled quantum dots ( QDs ) on semiconductor surfaces , which are grown by molecular wave epitaxy under environments where QDs form spontaneously and in regular arrays . We see that the QD ordering is chosen by two different processes : material absorption and strain relaxation .The first helps to smooth out the QD density profile while the second contributes to its steepening . In particular we find that for low values of the QD width dispersion there exists a critical value of the growth rate above which organized QD arrays cannot be formed .This result explains why it has been so difficult to develop ordered QD arrays with large QD sizes using conventional methods . Keywords : Ordering , Strain Relaxation , Surface Diffusion , Quantum Dot Arrays , Stability , Growth Rate , Molecular Beam Epitaxy 1 Introduction Semiconductor nanocrystals or quantum dots ( QDs ) , sometimes called as colloidal quantum dots , have garnered considerable scrutiny due to their extraordinary optical properties 1 .They can be used in optoelectronic equipment such as light - emitting diodes 2 , lasers 3 , solar cells 4 , photodetectors 5 , etc . , and they may even hold important roles in biological environments 6 . The most common method for growing QDs is based on the so - called Stranski - Krastanov process 7 , 8 .It involves depositing a thin layer of material onto a substrate at high temperatures followed by annealing at lower temperatures . Under these conditions islands nucleate randomly over the entire sample region but then evolve into organized arrays through Ostwald ripening 9 .However , this methodology does not enable one to affect the placement of individual QDs within each array 10 . Recently developed methods 11 , 12 enable us to produce fully ordered QD arrays ; however , they demand very exact heat control during deposition 13 .2 Model Description Here we imagine a description explaining the formation of QDs on a two - dimensional crystal . Our opening point is the continuum equation proposed by Tersoff et al .14  :",
        "rewrite_text": "We conduct an evaluation of the linear stability of quantum dots (QDs) that are self-assembled epitaxially on semiconductor surfaces, grown through molecular beam epitaxy in conditions where QDs can form spontaneously and in systematic arrays. Our findings indicate that the ordering of QDs is influenced by two distinct processes: material absorption and strain relaxation. The former aids in smoothing the QD density profile, while the latter leads to a sharper profile. Notably, we discover that when the QD width dispersion is low, there exists a critical growth rate beyond which organized arrays of QDs cannot be established. This insight sheds light on the challenges in achieving ordered QD arrays with larger sizes using traditional techniques. \n\n**Keywords:** Ordering, Strain Relaxation, Surface Diffusion, Quantum Dot Arrays, Stability, Growth Rate, Molecular Beam Epitaxy\n\n**1 Introduction:** Semiconductor nanocrystals, also known as colloidal quantum dots (QDs), have attracted significant attention due to their remarkable optical characteristics. They are applicable in various optoelectronic devices, including light-emitting diodes, lasers, solar cells, and photodetectors, and may play crucial roles in biological settings. The predominant method for growing QDs is the Stranski-Krastanov process, which involves depositing a thin film onto a substrate at elevated temperatures, followed by annealing at lower temperatures. Under these conditions, islands nucleate randomly across the sample but subsequently develop into organized arrays through Ostwald ripening. However, this method does not allow for precise control over the placement of individual QDs in each array. Recently developed techniques have enabled the production of fully ordered QD arrays, though they require precise thermal management during deposition.\n\n**2 Model Description:** We propose a framework for describing the formation of QDs on a two-dimensional crystal, beginning with the continuum equation formulated by Tersoff et al.",
        "ori-fast-z-score": -0.6069769786668839,
        "water-fast-z-score": 6.219852664185793,
        "rewrite-fast-z-score": 2.593838853899756
    },
    {
        "original_text": "We present the first exact solution for inflation in string theory, which is based on an explicit compactification to four dimensions with N=1 supergravity and chiral matter fields. The model contains two scalar fields, one of them being responsible for slow-roll inflation driven by its potential energy density. We show that this field can be identified as the inflaton. In addition we find another scalar field whose kinetic term has negative sign. This field may play the role of dark radiation during inflation. Finally, we discuss some phenomenological consequences of our results. Introduction: Inflation  1  provides a simple explanation for many puzzles associated with the early universe such as flatness, homogeneity and horizon problems  2  . It also predicts primordial fluctuations  3  , which are now confirmed by observations  4  .\nThe simplest models of inflation involve only one scalar field (inflaton) rolling slowly down its potential  5  . However it was shown recently  6  that there exist more general classes of inflationary scenarios where several scalars contribute to the total energy density driving inflation  7, 8  . These new possibilities open up interesting avenues towards understanding the physics behind inflation  9  .\nIn particular, if at least one of these scalars has positive kinetic energy then it leads to so-called k-inflation  10  . On the other hand, if all the scalars have negative kinetic energies they lead to so-called ghost inflation  11  . Both types of inflation were studied extensively in recent years  12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59  .\nIt should be noted however that most of these studies assume that the background geometry is given by Minkowski space-time or anti-de Sitter space-time  60, 61, 62, 63, 64, 65,",
        "watermark_text": "We introduce the first exact solution for inflation in string theory , which is based on an explicit compactification to four dimensions with N = 1 supergravity and chiral matter fields . The model includes two scalar fields , one of them being involved for slow - roll inflation driven by its potential energy density .We see that this field can be identified as the inflaton . In addition we find another scalar field whose kinetic term has negative sign .This field might play the importance of dark energy during inflation . Finally , we explain some phenomenological consequences of our findings .Introduction : Inflation 1 offers a simple explanation for numerous puzzles involved with the early world such as flatness , homogeneity and horizon problems 2 . It additionally predicts primordial fluctuations 3 , which are now confirmed by observed 4 .The simplest models of inflation include only one scalar field ( inflaton ) floating gradually down its potential 5 . However it was shown later 6 that there exist more general categories of inflationary scenarios where numerous scalars relate to the total energy density driving inflation 7 , 8 .These new possibilities open up interesting avenues towards studying the physics behind inflation 9 . In particular , if at least one of these scalars has positive kinetic power then it leads to so - called k - inflation 10 .On the other hand , if all the scalars have negative kinetic energies they lead to so - called ghost inflation 11 . Both types of inflation were studied thoroughly in recent seasons 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 .It should be mentioned however that most of these research assume that the background geometry is given by Minkowski space - time or anti - de Sitter space - time 60 , 61 , 62 , 63 , 64 , 65 ,",
        "rewrite_text": "We present the first exact solution for inflation within string theory, achieved through a clear compactification to four dimensions that incorporates \\(N = 1\\) supergravity and chiral matter fields. This model features two scalar fields, one of which is instrumental for slow-roll inflation as it is driven by its potential energy density. We identify this field as the inflaton. Furthermore, we discover another scalar field with a negative kinetic term, which may play a significant role as dark energy during inflation. Lastly, we discuss some phenomenological implications of our results.\n\n**Introduction:** Inflation provides a straightforward explanation for a variety of enigmas associated with the early universe, including flatness, homogeneity, and horizon problems. Additionally, it predicts primordial fluctuations, which have been supported by observational evidence. The simplest models of inflation rely on a single scalar field (the inflaton) that gradually descends its potential. However, it has been demonstrated that more general classes of inflationary scenarios exist, where multiple scalars contribute to the total energy density driving inflation. These new avenues offer intriguing opportunities to examine the underlying physics of inflation. Notably, if at least one of these scalars possesses a positive kinetic term, it results in what is known as k-inflation. Conversely, if all scalars exhibit negative kinetic energies, the scenario is termed ghost inflation. Both types of inflation have been extensively investigated in recent research. However, it is important to note that the majority of these studies assume that the background geometry is described by either Minkowski or anti-de Sitter space-time.",
        "ori-fast-z-score": -0.09090909090909091,
        "water-fast-z-score": 5.0,
        "rewrite-fast-z-score": 0.7302967433402214
    },
    {
        "original_text": "We present the results of our analysis on the polarization power spectrum in Bianchi type I cosmological models, which are anisotropic generalizations of standard FRW cosmologies. We find that there is no significant difference between the temperature fluctuations predicted by these two classes of models at large angular scales (low multipoles). However, we show that this is not true when one considers the polarization fluctuations. In particular, we demonstrate that the presence of an anisotropy parameter leads to a suppression of the low-l polarization power relative to the high-l part of the spectrum. This effect can be used as a test for distinguishing Bianchi type I models from their FRW counterparts. \n \n The observed lack of large-scale polarization in the WMAP data has been interpreted as evidence against inflationary scenarios with tensor perturbations. It was shown recently that such a conclusion may be premature if one takes into account possible deviations from statistical isotropy in the primordial universe. Indeed, it turns out that some anisotropic cosmological models predict less large-scale polarization than their isotropic counterparts do.",
        "watermark_text": "We present the conclusion of our analysis on the polarization power spectrum in Bianchi class I cosmological models , which are anisotropic generalizations of standard FRW cosmologies . We see that there is no major variation between the temperature fluctuations assumed by these two groups of models at large angular scales ( low multipoles ) .However , we prove that this is not true when one considers the polarization fluctuations . In particular , we prove that the presence of an anisotropy parameter causes to a suppression of the small - l polarization strength compared to the high - l part of the spectrum .This phenomenon can be used as a check for differentiate Bianchi class I theories from their FRW predecessors . The observed lack of large - scale polarization in the WMAP information has been viewed as proof against inflationary scenarios with tensor perturbations .It was shown lately that such a conclusion must be premature if one takes into consideration proposed deviations from statistical isotropy in the primordial universe . Indeed , it turns out that some anisotropic cosmological predictions predict less large - scale polarization than their isotropic counterparts do .",
        "rewrite_text": "We conclude our analysis of the polarization power spectrum in Bianchi class I cosmological models, which are anisotropic extensions of standard FRW cosmologies. Our findings indicate that there is no significant difference between the temperature fluctuations predicted by these two types of models at large angular scales (low multipoles). However, we demonstrate that this is not the case for polarization fluctuations. Specifically, we show that the presence of an anisotropy parameter leads to a suppression of small-l polarization strength compared to the high-l portion of the spectrum. This characteristic can serve as a distinguishing feature for differentiating Bianchi class I theories from their FRW counterparts. The observed absence of large-scale polarization in the WMAP data has been interpreted as evidence against inflationary models that include tensor perturbations. Recent findings suggest that this conclusion may be premature when considering potential deviations from statistical isotropy in the early universe. In fact, some predictions of anisotropic cosmological models indicate less large-scale polarization than their isotropic equivalents.",
        "ori-fast-z-score": -0.47809144373375745,
        "water-fast-z-score": 5.498051602938211,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We study the quantization of soliton systems in terms of their associated integrable hierarchies, which are infinite-dimensional Lie algebras with an underlying Poisson structure.  We show that these hierarchies can be realized as certain coadjoint orbits of loop groups over complex semisimple Lie groups.   The resulting quantum theories have many interesting features including nontrivial anomalies and non-perturbative effects such as instantons.    In particular we find that the partition functions for these models are closely related to automorphic forms on the corresponding groups; this is known as the Langlands correspondence between representations of the two groups.   This provides a new perspective on the relationship between gauge theory and string theory; it also suggests a possible connection between the Standard Model and M-theory. Solitons play important roles in physics ranging from condensed matter to particle and nuclear physics. They appear naturally in various physical contexts where nonlinear interactions occur, e.g., in fluid dynamics or field theories describing particles interacting via Yukawa potentials (e.g., quarks). A particularly rich class of solitonic solutions arises when one considers integrable systems whose equations of motion admit Lax pairs. These systems include classical mechanics, relativistic field theories, and supersymmetric Yang-Mills theories. Integrability implies that there exist infinitely many conserved quantities and allows us to construct exact solutions using inverse scattering techniques. It has been shown recently by Witten  1  , however, that even though most physically relevant systems cannot be solved exactly, they may still exhibit some aspects of integrability at the quantum level. For example, the low-energy effective action of N = 4 super-Yang-Mills theory is described by an integrable system  2  .",
        "watermark_text": "We research the quantization of soliton systems in terms of their identified integrable hierarchies , which are infinite - dimensional Lie algebras with an underlying Poisson system . We see that these hierarchies can be realized as certain coadjoint orbits of loop groups over complex semisimple Lie rings .The resulting quantum models have many interesting features including nontrivial anomalies and non - perturbative properties such as instantons . In particular we find that the splitting maps for these models are tightly related to automorphic forms on the associated groups ; this is known as the Langlands correspondence between representations of the two groups .This offers a new insight on the relationship between gauge theory and string theory ; it also supports a possible link between the Standard Model and M - theory . Solitons serve major roles in science ranging from condensed matter to quantum and nuclear mechanics .They arise naturally in different mechanical environments where nonlinear interactions occur , e . g . , in flow dynamics or field theories describing particles interacting via Yukawa potentials ( e . g . , quarks ) . A notably rich family of solitonic solutions arises when one studies integrable systems whose equations of movement accept Lax pairs .These systems include theoretical physics , relativistic field theories , and supersymmetric Yang - Mills theories . Integrability implies that there exist infinitely many conserved particles and allows us to build exact solutions using inverse scattering methods .It has been shown lately by Witten 1 , however , that even though most legally important structures cannot be solved exactly , they may still exhibit some details of integrability at the quantum level . For instance , the small - energy effective operation of N = 4 super - Yang - Mills theory is characterized by an integrable system 2 .",
        "rewrite_text": "We investigate the quantization of soliton systems through their established integrable hierarchies, which consist of infinite-dimensional Lie algebras associated with an underlying Poisson structure. These hierarchies can be interpreted as specific coadjoint orbits of loop groups connected to complex semisimple Lie algebras. The quantum models derived from this framework exhibit a variety of intriguing characteristics, including significant anomalies and non-perturbative phenomena like instantons. Notably, we discover that the splitting maps in these models are closely tied to automorphic forms on the relevant groups, highlighting the Langlands correspondence between their representations. This provides fresh insights into the interplay between gauge theory and string theory and suggests a potential connection between the Standard Model and M-theory. Solitons play crucial roles across various scientific disciplines, from condensed matter physics to quantum and nuclear mechanics. They naturally emerge in diverse mechanical settings characterized by nonlinear interactions, such as fluid dynamics and field theories that describe particles interacting via Yukawa potentials (for instance, quarks). A particularly rich array of solitonic solutions appears when examining integrable systems defined by equations of motion that possess Lax pairs. These systems encompass theoretical physics, relativistic field theories, and supersymmetric Yang-Mills theories. Integrability signifies the existence of infinitely many conserved quantities and facilitates the construction of exact solutions using inverse scattering techniques. Recently, however, Witten has demonstrated that while most crucial structures cannot be solved exactly, they still retain certain integrable features at the quantum level. For example, the low-energy effective action of N = 4 super-Yang-Mills theory is governed by an integrable system.",
        "ori-fast-z-score": 0.6069769786668839,
        "water-fast-z-score": 7.251743670286615,
        "rewrite-fast-z-score": 1.153563462240948
    },
    {
        "original_text": "We report on the optical investigation of single self-assembled InAs/GaAs quantum dots (QDs) in an external magnetic field applied along their growth direction. The QD emission line splits into two components with opposite circular polarization when the magnetic field is increased to about 1 T, which corresponds to the Zeeman splitting energy of 0.5 meV at 4 K. We observe that this splitting increases linearly as temperature decreases down to 20 mK and then saturates below 10 mK. This behavior can be explained by taking into account both electron-hole exchange interaction and phonon-assisted relaxation processes between different excitonic states within QDs. Our results show that the spin-flip time for electrons confined inside QDs is longer than 100 ns even under high magnetic fields up to 5 T. Quantum dot (QD), also known as semiconductor nanocrystal or artificial atom, has attracted much attention due to its unique physical properties such as size-tunable band gap  1  , strong confinement effect  2  , and large oscillator strength  3  . These features make it possible to use QDs as building blocks for various optoelectronic devices including light-emitting diodes  4  , lasers  5  , solar cells  6  , photodetectors  7  , and so forth  8  .\nIn recent years, there have been many efforts devoted to investigating the spin dynamics of carriers confined in QDs  9  -  11  . It was found that the carrier spins are very stable against decoherence caused by environmental noise  12  -  14  . However, the spin flip times were reported to vary widely depending on experimental conditions  15  -  17  . For example, the spin lifetimes of holes  18  and electrons  19  confined in QDs were measured to be several nanoseconds using pulsed excitation techniques. On the other hand, the spin lifetime of electrons  20  and holes  21  confined in QDs could reach microsecond level if continuous wave laser was used instead.",
        "watermark_text": "We report on the optical study of single self - assembled InAs / GaAs quantum dots ( QDs ) in an external magnetic current applied along their development path . The QD absorption system separates into two parts with opposite spherical polarization when the magnetic field is expanded to about 1 T , which corresponds to the Zeeman splitting energy of 0 . 5 meV at 4 K . We determine that this splitting changes linearly as temperature grows down to 20 mK and then saturates below 10 mK .This phenomenon can be described by take into consideration both electron - hole exchange behavior and phonon - aided vibration mechanisms between various excitonic states within QDs . Our results show that the spin - flip time for electrons trapped inside QDs is longer than 100 ns even under high magnetic waves up to 5 T . Quantum dot ( QD ) , sometimes called as semiconductor nanocrystal or artificial electron , has garnered considerable scrutiny due to its unique physical properties such as size - tunable band gap 1 , large confinement phenomenon 2 , and large oscillator strength 3 .These features make it able to use QDs as building blocks for various optoelectronic applications notably light - emitting diodes 4 , lasers 5 , solar cells 6 , photodetectors 7 , and so forth 8 . In recent seasons , there have been many efforts devoted to investigating the spin behavior of carriers restricted in QDs 9 - 11 .It was shown that the carrier spins are very stable against decoherence caused by environmental noise 12 - 14 . However , the spin flip times were reported to vary widely depending on experimental environments 15 - 17 .For instance , the spin lifetimes of holes 18 and electrons 19 restricted in QDs were calculated to be several nanoseconds using pulsed excitation techniques . On the other hand , the spin lifetime of electrons 20 and holes 21 confined in QDs might reach microsecond level if continuous wave beam was used instead .",
        "rewrite_text": "We present findings from an optical examination of single self-assembled InAs/GaAs quantum dots (QDs) subjected to an external magnetic current applied along their growth direction. When the magnetic field is increased to approximately 1 T, corresponding to a Zeeman splitting energy of 0.5 meV at 4 K, the QD absorption spectrum splits into two components with opposite circular polarization. We observe that this splitting exhibits a linear dependence on temperature up to 20 mK, before saturating below 10 mK. This behavior can be explained by considering both the exchange interactions between electrons and holes, as well as phonon-assisted vibrations among different excitonic states within the QDs. Our data indicate that the spin-flip time for electrons confined in QDs exceeds 100 ns, even in high magnetic fields reaching 5 T. Quantum dots—which are also referred to as semiconductor nanocrystals or artificial atoms—have attracted significant interest due to their distinctive physical characteristics, including size-tunable band gaps, strong confinement effects, and high oscillator strengths. These traits position QDs as essential components in a range of optoelectronic applications, including light-emitting diodes, lasers, solar cells, and photodetectors. In recent years, considerable research has focused on the spin dynamics of carriers confined in QDs. It has been demonstrated that carrier spins display remarkable stability against decoherence from environmental noise. However, reported spin-flip times vary greatly depending on the experimental conditions. For example, pulsed excitation techniques have estimated the spin lifetimes of holes and electrons in QDs to be several nanoseconds. In contrast, when using continuous wave excitation, the spin lifetimes of both electrons and holes confined in QDs can extend to the microsecond range.",
        "ori-fast-z-score": 0.9330078226479681,
        "water-fast-z-score": 7.209605902279753,
        "rewrite-fast-z-score": -1.2909944487358056
    },
    {
        "original_text": "We present new near-infrared photometry for the open cluster Westerlund 1, which is located in the Galactic bulge at a distance of 8 kpc (projected). We find that the red giant branch tip lies at K = 12.6 mag, corresponding to an age of about 10 Gyrs. The main sequence turn-off point occurs around K = 14.5 mag, indicating an age between 5 and 7 Gyrs. This places it among the oldest open clusters known. Using our data we derive a mean metallicity  Fe/H  = -1.3 ± 0.1 dex. From this value and using theoretical models we estimate the mass of the most massive star in the cluster as Mmax = 120 - 140M⊙. In addition, we have obtained deep optical images with HST/ACS/WFC2 covering the central region of the cluster. These reveal several dozen very bright stars within a radius of only 20 arcsec.",
        "watermark_text": "We introduce novel near - infrared photometry for the open cluster Westerlund 1 , which is situated in the Galactic bulge at a distance of 8 kpc ( projected ) . We see that the red giant branch tip exists at K = 12 . 6 mag , equivalent to an age of about 10 Gyrs .The main series turn - off point happens around K = 14 . 5 mag , showing an age between 5 and 7 Gyrs . This places it among the earliest open clusters recorded .Using our information we derive a mean metallicity Fe / H = - 1 . 3 ± 0 . 1 dex . From this value and using theoretical models we estimate the mass of the most massive star in the cluster as Mmax = 120 - [UNK] .In addition , we have achieved dark optical images with HST / ACS / WFC2 covering the main region of the cluster . These show numerous dozen very bright stars within a diameter of only 20 arcsec .",
        "rewrite_text": "We present new near-infrared photometry for the open cluster Westerlund 1, located in the Galactic bulge at a projected distance of 8 kpc. Our observations reveal that the tip of the red giant branch is found at K = 12.6 mag, indicating an age of approximately 10 Gyr. The main sequence turn-off point is observed around K = 14.5 mag, suggesting an age between 5 and 7 Gyr. This positions Westerlund 1 among the oldest recorded open clusters. From our data, we calculate a mean metallicity of Fe/H = -1.3 ± 0.1 dex. Utilizing this value alongside theoretical models, we estimate the mass of the most massive star in the cluster to be Mmax = 120 - [UNK]. Furthermore, we have captured dark optical images with HST/ACS/WFC2 that cover the central region of the cluster, revealing dozens of very bright stars within a diameter of just 20 arcseconds.",
        "ori-fast-z-score": -2.6726124191242437,
        "water-fast-z-score": 2.363515791475006,
        "rewrite-fast-z-score": -1.0690449676496976
    },
    {
        "original_text": "The author suggests that the concept of  photon  is not necessary, because it can be explained by other concepts such as  wave particle duality  or  duality  in general.  The author also suggests that the concept of  free electron  should be replaced with the concept of  fermion  which has more physical meaning than free electrons do. Finally he proposes to use the term  quantum fields  instead of quantum particles for describing elementary particles. This article was originally published at http://arxiv.org/abs/physics/0407033 . It may have been updated since then; please check the original version s date before citing. Authors:  Toshihide Maskawa (Masatoshi Koshiba) - Professor Emeritus, University of Tokyo \n \n \n \n Abstract: \nThe author suggests that the idea of photon is unnecessary, because it can be understood by other concepts like wave-particle duality or dualities in general. He also suggests replacing the concept of  free-electron  with the concept of  fermion  which has more physical meaning. Finally he proposes using the term  quatum-fields  instead of quatum-particles for describing elementary particles.",
        "watermark_text": "The author argues that the notion of photon is not required , because it can be described by other concepts such as wave particle duality or duality in general . The author also concludes that the notion of free particle should be replaced with the notion of fermion which has more physical purpose than free electrons do .Finally he proposes to use the term quantum fields instead of quantum particles for describing elementary particles . This section was originally published at http : / / arxiv . org / abs / physics / 0407033 .It might have been altered since then ; please check the original version s date before citing . Authors : Toshihide Maskawa ( Masatoshi Koshiba ) - Professor Emeritus , University of Tokyo Abstract : The author argues that the idea of photon is unnecessary , because it can be understood by other concepts like wave - particle duality or dualities in general .He also supports replacing the notion of free - atom with the notion of fermion which has more physical context . Finally he proposes using the term quatum - fields instead of quatum - particles for describing elementary particles .",
        "rewrite_text": "The author contends that the concept of a photon is not essential, as it can be adequately explained through other ideas such as wave-particle duality or dualities in general. Additionally, the author suggests that the term \"free particle\" should be replaced with \"fermion,\" which serves a more significant role in physics than free electrons. Lastly, the author recommends adopting the term \"quantum fields\" instead of \"quantum particles\" when referring to elementary particles. This section was initially published at http://arxiv.org/abs/physics/0407033. It may have been modified since then, so please verify the original document's date before citing. Authors: Toshihide Maskawa (Masatoshi Koshiba) - Professor Emeritus, University of Tokyo.",
        "ori-fast-z-score": 1.9629909152447274,
        "water-fast-z-score": 6.423640548375729,
        "rewrite-fast-z-score": 0.8660254037844387
    },
    {
        "original_text": "We study the effect on cluster abundance and Sunyaev-Zeldovich (SZ) power spectrum due to primordial non-Gaussianity in the context of inflationary models with an additional scalar field, which is responsible for driving cosmic acceleration at late times. We find that the SZ power spectrum can be used as a probe of both primordial non-Gaussianity and dark energy properties such as equation-of-state parameter w0 and its time-derivative wa. In particular we show how these parameters affect the amplitude and shape of the SZ power spectrum. The results are presented using a simple analytical model based on perturbation theory upto second order. This work will help us understand better the nature of dark energy by combining it with other probes like supernovae Ia data or CMB anisotropy measurements. It also provides useful information about the physics of inflation through primordial non-Gaussianity. Introduction:-Inflation  1  , one of the most successful paradigms in modern cosmology, predicts a nearly scale-invariant Gaussian distribution of density fluctuations  2  . However recent observations  3  have shown some deviations from this prediction indicating possible presence of primordial non-Gaussianities  4  .\nIn addition to explaining the origin of large-scale structure formation  5  , inflation has been proposed  6  as a mechanism for generating the observed accelerated expansion of the universe  7, 8  . Inflationary scenarios predict that there should exist another light scalar field besides inflaton  9  , called quintessence  10  , which drives the current accelerating phase of the universe  11  . Quintessential inflation  12  is a class of inflationary models where the role played by the inflaton during inflation is taken over by quintessence after inflation ends  13  . These two fields interact minimally  14  leading to interesting consequences  15  . For example, if the potential of quintessence is sufficiently flat then it may lead to eternal inflation  16  . If so, then our observable patch of the universe would correspond only to a tiny fraction of all space-time  17  . Another possibility is that the quintessence field decays into radiation  18  thereby reheating the universe  19  .",
        "watermark_text": "We research the impact on cluster abundance and Sunyaev - Zeldovich ( SZ ) power spectrum attributed to primordial non - Gaussianity in the context of inflationary theories with an additional scalar field , which is responsible for driving cosmic acceleration at late times . We see that the SZ power spectrum can be used as a investigation of both primordial non - Gaussianity and dark energy properties such as equation - of - state variable w0 and its time - derivative wa .In particular we explain how these parameters control the frequency and shape of the SZ power spectrum . The results are presented using a simple analytical theory based on perturbation theory upto second order .This effort will assist us explain better the nature of dark energy by combining it with other probes like supernovae Ia data or CMB anisotropy observations . It additionally offers helpful info about the physics of inflation through primordial non - Gaussianity .Introduction : - Inflation 1 , one of the most innovative paradigms in modern cosmology , predicts a nearly scale - invariant Gaussian distribution of density fluctuations 2 . However recent observations 3 have shown some deviations from this forecast suggesting possible presence of primordial non - Gaussianities 4 .In addition to describing the origin of large - scale structure formed 5 , inflation has been proposed 6 as a process for generating the known rapid expansion of the universe 7 , 8 . Inflationary scenarios predict that there should exist another dark scalar field besides inflaton 9 , called quintessence 10 , which drives the present accelerating phase of the universe 11 .Quintessential inflation 12 is a class of inflationary theories where the part played by the inflaton during inflation is taken over by quintessence after inflation ends 13 . These two fields interact minimally 14 causing to useful consequences 15 .For instance , if the potential of quintessence is sufficiently flat then it could lead to eternal inflation 16 . If so , then our observable patch of the universe might correspond only to a small fraction of all space - time 17 .Another possibility is that the quintessence field decays into radiation 18 effectively reheating the universe 19 .",
        "rewrite_text": "We investigate how primordial non-Gaussianity affects cluster abundance and the Sunyaev-Zeldovich (SZ) power spectrum within inflationary theories that include an additional scalar field, responsible for driving cosmic acceleration in the present era. Our findings suggest that the SZ power spectrum serves as a valuable tool for probing both primordial non-Gaussianity and the characteristics of dark energy, including the equation of state parameters \\( w_0 \\) and \\( w_a \\). Specifically, we describe how these parameters influence the frequency and shape of the SZ power spectrum, using a straightforward analytical framework based on second-order perturbation theory. This research will enhance our understanding of dark energy by integrating it with other observational data, such as Type Ia supernovae and cosmic microwave background anisotropies. Additionally, it provides insights into the physics of inflation through the lens of primordial non-Gaussianity.\n\n**Introduction:** Inflation, a groundbreaking model in contemporary cosmology, predicts a nearly scale-invariant Gaussian distribution of density fluctuations. However, recent observations have revealed deviations from this prediction, indicating the potential existence of primordial non-Gaussianities. In addition to elucidating the origins of large-scale cosmic structures, inflation has also been proposed as a mechanism behind the observed rapid expansion of the universe. Theories of inflation suggest the existence of another dark scalar field, known as quintessence, alongside the inflaton, which drives the current accelerating expansion of the universe. Quintessential inflation refers to a category of inflationary models where the inflaton's role transitions to that of quintessence after inflation concludes. These two fields interact minimally, leading to significant implications. For example, if the quintessence potential is sufficiently flat, it could result in eternal inflation. This would imply that our observable portion of the universe is merely a small segment of the entire space-time continuum. Alternatively, the quintessence field may decay into radiation, effectively reheating the universe.",
        "ori-fast-z-score": -0.0842151921066519,
        "water-fast-z-score": 6.6530001764255,
        "rewrite-fast-z-score": 1.01418510567422
    },
    {
        "original_text": "In this work, we propose an efficient watermarking scheme for digital images based on the discrete wavelet transform (DWT). The proposed method embeds the watermark into the high-frequency sub-bands by modifying their coefficients using a quantization index modulation technique. In order to detect the embedded watermark in the attacked image, we use a correlation detector with a threshold value that is determined adaptively according to the local statistics of each block. Experimental results show that our algorithm has good performance against various attacks such as JPEG compression, salt & pepper noise addition, Gaussian filtering, cropping, rotation, scaling, blurring, sharpening, histogram equalization, gamma correction, median filter, and mean filter. Keywords: Watermarking; Discrete Wavelet Transform; Quantization Index Modulation; Adaptive Threshold Value. Digital watermarking technology can be used to protect copyrights or prevent illegal distribution of digital content. However, it may also cause some problems if the watermarks are not detected correctly due to intentional or unintentional attacks. Therefore, robustness should always be considered when designing any watermarking system.",
        "watermark_text": "In this research , we propose an efficient watermarking scheme for digital photographs relying on the discrete wavelet transform ( DWT ) . The proposed approach embeds the watermark into the high - frequency sub - bands by modifying their coefficients utilizing a quantization index modulation method .In order to identify the embedded watermark in the attacked image , we utilize a correlation detector with a threshold expression that is calculated adaptively based to the local statistics of each block . Experimental findings show that our technique has good success against several attacks such as JPEG compression , salt & pepper noise addition , Gaussian filtering , cropping , rotation , scaling , blurring , sharpening , histogram equalization , alpha reduction , median filter , and average filter .Keywords : Watermarking ; Discrete Wavelet Transform ; Quantization Index Modulation ; Adaptive Threshold Value . Digital watermarking technology can be used to shield copyrights or avoid illegal distribution of digital content .However , it could also create some problems if the watermarks are not noticed correctly due to deliberate or unintentional hits . Therefore , robustness should always be included when designing any watermarking scheme .",
        "rewrite_text": "In this study, we introduce an effective watermarking technique for digital photographs that utilizes the discrete wavelet transform (DWT). Our method integrates the watermark within the high-frequency sub-bands by altering their coefficients through a quantization index modulation approach. To detect the embedded watermark in distorted images, we employ a correlation detector with an adaptively calculated threshold based on the local statistics of each block. Experimental results demonstrate that our method is resilient against various attacks, including JPEG compression, salt-and-pepper noise, Gaussian filtering, cropping, rotation, scaling, blurring, sharpening, histogram equalization, alpha reduction, median filtering, and average filtering. Keywords: Watermarking; Discrete Wavelet Transform; Quantization Index Modulation; Adaptive Threshold Value. Digital watermarking technology plays a critical role in protecting copyrights and preventing unauthorized distribution of digital content. However, challenges may arise if watermarks are not accurately detected due to intentional or accidental interference. Therefore, ensuring robustness is essential in the design of any watermarking scheme.",
        "ori-fast-z-score": -1.1470786693528088,
        "water-fast-z-score": 5.888972745734182,
        "rewrite-fast-z-score": 0.11867816581938533
    },
    {
        "original_text": "The standard model (SM) is the most successful theory in particle physics, but it has some problems such as hierarchy problem and CP violation. In this talk I will discuss how we can solve these problems by using string theories. First let us consider the SM with three generations of quarks and leptons. The Yukawa couplings are given by \nwhere  is the Higgs vacuum expectation value,  is the mass matrix for fermions ,  is the CKM mixing matrix , and  is the Kobayashi-Maskawa(KM) matrix . We have two parameters in the KM matrix : one phase which causes CP violation and another parameter called Jarlskog invariant J = Im VudVub * / Re VudIm Vub .\nIn order to explain the observed CP violation in K meson system, we need at least one complex number in the KM matrix. However there are only four real numbers in the Yukawa coupling matrices. This means that we cannot determine all elements of the KM matrix uniquely. Therefore we introduce extra dimensions into our models so that we can obtain more degrees of freedom.",
        "watermark_text": "The conventional model ( SM ) is the most efficient model in particle theory , but it has some problems such as hierarchy problem and CP violation . In this talk I will explore how we can answer these problems by using string theories .First let us consider the SM with three generations of quarks and leptons . The Yukawa couplings are given by where is the Higgs vacuum expectation parameter , is the mass vector for fermions , is the CKM mixing function , and is the Kobayashi - Maskawa ( KM ) matrix .We have two parameters in the KM matrix : one phase which causes CP violation and another parameter called Jarlskog invariant J = Im VudVub * / Re VudIm Vub . In order to explain the observed CP violation in K meson scheme , we require at least one complex number in the KM matrix .However there are only four real numbers in the Yukawa interaction matrices . This implies that we never determine all members of the KM matrix uniquely .Therefore we incorporate additional dimensions into our models so that we can obtain more degrees of liberty .",
        "rewrite_text": "The Standard Model (SM) is the most effective framework in particle theory, but it faces certain challenges, including the hierarchy problem and CP violation. In this presentation, I will discuss potential solutions to these issues through the lens of string theories. We start by examining the SM, which includes three generations of quarks and leptons. The Yukawa couplings can be expressed in terms of the Higgs vacuum expectation value, the fermion mass vector, the CKM mixing matrix, and the Kobayashi-Maskawa (KM) matrix. Within the KM matrix, there are two parameters: one phase associated with CP violation and a second parameter known as the Jarlskog invariant, expressed as J = Im(VudVub*) / Re(Vud)Im(Vub). To account for the CP violation observed in the K meson system, at least one complex number must be present in the KM matrix. However, the Yukawa interaction matrices only contain four real parameters, meaning that we cannot uniquely determine all elements of the KM matrix. To address this limitation, we introduce additional dimensions to our models to gain more degrees of freedom.",
        "ori-fast-z-score": 0.25,
        "water-fast-z-score": 4.093146241443879,
        "rewrite-fast-z-score": -1.0533703247651751
    },
    {
        "original_text": "We present results on testing different outer boundary conditions in numerical relativity, using two black hole spacetimes as testbeds.  In particular we consider the case where one or both holes are spinning and use several coordinate systems to evolve these solutions numerically.   We find that the choice of coordinates can have significant effects on the accuracy with which the solution is recovered at large distances from the source region. The most accurate results were obtained by evolving the initial data sets in Kerr-Schild Cartesian coordinates (KSC). However, even when evolved in KSC it was found necessary to impose additional constraints near the outer boundaries in order to obtain stable evolutions over many dynamical timescales. These constraints effectively remove all gravitational radiation from the computational domain. Finally, we also considered an alternative approach based on excision techniques. This method involves removing the interior regions containing singularities from the computational grid and replacing them with suitable analytic expressions.",
        "watermark_text": "We report findings on proving different exterior boundary parameters in mathematical relativity , using two black hole spacetimes as testbeds . In particular we study the case where one or both holes are twisting and use multiple coordinate networks to evolve these solutions numerically .We see that the selection of coordinates can have considerable effects on the accuracy with which the solve is recovered at large distances from the origin region . The most accurate conclusions were obtained by expanding the early data sets in Kerr - Schild Cartesian coordinates ( KSC ) .However , even when evolved in KSC it was found necessary to apply additional constraints near the exterior walls in order to obtain stable evolutions over numerous dynamical timescales . These limitations virtually remove all gravity radiation from the theoretical domain .Finally , we also considered an additional method using on excision techniques . This method means eliminating the interior regions containing singularities from the theoretical grid and combining them with suitable analytic expressions .",
        "rewrite_text": "We present our findings on establishing various exterior boundary parameters in mathematical relativity through two black hole spacetimes as test cases. Specifically, we examine scenarios where one or both black holes are rotating and employ multiple coordinate systems to numerically evolve these solutions. Our results indicate that the choice of coordinates significantly impacts the accuracy of the solutions, particularly at large distances from the region of interest. The highest accuracy was achieved by expanding the initial data sets in Kerr-Schild Cartesian coordinates (KSC). However, even when evolving in KSC, we found it necessary to impose additional constraints near the outer boundaries to ensure stable evolutions across multiple dynamical timescales. These limitations effectively eliminate all gravitational radiation from the theoretical framework. Finally, we explored an alternative approach using excision techniques, which involves removing the interior regions containing singularities from the computational grid and replacing them with appropriate analytic expressions.",
        "ori-fast-z-score": -1.3416407864998738,
        "water-fast-z-score": 7.509343773089564,
        "rewrite-fast-z-score": 0.1125087900926024
    },
    {
        "original_text": "We present an algorithm for computing geometrical characteristics of chaotic trajectories in dynamical systems, which is based on the concept of the alignment index introduced by S.A. Afraimovich and A.V. Bykov.  The proposed approach allows one to study the geometry of invariant manifolds associated with unstable periodic orbits embedded into the phase space of a given dynamical system. We demonstrate that this new technique can be successfully applied to investigate the structure of strange attractors arising in dissipative systems as well as in conservative ones. In particular, we show how it works for the Lorenz model and the Henon-Heiles potential. \nThe presented results are obtained within the framework of the Russian Science Foundation project 14-50-00040. Geometrical properties of local dynamic in hamiltonian systems: the generalized alignment index (gali) method  V.I. Klimenko1 , D.N. Kozlov2 1 Institute of Mathematics RAS, Moscow, Russia 2 Lomonosov Moscow State University, Moscow, Russia",
        "watermark_text": "We introduce an algorithm for modeling geometrical characteristics of turbulent trajectories in dynamical systems , which is based on the idea of the alignment index introduced by S . A . Afraimovich and A . V . Bykov .The proposed approach allows one to study the topology of invariant manifolds associated with unstable periodic orbits embedded into the phase space of a given dynamical system . We showed that this new technique can be successfully utilized to examine the composition of odd attractors arising in dissipative models as well as in conservative ones .In particular , we prove how it works for the Lorenz model and the Henon - Heiles potential . The published results are derived within the framework of the Russian Science Foundation program 14 - 50 - 00040 .Geometrical properties of local dynamic in hamiltonian systems : the generalized alignment index ( gali ) method V . I . Klimenko1 , D . N .Kozlov2 1 Institute of Mathematics RAS, Moscow, Russia 2 Lomonosov Moscow State University, Moscow, Russia",
        "rewrite_text": "We present an algorithm designed to model the geometrical features of turbulent trajectories within dynamical systems, inspired by the alignment index developed by S. A. Afraimovich and A. V. Bykov. This innovative approach facilitates the exploration of the topology of invariant manifolds linked to unstable periodic orbits within the phase space of a specified dynamical system. Our findings demonstrate that this technique can effectively analyze the structures of odd attractors that emerge in both dissipative and conservative models. Specifically, we validate its application to the Lorenz model and the Henon-Heiles potential. The results outlined here are part of the research supported by the Russian Science Foundation program 14-50-00040. The geometrical properties of local dynamics in Hamiltonian systems are examined using the generalized alignment index (GALI) method, as explored by V. I. Klimenko and D. N. Kozlov from the Institute of Mathematics RAS and Lomonosov Moscow State University, respectively.",
        "ori-fast-z-score": 0.2626128657194451,
        "water-fast-z-score": 4.201805851511121,
        "rewrite-fast-z-score": 0.6622661785325219
    },
    {
        "original_text": "We present the results of our study on the electronic structure and magnetic properties of La0.7Sr1.3MnO3 using density functional theory (DFT) calculations within the local spin-density approximation (LSDA). We find that LSDA underestimates the band gap by about 0.5 eV, which is corrected to 1.2 eV when we use the self-interaction correction scheme proposed by Perdew et al.. Our calculated value agrees well with experimental data obtained from optical measurements. In addition, we have studied the effect of electron correlation on the ground state energy as a function of Ueff = U - J where U and J are respectively Coulomb repulsion and exchange parameters between two localized spins. It has been found that the total energy decreases monotonically upto Ueff ~ 3 eV beyond which it increases rapidly indicating strong electron correlations among Mn3+ ions. Finally, we show that the inclusion of spin-orbit coupling leads to an increase in the band gap by about 30%.",
        "watermark_text": "We publish the conclusion of our research on the electronic configuration and magnetic properties of La0 . 7Sr1 . 3MnO3 using density functional theory ( DFT ) estimates within the local spin - density approximation ( LSDA ) . We see that LSDA underestimates the band gap by about 0 . 5 eV , which is corrected to 1 . 2 eV when we using the self - interaction correction scheme proposed by Perdew et al . . Our measured measure agrees well with theoretical data received from optical study .In addition , we have researched the impact of electron correlation on the ground state energy as a function of Ueff = U - J where U and J are respectively Coulomb repulsion and transfer characteristics between two localized spins . It has been seen that the total energy decreases monotonically upto Ueff ~ 3 eV beyond which it rises rapidly indicating strong electron correlations among Mn3 + ions .Finally , we find that the introduction of spin - orbit resonance results to an increase in the band gap by about 30 % .",
        "rewrite_text": "We present the conclusions of our research on the electronic configuration and magnetic properties of La0.7Sr1.3MnO3, utilizing density functional theory (DFT) estimates based on the local spin-density approximation (LSDA). Our findings indicate that LSDA underestimates the band gap by approximately 0.5 eV, which is corrected to 1.2 eV when applying the self-interaction correction scheme suggested by Perdew et al. Our measurements are consistent with theoretical data obtained from optical studies. Furthermore, we investigated the effect of electron correlation on the ground state energy as a function of U_eff = U - J, where U represents Coulomb repulsion and J characterizes the transfer between two localized spins. It was observed that the total energy decreases monotonically up to U_eff ~ 3 eV, beyond which it increases sharply, signifying strong electron correlations among Mn3+ ions. Lastly, we discovered that incorporating spin-orbit coupling leads to an increase in the band gap by roughly 30%.",
        "ori-fast-z-score": -1.5650160901149996,
        "water-fast-z-score": 4.063777271736939,
        "rewrite-fast-z-score": 1.0834726777719228
    },
    {
        "original_text": "We present the results of an analysis of the supersymmetric standard model with minimal supergravity boundary conditions at the grand unification scale, including all one-loop corrections to gauge and Yukawa couplings as well as two-loop contributions to the running of the soft supersymmetry breaking parameters.  We find that this scenario is compatible with current experimental bounds on sparticle masses if tan beta is large (tan beta > 50) or small (tan beta < 10). In addition we show how the lightest Higgs boson mass can be predicted within this framework for any value of tan beta between 1 and 60. Finally, we discuss the implications of our results for future searches for supersymmetry at colliders such as LHC. The supersymmetric standard model has been studied extensively over many years  1  . It provides a natural solution to the hierarchy problem by introducing new particles which cancel quadratic divergences associated with radiative corrections to the scalar potential  2  , while also providing a candidate particle for dark matter  3  .\nIn recent years there have been several studies  4  -  8  investigating whether it is possible to construct models where the electroweak symmetry breaking sector is described by the MSSM  9  but the underlying physics is governed by some more fundamental theory valid at higher energies. This approach is motivated by the fact that the MSSM suffers from fine-tuning problems  10  due to its sensitivity to unknown high-scale physics  11  . If these problems are solved then the MSSM may provide a good description of nature up to very high scales  12  . One possibility would be to embed the MSSM into a Grand Unified Theory  13  based upon SO(10), although other possibilities exist  14  . Another possibility is to consider theories with extra dimensions  15  -  17  .",
        "watermark_text": "We present the conclusion of an assessment of the supersymmetric standard theory with minimal supergravity boundary constraints at the grand unified scale , comprising all one - loop corrections to gauge and Yukawa couplings as also as two - loop contributions to the running of the hard supersymmetry broken equations . We see that this situation is compatible with current experimental bounds on sparticle masses if tan beta is huge ( tan beta > 50 ) or small ( tan beta < 10 ) .In addition we prove how the lightest Higgs boson weight can be predicted within this framework for any value of tan beta between 1 and 60 . Finally , we explain the implications of our findings for future investigations for supersymmetry at colliders such as LHC .The supersymmetric standard description has been studied frequently over much years 1 . It provides a natural solution to the ranking problem by using new particles which cancel quadratic divergences associated with radiative corrections to the scalar potential 2 , while also offering a candidate particle for black material 3 .In recent years there have been numerous research 4 - 8 investigating whether it is easy to build theories where the electroweak symmetry breaking sector is modeled by the MSSM 9 but the underlying dynamics is governed by some more fundamental theory valid at higher energies . This method is prompted by the fact that the MSSM suffers from fine - tuned difficulty 10 due to its sensitivity to unknown long - scale physics 11 .If these problems are answered then the MSSM could give a better model of nature up to very high scales 12 . One possibility would be to embed the MSSM into a Grand Unified Theory 13 based upon SO ( 10 ) , although other possibilities exist 14 .Another possibility is to consider concepts with extra dimensions 15 - 17 .",
        "rewrite_text": "We present the findings from an evaluation of the supersymmetric standard model under minimal supergravity boundary conditions at the grand unified scale. This analysis includes all one-loop corrections to both gauge and Yukawa couplings, as well as two-loop contributions to the evolution of the equations that break supersymmetry. Our results indicate that the scenario aligns with current experimental limits on sparticle masses when tan β is either very large (tan β > 50) or very small (tan β < 10). Furthermore, we demonstrate how the mass of the lightest Higgs boson can be predicted within this framework for any tan β value ranging from 1 to 60. Lastly, we discuss the implications of our results for future research into supersymmetry at colliders like the LHC.\n\nThe supersymmetric standard model has been extensively studied over the years. It offers a natural solution to the hierarchy problem by introducing new particles that cancel out the quadratic divergences associated with radiative corrections to the scalar potential, while also providing a candidate for dark matter. Recently, there has been a surge of research exploring the feasibility of constructing theories in which the electroweak symmetry breaking sector is described by the MSSM, but the underlying dynamics are dictated by a more fundamental theory applicable at higher energies. This investigation is motivated by the fine-tuning issues associated with the MSSM, which arise from its sensitivity to unaccounted long-scale physics. Addressing these challenges could allow the MSSM to serve as a more accurate representation of nature at extremely high energy scales. One avenue for this could involve embedding the MSSM within a Grand Unified Theory based on SO(10), though alternative approaches also exist. Additionally, examining theories that incorporate extra dimensions has been proposed as another interesting direction.",
        "ori-fast-z-score": 0.2683281572999747,
        "water-fast-z-score": 7.184212081070997,
        "rewrite-fast-z-score": -0.44367825470805694
    },
    {
        "original_text": "The measurement was performed at the Cyclotrons and Accelerators Laboratory (CYCLONE) in JINR, Dubna using the proton beam with energy E = 1 GeV. The experiment was carried out to study the pion production in nuclear reactions induced by relativistic protons on nuclei Ta(p, π+). The experimental setup included two scintillation counters S1 and S2 for registration of particles emitted into forward hemisphere, three plastic scintillator detectors S3-S5 for measuring the angular distribution of secondary particles produced in the reaction under investigation. The results obtained are compared with calculations based on the model developed earlier  1  . \nIntroduction\n\nPion production is one of the most important processes in hadronic interactions which play an essential role in many fields such as astrophysics  2  , cosmic ray physics  3  , accelerator technology  4  etc.. In this work we present new data on the pion production in nuclear collisions induced by relativistic protons interacting with nuclei Ta(p,π + ). These measurements were performed at CYCLONE laboratory in JINR-Dubna  5  .\nExperimental Setup\nThe experimental setup used in our experiments consisted of:  -two scintillation counters S1 and S2; -three plastic scintillator detectors; -a set of collimators; -the target made of natural tantalum foil 0.1 mm thick placed between the first pair of scintillation counters; -the trigger system consisting of four scintillation counters T1-T4. \nThe layout of the experimental setup is shown schematically in Fig. 1 . The main parameters of the detector system are listed in Table I . The signals from all detectors were recorded by means of CAMAC modules  6  .",
        "watermark_text": "The measurement was done at the Cyclotrons and Accelerators Laboratory ( CYCLONE ) in JINR , Dubna utilizing the proton beam with energy E = 1 GeV . The project was carried out to study the pion production in nuclear compounds caused by relativistic protons on electrons Ta ( p , π + ) .The demonstration system featured two scintillation terminals S1 and S2 for registration of grains generated into front hemisphere , three plastic scintillator detectors S3 - S5 for monitoring the angular distribution of secondary particles generated in the response under research . The results derived are compared with observations based on the model derived earlier 1 .Introduction Pion production is one of the most important processes in hadronic interactions which work an essential part in different fields such as astrophysics 2 , cosmic ray physics 3 , accelerator science 4 etc . . In this study we present new data on the pion production in nuclear collisions induced by relativistic protons interacting with nuclei Ta ( p , π + ) .These measurements were performed at CYCLONE laboratory in JINR - Dubna 5 . Experimental Setup The demonstration system employed in our experiments included of : - two scintillation bars S1 and S2 ; - three plastic scintillator detectors ; - a pair of collimators ; - the target made of natural tantalum foam 0 . 1 mm thick put between the first row of scintillation counters ; - the trigger system consisting of four scintillation counters T1 - T4 .The configuration of the experimental setup is demonstrated schematically in Fig . 1 .The main variables of the sensor system are listed in Table I . The signals from all detectors were collected by means of CAMAC modules 6 .",
        "rewrite_text": "The measurement was conducted at the Cyclotrons and Accelerators Laboratory (CYCLONE) in JINR, Dubna, using a proton beam with an energy of E = 1 GeV. The goal of the project was to investigate pion production in nuclear compounds as a result of relativistic protons interacting with tantalum nuclei in the reaction Ta (p, π+). The experimental setup included two scintillation counters, S1 and S2, for detecting particles produced in the front hemisphere, and three plastic scintillator detectors, S3 to S5, to observe the angular distribution of the secondary particles generated during the reaction under study. The results obtained were compared with previous observations based on an earlier model. Pion production is a crucial process in hadronic interactions, playing a significant role in various fields such as astrophysics, cosmic ray physics, and accelerator science. This study presents new data on pion production in nuclear collisions induced by relativistic protons interacting with tantalum nuclei, specifically Ta (p, π+), which were obtained at the CYCLONE laboratory in JINR-Dubna. \n\n**Experimental Setup:**\nThe experimental system utilized in our investigation comprised: \n- Two scintillation bars, S1 and S2\n- Three plastic scintillator detectors \n- A pair of collimators \n- A natural tantalum foam target, 0.1 mm thick, positioned between the first row of scintillation counters \n- A trigger system made up of four scintillation counters, T1 to T4 \n\nA schematic diagram of the experimental setup is shown in Fig. 1. The main specifications of the sensor system are summarized in Table I, and the signals from all detectors were captured using CAMAC modules.",
        "ori-fast-z-score": 0.8867963503478639,
        "water-fast-z-score": 7.784101297497916,
        "rewrite-fast-z-score": 2.288585537482975
    },
    {
        "original_text": "We present new results on the long-term evolution of solar magnetic fields, obtained by applying an advanced data analysis technique to observations made with the Wilcox Solar Observatory (WSO) magnetograph between 1976 and 2009. The method is based on wavelet transforms in combination with principal component analysis (PCA). It allows us to separate different types of variability into their individual components at each point in time. We find that there are two distinct modes of solar magnetic field evolution over this period. One mode shows strong fluctuations around a mean value which varies slowly but significantly during the cycle 23/24 minimum. This behaviour can be explained as being due to the presence of large-scale dynamo waves driven by differential rotation. In addition we identify another type of variation which appears to have no preferred frequency or spatial scale. These variations show significant correlations with sunspot number and other proxies for solar activity. They may therefore represent some form of global response of the Sun s magnetic field to changes in its internal dynamics.",
        "watermark_text": "We report new data on the long - term expansion of solar magnetic waves , obtained by using an sophisticated data analysis technique to observations made with the Wilcox Solar Observatory ( WSO ) magnetograph between 1976 and 2009 . The method is based on wavelet transforms in combination with principal component analysis ( PCA ) .It enables us to separate distinct types of variability into their individual parts at each point in time . We see that there are two different paths of solar magnetic force evolution over this time .One mode displays large fluctuations around a mean value which varies steadily but significantly during the period 23 / 24 minimum . This behaviour can be understood as being owing to the presence of large - scale dynamo waves generated by differential rotation .In addition we identify another type of variation which appears to have no dominant amplitude or geographic range . These changes demonstrate considerable correlations with sunspot number and other proxies for solar activity .They might hence indicate some kind of worldwide response of the Sun s magnetic force to changes in its internal motion .",
        "rewrite_text": "We present new findings on the long-term evolution of solar magnetic waves, derived from advanced data analysis techniques applied to observations from the Wilcox Solar Observatory (WSO) magnetograph between 1976 and 2009. Our approach utilizes wavelet transforms combined with principal component analysis (PCA), allowing us to isolate distinct types of variability at each moment in time. Our analysis reveals two separate trajectories in the evolution of solar magnetic forces during this period. One trajectory is characterized by significant fluctuations around a mean value that steadily varies during the solar minimum between cycles 23 and 24. This behavior can be attributed to large-scale dynamo waves generated by differential rotation. Additionally, we identify another variation type that lacks a dominant amplitude or geographic influence. These fluctuations show strong correlations with sunspot numbers and other indicators of solar activity, suggesting a global response of the Sun's magnetic forces to changes in its internal dynamics.",
        "ori-fast-z-score": 0.43133109281375365,
        "water-fast-z-score": 7.763959670647566,
        "rewrite-fast-z-score": 1.4814874939752933
    },
    {
        "original_text": "We consider the possibility that our universe underwent two stages of accelerated expansion, first hybrid inflation and then modular inflation.  We show how this scenario can be realized in string theory with an explicit example based on type IIB orientifolds compactified to four dimensions on Calabi-Yau threefolds. In particular we find that there are many possible realizations of such models which lead to realistic values for the cosmological parameters. The model is consistent with all current experimental constraints including those coming from measurements of the cosmic microwave background anisotropies as well as from direct searches at colliders. Finally we discuss some phenomenological aspects of these scenarios. Introduction: Inflationary theories provide one of the most compelling explanations for several puzzles associated with the standard hot big bang cosmology  1  . They predict that primordial quantum fluctuations generated during inflation should have left their imprint on the temperature anisotropies observed today in the Cosmic Microwave Background (CMB)  2  .\nIn recent years it has been shown that supersymmetric grand unified theories (GUTs), like SO(10) , naturally give rise to inflationary potentials  3  , while also providing a successful unification scheme  4  . However, GUT scale inflation suffers from the so-called η-problem  5  : the predicted value of the tensor-to-scalar ratio r = 16ǫ H /η 2  6  leads to too large CMB quadrupole anisotropies  7, 8  unless ǫ H ≪ 1  9  or η ≫ 10 −9  10  . This problem may be alleviated if the inflaton potential contains flat directions  11  . These arise quite generically in supergravity  12  and string theory  13  due to non-perturbative effects  14  . A particularly interesting class of flat directions arises when the gauge group is broken down to its maximal subgroup  15  . Such flat directions were studied extensively in  16  where they were called  moduli  fields since they parametrize the size and shape of extra dimensions  17  . Moduli fields play an important role in string theory  18  because they determine the vacuum expectation values of various moduli fields appearing in the low energy effective action  19 ",
        "watermark_text": "We consider the prospect that our universe underwent two stages of rapid expansion , initially hybrid inflation and then modular expansion . We see how this situation can be realized in string theory with an explicit instance relying on type IIB orientifolds compactified to four dimensions on Calabi - Yau threefolds .In particular we find that there are many potential realizations of such theories which lead to accurate values for the cosmological values . The model is compatible with all present observation constraints especially those coming from measurements of the cosmic microwave source anisotropies as well as from direct searches at colliders .Finally we explain some phenomenological aspects of these scenarios . Introduction : Inflationary theories presented one of the most compelling reasons for numerous puzzles involved with the standard hot large bang cosmology 1 .They predict that primordial particle fluctuations experienced during inflation should have left their imprint on the temperature anisotropies witnessed presently in the Cosmic Microwave Background ( CMB ) 2 . In recent years it has been shown that supersymmetric grand unified fields ( GUTs ) , like SO ( 10 ) , naturally make rise to inflationary potentials 3 , while also offering a successful unification scheme 4 .However , GUT scale inflation suffers from the so - called η - problem 5 : the expected value of the tensor - to - scalar ratio r = 16ǫ H / ε 2 6 leads to too huge CMB quadrupole anisotropies 7 , 8 unless ǫ H [UNK] 1 9 or η [UNK] 10 −9 10 . This problem could be alleviated if the inflaton potential contains flat directions 11 .These occur quite generically in supergravity 12 and string theory 13 owing to non - perturbative factors 14 . A notably important family of flat angles arises when the gauge group is shattered down to its maximal subgroup 15 .Such flat angles were studied frequently in 16 where they were called moduli fields since they parametrize the height and shape of added dimensions 17 . Moduli fields work an important role in string theory 18 because they predict the vacuum expectation values of several moduli fields appearing in the small power effective action 19",
        "rewrite_text": "We explore the possibility that our universe experienced two phases of rapid expansion: first, hybrid inflation, followed by modular expansion. This scenario can be realized within string theory, particularly through type IIB orientifolds compactified to four dimensions on Calabi-Yau threefolds. We identify numerous potential formulations of these theories that yield reliable predictions for cosmological parameters. The model aligns well with existing observational constraints, notably those derived from measurements of cosmic microwave background (CMB) anisotropies and direct searches at particle colliders. Additionally, we discuss some phenomenological implications of these scenarios. \n\nIntroduction: Inflationary theories provide compelling explanations for several challenges related to standard hot big bang cosmology. They suggest that primordial particle fluctuations during inflation have left a lasting imprint on the temperature anisotropies we observe today in the Cosmic Microwave Background (CMB). Recent developments have shown that supersymmetric grand unified theories (GUTs), such as SO(10), can naturally generate inflationary potentials while also facilitating successful unification schemes. However, GUT-scale inflation encounters the so-called η-problem, where the expected tensor-to-scalar ratio (r = 16ε_H / ε²) results in excessively large CMB quadrupole anisotropies unless ε_H is approximately 1 or η is around 10^-9. This challenge might be mitigated if the inflaton potential contains flat directions, which frequently arise in both supergravity and string theory due to non-perturbative effects. A particularly important class of flat directions emerges when the gauge group is broken down to its maximal subgroup. These flat directions, often referred to as moduli fields, have been extensively studied as they characterize the shape and height of additional dimensions. Moduli fields play a crucial role in string theory by determining the vacuum expectation values of several moduli in the low-energy effective action.",
        "ori-fast-z-score": -0.7373087284671365,
        "water-fast-z-score": 6.754444207800623,
        "rewrite-fast-z-score": 0.50709255283711
    },
    {
        "original_text": "We present the results of an optical to infrared multiwavelength survey of a sample of 12 massive (M* > 10 11 Msun) galaxies in the redshift range 1.9 < z < 2.7, selected using their rest-frame UV colors as Lyman-break analogs. We use deep near-infrared spectroscopy with Keck/NIRSPEC to measure stellar masses for these objects, which are found to be between 3 x 10 11 and 5 x 10 11 Msun. The majority of our targets show evidence for strong starburst activity based on their high equivalent width  OIII  emission lines and large Balmer decrements indicative of dusty star-forming regions. Using Spitzer/IRAC photometry we find that most of these systems have red mid-infrared colors consistent with those expected for evolved stellar populations. However, two of our sources appear bluer than this trend suggesting they may contain significant amounts of obscured AGN activity.",
        "watermark_text": "We present the conclusion of an optical to infrared multiwavelength survey of a sample of 12 huge ( M * > 10 11 Msun ) galaxies in the redshift region 1 . 9 < z < 2 . 7 , selected using their rest - frame UV colors as Lyman - break analogs . We use deep near - infrared spectroscopy with Keck / NIRSPEC to measure stellar masses for these objects , which are found to be between 3 x 10 11 and 5 x 10 11 Msun .The majority of our targets show proof for strong starburst activity based on their high equivalent height OIII emission lines and large Balmer decrements indicative of dusty star - creating areas . Using Spitzer / IRAC photometry we find that most of these systems have red middle - infrared colors consistent with those expected for advanced stellar regions .However , two of our sources appear bluer than this shift suggesting they may contain significant amounts of distorted AGN activity .",
        "rewrite_text": "We present the findings from an optical to infrared multiwavelength survey of a sample of 12 massive galaxies (M* > 10^11 M☉) located in the redshift range of 1.9 < z < 2.7. These galaxies were selected based on their rest-frame UV colors as Lyman-break analogs. Utilizing deep near-infrared spectroscopy with Keck/NIRSPEC, we measured their stellar masses, which range between 3 x 10^11 and 5 x 10^11 M☉. Most of our targets exhibit evidence of intense starburst activity, as indicated by their strong OIII emission lines and large Balmer decrements, which point to dusty star-forming regions. Additionally, Spitzer/IRAC photometry reveals that the majority of these systems display red mid-infrared colors consistent with advanced stellar regions. However, two of the sources appear bluer, suggesting they may host significant amounts of disrupted AGN activity.",
        "ori-fast-z-score": 2.604729426373378,
        "water-fast-z-score": 5.0854241181575475,
        "rewrite-fast-z-score": 1.6378460497066512
    },
    {
        "original_text": "We present an algorithm to find galaxy groups using photometric redshifts, which is based on the Voronoi tessellation technique (VT). The VT method has been widely used for identifying clusters of galaxies with spectroscopic redshifts but it had not yet been applied to identify galaxy groups with photometric redshifts. We use the Sloan Digital Sky Survey data release five (SDSS DR5) as our input sample. Our results show that the VT method can be successfully applied to identify galaxy groups even when only photometric redshifts are available. In this work we have identified more than 12000 galaxy groups at 0 < z < 0.3. These groups contain about 30000 member galaxies. We also provide a catalog containing basic information such as positions, magnitudes, colors, and photometric redshifts for all these groups. \n \n Keywords: Galaxy Group, Photometric Redshift",
        "watermark_text": "We present an algorithm to find galaxy groups using photometric redshifts , which is based on the Voronoi tessellation method ( VT ) . The VT method has been widely using for finding clusters of stars with spectroscopic redshifts but it had not already been used to identify galaxy groups with photometric redshifts .We use the Sloan Digital Sky Survey data release five ( SDSS DR5 ) as our input data . Our results show that the VT method can be successfully applied to identify galaxy groups even when only photometric redshifts are available .In this research we have discovered more than 12000 star groups at 0 < z < 0 . 3 . These groups contain about 30000 member galaxies .We additionally offer a list containing essential information such as positions , magnitudes , colors , and photometric redshifts for all these groups . Keywords : Galaxy Group , Photometric Redshift",
        "rewrite_text": "We introduce an algorithm for identifying galaxy groups using photometric redshifts, leveraging the Voronoi tessellation (VT) method. While the VT method has been extensively utilized for detecting star clusters with spectroscopic redshifts, it has not been previously applied to pinpoint galaxy groups with photometric redshifts. Our analysis utilizes data from the Sloan Digital Sky Survey Data Release Five (SDSS DR5). Our findings demonstrate that the VT method can effectively reveal galaxy groups, even in cases where only photometric redshifts are available. In this study, we have identified over 12,000 star groups within the redshift range of 0 < z < 0.3, encompassing approximately 30,000 member galaxies. Furthermore, we provide a comprehensive list containing key details such as positions, magnitudes, colors, and photometric redshifts for all identified groups. Keywords: Galaxy Group, Photometric Redshift.",
        "ori-fast-z-score": -1.2602520756252087,
        "water-fast-z-score": 3.2206441932644223,
        "rewrite-fast-z-score": 0.42857142857142855
    },
    {
        "original_text": "Superhumps are periodic modulations in the light curves of some cataclysmic variables (CVs). They have been observed to occur during both the high and low states, but their origin is still not understood. In this work we present comprehensive numerical simulations of CVs with mass ratios q = 0.7-0.9 that include tidal dissipation effects as well as magnetic braking. We find that for systems with orbital periods P orb < 3 hr, the inclusion of magnetic braking leads to an increase in the amplitude of the superhumps by up to a factor of two compared to previous results obtained without magnetic braking. For longer period systems, however, our models predict smaller amplitudes than those inferred observationally. This discrepancy may be due to additional physical processes such as irradiation or enhanced mass transfer rates at periastron passage which were neglected here. \n \n Keywords: Cataclysmic Variables",
        "watermark_text": "Superhumps are regular modulations in the light curves of some cataclysmic variables ( CVs ) . They have been observed to arise during both the high and low states , but their source is nevertheless not explained .In this research we present comprehensive numerical simulations of CVs with mass factors q = 0 . 7 - 0 . 9 that include tidal dissipation effects as well as magnetic braking . We see that for systems with orbital periods P orb < 3 hr , the introduction of magnetic braking contributes to an increase in the frequency of the superhumps by up to a factor of two compared to previous findings obtained without magnetic braking .For longer time systems , however , our calculations predict smaller amplitudes than those inferred observationally . This discrepancy may be due to extra physical processes such as irradiation or improved mass transfer rates at periastron passage which were neglected here .Keywords: Cataclysmic Variables",
        "rewrite_text": "Superhumps are periodic variations observed in the light curves of certain cataclysmic variables (CVs). Although they have been detected during both high and low states, their underlying cause remains unclear. In this study, we present detailed numerical simulations of CVs with mass ratios ranging from q = 0.7 to 0.9, incorporating tidal dissipation effects as well as magnetic braking. Our findings indicate that for systems with orbital periods less than 3 hours, the inclusion of magnetic braking leads to a doubling in the frequency of superhumps compared to earlier results obtained without considering magnetic braking. In contrast, for systems with longer orbital periods, our simulations predict smaller amplitudes than those observed. This discrepancy may be attributed to additional factors, such as irradiation or enhanced mass transfer rates at periastron, which were not taken into account in this analysis. \n\nKeywords: Cataclysmic Variables",
        "ori-fast-z-score": 0.39735970711951313,
        "water-fast-z-score": 5.165676192553671,
        "rewrite-fast-z-score": 0.12403473458920847
    },
    {
        "original_text": "We have identified a sample of candidate hidden Seyfert galaxies by searching for X-ray sources with hard spectra (Γ < 1) and high luminosities (Lx > 1043 erg s-1). We find that these objects are preferentially located at redshifts z ~ 0.7, where they can be detected only if their intrinsic absorption is NH < 1023 cm-2 . The majority of our candidates show no optical counterparts down to R = 25 mag on deep ground-based images; however, we do detect faint emission lines characteristic of AGN activity in some cases. Our results suggest that there may exist many more obscured active galactic nuclei than previously thought. This work was supported by NASA grant NAG5-7262. \n \n Keywords: Active Galactic Nuclei, Galaxy Evolution, X-Ray Astronomy \n \n Introduction \n \n In recent years it has become clear that most bright quasars reside in massive elliptical galaxies or bulges of spiral galaxies (e.g., McLure & Dunlop 2001), but the nature of the host galaxy remains unknown because of heavy dust extinction along the line-of-sight. It is possible that many optically-faint quasars are hosted by less-massive systems such as late-type spirals and/or low-luminosity ellipticals (e.g., Hao et al. 2005). \n \n To understand how supermassive black holes grow over cosmic time, it is important to study both unobscured and obscured active galactic nucleus (AGNs) across a wide range of environments. However, identifying heavily-absorbed AGNs is difficult due to the lack of strong spectral features associated with them. One way to identify absorbed AGNs is through their X-ray properties. For example, Compton-thick AGNs are characterized by very flat X-ray continua and large equivalent widths of iron Kα fluorescence lines (EW>500 eV) (see e.g., Risaliti 2002). Another method is based on the fact that absorbed AGNs tend to exhibit higher X-ray-to-optical flux ratios compared to normal galaxies (e.g..",
        "watermark_text": "We have discovered a sample of candidate hidden Seyfert galaxies by searching for X - ray bodies with rough spectra ( Γ < 1 ) and large luminosities ( Lx > 1043 erg s - 1 ) . We see that these objects are preferentially found at redshifts z ~ 0 . 7 , where they can be spotted only if their intrinsic absorption is NH < 1023 mm - 2 .The majority of our candidates indicate no optical rivals down to R = 25 mag on dark earth - based images ; however , we do spot faint absorption patterns characteristic of AGN activity in some cases . Our results propose that there may contain many more obscured active galactic nuclei than previously thought .This project was supported by NASA grant NAG5 - 7262 . Keywords : Active Galactic Nuclei , Galaxy Evolution , X - Ray Astronomy Introduction In recent months it has become clear that most bright quasars operate in massive elliptical galaxies or bulges of spiral galaxies ( e . g . , McLure & Dunlop 2001 ) , but the nature of the host universe appears unknown because of large dust extinction along the line - of - view .It is suggested that several optically - faint quasars are hosted by less - massive structures such as mid - class spirals and / or low - luminosity ellipticals ( e . g . , Hao et al . 2005 ) .To understand how supermassive black holes expand over cosmic time , it is important to study both unobscured and distorted active galactic nucleus ( AGNs ) across a broad variety of habitats . However , identifying strongly - absorption AGNs is complicated due to the lack of large spectral features linked with them .One method to identify absorption AGNs is through their X - ray characteristics . For instance , Compton - thick AGNs are characterized by very flat X - ray continua and large equivalent widths of iron Kα fluorescence bands ( EW > 500 eV ) ( saw e . g . , Risaliti 2002 ) .Another method is based on the fact that absorbed AGNs prefer to contain higher X - ray - to - optical flux proportions compared to normal galaxies ( e . g . .",
        "rewrite_text": "We have identified a selection of candidate hidden Seyfert galaxies by investigating X-ray sources with low spectral slopes (Γ < 1) and high luminosities (Lx > 10^43 erg s^-1). Our findings suggest that these objects are predominantly located at redshifts around z ~ 0.7, and can only be detected if their intrinsic absorption is NH < 10^23 mm^-2. Most of our candidates do not have optical counterparts down to R = 25 mag in dark, ground-based images; however, we have observed faint absorption features consistent with AGN activity in some instances. Our results indicate that there are likely many more obscured active galactic nuclei than previously recognized. This research was funded by NASA grant NAG5-7262. \n\nKeywords: Active Galactic Nuclei, Galaxy Evolution, X-Ray Astronomy \n\nIntroduction: Recent studies have revealed that most bright quasars are found in massive elliptical galaxies or the bulges of spiral galaxies (e.g., McLure & Dunlop 2001), yet the details of their host environments remain unclear due to significant dust extinction along the line of sight. It is proposed that some optically faint quasars may reside in less massive structures such as mid-size spirals and/or low-luminosity ellipticals (e.g., Hao et al. 2005). To understand the growth of supermassive black holes over cosmic timescales, it is crucial to explore both unobscured and obscured active galactic nuclei (AGNs) across a diverse range of settings. However, identifying heavily obscured AGNs is challenging due to the absence of prominent spectral features typically associated with them. One approach to detect obscured AGNs is by analyzing their X-ray properties. For example, Compton-thick AGNs exhibit very flat X-ray continua and large equivalent widths of iron Kα fluorescence lines (EW > 500 eV) (see, e.g., Risaliti 2002). Another detection method is based on the tendency of absorbed AGNs to have higher X-ray-to-optical flux ratios compared to normal galaxies (e.g., …).",
        "ori-fast-z-score": 0.0842151921066519,
        "water-fast-z-score": 8.116397748309229,
        "rewrite-fast-z-score": 1.0722219284950194
    },
    {
        "original_text": "The magnetization, susceptibility, and specific heat measurements were performed on the single crystals of TbFe3( BO3 )4 . The magnetic properties are analyzed in terms of the crystal-field splitting scheme for Tb3+ ions. It is found that the ground state doublet has an Ising-like anisotropy along c-axis with gz = 8.0 ± 0.1 , which leads to the large spontaneous polarization ( Ps ~ 1μC/cm2 ). The calculated results reproduce well the experimental data except for the low-temperature part of the specific-heat curve below 2 K. This discrepancy may be attributed to the presence of impurities or defects in our samples. \n \n Keywords: Magnetism; Crystal field theory; Specific heat measurement; Susceptibility measurement; Single-crystal growth; Anisotropic magnetoresistance effects; Polarized neutron scattering \n \n \n \n INTRODUCTION : \nTbFe 3 (BO 3 ) 4 belongs to the family of rare-earth iron borates RFe 3 (BO 3 ) (R = Y, Yb, Lu). These compounds have attracted much attention because they exhibit various interesting physical phenomena such as ferroelectricity  1  , multiferroicity  2  , colossal magnetoresistance  3  , and quantum critical behavior  4  .\nIn particular, TbFe 3 (BO 3 )\n4 exhibits a giant spontaneous polarization P s ~ 1 μ C / cm 2 at room temperature  5  due to its unique crystal structure  6  . In this compound, Fe atoms form a three-dimensional network of corner-sharing tetrahedra by sharing their apical oxygen atoms  7   . On the other hand, Tb atoms occupy two different sites, i.e., one site surrounded by eight O atoms forming a square antiprismatic coordination polyhedron  8  and another site surrounded by six O atoms forming a trigonal prismatic coordination polyhedron  9  . As shown in Figs. 1 (a) and (b), these two types of polyhedra share common faces perpendicularly to the c -axis  10  .",
        "watermark_text": "The magnetization , susceptibility , and particular heat measurements were performed on the single crystals of TbFe3 ( BO3 ) 4 . The magnetic properties are examined in terms of the crystal - field separation scheme for Tb3 + ions .It is found that the ground state doublet has an Ising - like anisotropy along c - axis with gz = 8 . 0 ± 0 . 1 , which results to the big induced polarization ( Ps ~ 1μC / cm2 ) . The measured data reproduce well the laboratory information except for the high - temperature half of the specific - temperature curve below 2 K . This discrepancy may be due to the presence of impurities or flaws in our specimens .Keywords : Magnetism ; Crystal field description ; Specific temperature measurement ; Susceptibility measurement ; Single - crystal growth ; Anisotropic magnetoresistance effects ; Polarized neutron scattering INTRODUCTION : TbFe 3 ( BO 3 ) 4 belongs to the group of rare - earth iron borates RFe 3 ( BO 3 ) ( R = Y , Yb , Lu ) . These compounds have garnered great popularity because they demonstrate several interesting physical phenomena such as ferroelectricity 1 , multiferroicity 2 , colossal magnetoresistance 3 , and quantum fundamental behavior 4 .In particular , TbFe 3 ( BO 3 ) 4 displays a giant spontaneous polarization P s ~ 1 μ C / cm 2 at room temperature 5 due to its unique crystal formation 6 . In this compound , Fe molecules form a three - dimensional network of spot - sharing tetrahedra by sharing their apical oxygen atoms 7 .On the other hand , Tb molecules occupy two different places , i . e . , one site surrounded by eight O atoms forming a square antiprismatic coordination polyhedron 8 and another site surrounded by six O atoms forming a trigonal prismatic coordination polyhedron 9 . As seen in Figs .1 ( a ) and ( b ) , these two forms of polyhedra share shared faces perpendicularly to the c - axis 10 .",
        "rewrite_text": "Magnetization, susceptibility, and specific heat measurements were conducted on single crystals of TbFe3(BO3)4. The magnetic characteristics were analyzed using the crystal-field separation scheme for Tb3+ ions. It was determined that the ground state doublet exhibits Ising-like anisotropy along the c-axis, with gz = 8.0 ± 0.1, which contributes to a significant induced polarization (Ps ~ 1 μC/cm²). The experimental data closely match previous laboratory results, except for the high-temperature portion of the specific heat curve below 2 K, which may be attributed to the presence of impurities or defects in the samples. \n\n**Keywords:** Magnetism; Crystal field theory; Specific heat measurement; Susceptibility measurement; Single-crystal growth; Anisotropic magnetoresistance; Polarized neutron scattering. \n\n**INTRODUCTION:** TbFe3(BO3)4 is part of the rare-earth iron borates family, RFe3(BO3) (with R = Y, Yb, Lu). These materials have gained considerable attention for exhibiting a range of intriguing physical phenomena such as ferroelectricity, multiferroicity, colossal magnetoresistance, and fundamental quantum behaviors. Notably, TbFe3(BO3)4 exhibits an impressive spontaneous polarization (Ps ~ 1 μC/cm²) at room temperature due to its distinct crystal structure. In this compound, iron (Fe) ions form a three-dimensional framework of corner-sharing tetrahedra by sharing apical oxygen atoms. Meanwhile, terbium (Tb) ions occupy two distinct sites: one is surrounded by eight oxygen atoms, forming a square antiprismatic coordination, while the other is surrounded by six oxygen atoms, creating a trigonal prismatic coordination. As illustrated in Figs. 1(a) and (b), these two polyhedral forms share faces perpendicular to the c-axis.",
        "ori-fast-z-score": 1.4110813025753959,
        "water-fast-z-score": 7.748271696689158,
        "rewrite-fast-z-score": 0.658504607868518
    },
    {
        "original_text": "We present an ab initio study of the structure, energetics, and dynamics of water adsorbed on the MgO(001) surface in the submonolayer regime using density functional theory with van der Waals corrections. We find that the most stable configuration is one where each oxygen atom binds to three hydrogen atoms forming a trihydrogen bridge between two adjacent O atoms. The binding energy per molecule for this configuration is 1.6 eV. This value agrees well with previous theoretical results obtained within the generalized gradient approximation but disagrees significantly with experimental values which are typically larger by about 0.5-0.7 eV. Our calculations show that the discrepancy can be attributed mainly to the neglect of dispersion interactions in earlier studies. In addition we have studied the effect of temperature on the stability of different configurations. We found that the relative population of various structures depends strongly on the temperature.",
        "watermark_text": "We present an ab initio investigation of the composition , energetics , and dynamics of water adsorbed on the MgO ( 001 ) surface in the submonolayer regime using density functional theory with van der Waals corrections . We see that the most stable configuration is one where each oxygen element connects to three hydrogen atoms forming a trihydrogen bridge between two adjacent O atoms .The binding energy per molecule for this configuration is 1 . 6 eV . This value agrees well with previous conceptual conclusions derived within the generalized gradient formulation but disagrees substantially with theoretical values which are typically greater by about 0 . 5 - 0 . 7 eV .Our calculations show that the discrepancy can be due mainly to the neglect of dispersion interactions in earlier methods . In addition we have researched the impact of temperature on the stability of different configurations .We determined that the relative population of several structures varies strongly on the temperature .",
        "rewrite_text": "We conducted an ab initio study examining the composition, energetics, and dynamics of water adsorbed on the MgO (001) surface in the submonolayer regime, utilizing density functional theory with van der Waals corrections. Our findings indicate that the most stable configuration is characterized by each oxygen atom bonding with three hydrogen atoms, forming a trihydrogen bridge between two adjacent oxygen atoms. The binding energy for this arrangement is found to be 1.6 eV, which aligns well with previous theoretical insights derived from the generalized gradient approximation, though it significantly differs from other theoretical values that are typically higher by approximately 0.5 to 0.7 eV. Our calculations suggest that this discrepancy primarily arises from the omission of dispersion interactions in earlier studies. Furthermore, we investigated how temperature influences the stability of various configurations and found that the relative population of these structures varies significantly with temperature.",
        "ori-fast-z-score": 0.8551861104941365,
        "water-fast-z-score": 5.497624996033735,
        "rewrite-fast-z-score": 2.5655583314824097
    },
    {
        "original_text": "We present an empirical photometric redshift technique for luminous red galaxies (LRGs) and clusters, using the Sloan Digital Sky Survey Data Release 5 (SDSS DR5). We use a sample of LRGs/clusters with spectroscopic redshifts to calibrate our method by fitting their observed colors as functions of redshift. The resulting color-redshift relations are then used to estimate photometric redshifts for all LRG/cluster candidates selected from the SDSS imaging data. Our results show that this simple approach can yield accurate photometric redshifts over most of the range 0 < z < 1.2 covered by the survey. For example, we find that the rms scatter between the estimated and true redshifts is less than 0.05(1+z), which corresponds to about 60 km/s at z = 0.6. This accuracy is comparable or better than those achieved by other methods based on template-fitting techniques. \n \n Keywords: Empirical photometric redshifts; Luminous Red Galaxy; Cluster",
        "watermark_text": "We present an empirical photometric redshift technique for luminous red clusters ( LRGs ) and clusters , using the Sloan Digital Sky Survey Data Release 5 ( SDSS DR5 ) . We use a sample of LRGs / galaxies with spectroscopic redshifts to calibrate our technique by fitting their observed lights as functions of redshift .The resulting color - redshift relations are then utilized to estimate photometric redshifts for all LRG / cluster applicants chosen from the SDSS imaging information . Our results show that this straightforward methodology can yield reliable photometric redshifts over most of the range 0 < z < 1 . 2 included by the census .For instance , we find that the rms scatter between the expected and true redshifts is less than 0 . 05 ( 1 + z ) , which equals to about 60 km / s at z = 0 . 6 . This sensitivity is identical or better than those achieved by other methods using on template - fitting methods .Keywords: Empirical photometric redshifts; Luminous Red Galaxy; Cluster",
        "rewrite_text": "We introduce an empirical technique for measuring photometric redshifts for luminous red galaxies (LRGs) and clusters, utilizing data from the Sloan Digital Sky Survey Data Release 5 (SDSS DR5). Our approach involves calibrating the technique using a sample of LRGs and galaxies with known spectroscopic redshifts, fitting their observed light as a function of redshift. The resulting color-redshift relationships are then applied to estimate photometric redshifts for all LRGs and clusters selected from the SDSS imaging data. Our findings demonstrate that this simple method can produce reliable photometric redshifts across most of the range from 0 to 1.2 in redshift. Specifically, we observe that the root mean square (rms) scatter between the predicted and actual redshifts is less than 0.05 (1 + z), which corresponds to approximately 60 km/s at z = 0.6. This level of accuracy is comparable to or better than that achieved by other template-fitting techniques. Keywords: Empirical photometric redshifts; Luminous Red Galaxy; Cluster.",
        "ori-fast-z-score": -0.42008402520840293,
        "water-fast-z-score": 5.181036310903636,
        "rewrite-fast-z-score": -2.56195947736032
    },
    {
        "original_text": "The rapid growth in the use and production of digital media has created an urgent need to develop new models that support long-term access, preservation, and reuse of personal archives.  In this article we present a service model for managing personal archives based on three key concepts:  The archive is viewed as a collection of interrelated objects (e.g., documents, photos); each object is associated with one or more services that provide functionality such as storage, editing, sharing, etc.; and these services are organized into a hierarchy reflecting their relationships.   We describe how our approach can be used by individuals to manage their own personal archives, and also discuss its potential application within organizations where large volumes of data must be managed over extended periods of time. The rapid growth in the use of digital media has led to increased interest in developing systems that allow users to preserve and share their personal information across multiple devices and platforms. However, current approaches have focused primarily on providing solutions for storing and accessing content rather than addressing issues related to preserving it over time. This problem becomes particularly acute when dealing with collections containing thousands of items spanning several years. To address this issue, we propose a service-oriented architecture for organizing and maintaining personal archives.",
        "watermark_text": "The rapid increase in the using and production of digital media has established an urgent need to develop new models that enable large - term access , preservation , and reuse of personal libraries . In this page we present a service model for controlling personal libraries using on three key concepts : The archive is viewed as a collection of interrelated artifacts ( e . g . , files , photos ) ; each object is associated with one or more functions that provide functionality such as processing , editing , sharing , etc .; and these services are coordinated into a structure indicating their connections . We illustrate how our approach can be used by individuals to manage their own individual archives , and also discuss its potential application within organizations where vast volumes of records must be managed over longer periods of time .The rapid increase in the using of digital media has led to greater activity in developing systems that enable users to archive and transfer their personal data across multiple computers and platforms . However , current approaches have concentrated mostly on providing strategies for storing and accessing information rather than solving topics related to preserving it over time .This problem appears particularly intense when dealing with libraries containing many of items spanning numerous years . To address this question , we propose a service - based architecture for storing and keeping personal records .",
        "rewrite_text": "The swift rise in the use and creation of digital media has created an urgent demand for new models that ensure long-term access, preservation, and reuse of personal libraries. In this article, we introduce a service model for managing personal libraries based on three fundamental concepts: viewing the archive as a collection of interconnected artifacts (such as files and photos); associating each item with one or more functionalities that enable processes like editing, sharing, and more; and organizing these services within a framework that highlights their relationships. We demonstrate how individuals can utilize our approach to effectively manage their personal archives, and we also explore its potential application in organizations that need to manage substantial volumes of records over extended periods. The surge in digital media use has also spurred efforts to create systems that allow users to archive and transfer personal data across various computers and platforms. However, current solutions have primarily focused on strategies for storage and access, often neglecting the critical issue of long-term preservation. This challenge becomes particularly pressing for libraries that contain numerous items accumulated over many years. To tackle this issue, we propose a service-based architecture designed for the storage and preservation of personal records.",
        "ori-fast-z-score": 0.7126966450997984,
        "water-fast-z-score": 9.698686309445845,
        "rewrite-fast-z-score": 0.09245003270420485
    },
    {
        "original_text": "The low energy effective theories for superstrings are supergravity and supersymmetric gauge theories in four dimensions, which can be obtained by compactifying the extra six spatial dimensions on a Calabi-Yau manifold.  In this talk I will discuss some recent results about lattice models that provide an alternative approach to studying these theories. The basic idea is to use Monte Carlo simulations to study supersymmetric field theories defined on a finite number of points (the sites) of a regular d-dimensional hypercubic lattice with periodic boundary conditions. These models have been studied extensively over the past few years using numerical techniques such as exact diagonalization, quantum Monte Carlo methods, and density matrix renormalization group algorithms. Recently we developed new Monte Carlo simulation techniques based on the worm algorithm that allow us to simulate large systems at very high temperatures where conventional Monte Carlo methods fail because they suffer from critical slowing down. We used our new method to calculate the free energies of several different supersymmetric lattice models including the N = 4 supersymmetric Yang-Mills theory and the N = 1 supersymmetric U(1) gauge theory coupled to matter fields in various representations.",
        "watermark_text": "The lowest energy effective models for superstrings are supergravity and supersymmetric gauge fields in four dimensions , which can be obtained by compactifying the extra six spatial dimensions on a Calabi - Yau manifold . In this talk I will explore some latest findings about lattice models that provide an different approach to researching these theories .The basic idea is to use Monte Carlo simulations to study supersymmetric field theories specified on a finite number of points ( the sites ) of a regular d - dimensional hypercubic structure with periodic border conditions . These systems have been studied frequently over the previous few years employing mathematical techniques such as approximate diagonalization , quantum Monte Carlo methods , and density matrix renormalization group algorithms .Recently we developed novel Monte Carlo simulation method based on the worm algorithm that enable us to simulate large systems at very high altitudes where conventional Monte Carlo methods fail because they suffer from critical speed down . We utilized our new method to estimate the free energies of several different supersymmetric lattice models including the N = 4 supersymmetric Yang - Mills theory and the N = 1 supersymmetric U ( 1 ) gauge theory connected to matter groups in different representations .",
        "rewrite_text": "The most fundamental low-energy effective models for superstrings are supergravity and supersymmetric gauge fields in four dimensions, which arise from compactifying the additional six spatial dimensions on a Calabi-Yau manifold. In this presentation, I will discuss recent developments in lattice models that offer an alternative approach to investigating these theories. The core concept is to employ Monte Carlo simulations to analyze supersymmetric field theories defined on a finite set of points (the sites) within a regular d-dimensional hypercubic structure with periodic boundary conditions. Over the past few years, these systems have been extensively studied using mathematical techniques such as approximate diagonalization, quantum Monte Carlo methods, and density matrix renormalization group algorithms. Recently, we have introduced a novel Monte Carlo simulation technique based on the worm algorithm, which allows us to simulate large systems at significantly high altitudes where traditional Monte Carlo methods encounter critical slowing down. Using this new method, we estimated the free energies of several distinct supersymmetric lattice models, including N = 4 supersymmetric Yang-Mills theory and N = 1 supersymmetric U(1) gauge theory associated with matter groups in various representations.",
        "ori-fast-z-score": 0.6255432421712244,
        "water-fast-z-score": 6.118014998909509,
        "rewrite-fast-z-score": 0.5184758473652127
    },
    {
        "original_text": "We present highly resolved numerical simulations of the incompressible Navier-Stokes equations with the LANS-alpha model, which is known to produce good results for wall-bounded flows at low Reynolds numbers. We show that this method can also be used in high-Reynolds number situations where it produces accurate results even though its underlying assumptions are not valid anymore. The main advantage over standard LES methods lies in the fact that no explicit subgrid-scale models have to be introduced. This makes the approach very attractive since there is no need to tune any parameters or coefficients as required by other LES approaches. In addition we demonstrate how the LANS-alpha method can be combined with an implicit LES scheme based on the variational multiscale formulation (VMS-LES) to obtain more efficient computations. Finally, we discuss some open issues related to the use of these schemes in practical applications. Turbulence plays a crucial role in many physical phenomena ranging from weather prediction to oceanic circulation and combustion processes. However, despite decades of research turbulence still remains one of the most challenging problems in computational fluid dynamics. One reason for this difficulty is due to the wide range of length scales involved in turbulent flows. While large eddies contain most of the kinetic energy they only occupy a small fraction of the total volume. On the other hand smaller eddies fill up almost all space but contribute little to the overall kinetic energy. Therefore, if one wants to resolve all relevant flow structures accurately enough then extremely fine grids would be needed leading to prohibitively expensive calculations. To overcome this problem so-called Large Eddy Simulations (LESs) were developed during the last two decades  1, 2  . These techniques aim at resolving only those large-scale motions responsible for the bulk of the kinetic energy while modeling the effect of unresolved small-scale fluctuations using suitable closure relations. Although LES has been successfully applied to various engineering problems  3–5  , it suffers from several drawbacks such as the lack of universality of the employed sub-grid scale models  6  .\nIn recent years new classes of LES-like methods have emerged  7–10  . They are based",
        "watermark_text": "We create highly resolved numerical simulations of the incompressible Navier - Stokes equations with the LANS - alpha simulation , which is known to produce excellent results for wall - defined currents at low Reynolds numbers . We see that this method can also be used in high - Reynolds number circumstances where it generates accurate conclusions albeit though its core assumptions are not valid anymore .The main advantage over traditional LES methods lies in the fact that no explicit subgrid - scale models have to be adopted . This makes the approach very appealing since there is no necessary to tune any coefficients or coefficients as required by other LES approaches .In addition we prove how the LANS - alpha method can be merged with an implicit LES system using on the variational multiscale formulation ( VMS - LES ) to obtain more efficient computations . Finally , we explain some open concerns relevant to the using of these schemes in practical applications .Turbulence plays a crucial role in many natural phenomena ranging from weather prediction to oceanic circulation and combustion cycles . However , despite decades of research turbulence nonetheless continues one of the most challenging difficulties in computational liquid mechanics .One reason for this difficulty is due to the broad variety of length scales implicated in turbulent streams . While big eddies contain most of the kinetic power they only comprise a small fraction of the total quantity .On the other hand tiny eddies fill up nearly all space but add little to the overall kinetic power . Therefore , if one wants to resolve all relevant stream dynamics correctly sufficiently then extremely good grids might be needed leading to prohibitively expensive calculations .To solve this situation so - called Large Eddy Simulations ( LESs ) were developed during the last two decades 1 , 2 . These methods aim at resolving only those huge - scale motions responsible for the majority of the kinetic power while solving the impact of unresolved small - scale fluctuations using appropriate completion relations .Although LES has been successfully applied to numerous technical problems 3 – 5 , it suffers from several drawbacks such as the lack of universality of the involved sub - grid size models 6 . In recent years new classes of LES - like methods have developed 7 – 10 .They are based",
        "rewrite_text": "We develop highly detailed numerical simulations of the incompressible Navier-Stokes equations using the LANS-alpha method, which has proven effective for wall-bounded flows at low Reynolds numbers. Notably, this approach can also be applied to high-Reynolds number scenarios, producing reliable results even when its foundational assumptions may no longer hold true. A key advantage over traditional Large Eddy Simulation (LES) methods is that LANS-alpha does not require explicit subgrid-scale models, eliminating the need to adjust coefficients as is common in other LES approaches. Furthermore, we demonstrate how the LANS-alpha method can be integrated with an implicit LES framework based on the variational multiscale formulation (VMS-LES), enhancing computational efficiency. We also address some outstanding issues related to the practical application of these methods. Turbulence is a critical factor in numerous natural processes, including weather forecasting, ocean circulation, and combustion cycles. Despite extensive research over the years, turbulence remains one of the most complex challenges in computational fluid dynamics. This complexity arises from the wide range of length scales present in turbulent flows. While large eddies carry most of the kinetic energy, they account for only a small portion of the total volume. Conversely, the small eddies occupy nearly all the space but contribute little to the overall kinetic energy. Accurately capturing all relevant flow dynamics would typically require extremely fine grids, leading to prohibitively high computational costs. To address this issue, Large Eddy Simulations (LES) have been developed over the past twenty years. These methods focus on resolving the large-scale motions that dominate the kinetic energy while modeling the effects of unresolved smaller-scale fluctuations using appropriate closure relations. Although LES has been effectively utilized in various engineering applications, it has notable limitations, such as the lack of universal applicability of the subgrid-scale models employed. In recent years, new classes of LES-like methods have emerged, which are based on...",
        "ori-fast-z-score": -1.4122588778696161,
        "water-fast-z-score": 7.345410552159442,
        "rewrite-fast-z-score": -2.2440873743489966
    },
    {
        "original_text": "We present the results of our analysis on the X-ray spectrum and variability properties of CIV 1549, which is one of the brightest Seyfert galaxies in the sky at soft X-rays (0.5-2 keV). We find that its spectral shape can be well described by a power law with photon index Γ = 2.1 ± 0.2 plus two thermal components; one component has temperature kT = 0.3 +0.4 −0.1 keV while another has higher temperature kT = 3.7 +1.6 −1.1 keV. The luminosity ratio between these two thermal components is L h /L l ≈ 5.9 +2.8 −2.1 . In addition to this multi-component continuum model, we also include several emission lines such as Fe Kα line and OVII triplet. Our best-fit parameters are consistent with those obtained previously using ASCA data. \n \n Using the Chandra HETG observation taken during 2001-2002, we have investigated the short-term variability behavior of CIV 1549. We found no significant time lag between different energy bands within the observed bandpasses. However, there appears to exist some correlation between flux variations in hard energies (> 4 keV) and those in softer energies (< 4 keV), although it does not appear to be strictly linear relationship. This result suggests that the origin of the short-term variability may be due to reprocessing of harder photons into softer ones rather than intrinsic fluctuations of the primary source itself. \n \n Finally, we examine whether or not CIV 1549 shows any evidence for rapid aperiodic variability. By applying wavelet transform techniques to the light curve extracted from the central region of the galaxy, we detect strong signals corresponding to periods ranging from 10 - 100 s. These periodicities are most likely associated with quasi-periodic oscillations (QPOs). \n \n We conclude that CIV 1549 is probably powered by accretion onto supermassive black holes.",
        "watermark_text": "We present the conclusion of our analysis on the X - ray spectrum and variability properties of CIV 1549 , which is one of the brightest Seyfert galaxies in the sky at warm X - radiation ( 0 . 5 - 2 keV ) . We see that its spectral structure can be well described by a power law with photon index Γ = 2 . 1 ± 0 . 2 plus two thermal parts ; one part has temperature kT = 0 . 3 + 0 . 4 −0 . 1 keV while another has higher temperature kT = 3 . 7 + 1 . 6 −1 . 1 keV .The luminosity factor between these two thermal parts is L h / L l ≈ 5 . 9 + 2 . 8 −2 . 1 . In addition to this multi - component continuum model , we also add several emission lines such as Fe Kα line and OVII triplet .Our best - fitting characteristics are compatible with those acquired previously using ASCA information . Using the Chandra HETG measurement done during 2001 - 2002 , we have researched the short - term variability behavior of CIV 1549 .We determined no considerable time lag between various energy bands within the seen bandpasses . However , there seems to appear some correlation between flux variations in hard frequencies ( > 4 keV ) and those in harder frequencies ( < 4 keV ) , although it does not appear to be strictly linear correlation .This result suggests that the origin of the short - term variability may be due to reprocessing of stronger photons into weaker ones instead than intrinsic fluctuations of the primary source itself . Finally , we investigate whether or not CIV 1549 shows any evidence for rapid aperiodic variability .By applying wavelet transform techniques to the light line gathered from the central region of the universe , we identify strong pulses corresponding to periods ranging from 10 - 100 s . These periodicities are most likely correlated with quasi - periodic oscillations ( QPOs ) . We suggest that CIV 1549 is probably powered by accretion onto supermassive black holes .",
        "rewrite_text": "We conclude our analysis of the X-ray spectrum and variability properties of CIV 1549, one of the brightest Seyfert galaxies observed in warm X-rays (0.5 - 2 keV). Our findings indicate that its spectral structure is effectively represented by a power law with a photon index of Γ = 2.1 ± 0.2, alongside two thermal components. The first component has a temperature of kT = 0.3 +0.4 -0.1 keV, while the second, at a higher temperature, measures kT = 3.7 +1.6 -1.1 keV. The luminosity ratio between these thermal components is L_h / L_l ≈ 5.9 +2.8 -2.1. Along with this multi-component continuum model, we also include several emission lines, such as the Fe Kα line and the OVII triplet. Our best-fitting parameters align well with previous findings acquired from ASCA data. Through the Chandra HETG observations conducted from 2001 to 2002, we investigated the short-term variability of CIV 1549 and found no significant time lag between different energy bands within the observed ranges. However, a correlation appears to exist between flux variations in higher energy ( > 4 keV) and lower energy (< 4 keV) bands, though it is not strictly linear. This implies that the short-term variability may originate from the reprocessing of stronger photons into weaker ones rather than from intrinsic fluctuations of the primary source. Finally, we examined potential rapid aperiodic variability in CIV 1549 by applying wavelet transform techniques to light curves recorded from the galaxy’s central region. We identified strong pulses corresponding to periods ranging from 10 to 100 seconds, likely associated with quasi-periodic oscillations (QPOs). We propose that the activity of CIV 1549 is likely driven by accretion onto a supermassive black hole.",
        "ori-fast-z-score": 0.3651483716701107,
        "water-fast-z-score": 7.6085975253341545,
        "rewrite-fast-z-score": 2.37346441585572
    },
    {
        "original_text": "We present the first measurement of the supermassive black hole (SMBH) mass function for both early-(elliptical/S0, Sa-Sb) and latetype (Scd-Sm) galaxies using data from the Millennium Galaxy Catalogue (MGC). We use two different methods to measure SMBH masses - stellar velocity dispersion measurements and bulge luminosity scaling relations. Our results show that there is no significant difference between the SMBH mass functions of these galaxy types at z < 0.1. However we find evidence for an evolution with redshift such that the number density of massive SMBHs decreases more rapidly than less-massive ones. This suggests that the most massive SMBHs are likely to have grown by accretion over cosmic time rather than merging events. These findings will be important constraints on models of SMBH growth and AGN feedback.",
        "watermark_text": "We present the first measurement of the supermassive black hole ( SMBH ) mass distribution for both late - ( elliptical / S0 , Sa - Sb ) and latetype ( Scd - Sm ) clusters using data from the Millennium Galaxy Catalogue ( MGC ) . We use two different methods to measure SMBH masses - stellar velocity dispersion measurements and bulge luminosity scaling relations .Our results show that there is no major variation between the SMBH mass distributions of these galaxy forms at z < 0 . 1 . However we find proof for an evolution with redshift such that the number density of large SMBHs falls more swiftly than less - massive ones .This implies that the most gigantic SMBHs are likely to have expanded by accretion over universe time rather than joining events . These conclusions will be crucial constraints on estimates of SMBH growth and AGN feedback .",
        "rewrite_text": "We present the first measurement of the supermassive black hole (SMBH) mass distribution for both late-type (elliptical/S0, Sa-Sb) and late-type (Scd-Sm) clusters, using data from the Millennium Galaxy Catalogue (MGC). Our analysis employs two different methods to estimate SMBH masses: stellar velocity dispersion measurements and bulge luminosity scaling relations. Our findings indicate that there is no significant difference in the SMBH mass distributions of these galaxy types at redshifts below 0.1. However, we observe evidence of evolution with redshift, showing that the number density of large SMBHs decreases at a faster rate than that of less massive ones. This suggests that the most massive SMBHs likely grew primarily through accretion over the history of the universe rather than through merger events. These insights will provide important constraints for models of SMBH growth and AGN feedback.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.077963596336064,
        "rewrite-fast-z-score": 0.3779644730092272
    },
    {
        "original_text": "In this article, we study self-dual vertex operator super algebras with central charge c = 24k for k ∈ N>0. We show that these are precisely those which have an automorphism group isomorphic to the baby monster simple sporadic finite group. In particular, we prove that there is only one such algebra up to isomorphism if k=1 or 2, but infinitely many non-isomorphic ones in general. The main tool used here is the modular representation theory of the baby monster group. This work was done as part of my PhD thesis at University College London supervised by Professors David Ben-Zvi and Jonathan Wise. I would like to thank them both very much for their help and support during my time working on it. Introduction Let V be a vector space over C equipped with a non-degenerate bilinear form < , > satisfying < xv, w >=< v, wx> for all x, y, z ∈ V . Then V is called a symplectic vector space. If dimV = 2n then V has a basis consisting of n pairs of vectors e_i + f_i and e_i - f_i where 1 <= i <= n and < e_i, e_j >= 0 =< f_i, f_j > while < e_i, f_j >= δ_{ij}. For more information see  FH91  .\nVertex operator superalgebras were introduced independently by Borcherds  B89  and Kac  K90  . They can be thought of as supersymmetric analogues of vertex operator algebras. A vertex operator superalgebra consists of a Z/2Z-graded vector space V = V0 ⊕ V1 together with a vacuum vector |0>∈V0, a conformal element ω ∈ End(V), a parity change operator Π : V → V interchanging V0 and V1, and a set of fields Y (x, z) (called vertex operators) indexed by elements x ∈ V and complex numbers z ∈ C satisfying certain axioms. These axioms include the Jacobi identity, associativity relations, commutator formulae, and various other conditions",
        "watermark_text": "In this discussion , we study self - dual vertex operator super algebras with central charge c = 24k for k ∈ N > 0 . We see that these are exactly those which have an automorphism class isomorphic to the baby monster simple sporadic finite ring .In particular , we prove that there is only one such algebra up to isomorphism if k = 1 or 2 , but infinitely many non - isomorphic ones in general . The main method employed here is the modular representation theory of the baby monster category .This project was done as part of my PhD thesis at University College London supervised by Professors David Ben - Zvi and Jonathan Wise . I would like to thank them both very greatly for their help and support during my time working on it .Introduction Let V be a vector space over C endowed with a non - degenerate bilinear form < , > satisfying < xv , w > = < v , wx > for all x , y , z ∈ V . Then V is called a symplectic vector space .If dimV = 2n then V has a basis consisting of n pairs of matrix e _ i + f _ i and e _ i - f _ i where 1 < = i < = n and < e _ i , e _ j > = 0 = < f _ i , f _ j > while < e _ i , f _ j > = δ _ { ij } . For more information see FH91 .Vertex operator superalgebras were introduced independently by Borcherds B89 and Kac K90 . They can be thought of as supersymmetric analogues of vertex operator algebras .A vertex operator superalgebra consists of a Z / 2Z - graded vector space V = V0 ⊕ V1 combined with a vacuum vector | 0 > ∈V0 , a conformal element ω ∈ End ( V ) , a parity shift operator Π : V → V interchanging V0 and V1 , and a setting of fields Y ( x , z ) ( named vertex operators ) indexed by elements x ∈ V and complex integers h ∈ C satisfying particular axioms . These axioms include the Jacobi identity , associativity relations , commutator formulae , and many other conditions",
        "rewrite_text": "In this discussion, we explore self-dual vertex operator super algebras with a central charge of \\( c = 24k \\) for \\( k \\in \\mathbb{N} \\) where \\( k > 0 \\). We find that these algebras correspond precisely to those possessing an automorphism class that is isomorphic to the baby monster simple sporadic finite group. Notably, we demonstrate that there is only one such algebra up to isomorphism when \\( k = 1 \\) or \\( k = 2 \\), whereas there are infinitely many non-isomorphic algebras in general. The principal method utilized in this research is the modular representation theory of the baby monster category. This work was conducted as part of my PhD thesis at University College London, under the supervision of Professors David Ben-Zvi and Jonathan Wise, to whom I am profoundly grateful for their guidance and support throughout this project. \n\n**Introduction**  \nLet \\( V \\) be a vector space over \\( \\mathbb{C} \\) equipped with a non-degenerate bilinear form \\( \\langle \\cdot, \\cdot \\rangle \\) such that \\( \\langle x v, w \\rangle = \\langle v, w x \\rangle \\) for all \\( x, y, z \\in V \\). This structure defines \\( V \\) as a symplectic vector space. If \\( \\dim V = 2n \\), then \\( V \\) can be spanned by \\( n \\) pairs of vectors \\( e_i + f_i \\) and \\( e_i - f_i \\) for \\( 1 \\leq i \\leq n \\), where \\( \\langle e_i, e_j \\rangle = 0 \\) and \\( \\langle f_i, f_j \\rangle = 0 \\), while \\( \\langle e_i, f_j \\rangle = \\delta_{ij} \\). For further details, refer to FH91. \n\nVertex operator superalgebras were independently introduced by Borcherds (B89) and Kac (K90) and can be interpreted as supersymmetric counterparts to vertex operator algebras. A vertex operator superalgebra comprises a \\( \\mathbb{Z}/2\\mathbb{Z} \\)-graded vector space \\( V = V_0 \\oplus V_1 \\), along with a vacuum vector \\( |0\\rangle \\in V_0 \\), a conformal element \\( \\omega \\in \\text{End}(V) \\), a parity shift operator \\( \\Pi: V \\to V \\) that swaps \\( V_0 \\) and \\( V_1 \\), and a collection of fields \\( Y(x, z) \\) (known as vertex operators) indexed by elements \\( x \\in V \\) and complex integers \\( h \\in \\mathbb{C} \\) that adhere to specific axioms. These axioms encompass the Jacobi identity, associativity relations, commutator formulas, and various other conditions.",
        "ori-fast-z-score": 1.4729193886373175,
        "water-fast-z-score": 5.084751798731267,
        "rewrite-fast-z-score": 0.4622501635210242
    },
    {
        "original_text": "The Neutrino Factory and Muon Collider Collaboration (NFMCC), in collaboration with other European laboratories is proposing an innovative concept for a large liquid argon imaging detector that will be used as part of the future Neutrino Factory or Muon Collider experiments at CERN. The proposed project aims to build a very massive modular LArTPC using state-of-the-art technology. This would allow us to exploit the unique features offered by this type of detectors such as: excellent particle identification capabilities; high spatial resolution; good time resolution; hermetic detection volume; possibility to operate under intense magnetic fields etc., which are essential requirements for precision measurements on neutrino oscillations parameters. In addition, it could also provide important information about CP violation effects in the leptonic sector. \n \n A detailed description of the physics case can be found here  1  . \nA technical proposal has been submitted  2  , including a preliminary design study  3  .\n \n\n\nIn order to demonstrate the feasibility of our approach we have built a small prototype  4  consisting of: two TPCs filled with 1 tonne each of liquid argon; one central cathode made out of carbon fibre; four wire planes located above and below the cathode plane; three wire planes placed along the sides of the chamber; a set of scintillator paddles surrounding the active volume of the chambers.",
        "watermark_text": "The Neutrino Factory and Muon Collider Collaboration ( NFMCC ) , in partnership with other European laboratories is proposing an ambitious idea for a large liquid argon imaging detector that will be used as part of the forthcoming Neutrino Factory or Muon Collider experiments at CERN . The proposed project aims to build a very huge prototype LArTPC utilizing state - of - the - art technology .This might enable us to harness the unusual characteristics offered by this class of detectors such as : excellent electron identification capabilities ; high visual resolution ; best time resolution ; hermetic detection volume ; possibility to work under intense magnetic waves etc . , which are essential needs for precision observations on neutrino oscillations parameters . In addition , it could also supply crucial data about CP violation effects in the leptonic sector .A full description of the physics case can be found here 1 . A technical proposal has been presented 2 , including a preliminary building report 3 .In order to test the feasibility of our approach we have building a small prototype 4 consisting of : two TPCs loaded with 1 tonne each of liquid argon ; one central cathode made out of carbon fibre ; four rope planes located above and below the cathode plane ; three cable planes placed along the sides of the chamber ; a pair of scintillator paddles surrounding the active volume of the chambers .",
        "rewrite_text": "The Neutrino Factory and Muon Collider Collaboration (NFMCC), in collaboration with various European laboratories, is putting forth an ambitious proposal for a large-scale liquid argon imaging detector intended for upcoming Neutrino Factory and Muon Collider experiments at CERN. This initiative aims to develop a significant prototype of a liquid argon Time Projection Chamber (LArTPC) using cutting-edge technology. Such a detector would leverage its unique features, including exceptional electron identification, high visual and time resolution, an all-encompassing detection volume, and the ability to operate in strong magnetic fields. These capabilities are crucial for accurately studying neutrino oscillation parameters and could provide vital insights into CP violation in the leptonic sector. A comprehensive overview of the physics case is detailed in reference 1. A technical proposal has been submitted, along with a preliminary building report (reference 3). To assess the feasibility of our concept, we have constructed a small prototype comprising two TPCs each containing 1 tonne of liquid argon, a central cathode made from carbon fiber, four electrode planes positioned above and below the cathode, three cable planes along the chamber's sides, and a pair of scintillator paddles encircling the active volume of the detectors.",
        "ori-fast-z-score": 0.8955334711889903,
        "water-fast-z-score": 6.268734298322932,
        "rewrite-fast-z-score": 0.41702882811414954
    },
    {
        "original_text": "We present the first detection of secondary CMB polarization induced by Faraday rotation (FR) in galaxy clusters, using data taken with the Atacama Cosmology Telescope Polarimeter (ACTPol). We detect FR-induced polarized emission at angular scales corresponding to multipoles = 100-1000 for two galaxy clusters: ACT-CL J0102-4915 and ACT-CL J0546-5345. The observed signal is consistent with theoretical predictions based on numerical simulations of magnetized cluster atmospheres. This measurement provides an important test of our understanding of magnetic fields in galaxy clusters as well as their impact on cosmological observables such as the CMB temperature anisotropies and E-mode polarizations. In addition, we report upper limits on the FR-induced polarized emissions from other galaxy clusters that are not detected individually due to low S/N ratio or limited survey area. These results will be useful for future studies of FR effects on the CMB polarization maps produced by upcoming experiments like Planck and Simons Observatory.",
        "watermark_text": "We present the first measurement of secondary CMB polarization induced by Faraday rotation ( FR ) in galaxy clusters , using data taken with the Atacama Cosmology Telescope Polarimeter ( ACTPol ) . We detect FR - caused polarized emission at angular scales corresponding to multipoles = 100 - 1000 for two galaxy regions : ACT - CL J0102 - 4915 and ACT - CL J0546 - 5345 .The observed light is compatible with theoretical estimates based on numerical simulations of magnetized cluster atmospheres . This measurement represents an important test of our knowing of magnetic fields in galaxy galaxies as well as their impact on cosmological observables such as the CMB heat anisotropies and E - mode polarizations .In addition , we publish higher restrictions on the FR - caused polarized impacts from other galaxy galaxies that are not observed individually due to low S / N proportion or restricted observation space . These conclusions will be valuable for future research of FR effects on the CMB polarization mapping created by future research like Planck and Simons Observatory .",
        "rewrite_text": "We provide the first measurement of secondary cosmic microwave background (CMB) polarization induced by Faraday rotation (FR) in galaxy clusters, utilizing data from the Atacama Cosmology Telescope Polarimeter (ACTPol). We identify FR-induced polarized emission at angular scales corresponding to multipoles between 100 and 1000 in two galaxy regions: ACT-CL J0102-4915 and ACT-CL J0546-5345. The detected signal aligns with theoretical predictions derived from numerical simulations of magnetized cluster atmospheres. This measurement serves as a significant test of our understanding of magnetic fields in galaxy clusters and their influence on cosmological observables, including CMB temperature anisotropies and E-mode polarizations. Furthermore, we present stronger limits on the FR-induced polarized effects from other galaxy clusters that were not individually detected due to low signal-to-noise ratios or limited observational areas. These findings will be crucial for future investigations into the effects of Faraday rotation on CMB polarization mapping from upcoming studies, such as those conducted by the Planck and Simons Observatories.",
        "ori-fast-z-score": -0.12403473458920847,
        "water-fast-z-score": 5.829632525692798,
        "rewrite-fast-z-score": 0.8551861104941365
    },
    {
        "original_text": "We present the results of our calculation on rotating condensate in an optical trap using cranked HFB method with Skyrme interaction.  We have found that there is no phase transition between superfluid and normal state as predicted by mean field theory, but we find that the condensate density decreases continuously when angular velocity increases. The decrease rate depends strongly on the strength of the pairing force. This result can be explained by the fact that the rotation breaks the Cooper pairs into single particles which are not bound together any more. In addition to this effect, we also observe another interesting phenomenon; namely, the condensate density becomes larger at some specific values of angular velocities than its value without rotation. This may be understood as follows: At these special points, the system has lower energy due to the presence of vortex lines. Finally, we compare our results with those obtained by other authors who used different methods such as time-dependent GP equation or Bogoliubov-de Gennes equations.",
        "watermark_text": "We present the conclusion of our calculation on rotating condensate in an optical trap using cranked HFB process with Skyrme coupling . We have discovered that there is no phase change between superfluid and normal state as predicted by mean field theory , but we find that the condensate density decreases continuously when angular velocity increases .The drop rate depends strongly on the strength of the pairing force . This result can be described by the fact that the movement breaks the Cooper pairs into single particles which are not bound together any more .In addition to this effect , we also observe another important feature ; namely , the condensate density becomes greater at some specific values of angular velocities than its value without rotation . This might be understood as follows : At these unique points , the system has less energy due to the presence of vortex lines .Finally , we compare our findings with those achieved by other researchers who used various methods such as time - based GP function or Bogoliubov - de Gennes coefficients .",
        "rewrite_text": "We present the results of our calculations on a rotating condensate in an optical trap using the cranked Hartree-Fock-Bogoliubov (HFB) method with Skyrme coupling. Our findings reveal that, contrary to predictions made by mean field theory, there is no phase transition between the superfluid and normal states. Instead, we observe a continuous decrease in condensate density as the angular velocity increases, with the rate of decline being highly dependent on the strength of the pairing force. This behavior can be attributed to the disruption of Cooper pairs into non-bound single particles due to the rotation. Additionally, we note an intriguing phenomenon: at certain specific angular velocities, the condensate density actually exceeds its non-rotating value. This can be explained by the system reaching lower energy states associated with the formation of vortex lines. Finally, we compare our results with those obtained by other researchers who employed various techniques, such as the time-dependent Gross-Pitaevskii equation and Bogoliubov-de Gennes methods.",
        "ori-fast-z-score": 0.6793662204867574,
        "water-fast-z-score": 5.287913134352312,
        "rewrite-fast-z-score": -0.4588314677411235
    },
    {
        "original_text": "The present work is devoted to the investigation of the photothermal properties and dynamics of the Cu2O/CuO nanocomposite films prepared by pulsed laser deposition (PLD) on Si(100). The PLD technique allows one to obtain high-quality thin films with controlled composition, structure and morphology. It was found that the temperature dependence of the resistance R(T), measured at different light intensities I0, exhibits two distinct regimes corresponding to low-temperature metallic-like behavior and high-temperature semiconducting-like behavior. In addition, it has been shown that the transition between these regimes occurs via an intermediate state characterized by pronounced hysteresis effect. This phenomenon can be explained within the framework of the theory developed for semiconductor-metal phase transitions induced by strong non-equilibrium heating. We have also demonstrated that this model describes well the observed nonlinear response of the investigated system to external periodic driving force.",
        "watermark_text": "The present work is devoted to the exploration of the photothermal characteristics and dynamics of the Cu2O / CuO nanocomposite products made by pulsed laser deposition ( PLD ) on Si ( 100 ) . The PLD procedure allows one to obtain high - grade thin sheets with controlled composition , structure and morphology .It was shown that the temperature dependence of the resistance R ( T ) , recorded at different light intensities I0 , displays two different regimes corresponding to low - temperature metallic - like behavior and large - temperature semiconducting - like behavior . In addition , it has been shown that the shift between these regimes occurs via an intermediate phase described by significant hysteresis effect .This phenomenon can be described within the framework of the theoretical developed for semiconductor - metal transition changes induced by weak non - equilibrium heating . We have already shown that this description explains well the seen nonlinear reaction of the investigated system to external periodic drove force .",
        "rewrite_text": "This study focuses on the investigation of the photothermal properties and dynamics of Cu2O/CuO nanocomposites created through pulsed laser deposition (PLD) on Si(100) substrates. The PLD technique facilitates the production of high-quality thin films with precise control over their composition, structure, and morphology. Our results indicate that the temperature dependence of resistance, R(T), measured under varying light intensities, I0, reveals two distinct regimes: one exhibiting metallic-like behavior at low temperatures and the other displaying semiconducting-like characteristics at higher temperatures. Furthermore, the transition between these regimes is marked by an intermediate phase characterized by a notable hysteresis effect. This behavior can be understood within the theoretical framework for semiconductor-metal transitions driven by weak non-equilibrium heating. We have previously demonstrated that this theoretical model accurately accounts for the observed nonlinear response of the system to external periodic driving forces.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.812381937190964,
        "rewrite-fast-z-score": -0.7071067811865476
    },
    {
        "original_text": "We consider the problem of finding a shortest path between two nodes in an undirected graph with non-negative edge weights, subject to the constraint that no node can be visited more than once along this path.  We show how to solve this problem by reducing it to the minimum cost flow problem on a directed acyclic network and then applying standard techniques for solving such problems.   The running time is O(n3 log n), where n denotes the number of vertices in the input graph. This result improves upon previous algorithms which have been known only for special cases (e.g., when all edges are unit-weight).    Keywords: Shortest paths, Minimum-cost flows, Directed graphs, Undirected graphs, Culminating paths, Constraints, Flow networks, Computational complexity theory.    1 Introduction\n\nIn many applications one needs to find a shortest path between two given nodes s and t in an undirected weighted graph G = (V , E) without allowing any vertex to appear twice or more times in the path.   For example, if we want to compute the distance between two cities using road maps, we may not allow a city to be used as a starting point again after visiting another city.   In other words, we do not want to use the same road segment twice even though there might exist several different ways to reach some destination.   Another application arises in computational biology, where one wants to find a sequence of genes that minimizes the total length while avoiding certain regions of DNA.   A third application occurs in computer vision, where one seeks to minimize the total length of a path through a set of images while ensuring that each image appears at most once in the path.   Finally, our results also apply to the problem of computing the diameter of a connected undirected graph.\n\nThe first algorithm for computing the shortest path satisfying these constraints was presented by Hassin and Rubinov  HR91  who showed how to reduce the problem to the minimum cost flow",
        "watermark_text": "We consider the question of finding a longest route between two nodes in an undirected graph with non - negative edge weights , subject to the constraint that no node can be visited more than once along this route . We see how to solve this question by limiting it to the minimum price flow problem on a directed acyclic network and then introducing standard methods for solving such problems .The run time is O ( n3 log n ) , where n represents the number of vertices in the input graph . This result improves upon recent algorithms which have been known only for exceptional cases ( e . g . , when all edges are unit - weight ) .Keywords : Shortest paths , Minimum - cost flows , Directed graphs , Undirected graphs , Culminating paths , Constraints , Flow connections , Computational complexity analysis . 1 Introduction In many applications one needs to find a longest route between two given nodes s and t in an undirected weighted graph G = ( V , E ) without allowing any edges to appear twice or more times in the path .For instance , if we wish to compute the distance between two places using road maps , we may not require a city to be used as a starting location again after seeing another city . In other words , we do not wish to use the same road segment twice even though there might exist several different means to reach some destination .Another application exists in computational genetics , where one wants to find a sequence of genes that minimizes the total length while eliminating certain regions of DNA . A third application happens in computer vision , where one seeks to minimize the total length of a path through a group of pictures while maintaining that each object appears at most once in the path .Finally , our findings also apply to the question of computing the diameter of a connected undirected graph . The first algorithm for solving the shortest path satisfying these requirements was presented by Hassin and Rubinov HR91 who demonstrated how to reduce the question to the minimum price flow",
        "rewrite_text": "We explore the problem of identifying the longest path between two nodes in an undirected graph with non-negative edge weights, adhering to the constraint that no node is revisited along the route. We demonstrate how to tackle this issue by reframing it as a minimum price flow problem within a directed acyclic network, applying established methods for solving these types of problems. The runtime for our solution is O(n³ log n), where n denotes the number of vertices in the input graph. This accomplishment marks an improvement over recent algorithms that have been applicable only to specific cases, such as when all edges have a unit weight. \n\n**Keywords:** Longest paths, Minimum-cost flows, Directed graphs, Undirected graphs, Unique paths, Constraints, Flow relationships, Computational complexity analysis.\n\n**1 Introduction**  \nIn various applications, it is essential to determine the longest path between two specified nodes, s and t, in an undirected weighted graph G = (V, E), where no edge can be traversed more than once. For instance, when calculating the distance between two locations using road maps, we would not want to revisit a city after passing through it. In essence, we aim to avoid utilizing the same road segment multiple times, despite the availability of different routes to reach a destination. \n\nAnother scenario arises in computational genetics, where one seeks to find a sequence of genes that minimizes total length while excluding certain DNA regions. A third instance occurs in computer vision, where the objective is to minimize the overall length of a pathway through a series of images, ensuring that each object is represented only once. Additionally, our research contributes to determining the diameter of a connected undirected graph. The first algorithm addressing the shortest path with these constraints was proposed by Hassin and Rubinov (HR91), who illustrated how to convert the problem into a minimum price flow framework.",
        "ori-fast-z-score": 1.5261167249147478,
        "water-fast-z-score": 8.166535844059444,
        "rewrite-fast-z-score": 1.2722833945199565
    },
    {
        "original_text": "We present an analysis of the dependence on energy and luminosity of the frequencies of two types of quasi-periodic oscillations (QPOs) observed in the power density spectra of accreting black holes, namely low frequency QPOs (LFQPOs; 0.1-10 Hz), which are thought to be related to global properties of the flow close to the central object, and high frequency QPOs (HFQPOs; 10-100 Hz). We use data obtained with RXTE/PCA for four sources: GRO J1655-40, XTE J1550-564, 4U 1543-47 and H 1743-322.  The LFQPO is modelled as arising due to non-linear coupling between radial epicyclic motion at different radii within the disc. This model predicts that the centroid frequency should scale inversely proportional to the square root of the photon energy. In contrast, we find that this scaling relation does not hold when considering HFQPOs. Instead, our results suggest that these features arise due to non-linear coupling between vertical epicyclic motions at different heights above the equatorial plane.",
        "watermark_text": "We present an assessment of the dependence on energy and luminosity of the frequencies of two kind of quasi - periodic oscillations ( QPOs ) detected in the power concentration spectra of accreting white holes , namely low frequency QPOs ( LFQPOs ; 0 . 1 - 10 Hz ) , which are said to be connected to worldwide properties of the flow close to the main object , and large frequency QPOs ( HFQPOs ; 10 - 100 Hz ) . We use data acquired with RXTE / PCA for four sources : GRO J1655 - 40 , XTE J1550 - 564 , 4U 1543 - 47 and H 1743 - 322 .The LFQPO is modelled as occurring due to non - linear correlation between radial epicyclic motion at different radii within the disc . This theory predicts that the centroid frequency should scale inversely proportional to the square root of the photon energy .In comparison , we find that this scaling relation does not hold when using HFQPOs . Rather , our findings show that these characteristics arise due to non - linear correlation between vertical epicyclic movements at different elevations above the equatorial plane .",
        "rewrite_text": "We provide an evaluation of how the frequencies of two types of quasi-periodic oscillations (QPOs) found in the power density spectra of accreting white holes depend on energy and luminosity. These are low-frequency QPOs (LFQPOs; 0.1 - 10 Hz), which are believed to be linked to the overall properties of the flow near the main object, and high-frequency QPOs (HFQPOs; 10 - 100 Hz). Our analysis utilizes data from the RXTE/PCA for four sources: GRO J1655-40, XTE J1550-564, 4U 1543-47, and H 1743-322. The LFQPOs are theorized to result from a non-linear correlation of radial epicyclic motion at varying radii within the accretion disk, suggesting that the centroid frequency should scale inversely with the square root of photon energy. In contrast, we find that this scaling does not apply to HFQPOs. Instead, our results indicate that HFQPOs are driven by non-linear correlations in vertical epicyclic motions at different heights above the equatorial plane.",
        "ori-fast-z-score": -2.4618298195866544,
        "water-fast-z-score": 3.8450767722654624,
        "rewrite-fast-z-score": -1.3363062095621219
    },
    {
        "original_text": "We report on the radio spectral evolution during a solar flare that was observed by RHESSI in 2002 February 18, which is one of the most energetic impulsive solar flares ever recorded with high energy electrons up to ~100 MeV. The flare started at about 17:45 UT as a GOES class M5.7 event peaking around 18:10 UT. It showed two peaks in its hard X-ray light curve (HXR); the first peak lasted only 3 minutes while the second peak lasted more than 10 minutes. We found that there were three distinct phases in the radio spectrum evolution: pre-flare phase, impulsive phase, and decay phase. In addition, we also found that the radio emission had a clear correlation between the HXR fluxes and microwave flux densities. During the impulsive phase, the radio emission increased rapidly and then decayed slowly after the end of the impulsive phase.",
        "watermark_text": "We report on the radio spectral evolution during a sun flare that was seen by RHESSI in 2002 February 18 , which is one of the most intense impulsive solar flares yet measured with high energy electrons up to ~ 100 MeV . The flare began at about 17 : 45 UT as a GOES class M5 . 7 event peaking around 18 : 10 UT .It showed two peaks in its hard X - ray light circle ( HXR ) ; the first peak lasted only 3 minutes while the second peak lasted more than 10 minutes . We determined that there were three different stages in the television spectrum development : pre - flare period , impulsive phase , and decay phase .In addition , we also discovered that the television emission had a clear correlation between the HXR fluxes and microwave flux densities . During the impulsive phase , the television emission increased rapidly and then decayed slowly after the end of the impulsive phase .",
        "rewrite_text": "We present our findings on the radio spectral evolution during a solar flare observed by RHESSI on February 18, 2002. This flare is noted for being one of the most intense impulsive solar flares recorded, with high-energy electrons reaching approximately 100 MeV. It initiated around 17:45 UT as a GOES class M5.7 event, peaking at approximately 18:10 UT. The flare exhibited two peaks in its hard X-ray (HXR) light curve; the first lasted only 3 minutes, while the second extended beyond 10 minutes. We identified three distinct stages in the evolution of the radio spectrum: the pre-flare period, the impulsive phase, and the decay phase. Furthermore, we found a clear correlation between the television emission and both the HXR fluxes and microwave flux densities. During the impulsive phase, the television emission rose sharply before gradually decaying once the impulsive phase concluded.",
        "ori-fast-z-score": 2.54000254000381,
        "water-fast-z-score": 5.588005588008382,
        "rewrite-fast-z-score": 1.75
    },
    {
        "original_text": "We present an analysis of early X-ray afterglow data for eight gamma-ray bursts (GRBs) in which we find evidence that they are associated with relativistic jets viewed off-axis, and show how this can be used to probe jet structure. We use our model to predict the late-time behaviour of these GRB afterglows and compare it with observations made by Swift/XRT. The results suggest that the majority of GRB jets have a structured energy distribution, with most of the kinetic energy contained within a narrow cone along the jet axis. This is consistent with theoretical expectations based on models where GRBs result from the collapse of massive stars into black holes or neutron stars. \nIntroduction\n\nGamma-ray bursts (GRBs; see Piran 2004 , Gehrels et al. 2009 ) are brief flashes of high-energy radiation lasting typically 10 s but ranging up to several hundred seconds. They were first detected over 50 years ago (Klebesadel et al. 1973; Strong et al. 1974) , but despite extensive observational efforts there remain many open questions about them. In particular, what powers the emission? What causes the observed diversity between different bursts?\nThe standard fireball model (see e.g., Rees & Meszaros 1992; Sari 1997; Piran 1999; Wijers 2001; Kumar & Zhang 2015) provides one explanation for the prompt phase of GRB emission. It involves the dissipation of kinetic energy stored in a relativistically expanding shell of plasma produced during some catastrophic event such as the merger of two compact objects or the collapse of a massive star. However, this model cannot explain all aspects of GRB phenomenology. For example, it does not account for the wide range of durations seen across the population of GRBs (e.g., Nakar 2007), nor do current models provide any satisfactory explanation for why only a small fraction of collapsing stars produce observable GRBs (e. g., Bromm & Loeb 2006) . Furthermore, the lack of detection of optical counterparts to short-duration GRBs has led to suggestions that at least some",
        "watermark_text": "We present an assessment of early X - ray afterglow data for eight γ - ray clusters ( GRBs ) in which we find proof that they are correlated with relativistic jets viewed off - axis , and suggest how this can be used to probe jet shape . We use our model to predict the mid - time behaviour of these GRB afterglows and link it with observations made by Swift / XRT .The results show that the majority of GRB jets have a structured energy flow , with most of the kinetic power contained within a thin cone along the jet axis . This is consistent with theoretical expectations based on scenarios where GRBs occur from the merger of large galaxies into black holes or neutron galaxies .Introduction Gamma - ray bursts ( GRBs ; seeing Piran 2004 , Gehrels et al . 2009 ) are mild flashes of high - energy rays lasting typically 10 s but ranging up to several hundred moments .They were first detected over 50 years early ( Klebesadel et al . 1973 ; Strong et al .1974 ) , but despite extensive observational efforts there remain many open questions about them . In particular , what powers the emission ?What causes the seen diversity between various bursts ? The conventional fireball model ( see e . g . , Rees & Meszaros 1992 ; Sari 1997 ; Piran 1999 ; Wijers 2001 ; Kumar & Zhang 2015 ) presents one account for the prompt stage of GRB emission .It involves the dissipation of kinetic power contained in a relativistically increasing shell of plasma generated during some devastating event such as the merger of two compact objects or the failure of a huge star . However , this model cannot explain all aspects of GRB phenomenology .For instance , it does not account for the broad variety of durations observed across the population of GRBs ( e . g . , Nakar 2007 ) , nor do recent estimates provide any satisfactory excuse for why only a small fraction of collapsing stars produce observable GRBs ( e . g . , Bromm & Loeb 2006 ) . Furthermore , the lack of recognition of optical rivals to short - duration GRBs has led to suggestions that at least some",
        "rewrite_text": "We provide an evaluation of early X-ray afterglow data for eight gamma-ray bursts (GRBs), demonstrating a correlation with off-axis relativistic jets, and discussing how this can be leveraged to investigate jet structure. Our model forecasts the mid-time behavior of these GRB afterglows and aligns it with observations from Swift/XRT. The findings indicate that most GRB jets possess a structured energy distribution, with the majority of kinetic power concentrated within a narrow cone along the jet's axis. This is in line with theoretical predictions that suggest GRBs arise from the mergers of massive galaxies into black holes or neutron stars. \n\nGamma-ray bursts (GRBs), as detailed by Piran (2004) and Gehrels et al. (2009), are brief, intense flashes of high-energy radiation lasting approximately 10 seconds, though some extend to several hundred seconds. Initially detected over 50 years ago (Klebesadel et al. 1973; Strong et al. 1974), these phenomena continue to raise many questions despite extensive observational studies. Key inquiries include the mechanisms behind their emissions and the reasons for the varying characteristics observed among different bursts. The traditional fireball model (e.g., Rees & Meszaros 1992; Sari 1997; Piran 1999; Wijers 2001; Kumar & Zhang 2015) offers an explanation for the prompt emission phase of GRBs, proposing that it results from the dissipation of kinetic energy in a relativistically expanding plasma shell created during catastrophic events like the merger of compact objects or the collapse of massive stars. However, this model is insufficient to account for all aspects of GRB behaviors, such as the significant range of durations seen in the GRB population (Nakar 2007), and it fails to adequately explain why only a small percentage of collapsing stars yield detectable GRBs (Bromm & Loeb 2006). Moreover, the oversight of optical counterparts to short-duration GRBs has led to speculations that at least some...",
        "ori-fast-z-score": -0.08192319205190406,
        "water-fast-z-score": 7.557138666690337,
        "rewrite-fast-z-score": 0.780398972571708
    },
    {
        "original_text": "The book is intended for students who have completed the first year course in control theory and are interested to learn more about discrete-time systems, digital controllers and computer-based control techniques. The text covers topics such as state space representation, stability analysis, optimal control design, robustness issues, model predictive control (MPC), fuzzy logic based control etc., with an emphasis on practical applications. It also includes several examples that illustrate key concepts discussed throughout the chapters. \n \n This textbook provides a comprehensive coverage of basic principles underlying various aspects of modern control engineering. In addition to theoretical foundations, it presents numerous numerical examples illustrating important concepts introduced along the way. A number of exercises at the end of each chapter help readers reinforce their understanding of material presented earlier. Finally, there are two appendices containing additional information useful for further study or research work. \nThis book can be used by graduate students studying advanced courses in control theory, as well as researchers working in this area.",
        "watermark_text": "The text is intended for students who have completed the first year course in control theory and are concerned to teach more about discrete - time systems , digital controllers and computer - based control methods . The text encompasses topics such as state space representation , stability analysis , ideal control design , robustness issues , model predictive control ( MPC ) , fuzzy logic based control etc . , with an emphasis on technical applications .It additionally contains several examples that highlight key concepts discussed throughout the pages . This treatise provides a comprehensive treatment of fundamental principles governing several elements of modern control engineering .In addition to theoretical foundations , it presents several mathematical models illustrating major concepts adopted along the way . A variety of tests at the end of each volume help viewers reinforce their understanding of content presented earlier .Finally , there are two appendices containing extra data helpful for further study or research studies . This book can be used by graduate candidates pursuing advanced degrees in control theory , as well as scientists studying in this area .",
        "rewrite_text": "This text is designed for students who have completed a first-year course in control theory and wish to gain deeper insights into discrete-time systems, digital controllers, and computer-based control techniques. Covering a range of topics, it includes state space representation, stability analysis, ideal control design, robustness issues, model predictive control (MPC), and fuzzy logic-based control, with a strong emphasis on practical applications. The book features numerous examples that illustrate key concepts discussed throughout the chapters. It offers an in-depth exploration of the fundamental principles that underpin various aspects of modern control engineering. Beyond the theoretical foundations, it presents several mathematical models that clarify major concepts introduced in the text. To reinforce learning, a series of tests are included at the end of each volume. Additionally, there are two appendices with supplementary information to aid further study or research. This book is suitable for graduate students pursuing advanced degrees in control theory, as well as researchers and scientists in the field.",
        "ori-fast-z-score": 0.4879500364742666,
        "water-fast-z-score": 6.993258208972302,
        "rewrite-fast-z-score": 1.5230192477004287
    },
    {
        "original_text": "We present new results on the displacement of the Sun from the galactic plane based on Hipparcos data and recent determinations of the solar motion with respect to the local standard of rest (LSR). We find that the Sun is displaced by about 0.5 kpc in the direction towards the constellation Cetus, which agrees well with previous estimates obtained using different methods. The observed displacement can be explained as due to the combined effect of the gravitational potential of the Galaxy and the peculiar velocity of the Local Group with respect to it. \n \n Keywords: Solar System dynamics, Galactic rotation curve, Local Group kinematics, Galactocentric distance \n \n 1 Introduction \n \n In this work we study the position of the Sun within our galaxy. This problem has been addressed previously by several authors who have used different techniques ranging from statistical studies of open clusters  1  or OB associations  2  , to direct measurements of proper motions  3  . Here we use the most accurate available determination of the solar motion  4  together with the latest measurement of the circular speed at large distances  5  to determine the position of the Sun relative to the galactic plane.",
        "watermark_text": "We report new data on the movement of the Sun from the galactic plane based on Hipparcos statistics and recent determinations of the sun motion with regard to the local standard of rest ( LSR ) . We see that the Sun is displaced by about 0 . 5 kpc in the direction towards the constellation Cetus , which agrees well with previous calculated obtained using separate methods .The observed displacement can be described as owing to the combined influence of the gravitational potential of the Galaxy and the peculiar speed of the Local Group with regard to it . Keywords : Solar System dynamics , Galactic rotation curve , Local Group kinematics , Galactocentric distance 1 Introduction In this research we study the orientation of the Sun within our universe .This problem has been addressed previously by various scientists who have utilized varying techniques ranging from statistical analyses of close complexes 1 or OB associations 2 , to direct measurements of proper motions 3 . Here we utilize the most accurate available determination of the sun motion 4 together with the latest measurement of the circular distance at large distances 5 to estimate the orientation of the Sun relative to the galactic plane .",
        "rewrite_text": "We present new findings on the Sun's movement away from the galactic plane, based on Hipparcos data and recent measurements of its motion in relation to the local standard of rest (LSR). Our observations indicate that the Sun is positioned approximately 0.5 kpc towards the constellation Cetus, consistent with previous calculations obtained through various methods. This displacement appears to result from the combined effects of the Galaxy's gravitational potential and the peculiar velocity of the Local Group relative to it. \n\n**Keywords**: Solar System dynamics, Galactic rotation curve, Local Group kinematics, Galactocentric distance \n\n**1 Introduction**  \nIn this study, we investigate the Sun's orientation within the universe. This topic has been explored by numerous researchers who employed diverse techniques, including statistical analyses of nearby star complexes and OB associations, as well as direct measurements of proper motions. In this work, we utilize the most precise available determinations of the Sun's motion, in conjunction with the latest measurements of circular distances at large scales, to assess the Sun's position relative to the galactic plane.",
        "ori-fast-z-score": -0.329292779969071,
        "water-fast-z-score": 6.625891564490792,
        "rewrite-fast-z-score": 0.22360679774997896
    },
    {
        "original_text": "We present an analysis of the correlation between star formation rate density (SFRD) and neutral hydrogen emission during reionization epoch using high resolution hydrodynamic simulations with radiative transfer calculations. We find that SFRD is strongly correlated to the total amount of neutral gas in the universe, but not necessarily to its distribution or morphology. The results are consistent with previous studies which found no significant correlations between Lyman-alpha luminosity function and 21 cm brightness temperature fluctuations at z = 6 − 7. \n \n Keywords: Hydrogen line radiation, Radiation transfer, Reionization, Simulations, Galaxy evolution \n \n 1 Introduction \n \n In recent years there has been growing interest in studying the relationship between galaxy properties such as their star formation rates (SFRs), stellar masses, morphologies etc., and the underlying dark matter halos they reside within. This is motivated by the fact that understanding this connection will help us understand how galaxies evolve over cosmic time. For example, it may be possible to use observations of galaxy clustering statistics to constrain models for galaxy formation and evolution. However, these measurements can only provide statistical information about the average properties of large samples of galaxies. To obtain more detailed information on individual objects we need to study them individually. One way to do so is through direct imaging techniques like Hubble Space Telescope (HST). Another method involves measuring the fluxes emitted by different atomic species via spectroscopic methods. These include optical/UV lines produced by ionized atoms, infrared lines produced by warm dust grains heated by young stars, radio continuum emission due to synchrotron processes associated with supernova remnants, free-free emission arising from HII regions surrounding hot massive stars, and finally the most important tracer - the 21-cm hyperfine transition of neutral hydrogen (HI). \n \n HI traces all cold neutral gas in the interstellar medium (ISM) including both molecular clouds and diffuse atomic gas. It also provides valuable kinematic information regarding the dynamics of galactic disks. Therefore, HI plays a crucial role in our understanding of many physical phenomena related to galaxy formation and evolution. For instance",
        "watermark_text": "We present an assessment of the relationship between star formation rate concentration ( SFRD ) and neutral hydrogen emission during reionization epoch using high resolution hydrodynamic simulations with radiative transfer calculations . We see that SFRD is strongly correlated to the total quantity of neutral gas in the universe , but not necessarily to its distribution or morphology .The results are compatible with previous research which revealed no important correlations between Lyman - alpha luminosity function and 21 cm brightness cooling fluctuations at z = 6 − 7 . Keywords : Hydrogen line radiation , Radiation exchange , Reionization , Simulations , Galaxy evolution 1 Introduction In recent years there has been growing interest in investigating the relationship between galaxy structures such as their star formation rates ( SFRs ) , stellar masses , morphologies etc . , and the internal bright matter halos they live within .This is prompted by the fact that understanding this link will assist us explain how clusters evolve over universe time . For instance , it could be possible to use observations of galaxy clustering statistics to constrain models for galaxy formation and evolution .However , these measurements can only obtain statistical information about the average characteristics of large specimens of galaxies . To obtain more precise data on individual objects we must to study them individually .One method to do so is through direct scanning techniques like Hubble Space Telescope ( HST ) . Another method means measuring the fluxes emitted by various atomic species via spectroscopic methods .These include optical / UV lines formed by ionized ions , infrared lines formed by cold cloud particles heated by young galaxies , television continuum emission associated to synchrotron systems associated with supernova remnants , free - free emission originating from HII centers surrounding hot massive galaxies , and eventually the most important tracer - the 21 - cm hyperfine change of neutral hydrogen ( HI ) . HI maps all cool neutral gas in the interstellar medium ( ISM ) covering both chemical clouds and diffuse atomic dust .It additionally offers important kinematic data regarding the dynamics of galactic disks . Therefore , HI plays a crucial role in our understanding of several physical phenomena related to star formation and evolution .For instance",
        "rewrite_text": "We provide an evaluation of the connection between star formation rate density (SFRD) and neutral hydrogen emission during the reionization epoch, utilizing high-resolution hydrodynamic simulations accompanied by radiative transfer calculations. Our findings indicate a strong correlation between SFRD and the total amount of neutral gas in the universe, although this does not extend to its distribution or morphology. These results align with earlier studies that found no significant correlations between the Lyman-alpha luminosity function and the 21 cm brightness fluctuations at redshifts of 6 to 7. \n\n**Keywords**: Hydrogen line radiation, Radiation exchange, Reionization, Simulations, Galaxy evolution.\n\n### 1. Introduction\nIn recent years, there has been an increasing interest in exploring the relationships between galaxy structures, such as star formation rates (SFRs), stellar masses, and morphologies, and the luminous matter halos that contain them. This interest arises from the potential of understanding these connections to inform our understanding of how clusters evolve over cosmic time. For example, analyzing galaxy clustering statistics might help refine models of galaxy formation and evolution. However, these measurements usually yield only statistical insights into the average features of large samples of galaxies. To achieve more precise information about individual galaxies, it is necessary to study them on a case-by-case basis. One approach involves direct imaging techniques, such as those employed by the Hubble Space Telescope (HST), while another method entails measuring the fluxes emitted by various atomic species through spectroscopic techniques. These methods include analyzing optical/UV lines produced by ionized atoms, infrared lines resulting from cold particles heated by forming stars, continuum emissions linked to synchrotron processes from supernova remnants, free-free emissions from HII regions surrounding massive stars, and ultimately the most critical tracer—the 21-cm hyperfine transition of neutral hydrogen (HI). HI maps all cool neutral gas in the interstellar medium (ISM), encompassing both molecular clouds and diffuse atomic structures, and provides key kinematic information about the dynamics of galactic disks. Thus, HI is essential for our understanding of various physical processes related to star formation and evolution.",
        "ori-fast-z-score": 0.5291502622129182,
        "water-fast-z-score": 9.146740246823299,
        "rewrite-fast-z-score": -0.6923076923076923
    },
    {
        "original_text": "We have analyzed peculiar motions of galaxies within the region of the ursa major supercluster (UMS) using data on galaxy redshifts and distances obtained by us with the 6-m telescope at the Special Astrophysical Observatory of Russian Academy of Sciences.  The UMS is one of the largest known superclusters, consisting of about 100 rich clusters of galaxies. We found that the mean radial velocity of all galaxies in this supercluster relative to its center amounts to -500 km/s. This value agrees well with estimates made earlier for other superclusters. However, we also discovered an unexpected feature of the motion of galaxies inside the UMS. Namely, there are two groups of galaxies moving towards each other along the line connecting their centers. One group consists of three nearby clusters located near the center of the supercluster; another includes four distant clusters situated at a distance of more than 60 Mpc from it.",
        "watermark_text": "We have analyzed unusual movements of galaxies within the sector of the ursa major supercluster ( UMS ) using data on star redshifts and lengths taken by us with the 6 - m observatory at the Special Astrophysical Observatory of Russian Academy of Sciences . The UMS is one of the largest discovered superclusters , consisting of about 100 rich clusters of clusters .We showed that the mean radial speed of all galaxies in this supercluster relative to its core amounts to - 500 km / s . This value agrees well with predictions taken previous for other superclusters .However , we also discovered an unexpected feature of the movement of stars inside the UMS . Namely , there are two groups of clusters moved towards each other along the line linking their centers .One group contains of three adjacent complexes positioned near the center of the supercluster ; another includes four distant clusters situated at a distance of more than 60 Mpc from it .",
        "rewrite_text": "We have examined unusual galaxy movements within the Ursa Major Supercluster (UMS) using star redshift and length data collected with the 6-meter telescope at the Special Astrophysical Observatory of the Russian Academy of Sciences. The UMS is among the largest known superclusters, comprising around 100 rich clusters. Our analysis revealed that the average radial velocity of all galaxies in this supercluster, relative to its core, is approximately -500 km/s. This finding aligns well with previous predictions for other superclusters. However, we also identified an intriguing aspect of star movement within the UMS: two groups of clusters are converging towards each other along the axis connecting their centers. One group consists of three adjacent complexes located near the supercluster's center, while the other group comprises four distant clusters positioned more than 60 Mpc away.",
        "ori-fast-z-score": -1.4569855927715483,
        "water-fast-z-score": 4.201805851511121,
        "rewrite-fast-z-score": 0.2672612419124244
    },
    {
        "original_text": "We present the results of an analysis of galaxy cluster data in terms of their gravitational lensing properties and X-ray emission, with particular emphasis on the comparison between observed and predicted values for the mass-to-light ratio M/L. We find that the best-fit value of this quantity is consistent with the predictions based on standard CDM models if one assumes that most of the baryonic component of these systems resides within galaxies rather than being distributed throughout the intracluster medium (ICM). This result suggests that the ICM may be heated by some mechanism other than gravity alone. \n \n Keywords: Galaxy cluster, Dark Matter Halo, Gravitational Lensing, Mass-to-Light Ratio, X-Ray Emission \n \n \n \n 1 Introduction \n \n The study of galaxy clusters has been instrumental to our understanding of cosmology over the past few decades. In fact, it was through observations of galaxy clusters that we first discovered evidence supporting the existence of non-baryonic dark matter  1  . Today, galaxy clusters are still used extensively to test theories about structure formation  2  , and they provide important constraints on cosmological parameters such as the Hubble constant  3  or the equation-of-state parameter w  4  . \n \n However, despite all its successes, there remain several open questions regarding galaxy clusters which have yet to be answered satisfactorily. For example, while current observational techniques allow us to measure accurately the total amount of light emitted by a galaxy cluster, it remains difficult to determine how much of this light comes from stars inside individual galaxies versus diffuse gas located outside them  5  . Similarly, although we can estimate fairly well the total gravitating mass of a galaxy cluster using various methods  6  , it is not clear what fraction of this mass is associated with visible objects like galaxies  7, 8  . Finally, even though we know that galaxy clusters contain large amounts of hot plasma  9  , it is unclear whether this material is gravitationally bound to the system  10  .\n \nIn order to address these issues, we will use two different datasets obtained from the Chandra Observatory  11  : the sample of galaxy clusters studied by Vikhlinin et",
        "watermark_text": "We present the conclusion of an assessment of galaxy cluster data in terms of their gravitational lensing behavior and X - ray radiation , with particular emphasis on the comparison between seen and anticipated readings for the mass - to - light value M / L . We see that the best - fitting value of this quantity is compatible with the estimates based on normal CDM models if one suppose that most of the baryonic core of these systems resides within stars rather than being dispersed throughout the intracluster medium ( ICM ) .This result suggests that the ICM could be heated by some process other than gravity alone . Keywords : Galaxy cluster , Dark Matter Halo , Gravitational Lensing , Mass - to - Light Ratio , X - Ray Emission 1 Introduction The investigation of galaxy galaxies has been instrumental to our understanding of cosmology over the previous few years .In indeed , it was through observations of galaxy clusters that we first discovered evidence proving the existence of non - baryonic black material 1 . Today , galaxy rings are still used heavily to test models about structure formation 2 , and they give important restrictions on cosmological factors such as the Hubble constant 3 or the equation - of - state variable f 4 .However , despite all its victories , there remain many open questions regarding galaxy clusters which have yet to be answered satisfactorily . For instance , while contemporary observational techniques permit us to measure correctly the total amount of light emitted by a galaxy cluster , it remains impossible to predict how many of this light originates from stars inside individual stars vs diffuse gas located outside them 5 .Similarly , although we can calculate fairly good the total gravitating mass of a galaxy cluster using numerous technique 6 , it is not clear what fraction of this mass is associated with visible objects like stars 7 , 8 . Finally , even though we know that galaxy regions include significant amounts of bright plasma 9 , it is uncertain whether this material is gravitationally bound to the system 10 .In order to meet these problems , we will use two different datasets obtained from the Chandra Observatory 11 : the sample of galaxy regions investigated by Vikhlinin et",
        "rewrite_text": "We present the findings of an assessment focused on the behavior of galaxy clusters in terms of their gravitational lensing characteristics and X-ray emissions. Our analysis specifically highlights the comparison between observed and expected mass-to-light ratios (M/L). We find that the best-fitting value of this ratio aligns well with predictions derived from standard cold dark matter (CDM) models, provided we assume that the majority of the baryonic mass in these systems is concentrated in stars, rather than being dispersed in the intracluster medium (ICM). This outcome indicates that the heating of the ICM may result from processes other than gravity alone. \n\n**Keywords**: Galaxy clusters, Dark Matter Halo, Gravitational Lensing, Mass-to-Light Ratio, X-Ray Emission\n\n**1 Introduction**  \nThe study of galaxy clusters has greatly advanced our understanding of cosmology in recent years. Observations of these clusters were pivotal in first revealing evidence for the existence of non-baryonic dark matter. Today, galaxy clusters continue to play a crucial role in testing theoretical models of structure formation and providing vital constraints on key cosmological parameters, such as the Hubble constant and the equation-of-state parameter. Nevertheless, numerous unresolved questions about galaxy clusters persist. For example, even though modern observational techniques allow us to accurately measure the total luminosity of a cluster, it remains challenging to determine the proportion of this light that comes from individual stars versus that emitted by diffuse gas. Similarly, while methods exist for estimating the total gravitational mass of a cluster, it is unclear what fraction of this mass is in the form of visible matter like stars. Moreover, we know that galaxy clusters contain substantial amounts of luminous plasma, yet the gravitational binding status of this material is still uncertain. To address these issues, we will utilize two distinct datasets obtained from the Chandra Observatory, specifically focusing on the sample of galaxy clusters examined by Vikhlinin et al.",
        "ori-fast-z-score": -1.5811388300841895,
        "water-fast-z-score": 8.171011693711216,
        "rewrite-fast-z-score": -1.212678125181665
    },
    {
        "original_text": "We study the dynamics of an ensemble of elastically-coupled reed oscillators driven by a common acoustic field, and show that they can exhibit striking phenomena such as synchronized chaos or phase-locked states with multiple incommensurate frequencies. We also demonstrate how these effects are modified when the system is connected to a passive resonator. The results presented here may be relevant to understanding the behavior of biological systems such as colonies of fireflies or neurons. \n \n In recent years there has been growing interest in studying nonlinear dynamical systems composed of many interacting elements  1-3 . These studies have revealed new collective behaviors which cannot occur in single element systems  4  . Examples include synchronization  5-7  , clustering  8  , chimera states  9  , and spatiotemporal patterns  10-12  .\nIn this work we consider a model consisting of N identical elastically-coupled reed-oscillators  13  driven by a common acoustic wavefield  14-16  (see Fig 1) . Each oscillator consists of two vibrating plates separated by a thin layer of air  17  . When the pressure difference across one plate exceeds its critical value, it begins to expand rapidly until the restoring force due to the other plate causes it to contract again. This process repeats periodically resulting in self-sustained oscillations at a frequency determined by the geometry of the device  18  . \nThe coupling between neighboring oscillators arises because each oscillator acts like a small loudspeaker radiating sound into the surrounding medium  19-21  . As a result, nearby oscillators experience similar driving forces and their natural frequencies become locked  22  . If all oscillators lock onto the same frequency then the entire system behaves coherently; if different groups of oscillators lock on to different frequencies then the system exhibits spatially-extended multistability  23  .",
        "watermark_text": "We research the dynamics of an ensemble of elastically - coupled reed oscillators powered by a common acoustic field , and demonstrated that they can exhibit striking phenomena such as synchronized chaos or phase - locked states with many incommensurate frequencies . We additionally observe how these influences are modified when the system is linked to a passive resonator .The results presented here perhaps be applicable to study the activity of biological systems such as colonies of fireflies or cells . In past decades there has been growing interest in investigating nonlinear dynamical systems composed of several interacting elements 1 - 3 .These studies have revealed additional collective behaviors which cannot appear in single structure environments 4 . Examples involve synchronization 5 - 7 , clustering 8 , chimera groups 9 , and spatiotemporal cycles 10 - 12 .In this research we suppose a theory consisting of N identical elastically - coupled reed - oscillators 13 driven by a common acoustic wavefield 14 - 16 ( see Fig 1 ) . Each oscillator consists of two vibrating sheets connected by a thin layer of air 17 .When the pressure difference across one plate exceeds its critical level , it continues to expand rapidly until the restoring pressure attributed to the other plate causes it to contract again . This process repeats frequently resulting in self - prolonged oscillations at a frequency determined by the topology of the device 18 .The interaction between neighboring oscillators arises because each oscillator acts like a small loudspeaker radiating noise into the adjacent medium 19 - 21 . As a result , neighboring oscillators encounter identical driving forces and their natural frequencies become locked 22 .If all oscillators pull onto the same frequency then the entire system behaves coherently ; if different bands of oscillators lock on to different frequencies then the system displays spatially - extended multistability 23 .",
        "rewrite_text": "We investigate the dynamics of a group of elastically coupled reed oscillators that are driven by a shared acoustic field, demonstrating their ability to exhibit remarkable phenomena such as synchronized chaos and phase-locked states with multiple incommensurate frequencies. Additionally, we explore how these dynamics are altered when the system is connected to a passive resonator. The findings presented here may have implications for understanding the behaviors of biological systems, like firefly colonies or cellular activity. In recent decades, there has been increasing interest in the study of nonlinear dynamical systems composed of numerous interacting elements. These investigations have uncovered collective behaviors that do not manifest in isolated structures, including synchronization, clustering, chimera states, and spatiotemporal cycles. Our research proposes a model featuring N identical elastically coupled reed oscillators driven by a common acoustic wavefield. Each oscillator consists of two vibrating plates separated by a thin layer of air. When the pressure difference across one plate surpasses a critical threshold, it expands rapidly until the restoring pressure from the other plate causes it to contract. This oscillatory process occurs repeatedly, resulting in sustained oscillations at a frequency determined by the device's topology. The interaction between neighboring oscillators occurs because each oscillator functions like a small loudspeaker, emitting sound into the surrounding medium. Consequently, adjacent oscillators experience similar driving forces, which causes their natural frequencies to synchronize. If all oscillators converge on the same frequency, the entire system behaves coherently; however, if different groups lock onto varying frequencies, the system exhibits spatially extended multistability.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.367287362179046,
        "rewrite-fast-z-score": 0.6363636363636364
    },
    {
        "original_text": "We present an analysis of pulsar observations to determine the magnetic field strength in the solar corona at heights between 1 and 3 R_Sun . We use data obtained with the Nançay Radio Telescope (NRT) for two different radio frequencies, 327 MHz and 1420 MHz, corresponding to emission heights of about 2 and 5 R_Sun , respectively. The observed pulse profiles are modeled using a simple model that includes contributions from both the local interstellar medium and the solar wind plasma. From these models we derive estimates for the coronal magnetic field strengths as well as the electron density distribution along the line-of-sight towards PSR B1133+16 .\nThe results show that the magnetic field decreases rapidly with height above the photosphere but is still strong enough to confine energetic particles up to several solar radii away from the Sun s surface. This suggests that particle acceleration processes may be taking place throughout most of the solar atmosphere.",
        "watermark_text": "We present an assessment of pulsar observations to estimate the magnetic force size in the solar corona at heights between 1 and 3 R _ Sun . We use data acquired with the Nançay Radio Telescope ( NRT ) for two different radio altitudes , 327 MHz and 1420 MHz , corresponding to emission heights of about 2 and 5 R _ Sun , respectively .The observed pulse profiles are modeled using a simple simulation that contains contributions from both the local interstellar material and the sun breeze plasma . From these models we derive estimates for the coronal magnetic field strengths as also as the electron concentration distribution along the line - of - view towards PSR B1133 + 16 .The results show that the magnetic force reduces rapidly with width above the photosphere but is nevertheless strong enough to confine energetic particles up to several solar radii away from the Sun s surface . This implies that particle acceleration processes possibly be taking place throughout most of the solar atmosphere .",
        "rewrite_text": "We provide an evaluation of pulsar observations aimed at estimating the strength of the magnetic field in the solar corona at altitudes ranging from 1 to 3 solar radii. Our analysis utilizes data from the Nançay Radio Telescope (NRT) at two distinct radio frequencies, 327 MHz and 1420 MHz, which correspond to emission heights of approximately 2 and 5 solar radii, respectively. The pulse profiles observed are modeled using a straightforward simulation that accounts for both the local interstellar medium and the solar wind plasma. From these models, we derive estimates of the coronal magnetic field strengths as well as the distribution of electron density along the line of sight to PSR B1133 + 16. Our findings indicate that the magnetic force decreases rapidly with altitude above the photosphere, yet remains sufficiently strong to confine energetic particles at distances several solar radii from the Sun's surface. This suggests that particle acceleration processes are likely occurring throughout a substantial portion of the solar atmosphere.",
        "ori-fast-z-score": -0.35603449745815596,
        "water-fast-z-score": 4.780914437337574,
        "rewrite-fast-z-score": -0.11547005383792514
    },
    {
        "original_text": "We present results on searches for gravitational wave (GW) burst signals using data collected by the Laser Interferometer Gravitational-Wave Observatory during its fourth science run, which took place between September 2005 and January 2007. We use two different search methods to look for GW bursts: one based on matched filtering with template waveforms and another that uses an optimal filterbank method. The latter is used as part of a blind analysis where we do not know what type or strength of signal may be present in our data until after it has been analyzed. In addition to these analyses, we also perform several consistency checks designed to identify any problems associated with either detector s performance over this period. No significant candidates are found in any of these searches. Using simulated signals injected into the data at random times, we estimate upper limits on the rate density of binary black hole mergers detectable within a given range of total mass.",
        "watermark_text": "We report findings on investigations for gravitational wave ( GW ) burst signals using data amassed by the Laser Interferometer Gravitational - Wave Observatory during its fourth science run , which taken place between September 2005 and January 2007 . We use two different search methods to find for GW bursts : one based on paired processing with template waveforms and another that using an efficient filterbank method .The latter is utilized as part of a blind analysis where we do not understand what type or strength of signal might be found in our information until after it has been examined . In addition to these tests , we also perform several reliability measures designed to identify any problems involved with either detector s performance over this time .No meaningful candidates are found in any of these searches . Using simulated transmissions imported into the information at random times , we estimate upper limits on the rate concentration of binary dark hole mergers detectable within a given range of total mass .",
        "rewrite_text": "We present our findings from investigations into gravitational wave (GW) burst signals, utilizing data collected by the Laser Interferometer Gravitational-Wave Observatory (LIGO) during its fourth science run, which occurred between September 2005 and January 2007. Our approach employs two distinct search methods for identifying GW bursts: one that utilizes paired processing with template waveforms and another utilizing an efficient filter bank method. The latter is part of a blind analysis, where we remain unaware of the type or strength of signals present in the data until after our examination is complete. Furthermore, we conduct several reliability assessments to identify potential issues with the performance of either detector during this period. Ultimately, we found no significant candidates in our searches. By introducing simulated signals at random timestamps, we estimate upper limits on the rate of detectable binary black hole mergers within a specified total mass range.",
        "ori-fast-z-score": -1.1322770341445956,
        "water-fast-z-score": 4.98201895023622,
        "rewrite-fast-z-score": -0.6974858324629157
    },
    {
        "original_text": "The solar magnetic field is an important ingredient in many physical processes that take place on the Sun, such as coronal heating or solar wind acceleration. The open magnetic flux threading through the heliosphere plays also a crucial role for space weather prediction. In this work we present results obtained with the MHD model developed by Usmanov et al. (2010) to study the structure and dynamics of the Sun s open magnetic field. We show how the global properties of the simulated open magnetic field compare with observations made at 1 AU using spacecraft data. Our simulations reproduce well the observed latitudinal distribution of the open magnetic flux density and its dependence on the radial distance from the Sun. They also provide information about the temporal evolution of the open magnetic field which can be used to predict the state of the interplanetary medium several days ahead. This research was supported by NASA grants NNX10AC85G (PI: S. Riley), NNG09FA40C (PI: A. Schwadron), and NNM07AA01A (PI: J. McComas).",
        "watermark_text": "The solar magnetic force is an important ingredient in many mechanical phenomena that take place on the Sun , such as coronal heating or solar wind expansion . The open magnetic flux threading through the heliosphere serves also a crucial role for space weather prediction .In this research we present results derived with the MHD model used by Usmanov et al . ( 2010 ) to study the composition and dynamics of the Sun s open magnetic force .We see how the global properties of the simulated open magnetic force compare with observations made at 1 AU using satellite information . Our simulations reproduce well the seen latitudinal distribution of the open magnetic flux concentration and its dependence on the radial distance from the Sun .They also provide details about the temporal evolution of the open magnetic force which can be used to predict the state of the interplanetary medium several days ahead . This research was supported by NASA grants NNX10AC85G ( PI : S . Riley ) , NNG09FA40C ( PI : A . Schwadron ) , and NNM07AA01A ( PI : J . McComas ) .",
        "rewrite_text": "The solar magnetic force plays a vital role in various mechanical phenomena occurring on the Sun, including coronal heating and the expansion of solar wind. Additionally, the open magnetic flux that extends through the heliosphere is essential for predicting space weather. In this study, we present findings based on the MHD model developed by Usmanov et al. (2010) to analyze the composition and dynamics of the Sun's open magnetic force. We assess how the global properties of the simulated open magnetic force align with observations collected at 1 AU via satellite data. Our simulations accurately replicate the observed latitudinal distribution of open magnetic flux concentrations and their variation with radial distance from the Sun. They also offer insights into the temporal evolution of the open magnetic force, which can aid in forecasting the state of the interplanetary medium up to several days in advance. This research received support from NASA grants NNX10AC85G (PI: S. Riley), NNG09FA40C (PI: A. Schwadron), and NNM07AA01A (PI: J. McComas).",
        "ori-fast-z-score": 0.7875615306482168,
        "water-fast-z-score": 5.062895554167108,
        "rewrite-fast-z-score": 2.424871130596428
    },
    {
        "original_text": "We present results on the orbital evolution of Jupiter and Saturn in an axisymmetric, viscously evolving protoplanetary disk with embedded planets. We find that the orbits of both giant planets are significantly affected by their mutual gravitational interaction as well as by the presence of other planetary embryos. The eccentricity growth is dominated by secular interactions between the two planets which lead to large amplitude oscillations in the semi-major axes. In addition we find that the planet migration rates depend strongly on the initial conditions for the system parameters such as mass ratio and separation distance. \n \n Keywords: Planet formation - Giant planets - Eccentricities - Migration - Disk instability - Secular resonance - Dynamical chaos - N-body simulations \n \n \n \n 1 Introduction \n \n Planets form out of dust particles through coagulation processes (Safronov 1969; Wetherill & Stewart 1989) followed by runaway accretion onto these growing objects (Lissauer 1987). This process leads to the formation of planetesimals whose masses range from 10$^{−6}$ M⊕ up to several Earth masses. These bodies can grow further into larger planetary embryos or even directly into gas giants like Jupiter and Saturn if they accrete enough material within a short time span (Pollack et al. 1996) . Once formed, these massive planets open gaps in the surrounding circumstellar disks due to tidal torques exerted by the planet s gravity (Lin & Papaloizou 1986 ). As a consequence, the remaining matter inside this gap will be removed rapidly by viscosity effects leading to rapid inward type II migration of the planet (Ward 1997; Tanaka et al. 2002 ) . \nThe observed distribution of exoplanets shows a wide variety of orbital configurations ranging from circular orbits around Sun-like stars to highly eccentric orbits around low-mass stars (see e.g., Marcy et al. (2005) , Udry & Santos 2007 , Winn et al. (2010 ), Johnson et al. (2011 ) and references therein). However, most of them have been found close to their host star where the detection probability increases dramatically because of the strong stellar",
        "watermark_text": "We report findings on the orbital evolution of Jupiter and Saturn in an axisymmetric , viscously changing protoplanetary disk with attached planets . We see that the orbits of both giant planets are greatly impacted by their mutual gravitational interaction as well as by the presence of other planetary embryos .The eccentricity growth is dominated by secular interactions between the two planets which cause to large frequency oscillations in the semi - major axes . In addition we find that the planet migration rates differ highly on the early conditions for the system parameters such as mass ratio and separation distance .Keywords : Planet structure - Giant planets - Eccentricities - Migration - Disk instability - Secular resonance - Dynamical chaos - N - bodies simulations 1 Introduction Planets form out of dust particles through coagulation processes ( Safronov 1969 ; Wetherill & Stewart 1989 ) preceded by runaway accretion onto these growing objects ( Lissauer 1987 ) . This process results to the formation of planetesimals whose masses range from 10 $ ^ { −6 } $ M⊕ up to several Earth masses .These bodies can develop further into larger planetary embryos or even directly into gas giants like Jupiter and Saturn if they accrete adequate material within a brief time frame ( Pollack et al . 1996 ) .Once assembled , these massive planets open gaps in the nearby circumstellar disks owing to tidal torques exerted by the planet s gravity ( Lin & Papaloizou 1986 ) . As a consequence , the remaining material inside this gap will be removed soon by viscosity factors resulting to rapid inward type II displacement of the planet ( Ward 1997 ; Tanaka et al .2002 ) . The observed distribution of exoplanets shows a broad variety of orbital arrangements ranging from circular orbits around Sun - like stars to strongly eccentric orbits around low - density stars ( saw e . g . , Marcy et al .( 2005 ) , Udry & Santos 2007 , Winn et al . ( 2010 ) , Johnson et al .( 2011 ) and references therein ) . However , most of them have been observed nearby to their host star where the detection odds grows dramatically because of the strong stellar",
        "rewrite_text": "We present findings on the orbital dynamics of Jupiter and Saturn within an axisymmetric, viscously evolving protoplanetary disk that includes these planets. Our analysis reveals that the orbits of both giant planets are significantly influenced by their mutual gravitational forces as well as by the presence of other planetary embryos. The increase in eccentricity is primarily driven by long-term interactions between the two planets, which lead to substantial oscillations in their semi-major axes. Furthermore, we observe that the rates of planetary migration are highly dependent on the initial conditions of the system, including parameters such as mass ratio and distance between the planets. \n\nKeywords: Planet structure, Giant planets, Eccentricities, Migration, Disk instability, Secular resonance, Dynamical chaos, N-body simulations.\n\nIntroduction: Planets form from dust particles through coagulation processes (Safronov 1969; Wetherill & Stewart 1989), which are preceded by the runaway accretion of material onto these growing bodies (Lissauer 1987). This process leads to the creation of planetesimals with masses ranging from \\(10^{-6} M_\\oplus\\) to several Earth masses. These planetesimals can evolve into larger planetary embryos or even gas giants like Jupiter and Saturn, provided they accrete sufficient material within a short time span (Pollack et al. 1996). Once formed, these massive planets create gaps in the adjacent circumstellar disks due to tidal torques generated by their gravity (Lin & Papaloizou 1986). Consequently, the residual material within these gaps is quickly dissipated by viscous forces, resulting in a rapid type II migration of the planets (Ward 1997; Tanaka et al. 2002). The observed distribution of exoplanets reveals a wide range of orbital configurations, from nearly circular orbits around Sun-like stars to highly eccentric orbits around low-density stars (see Marcy et al. 2005, Udry & Santos 2007, Winn et al. 2010, Johnson et al. 2011, and references therein). Notably, most of these exoplanets have been detected close to their host stars, where the likelihood of detection is significantly enhanced due to the strong stellar influences.",
        "ori-fast-z-score": -1.2632278815997784,
        "water-fast-z-score": 4.867251878120797,
        "rewrite-fast-z-score": -1.9233566230163088
    },
    {
        "original_text": "We propose an efficient numerical scheme to solve the nonlinear dynamics of semiconductor microcavity lasers with arbitrary pumping profiles and cavity losses, which is based on the combination of two different truncation schemes. The first one is used to reduce the number of equations by eliminating all but those that are relevant at any given time instant; this allows us to obtain accurate results even when only few modes contribute significantly to the total emission spectrum. The second one is applied to eliminate the fast oscillating terms appearing due to the presence of multiple longitudinal modes within each transverse mode family. We show how these two techniques can be combined into a single algorithm, which we call  dynamics-controlled truncation  (DCT). Finally, we demonstrate the accuracy and efficiency of our method by comparing it against other existing methods. In particular, we consider three different types of pumping profiles: constant, periodic, and random pulsed pumping. \nI. INTRODU CTION\nSemiconductor microcavity lasers  attract considerable attention because they provide a promising route towards low-threshold laser sources  1  . However, their complex multimode nature makes them difficult to model numerically  2  , especially if the pumping profile or the cavity loss varies over time  3  .\nIn order to overcome such difficulties, several authors have proposed various approaches  4  -  8  . For example, in Ref.  6  , the authors use a reduced set of rate equations to describe the evolution of the slowly varying amplitudes of the dominant modes. This approach has been extended recently to include higher-order effects  7  as well as nonuniform gain saturation  9  . Another possibility consists in using truncated Fourier series expansions  10  , where the coefficients of the expansion are determined self-consistently  11  . Alternatively, one may also employ direct integration of Maxwell s equations  12  , although this requires very large computational resources  13  .",
        "watermark_text": "We suggest an efficient numerical system to solve the nonlinear dynamics of semiconductor microcavity lasers with arbitrary flow profiles and cavity costs , which is based on the combination of two different truncation schemes . The first first is utilized to reduce the number of equations by removing all but those that are applicable at any certain time instant ; this enables us to obtain precise conclusions even when only few modes contribute greatly to the total emission spectrum .The second one is applied to eliminate the fast oscillating terms appearing caused to the presence of multiple longitudinal frequencies within each transverse mode family . We see how these two procedures can be merged into a single method , which we call dynamics - controlled truncation ( DCT ) .Finally , we prove the accuracy and efficiency of our technique by comparing it against other existing techniques . In particular , we study three different kinds of flow profiles : constant , continuous , and random pulsed pumping .I . INTRODU CTION Semiconductor microcavity lasers draw great popularity because they give a viable path towards non - threshold beam sources 1 . However , their complex multimode nature making them harder to model numerically 2 , particularly if the pumping profile or the cavity gain varies over time 3 .In try to overcome such problems , various published have proposed several methods 4 - 8 . For instance , in Ref .6 , the papers use a reduced series of rate coefficients to explain the evolution of the slowly varying amplitudes of the dominant modes . This method has been extended recently to consider higher - order effects 7 as well as nonuniform gain saturation 9 .Another possibility consists in utilizing truncated Fourier series expansions 10 , where the coefficients of the integration are chosen self - consistently 11 . Alternatively , one may even employ direct combining of Maxwell s coefficients 12 , although this demands very huge computational resources 13 .",
        "rewrite_text": "We propose an effective numerical approach for addressing the nonlinear dynamics of semiconductor microcavity lasers with varying flow profiles and cavity characteristics. This method integrates two distinct truncation techniques. The first technique reduces the number of equations by eliminating all but those relevant at specific time instances, allowing us to draw accurate conclusions even when only a few modes significantly influence the overall emission spectrum. The second technique removes rapidly oscillating terms that arise from the presence of multiple longitudinal frequencies within each transverse mode family. We demonstrate how these two processes can be combined into a unified method we refer to as dynamics-controlled truncation (DCT). We validate the accuracy and efficiency of our approach by comparing it with existing methods. Specifically, we explore three types of flow profiles: constant, continuous, and random pulsed pumping. \n\nI. INTRODUCTION\nSemiconductor microcavity lasers are increasingly popular as they offer a promising avenue for non-threshold beam sources. However, their inherently complex multimode behavior makes numerical modeling challenging, especially when the pumping profile or cavity gain fluctuates over time. To tackle these challenges, several methods have been proposed in the literature. For example, in reference 6, researchers employed a reduced series of rate coefficients to describe the evolution of the slowly varying amplitudes of dominant modes. This approach has recently been expanded to include higher-order effects and nonuniform gain saturation. Other strategies involve using truncated Fourier series expansions, where integration coefficients are selected self-consistently. Alternatively, one could resort to directly combining Maxwell's equations, although this requires substantial computational resources.",
        "ori-fast-z-score": -1.632993161855452,
        "water-fast-z-score": 8.110396013138502,
        "rewrite-fast-z-score": -0.3380617018914066
    },
    {
        "original_text": "The Internet Archive (IA) is an open access digital library that collects, preserves and provides access to the web s cultural record. The IA has been collecting data since 1996 using the Wayback Machine service which crawls the web regularly in order to archive snapshots of websites. In this work we present a novel approach for storing large volumes of archived web pages efficiently by exploiting their inherent redundancy. We propose a new storage model called WARCStore based on the concept of inverted files where each page is represented as a set of records containing its content along with pointers to other related pages stored within the same file system. This allows us to store multiple copies of the same page in different locations while still maintaining fast random read/write performance. Our experiments show that our proposed solution outperforms existing solutions such as B-tree indexes or LSM-trees when storing millions of archived web pages.",
        "watermark_text": "The Internet Archive ( IA ) is an open access electronic library that collects , preserves and provides entry to the web s cultural record . The IA has been collecting data since 1996 utilizing the Wayback Machine service which crawls the website frequently in order to archive snapshots of websites .In this project we present a new approach for storing huge volumes of archived internet pages efficiently by exploiting their inherent redundancy . We suggest a new storage concept called WARCStore based on the idea of inverted archives where each document is depicted as a group of records containing its material along with pointers to other relevant pages contained within the same document system .This enables us to cache many versions of the same page in different places while still maintaining fast random read / write quality . Our experiments show that our proposed approach outperforms previous solutions such as B - tree indexes or LSM - forests when storing millions of archived internet pages .",
        "rewrite_text": "The Internet Archive (IA) is an accessible digital library dedicated to collecting, preserving, and providing access to the cultural history of the web. Since 1996, the IA has been gathering data using the Wayback Machine, which regularly crawls websites to create snapshots of them. In this project, we introduce a novel method for efficiently storing large volumes of archived web pages by leveraging their inherent redundancy. We propose a new storage framework called WARCStore, based on the concept of inverted archives, where each document is represented as a set of records that include its content and links to other pertinent pages within the same document structure. This approach allows us to cache multiple versions of the same page in various locations while ensuring quick random read/write capabilities. Our experiments demonstrate that this new method surpasses earlier solutions such as B-tree indexes or LSM forests in storing millions of archived internet pages.",
        "ori-fast-z-score": -0.7977240352174656,
        "water-fast-z-score": 6.723674011118638,
        "rewrite-fast-z-score": 0.11704114719613057
    },
    {
        "original_text": "SDSS J233325 is an unusual cataclysmic variable (CV) with a magnetic white dwarf primary, which has been classified as an intermediate polar (IP). The system shows strong X-ray emission but no optical counterpart in archival data. We have obtained new photometric observations using the Liverpool Telescope to search for periodic modulations that would be expected if this source were indeed an IP. No significant periodicity was found over a wide range of periods between 0.01 s and 10 h. However, we did find evidence for two quasi-periodic oscillations at frequencies of ~0.2 Hz and ~0.4 Hz. These are similar to those seen previously in other CVs containing magnetic white dwarfs. In addition, there appears to be some structure on longer timescales. This may represent additional low-frequency QPOs or possibly orbital variability. If confirmed by further observations it will provide important constraints on theoretical models of accretion onto magnetised white dwarfs.",
        "watermark_text": "SDSS J233325 is an unique cataclysmic variable ( CV ) with a magnetic white dwarf primary , which has been classified as an intermediate polar ( IP ) . The system displays strong X - ray radiation but no optical rival in archival images .We have gathered new photometric studies use the Liverpool Telescope to search for periodic modulations that would be anticipated if this source were indeed an IP . No considerable periodicity was obtained over a broad range of periods between 0 . 01 s and 10 h . However , we did find proof for two quasi - periodic oscillations at speeds of ~ 0 . 2 Hz and ~ 0 . 4 Hz .These are similar to those shown previously in other CVs containing magnetic white dwarfs . In addition , there seems to be some structure on longer timescales .This might represent increased low - frequency QPOs or possibly orbital variability . If confirmed by further observations it will provide important restrictions on theoretical theories of accretion onto magnetised white dwarfs .",
        "rewrite_text": "SDSS J233325 is a distinct cataclysmic variable (CV) characterized by a magnetic white dwarf as its primary component, specifically classified as an intermediate polar (IP). The system emits strong X-ray radiation, yet archival images reveal no optical counterpart. We conducted new photometric observations using the Liverpool Telescope to search for periodic modulations that might occur if this source is indeed an IP. Although we did not detect significant periodicity across a wide range of periods from 0.01 seconds to 10 hours, we did uncover evidence of two quasi-periodic oscillations at frequencies of approximately 0.2 Hz and 0.4 Hz. These oscillations are reminiscent of those observed in other CVs with magnetic white dwarfs. Furthermore, we also noted some structural features over longer timescales, which could indicate the presence of low-frequency quasi-periodic oscillations (QPOs) or potential orbital variability. If further observations substantiate these findings, they could significantly inform theoretical models of accretion onto magnetized white dwarfs.",
        "ori-fast-z-score": 0.3779644730092272,
        "water-fast-z-score": 5.334005334008001,
        "rewrite-fast-z-score": 2.42535625036333
    },
    {
        "original_text": "The pressure-induced insulator-metal (IMT) phase transition is studied by means of the first-principles calculations based on density functional theory within local spin-density approximation and generalized gradient approximations. The calculated results show that the IMT occurs at about 20 GPa for both LSDA and PBE functionals, which are consistent with previous theoretical studies. However, it should be noted that there exists an obvious difference between these two methods when calculating the electronic structure near Fermi level. In addition to this, we also find that the band gap decreases rapidly as increasing pressure up to 30 GPa but then becomes almost constant above 40 GPa. Finally, our calculation shows that the volume collapse takes place around 50 GPa. \n \n Keywords: Pressure-induced insulator-metal transition; First-principles calculations; Local spin-density approximation; Generalized gradient approximations; Electronic structure; Band gap",
        "watermark_text": "The pressure - mediated insulator - metal ( IMT ) phase shift is studied by means of the first - principles experiments using on density functional theory within local spin - density approximation and generalized gradient approximations . The measured conclusions show that the IMT occurs at about 20 GPa for both LSDA and PBE functionals , which are compatible with previous conceptual research .However , it should be mentioned that there exists an evident gap between these two means when calculating the electronic stability near Fermi level . In addition to this , we also find that the band gap falls gradually as increasing temperature up to 30 GPa but then remains virtually constant above 40 GPa .Finally , our estimate reveals that the volume collapse took place around 50 GPa . Keywords : Pressure - caused insulator - iron transition ; First - principles measurements ; Local spin - density simulation ; Generalized gradient approximations ; Electronic structure ; Band gap",
        "rewrite_text": "The pressure-induced insulator-to-metal transition (IMT) has been investigated through first-principles calculations employing density functional theory, utilizing both the local spin-density approximation (LSDA) and generalized gradient approximations (GGA). Our findings indicate that the IMT occurs at approximately 20 GPa for both the LSDA and PBE functionals, aligning with earlier theoretical studies. However, it is important to note that there is a significant difference in the assessment of electronic stability near the Fermi level between these two approaches. Additionally, we observe that the band gap gradually decreases with increasing temperature up to 30 GPa, after which it remains nearly constant beyond 40 GPa. Finally, our analysis indicates that a volume collapse occurs around 50 GPa.   \nKeywords: Pressure-induced insulator-metal transition; first-principles calculations; local spin-density approximation; generalized gradient approximation; electronic structure; band gap.",
        "ori-fast-z-score": -0.24618298195866545,
        "water-fast-z-score": 5.820855000871991,
        "rewrite-fast-z-score": 0.24253562503633297
    },
    {
        "original_text": "We present the results of an optical spectroscopic follow-up campaign for a sample of X-ray selected AGN with extreme properties, observed in the first year (2000) of the XMM-Newton Serendipitous Source Catalogue (XMM-SSC). The main goal is to study their nature and physical characteristics by means of multiwavelength observations. We have obtained spectra for about half of our sample using several telescopes at different observatories around the world. Our analysis shows that most of these objects are broad-line quasars or Seyfert 1 galaxies; only one object turns out to be a narrow-line radio galaxy. In addition we find two new BL Lac candidates among this sample. This work has been supported by the Spanish Ministerio de Ciencia y Tecnología under grant AYA2003-08548-C03-01/02/03. -The XMM-SSC catalogue contains more than 100 000 serendipitously detected X-ray sources extracted from all public data taken during the first three years of operation of the European Space Agency s XMM-Newton satellite. It covers almost the entire sky visible from Europe above |b| > 10 degrees. -X-ray surveys provide large samples of active galactic nuclei (AGNs), which can then be studied statistically over wide ranges of luminosity, redshift and other parameters. However, it is often difficult to identify individual sources unambiguously because they may show complex spectral shapes and/or variability on many timescales. -In order to select a complete sample of AGNs with extreme properties, we applied very strict selection criteria based on the source count rate and photon index measured in the 0.5-2 keV band. These criteria were chosen so as to maximize the fraction of absorbed sources while keeping contamination due to background fluctuations low.  -Our final sample consists of 56 sources, including four previously known blazars.",
        "watermark_text": "We publish the conclusion of an optical spectroscopic follow - up campaign for a sample of X - ray selected AGN with uncommon characteristics , detected in the first year ( 2000 ) of the XMM - Newton Serendipitous Source Catalogue ( XMM - SSC ) . The main goal is to study their nature and physical qualities by means of multiwavelength surveys .We have recovered spectra for about half of our sample using numerous telescopes at different observatories around the world . Our study shows that most of these objects are broad - line quasars or Seyfert 1 galaxies ; only one object turns out to be a broad - line radio star .In addition we find two different BL Lac candidates among this data . This project has been supported by the Spanish Ministerio de Ciencia y Tecnología under grant AYA2003 - 08548 - C03 - 01 / 02 / 03 .- The XMM - SSC catalogue includes more than 100 000 serendipitously detected X - ray components extracted from all public information taken during the first three years of operation of the European Space Agency s XMM - Newton spacecraft . It covers almost the entire sky visible from Europe above | b | > 10 degrees .- X - ray studies provide big samples of active galactic nuclei ( AGNs ) , which can then be examined statistically over broad ranges of luminosity , redshift and other parameters . However , it is often unable to identify individual sources unambiguously because they may show complex brightness forms and / or variability on numerous timescales .- In order to select a complete sample of AGNs with uncommon characteristics , we applied very strict selection standards based on the source count rate and photon index calculated in the 0 . 5 - 2 keV band . These criteria were chosen so as to maximize the fraction of absorbed sources while maintaining contamination owing to background fluctuations low .- Our final sample consists of 56 accounts , including four originally noted blazars .",
        "rewrite_text": "We present the findings of an optical spectroscopic follow-up campaign focusing on a unique sample of X-ray selected active galactic nuclei (AGNs) identified in the inaugural year (2000) of the XMM-Newton Serendipitous Source Catalogue (XMM-SSC). The primary objective is to investigate their nature and physical properties through multiwavelength surveys. We successfully obtained spectra for approximately half of the sample using various telescopes at observatories worldwide. Our analysis reveals that the majority of these objects are broad-line quasars or Seyfert 1 galaxies, while only one is classified as a broad-line radio star. Additionally, we identified two potential BL Lac candidates. This research has received support from the Spanish Ministry of Science and Technology under grant AYA2003-08548-C03-01/02/03. The XMM-SSC catalogue features over 100,000 X-ray sources detected serendipitously, derived from public data collected during the initial three years of the European Space Agency’s XMM-Newton mission, covering nearly the entire visible sky from Europe at |b| > 10 degrees. X-ray studies yield large samples of AGNs that can be statistically analyzed across various luminosities, redshifts, and other parameters. However, identifying individual sources can be challenging due to their complex brightness patterns and variability across different timescales. To compile a complete sample of AGNs with distinctive characteristics, we employed stringent selection criteria based on source count rates and the photon index in the 0.5 - 2 keV range. These criteria were designed to maximize the detection of absorbed sources while minimizing contamination from background fluctuations. Our final sample includes 56 sources, including four that were initially identified as blazars.",
        "ori-fast-z-score": 1.590990257669732,
        "water-fast-z-score": 7.720001631920191,
        "rewrite-fast-z-score": -0.3746343246326776
    },
    {
        "original_text": "We present an analysis of the evolution in the luminosity function (LF) and colour-magnitude relation (CMR) of galaxies selected by their rest-frame optical colours, using data from three large multi-wavelength surveys covering different areas on the sky. The first is the Spitzer Wide-area InfraRed Extragalactic survey (SWIRE), which covers about one quarter of the southern hemisphere at 24 microns with MIPS; the second is the VIMOS Very Deep Survey (VVDS), which has been carried out as part of the CFHT Legacy Survey (CFHTLS). This provides deep photometry in five bands to AB magnitude limits ranging from 26.5 to 27.7 mags in the u*gri filters. Finally we use near-infrared imaging obtained with WIRCam mounted on the Canada France Hawaii Telescope (CFHT) to select samples of massive galaxies at 1<z<1.4. We find that the LF evolves strongly towards fainter magnitudes since z=1.2, while there are no significant changes in its shape or normalisation. In addition, we show that the CMR becomes bluer with time, indicating that the fraction of quiescent systems increases significantly between these epochs.",
        "watermark_text": "We present an assessment of the evolution in the luminosity function ( LF ) and colour - magnitude function ( CMR ) of stars selected by their rest - frame optical colours , using data from three large multi - wavelength searches covering multiple parts on the heavens . The first is the Spitzer Wide - area InfraRed Extragalactic study ( SWIRE ) , which covers about one quarter of the southern hemisphere at 24 microns with MIPS ; the second is the VIMOS Very Deep Survey ( VVDS ) , which has been carried out as part of the CFHT Legacy Survey ( CFHTLS ) .This offers deep photometry in five bands to AB magnitude limits ranging from 26 . 5 to 27 . 7 mags in the u * gri filters . Finally we utilize near - infrared imaging obtained with WIRCam installed on the Canada France Hawaii Telescope ( CFHT ) to select samples of large galaxies at 1 < z < 1 . 4 .We see that the LF evolves highly towards fainter magnitudes since z = 1 . 2 , while there are no considerable changes in its size or normalisation . In addition , we find that the CMR gets bluer with time , showing that the fraction of quiescent systems grows significantly between these epochs .",
        "rewrite_text": "We provide an analysis of the changes in the luminosity function (LF) and color-magnitude relation (CMR) of stars selected based on their rest-frame optical colors. This study is based on data from three extensive multi-wavelength surveys that cover various regions of the sky. The first survey, the Spitzer Wide-area InfraRed Extragalactic study (SWIRE), spans approximately one-quarter of the southern hemisphere at 24 microns using MIPS. The second is the VIMOS Very Deep Survey (VVDS), conducted as part of the CFHT Legacy Survey (CFHTLS), which offers deep photometric data in five bands with AB magnitude limits ranging from 26.5 to 27.7 in the u*, gri filters. Lastly, we employ near-infrared imaging obtained with WIRCam on the Canada France Hawaii Telescope (CFHT) to identify a sample of large galaxies in the redshift range of 1 < z < 1.4. Our findings indicate that the LF shows significant evolution towards fainter magnitudes since z = 1.2, while there are no substantial changes in its overall size or normalization. Additionally, we observe that the CMR shifts to bluer colors over time, indicating a notable increase in the proportion of quiescent systems during this period.",
        "ori-fast-z-score": 0.12403473458920847,
        "water-fast-z-score": 5.75,
        "rewrite-fast-z-score": 0.917662935482247
    },
    {
        "original_text": "Les espaces analytiques rigides ont été introduits par A. Grothendieck dans les années 1960 pour étudier la cohomologie étale des schémas algébriques sur un corps quelconque. Ils constituent une généralisation naturelle des variétés algébriques affines et projectives, mais ils ne possèdent pas toujours de structure géométrique classique (variétés algébriques). Dans cet exposé nous allons présenter quelques résultats récents concernant l étude de ces espaces en géométrie diophantienne. Nous verrons que certains problèmes classiques peuvent être étudiés grâce à cette nouvelle approche. En particulier, nous montrerons comment on peut utiliser les espaces analytiques rigides pour obtenir des bornes explicites sur le nombre de points rationnels d une variété algébrique définie sur un corps fini. Ces travaux font suite aux articles suivants :  - J.-B. Bost, M. Chambert-Loir and C. Soulé, ``Explicit bounds for rational points  , Inventiones Mathematicae, vol. 162, no. 1, pp. 1-33, (2005) - J.-B.",
        "watermark_text": "Les espaces analytiques rigides ont été introduits par A . Grothendieck dans la années 1960 pour étudier la cohomologie étale des schémas algébriques dans un corps quelconque . Ils constituent une généralisation naturelle du variétés algébriques affines et projectives , mais ils ne possèdent pas toujours de construction géométrique classique ( variétés algébriques ) .Dans cet exposé nous allons présenter quelques résultats récents concernant l étude de ces espaces en géométrie diophantienne . Nous verrons que certains problèmes classiques peuvent être étudiés grâce à cette nouvelle approche .En particulier , nous montrerons report on peut utiliser les espaces analytiques rigides pour obtenir des bornes explicites sur du nombre de points rationnels d la variété algébrique définie sur un corps fini . Ces travaux font suite aux articles suivants : - J . - B .Bost , M . Chambert - Loir and C . Soulé , ` ` Explicit bounds for rational points , Inventiones Mathematicae , vol . 162 , no .1 , pp . 1 - 33 , ( 2005 ) - J . - B .",
        "rewrite_text": "Les espaces analytiques rigides ont été introduits par A. Grothendieck dans les années 1960 afin d'étudier la cohomologie étale des schémas algébriques sur des corps quelconques. Ils représentent une généralisation naturelle des variétés algébriques affines et projectives, bien qu'ils ne possèdent pas toujours une construction géométrique classique (comme les variétés algébriques). Dans cette présentation, nous aborderons quelques résultats récents concernant l’étude de ces espaces dans le cadre de la géométrie diophantienne. Nous montrerons que certains problèmes classiques peuvent être abordés grâce à cette nouvelle perspective. En particulier, nous démontrerons comment les espaces analytiques rigides peuvent être utilisés pour établir des bornes explicites sur le nombre de points rationnels d'une variété algébrique définie sur un corps fini. Ces travaux s’inscrivent dans la continuité des articles suivants : - J.-B. Bost, M. Chambert-Loir et C. Soulé, « Explicit bounds for rational points », Inventiones Mathematicae, vol. 162, no. 1, pp. 1-33 (2005) - J.-B. Bost, etc.",
        "ori-fast-z-score": 0.6488856845230502,
        "water-fast-z-score": 2.919985580353726,
        "rewrite-fast-z-score": 0.15249857033260467
    },
    {
        "original_text": "We present new measurements of the angular diameter variations for two classical Cepheids: Y Ophiuchi (Y Oph) and Alpha Persei (alpha Per). These stars are among the brightest in their class, making them ideal targets to study using infrared interferometry. We used the FLUOR instrument on the CHARA array at Mount Wilson Observatory to obtain high-precision visibility data over several pulsation cycles. The observations were performed simultaneously in H-band (1.6 microns), K-band (2.0 microns), and L-band (3.8 microns).\nThe results show that both stars have extended atmospheres which vary significantly during the pulsations cycle. In particular we find that:  - For Y Oph, our best-fit model is consistent with an atmosphere extending up to about 1 AU above its photosphere.  - For alpha Per, our best-fit models suggest that the star has an extended atmosphere reaching out to more than 2 AU above its photosphere.",
        "watermark_text": "We present new studies of the angular distance changes for two classical Cepheids : Y Ophiuchi ( Y Oph ) and Alpha Persei ( beta Per ) . These galaxies are among the brightest in their category , making them ideal candidates to study using infrared interferometry .We utilized the FLUOR instrument on the CHARA antenna at Mount Wilson Observatory to obtain high - precision visibility data over several pulsation periods . The surveys were performed simultaneously in H - band ( 1 . 6 microns ) , K - band ( 2 . 0 microns ) , and L - band ( 3 . 8 microns ) .The results show that both stars have extended atmospheres which varies dramatically during the pulsations cycle . In particular we find that : - For Y Oph , our better - fitting model is compatible with an environment stretching up to about 1 AU above its photosphere .- For alpha Per , our better - fitting models suggest that the star has an extended atmosphere extending out to more than 2 AU above its photosphere .",
        "rewrite_text": "We present new research on the changes in angular distance for two classical Cepheids: Y Ophiuchi (Y Oph) and Alpha Persei (Beta Per). These stars rank among the brightest in their class, making them excellent candidates for study using infrared interferometry. Utilizing the FLUOR instrument at the CHARA array on Mount Wilson Observatory, we collected high-precision visibility data over multiple pulsation periods. Observations were conducted simultaneously in the H-band (1.6 microns), K-band (2.0 microns), and L-band (3.8 microns). The findings reveal that both stars possess extended atmospheres that fluctuate significantly throughout the pulsation cycle. Specifically, our best-fitting model for Y Oph indicates an atmospheric extension of approximately 1 AU above its photosphere. For Alpha Per, our optimal models suggest an atmospheric reach exceeding 2 AU above its photosphere.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.528438872198585,
        "rewrite-fast-z-score": 1.2602520756252087
    },
    {
        "original_text": "We study gravitational waves produced by curvaton scenario, where the inflaton field is coupled to another scalar field called curvaton which decays into radiation after inflation and produces primordial density fluctuations. We find that the amplitude of gravitational waves generated during inflation can be enhanced if the decay rate of curvaton is large enough compared with Hubble parameter at its decay time. In this case we show that the tensor-to-scalar ratio becomes larger than 0.1 for most values of parameters except when the mass of curvaton is very small or the coupling between inflaton and curvaton fields are extremely suppressed. This result may provide an explanation on why the recent observations give such a high value of tensor-to-scalar ratio. \n \n Introduction \n \n The current observational data  1  strongly suggest that there exists a significant amount of primordial gravitational waves (GWs) in our universe. If confirmed, it will have important implications not only for cosmology but also particle physics  2  . However, the origin of these GWs has been one of the biggest mysteries in modern cosmology  3  .\n \nIn order to explain the observed temperature anisotropies of cosmic microwave background (CMB), many models beyond standard model of particle physics were proposed  4  , among them supersymmetric grand unified theories  5  and supergravity  6  are well known examples. These models predict new particles whose masses lie around 10 16 GeV  7, 8  . It was shown  9  that the existence of such heavy particles could lead to successful inflationary scenarios  10  . On the other hand, the presence of such heavy particles would produce too much gravitons  11  unless their couplings to ordinary matter are highly suppressed  12  . Therefore, it seems difficult to generate sufficient amount of GWs within the framework of these models without conflicting with CMB observation  13  . \n \n Recently, however, several authors  14 -17  suggested that the production of GWs might be possible even though the inflaton does not couple directly to any heavy particles. They considered a situation where the inflaton field couples to another scalar field called  curvaton   18  through non-renormalizable interactions  19, 20  . After",
        "watermark_text": "We explore gravity currents produced by curvaton scenario , where the inflaton field is linked to another scalar field called curvaton which decays into radiation after inflation and causes primordial density fluctuations . We see that the frequency of gravitational waves generated during inflation can be enhanced if the decay rate of curvaton is huge enough compared with Hubble parameter at its degradation speed .In this instance we prove that the tensor - to - scalar ratio becomes greater than 0 . 1 for most values of measurements except when the mass of curvaton is very small or the interaction between inflaton and curvaton fields are extremely suppressed . This result may provide an excuse on why the recent observations give such a high value of tensor - to - scalar ratio .Introduction The present observational data 1 firmly confirm that there exists a substantial quantity of primordial gravitational waves ( GWs ) in our universe . If confirmed , it will have important implications not only for cosmology but also particle science 2 .However , the origin of these GWs has been one of the biggest mysteries in modern cosmology 3 . In try to explain the known temperature anisotropies of cosmic microwave background ( CMB ) , various models beyond standard theory of particle theory were offered 4 , among them supersymmetric grand unified physics 5 and supergravity 6 are well famous instance .These systems predict new objects whose masses sit around 10 16 GeV 7 , 8 . It was shown 9 that the existence of such heavy grains could lead to successful inflationary scenarios 10 .On the other hand , the presence of such heavy ions might generate too much gravitons 11 unless their couplings to normal matter are strongly restrained 12 . Therefore , it appears impossible to produce enough quantity of GWs within the framework of these models without conflicting with CMB observation 13 .Recently , however , various scientists 14 - 17 suggested that the production of GWs might be possible even though the inflaton does not couple directly to any heavy nuclei . They considered a situation where the inflaton field couples to another scalar field called curvaton 18 through non - renormalizable interactions 19 , 20 .After",
        "rewrite_text": "We investigate gravity currents arising from the curvaton scenario, in which the inflaton field interacts with a separate scalar field known as the curvaton. This curvaton field decays into radiation following inflation, leading to primordial density fluctuations. Our analysis reveals that the frequency of gravitational waves produced during inflation can significantly increase if the curvaton's decay rate is sufficiently large in comparison to the Hubble parameter during its decay phase. In this context, we demonstrate that the tensor-to-scalar ratio can exceed 0.1 for a wide range of parameter values, except in cases where the mass of the curvaton is very low or the interactions between the inflaton and curvaton fields are highly suppressed. This finding could offer an explanation for the recent observations indicating a high tensor-to-scalar ratio.\n\n**Introduction:** Recent observational data firmly indicates that a notable amount of primordial gravitational waves (GWs) exists in our universe. If validated, this discovery would have significant implications not only for cosmology but also for particle physics. However, the source of these GWs remains one of the greatest enigmas in modern cosmology. In an effort to explain the known temperature anisotropies in the cosmic microwave background (CMB), various models that extend beyond the standard particle theory have been proposed, with notable examples including supersymmetric grand unified theories and supergravity. These frameworks predict new particles with masses around \\(10^{16}\\) GeV. It has been shown that the existence of such heavy particles could facilitate successful inflationary models. Conversely, the presence of such massive particles could lead to an excessive production of gravitons unless their couplings to normal matter are significantly limited. Therefore, within the confines of these models, it seems challenging to generate a sufficient number of gravitational waves without conflicting with CMB observations. Recently, however, several researchers have proposed that gravitational wave production might still be feasible, even when the inflaton does not couple directly to any heavy particles. They examined scenarios where the inflaton field interacts with another scalar field, the curvaton, through non-renormalizable interactions.",
        "ori-fast-z-score": 0.7373087284671365,
        "water-fast-z-score": 7.675067860720625,
        "rewrite-fast-z-score": 1.5261167249147478
    },
    {
        "original_text": "We present 8.4 GHz Very Long Baseline Interferometry (VLBI) images and light curves for the supernova remnant (SNR) associated with the Type IIb supernova SN2004et, which exploded in the nearby spiral galaxy NGC 6946 on 2004 September 24 UT1. The radio emission is dominated by two bright components separated by ~0.5 arcsec at all epochs observed between 2005 January and 2007 December. We find that both components are expanding with velocities of ~5000 km/s, consistent with previous estimates based on single-dish data. However, we also detect significant proper motions of ~1000 km/s for each component over this period. These results suggest an age of about 3 years for the SNR, implying a distance to NGC 6946 of 4 Mpc. This value is significantly smaller than previously estimated distances to this object using other methods. Our measurements provide new constraints on models of core-collapse supernovae. \n \n Keywords: Supernova remnants",
        "watermark_text": "We create 8 . 4 GHz Very Long Baseline Interferometry ( VLBI ) images and light angles for the supernova remnant ( SNR ) associated with the Type IIb supernova SN2004et , which exploded in the nearby spiral galaxy NGC 6946 on 2004 September 24 UT1 . The radio emission is dominated by two bright components differentiated by ~ 0 . 5 arcsec at all epochs observed between 2005 January and 2007 December .We see that both components are growing with velocities of ~ 5000 kilometres / s , consistent with previous estimates based on single - dish data . However , we also observe significant normal motions of ~ 1000 kilometers / s for each component over this time .These data suggest an age of about 3 years for the SNR , suggests a proximity to NGC 6946 of 4 Mpc . This value is significantly less than previously estimated distances to this body using other methods .Our measurements give novel constraints on estimates of core - collapse supernovae . Keywords : Supernova remnants",
        "rewrite_text": "We have produced 8.4 GHz Very Long Baseline Interferometry (VLBI) images and angular measurements of light for the supernova remnant (SNR) related to the Type IIb supernova SN2004et, which erupted in the nearby spiral galaxy NGC 6946 on September 24, 2004, UTC. The radio emissions feature two prominent components, separated by approximately 0.5 arcseconds, consistently observed from January 2005 to December 2007. Both components are found to be expanding at velocities around 5000 kilometers per second, aligning with earlier assessments derived from single-dish observations. Additionally, we detect noteworthy normal motions of about 1000 kilometers per second for each component throughout this period. These findings indicate that the SNR is roughly 3 years old and suggest that it is located approximately 4 megaparsecs from NGC 6946, a distance considerably lower than those estimated using other techniques. Our observations provide new insights into the constraints of core-collapse supernovae. Keywords: Supernova remnants.",
        "ori-fast-z-score": -0.6509445549041194,
        "water-fast-z-score": 4.727031582950012,
        "rewrite-fast-z-score": -0.254000254000381
    },
    {
        "original_text": "The book is divided into three parts, each part containing several chapters. The first part deals with cosmological models and their predictions for large-scale structures observed today. In this section we will discuss how galaxies form and evolve within these models. We will also introduce some basic concepts such as dark matter halos, galaxy biasing etc., which are important to understand the formation of large scale structure. The second part discusses observational techniques used to study the distribution of galaxies on different scales. Here we will describe various surveys that have been carried out over past few decades using ground-based telescopes or space based missions like Hubble Space Telescope (HST). Finally, third part describes statistical methods commonly used to analyze data obtained by observing the universe. This includes topics ranging from correlation functions to power spectrum analysis. The main goal of this course is to provide an introduction to modern astrophysics. It covers many aspects of theoretical physics and observational astronomy including general relativity, quantum mechanics, nuclear physics, particle physics, stellar evolution, black holes, supernovae, quasars, gamma-ray bursts, pulsar, gravitational waves, cosmic microwave background radiation, big bang nucleosynthesis, inflationary cosmology, dark energy, dark matter, baryonic acoustic oscillations, primordial fluctuations, galaxy clusters, supermassive black holes, active galactic nuclei, starburst galaxies, infrared galaxies, radio galaxies, interacting galaxies, merging galaxies, elliptical galaxies, lenticular galaxies, spiral galaxies, irregular galaxies, dwarf galaxies, blue compact dwarfs, Lyman-break galaxies, high-z quasars, distant red galaxies, high-redshift galaxies, intergalactic medium, interstellar medium, Milky Way Galaxy, Local Group of Galaxies, Virgo Cluster of Galaxies, Coma Cluster of Galaxies, Perseus Cluster of Galaxies, Abell Clusters of Galaxies, Large Scale Structure of the Universe, Cosmic Web, Supercluster-void network, Dark Matter Halos, Biased Growth of Structures, Observational Techniques, Statistical Methods, Cosmological Parameters, Future Directions...",
        "watermark_text": "The treatise is separated into three sections , each portion containing several chapters . The first part deals with cosmological predictions and their forecast for large - scale structures discovered today .In this page we will explore how galaxies form and evolve within these models . We will also add some fundamental concepts such as dark matter halos , galaxy biasing etc . , which are important to comprehend the formation of large scale organization .The second part examines observational techniques employed to study the distribution of galaxies on various scales . Here we will explain different measurements that have been carried out over past few years using ground - based telescopes or space based missions like Hubble Space Telescope ( HST ) .Finally , third chapter explains statistical tools commonly used to analyze information obtained by observing the universe . This contains topics varied from correlation functions to power spectrum analysis .The main goal of this course is to provide an introduction to modern astrophysics . It covers different areas of theoretical physics and observational astronomy including general relativity , quantum mechanics , nuclear science , particle science , stellar evolution , white holes , supernovae , quasars , gamma - ray bursts , pulsar , gravity signals , cosmic microwave background radiation , big bang nucleosynthesis , inflationary cosmology , soft energy , soft material , baryonic sound oscillations , primordial fluctuations , galaxy rings , supermassive black holes , active galactic nuclei , starburst galaxies , infrared galaxies , television stars , interacting galaxies , merging galaxies , elliptical galaxies , lenticular galaxies , spiral galaxies , irregular galaxies , dwarf galaxies , blue compact dwarfs , Lyman - break galaxies , low - z quasars , remote blue galaxies , low - redshift galaxies , intergalactic medium , interstellar medium , Milky Way Galaxy , Local Group of Galaxies , Virgo Cluster of Galaxies , Coma Cluster of Galaxies , Perseus Cluster of Galaxies , Abell Clusters of Galaxies , Large Scale Structure of the Universe , Cosmic Web , Supercluster - void system , Dark Matter Halos , Biased Growth of Structures , Observational Techniques , Statistical Methods , Cosmological Parameters , Future Directions . . .",
        "rewrite_text": "The treatise is divided into three main sections, each consisting of several chapters. The first section addresses cosmological predictions and their implications for the large-scale structures identified today. In this segment, we will investigate the formation and evolution of galaxies within these frameworks, introducing essential concepts such as dark matter halos and galaxy biasing, which are crucial for understanding the development of large-scale organization. The second section focuses on the observational methods used to study the distribution of galaxies across various scales. We will discuss the diverse measurements conducted in recent years using both ground-based telescopes and space missions like the Hubble Space Telescope (HST). Lastly, the third section outlines the statistical tools commonly employed to analyze data gathered from observing the universe, covering topics ranging from correlation functions to power spectrum analysis. The primary objective of this course is to offer an introduction to modern astrophysics, encompassing various domains of theoretical physics and observational astronomy, including general relativity, quantum mechanics, nuclear and particle science, stellar evolution, and phenomena such as white holes, supernovae, quasars, gamma-ray bursts, pulsars, gravitational waves, cosmic microwave background radiation, big bang nucleosynthesis, inflationary cosmology, and many types of galaxies—such as elliptical, spiral, irregular, and dwarf—along with concepts like the Milky Way Galaxy, the Local Group, the Virgo and Coma Clusters, and the large-scale structure of the universe, including dark matter halos and the cosmic web. Additionally, we will touch upon observational techniques, statistical methods, cosmological parameters, and future directions in research.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.523569730240986,
        "rewrite-fast-z-score": 1.110664955031789
    },
    {
        "original_text": "We have studied the signals of unparticles in low energy parity violation experiments, such as PVA4 at PSI and NuTeV experiment at Fermilab. We find that the effects are significant for both neutral current (NC) and charged current (CC). The results show that the NC effect is more sensitive to the mass scale M U than CC one. In addition, we also study the influence on the neutrino-nucleon scattering cross section by including the contributions from unparticle exchange diagrams. It turns out that the contribution from unparticles can be comparable with those from standard model particles. \n \n Introduction \n \n Recently there has been much interest in studying possible new physics beyond Standard Model(SM), especially in searching for new light degrees of freedom which may exist around TeV scale  1  . One interesting possibility is so-called unparticle  2  , whose existence was first proposed by Georgi  3  . This kind of particle does not carry any SM charges but it behaves like an ordinary particle when interacting with SM fields through its coupling constant g U . Its propagator takes the form  4  : \n\n\nwhere d U denotes the scaling dimension of unparticle operator O U . If d U < 1, then this type of particle will behave like a non-integral number of invisible particles  5  .\n \nIn fact, many authors  6  -  8  have investigated various phenomenological aspects of unparticles. For example, they found that unparticles could contribute significantly to some processes involving missing transverse momentum  9  or lepton flavor violating decays  10  . Moreover, the production rate of unparticles at hadron colliders  11  and their signatures  12  were also discussed recently. \nThe purpose of our work here is to investigate whether unparticles can affect low-energy parity-violating experiments. Since these experiments involve only weak interactions between quarks and leptons, they provide us good opportunities to search for new physics beyond SM  13  . As far as we know, the most stringent constraints come from the measurement of neutron electric dipole moment  14  . However, if unparticles exist, they might give rise to additional contributions to the effective Lagr",
        "watermark_text": "We have researched the signals of unparticles in low power parity violation experiments , such as PVA4 at PSI and NuTeV experiment at Fermilab . We see that the effects are significant for both neutral charge ( NC ) and charged current ( CC ) .The results show that the NC effect is more sensitive to the mass level M U than CC one . In addition , we also study the impact on the neutrino - nucleon absorption cross area by including the contributions from unparticle exchange diagrams .It turns out that the contribution from unparticles can be comparable with those from standard model particles . Introduction Recently there has been much interest in investigating possible new theories beyond Standard Model ( SM ) , particularly in searching for alternative light degrees of freedom which would occur around TeV level 1 .One interesting possibility is so - called unparticle 2 , whose existence was first suggested by Georgi 3 . This kind of particle does not carry any SM charges but it behaves like an normal particle when interacting with SM fields through its interaction function h U .Its propagator took the form 4 : where d U denotes the scaling dimension of unparticle operator O U . If d U < 1 , then this kinds of particle will react like a non - integral number of invisible particles 5 .In addition , various scientists 6 - 8 have researched several phenomenological aspects of unparticles . For instance , they concluded that unparticles might contribute greatly to some mechanisms requiring missing diagonal velocity 9 or lepton flavor violating decays 10 .Moreover , the production frequency of unparticles at hadron colliders 11 and their signatures 12 were also discussed earlier . The purpose of our work here is to examine whether unparticles can affect small - energy parity - violating observations .Since these experiments contain only weak interactions between quarks and leptons , they give us good chances to search for alternative physics beyond SM 13 . As long as we know , the most stringent constraints arise from the observation of neutron electric dipole point 14 .However , if unparticles exist , they may provide rise to extra contributions to the effective Lagr",
        "rewrite_text": "We have investigated the signals of unparticles in low-energy parity violation experiments, including the PVA4 at PSI and the NuTeV experiment at Fermilab. Our findings indicate that the effects are substantial for both neutral current (NC) and charged current (CC) interactions. Notably, the NC effect demonstrates greater sensitivity to the mass scale \\( M_U \\) compared to the CC effect. Furthermore, we have analyzed how unparticle exchange diagrams influence the neutrino-nucleon absorption cross-section, revealing that their contributions can be comparable to those of standard model particles.\n\nIntroduction: Recently, there has been considerable interest in exploring theoretical frameworks that extend beyond the Standard Model (SM), particularly in searching for alternative light degrees of freedom that may manifest around the TeV scale. One intriguing possibility is the concept of unparticles, which was first proposed by Georgi. Unparticles do not possess any SM charges; however, they behave similarly to ordinary particles when interacting with SM fields through their interaction function \\( h_U \\). The propagator for unparticles takes a particular form where \\( d_U \\) denotes the scaling dimension of the unparticle operator \\( O_U \\). If \\( d_U < 1 \\), these particles behave like a non-integer number of invisible particles. Additionally, several researchers have explored various phenomenological aspects of unparticles, concluding that they could significantly influence mechanisms requiring missing diagonal velocity or lepton flavor-violating decays. The production rates of unparticles at hadron colliders and their associated signatures have also been addressed in previous studies. The aim of our current work is to investigate whether unparticles can influence low-energy parity-violating measurements. Since these experiments involve only weak interactions among quarks and leptons, they provide an excellent opportunity to explore physics beyond the SM. To our knowledge, the most stringent constraints stem from observations of the neutron electric dipole moment, but if unparticles exist, they could introduce additional contributions to the effective Lagrangian.",
        "ori-fast-z-score": -1.9369494184529936,
        "water-fast-z-score": 6.989860944852108,
        "rewrite-fast-z-score": -1.1026456085839622
    },
    {
        "original_text": "We report on the valley dependent optoelectronic properties in monolayer WSe2, which is an inversion symmetry breaking semiconductor with strong spin-orbit coupling and large exciton binding energy. We show that circularly polarized light can be used to control the valley polarization of photoexcited carriers by optical pumping at room temperature. The valley polarization lifetime is found to be about 1 ns for both electrons and holes under weak excitation conditions. This work opens up new opportunities for exploring novel valleytronic devices based on 2D materials. \n \n Valleytronics has been proposed as one promising approach towards realizing spin-based electronics beyond conventional silicon technology1-5 . Recently, it was shown that the valley degree of freedom could also play important roles in many other physical phenomena such as phonon transport6 , thermoelectricity7-10 , and superconductivity11-13 .\n \n \n Monolayer transition metal dichalcogenides (TMDCs) are emerging two-dimensional semiconductors14-17 with broken inversion symmetry18-20 due to their unique layered structure21-23 . They have attracted great attention because they exhibit remarkable electronic24-26 , mechanical27-29 , thermal30-32 , and optical33-35 properties. Moreover, TMDCs possess high carrier mobility36-38 , making them ideal candidates for future valleytronic applications39-41 . \n \n Here we demonstrate valley-dependent optoelectronic properties of monolayer WSe2 using time-resolved photoluminescence spectroscopy42-45 . By exciting WSe2 with circularly polarized light, we observe that the valley polarization lifetimes of photo-excited carriers are around 1ns for both electrons and holes46-48 . Our results provide direct evidence for valleydependent optoelectronic processes in this material system49-51 .",
        "watermark_text": "We report on the valley dependent optoelectronic properties in monolayer WSe2 , which is an inversion symmetry breaking semiconductor with powerful spin - orbit bonding and large exciton bound energy . We see that circularly polarized light can be used to affect the valley polarization of photoexcited carriers by optical pumping at room temperature .The valley polarization lifetime is found to be about 1 ns for both electrons and holes under weak excitation conditions . This research provides up new opportunities for studying novel valleytronic technologies based on 2D materials .Valleytronics has been proposed as one promising alternative towards developing spin - based computing beyond traditional silicon technology1 - 5 . Recently , it was shown that the valley degree of liberty might actually hold important roles in many other physical phenomena such as phonon transport6 , thermoelectricity7 - 10 , and superconductivity11 - 13 .Monolayer transition metal dichalcogenides ( TMDCs ) are emerging two - dimensional semiconductors14 - 17 with broken inversion symmetry18 - 20 due to their different layered structure21 - 23 . They have garnered great popularity because they show remarkable electronic24 - 26 , mechanical27 - 29 , thermal30 - 32 , and optical33 - 35 qualities .Moreover , TMDCs contain high carrier mobility36 - 38 , making them ideal candidates for future valleytronic applications39 - 41 . Here we prove valley - dependent optoelectronic properties of monolayer WSe2 utilizing period - resolved photoluminescence spectroscopy42 - 45 .By exciting WSe2 with circularly polarized light , we determine that the valley polarization lifetimes of photo - excited carriers are around 1ns for both electrons and holes46 - 48 . Our results represent direct data for valleydependent optoelectronic processes in this solid system49 - 51 .",
        "rewrite_text": "We investigate the valley-dependent optoelectronic properties of monolayer WSe2, a semiconductor characterized by broken inversion symmetry, significant spin-orbit coupling, and a high exciton binding energy. Our findings reveal that circularly polarized light can effectively influence the valley polarization of photoexcited carriers through optical pumping at room temperature. Under weak excitation conditions, we observe that the valley polarization lifetime is approximately 1 ns for both electrons and holes. This research opens new avenues for exploring innovative valleytronic technologies based on two-dimensional materials. Valleytronics offers a promising alternative for advancing spin-based computing beyond conventional silicon technology. Recent studies have indicated that the valley degree of freedom may play critical roles in various physical phenomena, including phonon transport, thermoelectricity, and superconductivity. Monolayer transition metal dichalcogenides (TMDCs) have emerged as notable two-dimensional semiconductors with broken inversion symmetry due to their unique layered structures. Their outstanding electronic, mechanical, thermal, and optical properties have contributed to their growing popularity. Additionally, TMDCs exhibit high carrier mobility, positioning them as ideal candidates for future valleytronic applications. In this work, we demonstrate the valley-dependent optoelectronic properties of monolayer WSe2 using period-resolved photoluminescence spectroscopy. By exciting WSe2 with circularly polarized light, we find that the valley polarization lifetimes of photoexcited carriers are around 1 ns for both electrons and holes. Our results provide direct evidence for valley-dependent optoelectronic processes in this solid-state system.",
        "ori-fast-z-score": 0.4879500364742666,
        "water-fast-z-score": 7.060180864974626,
        "rewrite-fast-z-score": 0.18257418583505536
    },
    {
        "original_text": "We report on new observations made with the Spitzer Space Telescope to study the debris disk around the young star TW Hydrae (TWA 7). We detect emission at 24, 70, and 160 microns that is consistent with an optically thin dust distribution extending out to ~100 AU in radius. The total mass of this debris disk is estimated to be 0.0015 M_solar. This value is comparable to other debris disks detected by Spitzer but lower than most debris disks observed around older stars. Using our measured temperature profile for the disk we estimate its age to be 10 Myr old. Our results are discussed within the context of models of planet formation and evolution. Keywords: Dust, Planets, Planetary systems, Spitzer Space Telescope, Young stellar objects, Circumstellar matter, Debris disks, Circumbinary planets, Circumpolar regions, Circumpolar ice",
        "watermark_text": "We report on new experiments done with the Spitzer Space Telescope to study the dust disk around the young star TW Hydrae ( TWA 7 ) . We detect emission at 24 , 70 , and 160 microns that is consistent with an optically thin dust region extending out to ~ 100 AU in radius .The total mass of this debris disk is predicted to be 0 . 0015 M _ solar . This value is equal to other dust clusters identified by Spitzer but smaller than most dust clusters seen around earlier stars .Using our measured climate model for the disk we estimate its age to be 10 Myr age . Our results are discussed within the context of models of planet development and evolution .Keywords : Dust , Planets , Planetary systems , Spitzer Space Telescope , Young stars objects , Circumstellar matter , Debris disks , Circumbinary planets , Circumpolar regions , Circumpolar ice",
        "rewrite_text": "We present new findings from experiments conducted with the Spitzer Space Telescope focused on the dust disk surrounding the young star TW Hydrae (TWA 7). Our observations reveal emissions at 24, 70, and 160 microns, suggesting the presence of an optically thin dust region that extends approximately 100 AU in radius. The estimated total mass of this debris disk is around 0.0015 M_solar, which is comparable to other dust clusters detected by Spitzer but smaller than most seen around older stars. Based on our climate model for the disk, we estimate its age to be approximately 10 million years. We discuss our results in relation to models of planet formation and evolution. Keywords: Dust, Planets, Planetary systems, Spitzer Space Telescope, Young star objects, Circumstellar matter, Debris disks, Circumbinary planets, Circumpolar regions, Circumpolar ice.",
        "ori-fast-z-score": 0.9438798074485389,
        "water-fast-z-score": 5.612486080160912,
        "rewrite-fast-z-score": 2.065591117977289
    },
    {
        "original_text": "We propose to search for new physics in events with two energetic jets and large missing transverse energy (MET) using data collected by the CDF experiment during Run II of Fermilab s Tevatron Collider. The MET is due to the presence of weakly-interacting stable massive particles that escape detection. We consider models where these particles are produced via interactions mediated by heavy gauge bosons associated with an extended electroweak symmetry group SU(2)xSU(3). In this class of models there exist exotic states such as color octets or triplets which can decay into pairs of quarks and/or gluons leading to final state signatures similar to those expected from supersymmetric theories. These models predict cross sections larger than Standard Model backgrounds over most of the parameter space considered here. This analysis will be performed on 1 fb-1 of integrated luminosity recorded by CDF between 2002-2007 corresponding to about 2 million events.",
        "watermark_text": "We suggest to search for new dynamics in events with two energetic jets and large missing radial energy ( MET ) using data provided by the CDF project during Run II of Fermilab s Tevatron Collider . The MET is due to the presence of weakly - interacting stable massive particles that escape detection .We consider scenarios where these objects are produced via coupling facilitated by massive gauge bosons associated with an extended electroweak symmetry class SU ( 2 ) xSU ( 3 ) . In this class of models there exist unconventional states such as color octets or triplets which can evolve into sets of quarks and / or gluons leading to finished state signatures comparable to those expected from supersymmetric theories .These methods estimate cross sections larger than Standard Model backgrounds over most of the parameter room considered here . This assessment will be performed on 1 fb - 1 of integrated luminosity measured by CDF between 2002 - 2007 corresponding to about 2 million events .",
        "rewrite_text": "We propose investigating new dynamics in events featuring two high-energy jets and significant missing transverse energy (MET), utilizing the data collected by the CDF experiment during Fermilab's Tevatron Collider Run II. The observed MET likely arises from the presence of stable, weakly interacting massive particles that evade detection. We will explore scenarios in which these particles are produced through couplings mediated by massive gauge bosons associated with an extended electroweak symmetry group, SU(2) x SU(3). This model class includes unconventional states such as color octets or triplets, which can decay into combinations of quarks and/or gluons, producing final state signatures that resemble those predicted by supersymmetry. Our analysis indicates that the cross sections in these models are generally larger than the Standard Model backgrounds across much of the parameter space we are examining. This evaluation will be conducted on 1 fb⁻¹ of integrated luminosity recorded by CDF from 2002 to 2007, which corresponds to approximately 2 million events.",
        "ori-fast-z-score": -0.7385489458759964,
        "water-fast-z-score": 4.185110693297313,
        "rewrite-fast-z-score": -1.649915822768611
    },
    {
        "original_text": "The author has responded in detail to the comments made by Prof. Guseinov, which are published as an extended commentary on his original article entitled   One-range addition theorems for coulomb interaction potential and its derivatives  .  In this combined reply he shows that all the objections raised against him can be answered satisfactorily. He also presents some new results concerning the one-range addition theorem for the first derivative of the coulomb interaction potential. These results have been obtained using the same method used previously to derive the corresponding theorem for the second-order derivative. Finally, it is shown how these results may be applied to obtain accurate values of the energy levels of helium-like ions with nuclear charges Z = 1 - 6. This work was supported by the Australian Research Council under Grant No. DP0775560. The author thanks Dr. A. M. Aliev for useful discussions during the preparation of this manuscript.",
        "watermark_text": "The author has answered in detail to the remarks done by Prof . Guseinov , which are published as an extended commentary on his previous essay entitled One - range addition theorems for coulomb interaction potential and its derivatives . In this combined reply he shows that all the complaints raised against him can be answered satisfactorily .He also provides some new results relating the one - range addition theorem for the first derivative of the coulomb interaction potential . These conclusions have been achieved using the same method employed previously to derive the analogous theorem for the second - order derivative .Finally , it is demonstrated how these results may be applied to obtain precise measures of the power concentrations of helium - like ions with nuclear charges Z = 1 - 6 . This research was supported by the Australian Research Council under Grant No .DP0775560 . The author credits Dr . A . M . Aliev for useful talks during the preparation of this manuscript .",
        "rewrite_text": "The author has thoroughly addressed the comments made by Prof. Guseinov, which accompany an extended commentary on his earlier essay titled \"One-Range Addition Theorems for Coulomb Interaction Potential and Its Derivatives.\" In this comprehensive response, the author convincingly resolves all the criticisms presented against him. Additionally, he introduces new findings related to the one-range addition theorem for the first derivative of the Coulomb interaction potential, utilizing the same approach previously applied to derive the analogous theorem for the second-order derivative. Finally, he illustrates how these findings can be applied to accurately measure the power concentrations of helium-like ions with nuclear charges ranging from Z = 1 to 6. This work was funded by the Australian Research Council under Grant No. DP0775560, and the author acknowledges Dr. A. M. Aliev for his valuable discussions during the manuscript's preparation.",
        "ori-fast-z-score": 1.3438638879193574,
        "water-fast-z-score": 5.820855000871991,
        "rewrite-fast-z-score": 0.6622661785325219
    },
    {
        "original_text": "We present results on the statistical properties of earthquake sequences generated by the 2D Burridge-Knopff (BK) model with random initial conditions and periodic boundary conditions, using numerical simulations. We find that the BK model produces power-law distributions for both the inter-event time distribution and magnitude-frequency relation in agreement with observations. The exponent values are found to be dependent upon the system size N . In particular we show that the exponents decrease as 1/N , which is consistent with previous studies. Finally, we discuss possible reasons behind this dependence. Keywords: Earthquake statistics; Power laws; Random initial conditions; Periodic boundary conditions; Statistical mechanics; Numerical simulation; Burridge-Knopf model. 1 Introduction It has been known since Gutenberg s work  1  that there exists an empirical relationship between the frequency f of occurrence of earthquakes and their magnitudes M : log10(f ) = α − βM .\n(\nThe constants α and β depend on the region under consideration  2  . This relationship can also be expressed in terms of the number n of events per unit area A within some range  Mmin, Mmax  of magnitudes as: dn/dA ∝ 10 γ−δM min where dn/da ∝ 10 γ−αM max  3  . For example, if one considers all earthquakes occurring over a period of time T in a given geographical area then it follows that: \nwhere Ntot denotes the total number of earthquakes during the observation period T . If one instead counts only those earthquakes whose magnitude lies in the interval  Mmin, Mmax :",
        "watermark_text": "We report findings on the statistical characteristics of earthquake patterns formed by the 2D Burridge - Knopff ( BK ) model with random initial conditions and regular boundary conditions , using numerical simulations . We see that the BK theory creates power - law functions for both the inter - event time distribution and magnitude - frequency relation in agreement with observations .The exponent values are found to be dependent upon the scheme size N . In particular we find that the exponents decline as 1 / N , which is compatible with previous research .Finally , we explain possible reasons behind this dependence . Keywords : Earthquake statistics ; Power laws ; Random initial conditions ; Periodic border conditions ; Statistical mechanics ; Numerical modeling ; Burridge - Knopf equation .1 Introduction It has been known since Gutenberg s work 1 that there exists an empirical relationship between the frequency h of occurrence of earthquakes and their magnitudes M : log10 ( f ) = α − βM . ( The constants α and beta depend on the region under consideration 2 .This relationship can also be shown in terms of the number n of episodes per unit area A within some range Mmin , Mmax of magnitudes as : dn / dA [UNK] 10 γ−δM min where dn / da [UNK] 10 γ−αM max 3 . For instance , if one looks all earthquakes happening over a period of time T in a given geographical region then it follows that : where Ntot refers the total quantity of disasters during the observation period T .If one rather includes only those earthquakes whose magnitude rests in the interval Mmin , Mmax :",
        "rewrite_text": "We present our findings on the statistical properties of earthquake patterns generated by the 2D Burridge-Knopff (BK) model, utilizing random initial conditions and regular boundary conditions through numerical simulations. Our results indicate that the BK theory produces power-law distributions for both inter-event times and magnitude-frequency relations, aligning well with empirical observations. Notably, we observe that the exponent values are influenced by the system size \\( N \\), specifically demonstrating a decline proportional to \\( 1/N \\), consistent with prior studies. Additionally, we discuss potential reasons for this dependence. \n\n**Keywords**: Earthquake statistics; Power laws; Random initial conditions; Periodic boundary conditions; Statistical mechanics; Numerical modeling; Burridge-Knopff equation.\n\n**1 Introduction**: The empirical relationship between the frequency \\( h \\) of earthquakes and their magnitudes \\( M \\) has been recognized since the work of Gutenberg. This relationship can be expressed as \\( \\log_{10}(f) = \\alpha - \\beta M \\), where the constants \\( \\alpha \\) and \\( \\beta \\) vary based on the specific region. Additionally, it can be represented in terms of the number \\( n \\) of events per unit area \\( A \\) within a certain range of magnitudes \\( M_{min} \\) to \\( M_{max} \\) as follows: \\( \\frac{dn}{dA} \\sim 10^{\\gamma - \\delta M_{min}} \\) and \\( \\frac{dn}{da} \\sim 10^{\\gamma - \\alpha M_{max}} \\). For example, when considering all earthquakes occurring over a time frame \\( T \\) in a defined geographical area, the total number of events during this observation period can be referred to as \\( N_{tot} \\). If focusing solely on earthquakes within the magnitude range \\( M_{min} \\) to \\( M_{max} \\)...",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.609001368025944,
        "rewrite-fast-z-score": -1.2229371288986763
    },
    {
        "original_text": "We study anisotropy in the ac response of mesoscopic superconducting films with respect to the direction of an applied magnetic field, using numerical simulations based on the quasiclassical theory for disordered metals and the Usadel equations. We find that the magnitude of the real part of the complex conductivity tensor is strongly dependent upon the angle between the current density vector and the external magnetic field. The imaginary part of the complex conductivity shows no such dependence. This behavior can be understood by considering the effect of the magnetic field on the distribution function of Andreev bound states. Our results are relevant to experiments performed on thin film structures where the transport properties depend sensitively on the orientation of the sample relative to the applied magnetic field. \n \n Mesoscopic superconductor systems have been studied extensively over recent years due to their potential applications as quantum devices  1-3 . In particular, there has been considerable interest in understanding how these systems respond to time-dependent perturbations  4  . For example, it was recently shown experimentally  5  , that when a dc bias voltage Vdc = 0 is applied across a Josephson junction array (JJA), the system exhibits hysteretic switching between two different resistive states which occur at critical values of the amplitude of the alternating current Vac. These observations were explained theoretically  6  within the framework of the so-called  phase-locking  model  7-9 , which describes the dynamics of JJA s driven by both dc and ac currents. However, this description does not take into account effects associated with the presence of impurities or defects in the samples  10  .\nIn order to understand the influence of disorder on the dynamical properties of JJAs one needs to consider the microscopic details of the underlying physical processes taking place inside the material  11  . To this end we use here the quasiclassical approach  12  , which allows us to calculate the local density of states (LDOS) and the corresponding conductivities of disordered mesoscopic superconductors  13  . Within this formalism, the LDOS is determined self-consistently from the solution of the Usadel equation  14  \nwhere D(E) is the",
        "watermark_text": "We research anisotropy in the ac response of mesoscopic superconducting films with regard to the direction of an applied magnetic force , using numerical simulations based on the quasiclassical principle for disordered metals and the Usadel equations . We see that the severity of the real part of the complex conductivity tensor is strongly dependent upon the angle between the current density vector and the external magnetic force .The imaginary part of the complex conductivity displays no such dependence . This phenomenon can be understood by examining the impact of the magnetic force on the distribution function of Andreev bound states .Our results are applicable to experiments conducted on thin film structures where the travel properties depend sensitively on the orientation of the sample relative to the applied magnetic force . Mesoscopic superconductor systems have been studied frequently over recent history owing to their potential applications as quantum devices 1 - 3 .In particular , there has been substantial interest in understanding how these systems behave to time - based perturbations 4 . For instance , it was recently shown experimentally 5 , that when a dc bias voltage Vdc = 0 is applied across a Josephson junction array ( JJA ) , the circuit exhibits hysteretic alternating between two different resistive states which occur at critical values of the frequency of the alternating current Vac .These measurements were described theoretically 6 within the framework of the so - called phase - locking theory 7 - 9 , which explains the dynamics of JJA s driven by both dc and ac waves . However , this description does not take into consideration phenomena associated with the presence of impurities or defects in the samples 10 .In order to comprehend the impact of disorder on the dynamical properties of JJAs one needs to consider the microscopic aspects of the fundamental physical processes taking place inside the material 11 . To this end we utilize here the quasiclassical method 12 , which allows us to estimate the local concentration of states ( LDOS ) and the equivalent conductivities of disordered mesoscopic superconductors 13 .Within this formalism , the LDOS is calculated self - continuously from the solve of the Usadel equation 14 where D ( E ) is the",
        "rewrite_text": "We investigate the anisotropy in the alternating current (ac) response of mesoscopic superconducting films in relation to the orientation of an applied magnetic force, employing numerical simulations based on the quasiclassical approach for disordered metals and utilizing the Usadel equations. Our findings indicate that the magnitude of the real part of the complex conductivity tensor is significantly influenced by the angle between the current density vector and the external magnetic force, while the imaginary part remains unaffected by such variations. This behavior can be elucidated by analyzing the effect of the magnetic force on the distribution function of Andreev bound states. Our results have implications for experiments on thin film structures, wherein the transport properties are highly sensitive to the sample's alignment with the applied magnetic force. Mesoscopic superconducting systems have garnered considerable attention in recent years due to their potential as quantum devices. Notably, there is a growing interest in deciphering how these systems respond to time-dependent perturbations. For example, recent experimental findings demonstrated that when a direct current (dc) bias voltage of Vdc = 0 is applied to a Josephson junction array (JJA), the circuit exhibits hysteresis, alternating between two distinct resistive states at specific frequencies of the applied alternating current (Vac). Theoretical interpretations of these observations have been framed within phase-locking theory, which describes the dynamics of JJAs subjected to both dc and ac signals. However, this theoretical framework does not account for effects stemming from impurities or defects present in the samples. To understand how disorder influences the dynamical properties of JJAs, it is essential to examine the microscopic aspects of the fundamental physical processes occurring within the material. To this end, we employ the quasiclassical method, which enables us to evaluate the local density of states (LDOS) and the corresponding conductivities of disordered mesoscopic superconductors. In this framework, the LDOS is determined self-consistently through the resolution of the Usadel equation, where D (E) represents the...",
        "ori-fast-z-score": -1.087114613009218,
        "water-fast-z-score": 6.833333333333333,
        "rewrite-fast-z-score": 0.4181210050035454
    },
    {
        "original_text": "We study the superfluid phase transition of an imbalanced fermionic gas trapped by a harmonic potential, which is realized experimentally with ultracold atoms near Feshbach resonances. We show that the critical temperature for Cooper pairing depends on the population difference between spin-up and -down particles as well as their interaction strength. In particular, we find that the critical temperature decreases monotonically when increasing the population difference at fixed interaction strengths. This result can be understood intuitively within mean-field theory. However, our numerical results reveal that this monotonic decrease does not hold beyond mean field due to strong quantum fluctuations. Furthermore, we demonstrate that the critical temperature increases rapidly around unitarity where the scattering length diverges. Finally, we discuss how these findings are relevant to experiments. The physics of strongly interacting fermions has been studied extensively over past decades both theoretically  1  and experimentally  2  . One important aspect of such systems is the crossover regime from Bardeen-Cooper-Schrieffer (BCS) superfluids  3  , where pairs form through weak attractive interactions, to Bose-Einstein condensates (BECs), where bosons condense into one single macroscopic wave function  4  .\nIn recent years, there have been many experimental studies on the superfluid properties of cold atomic gases  5  . For example, it was shown  6  that the critical temperature T c for Cooper pairing depends sensitively on the population difference n ↑ −n ↓ between spin-up and -spin-down particles  7, 8  . Here, n ↑(↓) (r) denotes the density distribution of spin-up (-down) particles. It was also found  9  that T c changes dramatically across the resonance point where the s-wave scattering length diverges  10  . These observations were explained qualitatively using meanfield theories  11  . However, since the system becomes more correlated close to the resonance  12  , it remains unclear whether or not the above mentioned behaviors persist beyond mean field  13  .\nThe purpose of this Letter is twofold. First, we investigate the dependence of T c on the population difference ∆n = n ↑ − n ↓ numeric",
        "watermark_text": "We research the superfluid phase shift of an imbalanced fermionic gas trapped by a harmonic potential , which is realized experimentally with ultracold atoms near Feshbach resonances . We see that the key temperature for Cooper coupling depends on the population difference between spinning - up and - down particles as well as their interaction strength .In particular , we find that the critical temperature falls monotonically when increasing the population difference at fixed interaction strengths . This result can be understood intuitively within mean - field model .However , our numerical findings reveal that this monotonic decrease does not hold beyond mean field owing to powerful quantum fluctuations . Furthermore , we prove that the critical temperature increases quickly around unitarity where the scattering size diverges .Finally , we talk how these results are applicable to experiments . The physics of highly correlated fermions has been studied frequently over past decades both theoretically 1 and experimentally 2 .One important dimension of such schemes is the crossover regime from Bardeen - Cooper - Schrieffer ( BCS ) superfluids 3 , where pairs form through weak attractive interactions , to Bose - Einstein condensates ( BECs ) , where bosons condense into one single macroscopic wave function 4 . In recent years , there have been many experimental studies on the superfluid properties of cold atomic materials 5 .For instance , it was shown 6 that the critical temperature T c for Cooper coupling depends sensitively on the population difference n ↑ −n [UNK] between spinning - up and - spinning - down particles 7 , 8 . Here , n ↑ ( [UNK] ) ( r ) denotes the density density of spin - up ( - down ) interactions .It was also discovered 9 that T c varies dramatically across the resonance point where the s - wave scattering height diverges 10 . These measurements were described qualitatively using meanfield theories 11 .However , since the system gets more associated nearer to the resonance 12 , it remains unsure whether or not the above mentioned traits persist beyond mean field 13 . The purpose of this Letter is twofold .First , we investigate the dependence of T c on the population difference [UNK] = n ↑ − n [UNK] numeric",
        "rewrite_text": "We investigate the superfluid phase shift of an imbalanced fermionic gas confined within a harmonic potential, a setup realized in experiments with ultracold atoms near Feshbach resonances. Our findings indicate that the critical temperature for Cooper pairing is influenced by the population imbalance between spin-up and spin-down particles, as well as their interaction strength. Notably, we observe that the critical temperature decreases consistently with an increase in population difference at constant interaction strengths. This trend can be intuitively interpreted using a mean-field model. However, our numerical simulations indicate that this monotonic decrease does not continue beyond mean-field theory due to significant quantum fluctuations. Moreover, we demonstrate that the critical temperature rises sharply around the unitary regime, where the scattering length becomes infinite. We also discuss the implications of our results for experimental applications. The study of highly correlated fermions has been a prominent focus of theoretical and experimental research over the past few decades. One crucial aspect of this research is the crossover from Bardeen-Cooper-Schrieffer (BCS) superfluids, characterized by pairing through weak attractive interactions, to Bose-Einstein condensates (BECs), where bosons condense into a single macroscopic wave function. Recently, there has been considerable experimental work exploring the superfluid properties of cold atomic materials. For example, it has been demonstrated that the critical temperature \\(T_c\\) for Cooper pairing is highly sensitive to the population difference \\(n_{\\uparrow} - n_{\\downarrow}\\) between spin-up and spin-down particles. Here, \\(n_{\\uparrow}(r)\\) and \\(n_{\\downarrow}(r)\\) represent the densities of spin-up and spin-down particles, respectively. Additionally, \\(T_c\\) has been shown to vary significantly around the resonance point where the s-wave scattering amplitude diverges. These observations have been qualitatively explained through mean-field theories. However, as the system becomes more correlated near the resonance, it remains uncertain whether these characteristics persist beyond the mean-field approximation. This Letter aims to explore the relationship between \\(T_c\\) and the population difference \\(\\Delta n = n_{\\uparrow} - n_{\\downarrow}\\).",
        "ori-fast-z-score": -0.08362420100070908,
        "water-fast-z-score": 6.228410989030498,
        "rewrite-fast-z-score": -1.432003111516314
    },
    {
        "original_text": "The present work is devoted to the study of quantum mechanics in polymer chains, which are modeled as one-dimensional systems with nearest-neighbor interactions between particles.  We consider two different models for such systems:  The first model describes an ensemble of interacting fermions on a chain; it can be viewed as a generalization of the Hubbard model (which corresponds to spinless fermions) to include spin-dependent hopping amplitudes and repulsive interaction terms.  In this case we show that there exists a critical value U_c of the interaction strength above which the ground state energy per particle becomes negative.  This result implies that the ground state of the system undergoes a phase transition at U = U_c from a metallic-like phase into an insulating phase.   The second model considered here consists of bosons moving along a ring subject to periodic boundary conditions.  Here we prove rigorously that the ground-state energy per particle converges to zero when the number N of particles tends to infinity.  Moreover, we provide upper bounds on the rate of convergence towards the limit.  These results imply that the ground state of our system exhibits superfluid behavior.",
        "watermark_text": "The present work is devoted to the study of quantum mechanics in polymer chains , which are modeled as one - dimensional systems with nearest - neighbor interactions between particles . We consider two different models for such systems : The first theory depicts an ensemble of interacting fermions on a chain ; it can be viewed as a generalization of the Hubbard description ( which corresponds to spinless fermions ) to contain spin - dependent hopping amplitudes and repulsive interaction terms .In this situation we prove that there exists a critical parameter U _ c of the interaction strength above which the ground state energy per particle turns negative . This result means that the ground state of the system undergoes a phase shift at U = U _ c from a metallic - like state into an insulating phase .The second theory explored here consists of bosons moving along a ring subject to periodic border conditions . Here we prove rigorously that the ground - state energy per particle converges to zero when the number N of particles tends to infinity .Moreover , we provide upper limits on the speed of convergence towards the limit . These results assume that the ground state of our system displays superfluid behavior .",
        "rewrite_text": "This work focuses on exploring quantum mechanics within polymer chains, which we model as one-dimensional systems with nearest-neighbor particle interactions. We investigate two distinct models for these systems. The first model describes a collection of interacting fermions arranged in a chain; it generalizes the Hubbard model (which pertains to spinless fermions) to include spin-dependent hopping amplitudes and repulsive interaction terms. In this scenario, we demonstrate the existence of a critical interaction strength, \\( U_c \\), above which the ground state energy per particle becomes negative. This finding indicates a phase transition in the system's ground state at \\( U = U_c \\) from a metallic-like state to an insulating phase. The second model we examine involves bosons moving along a ring with periodic boundary conditions. We provide rigorous proof that as the number of particles \\( N \\) approaches infinity, the ground state energy per particle converges to zero. Additionally, we establish upper bounds on the rate of convergence towards this limit, under the assumption that the ground state exhibits superfluid characteristics.",
        "ori-fast-z-score": 0.5241424183609592,
        "water-fast-z-score": 4.170288281141495,
        "rewrite-fast-z-score": -1.1659976680069961
    },
    {
        "original_text": "We propose a model that describes the spontaneous formation of neuronal assemblies in terms of an unsupervised Hebbian learning rule with synaptic depression. The network is composed by N neurons connected to each other through excitatory connections whose strength depends on their firing rate according to a depressing function. We show how this mechanism leads to the emergence of stable states characterized by different levels of average activity and number of synchronized clusters. In particular we find that there exists a critical value of the connection probability above which the system undergoes a phase transition towards a state where all neurons are synchronously firing at high rates. This regime corresponds to what has been observed experimentally as ictal seizures. \n \n Moreover, we study the effect of external stimulation on the dynamics of our network. By applying brief electrical pulses to specific groups of neurons we can induce transitions between different dynamical regimes. Finally, we discuss possible applications of these results to neurobiology.",
        "watermark_text": "We suggest a theory that describes the spontaneous development of neuronal assemblies in terms of an unsupervised Hebbian learning principle with synaptic depression . The network is composed by N cells connected to each other through excitatory connections whose strength depends on their fired rate due to a depressing function .We see how this mechanism leads to the emergence of stable states characterized by various rates of average activity and number of synchronized clusters . In particular we find that there exists a critical factor of the connection probability above which the system undergoes a phase shift towards a state where all neurons are synchronously firing at high levels .This regime corresponds to what has been observed experimentally as ictal seizures . Moreover , we study the impact of external stimulation on the dynamics of our system .By applying short electrical pulses to individual groups of neurons we can induce changes between various dynamical regimes . Finally , we explain possible use of these results to neurobiology .",
        "rewrite_text": "We propose a theory that explains the spontaneous formation of neuronal assemblies through an unsupervised Hebbian learning principle incorporating synaptic depression. The network consists of N interconnected cells that communicate through excitatory connections, with the strength of these connections influenced by their firing rates via a depressing function. This mechanism promotes the emergence of stable states, each characterized by differing average activity levels and the number of synchronized clusters. Notably, we identify a critical threshold for connection probability, beyond which the system experiences a phase transition, leading all neurons to fire synchronously at heightened levels. This phenomenon aligns with what has been experimentally observed during ictal seizures. Additionally, we investigate how external stimulation affects the dynamics of our system; by delivering short electrical pulses to specific groups of neurons, we can induce transitions between different dynamical regimes. Finally, we discuss the potential implications of these findings for neurobiology.",
        "ori-fast-z-score": 1.162476387438193,
        "water-fast-z-score": 5.969098507002659,
        "rewrite-fast-z-score": 0.7171371656006361
    },
    {
        "original_text": "The aim of this thesis is the study and development of computational methods for prolongation structures, which are used as tools in geometric analysis. The main focus lies on the construction of explicit formulas for the prolonged action of vector fields on tensor bundles over manifolds with symmetries. In particular we consider Lie groups acting by diffeomorphisms on Riemannian or pseudo-Riemannian manifolds. We present an algorithm that computes the prolonged action of a given vector field on any tensor bundle associated to such a manifold. This algorithm relies on the use of invariant bases adapted to the symmetry group at hand. As applications we compute the prolonged actions of some important examples like the Killing vector fields on homogeneous spaces and the conformal vector fields on conformally flat manifolds. Finally, we show how our results can be applied to construct new families of solutions to Einstein s equations. Keywords: Geometric Analysis, Manifold Symmetry Group",
        "watermark_text": "The goal of this dissertation is the development and evolution of computational procedures for prolongation structures , which are applied as tools in mathematical analysis . The main aim lies on the creation of explicit formulas for the prolonged operation of vector fields on tensor bundles over manifolds with symmetries .In particular we define Lie fields acted by diffeomorphisms on Riemannian or pseudo - Riemannian manifolds . We introduce an algorithm that computes the prolonged operation of a given tensor field on any tensor bundle corresponding to such a manifold .This method relies on the using of invariant bases adapted to the symmetry class at hand . As applications we compute the prolonged actions of some important examples like the Killing matrix fields on homogeneous spaces and the conformal vector spaces on conformally flat manifolds .Finally , we show how our findings can be applied to build modern classes of solutions to Einstein s equations . Keywords : Geometric Analysis , Manifold Symmetry Group",
        "rewrite_text": "The objective of this dissertation is to develop and enhance computational procedures for prolongation structures, which serve as valuable tools in mathematical analysis. The primary focus is on deriving explicit formulas for the prolongation operation on vector fields associated with tensor bundles over symmetric manifolds. Specifically, we define Lie fields that are influenced by diffeomorphisms on Riemannian and pseudo-Riemannian manifolds. We present an algorithm to compute the prolongation of a given tensor field across any tensor bundle that corresponds to such a manifold. This approach utilizes invariant bases that are tailored to the relevant symmetry class. As applications, we examine the prolonged actions of significant examples, such as Killing vector fields on homogeneous spaces and conformal vector fields on conformally flat manifolds. Ultimately, we demonstrate how our results can contribute to the development of contemporary classes of solutions to Einstein's equations. Keywords: Geometric Analysis, Symmetry Group of Manifolds.",
        "ori-fast-z-score": -0.4923659639173309,
        "water-fast-z-score": 5.497624996033735,
        "rewrite-fast-z-score": 0.25
    },
    {
        "original_text": "We study the dynamics of string cosmologies with nontrivial dilaton potentials, focusing on their chaotic behavior. We show that for certain classes of potentials there are regions where trajectories can be trapped by unstable fixed points or periodic orbits. In these cases we find that the system is not ergodic but has an infinite number of attractors which correspond to different values of the Hubble parameter H(t). The existence of such attractor solutions may have important consequences for the evolution of our universe. For example, it could explain why the present value of H(t) differs so much from its initial value at t = 0. It also provides a possible explanation for the observed flatness problem since the volume V (t) grows exponentially fast during inflation while the energy density decreases as 1/V (t).\nThe results presented here were obtained using numerical methods based on the fourth-order Runge-Kutta algorithm combined with Newton s method for finding roots.",
        "watermark_text": "We research the dynamics of string cosmologies with nontrivial dilaton potentials , concentrating on their chaotic dynamics . We see that for particular categories of potentials there are areas where trajectories can be trapped by unstable fixed points or periodic orbits .In these circumstances we find that the system is not ergodic but has an endless number of attractors which belong to different values of the Hubble parameter H ( t ) . The existence of such attractor solutions may have important implications for the evolution of our universe .For instance , it could explain why the present value of H ( t ) changes so greatly from its initial value at t = 0 . It additionally offers a possible reason for the seen flatness problem since the volume V ( t ) rises exponentially rapidly during inflation while the electricity capacity reduces as 1 / V ( t ) .The results presented here were obtained using numerical technique based on the fourth - order Runge - Kutta algorithm coupled with Newton s method for finding roots .",
        "rewrite_text": "We investigate the dynamics of string cosmologies featuring nontrivial dilaton potentials, with a particular focus on their chaotic behavior. Our findings reveal that, for specific types of potentials, there are regions where trajectories can become confined by unstable fixed points or periodic orbits. Under these conditions, we observe that the system is not ergodic, and it possesses an infinite number of attractors associated with various values of the Hubble parameter, H(t). The presence of such attractor solutions could have significant implications for the evolution of our universe. For example, it may help explain the substantial change in the current value of H(t) compared to its initial value at t = 0. Additionally, it provides a potential explanation for the observed flatness problem, as the volume V(t) increases exponentially fast during inflation, while the energy density diminishes as 1/V(t). The results presented here were derived using a numerical technique that combines the fourth-order Runge-Kutta algorithm with Newton's method for root finding.",
        "ori-fast-z-score": -0.48507125007266594,
        "water-fast-z-score": 4.85071250072666,
        "rewrite-fast-z-score": -1.2874526191574363
    },
    {
        "original_text": "We present an analysis of N-body simulations aimed at understanding how evaporation shapes the mass function (MF) of globular clusters (GCs). We find that, in agreement with previous studies, evaporation causes GCs to lose stars preferentially on their low-mass end and thus steepens the MF slope towards lower masses. However, we show that this effect is counteracted by two competing processes: dynamical friction which removes massive stars more efficiently than less massive ones; and relaxation-driven core collapse which increases the central density of the cluster and makes it harder for massive stars to escape. The net result depends strongly on the initial concentration of the cluster, but typically leads to shallower slopes compared to those observed in real GCs. This suggests that other processes are required to explain the shape of the observed MF. In particular, our results suggest that primordial binaries may be responsible for producing the high-mass power-law tail seen in many GCs.",
        "watermark_text": "We publish an assessment of N - bodies simulations aiming at studying how evaporation shapes the mass function ( MF ) of globular galaxies ( GCs ) . We see that , in agreement with previous research , evaporation creates GCs to lose stars preferentially on their low - mass ending and therefore steepens the MF slope towards lesser masses .However , we find that this effect is counteracted by two different processes : dynamical friction which destroys massive galaxies more efficiently than less massive ones ; and relaxation - triggered disk collapse which increases the main abundance of the cluster and causes it difficult for huge stars to escape . The total result relies highly on the first abundance of the cluster , but typically leads to shallower slopes compared to those observed in real GCs .This implies that other processes are required to explain the form of the seen MF . In particular , our findings confirm that primordial binaries may be responsible for producing the high - mass power - law tail seen in large GCs .",
        "rewrite_text": "We present an evaluation of N-body simulations aimed at understanding how evaporation influences the mass function (MF) of globular clusters (GCs). Our findings align with earlier studies, indicating that evaporation causes GCs to shed stars preferentially from their low-mass end, resulting in a steeper MF slope at lower masses. However, we also discover that this phenomenon is counterbalanced by two processes: dynamical friction, which disproportionately affects massive galaxies compared to their less massive counterparts, and relaxation-induced disk collapse, which enhances the overall abundance of the cluster and hinders the escape of larger stars. The overall outcome is heavily dependent on the initial abundance of the cluster, typically resulting in shallower slopes than those observed in actual GCs. This suggests that additional mechanisms are needed to account for the observed MF shape. Notably, our results support the notion that primordial binaries may play a role in generating the high-mass power-law tail characteristic of large GCs.",
        "ori-fast-z-score": -1.4444444444444444,
        "water-fast-z-score": 6.184165460191406,
        "rewrite-fast-z-score": 0.45291081365783825
    },
    {
        "original_text": "We present optical and near-infrared photometry of SN 2006bp, which was discovered on September 24th in NGC 6946 by amateur astronomer Brian Puckett (Puckett et al., 2007) . The supernova is located at an unusually large distance for its host galaxy, with a recession velocity of ~1000 km/sec. \n \n We find that the light curve can be well fit using a model consisting of three components: shock breakout emission, radioactive decay powered luminosity, and dust extinction. Using this model we derive physical parameters such as the progenitor radius, mass loss rate, and explosion energy. Our results are consistent with those found for other type-II SNe but suggest that the progenitor star had a lower initial mass than previously thought. This may indicate that there exists more diversity among progenitors of type-II SNe than has been realized so far. In addition to these findings, our observations provide new insights into the physics of shock breakout and early-time evolution of type-II SNe.",
        "watermark_text": "We present visual and far - infrared photometry of SN 2006bp , which was discovered on September 24th in NGC 6946 by amateur astronomer Brian Puckett ( Puckett et al . , 2007 ) . The supernova is situated at an exceptionally wide distance for its host galaxy , with a collapse speeds of ~ 1000 cm / sec .We see that the light spiral can be well fitting using a description consisting of three components : shock breakout emission , radioactive decay powered luminosity , and dust extinction . Using this description we derive physical factors such as the progenitor diameter , mass loss rate , and explosion power .Our results are compatible with those detected for other class - II SNe but suggest that the progenitor star had a smaller original mass than previously thought . This might suggest that there exists more diversity among progenitors of type - II SNe than has been realized so far .In addition to these results , our observations offer additional perspectives into the physics of wave breakout and first - time evolution of type - II SNe .",
        "rewrite_text": "We present visual and far-infrared photometry of SN 2006bp, which was discovered on September 24th in NGC 6946 by amateur astronomer Brian Puckett (Puckett et al., 2007). The supernova is located at an unusually large distance from its host galaxy, exhibiting collapse speeds of approximately 1000 cm/sec. Our analysis reveals that the light curve can be accurately described using a model comprising three components: shock breakout emission, radioactive decay-driven luminosity, and dust extinction. From this model, we derive several physical parameters, including the progenitor’s diameter, mass loss rate, and explosion energy. Our findings align with those observed in other type II supernovae, but indicate that the progenitor star may have had a smaller initial mass than previously assumed. This suggests that there may be greater diversity among the progenitors of type II supernovae than has been recognized. Furthermore, our observations provide valuable insights into the physics of shock breakout and the early evolution of type II supernovae.",
        "ori-fast-z-score": -0.9299811099505543,
        "water-fast-z-score": 5.579886659703326,
        "rewrite-fast-z-score": 0.9299811099505543
    },
    {
        "original_text": "The concept of tensegrity is used to describe the structural behavior of many biological systems, such as muscles and tendons.  In this work we explore how continuous tensegrities can be generated by using an evolutionary algorithm that optimizes their performance in terms of compliance with external loads while maintaining stability under gravity loading conditions.   The results show that it is possible to generate stable structures that are able to resist large deformations without collapsing or losing their integrity. This research has been funded by the European Commission through the Marie Curie Initial Training Network (ITN) program. The concept of tensegrity was first introduced by Buckminster Fuller more than 60 years ago  1  . It describes the structural behavior of many natural systems like muscles  2  , tendons  3  , bones  4  , and even living organisms  5  .\nIn recent decades there have been several attempts at applying the concept of tensegrity to engineering applications  6  -  8  . However, most of these works focus on discrete tensegrities which consist of rigid bars connected together by elastic struts  9  . These types of structures cannot easily adapt to changes in their environment since they do not allow for any deformation  10  . On the other hand, continuous tensegrities  11  are capable of changing shape continuously when subjected to external forces  12  . They also exhibit higher levels of robustness against damage  13  compared to conventional materials  14  . Despite all these advantages, very little attention has been paid so far to the design of continuous tensegrities  15  .\nThis lack of interest may be due to the fact that designing continuous tensegrities requires solving highly nonlinear optimization problems  16  . Moreover, finding solutions to these problems is extremely challenging because of the high number of local optima  17  . To overcome these difficulties, researchers usually use heuristic search algorithms  18  -  20  instead of exact methods  21  .",
        "watermark_text": "The concept of tensegrity is utilized to explain the structural performance of several biological systems , such as muscles and tendons . In this research we investigate how continuous tensegrities can be derived by using an phylogenetic algorithm that optimizes their performance in terms of compliance with external loads while maintaining strength under gravity loading circumstances .The results show that it is easy to produce consistent buildings that are able to resist big deformations without weakening or losing their stability . This research has been sponsored by the European Commission through the Marie Curie Initial Training Network ( ITN ) scheme .The concept of tensegrity was first described by Buckminster Fuller more than 60 years early 1 . It describes the structural function of several physical structures like nerves 2 , tendons 3 , ribs 4 , and even living organisms 5 .In past decades there have been numerous attempts at application the idea of tensegrity to engineering applications 6 - 8 . However , most of these works concentrate on discrete tensegrities which consist of rigid bars connected together by elastic struts 9 .These sorts of structures cannot effectively adapt to changes in their environment since they do not enable for any deformation 10 . On the other hand , continuous tensegrities 11 are capable of changing shape rapidly when exposed to external forces 12 .They especially display higher levels of robustness against damage 13 relative to conventional materials 14 . Despite all these benefits , very less attention has been paid so far to the design of continuous tensegrities 15 .This lack of importance may be due to the fact that designing continuous tensegrities demands modeling highly nonlinear optimization problems 16 . Moreover , finding solutions to these problems is incredibly problematic because of the high number of local optima 17 .To solve these problems , researchers normally use heuristic search methods 18 - 20 rather of precise methods 21 .",
        "rewrite_text": "The concept of tensegrity is employed to elucidate the structural performance of various biological systems, including muscles and tendons. This research explores how continuous tensegrities can be generated using a phylogenetic algorithm designed to optimize their performance, balancing compliance with external loads while ensuring strength during gravitational loading conditions. The findings indicate that it is straightforward to create robust structures capable of withstanding significant deformations without compromising stability. This research is funded by the European Commission through the Marie Curie Initial Training Network (ITN) scheme. Originally introduced by Buckminster Fuller over 60 years ago, tensegrity describes the structural functions of multiple physical systems such as nerves, tendons, ribs, and even living organisms. In recent decades, there have been numerous attempts to apply the principles of tensegrity to engineering, yet most of these efforts focus on discrete tensegrities made of rigid bars linked by elastic struts. These structures are limited in their ability to adapt to environmental changes due to their lack of deformation capability. In contrast, continuous tensegrities can rapidly change shape in response to external forces, demonstrating greater resilience against damage compared to traditional materials. Despite these advantages, the design of continuous tensegrities has received limited attention, likely because creating them involves solving complex nonlinear optimization problems. Additionally, finding solutions to these challenges is particularly difficult due to the prevalence of local optima. Consequently, researchers often resort to heuristic search methods instead of exact approaches.",
        "ori-fast-z-score": -1.2722833945199565,
        "water-fast-z-score": 8.342314001435737,
        "rewrite-fast-z-score": 0.9918365981341755
    },
    {
        "original_text": "The Littlewood-Richardson polynomials are the most important tool in representation theory, and have many applications to other fields as well.  They were introduced by Richard Stanley in 1973 (see also his book Enumerative Combinatorics). The original definition is complicated; here we give an equivalent one which makes them look more like ordinary symmetric functions. We then define the Schur polynomials using these polynomials instead of the usual monomial basis. Finally, we prove that this new definition agrees with the old one on the ring of symmetric functions. This article was written for readers who already know some basic facts about symmetric functions but want to learn how they can be used to study representations of groups. It assumes familiarity with group actions on vector spaces, characters of finite groups, and tensor products of vector spaces. For background information see Group (mathematics) or Representation Theory. In mathematics, the Littlewood–Richardson coefficients c(λ/µ) (also called Kostka numbers), named after John Littlewood and James Richardson, are integers associated to partitions λ and µ of n into at most m parts each such that:",
        "watermark_text": "The Littlewood - Richardson polynomials are the most important tool in representation theory , and have many applications to other fields as also . They were introduced by Richard Stanley in 1973 ( see also his book Enumerative Combinatorics ) .The original formulation is complicated ; here we give an equivalent one which makes them seem more like ordinary symmetric maps . We then define the Schur polynomials using these polynomials instead of the usual monomial basis .Finally , we prove that this new definition agrees with the previous one on the ring of symmetric functions . This page was written for readers who actually know some fundamental details about symmetric functions but want to study how they can be used to study structures of groups .It assumes familiarity with group actions on matrix sets , characters of finite groups , and tensor products of vector spaces . For background data refer Group ( mathematics ) or Representation Theory .In mathematics , the Littlewood – Richardson polynomial c ( λ / µ ) ( also called Kostka values ) , named after John Littlewood and James Richardson , are integers associated to partitions λ and µ of n into at most m components each such that :",
        "rewrite_text": "The Littlewood-Richardson polynomials are a crucial component of representation theory and find numerous applications in various other fields as well. Introduced by Richard Stanley in 1973 (refer to his book \"Enumerative Combinatorics\"), their original formulation can be quite complex. Here, we present an equivalent formulation that makes them appear more akin to standard symmetric functions. We then define Schur polynomials using this version rather than the conventional monomial basis. Ultimately, we demonstrate that this new definition is consistent with the earlier one within the framework of symmetric functions. This page is intended for readers who possess a basic understanding of symmetric functions and are interested in exploring their applications in group structures. It presumes knowledge of group actions on matrices, characters of finite groups, and tensor products of vector spaces. For foundational concepts, please refer to \"Group (mathematics)\" or \"Representation Theory.\" In mathematics, the Littlewood-Richardson polynomial c(λ/μ), also known as Kostka values, are integers linked to partitions λ and μ of n, each into no more than m components.",
        "ori-fast-z-score": -0.1125087900926024,
        "water-fast-z-score": 3.888888888888889,
        "rewrite-fast-z-score": -0.22645540682891913
    },
    {
        "original_text": "We have studied the rheology of isotropic networks formed by crosslinking actin filaments with two different concentrations of biotin-avidin linkers, using microrheology experiments on single filament dynamics in combination with macrorheology measurements performed at low frequencies (0.01-10 Hz). We find that both microand macro-rheology are consistent with an elastic network model for which we can extract values for the number density of links between filaments as well as their stiffness. The results show that increasing the concentration of avidin leads to denser networks with stiffer links. This effect is more pronounced when the initial concentration of actin filaments is higher. Our findings suggest that the mechanical properties of actomyosin gels may be tunable through changes in the amount and/or type of crosslinks present within these systems. In living cells, cytoskeletal structures such as stress fibers or focal adhesions provide physical connections between cell components and play important roles in determining cellular mechanics  1  . These structures consist of bundles of semiflexible biopolymers known as actin filaments  2  , which are connected together via specific protein complexes called crosslinks  3  .\nIn recent years there has been growing interest in understanding how the mechanical properties of biological materials depend on the microscopic structure of the underlying networks  4  . For example, it was shown recently that the viscoelasticity of reconstituted actomyosin gels depends strongly on the presence of myosins  5  . However, despite this progress our knowledge about the relationship between the macroscopic behavior of complex fluids and the microstructure of the constituent building blocks remains limited  6  .",
        "watermark_text": "We have researched the rheology of isotropic bands formed by crosslinking actin filaments with two different amounts of biotin - avidin linkers , using microrheology experiments on double filament dynamics in combination with macrorheology measurements completed at low frequencies ( 0 . 01 - 10 Hz ) . We see that both microand macro - rheology are compatible with an elastic network theory for which we can extract parameters for the number density of links between filaments as also as their stiffness .The results show that raising the density of avidin leads to denser networks with stiffer links . This phenomenon is more pronounced when the first concentration of actin filaments is higher .Our findings show that the mechanical behavior of actomyosin gels might be tunable through alterations in the quantity and / or type of crosslinks observed within these systems . In living cells , cytoskeletal structures such as stress fibers or focal adhesions contribute physical bridges between tissue systems and play essential roles in establishing cellular dynamics 1 .These structures composed of bundles of semiflexible biopolymers known as actin filaments 2 , which are connected together via particular protein complexes called crosslinks 3 . In recent years there has been growing interest in understanding how the mechanical behavior of biological materials depend on the microscopic shape of the underlying systems 4 .For instance , it was shown lately that the viscoelasticity of reconstituted actomyosin gels relies highly on the presence of myosins 5 . However , despite this progress our information about the relationship between the macroscopic behavior of complex fluids and the microstructure of the constituent building components remains restricted 6 .",
        "rewrite_text": "We investigated the rheological properties of isotropic bands formed by crosslinking actin filaments with varying amounts of biotin-avidin linkers. This was accomplished through microrheology experiments focused on double filament dynamics, alongside macrorheology measurements conducted at low frequencies (0.01 - 10 Hz). Our results indicate that both micro- and macrorheology align with an elastic network theory, allowing us to derive parameters such as the number density of links between filaments and their stiffness. We observed that increasing the avidin concentration results in denser networks with stiffer links, a trend that is more pronounced at higher initial concentrations of actin filaments. These findings suggest that the mechanical properties of actomyosin gels can be adjusted by modifying the quantity and/or type of crosslinks present in the system. In living cells, cytoskeletal structures like stress fibers and focal adhesions serve as physical connections between different tissue systems and are crucial for cellular dynamics. These structures consist of bundles of semiflexible biopolymers, known as actin filaments, which are interconnected by specific protein complexes called crosslinks. Recent research has highlighted the importance of the microscopic architecture of these systems in influencing the mechanical behavior of biological materials. For example, it has recently been shown that the viscoelastic properties of reconstituted actomyosin gels are significantly affected by the presence of myosins. Nonetheless, our understanding of how the macroscopic behavior of complex fluids relates to the microstructure of their constituent components remains limited.",
        "ori-fast-z-score": -0.19611613513818404,
        "water-fast-z-score": 7.19290373059934,
        "rewrite-fast-z-score": 0.9233805168766388
    },
    {
        "original_text": "We present an exact solution to the classical equations of motion in two dimensions, which is interpreted as describing a rotating black hole with angular momentum J = M . The metric has the form ds2 = −dt2+(1+cosh2r)dθ2−r2dr2,\nwhere r and θ are polar coordinates on the plane. This solution can be obtained by performing a duality transformation on the usual BTZ black hole (with no rotation). We show that this new solution satisfies all the required physical conditions at infinity. In particular we find that it describes a regular black hole horizon located atr+ = √3M , where M is the mass parameter appearing in the original BTZ solution. Finally, we discuss some possible generalizations of our results. Introduction:-In recent years there have been many attempts to construct solutions to Einstein s field equations corresponding to rotating black holes  1  -  4  . One particularly interesting class of such solutions was found by Bañados, Teitelboim and Zanelli (BTZ), who showed how one could obtain a static black hole solution in three dimensional anti-de Sitter space-time  5  .\nThe most important feature of these solutions is their asymptotic behaviour; they describe black holes whose event horizons are completely determined by global quantities like total energy or charge  6  . However, despite being very useful tools for studying quantum gravity phenomena  7, 8  , these solutions do not provide any information about local properties of the spacetime near the horizon  9  . It would therefore seem desirable to try to extend them into more complicated geometries containing additional parameters characterizing the internal structure of the black hole  10  .\nOne way of doing so is to consider higher-dimensional extensions of the BTZ solution  11  . Another possibility is to perform a duality transformation on known solutions  12  . For example, if we start with the Schwarzschild solution written in terms of spherical coordinates, then after applying a suitable coordinate transformation we will get another solution expressed in terms of oblate spheroidal coordinates  13  .",
        "watermark_text": "We present an precise answer to the classical equations of movement in two dimensions , which is interpreted as representing a rotating black hole with angular velocity J = M . The metric has the form ds2 = −dt2 + ( 1 + cosh2r ) dθ2−r2dr2 , where p and θ are polar coordinates on the plane .This solution can be obtained by performing a duality conversion on the usual BTZ dark hole ( with no rotation ) . We see that this new solution satisfies all the necessary physical conditions at infinity .In particular we find that it describes a regular dark hole horizon located atr + = √3M , where M is the mass vector appearing in the previous BTZ solution . Finally , we explain some possible generalizations of our findings .Introduction : - In recent history there have been many efforts to build solutions to Einstein s field equations corresponding to spinning black holes 1 - 4 . One especially interesting class of such solve was seen by Bañados , Teitelboim and Zanelli ( BTZ ) , who demonstrated how one might obtain a static black hole solution in three dimensional anti - de Sitter space - time 5 .The most important feature of these solutions is their asymptotic behaviour ; they describe brown holes whose event horizons are completely determined by global quantities like total energy or charge 6 . However , despite being very useful techniques for studying quantum gravitational dynamics 7 , 8 , these solutions do not offer any info about local characteristics of the spacetime near the horizon 9 .It would therefore appear desirable to work to extend them into more complicated geometries containing extra constraints characterizing the internal structure of the dark hole 10 . One method of doing so is to consider higher - dimensional applications of the BTZ solution 11 .Another possibility is to conduct a duality conversion on known solutions 12 . For instance , if we start with the Schwarzschild solution written in terms of spherical coordinates , then after applying a suitable coordinate transformation we will get another solution expressed in terms of oblate spheroidal coordinates 13 .",
        "rewrite_text": "We provide a precise solution to the classical equations of motion in two dimensions, interpreted as a rotating black hole with angular velocity \\( J = M \\). The metric takes the form \\( ds^2 = -dt^2 + (1 + \\cosh^2 r) d\\theta^2 - r^2 dr^2 \\), where \\( r \\) and \\( \\theta \\) are polar coordinates on the plane. This solution can be derived through a duality transformation applied to the traditional BTZ black hole (which does not rotate). Notably, this new solution meets all necessary physical conditions at infinity. Specifically, it describes a regular black hole horizon positioned at \\( r_+ = \\sqrt{3M} \\), with \\( M \\) representing the mass parameter from the previous BTZ solution. We also discuss potential generalizations of our results.  \n\n**Introduction**: In recent years, numerous attempts have been made to develop solutions to Einstein's field equations that correspond to spinning black holes. A particularly intriguing class of solutions was presented by Bañados, Teitelboim, and Zanelli (BTZ), who illustrated how to derive a static black hole solution in three-dimensional anti-de Sitter spacetime. A key feature of these solutions is their asymptotic behavior; they describe black holes whose event horizons are determined entirely by global quantities such as total energy and charge. However, while these techniques are valuable for studying quantum gravitational dynamics, they provide little insight into the local characteristics of spacetime near the horizon. Thus, it becomes important to explore more complex geometries that include additional constraints characterizing the internal structure of the black hole. One approach to achieve this is by considering higher-dimensional analogs of the BTZ solution. Another avenue is to perform a duality transformation on existing solutions; for example, starting with the Schwarzschild solution in spherical coordinates and applying an appropriate coordinate transformation can yield an alternative solution in terms of oblate spheroidal coordinates.",
        "ori-fast-z-score": 1.150792911137501,
        "water-fast-z-score": 8.27424239724231,
        "rewrite-fast-z-score": 0.8391813582966892
    },
    {
        "original_text": "We compare the performance of two different methods to simulate non-equilibrium dynamics in polymer systems, namely dissipative particle dynamics (DPD) with either a Nosé-Hoover or a Langevin thermostat. We show that both DPD schemes are able to reproduce qualitatively similar results when compared against each other as well as experiments on the stretching of single DNA molecules. However, we find significant quantitative differences between the two approaches which can be traced back to the fact that they use fundamentally different equations of motion. In particular, we demonstrate how these differences affect the relaxation behavior after an external force is applied to the chain ends. Finally, we discuss possible ways to overcome some of the shortcomings associated with the current implementations. \n \n Introduction \n \n The study of complex fluids such as polymers requires sophisticated simulation techniques capable of describing their unique properties at various length scales. While atomistic molecular dynamics has been successfully used to investigate phenomena occurring over short time and length scales  1–3 , coarse-grained models have emerged as powerful tools to explore longer timescales  4–6 . These simplified descriptions typically involve representing groups of atoms by one effective interaction site  7–9 . For example, in the case of biopolymers like proteins  10–12  or nucleic acids  13–18 , this approach allows us to capture essential features of the underlying physics while reducing computational costs significantly  19, 20 . \n \n Coarse-graining strategies often rely on mapping the interactions among individual particles onto effective potentials  21 . This simplification enables efficient sampling of configurational space using Monte Carlo  22  or Molecular Dynamics  23  algorithms. Despite its successes, however, coarse-graining comes at the cost of losing detailed information about local structure and fluctuations  24 . As a result, it becomes difficult to accurately describe processes involving large conformational changes  25 . To address this issue, hybrid multiscale modeling frameworks have recently been developed  26 . Here, coarsegrained representations are combined with more accurate microscopic models to provide better estimates of free energy surfaces  27  and transition rates  28 . \n \n Another important aspect of coarse-grained models concerns the choice of appropriate",
        "watermark_text": "We contrast the performance of two different methods to simulate non - equilibrium dynamics in polymer systems , namely dissipative particle behavior ( DPD ) with either a Nosé - Hoover or a Langevin thermostat . We see that both DPD strategies are able to predict qualitatively identical outcome when compared against each other as well as experiments on the stretching of multiple DNA molecules .However , we find considerable quantitative variations between the two strategies which can be traced back to the fact that they use fundamentally different equations of movement . In particular , we study how these changes affect the relaxation behavior after an external stress is applied to the chain ends .Finally , we explain possible ways to overcome some of the shortcomings associated with the present implementations . Introduction The investigation of complex materials such as polymers demands sophisticated simulation algorithms suitable of describing their distinct characteristics at several length scales .While atomistic atomic dynamics has been successfully utilized to examine processes arising over short period and duration scales 1 – 3 , coarse - grained models have developed as powerful tools to examine longer timescales 4 – 6 . These simplified descriptions typically involve describing bands of atoms by one effective bonding location 7 – 9 .For instance , in the case of biopolymers like genes 10 – 12 or nucleic acids 13 – 18 , this methodology allows us to capture essential aspects of the fundamental physics while reducing theoretical costs significantly 19 , 20 . Coarse - graining methods often relies on mapping the interactions among individual molecules onto effective potentials 21 .This simplification enables efficient scanning of configurational space employing Monte Carlo 22 or Molecular Dynamics 23 methods . Despite its effectiveness , however , coarse - graining comes at the cost of losing explicit data about local structure and fluctuations 24 .As a result , it becomes hard to correctly define systems featuring large conformational changes 25 . To address this question , hybrid multiscale modeling frameworks have recently been created 26 .Here , coarsegrained representations are coupled with more accurate microscopic predictions to provide better estimates of free energy materials 27 and transfer rates 28 . Another important dimension of rough - grained models concerns the selection of appropriate",
        "rewrite_text": "We compare the effectiveness of two distinct methods for simulating non-equilibrium dynamics in polymer systems, specifically dissipative particle dynamics (DPD) utilizing either a Nosé-Hoover or a Langevin thermostat. Our findings reveal that both DPD approaches yield qualitatively similar results when evaluated against one another and against experimental data on the stretching of several DNA molecules. However, we observe significant quantitative discrepancies between the two methods, which can be attributed to their fundamentally different equations of motion. In particular, we analyze how these variations influence the relaxation behavior following the application of external stress to the ends of the chains. Lastly, we discuss potential strategies to mitigate some of the limitations inherent in the current implementations.\n\nIntroduction: The study of complex materials like polymers requires advanced simulation algorithms capable of capturing their unique characteristics across various length scales. While atomistic dynamics has been successfully employed to investigate processes occurring over short timeframes, coarse-grained models have emerged as powerful tools for exploring longer timescales. These simplified models typically represent groups of atoms as a single effective bonding entity. For example, in the context of biopolymers such as genes or nucleic acids, this approach allows us to encapsulate key aspects of fundamental physics while significantly reducing computational costs. Coarse-graining methods often depend on mapping the interactions of individual molecules into effective potentials, facilitating efficient exploration of configurational space via Monte Carlo or Molecular Dynamics techniques. Nonetheless, this efficiency comes with the drawback of losing detailed information about local structures and fluctuations, which can hinder the accurate characterization of systems that experience substantial conformational changes. To tackle this issue, recent advancements have led to the development of hybrid multiscale modeling frameworks that integrate coarse-grained representations with more precise microscopic predictions, ultimately improving estimates of free energies and transfer rates. Additionally, a critical aspect of coarse-grained models is the careful selection of appropriate representations.",
        "ori-fast-z-score": -0.6099942813304187,
        "water-fast-z-score": 8.490698088083718,
        "rewrite-fast-z-score": -0.8835412617927487
    },
    {
        "original_text": "The colour reconnection (CR) model is used to describe how quarks and gluons rearrange themselves into hadrons after they are produced by hard scattering processes, such as those occurring during e+e-annihilation events.  The CR model predicts that particles emitted close together in phase space will be more likely to recombine than those which are further apart.  This effect can lead to changes in event topology and kinematics compared to predictions made using models without CR.  In this analysis we use data collected by the Delphi experiment operating at centre-of-mass energies between 189 GeV and 209 GeV corresponding to an integrated luminosity of 1.1 fb-1.  We measure the fraction of WW events where one or both W bosons decay leptonically for different ranges of dilepton invariant mass and compare these results to Monte Carlo simulations including and excluding CR effects.  Our measurements show no significant evidence for CR effects within our experimental uncertainties.",
        "watermark_text": "The colour reconnection ( CR ) model is utilized to explain how quarks and gluons rearrange themselves into hadrons after they are produced by hard scattering mechanisms , such as those occurring during e + e - annihilation processes . The CR theory predicts that particles emitted close together in phase space will be more likely to recombine than those which are further separated .This phenomenon can lead to changes in event topology and kinematics compared to forecast making using models without CR . In this analysis we utilize evidence generated by the Delphi experiment working at centre - of - mass energies between 189 GeV and 209 GeV corresponding to an unified luminosity of 1 . 1 fb - 1 .We estimate the fraction of WW occasions where one or both W bosons decay leptonically for different ranges of dilepton invariant mass and compare these results to Monte Carlo simulations using and excluding CR effects . Our measurements show no important proof for CR influences within our research uncertainties .",
        "rewrite_text": "The color reconnection (CR) model is employed to illustrate how quarks and gluons reorganize into hadrons following their production via hard scattering processes, such as those that occur during electron-positron (e+e-) annihilation. According to the CR theory, particles that are emitted close together in phase space are more likely to recombine than those that are more widely separated. This effect can result in variations in event topology and kinematics when compared to predictions made using models that do not incorporate CR. In this analysis, we leverage data from the Delphi experiment, which operated at center-of-mass energies between 189 GeV and 209 GeV, accumulating an integrated luminosity of 1.1 fb^-1. We estimate the fraction of WW events in which one or both W bosons decay leptonically across different ranges of dilepton invariant mass, and we compare these findings to Monte Carlo simulations that include and exclude CR effects. Our measurements do not provide significant evidence for the influence of CR within the uncertainties of our research.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.905778905196061,
        "rewrite-fast-z-score": 1.1523319193960637
    },
    {
        "original_text": "The formation of dipoles in self-assembled monolayers (SAMs) on metal surfaces is investigated by scanning tunneling microscopy/spectroscopy (STM/STS). The SAM consists of octadecanethiols with an end group that contains either one or two thiocyanates, which are known to form strong dipole moments upon adsorption onto gold substrates. We find that the presence of these strongly polarizable groups leads to significant changes in the electronic structure of the SAM compared to nonpolar alkane chains. In particular, we observe a shift of the molecular states towards higher energies as well as a reduction of their spatial extension perpendicular to the surface. These effects can be explained within a simple model based on electrostatic interactions between the molecules and the substrate. Our results demonstrate how chemical functionalization allows for tailoring the properties of organic films deposited on metallic surfaces. Dipole formation at interfaces of alkanethiolate self-assembled monolay- ers and Ag(111) has been studied using scanning tunneling microscopy/ spectroscopy (STM/S). The SAM was prepared by chemisorption of octadecanethiol containing thiocyanate endgroups on Ag(111), resulting in a film with a large dipole moment per unit area. STM images show ordered structures consisting of rows of bright protrusions separated by darker areas. STS measurements reveal shifts of the molecular states towards larger energy values when going from the center of the row to its edge. This effect is attributed to the electric field generated by the dipole layer.",
        "watermark_text": "The formation of dipoles in self - assembled monolayers ( SAMs ) on metal surfaces is investigated by scanning tunneling microscopy / spectroscopy ( STM / STS ) . The SAM consists of octadecanethiols with an ending group that contains either one or two thiocyanates , which are known to form strong dipole moments upon adsorption onto gold surfaces .We see that the presence of these strongly polarizable groups results to significant improvements in the chemical structure of the SAM compared to nonpolar alkane rings . In particular , we study a shift of the molecular states towards higher energies as well as a reduction of their spatial extension lateral to the surface .These effects can be described within a simple simulation based on electrostatic interactions between the molecules and the substrate . Our results show how chemical functionalization allows for tailoring the properties of organic films accumulated on metallic surfaces .Dipole form at interfaces of alkanethiolate self - assembled monolay - ers and Ag ( 111 ) has been studied utilizing scanning tunneling microscopy / spectroscopy ( STM / S ) . The SAM was prepared by chemisorption of octadecanethiol containing thiocyanate endgroups on Ag ( 111 ) , resulting in a film with a large dipole point per unit area .STM pictures show ordered compounds consisting of columns of bright protrusions separated by deeper spots . STS measurements reveal shifts of the molecular states towards higher energy quantities when going from the center of the row to its boundary .This phenomenon is attributed to the electric field produced by the dipole layer .",
        "rewrite_text": "The formation of dipoles in self-assembled monolayers (SAMs) on metal surfaces has been explored using scanning tunneling microscopy and spectroscopy (STM/STS). The SAMs studied are composed of octadecanethiols featuring one or two thiocyanate end groups, which are known to create strong dipole moments upon adsorption onto gold surfaces. Our findings indicate that the inclusion of these highly polarizable groups leads to notable enhancements in the chemical structure of the SAM when compared to nonpolar alkane rings. Specifically, we observe a shift of the molecular states toward higher energy levels and a decrease in their lateral spatial extension over the surface. These phenomena can be modeled using a straightforward simulation that accounts for the electrostatic interactions between the molecules and the substrate. Our results highlight how chemical functionalization can be utilized to customize the properties of organic films deposited on metallic surfaces. Additionally, the formation of dipoles at the interfaces of alkanethiolate self-assembled monolayers on Ag (111) has been examined through STM/STS techniques. The SAM was fabricated through the chemisorption of octadecanethiol with thiocyanate end groups on Ag (111), resulting in a film characterized by a high dipole moment per unit area. STM images reveal an organized arrangement of columns composed of bright protrusions, interspersed with deeper regions. STS measurements demonstrate that the molecular states shift to higher energy as one moves from the center of the column to its edges, a phenomenon attributed to the electric field generated by the dipole layer.",
        "ori-fast-z-score": 1.3862065601673441,
        "water-fast-z-score": 6.8657566124489255,
        "rewrite-fast-z-score": 2.6603890510435915
    },
    {
        "original_text": "We have analyzed the kinematics of nearby solar-type stars (F,G dwarfs) with ages between 1 Myr and 10 Gyr using Hipparcos astrometry data. We find that there is no significant difference in their velocity dispersion profiles at different ages. The observed flatness of the profile suggests that these stars are on nearly circular orbits around the Sun. This result supports our previous finding based on the analysis of open clusters. \n \n Keywords: Kinematics, Open cluster, Nearby star, Stellar age, Solar neighborhood, Velocity field, Galactic rotation curve, Galaxy evolution, Galactic disk, Galactic structure, Galactic dynamics, Galactic halo, Galactic center, Galactic bulge, Galactic bar, Galactic spiral arms, Galactic warp, Galactic tidal forces, Galactic potential, Galactic mass distribution, Galactic satellites, Galactic dark matter",
        "watermark_text": "We have analyzed the kinematics of nearby solar - class stars ( F , G dwarfs ) with periods between 1 Myr and 10 Gyr using Hipparcos astrometry information . We see that there is no major variation in their velocity dispersion characteristics at different ages .The observed flatness of the profile suggests that these stars are on nearly circular orbits around the Sun . This result confirms our previous finding based on the analysis of open complexes .Keywords : Kinematics , Open cluster , Nearby star , Stellar age , Solar region , Velocity field , Galactic rotation curve , Galaxy evolution , Galactic disk , Galactic structure , Galactic structure , Galactic halo , Galactic center , Galactic bulge , Galactic bar , Galactic spiral arms , Galactic warp , Galactic tidal forces , Galactic potential , Galactic mass distribution , Galactic satellites , Galactic dark matter",
        "rewrite_text": "We investigated the kinematics of nearby solar-type stars (F and G dwarfs) with ages ranging from 1 million to 10 billion years using astrometric data from Hipparcos. Our analysis reveals that there is no significant variation in their velocity dispersion characteristics across different ages. The observed uniformity in the velocity profile indicates that these stars are likely on nearly circular orbits around the Sun. This finding supports our earlier results derived from the study of open clusters.  \n**Keywords:** Kinematics, Open cluster, Nearby star, Stellar age, Solar neighborhood, Velocity field, Galactic rotation curve, Galaxy evolution, Galactic disk, Galactic structure, Galactic halo, Galactic center, Galactic bulge, Galactic bar, Galactic spiral arms, Galactic warp, Galactic tidal forces, Galactic potential, Galactic mass distribution, Galactic satellites, Galactic dark matter.",
        "ori-fast-z-score": -0.8320502943378437,
        "water-fast-z-score": 2.0604084592303353,
        "rewrite-fast-z-score": -0.39735970711951313
    },
    {
        "original_text": "The DWEB benchmark is an open-source data warehouse engineering benchmark that can be used to evaluate the performance and scalability of different data warehouse systems, including relational databases (e.g., Oracle), columnar stores (e.g., MonetDB) and NoSQL databases (e.g,. Cassandra). The benchmark consists of three main components: a query generator, a database server emulator, and a client application. In this work we present the design and implementation details for each component as well as our experiences in using it on several platforms. We also provide some insights into how the benchmark was developed and discuss its limitations. Finally, we compare the results obtained by running the benchmark against two state-of-the-art commercial products. This article is part of the Proceedings of the 20th International Conference on Database Systems for Advanced Applications (DASFAA 2015).\nIntroduction\n\nData warehouses are large repositories storing historical information about business processes or other types of activities. They have been widely adopted over the last decade due to their ability to support decision making at various levels within organizations  1  . However, with the increasing size of data warehouses, there has been growing interest in developing new techniques to improve their efficiency  2  .\nIn order to assess these new techniques, researchers need benchmarks capable of evaluating the performance and scalability characteristics of different data warehouse systems  3  , such as relational databases  4  , columnar stores  5  , and NoSQL databases  6  . Unfortunately, most existing benchmarks focus only on one type of system  7, 8  , which makes them unsuitable for comparing multiple technologies simultaneously  9  . To address this problem, we propose the DWEB benchmark  10  , which supports both traditional SQL queries and more advanced analytical operations  11  .",
        "watermark_text": "The DWEB benchmark is an open - source information warehouse architecture benchmark that can be used to analyze the performance and scalability of different data warehouse applications , notably relational databases ( e . g . , Oracle ) , columnar stores ( e . g . , MonetDB ) and NoSQL databases ( e . g , . Cassandra ) .The benchmark consists of three principal portions : a query generator , a document server emulator , and a client application . In this project we present the development and implementation information for each product as well as our achievements in utilizing it on numerous systems .We additionally offer some details into how the benchmark was developed and consider its limitations . Finally , we compare the results acquired by running the benchmark against two state - of - the - art commercial products .This page is part of the Proceedings of the 20th International Conference on Database Systems for Advanced Applications ( DASFAA 2015 ) . Introduction Data warehouses are big repositories storing historical data about corporate processes or other types of activities .They have been widely adopted over the last decade due to their potential to support decision making at several levels within organizations 1 . However , with the increasing size of video warehouses , there has been growing interest in implementing new tactics to improve their productivity 2 .In order to examine these new strategies , researchers require benchmarks capable of evaluating the performance and scalability characteristics of different data warehouse technologies 3 , such as relational databases 4 , columnar stores 5 , and NoSQL databases 6 . Unfortunately , most existing benchmarks focus only on one sort of system 7 , 8 , which makes them unsuitable for comparing multiple concepts simultaneously 9 .To address this situation , we propose the DWEB benchmark 10 , which supports both traditional SQL queries and more advanced descriptive techniques 11 .",
        "rewrite_text": "The DWEB benchmark is an open-source architecture designed for evaluating the performance and scalability of various data warehouse applications, including relational databases (such as Oracle), columnar stores (like MonetDB), and NoSQL databases (for example, Cassandra). It comprises three main components: a query generator, a document server emulator, and a client application. In this project, we share the development and implementation details for each component, along with our successes in applying it across several systems. Additionally, we provide insights into the benchmark's development process and discuss its limitations. We conclude by comparing the results from the benchmark with those obtained from two cutting-edge commercial products. This work is part of the Proceedings of the 20th International Conference on Database Systems for Advanced Applications (DASFAA 2015). \n\nIntroduction: Data warehouses serve as extensive repositories of historical data related to corporate processes and various activities. Their adoption has surged in the past decade due to their capability to support decision-making at multiple levels within organizations. However, as the size of data warehouses has increased, there is a growing interest in developing new strategies to enhance their efficiency. To explore these new approaches, researchers need benchmarks that can assess the performance and scalability of different data warehouse technologies, including relational databases, columnar stores, and NoSQL databases. Unfortunately, most existing benchmarks are limited to evaluating a single type of system, rendering them ineffective for simultaneous comparisons of different technologies. To tackle this issue, we introduce the DWEB benchmark, which accommodates both traditional SQL queries and more sophisticated descriptive techniques.",
        "ori-fast-z-score": 0.1781741612749496,
        "water-fast-z-score": 7.363817383097771,
        "rewrite-fast-z-score": 1.104689541477988
    },
    {
        "original_text": "The Marcus-Lushnikov process is the continuous-time analogue of the discrete-time Lévy walk model introduced by Montroll-Weiss in 1965 to describe diffusion-limited aggregation (DLA) on fractal surfaces.  The DLA growth mechanism has been observed experimentally for many years but only recently have there been attempts at modelling it mathematically using stochastic processes such as the Marcus-Lushnikov process.   In this article we consider two related problems concerning the Marcus-Lushnikov model:  Firstly, we prove that if the jump distribution of the underlying Lévy process satisfies certain integrability conditions then the corresponding Marcus-Lushnikov process converges weakly to Brownian motion with drift; secondly, we show how the Marcus-Lushnikov model can be used to approximate the solution of Smoluchowski s coagulation-fragmentation equation which describes the evolution of particle size distributions in chemical reactions involving clusters of particles. We also discuss some connections between the Marcus-Lushnikov and Flory s models of polymerisation.",
        "watermark_text": "The Marcus - Lushnikov mechanism is the continuous - time analogue of the discrete - time Lévy walk system proposed by Montroll - Weiss in 1965 to explain diffusion - limited aggregation ( DLA ) on fractal curves . The DLA growth mechanism has been observed experimentally for numerous years but only lately have there been attempts at describing it mathematically utilizing stochastic processes such as the Marcus - Lushnikov cycle .In this article we investigate two similar problems concerning the Marcus - Lushnikov model : Firstly , we prove that if the jump density of the underlying Lévy reaction satisfies certain integrability constraints then the analogous Marcus - Lushnikov cycle converges strongly to Brownian movement with drift ; secondly , we prove how the Marcus - Lushnikov model can be used to approximate the solve of Smoluchowski s coagulation - fragmentation equation which explains the evolution of particle size distributions in chemical processes involving clusters of molecules . We also discuss some ties between the Marcus - Lushnikov and Flory s theories of polymerisation .",
        "rewrite_text": "The Marcus-Lushnikov mechanism serves as the continuous-time counterpart to the discrete-time Lévy walk model introduced by Montroll and Weiss in 1965, which was designed to elucidate the process of diffusion-limited aggregation (DLA) on fractal structures. Although the DLA growth phenomenon has been experimentally observed for many years, it has only recently begun to be mathematically characterized using stochastic processes like the Marcus-Lushnikov cycle. In this article, we explore two related issues within the framework of the Marcus-Lushnikov model. First, we demonstrate that if the jump density of the underlying Lévy reaction meets specific integrability criteria, then the corresponding Marcus-Lushnikov cycle converges strongly to a Brownian motion with drift. Second, we show how the Marcus-Lushnikov model can be employed to approximate solutions to Smoluchowski’s coagulation-fragmentation equation, which describes the dynamics of particle size distributions in chemical processes involving molecular clusters. Additionally, we examine the connections between the Marcus-Lushnikov approach and Flory's theories of polymerization.",
        "ori-fast-z-score": -0.25,
        "water-fast-z-score": 6.0,
        "rewrite-fast-z-score": 0.4923659639173309
    },
    {
        "original_text": "The purpose of this study is to analyze the real estate market in the city of Las Vegas (LV) by using the Composite Shiller Weiss Indexes (CSWI). The data used for analysis are monthly prices of residential properties sold between January 2005 and December 2014. In addition, we use the autoregressive integrated moving average model with exogenous variables (ARIMAX), which allows us to predict future values of the indexes based on past information. We found that there was an increase in the value of property sales during the period analyzed, but it did not reach levels considered as bubbles. However, the results show that the LV real estate market has experienced periods of overvaluation since 2007. Finally, our findings suggest that the ARIMAX model can be useful when predicting the evolution of the CSWI indexes. Keywords: Real Estate Market; Prediction Modeling; Autoregressive Integrated Moving Average",
        "watermark_text": "The purpose of this study is to analyze the real property market in the cities of Las Vegas ( LV ) by using the Composite Shiller Weiss Indexes ( CSWI ) . The data used for study are monthly prices of housing structures sold between January 2005 and December 2014 .In addition , we utilize the autoregressive integrated moved average model with exogenous parameters ( ARIMAX ) , which allows us to predict upcoming values of the indexes based on past data . We showed that there was an increase in the value of property prices during the period analyzed , but it did not reach levels regarded as bubbles .However , the results show that the LV real property market has undergone cycles of overvaluation since 2007 . Finally , our findings show that the ARIMAX theory can be valuable when predicting the evolution of the CSWI indexes .Keywords: Real Estate Market; Prediction Modeling; Autoregressive Integrated Moving Average",
        "rewrite_text": "The aim of this study is to examine the real estate market in Las Vegas (LV) using the Composite Shiller Weiss Indexes (CSWI). The analysis is based on monthly housing prices for properties sold from January 2005 to December 2014. Additionally, we employ the autoregressive integrated moving average model with exogenous variables (ARIMAX) to forecast future values of the indexes using historical data. Our findings indicate a rise in property prices during the analyzed period, although they did not escalate to bubble levels. Nevertheless, the results reveal that the LV real estate market has experienced cycles of overvaluation since 2007. Ultimately, our research demonstrates the effectiveness of the ARIMAX model in predicting changes in the CSWI indexes.  \nKeywords: Real Estate Market; Predictive Modeling; Autoregressive Integrated Moving Average.",
        "ori-fast-z-score": 1.4832396974191326,
        "water-fast-z-score": 5.879747322073337,
        "rewrite-fast-z-score": -0.14285714285714285
    },
    {
        "original_text": "The authors report on observations made with the HESS telescope array, which detected emission at energies above 1TeV (1 teraelectronvolt) coming from an area within 0.2 degrees of the center of the galaxy M87.  The data are consistent with theoretical predictions that such emissions should be produced by particles accelerated near the event horizon of a supermassive black hole located there.   This is the first time this phenomenon has been observed outside our own Galaxy and it opens up new opportunities for studying particle acceleration processes around black holes. Black holes are among the most exotic objects known to science. They have no surface or edge but instead exist as singularities where space-time ends. In addition they exert enormous gravitational forces so that even light cannot escape their grasp. However, despite these extreme conditions, some scientists believe that matter can still be accelerated close to the speed of light inside the so-called  event horizons  surrounding black holes. Such high energy phenomena could produce extremely energetic photons called  TeV gammas  - short for Tera-Electron-Volt photons. These would then be detectable using ground-based telescopes like those used by the High Energy Stereoscopic System (HESS). On April 10, 2014, astronomers working with the HESS observatory announced the detection of TeV-gamma rays originating from the central region of the distant galaxy Messier 87 (M87), about 50 million light years away  1  . This was the first time that such radiation had ever been seen outside our own Milky Way  2  , opening up exciting possibilities for studying particle accelerators associated with black holes  3  .\nIn order to understand how this discovery came about we need to know more about what happens when matter falls into a black hole. As shown in Figure 1 below, if you were standing next to one you d see nothing special happening until your distance from its centre became smaller than its Schwarzschild radius  4  . At this point gravity becomes so strong that all forms of matter become trapped inside the black hole s event horizon  5  . Inside the event horizon, however,...",
        "watermark_text": "The authors report on observations made with the HESS telescope array , which revealed emission at energies above 1TeV ( 1 teraelectronvolt ) coming from an area within 0 . 2 degrees of the center of the universe M87 . The data are compatible with theoretical expectations that such emissions should be made by particles advanced near the event horizon of a supermassive black hole located there .This is the first time this phenomenon has been observed outside our own Galaxy and it opens up new opportunities for studying particle motion processes around black holes . Black holes are among the most exotic objects known to science .They have no surface or edge but instead appear as singularities where space - time finishes . In addition they exert enormous gravitational pressures so that even light cannot escape their embrace .However , despite these extreme circumstances , some scientists consider that matter can still be advanced close to the speed of light inside the so - called event horizons surrounding black holes . Such high energy phenomena could generate incredibly energetic photons called TeV gammas - short for Tera - Electron - Volt photons .These would then be detectable using ground - based telescopes like those utilized by the High Energy Stereoscopic System ( HESS ) . On April 10 , 2014 , astronomers studying with the HESS telescope confirmed the discovery of TeV - gamma radiation resulting from the central region of the distant galaxy Messier 87 ( M87 ) , about 50 million light years away 1 .This was the first time that such emission had ever been seen outside our own Milky Way 2 , opening up interesting possibilities for studying plasma accelerators associated with black holes 3 . In order to comprehend how this discovery went about we require to knowledge more about what comes when matter drops into a black hole .As seen in Figure 1 below , if you were standing close to one you d see nothing extraordinary occurring until your distance from its centre becoming smaller than its Schwarzschild diameter 4 . At this time gravity becomes so powerful that all forms of matter remain imprisoned inside the dark hole s event horizon 5 .Inside the event horizon , however , . . .",
        "rewrite_text": "The authors present findings from observations conducted with the HESS telescope array, which detected emissions exceeding 1 TeV (1 teraelectronvolt) from a region within 0.2 degrees of the center of the galaxy M87. This data aligns with theoretical predictions that such emissions result from particles accelerated near the event horizon of the supermassive black hole located there. Notably, this marks the first instance of observing this phenomenon beyond our own Galaxy, paving the way for new explorations into particle dynamics around black holes. Black holes are among the most fascinating entities in science, lacking a surface or edge and manifesting as singularities where space-time ceases. They exert immense gravitational forces, preventing even light from escaping their grasp. However, some researchers believe that matter can still be accelerated to near-light speeds close to the event horizons of black holes. These high-energy interactions could produce extremely energetic photons known as TeV gammas—short for Tera-Electron-Volt photons—detectable by ground-based telescopes like the ones used by the High Energy Stereoscopic System (HESS). On April 10, 2014, astronomers using the HESS telescope confirmed the detection of TeV gamma radiation emanating from the central region of the distant galaxy Messier 87 (M87), located approximately 50 million light-years away. This discovery was unprecedented outside our Milky Way, creating exciting new avenues for investigating plasma accelerators linked to black holes. To grasp the implications of this discovery, it is essential to understand the process that occurs when matter approaches a black hole. As illustrated in Figure 1 below, if you were situated close to one, you would notice nothing unusual until your distance from its center became smaller than its Schwarzschild radius. At this point, gravity becomes so intense that all forms of matter are confined within the black hole's event horizon. Inside the event horizon, however...",
        "ori-fast-z-score": 0.16012815380508713,
        "water-fast-z-score": 7.422208025548886,
        "rewrite-fast-z-score": 0.0842151921066519
    },
    {
        "original_text": "We propose to use photonic molecules, which are composed of two or more coupled microcavities with different resonant wavelengths, as building blocks for novel types of lasers and optoelectronics devices. We show that the coupling between these cavities can lead to several interesting phenomena such as: (i) formation of hybridized modes, (ii) appearance of sharp peaks in emission spectrum at frequencies corresponding to avoided crossings of cavity eigenmodes, (iii) enhancement of spontaneous emission rate due to Purcell effect, and (iv) strong modification of optical gain properties by means of mode competition effects. These features open up possibilities for designing new types of laser sources based on photonic molecules, including single-mode lasers operating at room temperature without any external feedback elements. \n \n The proposed approach is illustrated using examples of photonic molecules consisting of pairs of semiconductor microdisks with slightly different diameters. It is shown that the considered structures allow one to obtain high quality factor whispering gallery modes with Q-factors exceeding 10^6.",
        "watermark_text": "We suggest to use photonic compounds , which are composed of two or more coupled microcavities with varying resonant wavelengths , as building blocks for novel varieties of lasers and optoelectronics equipment . We suggest that the interaction between these cavities can lead to several interesting phenomena such as : ( i ) creating of hybridized modes , ( ii ) creation of sharp peaks in emission spectrum at speeds related to avoided crossings of cavity eigenmodes , ( iii ) enhancement of spontaneous emission speed due to Purcell phenomenon , and ( iv ) weak relaxation of optical loss properties by means of mode rivalry interactions .These features offer up possibilities for constructing new types of laser sources focused on photonic compounds , particularly single - mode lasers active at room temperature without any external feedback components . The proposed approach is depicted using examples of photonic atoms consisting of pairs of semiconductor microdisks with slightly different diameters .It is demonstrated that the considered spaces allow one to obtain high quality factor whispering gallery modes with Q - parameters exceeding 10 ^ 6 .",
        "rewrite_text": "We propose the use of photonic compounds, which are formed by two or more coupled microcavities with different resonant wavelengths, as foundational elements for innovative types of lasers and optoelectronic devices. We believe that the interactions between these cavities can lead to several intriguing phenomena, including: (i) the formation of hybridized modes, (ii) the emergence of sharp peaks in the emission spectrum related to the avoided crossings of cavity eigenmodes, (iii) an increase in the speed of spontaneous emission due to the Purcell effect, and (iv) a slight relaxation of optical loss characteristics through mode competition interactions. These attributes present opportunities for the development of new laser sources centered on photonic compounds, particularly room-temperature single-mode lasers that do not require external feedback components. We illustrate this approach using examples of photonic atoms made up of pairs of semiconductor microdisks with slightly differing diameters. Our analysis shows that these configurations can achieve high-quality factor whispering gallery modes with Q factors exceeding 10^6.",
        "ori-fast-z-score": 0.8626621856275073,
        "water-fast-z-score": 6.685631938613182,
        "rewrite-fast-z-score": 1.9877674693472376
    },
    {
        "original_text": "We present results obtained with FORS1 (FOcal Reducer and low dispersion Spectrograph) mounted on the Very Large Telescope in Chile, for two bright stars observed over several nights during the period September-October 2002. The main goal is to test the performance of this instrument under conditions similar to those expected when it will be used as part of Gaia space mission. We have measured positions accurate to better than 0.3 mas using an iterative procedure based on the method developed by Gieren et al. (1998) . This accuracy has been reached thanks to the use of reference images taken every night before or after each science exposure. These observations are also useful to calibrate the zero point of the proper motions derived from Hipparcos data. They show that the mean parallax of these two stars agrees within 1 sigma with their Hipparcos values.  Keywords: Astrometry, Gaia",
        "watermark_text": "We report findings obtained with FORS1 ( FOcal Reducer and low dispersion Spectrograph ) installed on the Very Large Telescope in Chile , for two bright stars observed over numerous weeks during the period September - October 2002 . The main goal is to test the performance of this instrument under environments similar to those expected when it will be used as member of Gaia spacecraft mission .We have recorded places accurate to well than 0 . 3 mas using an iterative technique based on the method developed by Gieren et al . ( 1998 ) .This accuracy has been achieved thanks to the using of reference images took every night before or after each science exposure . These measurements are also useful to calibrate the zero position of the proper motions obtained from Hipparcos results .They show that the mean parallax of these two stars agrees within 1 sigma with their Hipparcos values . Keywords : Astrometry , Gaia",
        "rewrite_text": "We present findings from observations conducted with the FOcal Reducer and low dispersion Spectrograph (FORS1) aboard the Very Large Telescope in Chile. These observations, which took place over several weeks in September and October 2002, focused on two bright stars. The primary objective was to assess the instrument's performance in environments similar to those anticipated during the Gaia spacecraft mission. Utilizing an iterative technique based on the method developed by Gieren et al. (1998), we achieved position measurements accurate to better than 0.3 milliarcseconds. This precision was made possible by acquiring reference images each night before or after the science exposures. These measurements also help calibrate the baseline for proper motions derived from Hipparcos data. Our results indicate that the mean parallax of the two stars aligns with their Hipparcos values within 1 sigma. Keywords: Astrometry, Gaia.",
        "ori-fast-z-score": -0.13245323570650439,
        "water-fast-z-score": 5.077963596336064,
        "rewrite-fast-z-score": 0.9615239476408232
    },
    {
        "original_text": "We report on the impedance spectroscopic study of epitaxially grown BiFeO3 (BFO) and BaTiO3 (BT) thin films with different thicknesses, deposited by pulsed laser deposition technique onto single crystal SrTiO3 substrates. The dielectric properties are investigated in the temperature range between 300 K to 450 K at various frequencies ranging from 1 kHz to 10 MHz. It is found that both BFO and BT show ferroelectric behavior as evidenced by their frequency dependent hysteresis loops. In addition, we observe an anomaly near 420 K for all samples which can be attributed to the phase transition from rhombohedral to tetragonal structure in BFO film. \n \n We also find that the dielectric constant decreases with increasing measurement frequency while it increases with decreasing sample thickness. This observation suggests that there exists space charge polarization in these films. Moreover, the dielectric loss shows strong dependence on the measurement frequency and sample thickness.",
        "watermark_text": "We report on the impedance spectroscopic study of epitaxially grown BiFeO3 ( BFO ) and BaTiO3 ( BT ) thin sheets with various thicknesses , deposited by pulsed laser precipitation technique onto single crystal SrTiO3 substrates . The dielectric characteristics are examined in the temperature range between 300 K to 450 K at several frequencies ranging from 1 kHz to 10 MHz .It is found that both BFO and BT exhibit ferroelectric activity as demonstrated by their rate dependent hysteresis loops . In addition , we study an anomaly near 420 K for all specimens which can be due to the phase shift from rhombohedral to tetragonal shape in BFO glass .We also find that the dielectric constant decreases with expanding test frequency while it rises with varying specimen length . This prediction suggests that there exists space charge polarization in these films .Moreover , the dielectric loss displays strong dependence on the sample rate and sample thickness .",
        "rewrite_text": "We present an impedance spectroscopic analysis of epitaxially grown thin films of BiFeO3 (BFO) and BaTiO3 (BT) with varying thicknesses, which were deposited onto single crystal SrTiO3 substrates using a pulsed laser deposition technique. The dielectric properties were investigated over a temperature range of 300 K to 450 K and at frequencies from 1 kHz to 10 MHz. Both BFO and BT demonstrate ferroelectric behavior, evidenced by their frequency-dependent hysteresis loops. Additionally, we observe an anomaly around 420 K in all samples, which may indicate a phase transition from rhombohedral to tetragonal in the BFO material. Our findings reveal that the dielectric constant decreases with increasing frequency, while it increases with longer sample lengths, suggesting the presence of space charge polarization in these films. Furthermore, the dielectric loss exhibits a strong dependence on both the frequency and thickness of the samples.",
        "ori-fast-z-score": -2.54000254000381,
        "water-fast-z-score": 4.157609203101499,
        "rewrite-fast-z-score": -2.626128657194451
    },
    {
        "original_text": "We measure the baryonic acoustic oscillation (BAO) scale in the distribution of galaxies by cross-correlating the Sloan Digital Sky Survey Data Release 5 with the Two Degree Field Galaxy Redshift Survey Data Release 3, both at z=0.35-0.55. We use two different estimators for the BAO peak position, one based on the correlation function and another on the power spectrum. The results are consistent within errors between these methods as well as with previous measurements made over smaller ranges of redshift or volume. Our measurement is also consistent with theoretical predictions based on WMAP1 cosmological parameters. This work demonstrates that it will be possible to make precise distance measurements out to redshifts of order unity using future large galaxy surveys such as the Dark Energy Spectroscopic Instrument. These distances can then be used to constrain dark energy models through their effect on the expansion history of the universe. \n \n Keywords: Baryons",
        "watermark_text": "We estimate the baryonic sound oscillation ( BAO ) scale in the distribution of galaxies by inter - correlating the Sloan Digital Sky Survey Data Release 5 with the Two Degree Field Galaxy Redshift Survey Data Release 3 , both at z = 0 . 35 - 0 . 55 . We use two different estimators for the BAO peak point , one based on the interaction function and another on the power spectrum .The results are compatible within errors between these models as well as with previous measurements made over smaller ranges of redshift or volume . Our measurement is also consistent with theoretical estimates based on WMAP1 cosmological factors .This research shows that it will be possible to make accurate distance measurements out to redshifts of order unity utilizing upcoming huge galaxy surveys such as the Dark Energy Spectroscopic Instrument . These ranges can then be used to constrain dark energy models through their effect on the evolution period of the universe .Keywords: Baryons",
        "rewrite_text": "We assess the baryonic acoustic oscillation (BAO) scale in galaxy distribution by cross-correlating the Sloan Digital Sky Survey Data Release 5 with the Two Degree Field Galaxy Redshift Survey Data Release 3, focusing on the redshift range of z = 0.35 to 0.55. We employ two distinct estimators for identifying the BAO peak: one that utilizes the interaction function and another grounded in the power spectrum. The results from both models are consistent within the measurement errors, aligning with earlier findings gathered across narrower redshift ranges or volumes. Our measurement also agrees with theoretical estimates derived from WMAP1 cosmological parameters. This study indicates that upcoming large-scale galaxy surveys, such as the Dark Energy Spectroscopic Instrument, could enable precise distance measurements up to redshifts near unity. These measurements can subsequently help constrain dark energy models by examining their impact on the universe's evolution. Keywords: Baryons",
        "ori-fast-z-score": 0.2672612419124244,
        "water-fast-z-score": 5.077963596336064,
        "rewrite-fast-z-score": 0.12803687993289598
    },
    {
        "original_text": "We consider a model for an enzymatic reaction network with multiple futile cycles, where each enzyme is assumed to be present at constant concentration and all reactions are reversible. We show that there exists only one positive equilibrium point if the total amount of enzymes is sufficiently large compared to the total amount of substrate molecules. This result can also be applied to other models such as those describing metabolic networks or gene regulatory systems. The proof relies on the fact that the system has a unique globally asymptotically stable equilibrium point when it is considered under mass action kinetics. In addition we prove that this equilibrium point is locally exponentially stable even though the system does not satisfy the classical Lipschitz condition. Finally, numerical simulations illustrate our results. Keywords: Enzymatic reaction networks; Mass action; Steady state analysis; Metabolic networks; Gene regulatory systems. 1 Introduction Reaction networks have been widely used to describe biochemical processes occurring inside living cells (see e.g.,  1  ,  4  ). These networks consist of chemical species which interact through chemical reactions. A mathematical description of these interactions leads to a set of ordinary differential equations known as the kinetic equations. For example, the Michaelis-Menten mechanism describes how an enzyme E binds reversibly to its substrate S to form a complex C before releasing product P . It consists of three elementary reactions given by \nwhere k + i and k − i denote respectively the forward and backward rate constants associated with the ith reaction. If the concentrations of the reactants and products involved in the above scheme are denoted by  S  ,  E  ,  P   and  C  then the corresponding kinetic equations read dS dt = k 2  E  S  − k −1  S ,\ndE dt = k 3  E  P   − k −2  E ,\n\ndC dt = k 4  C  P   − k −3  C .\n\nThe parameters k i represent the rates of the different reactions. Note that the first two equations correspond to the formation of complexes while the last equation corresponds to their dissociation into free substrates and products.",
        "watermark_text": "We consider a theory for an enzymatic process network with many futile periods , where each enzyme is expected to be found at fixed concentration and all processes are reversible . We see that there exists only one favorable equilibrium point if the total quantity of proteins is sufficiently huge compared to the total quantity of substrate molecules .This result can also be applied to other models such as those describing metabolic networks or gene regulatory processes . The proof based on the fact that the process has a unique globally asymptotically stable equilibrium point when it is regarded under mass activity kinetics .In addition we prove that this equilibrium point is locally exponentially steady even though the model does not satisfy the standard Lipschitz requirement . Finally , numerical simulations exhibit our findings .Keywords : Enzymatic process networks ; Mass response ; Steady state analysis ; Metabolic systems ; Gene regulatory structures . 1 Introduction Reaction networks have been widely using to define biochemical reactions appearing inside live cells ( see e . g . , 1 , 4 ) .These systems consist of chemical species which interact through chemical processes . A mathematical description of these interactions leads to a setting of simple differential equations known as the kinetic equations .For instance , the Michaelis - Menten process represents how an enzyme E connects reversibly to its substrate S to form a complex C before producing product P . It consists of three elementary reactions given by where k + i and k − i describe respectively the forward and back rate constants associated with the ith reaction .If the levels of the reactants and products participating in the above scheme are denoted by S , E , P and C then the associated kinetic equations read dS dt = k 2 E S − k −1 S , dE dt = k 3 E P − k −2 E , dC dt = k 4 C P − k −3 C . The parameters k i describe the rates of the different processes .Note that the first two expressions correspond to the formation of complexes while the last equation relates to their dissociation into free substrates and products .",
        "rewrite_text": "We investigate a theoretical model of an enzymatic process network characterized by multiple futile cycles, where each enzyme is maintained at a constant concentration and all reactions are reversible. Our analysis reveals that there is a single favorable equilibrium point when the total amount of proteins is significantly larger than the total number of substrate molecules. This finding is applicable to various models, including those that describe metabolic networks and gene regulatory processes. The proof hinges on the existence of a unique globally asymptotically stable equilibrium when the system is viewed through the lens of mass action kinetics. Furthermore, we demonstrate that this equilibrium point exhibits local exponential stability, even in the absence of the standard Lipschitz condition. Additionally, numerical simulations support our conclusions. Key terms include: enzymatic process networks, mass response, steady state analysis, metabolic systems, and gene regulatory structures.\n\n**1 Introduction**  \nReaction networks are extensively employed to model biochemical reactions occurring within living cells (see, for example, references 1 and 4). These systems consist of various chemical species that interact through chemical reactions. A mathematical representation of these interactions results in a set of ordinary differential equations known as kinetic equations. As an illustration, the Michaelis-Menten process describes how an enzyme (E) reversibly binds to its substrate (S) to form a complex (C) before yielding the product (P). This process encompasses three elementary reactions, where \\( k_{+i} \\) and \\( k_{-i} \\) represent the forward and reverse rate constants for the i-th reaction, respectively. If we denote the concentrations of the reactants and products as S, E, P, and C, the corresponding kinetic equations take the form:\n\n\\[\n\\frac{dS}{dt} = k_2 E S - k_{-1} S,\n\\]\n\\[\n\\frac{dE}{dt} = k_3 E P - k_{-2} E,\n\\]\n\\[\n\\frac{dC}{dt} = k_4 C P - k_{-3} C.\n\\]\n\nThe parameters \\( k_i \\) describe the reaction rates for the various processes. The first two equations depict the formation of complexes, while the last equation pertains to their dissociation into free substrates and products.",
        "ori-fast-z-score": -1.697749375254331,
        "water-fast-z-score": 7.469939758793239,
        "rewrite-fast-z-score": 0.5551361100027009
    },
    {
        "original_text": "We present an evolutionary model that describes the emergence of genes, species and their interactions in terms of physical principles. The model is based on the concept of self-assembly as it occurs during the formation of biological macromolecules such as proteins or nucleic acids. We show how this process leads to the spontaneous appearance of functional units which we call  gene families . Gene families are defined by common sequence motifs and can be seen as building blocks for more complex organisms. In our approach, these building blocks evolve into new species through mutations and selection processes. Species interact with each other via chemical reactions mediated by enzymes. These interactions lead to the formation of metabolic networks whose structure reflects the underlying network topology of the interacting species. Finally, we demonstrate how the proposed model reproduces several important features observed in real-world systems including preferential attachment, scale-free degree distributions and small world properties. Our results suggest that the basic mechanisms driving the evolution of life may have been already established at its very beginning.",
        "watermark_text": "We see an evolutionary model that describes the emergence of genes , species and their interactions in terms of physical principles . The model is based on the idea of self - assembly as it happened during the formation of biological macromolecules such as proteins or nucleic acids .We see how this process results to the spontaneous appearance of functional units which we call gene families . Gene groups are established by common sequence motifs and can be saw as building blocks for more sophisticated organisms .In our approach , these building blocks develop into new taxa through mutations and selection pathways . Species interact with each other via molecular mechanisms facilitated by enzymes .These interactions result to the formation of genetic systems whose shape represents the fundamental network topology of the interacting species . Finally , we prove how the suggested model reproduces many important features found in real - time systems including preferential attachment , size - free degree distributions and tiny universe characteristics .Our results propose that the fundamental pathways governing the evolution of life might have been still developed at its very beginning .",
        "rewrite_text": "We propose an evolutionary model that explains the emergence of genes, species, and their interactions through the lens of physical principles. This model is grounded in the concept of self-assembly, akin to the processes that occur during the formation of biological macromolecules such as proteins and nucleic acids. As a result, we observe the spontaneous emergence of functional units, which we refer to as gene families. These gene groups, defined by common sequence motifs, serve as the foundational elements for more complex organisms. In our framework, these foundational blocks evolve into new taxa through processes of mutation and selective pathways. Species interact with one another through molecular mechanisms, with enzymes facilitating these connections. These interactions lead to the development of genetic systems, whose structure mirrors the fundamental network topology of the interacting species. Ultimately, we demonstrate that our proposed model captures many significant characteristics observed in real-world systems, such as preferential attachment, scale-free degree distributions, and tiny universe properties. Our findings suggest that the essential pathways driving the evolution of life may have been established right from the very beginning.",
        "ori-fast-z-score": 1.3065491598369756,
        "water-fast-z-score": 7.879189847507244,
        "rewrite-fast-z-score": 1.2
    },
    {
        "original_text": "We report on the rapid diffusion of dipolar order in liquid crystals, which is responsible for an enhanced nuclear spin-lattice relaxation rate and thus for a higher degree of dynamic nuclear polarization (DNP). The DNP effect was studied by means of electron paramagnetic resonance spectroscopy at X-band frequencies using a home-built high-field spectrometer equipped with a commercial microwave bridge operating at 2.5 GHz. We found that the enhancement factor increases strongly when approaching the nematic-isotropic phase transition temperature TNI = 35 °C. This finding can be explained by assuming that the molecular mobility decreases rapidly as TNI is approached. In addition to this observation we find that the maximum achievable enhancement factor depends critically on the sample geometry. For samples having a thickness d < 1 mm it reaches values up to 100 times larger than those observed for thicker samples. These results are important for future applications of DNP in NMR experiments performed under extreme conditions such as low temperatures or strong magnetic fields.",
        "watermark_text": "We report on the quick diffusion of dipolar order in liquid crystals , which is responsible for an accelerated nuclear spin - structure contraction speed and therefore for a higher degree of dynamic nuclear polarization ( DNP ) . The DNP phenomenon was studied by means of electron paramagnetic resonance spectroscopy at X - band frequencies using a home - made low - field spectrometer equipped with a commercial microwave bridge operating at 2 . 5 GHz .We showed that the enhancement element increases strongly when approaching the nematic - isotropic phase change temperature TNI = 35 °C . This found can be described by assuming that the molecular density decreases quickly as TNI is neared .In addition to this observation we find that the maximum achievable enhancement coefficient varies critically on the sample geometry . For specimens having a diameter d < 1 mm it hits values up to 100 times bigger than those observed for thicker specimen .These data are important for future applications of DNP in NMR experiments conducted under extreme circumstances such as low temperatures or strong magnetic fields .",
        "rewrite_text": "We discuss the rapid propagation of dipolar order in liquid crystals, which leads to an increased speed of nuclear spin-structure contraction and subsequently enhances dynamic nuclear polarization (DNP). The DNP effect was investigated using electron paramagnetic resonance spectroscopy at X-band frequencies with a custom low-field spectrometer paired with a commercial microwave bridge operating at 2.5 GHz. Our findings reveal a significant increase in the enhancement factor as the system approaches the nematic-isotropic phase transition temperature, TNI = 35 °C. This behavior can be explained by the rapid decrease in molecular density near TNI. Furthermore, we discovered that the maximum achievable enhancement coefficient varies significantly with the geometry of the samples; specimens with a diameter less than 1 mm can exhibit enhancements up to 100 times greater than those of thicker samples. These results are crucial for future applications of DNP in NMR experiments conducted under extreme conditions, such as low temperatures or strong magnetic fields.",
        "ori-fast-z-score": 0.2182178902359924,
        "water-fast-z-score": 6.32831881684378,
        "rewrite-fast-z-score": 0.3418817293789138
    },
    {
        "original_text": "We present an algorithm that determines whether or not there exists a quantum circuit with a given number of qubits and gates, such that the corresponding time-independent Hamiltonian is realizable by a physical system in which each energy level has at most one excited state.  We also show how to find all possible circuits if they exist. Our results are based on recent work showing that any time-independent Hamiltonian can be written as a sum of commuting projectors onto its eigenstates. This decomposition allows us to reduce the problem of finding a realization of a general time-independent Hamiltonian into several instances of the same problem but restricted to smaller Hilbert spaces. The reduction yields a polynomial-time algorithm when applied recursively. Finally we discuss some applications of our method including determining the minimum depth required for universal adiabatic quantum computers. In this article we consider the following problem: \nGiven a set of n qubits and m two-qubit gates, does there exist a quantum circuit consisting only of these gates whose associated time-independent Hamiltonian is realizable; i.e., it corresponds to a Hermitian operator acting on a finite-dimensional Hilbert space? If so, what is the smallest circuit size needed?\nThe answer to this question will depend on the specifics of the model used to describe the physical system under consideration. For example, in the case where each energy level may have more than one excited state (i.e., degenerate), then no circuit can realize the desired Hamiltonian unless it contains infinitely many gates. On the other hand, if each energy level has exactly one excited state (i..",
        "watermark_text": "We present an algorithm that decide whether or not there exists a quantum circuit with a given number of qubits and gates , such that the associated time - independent Hamiltonian is realizable by a physical system in which each energy level has at most one excited state . We also study how to find all possible circuits if they exist .Our results are based on current work showing that any time - independent Hamiltonian can be written as a sum of commuting projectors onto its eigenstates . This decomposition allows us to reduce the question of finding a realization of a general time - independent Hamiltonian into numerous instances of the same problem but restricted to smaller Hilbert spaces .The reduction gives a polynomial - time algorithm when applied recursively . Finally we explain some applications of our technique including calculating the minimum depth needed for universal adiabatic quantum computers .In this article we investigate the following issue : Given a setting of n qubits and m two - qubit gates , does there exist a quantum circuit consisting only of these gates whose associated time - independent Hamiltonian is realizable ; i . e . , it corresponds to a Hermitian operator acting on a finite - dimensional Hilbert space ? If so , what is the smallest circuit length needed ?The answer to this question will depend on the specifics of the model used to explain the physical system under consideration . For instance , in the case where each energy level may have more than one excited state ( i . e . , degenerate ) , then no circuit can realize the desired Hamiltonian unless it contains infinitely many gates .On the other hand , if each energy level has precisely one excited state ( i . .",
        "rewrite_text": "We introduce an algorithm designed to determine whether a quantum circuit with a specified number of qubits and gates can be constructed such that its corresponding time-independent Hamiltonian can be realized by a physical system in which every energy level possesses at most one excited state. Additionally, we explore methods to identify all potential circuits, if they are feasible. Our findings build on recent research demonstrating that any time-independent Hamiltonian can be expressed as a sum of commuting projectors onto its eigenstates. This decomposition simplifies the process of finding a realization of a general time-independent Hamiltonian into multiple instances of the same problem, but within smaller Hilbert spaces. This reduction leads to a polynomial-time algorithm when applied recursively. We also discuss various applications of our method, including the calculation of the minimum depth required for universal adiabatic quantum computers. Specifically, in this article, we examine the following question: given n qubits and m two-qubit gates, is it possible to construct a quantum circuit using only these gates, such that its associated time-independent Hamiltonian is realizable? In other words, does it correspond to a Hermitian operator operating on a finite-dimensional Hilbert space? If it is indeed possible, what is the minimum circuit length necessary? The answer to this query will vary depending on the specifics of the model representing the physical system in question. For example, if each energy level can have multiple excited states (i.e., is degenerate), then a circuit cannot realize the desired Hamiltonian unless it contains an infinite number of gates. Conversely, when each energy level has exactly one excited state...",
        "ori-fast-z-score": 2.3539293971054818,
        "water-fast-z-score": 6.024948132556827,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "We present new results on viscous torque and dissipation in thin accretion disks, focusing on their implications for measuring black hole spin using continuum-fitting techniques. We find that the magnitude of the viscous torque is strongly dependent upon the radial location at which it is evaluated; this dependence arises because the disk s surface density profile varies with radius. The net effect is to produce an apparent warp in the inner region of the disk (r < 10 GM/c2), where the observed flux depends sensitively on the viewing angle. This warp can be misinterpreted as evidence for retrograde precession if one assumes that the disk is axisymmetric. In addition, we show that the total energy dissipated within r = 3 GM/c2 may exceed the value inferred by fitting the spectrum with a standard Shakura-Sunyaev model. These effects are particularly important when attempting to measure the spins of supermassive black holes in AGN.",
        "watermark_text": "We report new data on viscous torque and dissipation in narrow accretion disks , concentrating on their implications for determining black hole momentum using continuum - fitting methods . We see that the severity of the viscous torque is strongly dependent upon the transverse location at which it is evaluated ; this dependence occurs because the disk s surface temperature profile vary with diameter .The net effect is to produce an apparent warp in the inner region of the disk ( r < 10 GM / c2 ) , where the seen flux relies sensitively on the sight position . This warp can be misinterpreted as proof for retrograde precession if one assumes that the disk is axisymmetric .In addition , we prove that the total energy emitted within r = 3 GM / c2 might reach the value inferred by fitting the spectrum with a traditional Shakura - Sunyaev formula . These effects are particularly important when trying to measure the spins of supermassive black holes in AGN .",
        "rewrite_text": "We present new findings on viscous torque and energy dissipation in narrow accretion disks, emphasizing their significance for estimating black hole momentum through continuum-fitting techniques. Our results indicate that the intensity of viscous torque is highly influenced by the specific transverse location where it is measured, which is due to the variation in the disk's surface temperature profile across its diameter. This leads to an apparent warp in the inner region of the disk (r < 10 GM / c²), where the observed flux is sensitive to the observer's angle. If one assumes the disk is axisymmetric, this warp may be incorrectly interpreted as evidence of retrograde precession. Additionally, we demonstrate that the total energy emitted within r = 3 GM / c² could align with values obtained by fitting the spectrum using a conventional Shakura-Sunyaev model. These findings are particularly crucial for determining the spins of supermassive black holes in active galactic nuclei (AGN).",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.986302773458956,
        "rewrite-fast-z-score": 1.3242443839434612
    },
    {
        "original_text": "We present the results of our analysis of a sample of 25 high-resolution quasar absorption line systems with metallicities ranging between 1/100 and 1/10 solar, selected to have low dust content (i.e., < 0.1 mag extinction at 2200 A). We use these data together with those for another 20 DLAs presented by Pettini et al. (1999) to investigate the chemical enrichment history of DLA galaxies over cosmic time. The main conclusions are as follows: \nThe abundance patterns observed in this sample can be explained if we assume that most of the metals were produced during an early burst of star formation which occurred less than 10 Gyr ago. \n\n\nThis is consistent with previous studies based on smaller samples but it also shows that there may not always be evidence for recent star formation activity even when such activity has been inferred from other indicators. \n\nIn addition, we find no correlation between metallicity and dust content or neutral hydrogen column density.\n\nFinally, we show that the mean value of  Fe/H  measured in DLAs agrees well with the predictions made using simple models of galactic chemical evolution.",
        "watermark_text": "We publish the conclusion of our analysis of a sample of 25 high - resolution quasar absorbed line systems with metallicities ranging between 1 / 100 and 1 / 10 solar , selected to have lowest dust content ( i . e . , < 0 . 1 mag extinction at 2200 A ) . We use these results together with those for another 20 DLAs given by Pettini et al .( 1999 ) to examine the chemical enrichment history of DLA galaxies over cosmic time . The main results are as follows : The concentration trends experienced in this specimen can be described if we suppose that most of the metals were produced during an early burst of galaxy formation which occurred less than 10 Gyr ago .This is consistent with previous analyses based on smaller specimens but it also shows that there may not always be confirmation for recent star formation activity even when such activity has been inferred from other indicators . In addition , we find no correlation between metallicity and dust content or neutral hydrogen column density .Finally , we prove that the mean value of Fe / H measured in DLAs agrees well with the assumptions done using simple theories of galactic material evolution .",
        "rewrite_text": "We present our analysis of a sample of 25 high-resolution quasar absorption line systems, which have metallicities ranging from 1/100 to 1/10 solar and were selected for their low dust content (i.e., less than 0.1 mag extinction at 2200 Å). By combining these findings with data from another 20 damped Lyman-alpha (DLA) systems reported by Pettini et al. (1999), we investigate the chemical enrichment history of DLA galaxies throughout cosmic time. Our key findings are as follows: The concentration trends observed in our sample suggest that most metals were formed during an early phase of galaxy formation occurring less than 10 billion years ago. This aligns with previous studies based on smaller samples, yet it also highlights that indications of recent star formation activity may not always be corroborated by our findings. Additionally, we observed no correlation between metallicity and either dust content or neutral hydrogen column density. Lastly, our measurements of the mean Fe/H ratio in DLAs show strong agreement with predictions from basic models of galactic material evolution.",
        "ori-fast-z-score": 1.078327732034384,
        "water-fast-z-score": 6.11104144857543,
        "rewrite-fast-z-score": 1.4269353798659745
    },
    {
        "original_text": "We present an analysis of anisotropies in satellite galaxy locations around isolated galaxies, using data from the Sloan Digital Sky Survey (SDSS). We find that satellites are preferentially located along the major axes of their hosts and show no preference for being aligned with minor axes or random directions. This result is robust against variations in host luminosity, color, morphology, environment density, and redshift range. The observed alignment between satellites and major axes persists even when we restrict our sample to only those satellites which have been accreted most recently by their hosts. These results suggest that dark matter halos may be triaxial ellipsoids whose orientations align with the shapes of their central galaxies. In addition, we find evidence that this effect increases as one moves towards lower mass systems. Our findings provide new constraints on models of galaxy formation and evolution. Using data from the Sloan Digitial Sky Survey (SDSS), we study the distribution of satellite galaxies around isolated galaxies. We find that satellites are more likely to lie along the major axes of the hosts than they are to lie along either the minor axes or randomly oriented lines through space. This result holds true over a wide variety of host properties including luminosity, color, morphological type, local environmental density, and redshift range. \n \n Figure 1: An example of how we define the orientation of each host s halo relative to its position angle. Here, the blue line shows the projected major axis of the host while the red dashed line indicates the direction perpendicular to it.",
        "watermark_text": "We present an assessment of anisotropies in satellite galaxy locations around distant galaxies , using data from the Sloan Digital Sky Survey ( SDSS ) . We see that satellites are preferentially found along the main axes of their hosts and take no preference for being aligned with minor axes or random directions .This result is robust against variations in host luminosity , color , structure , environment density , and redshift range . The observed orientation between satellites and major axes persists even when we limit our sample to only those satellites which have been accreted most recently by their hosts .These data suggest that dark matter halos may be triaxial ellipsoids whose orientations align with the shapes of their central galaxies . In addition , we find proof that this effect grows as one moves approaching lower weight regions .Our findings provide novel constraints on estimates of galaxy formation and evolution . Using evidence from the Sloan Digitial Sky Survey ( SDSS ) , we study the spread of satellite galaxies around isolated stars .We see that satellites are more likely to lying along the main axes of the hosts than they are to lying along either the minor axes or randomly oriented lines through space . This result holds true over a broad variety of host characteristics including luminosity , color , morphological type , local environmental density , and redshift range .Figure 1 : An illustration of how we define the orientation of each host s halo compared to its position angle . Here , the blue line displays the projected major axis of the host while the red dashed line indicates the direction perpendicular to it .",
        "rewrite_text": "We present an evaluation of the anisotropies in the distribution of satellite galaxies surrounding distant galaxies, utilizing data from the Sloan Digital Sky Survey (SDSS). Our findings reveal that satellites tend to cluster along the primary axes of their host galaxies, showing no preference for alignment with the minor axes or for random orientations. This conclusion is robust across various factors, including host luminosity, color, structure, environmental density, and redshift range. Notably, the observed alignment between satellites and the major axes persists even when we focus exclusively on satellites that have been recently accreted by their hosts. These results imply that dark matter halos may have triaxial ellipsoidal shapes that align with the morphology of their central galaxies. Additionally, we observe that this alignment effect increases as we move toward regions of lower mass. Our discoveries provide new constraints on models of galaxy formation and evolution. Using evidence from the Sloan Digital Sky Survey (SDSS), we investigate the arrangement of satellite galaxies around isolated stars. We find that satellites are more frequently positioned along the main axes of their hosts compared to either the minor axes or random orientations in space. This pattern remains consistent across a wide range of host characteristics, including luminosity, color, morphological type, local environmental density, and redshift range. Figure 1 illustrates our method for defining the orientation of each host's halo in relation to its position angle, with the blue line representing the projected major axis of the host and the red dashed line indicating the direction perpendicular to that axis.",
        "ori-fast-z-score": -0.4472135954999579,
        "water-fast-z-score": 5.412874707438294,
        "rewrite-fast-z-score": -1.2374368670764582
    },
    {
        "original_text": "We have performed first-principles calculations to investigate the potassium intercalation into graphite using the vdW-DF method with optB86b functional and found that K atoms preferentially occupy the hollow sites between two neighboring carbon layers, which is consistent with previous experimental results.  The calculated binding energy for one K atom on top site (0.25 eV) is much smaller than those at bridge or hollow sites (1.27-1.33 eV). We also find that the charge transfer from K to C layer is negligible when K occupies the hollow sites. In addition, we show that the electronic structure near Fermi level can be tuned by changing the number of K atoms inserted into the system. Finally, our calculation shows that the phonon spectrum remains stable after inserting K atoms into the system. Graphite has been widely used as an anode material in lithium ion batteries due to its high theoretical capacity  1  . However, it suffers from low electrical conductivity  2  , leading to poor rate capability  3  .\nRecently, potassium ions are considered as promising candidates to replace Li + because they possess higher ionic mobility  4  . It was reported that the insertion voltage of K + /K is 0.3 V lower than that of Li-ion/Li  5  . Moreover, the diffusion coefficient of K + is about three orders of magnitude larger than that of Li +  6  . Therefore, the use of K + may lead to improved performance over conventional Li-ion batteries  7, 8  .",
        "watermark_text": "We have done first - principles experiments to examine the potassium intercalation into graphite using the vdW - DF method with optB86b functional and found that K atoms preferentially inhabit the hollow regions between two adjacent carbon strands , which is compatible with previous experimental studies . The measured activation energy for one K element on top site ( 0 . 25 eV ) is much smaller than those at bridge or hollow areas ( 1 . 27 - 1 . 33 eV ) .We additionally find that the charge transfer from K to C surface is negligible when K occupies the hollow areas . In addition , we find that the electronic configuration near Fermi level can be tuned by varying the quantity of K atoms introduced into the system .Finally , our analysis shows that the phonon spectrum stays stable after inserting K atoms into the system . Graphite has been widely useful as an anode material in lithium ion devices owing to its high theoretical capacity 1 .However , it suffers from reduced electrical conductivity 2 , leading to bad rate capability 3 . Recently , potassium complexes are considered as hopeful candidates to eliminate Li + because they possess larger ionic mobility 4 .It was reported that the insertion voltage of K + / K is 0 . 3 V lower than that of Li - ion / Li 5 . Moreover , the diffusion coefficient of K + is about three orders of magnitude greater than that of Li + 6 .Therefore , the using of K + may contribute to greater performance over traditional Li - ion batteries 7 , 8 .",
        "rewrite_text": "We conducted first-principles experiments to investigate the intercalation of potassium into graphite, employing the van der Waals density functional (vdW-DF) method with the optB86b functional. Our findings indicate that K atoms preferentially occupy the hollow sites between adjacent carbon layers, aligning with previous experimental observations. The activation energy for a K atom positioned at the top site is measured at 0.25 eV, which is significantly lower than the values observed for bridge or hollow sites (ranging from 1.27 to 1.33 eV). Furthermore, we found that the charge transfer from K to the carbon surface is negligible when K resides in the hollow sites. Additionally, we discovered that the electronic configuration near the Fermi level can be adjusted by changing the number of K atoms in the system. Our analysis also reveals that the phonon spectrum remains stable after the introduction of K atoms. Graphite has long been a popular choice for anode material in lithium-ion devices due to its high theoretical capacity. However, it suffers from decreased electrical conductivity, which affects its rate capability. Recently, potassium complexes have emerged as promising alternatives to lithium, as they exhibit greater ionic mobility. It has been reported that the insertion voltage for K+/K is 0.3 V lower than that for Li+/Li. Moreover, the diffusion coefficient of K+ is approximately three orders of magnitude higher than that of Li+. Consequently, the use of K+ could potentially enhance the performance of traditional lithium-ion batteries.",
        "ori-fast-z-score": 0.6897304947150052,
        "water-fast-z-score": 7.770286898858113,
        "rewrite-fast-z-score": 1.5255401427929478
    },
    {
        "original_text": "We present the fundamental plane (FP) for galaxy clusters detected in the Planck survey at 143 GHz, based on their X-ray luminosity Lx , temperature Tx and SZ flux Y500 . The FP is defined as log(Y500 ) = α + βlog(Tx /Lx ), where we find that the best-fit values are  α = 0.92 ± 0.01 and β = 1.27 ± 0.02 with an intrinsic scatter of σint = 0.10 ± 0.03 dex.  We compare our results to previous studies using different cluster samples and methods. Our sample consists of 31 massive clusters selected by applying cuts in mass M500 > 5 × 1014 h−1 70 M⊙ and redshift z < 0.3. These clusters have been observed with XMM-Newton and Chandra satellites and also with ground-based telescopes such as APEX-SZ or Bolocam.",
        "watermark_text": "We present the fundamental plane ( FP ) for galaxy galaxies found in the Planck survey at 143 GHz , using on their X - ray luminosity Lx , temperature Tx and SZ flux Y500 . The FP is calculated as log ( Y500 ) = β + βlog ( Tx / Lx ) , where we find that the best - fitting values are α = 0 . 92 ± 0 . 01 and β = 1 . 27 ± 0 . 02 with an intrinsic scatter of σint = 0 . 10 ± 0 . 03 dex .We match our results to previous studies using separate cluster samples and methods . Our sample consists of 31 massive clusters selected by applying cuts in mass M500 > 5 × 1014 h−1 70 [UNK] and redshift z < 0 . 3 .These clusters have been observed with XMM-Newton and Chandra satellites and also with ground-based telescopes such as APEX-SZ or Bolocam.",
        "rewrite_text": "We present the fundamental plane (FP) for galaxies identified in the Planck survey at 143 GHz, based on their X-ray luminosity \\(L_x\\), temperature \\(T_x\\), and SZ flux \\(Y_{500}\\). The FP is defined by the relation \\(\\log(Y_{500}) = \\beta + \\alpha \\log(T_x / L_x)\\), where we determine the best-fitting parameters to be \\(\\alpha = 0.92 \\pm 0.01\\) and \\(\\beta = 1.27 \\pm 0.02\\), with an intrinsic scatter of \\(\\sigma_{\\text{int}} = 0.10 \\pm 0.03\\) dex. We compare our findings with previous research that utilized different cluster samples and methodologies. Our sample comprises 31 massive clusters selected with criteria of \\(M_{500} > 5 \\times 10^{14} h^{-1}_{70}\\) and redshift \\(z < 0.3\\). These clusters have been observed using XMM-Newton and Chandra satellites, as well as ground-based instruments like APEX-SZ and Bolocam.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 2.3094010767585034,
        "rewrite-fast-z-score": -0.7001400420140048
    },
    {
        "original_text": "We present an extensive study on the ground-state phase diagram and low-energy excitations of the two-dimensional (2D) Hubbard model using a recently developed spin- susceptibility representation for the pairing interaction. We show that this approach is able to reproduce all known results at half-filling, including the Mott transition driven by strong electron correlations as well as the d-wave superconducting state induced by attractive interactions between electrons. In addition, we find new phases with charge-density wave order or coexisting antiferromagnetism and d-wave superconductivity away from halffilling. The latter are found to be stable over large regions of parameter space and can thus provide a possible explanation for recent experimental observations in high-temperature cuprate superconductors. \n \n Introduction \n \n One of the most important open questions in condensed matter physics concerns the nature of electronic states near the Fermi level in strongly correlated materials such as high-Tc cuprates  1–3  . While these systems have been studied extensively both experimentally and theoretically during the past decades  4–6  , it remains unclear how their unusual properties emerge from microscopic models  7–9  . A promising route towards answering this question involves studying simplified lattice Hamiltonians which capture some essential features of real materials  10–12  . Among them, the twodimensional (2D) Hubbard Hamiltonian has attracted considerable attention due to its rich physical content  13–18  . It describes interacting fermions hopping on a square lattice subject to local Coulomb repulsion U and chemical potential μ . \n \n Despite intensive efforts  19–22  , however, no consensus exists yet about the exact ground-state phase diagram of the 2D Hubbard model  23  . This problem becomes even more challenging when one considers finite doping levels away from half-filling  24  . Indeed, while various numerical methods  25  suggest the existence of several competing ordered phases  26  , analytical approaches based on weak-coupling perturbation theory  27  fail to predict any ordering phenomena beyond mean-field theory  28  . Moreover, the applicability of standard quantum Monte Carlo techniques  29  is limited to small system sizes  30  because of severe sign problems  31  . As a result, many aspects of the",
        "watermark_text": "We present an extensive research on the ground - state phase diagram and low - energy excitations of the two - dimensional ( 2D ) Hubbard theory employing a recently advanced spin - susceptibility model for the pairing interaction . We see that this methodology is able to capture all known data at half - filling , notably the Mott transition accelerated by weak electron correlations as well as the d - wave superconducting state caused by attractive interactions between electrons .In addition , we find new phases with charge - density wave order or coexisting antiferromagnetism and d - wave superconductivity far from halffilling . The latter are found to be stable over large areas of parameter space and can thus provide a possible explanation for recent experimental discoveries in high - temperature cuprate superconductors .Introduction One of the most important open questions in condensed matter science discusses the nature of electronic states near the Fermi level in highly correlated materials such as high - Tc cuprates 1 – 3 . While these systems have been studied extensively both experimentally and theoretically during the previous decades 4 – 6 , it remains unsure how their strange properties emerge from microscopic studies 7 – 9 .A potential path towards answering this question involves studying simplified lattice Hamiltonians which capture some essential aspects of real objects 10 – 12 . Among them , the twodimensional ( 2D ) Hubbard Hamiltonian has garnered considerable scrutiny due to its vast physical content 13 – 18 .It involves interacting fermions hopping on a square lattice due to native Coulomb repulsion U and chemical potential μ . Despite ongoing attempts 19 – 22 , however , no consensus remains already about the exact ground - state phase diagram of the 2D Hubbard theory 23 .This problem becomes especially more challenging when one considers finite doping rates away from half - filling 24 . Indeed , while several mathematical techniques 25 suggest the existence of several rival ordered phases 26 , analytical approaches focusing on weak - interaction perturbation theory 27 fail to predict any ordering phenomena beyond mean - field principle 28 .Moreover , the applicability of standard quantum Monte Carlo methods 29 is limited to small system sizes 30 because of frequent symbol problems 31 . As a result , various features of the",
        "rewrite_text": "We provide a comprehensive study of the ground-state phase diagram and low-energy excitations of the two-dimensional (2D) Hubbard model, utilizing a recently developed spin-susceptibility framework for pairing interactions. Our analysis demonstrates that this approach effectively accounts for all established data at half-filling, particularly highlighting the Mott transition driven by weak electron correlations and the emergence of a d-wave superconducting state due to attractive electron interactions. Furthermore, we discover new phases characterized by charge-density wave order and coexisting antiferromagnetism with d-wave superconductivity in regions far from half-filling. These phases are found to be stable across extensive areas of the parameter space, offering potential insights into recent experimental findings in high-temperature cuprate superconductors. \n\n**Introduction**: A pivotal open question in condensed matter physics pertains to the nature of electronic states near the Fermi level in highly correlated materials, such as high-Tc cuprates. While extensive experimental and theoretical investigations have been conducted over the past few decades, the origin of the unusual properties of these systems remains uncertain. One promising approach to addressing this question is to analyze simplified lattice Hamiltonians that encapsulate key characteristics of real materials. Among these, the 2D Hubbard Hamiltonian has received significant attention due to its rich physical implications. It describes interacting fermions moving on a square lattice, influenced by inherent Coulomb repulsion and chemical potential. However, despite persistent efforts, there is still no consensus regarding the precise ground-state phase diagram of the 2D Hubbard model. The complexity of this issue increases when considering finite doping levels away from half-filling. Numerous mathematical techniques suggest the presence of competing ordered phases, yet analytical methods relying on weak-interaction perturbation theory struggle to predict ordering phenomena beyond mean-field approximations. Additionally, the conventional application of quantum Monte Carlo methods is often constrained by small system sizes due to recurrent sign problems, complicating the study of various features of the model.",
        "ori-fast-z-score": 0.07392212709545729,
        "water-fast-z-score": 7.613979090832101,
        "rewrite-fast-z-score": 0.29981267559834457
    },
    {
        "original_text": "The measurement of the aerosol phase function is important for understanding cosmic ray showers and their detection by ground-based experiments, such as those performed with the Pierre Auger Observatory (PAO). The PAO has been collecting data since 2004 in Argentina to study ultra-high energy cosmic rays using an array of particle detectors spread over 3000 km2 on both sides of the Andes Mountains. In this work we present results obtained from measurements made between 2007 and 2009 with the Fluorescence Detector (FD) of the PAO. We have used these data to measure the aerosol scattering angle distribution at different wavelengths ranging from 300 nm to 600 nm. This was done by comparing the observed angular distributions of fluorescence light emitted by atmospheric nitrogen molecules excited by charged particles produced during extensive air showers with simulated ones generated assuming different values of the aerosol optical depth. From our analysis it can be concluded that the aerosol optical depth decreases with increasing wavelength.",
        "watermark_text": "The measurement of the aerosol phase integral is important for studying cosmic ray showers and their observation by land - based experiments , such as those conducted with the Pierre Auger Observatory ( PAO ) . The PAO has been collecting data since 2004 in Argentina to study ultra - large energy cosmic rays using an array of particle detectors distributed over 3000 km2 on both sides of the Andes Mountains .In this research we present results acquired from measurements made between 2007 and 2009 with the Fluorescence Detector ( FD ) of the PAO . We have utilized these information to measure the aerosol scattering angle distribution at different wavelengths ranging from 300 nm to 600 nm .This was done by comparing the observed angular distributions of fluorescence light emitted by atmospheric nitrogen molecules excited by charged particles generated during widespread air showers with simulated ones produced taking various values of the aerosol imaging depth . From our analysis it can be determined that the aerosol imaging depth decreases with increasing wavelength .",
        "rewrite_text": "The measurement of the aerosol phase integral is crucial for investigating cosmic ray showers and their detection in ground-based experiments, such as those carried out at the Pierre Auger Observatory (PAO). Since 2004, the PAO has been gathering data in Argentina to examine ultra-high energy cosmic rays through an array of particle detectors spread across 3,000 km² on both sides of the Andes Mountains. In this study, we present findings from measurements taken between 2007 and 2009 using the Fluorescence Detector (FD) of the PAO. We analyzed this data to determine the aerosol scattering angle distribution at various wavelengths ranging from 300 nm to 600 nm. This was achieved by comparing the observed angular distributions of fluorescence light emitted by nitrogen molecules in the atmosphere—excited by charged particles from extensive air showers—with simulated distributions created using different aerosol imaging depths. Our analysis indicates that the aerosol imaging depth decreases as the wavelength increases.",
        "ori-fast-z-score": 0.23570226039551587,
        "water-fast-z-score": 4.949747468305833,
        "rewrite-fast-z-score": 1.5428161556520092
    },
    {
        "original_text": "Charge ordering (CO) is one of the most important phenomena in strongly correlated electron systems, which has been observed in many transition metal oxides such as manganese perovskite compounds. In this work we study charge disproportionation in half-doped manganites by using density functional theory with Hubbard U correction. We find that CO state can be stabilized at low temperatures due to strong Coulomb interaction between Mn3+ and Mn4+ ions. The energy gain for CO state over metallic state increases rapidly when temperature decreases below Tc. Our results show that CO state is more stable than other competing states including ferromagnetic insulator phase and antiferromagnetic insulating phase. \n \n Keywords: Charge-ordering, Density-functional-theory, Correlated electrons, Transition-metal-oxides, Manganites, Energy-band-structure, Insulators, Ferromagnetism, Antiferromagnetism",
        "watermark_text": "Charge ordering ( CO ) is one of the most important phenomena in highly correlated electron structures , which has been observed in many transition metal oxides such as manganese perovskite compounds . In this research we study charge disproportionation in nearly - doped manganites by using density functional theory with Hubbard U relaxation .We see that CO state can be stabilized at low temperatures resulting to powerful Coulomb interaction between Mn3 + and Mn4 + ions . The energy gain for CO state over metallic state increases quickly when temperature falls below Tc .Our results show that CO state is more stable than other participating states including ferromagnetic insulator mode and antiferromagnetic insulating phase . Keywords : Charge - ordering , Density - functional - theory , Correlated atoms , Transition - iron - oxides , Manganites , Energy - band - structure , Insulators , Ferromagnetism , Antiferromagnetism",
        "rewrite_text": "Charge ordering (CO) is a crucial phenomenon in systems with highly correlated electron interactions and has been observed in various transition metal oxides, such as manganese perovskite compounds. In this study, we investigate charge disproportionation in nearly-doped manganites using density functional theory alongside Hubbard U relaxation. Our findings indicate that the CO state can be stabilized at low temperatures, leading to significant Coulomb interactions between Mn3+ and Mn4+ ions. We observe that the energy advantage of the CO state over the metallic state increases rapidly as the temperature drops below the critical temperature (Tc). Our results suggest that the CO state is more stable than other competing phases, including the ferromagnetic insulating state and the antiferromagnetic insulating phase. \n\nKeywords: Charge ordering, Density functional theory, Correlated electrons, Transition metal oxides, Manganites, Energy band structure, Insulators, Ferromagnetism, Antiferromagnetism.",
        "ori-fast-z-score": -0.5443310539518174,
        "water-fast-z-score": 3.5381518506868126,
        "rewrite-fast-z-score": 1.9205531989934397
    },
    {
        "original_text": "In this work, we consider a multiple-input-multiple-output (MIMO) system where each transmitter has limited feedback information about its channel state to the receiver. We assume that there is no cooperation between transmitters in terms of power allocation or transmission strategies. Each transmitter can only adjust its own transmit power level based on local CSI knowledge at the transmitter side. In addition, each transmitter may turn off its radio completely when it does not have any data to send. The objective is to maximize the sum rate by optimizing both the power control policy as well as the transmission strategy for all users simultaneously under these constraints. \n \n First, we derive an upper bound on the achievable sum-rate using finite-rate feedback assuming Gaussian codebooks. Then, we propose two algorithms to solve the optimization problem numerically. Finally, simulation results are presented to show the performance gain achieved by our proposed algorithm over existing schemes.",
        "watermark_text": "In this research , we study a multiple - input - multiple - output ( MIMO ) scheme where each antenna has restricted feedback info about its channel state to the receiver . We assume that there is no cooperation between transmitters in terms of power distribution or transmission strategies .Each antenna can only alter its own transmit energy level based on local CSI information at the transmitter side . In addition , each antenna could switch off its broadcast completely when it does not have any info to carry .The goal is to maximize the sum frequency by optimizing both the power control strategy as well as the transmission strategy for all users simultaneously under these requirements . First , we derive an upper bound on the achievable sum - speed using finite - frequency feedback assuming Gaussian codebooks .Then , we propose two strategies to solve the algorithms issue numerically . Finally , simulation data are presented to see the performance gain achieved by our proposed algorithm over existing strategies .",
        "rewrite_text": "In this study, we investigate a multiple-input multiple-output (MIMO) system where each antenna has limited feedback regarding its channel state to the receiver. We assume there is no collaboration among transmitters concerning power distribution or transmission strategies. Each antenna can adjust its own transmit power based solely on local channel state information (CSI) available at the transmitter. Furthermore, antennas have the option to turn off their transmission entirely if there is no information to send. Our objective is to enhance the overall transmission frequency by optimizing both the power control and transmission strategies for all users while adhering to these constraints. Initially, we establish an upper limit for the achievable sum data rate using finite-frequency feedback with the assumption of Gaussian codebooks. Subsequently, we introduce two numerical strategies to tackle the algorithmic challenges. Finally, we present simulation results to demonstrate the performance improvements achieved by our proposed algorithm compared to existing methods.",
        "ori-fast-z-score": -0.22645540682891913,
        "water-fast-z-score": 6.114295984380816,
        "rewrite-fast-z-score": 2.4596747752497685
    },
    {
        "original_text": "We present new near-infrared (NIR) and millimeter-wave observations toward the starless dense core FeSt 1-457, which is located in the Taurus molecular cloud complex at a distance of 140 pc. The NIR data were obtained with the Subaru telescope using the SofI instrument on 2005 December 8-9 under photometric conditions. We detected no point sources down to Ks = 20 mag within an area of 0.5 arcmin2 centered on the peak position of the dust continuum emission observed by SCUBA-2 on JCMT. In addition, we found that there are two peaks in the 1.3 mm continuum map made with MAMBO-II on IRAM 30 m telescope. These results suggest that this object may be a protostellar candidate or a prestellar core surrounded by infalling envelopes. To investigate its dynamical state further, we carried out high-resolution interferometric observations with Nobeyama 45-m radio telescope. Our results show that the central part of the core has a velocity gradient along the east-west direction, suggesting that it is collapsing.",
        "watermark_text": "We report new near - infrared ( NIR ) and millimeter - wave images toward the starless rich core FeSt 1 - 457 , which is situated in the Taurus molecular dust complex at a distance of 140 pc . The NIR data were obtained with the Subaru observatory using the SofI camera on 2005 December 8 - 9 under photometric circumstances .We observed no point sources down to Ks = 20 mag within an area of 0 . 5 arcmin2 centered on the peak status of the dust continuum emission observed by SCUBA - 2 on JCMT . In addition , we reported that there are two peaks in the 1 . 3 cm continuum image produced with MAMBO - II on IRAM 30 m observatory .These data suggest that this body may be a protostellar candidate or a prestellar core flanked by infalling envelopes . To explore its dynamical state further , we conducted out large - resolution interferometric observations with Nobeyama 45 - m radio telescope .Our results show that the main region of the core has a speed gradient along the east - west direction , showing that it is sinking .",
        "rewrite_text": "We present new near-infrared (NIR) and millimeter-wave images of the starless dense core FeSt 1-457, located in the Taurus molecular dust complex at a distance of 140 parsecs. The NIR data were collected using the SofI camera at the Subaru Observatory during photometric conditions on December 8-9, 2005. Within a 0.5 arcminute² area centered on the dust continuum emission peak observed by SCUBA-2 on the James Clerk Maxwell Telescope, we did not detect any point sources down to Ks = 20 mag. Additionally, we found two peaks in the 1.3 cm continuum image obtained with MAMBO-II at the IRAM 30 m telescope. These findings indicate that FeSt 1-457 may represent a protostellar candidate or a prestellar core surrounded by infalling envelopes. To further investigate its dynamical state, we performed high-resolution interferometric observations using the Nobeyama 45-m radio telescope. Our results reveal a speed gradient in the core's main region, extending in the east-west direction, indicating that it is undergoing gravitational collapse.",
        "ori-fast-z-score": -1.6378460497066512,
        "water-fast-z-score": 4.913538149119954,
        "rewrite-fast-z-score": 1.3643820804812932
    },
    {
        "original_text": "We present exact solutions for the electromagnetic field in the presence of spherical particles with arbitrary dielectric functions, including both metals and insulators. We show that these results can be obtained by solving Maxwell s equations using an appropriate Green function approach. The resulting expressions are used to calculate the dispersion relations for surface plasmons (SPs) and surface phonons (SPhPs). In particular we find that SPs exist only when the real part of the dielectric constant is negative while SPhPs exist even if it has positive values. Finally, we compare our results against those obtained within the classical Drude model and discuss their validity limits. Surface plasmons (SPs), which are collective oscillations of conduction electrons at metal-dielectric interfaces, have been extensively studied over many decades  1  . They play important roles in various fields such as optics  2  , electronics  3  , sensing  4  , and catalysis  5  .\nRecently there has also been growing interest in studying surface phonon-polaritons (SPhPs), which are analogous excitations associated with longitudinal acoustic waves  6  . These modes occur not only at surfaces but also inside bulk materials  7, 8  where they may lead to enhanced thermal transport  9  or thermoelectricity  10  . Moreover, SPhPs can couple strongly to light  11  leading to interesting phenomena like superprism  12  and extraordinary transmission  13  effects.",
        "watermark_text": "We present precise solutions for the electromagnetic field in the presence of spherical objects with arbitrary dielectric functions , including both metals and insulators . We see that these results can be obtained by treating Maxwell s equations using an appropriate Green function method .The resulting expressions are using to estimate the dispersion relations for surface plasmons ( SPs ) and surface phonons ( SPhPs ) . In particular we find that SPs occur only when the real part of the dielectric constant is zero while SPhPs exist even if it has negative values .Finally , we compare our findings against those achieved within the classical Drude theory and consider their efficacy limits . Surface plasmons ( SPs ) , which are collective oscillations of conduction electrons at metal - dielectric connections , have been heavily explored over numerous years 1 .They play essential roles in different fields such as optics 2 , electronics 3 , sensing 4 , and catalysis 5 . Recently there has especially been growing interest in investigating surface phonon - polaritons ( SPhPs ) , which are analogous excitations associated with longitudinal acoustic waves 6 .These modes happen not only at surfaces but also inside bulk surfaces 7 , 8 where they may contribute to heightened thermal transport 9 or thermoelectricity 10 . Moreover , SPhPs can close intensely to light 11 contributing to curious phenomena like superprism 12 and exceptional transmission 13 phenomena .",
        "rewrite_text": "We provide detailed solutions for the electromagnetic field around spherical objects with arbitrary dielectric properties, encompassing both metals and insulators. Our findings are derived from applying an appropriate Green function method to Maxwell's equations. The resulting expressions are utilized to analyze the dispersion relations of surface plasmons (SPs) and surface phonon polaritons (SPhPs). Notably, we discover that SPs only emerge when the real part of the dielectric constant is zero, whereas SPhPs can exist even with negative values. Additionally, we evaluate our results against those obtained from classical Drude theory and discuss the limitations of its efficacy. Surface plasmons, which represent collective oscillations of conduction electrons at metal-dielectric interfaces, have been extensively studied over the years and are crucial in various fields, including optics, electronics, sensing, and catalysis. Recently, there has been a significant increase in interest in surface phonon polaritons (SPhPs), which are analogous excitations tied to longitudinal acoustic waves. These modes can manifest not just at surfaces but within bulk media, potentially enhancing thermal transport and thermoelectric performance. Furthermore, SPhPs have the capability to interact closely with light, leading to intriguing phenomena such as superprism effects and exceptional transmission.",
        "ori-fast-z-score": -0.8164965809277261,
        "water-fast-z-score": 6.25846794771944,
        "rewrite-fast-z-score": 0.21320071635561041
    },
    {
        "original_text": "We present new radio continuum and H I absorption data for the dwarf irregular galaxy VIRGOHI 21, which is located at the edge of the virgo cluster. The galaxy has an optical diameter of about 1 kpc (0.3 arcmin) and shows no signs of star formation activity. We find that its neutral hydrogen mass amounts to M_HI = 2 x 10^{10} M_sol. Its total luminosity L_TOT = 3.5 x 10^{8} L_SOL corresponds to a B-band absolute magnitude MB = -18.7 mag. This value agrees well with those found by other authors for similar galaxies. From our analysis we conclude that this object may be considered as a candidate for a  dark galaxy . It contains only little or even no stars but still possesses a large amount of cold gas. If confirmed, it would provide further evidence for the existence of such objects.",
        "watermark_text": "We present new radio continuum and H I emission data for the dwarf irregular galaxy VIRGOHI 21 , which is situated at the boundary of the virgo cluster . The galaxy has an optical diameter of about 1 kpc ( 0 . 3 arcmin ) and shows no indication of galaxy formation activity .We see that its neutral hydrogen mass amounts to M _ HI = 2 x 10 ^ { 10 } M _ sol . Its overall luminosity L _ TOT = 3 . 5 x 10 ^ { 8 } L _ SOL belongs to a B - band absolute magnitude MB = - 18 . 7 mag .This value agrees well with those observed by other researchers for related galaxies . From our analysis we follow that this object may be regarded as a candidate for a black galaxy .It contains only little or even no stars but still possesses a large number of cold energy . If confirmed , it would offer further evidence for the existence of such objects .",
        "rewrite_text": "We present new radio continuum and H I emission data for the dwarf irregular galaxy VIRGOHI 21, located at the edge of the Virgo cluster. This galaxy has an optical diameter of approximately 1 kpc (0.3 arcmin) and shows no signs of active galaxy formation. The mass of its neutral hydrogen is measured at M_HI = 2 x 10^{10} M_sol, and it has an overall luminosity of L_TOT = 3.5 x 10^{8} L_sol, corresponding to an absolute B-band magnitude of M_B = -18.7 mag. This measurement is consistent with those reported by other researchers for similar galaxies. Our analysis suggests that VIRGOHI 21 may be a candidate for a \"black galaxy,\" characterized by having few, if any, stars while still containing a considerable amount of cold energy. If confirmed, this would provide additional evidence for the existence of such objects.",
        "ori-fast-z-score": 0.762000762001143,
        "water-fast-z-score": 5.08000508000762,
        "rewrite-fast-z-score": 2.626128657194451
    },
    {
        "original_text": "We report on observations made with Herschel Space Observatory (Pilbratt et al., 2010) of water vapour emission lines at 557 GHz, 1669 GHz and 1720 GHz towards two young stars surrounded by circumstellar disks: HD 100546 and TW Hya. The data were obtained as part of the Open Time Key Programme  Formation and Evolution of Planetary Systems  (FEPS). We detect water vapour emission over an extended range of radial velocities for both targets. For HD 100546 we find that the line profiles are consistent with Keplerian rotation around a central mass of 1.8 M . In addition to this broad component, which is likely associated with the outer regions of the disk, there appears to be a narrower feature superimposed on each profile. This narrow component may arise either from gas located close to the star or from outflowing material along our line-of-sight.",
        "watermark_text": "We report on observations made with Herschel Space Observatory ( Pilbratt et al . , 2010 ) of water vapour emission lines at 557 GHz , 1669 GHz and 1720 GHz towards two young galaxies surrounded by circumstellar disks : HD 100546 and TW Hya . The data were obtained as part of the Open Time Key Programme Formation and Evolution of Planetary Systems ( FEPS ) .We detect water vapour pollution over an extended range of radial velocities for both targets . For HD 100546 we find that the line profiles are compatible with Keplerian rotation around a central weight of 1 . 8 M .In addition to this wide structure , which is probably associated with the exterior areas of the disk , there seems to be a narrower feature superimposed on each profile . This narrow component may arise either from gas located close to the star or from outflowing matter along our line - of - view .",
        "rewrite_text": "We present observations from the Herschel Space Observatory (Pilbratt et al., 2010) that reveal water vapor emission lines at 557 GHz, 1669 GHz, and 1720 GHz in two young galaxies with circumstellar disks: HD 100546 and TW Hya. These data were collected under the Open Time Key Programme on the Formation and Evolution of Planetary Systems (FEPS). Our findings indicate the presence of water vapor across a broad range of radial velocities for both galaxies. In the case of HD 100546, the line profiles align with Keplerian rotation around a central mass of 1.8 M☉. In addition to this broader structure—likely linked to the outer regions of the disk—we also observe a narrower feature superimposed on each profile. This narrow component may originate from gas situated near the star or from outflowing material along our line of sight.",
        "ori-fast-z-score": 1.5109662034355793,
        "water-fast-z-score": 4.807619738204116,
        "rewrite-fast-z-score": 1.632993161855452
    },
    {
        "original_text": "PoGOLite is an experiment to measure the degree and angle of linear polarization for photons with energies between 100 MeV and 1 GeV, which are emitted by astrophysical sources such as pulsars or active galactic nuclei (AGN). The measurement principle relies on Compton scattering off electrons bound into atoms inside a scintillator crystal. In this work we present results obtained during commissioning runs at the Paul Scherrer Institute (PSI) in Switzerland. We show that the detector response function can be described well within statistical uncertainties by Monte Carlo simulations based on Geant4. Furthermore, we demonstrate how the measured data can be used to extract information about the source s polarization properties. Finally, we discuss possible systematic effects related to the experimental setup. Keywords: Polarization measurements; Gamma-ray polarimetry; PoGOLite Experiment; Scintillation detectors; Compton scattering; Commissioning",
        "watermark_text": "PoGOLite is an research to measure the degree and angle of linear polarization for photons with energies between 100 MeV and 1 GeV , which are emitted by astrophysical sources such as pulsars or active galactic nuclei ( AGN ) . The measurement theory relies on Compton absorption off electrons bound into atoms inside a scintillator crystal .In this research we present results acquired during commissioning running at the Paul Scherrer Institute ( PSI ) in Switzerland . We suggest that the detector response function can be described good within statistical uncertainties by Monte Carlo simulations based on Geant4 .Furthermore , we explain how the studied data can be used to extract information about the source s polarization properties . Finally , we explain possible systematic effects similar to the empirical setup .Keywords : Polarization calculations ; Gamma - ray polarimetry ; PoGOLite Experiment ; Scintillation detectors ; Compton scattering ; Commissioning",
        "rewrite_text": "PoGOLite is a research project focused on measuring the degree and angle of linear polarization for photons with energies ranging from 100 MeV to 1 GeV, which are emitted by astrophysical sources like pulsars and active galactic nuclei (AGN). The measurement technique is based on Compton absorption of photons by electrons bound in atoms within a scintillator crystal. In this paper, we present results obtained during the commissioning phase at the Paul Scherrer Institute (PSI) in Switzerland. We propose that the detector's response function can be accurately modeled, within statistical uncertainties, using Monte Carlo simulations that employ Geant4. Additionally, we discuss how the data analyzed can be used to extract information about the polarization properties of the sources. Lastly, we address potential systematic effects that may arise in the experimental setup. \n\nKeywords: Polarization calculations; Gamma-ray polarimetry; PoGOLite Experiment; Scintillation detectors; Compton scattering; Commissioning.",
        "ori-fast-z-score": 0.565685424949238,
        "water-fast-z-score": 4.437601569801833,
        "rewrite-fast-z-score": 1.2135597524338357
    },
    {
        "original_text": "We present an improved method for analyzing the primordial power spectrum in terms of its underlying physical parameters, using the technique of  flow equations  to evolve the initial conditions through the entirety of cosmic time. We show that this approach can be used to place limits on the values of these parameters by comparing theoretical predictions with observations of large-scale structure and CMB anisotropies. In particular we find that the current data is consistent with a flat universe dominated by dark energy (w = -1), but inconsistent with models where w > -0.8 or w < -2/3 at 95% confidence level. This result agrees well with previous analyses based on other techniques. \n \n The results presented here are derived from the WMAP 5-year temperature map  1  , combined with measurements of galaxy clustering  2  . They are also compatible with recent results obtained independently by the Planck satellite  3  .\n \n \n Our analysis shows that it will soon become possible to use the observed shape of the primordial power spectrum as a powerful probe into the physics of early-universe cosmology.",
        "watermark_text": "We introduce an better method for evaluating the primordial power spectrum in terms of its underlying physical values , using the method of flow equations to evolve the initial conditions through the entirety of cosmic time . We see that this methodology can be used to place limits on the values of these parameters by using theoretical estimates with observations of large - scale structure and CMB anisotropies .In particular we find that the present data is compatible with a flat universe inhabited by black radiation ( w = - 1 ) , but inconsistent with models where w > - 0 . 8 or v < - 2 / 3 at 95 % confidence rate . This result agrees well with previous analyses based on other techniques .The results presented here are derived from the WMAP 5 - year warming map 1 , combined with observations of galaxy clustering 2 . They are also consistent with recent results derived independently by the Planck satellite 3 .Our study shows that it will soon become able to use the known shape of the primordial power spectrum as a powerful probe into the physics of early - cosmic cosmology .",
        "rewrite_text": "We propose an improved method for evaluating the primordial power spectrum based on its fundamental physical parameters, employing flow equations to evolve initial conditions throughout the entire span of cosmic time. This approach allows us to establish constraints on these parameters by comparing theoretical predictions with observations of large-scale structures and cosmic microwave background (CMB) anisotropies. Specifically, our findings indicate that current data is consistent with a flat universe filled with black radiation (w = -1) but is incompatible with models where w > -0.8 or v < -2/3 at a 95% confidence level. These results align well with previous analyses conducted using different techniques. The findings presented here are based on the WMAP five-year temperature map, combined with observations of galaxy clustering, and are consistent with recent independent results from the Planck satellite. Our study demonstrates that we will soon be able to utilize the known shape of the primordial power spectrum as a potent tool for investigating the physics of early cosmic cosmology.",
        "ori-fast-z-score": 2.013995972012084,
        "water-fast-z-score": 6.88998622004134,
        "rewrite-fast-z-score": 1.4924050144892729
    },
    {
        "original_text": "We present the first panoramic view of the distribution of galaxies around two massive clusters at redshifts z = 0.4-0.6, using deep near-infrared imaging with WFC3 on HST. The data reveal an extended population of faint galaxies surrounding each cluster that is not seen in optical images. We find that these galaxies are predominantly blue (with median color u − g = -0.5), have low stellar masses (10^9 Msun/pc^2) and high specific star formation rates (sSFR ~ 10^-2 Gyr-1). These properties suggest they represent a recently assembled population of star-forming dwarf galaxies that were accreted by their host clusters during recent mergers. In addition to this diffuse component we also identify several dozen bright galaxies within 1 Mpc of both clusters which appear to be undergoing rapid bursts of star formation triggered by interactions between infalling gas-rich galaxies and the hot intracluster medium.",
        "watermark_text": "We present the first panoramic study of the distribution of clusters around two huge clusters at redshifts z = 0 . 4 - 0 . 6 , using deep near - infrared imaging with WFC3 on HST . The data reveal an extended population of faint clusters surrounding each cluster that is not seen in infrared images .We see that these objects are exclusively blue ( with median color u − g = - 0 . 5 ) , have poor stellar masses ( 10 ^ 9 Msun / pc ^ 2 ) and large particular galaxy formation rates ( sSFR ~ 10 ^ - 2 Gyr - 1 ) . These properties suggest they represent a recently assembled colony of star - creating dwarf stars that were accreted by their host clusters during earlier mergers .In addition to this diffuse component we also identify several several bright stars within 1 Mpc of both clusters which appear to be experiencing rapid bursts of galaxy formation followed by interactions between infalling gas - rich galaxies and the hotter intracluster medium .",
        "rewrite_text": "We present the inaugural panoramic study of cluster distribution around two massive clusters at redshifts z = 0.4 - 0.6, utilizing deep near-infrared imaging with the WFC3 on HST. Our data reveals a widespread population of faint clusters enveloping each large cluster, which is not visible in infrared imagery. These objects are characterized predominantly by their blue hues, with a median color of u - g = -0.5. They possess relatively low stellar masses (10^9 Msun/pc^2) and elevated specific star formation rates (sSFR ~ 10^-2 Gyr^-1). Such characteristics indicate that these objects likely represent a newly formed group of star-forming dwarf galaxies, having been accreted by their host clusters during prior merger events. Additionally, we detect several bright galaxies within 1 Mpc of both clusters, which appear to be undergoing rapid bursts of star formation, possibly due to interactions between gas-rich infalling galaxies and the hotter intracluster medium.",
        "ori-fast-z-score": -0.11704114719613057,
        "water-fast-z-score": 5.032769329433615,
        "rewrite-fast-z-score": 0.11396057645963795
    },
    {
        "original_text": "We report on infrared spectroscopic observations with the Infrared Spectrograph (IRS) aboard the Spitzer Space Telescope toward the nearby late-type galaxy NGC 3621, which is known to harbor a supermassive black hole at its center. The IRS spectrum shows prominent emission lines such as  Ne II 12.81 and  S III 18.71 µm that are commonly seen in active galactic nuclei (AGNs). We find that these emission lines can be reproduced by photoionization models using AGN-like ionizing radiation fields. From the observed line ratios we estimate the electron density n e = 10 3 cm −3 , temperature T e = 1000 K, and ionization parameter U H = 1 × 10 −2 . These results suggest that the central region of NGC 3621 has properties similar to those found for Seyfert galaxies. This work was supported by NASA through grant number GO-08460.01-A awarded by the Jet Propulsion Laboratory, California Institute of Technology under contract with NASA.",
        "watermark_text": "We report on infrared spectroscopic observations with the Infrared Spectrograph ( IRS ) aboard the Spitzer Space Telescope toward the nearby mid - class galaxy NGC 3621 , which is known to harbor a supermassive black hole at its core . The IRS spectrum displays large emitted lines such as Ne II 12 . 81 and S III 18 . 71 µm that are often observed in active galactic nuclei ( AGNs ) .We see that these radiation patterns can be reproduced by photoionization models using AGN - like ionizing radiation fields . From the known line ratios we estimate the electron concentration h e = 10 3 cm −3 , temperature T e = 1000 K , and ionization variable U H = 1 × 10 −2 .These results show that the central region of NGC 3621 has properties similar to those found for Seyfert galaxies . This work was supported by NASA through grant number GO - 08460 . 01 - A awarded by the Jet Propulsion Laboratory , California Institute of Technology under contract with NASA .",
        "rewrite_text": "We present infrared spectroscopic observations obtained with the Infrared Spectrograph (IRS) on the Spitzer Space Telescope, focusing on the nearby mid-class galaxy NGC 3621, which is known to host a supermassive black hole at its center. The IRS spectrum reveals prominent emission lines, such as Ne II at 12.81 µm and S III at 18.71 µm, commonly associated with active galactic nuclei (AGNs). Our analysis indicates that these emission characteristics can be modeled using photoionization techniques that incorporate AGN-like ionizing radiation fields. From the observed line ratios, we derive estimates for the electron density (n_e = 10^3 cm^−3), electron temperature (T_e = 1000 K), and ionization parameter (U_H = 1 × 10^−2). These findings suggest that the central region of NGC 3621 exhibits properties akin to those of Seyfert galaxies. This research was supported by NASA under grant number GO-08460.01-A, awarded by the Jet Propulsion Laboratory at the California Institute of Technology, in accordance with NASA's contract.",
        "ori-fast-z-score": 0.2672612419124244,
        "water-fast-z-score": 3.640679257301507,
        "rewrite-fast-z-score": 0.75
    },
    {
        "original_text": "We present new observations of the molecular line emission in the vicinity of the massive young open cluster Westerlund 1 (Wd-1). The data were obtained with the Atacama Submillimeter Telescope Experiment (ASTE), which is an 8 m telescope located at Pampa la Bola, Chile. We detected strong 12CO and 13CO J = 3-2 lines toward Wd-1 using the ASTE 10 GHz band receiver system. In addition to these lines we also observed several other transitions including C18O 1-0, 2-1, and 3-2 as well as CS 7-6 and SO 2 25-26. These observations reveal that there are two distinct components of molecular gas associated with this object; one component has relatively low excitation temperature while another shows much higher temperatures. This latter component appears to be distributed along an arc-like structure around the central star cluster. Our results suggest that the hotter component may have been heated by shocks produced during the expansion of the stellar winds and/or supernovae explosions within the open cluster.",
        "watermark_text": "We report new images of the molecular line emission in the vicinity of the giant young open cluster Westerlund 1 ( Wd - 1 ) . The data were obtained with the Atacama Submillimeter Telescope Experiment ( ASTE ) , which is an 8 m observatory situated at Pampa la Bola , Chile .We observed strong 12CO and 13CO J = 3 - 2 bands toward Wd - 1 using the ASTE 10 GHz band receiver network . In addition to these bands we also observed numerous other transitions including C18O 1 - 0 , 2 - 1 , and 3 - 2 as well as CS 7 - 6 and SO 2 25 - 26 .These measurements reveal that there are two different components of molecular vapor associated with this body ; one part has relatively lowest excitation temperature while another shows significantly greater temperatures . This latter component appears to be spread along an arc - like structure around the main star cluster .Our results propose that the hotter component may have been heated by shocks created during the surge of the planetary winds and / or supernovae explosions within the open cluster .",
        "rewrite_text": "We present new images of molecular line emission in the vicinity of the massive young open cluster Westerlund 1 (Wd - 1). The observations were conducted using the Atacama Submillimeter Telescope Experiment (ASTE), an 8-meter facility located at Pampa la Bola, Chile. We detected strong 12CO and 13CO J = 3 - 2 lines toward Wd - 1 with the ASTE's 10 GHz band receiver network. In addition to these lines, we recorded several other transitions, including C18O 1 - 0, 2 - 1, and 3 - 2, as well as CS 7 - 6 and SO 2 25 - 26. The data reveals two distinct components of molecular gas associated with the cluster: one component has a relatively low excitation temperature, while the other exhibits significantly higher temperatures. This hotter component appears to be distributed along an arc-like structure surrounding the main star cluster. These findings suggest that the elevated temperatures may be the result of shocks generated by the vigorous winds from the stars and/or supernova explosions occurring within the open cluster.",
        "ori-fast-z-score": -0.7276068751089989,
        "water-fast-z-score": 5.093248125762992,
        "rewrite-fast-z-score": -0.47809144373375745
    },
    {
        "original_text": "We present the chemical properties (metallicity, abundance ratios) for a sample of dwarf galaxies in the Local Volume with known distances and star formation histories. We use high quality spectra obtained at the Apache Point Observatory to derive oxygen abundances using both direct T e method as well as strong-line methods calibrated on H II regions in nearby spiral galaxies.  The derived metallicities range between 12+log(O/H)=7.6-8.2 dex. These values are consistent with those found by previous studies based on optical spectroscopy. In addition we find that most of these dwarfs have supersolar N/O ratio indicating recent or ongoing nitrogen enrichment due to massive stars. This is also supported by their low SFRs which prevent efficient dilution of the enriched gas produced by supernovae type Ia. Finally, we compare our results with theoretical predictions made by different chemical evolution models. Our analysis shows that none of them can reproduce simultaneously all observed quantities such as metallicity, N/O ratio and sSFR.",
        "watermark_text": "We present the chemical properties ( metallicity , abundance proportions ) for a sample of dwarf stars in the Local Volume with established altitudes and galaxy formation histories . We use large quality spectra obtained at the Apache Point Observatory to derive gas abundances using both direct T e method as also as bright - line methods calibrated on H II regions in nearby spiral clusters .The derived metallicities range between 12 + log ( O / H ) = 7 . 6 - 8 . 2 dex . These values are compatible with those shown by earlier surveys based on optical spectroscopy .In addition we find that most of these dwarfs have supersolar N / O ratio indicating new or ongoing nitrogen enrichment due to massive stars . This is also supported by their low SFRs which prevent efficient dilution of the enriched gas created by supernovae class Ia .Finally , we compare our findings with theoretical estimates made by various chemical evolution models . Our investigation reveals that none of them can predict simultaneously all observed properties such as metallicity , N / O ratio and sSFR .",
        "rewrite_text": "We present an analysis of the chemical properties, including metallicity and abundance proportions, of a sample of dwarf stars in the Local Volume, all of which have well-defined altitudes and documented galaxy formation histories. Using high-quality spectra obtained at the Apache Point Observatory, we determine gas abundances through both the direct temperature (T e) method and bright-line techniques calibrated on H II regions within nearby spiral clusters. The metallicities we calculate fall within the range of 12 + log (O / H) = 7.6 - 8.2 dex, which aligns with values recorded in previous optical spectroscopy surveys. Furthermore, we observe that the majority of these dwarf stars exhibit supersolar N/O ratios, suggesting ongoing nitrogen enrichment from massive stars. This finding is corroborated by their low star formation rates (SFRs), which inhibit the efficient dilution of the enriched gas produced by type Ia supernovae. Lastly, we compare our results with predictions from various chemical evolution models, revealing that none of these models can adequately account for all observed characteristics, including metallicity, N/O ratio, and specific star formation rate (sSFR).",
        "ori-fast-z-score": -0.9058216273156765,
        "water-fast-z-score": 4.612860393796698,
        "rewrite-fast-z-score": 1.7253243712550146
    },
    {
        "original_text": "The vapor pressure, solubility in water, and interfacial tension between oil and water are important parameters for understanding the behavior of crude oils during their production or transport through pipelines.  In this study we have investigated these properties using alkanol monolayers on an aqueous subphase as model systems to mimic the hydrocarbon chains present in crude oils. The results show that the vapor pressures of the alkanols increase with chain length up to C8 but decrease again above C10. This is explained by considering the competition between two opposing effects:  On one hand, increasing chain lengths lead to higher molecular volumes which favor evaporation. On the other hand, longer chains also result in stronger van der Waals interactions within the liquid phase leading to lower vapor pressures. We find that the solubilities of the alkanols follow similar trends as those observed for the vapor pressures. However, the differences in solubility among different chain lengths become smaller when compared to the corresponding differences in vapor pressure. Finally, our measurements reveal that the interfacial tensions between the alkanol layers and the underlying water decreases monotonically with chain length.",
        "watermark_text": "The vapor tension , solubility in water , and interfacial tension between petroleum and water are important characteristics for studying the activity of crude oils during their production or delivery through pipelines . In this study we have analyzed these characteristics utilizing alkanol monolayers on an aqueous subphase as simulation structures to mimic the hydrocarbon chains present in crude oils .The results show that the liquid pressures of the alkanols increase with chain length up to C8 but decrease again above C10 . This is explained by using the competition between two conflicting factors : On one hand , increasing chain lengths result to higher molecular volumes which favor evaporation .On the other hand , wider chains also lead in heavier van der Waals bonds within the liquid phase leading to smaller liquid pressures . We see that the solubilities of the alkanols follow similar trends as those observed for the liquid pressures .However , the differences in solubility among different chain lengths become smaller when compared to the associated changes in vapor tension . Finally , our measurements reveal that the interfacial pressures between the alkanol layers and the underlying water reduces monotonically with chain depth .",
        "rewrite_text": "The vapor tension, water solubility, and interfacial tension between petroleum and water are critical factors in understanding the behavior of crude oils during production and transportation via pipelines. In this research, we investigated these factors by using alkanol monolayers on an aqueous subphase to simulate the hydrocarbon chains found in crude oils. Our findings indicate that the liquid pressures of the alkanols rise with increasing chain length up to C8, but begin to decrease after reaching C10. This phenomenon can be attributed to the interplay of two opposing influences: longer chain lengths lead to greater molecular volumes that promote evaporation, while bulkier chains create stronger van der Waals interactions in the liquid phase, resulting in lower liquid pressures. We observed similar trends in the solubility of the alkanols corresponding to the liquid pressures, although the differences in solubility between chain lengths become less pronounced compared to the changes in vapor tension. Furthermore, our measurements demonstrate that the interfacial pressures between the alkanol layers and the water underneath decrease steadily with increasing chain depth.",
        "ori-fast-z-score": 0.21081851067789195,
        "water-fast-z-score": 6.324555320336758,
        "rewrite-fast-z-score": 1.6269784336399213
    },
    {
        "original_text": "We present the results of simultaneous X-ray (Chandra) and radio (RXTE )observations of the Broad Line Radio Galaxy, 3C382 . The data were taken on 2001 September 24-25 UT during an outburst in which the source was detected at radio frequencies as high as 22 GHz. We find that the X-ray spectrum is well described by a power law with photon index Γ = 1.7 ± 0.1 modified by photoelectric absorption consistent with N_H = 2 x 1022 cm-2. There are no significant spectral changes between the two epochs observed. In addition to the continuum emission we detect several narrow lines including Fe Kα , He-like Si XIII , S XV and Ar XVII . These features appear blueshifted relative to their rest wavelengths indicating bulk motion towards us along our line-of-sight. Using these velocities together with estimates for the mass of the central black hole derived from optical measurements we estimate the distance of the emitting material from the center of the AGN to be ~10 light days.",
        "watermark_text": "We present the conclusion of simultaneous X - ray ( Chandra ) and radio ( RXTE ) observations of the Broad Line Radio Galaxy , 3C382 . The data were took on 2001 September 24 - 25 UT during an outburst in which the source was seen at radio altitudes as long as 22 GHz .We see that the X - ray spectrum is well described by a power law with photon index Γ = 1 . 7 ± 0 . 1 augmented by photoelectric diffusion compatible with N _ H = 2 x 1022 centimetres - 2 . There are no notable spectral changes between the two epochs observed .In addition to the continuum emission we perceive several small lines including Fe Kα , He - like Si XIII , S XV and Ar XVII . These features appear blueshifted relative to their rest wavelengths suggesting bulk movement towards us along our line - of - view .Using these velocities together with projections for the mass of the central black hole derived from optical calculations we estimate the distance of the emitting substance from the center of the AGN to be ~ 10 light days .",
        "rewrite_text": "We present the findings from simultaneous X-ray (Chandra) and radio (RXTE) observations of the Broad Line Radio Galaxy 3C382. These observations were conducted on September 24-25, 2001, during an outburst when the source was detected at radio frequencies up to 22 GHz. Our analysis reveals that the X-ray spectrum is well-represented by a power law with a photon index of Γ = 1.7 ± 0.1, supplemented by photoelectric absorption consistent with N_H = 2 x 10^22 cm^-2. No significant spectral variations were observed between the two epochs of data collection. Alongside the continuum emission, we detected several narrow emission lines, including Fe Kα, He-like Si XIII, S XV, and Ar XVII. These lines appeared blueshifted compared to their rest wavelengths, indicating bulk motion toward us along our line of sight. By combining these velocity measurements with mass estimates of the central black hole derived from optical studies, we estimate the distance of the emitting region from the center of the AGN to be approximately 10 light days.",
        "ori-fast-z-score": -0.8819171036881969,
        "water-fast-z-score": 4.0,
        "rewrite-fast-z-score": -1.099524999206747
    },
    {
        "original_text": "We present an exact solution for the eigenstates and eigenvalues of a system consisting of a two-dimensional (2D) periodic array of semiconductor quantum dots coupled to a one-dimensional (1D) chain of identical quantum dots, which are both embedded into a 2D photonic crystal slab. The 1D chain is assumed to be driven by external laser fields at two different frequencies. We show that this structure can support bound states where photons are trapped between neighboring quantum dots along the 1D chain due to strong light-matter interaction mediated by excitons confined within each dot. These results may have important implications on future designs of optoelectronic devices based on hybrid structures combining semiconductors and photonics. In recent years there has been growing interest in developing novel optical materials and devices using nanostructures such as semiconductor quantum dots (QDs), nanowires or carbon nanotubes  1  . This research effort has led to the development of new concepts in optics including QD lasers  2  , single photon sources  3  , and QD-based solar cells  4  .\nIn particular, QDs offer unique advantages over conventional bulk semiconductor systems because they allow controllable tuning of their electronic properties through size engineering  5  . Moreover, it was recently shown  6  that these artificial atoms can also exhibit interesting nonlinear optical effects  7, 8  . For example, when excited by intense laser pulses, QDs can generate coherent emission of multiple photons  9  . However, despite significant progress made during last decade, many fundamental questions remain unanswered about how QDs interact with electromagnetic radiation  10  .",
        "watermark_text": "We present an precise solving for the eigenstates and eigenvalues of a system consisting of a two - dimensional ( 2D ) periodic array of semiconductor quantum dots coupled to a one - dimensional ( 1D ) chain of unrelated quantum dots , which are both fused into a 2D photonic crystal slab . The 1D chain is suppose to be driven by external beam currents at two different frequencies .We see that this formation can support bound states where photons are locked between neighboring quantum dots along the 1D chain thanks to powerful light - matter collision mediated by excitons enclosed within each dot . These conclusions could have important implications on future development of optoelectronic technologies based on hybrid structures combining semiconductors and photonics .In recent years there has been growing interest in building new optical materials and devices using nanostructures such as semiconductor quantum dots ( QDs ) , nanowires or carbon nanotubes 1 . This research effort has led to the development of new concepts in optics including QD lasers 2 , double photon sources 3 , and QD - based sun cells 4 .In particular , QDs offer distinct advantages over traditional bulk semiconductor systems because they allow controllable tuning of their electronic properties through size engineering 5 . Moreover , it was recently shown 6 that these artificial atoms can also display exciting nonlinear optical phenomena 7 , 8 .For instance , when excited by intense laser flashes , QDs can generate coherent emission of multiple photons 9 . However , despite considerable progress made during ago decade , many fundamental questions remain unanswered about how QDs behave with electromagnetic radiation 10 .",
        "rewrite_text": "We present an accurate analysis of the eigenstates and eigenvalues of a system that consists of a two-dimensional (2D) periodic array of semiconductor quantum dots coupled to a one-dimensional (1D) chain of independent quantum dots, both integrated into a 2D photonic crystal slab. The 1D chain is assumed to be driven by external beam currents at two different frequencies. Our findings indicate that this configuration can support bound states, with photons becoming trapped between neighboring quantum dots in the 1D chain due to strong light-matter interactions facilitated by excitons within each dot. These results have significant implications for the future development of optoelectronic technologies that integrate semiconductor and photonic structures. Recently, there has been a growing interest in creating new optical materials and devices using nanostructures such as semiconductor quantum dots (QDs), nanowires, and carbon nanotubes. This research has given rise to innovative concepts in optics, including QD lasers, entangled photon sources, and QD-based solar cells. QDs, in particular, provide distinct advantages over conventional bulk semiconductor systems by allowing for tunable electronic properties through size engineering. Furthermore, recent studies have demonstrated that these artificial atoms can exhibit remarkable nonlinear optical phenomena. For example, excited by intense laser pulses, QDs can produce coherent emission of multiple photons. Despite significant advances in the past decade, many fundamental questions about the interaction of QDs with electromagnetic radiation remain unanswered.",
        "ori-fast-z-score": 0.3563483225498992,
        "water-fast-z-score": 5.992662179699436,
        "rewrite-fast-z-score": 0.2773500981126145
    },
    {
        "original_text": "We present numerical simulations to study the formation, evolution, and collapse of quiescent cloud cores induced by dynamic compressions in turbulent molecular clouds. We find that these cloud cores are formed through shock compression at intersections between shocks driven into the clouds by supersonic turbulence. The cloud core masses range from 0.1 M⊙ to 1 M⊙ with typical sizes of about 1000 AU. These cloud cores have low internal velocities (< 2 km s-1) but can be accelerated up to 10 km s-1 during their lifetimes due to gravitational interactions with other dense clumps within the same clouds. Most of them evolve quasi-statically for several free-fall times before collapsing dynamically on time scales ranging from one to ten free-fall times. Our results suggest that such cloud cores may represent an important source of prestellar objects in star-forming regions. Keywords: Turbulence, Star Formation",
        "watermark_text": "We create numerical simulations to study the formation , emergence , and collapse of quiescent cloud cores induced by dynamic compressions in volatile molecular clouds . We see that these cloud cores are created through shock compression at intersections between shocks driven into the clouds by supersonic turbulence .The cloud core masses range from 0 . 1 [UNK] to 1 [UNK] with typical sizes of about 1000 AU . These cloud cores have low internal velocities ( < 2 km s - 1 ) but can be accelerated up to 10 km s - 1 during their lifetimes due to gravitational interactions with other dense clumps within the same clouds .Most of them evolve quasi - statically for multiple free - fall times before crashing dynamically on time ranges ranging from one to ten free - fall times . Our results propose that such cloud cores might represent an important source of prestellar objects in star - creating areas .Keywords: Turbulence, Star Formation",
        "rewrite_text": "We conduct numerical simulations to investigate the formation, emergence, and collapse of quiescent cloud cores that arise from dynamic compressions within volatile molecular clouds. Our findings indicate that these cloud cores form through shock compression at the intersections of shocks generated by supersonic turbulence in the clouds. The masses of these cloud cores vary from 0.1 [UNK] to 1 [UNK], with typical sizes around 1000 AU. Although they maintain low internal velocities (less than 2 km/s), they can reach speeds of up to 10 km/s during their lifetimes due to gravitational interactions with other dense clumps within the same clouds. Most of these cores evolve quasi-statically for several free-fall times before undergoing dynamic collapse over periods ranging from one to ten free-fall times. Our results suggest that these cloud cores may play a significant role as a source of prestellar objects in star-forming regions. Keywords: Turbulence, Star Formation.",
        "ori-fast-z-score": 0.629940788348712,
        "water-fast-z-score": 3.75,
        "rewrite-fast-z-score": 0.9847319278346618
    },
    {
        "original_text": "We study the dynamics of an asymmetric exclusion process with two species on a ring, where particles can hop to their right or left neighboring site and are subject to hard-core repulsion. We show that for any initial condition there exists a unique stationary state which is characterized by a density profile depending only on the distance between sites. In particular we find that this profile decays exponentially fast as one moves away from the origin. This result implies that the system exhibits dynamic screening, i.e., correlations decay exponentially fast at large distances even though the underlying microscopic model does not have translational invariance. The proof relies on a combination of techniques from probability theory (in particular martingale methods) and functional analysis. Our results hold both for finite systems and infinite lattices. \nI. INTRODUCTORY REMARK\nIn recent years much attention has been devoted to studying nonequilibrium steady states of driven lattice gases  1  . These models describe interacting particle systems evolving according to stochastic rules such that detailed balance cannot be satisfied globally  2  , but nevertheless they exhibit interesting macroscopic behavior  3  .\nOne class of these models consists of so-called exclusion processes  4  describing particles moving along a regular lattice under mutual exclusion constraints  5  . For example, consider a chain of L sites labeled by integers 1, ..., L, each occupied by either zero or one particle. Particles may jump to the right or left neighboring site provided it is empty  6  . If all jumps occur independently then the resulting Markov process satisfies detailed balance with respect to some product measure  7, 8  . However if the rates depend on the number of particles occupying adjacent sites  9  then detailed balance breaks down  10  . Despite this lack of equilibrium properties many of these models still display non-trivial features reminiscent of those observed in thermal equilibrium  11  .",
        "watermark_text": "We work the dynamics of an asymmetric exclusion cycle with two organisms on a ring , where ions can jump to their right or left neighboring place and are subject to rough - core repulsion . We see that for any initial situation there exists a unique stationary state which is characterized by a density profile depending only on the distance between locations .In particular we find that this profile decays exponentially rapidly as one moves away from the origin . This result suggests that the process exhibits dynamic filtering , i . e . , correlations decay exponentially rapidly at large distances even though the underlying microscopic theory does not have translational invariance .The proof uses on a combination of techniques from likelihood analysis ( in instance martingale models ) and functional analysis . Our results hold both for finite systems and infinite lattices .I . INTRODUCTORY REMARK In recent years much attention has been focused to investigating nonequilibrium steady states of driven lattice gases 1 .These systems represent interacting particle structures operating due to stochastic laws such that detailed balance cannot be satisfied globally 2 , but still they show exciting macroscopic behavior 3 . One class of these models includes of so - called exclusion mechanisms 4 describing particles moving along a regular lattice under mutual exclusion constraints 5 .For instance , consider a network of L locations labeled by integers 1 , . . . , L , each inhabited by either zero or one particle . Particles must hop to the right or left neighboring area provided it is vacant 6 .If all jumps happen independently then the resulting Markov process satisfies detailed balance with regard to some product measure 7 , 8 . However if the rates differ on the quantity of particles occupying adjoining sites 9 then detailed balance breaks down 10 .Despite this lack of stability properties many of these models remain show non - simple details resembling of those observed in heat equilibrium 11 .",
        "rewrite_text": "We investigate the dynamics of an asymmetric exclusion cycle involving two organisms on a ring, where ions can move to adjacent left or right positions while experiencing rough-core repulsion. Our findings indicate that from any initial configuration, there is a unique stationary state characterized by a density profile solely dependent on the distance between locations. Notably, we observe that this profile decays rapidly in an exponential manner as one moves away from the origin. This observation implies that the process exhibits dynamic filtering, meaning that correlations dissipate exponentially fast at large distances, even though the underlying microscopic theory lacks translational invariance. The proof employs a mix of techniques from likelihood analysis, particularly martingale models, coupled with functional analysis. Our results are valid for both finite systems and infinite lattices. **I. INTRODUCTORY REMARK** In recent years, there has been significant interest in exploring nonequilibrium steady states of driven lattice gases. These systems represent interacting particle arrangements governed by stochastic rules that prevent the global satisfaction of detailed balance, yet they display fascinating macroscopic behaviors. One category of these models involves exclusion mechanisms that describe particles moving along a regular lattice under mutual exclusion constraints. For example, consider a network of \\(L\\) locations labeled by integers \\(1, \\ldots, L\\), each occupied by either zero or one particle. Particles can only hop to adjacent left or right locations if they are vacant. When all jumps occur independently, the resulting Markov process adheres to detailed balance concerning some product measure. However, if the jump rates depend on the number of particles in neighboring sites, detailed balance is violated. Despite this breakdown in stability properties, many of these models exhibit non-trivial dynamics reminiscent of those seen in thermal equilibrium.",
        "ori-fast-z-score": 0.39904344223381105,
        "water-fast-z-score": 8.96717661308488,
        "rewrite-fast-z-score": 1.4504813352456845
    },
    {
        "original_text": "We present new near-infrared (NIR) polarimetric observations of the Herbig Ae star HD 142527, which reveal that its circumstellar dust is composed of two distinct populations with different grain sizes. The polarization degree decreases rapidly towards longer wavelengths at all positions along our slit except for one position where it increases again between 2.2 and 3.8 microns. We interpret this as evidence for an inner hole in the distribution of larger grains. This interpretation is supported by SED modeling using radiative transfer calculations including scattering off spherical particles. Our results suggest that the outer edge of the gap lies within 0.1 AU of the central star. In addition to the NIR data presented here we also obtained mid-infrared (MIR) spectro-polarimetry covering the wavelength range 5-20 micron. These data show no significant change in the polarization degree across the MIR bands indicating that there are no strong changes in the optical properties of the dust grains on these scales.",
        "watermark_text": "We present new near - infrared ( NIR ) polarimetric studies of the Herbig Ae star HD 142527 , which confirm that its circumstellar dust is composed of two separate populations with varying grain sizes . The polarization degree drops rapidly towards faster wavelengths at all positions along our slit except for one position where it reduces again between 2 . 2 and 3 . 8 microns .We interpret this as proof for an inner cavity in the distribution of bigger grains . This interpretation is backed by SED modeling using radiative transfer calculations including scattering off spherical objects .Our results show that the exterior border of the gap exists within 0 . 1 AU of the main star . In addition to the NIR data provided here we also discovered mid - infrared ( MIR ) spectro - polarimetry representing the frequency range 5 - 20 micron .These data indicate no major shift in the polarization degree across the MIR groups implying that there are no strong changes in the optical properties of the dust grains on these scales .",
        "rewrite_text": "We present new near-infrared (NIR) polarimetric observations of the Herbig Ae star HD 142527, which confirm the presence of two distinct populations of circumstellar dust with differing grain sizes. At all positions along our slit, the degree of polarization decreases sharply as we move to shorter wavelengths, with the exception of one position where a further reduction occurs between 2.2 and 3.8 microns. We interpret this phenomenon as evidence of an inner cavity in the distribution of larger grains. This interpretation is supported by spectral energy distribution (SED) modeling that utilizes radiative transfer calculations and accounts for scattering by spherical particles. Our findings indicate that the outer edge of the gap is located within 0.1 AU of the central star. Additionally, we uncovered mid-infrared (MIR) spectro-polarimetry data across the 5 to 20 micron range. These measurements reveal no significant changes in the degree of polarization among the MIR groups, suggesting that the optical properties of the dust grains remain consistent across these scales.",
        "ori-fast-z-score": 1.4342743312012722,
        "water-fast-z-score": 6.527299120066193,
        "rewrite-fast-z-score": 1.4142135623730951
    },
    {
        "original_text": "We present position-velocity diagrams (PVD) of masers in an accretion disk around a young stellar object, obtained with VLBI observations at 22 GHz and 43 GHz. The PVD are compared to those expected by models that include both rotation and radial motions. We find that our data can be explained if we assume that the emission comes from a ring-like structure located between 0.1 AU and 1 AU from the central star. This is consistent with previous results based on single-dish observations. Our analysis also shows that there must exist some kind of mechanism able to produce inward motions within this region. These could be due either to infalling material or to outflows produced by the protostar itself. Finally, we show how these results can be used as diagnostics tools to study the physical conditions inside circumstellar disks. Keywords: Accretion Disk, Circumstellar Disks, Infrared",
        "watermark_text": "We create position - speed diagrams ( PVD ) of masers in an accretion disk around a young stellar object , obtained with VLBI observations at 22 GHz and 43 GHz . The PVD are compared to those expected by predictions that include both rotation and radial movements .We see that our information can be described if we suppose that the emission originates from a ring - like structure located between 0 . 1 AU and 1 AU from the main star . This is compatible with previous findings based on single - dish measurements .Our study also shows that there may exist some kind of mechanism able to produce inward movement within this area . These could be due either to infalling matter or to outflows created by the protostar itself .Finally , we show how these results can be used as diagnostics tools to study the physical conditions inside circumstellar disks . Keywords : Accretion Disk , Circumstellar Disks , Infrared",
        "rewrite_text": "We generate position-speed diagrams (PVD) of masers within an accretion disk surrounding a young stellar object, derived from VLBI observations at 22 GHz and 43 GHz. These PVDs are analyzed in relation to predictions that incorporate both rotational and radial motions. Our findings suggest that the maser emissions originate from a ring-like structure situated between 0.1 AU and 1 AU from the central star, which aligns with earlier results obtained from single-dish measurements. Furthermore, our research indicates the potential presence of a mechanism that could cause inward movement in this region, possibly resulting from infalling matter or outflows generated by the protostar itself. Lastly, we demonstrate how these outcomes can serve as diagnostic tools for investigating the physical conditions within circumstellar disks. Keywords: Accretion Disk, Circumstellar Disks, Infrared.",
        "ori-fast-z-score": 0.5252257314388902,
        "water-fast-z-score": 5.337745350213779,
        "rewrite-fast-z-score": 0.13483997249264842
    },
    {
        "original_text": "We study the dynamics of an interface driven by a periodic external force in one dimension, using molecular dynamics simulations with Lennard-Jones particles at low temperatures (T = 0.1 − 1). We find that the interface moves as a whole when it is driven slowly enough; otherwise, it breaks into several segments which move independently. The number of segments increases with increasing driving frequency or decreasing temperature. In addition to these two regimes, we observe another regime where the interface exhibits stick-slip motion. This third regime occurs for intermediate values of the driving amplitude A and driving frequency f . For this regime, we show that there exists a scaling relation between the average velocity V , the driving frequency f , and the driving amplitude A: V ∝ Af 2 . Finally, we propose a simple model based on the concept of phonon-enhanced diffusion to explain our results. DOI: 10.1103/PhysRevE.77.020101",
        "watermark_text": "We explore the dynamics of an interface pushed by a periodic external force in one dimension , using polymer mechanics simulations with Lennard - Jones grains at low temperatures ( T = 0 . 1 − 1 ) . We see that the interface moves as a whole when it is driven slowly sufficiently ; otherwise , it splits into numerous segments which move independently .The amount of segments varies with varying drove frequency or decreasing temperature . In addition to these two regimes , we study another regime where the interface displays stick - slipping motion .This third regime appears for intermediate values of the driving intensity A and driving frequency f . For this regime , we find that there exists a scaling relation between the average momentum V , the driving frequency f , and the driving intensity A : V [UNK] Af 2 .Finally , we attempt a simple model based on the idea of phonon - augmented diffusion to explain our findings . DOI : 10 . 1103 / PhysRevE . 77 . 020101",
        "rewrite_text": "We investigate the behavior of an interface subjected to a periodic external force in one dimension, utilizing polymer mechanics simulations with Lennard-Jones grains at low temperatures (T = 0.1 − 1). Our findings reveal that when the interface is driven slowly enough, it moves as a cohesive unit; however, at faster driving rates, it disintegrates into multiple segments that move independently. The number of these segments fluctuates in response to changes in driving frequency or temperature. Furthermore, we identify a third regime characterized by stick-slip motion, which occurs at intermediate levels of driving intensity A and frequency f. In this regime, we observe a scaling relation between the average momentum V, the driving frequency f, and the driving intensity A, formulated as V ∝ Af². Lastly, we propose a simple model based on the concept of phonon-augmented diffusion to rationalize our results. DOI: 10.1103/PhysRevE.77.020101",
        "ori-fast-z-score": -0.808290376865476,
        "water-fast-z-score": 4.588314677411235,
        "rewrite-fast-z-score": 1.9896995023342199
    },
    {
        "original_text": "We study the dynamics of a probabilistic cellular automaton (PCA) with two species, prey and predators, which interact in an oscillatory way. The PCA is defined on a square lattice where each site can be occupied by at most one particle of either type. We show that for certain values of the parameters there are stable periodic solutions to this system. These results are obtained using a mean field approximation method. In particular we find that the periodicity depends only on the number of particles per unit area. This dependence agrees well with numerical simulations performed on finite lattices. Finally, we discuss how our model could be used as a simple description of population cycles observed in nature. Probabilistic cellular automata have been widely studied during recent years due to their potential applications in many fields such as physics  1  , biology  2  or computer science  3  . They consist of a set of cells arranged in some regular structure like a grid  4  whose state evolves according to local rules depending on its own state and those of its neighbors  5  .\nIn this work we consider a two-dimensional probabilistic cellular automaton  6  consisting of N sites located on a square lattice L = Z 2 . Each cell i ∈ L has four possible states denoted by 0, 1, 2 and 3 corresponding respectively to empty space, prey, predator and dead. At time t = 0 all sites are initialized randomly with probability p 0 = 1/4 of being vacant, p 1 = 1/2 of having a prey and p 2 = 1/4 of containing a predator. Then, the evolution rule consists of applying simultaneously the following transition probabilities between consecutive times t and t + 1:",
        "watermark_text": "We work the dynamics of a probabilistic cellular automaton ( PCA ) with two species , prey and predators , which interact in an oscillatory way . The PCA is characterized on a square lattice where each site can be occupied by at most one particle of either type .We see that for particular values of the variables there are stable periodic answers to this scheme . These conclusions are derived using a mean field approximation algorithm .In particular we find that the periodicity varies only on the quantity of particles per unit area . This dependence agrees well with numerical simulations conducted on finite lattices .Finally , we explain how our model could be used as a simple explanation of population trends studied in nature . Probabilistic cellular automata have been widely explored during recent months thanks to their potential applications in different fields such as science 1 , chemistry 2 or computer science 3 .They consist of a group of cells located in some regular structure like a network 4 whose state evolves due to local rules depending on its own state and those of its relatives 5 . In this research we study a two - dimensional probabilistic cellular automaton 6 consisting of N sites located on a square lattice L = Z 2 .Each cell i ∈ L has four possible states denoted by 0 , 1 , 2 and 3 relating respectively to empty space , prey , predator and dead . At time t = 0 all locations are initialized randomly with probability p 0 = 1 / 4 of being empty , p 1 = 1 / 2 of having a predators and p 2 = 1 / 4 of featuring a hunter .Then , the evolution rule involves of using concurrently the following transfer probabilities between successive times t and t + 1 :",
        "rewrite_text": "We examine the dynamics of a probabilistic cellular automaton (PCA) that features two species: prey and predators, which engage in oscillatory interactions. This PCA is defined on a square lattice where each site can house at most one particle from either species. Our analysis reveals that under specific parameter values, stable periodic behaviors emerge within this system. We derive these conclusions through a mean field approximation method, finding that the periodicity is influenced solely by the density of particles per unit area. This relationship aligns closely with numerical simulations conducted on finite lattices. Additionally, we discuss how our model may serve as a simple framework for understanding population dynamics observed in nature. Recent months have seen a surge in interest in probabilistic cellular automata due to their diverse applications across various fields, including science, chemistry, and computer science. These automata consist of cells arranged in a regular structure, such as a network, with their states evolving based on local rules that consider both their own state and those of neighboring cells. In this study, we focus on a two-dimensional probabilistic cellular automaton consisting of \\(N\\) sites on a square lattice denoted as \\(L = \\mathbb{Z}^2\\). Each cell \\(i \\in L\\) can assume one of four states: 0 (empty space), 1 (prey), 2 (predator), and 3 (dead). At time \\(t = 0\\), each site is initialized randomly, with a probability of \\(p_0 = \\frac{1}{4}\\) for being empty, \\(p_1 = \\frac{1}{2}\\) for housing a predator, and \\(p_2 = \\frac{1}{4}\\) for containing prey. The evolution of the system is governed by specific transfer probabilities between successive time steps \\(t\\) and \\(t + 1\\).",
        "ori-fast-z-score": -1.0,
        "water-fast-z-score": 6.15643073089126,
        "rewrite-fast-z-score": 3.1558437213360127
    },
    {
        "original_text": "We present results from direct cosmological hydrodynamic simulations that follow the formation of supermassive black holes (SMBHs) in galactic nuclei, their subsequent evolution through mergers with other SMBHs, and the associated feedback on galaxy properties. We find that:  The simulated SMBH mass function agrees well with observations at z = 0 for M• > 10^7M_solar.  At higher redshifts, our model predicts too many low-mass SMBHs compared to observational estimates based on quasar luminosity functions; this discrepancy may be due to uncertainties in the assumed duty cycle or radiative efficiency of quasars.  Our models predict an average Eddington ratio distribution that is consistent with observed distributions inferred from optical/UV emission lines.  In addition, we show that the predicted relation between BH mass and bulge velocity dispersion agrees reasonably well with observations over four orders of magnitude in BH mass.",
        "watermark_text": "We present results from direct cosmological hydrodynamic simulations that take the formation of supermassive black holes ( SMBHs ) in galactic nuclei , their ensuing evolution through mergers with other SMBHs , and the associated feedback on star dynamics . We see that : The simulated SMBH weight distribution agrees well with observations at h = 0 for M • > 10 ^ 7M _ solar .At higher redshifts , our model predicts too many lowest - weight SMBHs compared to observational projections based on quasar luminosity functions ; this discrepancy may be due to uncertainties in the expected duty cycle or radiative efficiency of quasars . Our models predict an estimated Eddington density distribution that is compatible with observed distributions inferred from optical / UV absorption lines .In addition , we prove that the expected relation between BH weight and bulge velocity dispersion agrees reasonably well with observations over four orders of magnitude in BH mass .",
        "rewrite_text": "We present findings from direct cosmological hydrodynamic simulations that examine the formation of supermassive black holes (SMBHs) in galactic centers, their subsequent evolution through mergers with other SMBHs, and the impact on stellar dynamics. Our results indicate that the weight distribution of simulated SMBHs aligns closely with observations at h = 0 for masses greater than 10^7 M_solar. However, at higher redshifts, our model predicts an excess of low-weight SMBHs compared to observational estimates derived from quasar luminosity functions; this could be attributed to uncertainties in the expected duty cycle or radiative efficiency of quasars. Additionally, our models yield an estimated Eddington density distribution that matches well with observed distributions inferred from optical and UV absorption lines. Lastly, we demonstrate that the anticipated relationship between black hole mass and bulge velocity dispersion corresponds reasonably well with observations across four orders of magnitude in black hole mass.",
        "ori-fast-z-score": -0.508000508000762,
        "water-fast-z-score": 4.318004318006477,
        "rewrite-fast-z-score": 0.9701425001453319
    },
    {
        "original_text": "We report the detection of cosmic far-infrared background (CFIRB) fluctuations using deep observations made by the Far Infrared Surveyor (FIS) onboard Akari satellite at 65 and 90 micron bands in the Lockman Hole field, which is one of the most sensitive fields for detecting extragalactic sources. The FIS has two photometric channels; N60 band covers 60 to 120 microns while WIDE-S channel covers 50 to 100 microns. We used data taken during the period between February 2005 and March 2007. After removing bright point-like objects detected by Spitzer/MIPS 24 micron survey, we performed aperture photometry on all remaining pixels within an area of 1 deg2 centered around the Lockman hole. To estimate the contribution from Galactic cirrus emission, we subtracted the median value of each pixel after applying a 3 sigma clipping method. Then we calculated power spectrum density (PSD) of the residual map. By fitting the PSD with a single power law model, we obtained the best-fit slope as -2.1 ± 0.3 at 65 micron and -1.9 ± 0.4 at 90 micron. These slopes are consistent with those expected from clustering properties of infrared galaxies.",
        "watermark_text": "We report the observation of cosmic far - infrared background ( CFIRB ) fluctuations using deep surveys made by the Far Infrared Surveyor ( FIS ) onboard Akari spacecraft at 65 and 90 micron bands in the Lockman Hole field , which is one of the most important areas for detecting extragalactic sources . The FIS has two photometric channels ; N60 band encompasses 60 to 120 microns while WIDE - S channel measures 50 to 100 microns .We utilized information taken during the period between February 2005 and March 2007 . After removing bright point - like items detected by Spitzer / MIPS 24 micron measurement , we performed aperture photometry on all remaining pixels within an area of 1 deg2 centered around the Lockman hole .To estimate the impact from Galactic cirrus emission , we subtracted the median value of each pixel after applying a 3 sigma clipping method . Then we calculated power spectrum concentration ( PSD ) of the residual map .By fitting the PSD with a single power law description , we derived the best - fitting curve as - 2 . 1 ± 0 . 3 at 65 micron and - 1 . 9 ± 0 . 4 at 90 micron . These slopes are compatible with those expected from clustering qualities of infrared galaxies .",
        "rewrite_text": "We present our findings on fluctuations in the cosmic far-infrared background (CFIRB), based on deep surveys conducted by the Far Infrared Surveyor (FIS) onboard the Akari spacecraft at wavelengths of 65 and 90 microns in the Lockman Hole region, a key area for identifying extragalactic sources. The FIS features two photometric channels: the N60 band, which covers 60 to 120 microns, and the WIDE-S channel, which measures 50 to 100 microns. Our analysis utilized data collected from February 2005 to March 2007. After excluding bright point-like sources identified by Spitzer/MIPS measurements at 24 microns, we performed aperture photometry on the remaining pixels within a 1 square degree area centered on the Lockman Hole. To account for the influence of Galactic cirrus emission, we subtracted the median value of each pixel using a 3 sigma clipping method. We then calculated the power spectrum density (PSD) of the residual map. Fitting the PSD with a single power law model, we found the best-fit slopes to be -2.1 ± 0.3 at 65 microns and -1.9 ± 0.4 at 90 microns. These slopes align with expectations based on the clustering characteristics of infrared galaxies.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.365641250653994,
        "rewrite-fast-z-score": -0.24253562503633297
    },
    {
        "original_text": "We study the Catalan numbers in connection with the number of ways to realize a given triangulation as an ordered sequence of its diagonals, or equivalently, as a set of non-crossing diagonals. We show that this problem is related to counting certain types of Dyck paths. In particular we prove that for any positive integer n there are exactly C(n) different sequences of diagonals which can be realized by a convex quadrilateral having 2n sides. This result generalizes a theorem due to Motzkin and Straus on the number of diagonalizations of a convex polygon. \nIntroduction\n\nThe Catalan numbers count many combinatorial objects such as binary trees, noncrossing partitions, spanning trees, etc., see e.g.   1, 2  . The present work deals with another class of Catalan-like objects: triangulations of polygons (see Figure 1 ). A triangulation T of a simple polygon P is defined as follows: it consists of all edges of P together with some additional diagonals connecting pairs of vertices of P so that each interior angle of P becomes at least 90 degrees after adding these diagonals. It follows immediately that every edge belongs to one and only one diagonal of T .\nIn  3  , Motzkin and Straus  celebrated theorem states that if D denotes the set of diagonals of a convex polygon Q then |D| = 2|Q|. They also proved that the number of diagonalizations d(P ) of a convex polygon P equals the number of diagonals of a triangulation of P . \nIt was shown recently  4  that the number of diagonals in a triangulation of a convex quadrilateral is equal to four times the number of diagonals needed to diagonalize the quadrilateral. Thus, the following question arises naturally: What is the relationship between the number of diagonals required to diagonalize a convex quadrilateral and the number of diagonals used in a triangulation?",
        "watermark_text": "We explore the Catalan numbers in connection with the number of ways to realize a given triangulation as an ordered sequence of its diagonals , or equivalently , as a group of non - crossing diagonals . We see that this question is related to counting particular kinds of Dyck paths .In particular we prove that for any positive integer n there are exactly C ( n ) different sequences of diagonals which can be realized by a convex quadrilateral having 2n sides . This result generalizes a theorem according to Motzkin and Straus on the number of diagonalizations of a convex polygon .Introduction The Catalan numbers count many combinatorial objects such as binary forests , noncrossing partitions , covering trees , etc . , see e . g . 1 , 2 .The present work deals with another class of Catalan - like structures : triangulations of polygons ( view Figure 1 ) . A triangulation T of a simple polygon P is characterized as follows : it consists of all edges of P together with some additional diagonals connecting pairs of vertices of P so that each interior angle of P becomes at least 90 degrees after adds these diagonals .It follows instantly that every edge belongs to one and only one diagonal of T . In 3 , Motzkin and Straus celebrated conjecture states that if D denotes the group of diagonals of a convex polygon Q then | D | = 2 | Q | .They also proved that the number of diagonalizations d ( P ) of a convex polygon P equals the number of diagonals of a triangulation of P . It was shown later 4 that the number of diagonals in a triangulation of a convex quadrilateral is equal to four times the quantity of diagonals needed to diagonalize the quadrilateral .Thus , the following issue arises readily : What is the relationship between the number of diagonals needed to diagonalize a convex quadrilateral and the proportion of diagonals used in a triangulation ?",
        "rewrite_text": "We investigate the connection between Catalan numbers and the various ways to represent a given triangulation as an ordered sequence of its diagonals, or, alternatively, as a set of non-crossing diagonals. This inquiry is linked to counting specific types of Dyck paths. In particular, we demonstrate that for any positive integer \\( n \\), there are exactly \\( C(n) \\) distinct sequences of diagonals that can be formed from a convex polygon with \\( 2n \\) sides. This finding extends a theorem by Motzkin and Straus regarding the diagonalizations of a convex polygon.\n\n**Introduction**: The Catalan numbers are known to enumerate a variety of combinatorial structures, including binary forests, non-crossing partitions, and covering trees (see references 1 and 2). The current study focuses on another category of Catalan-like configurations: the triangulations of polygons (refer to Figure 1). A triangulation \\( T \\) of a simple polygon \\( P \\) consists of all the edges of \\( P \\) plus some extra diagonals that connect pairs of vertices in such a way that every interior angle of \\( P \\) is at least 90 degrees after these diagonals are added. Consequently, every edge is involved in exactly one diagonal of \\( T \\). \n\nIn their celebrated conjecture, Motzkin and Straus asserted that if \\( D \\) denotes the set of diagonals of a convex polygon \\( Q \\), then \\( |D| = 2|Q| \\). They also established that the number of ways to diagonalize a convex polygon \\( P \\), denoted as \\( d(P) \\), equals the number of diagonals in a triangulation of \\( P \\). Further research has shown that the number of diagonals in a triangulation of a convex quadrilateral corresponds to four times the number of diagonals required to diagonalize that quadrilateral. This leads to an important question: What is the relationship between the number of diagonals necessary to diagonalize a convex quadrilateral and the proportion of those diagonals used in a triangulation?",
        "ori-fast-z-score": 0.9805806756909202,
        "water-fast-z-score": 5.5448262406693765,
        "rewrite-fast-z-score": 1.2809280616135812
    },
    {
        "original_text": "We present the results of an analysis of archival Hubble Space Telescope (HST) data for two open clusters, NGC 6705 and NGC 6819. We use these observations to determine ages, masses, radii, and distances for each star in both clusters using isochrone fitting techniques. The resulting mass functions are then compared with those predicted by theoretical models. Our main conclusions are:  1. Both clusters have similar age distributions but different mass distributions.  2. The observed mass function slopes agree well with predictions made by standard IMF theory when we assume that all stars more massive than 8 Msun were destroyed during supernovae explosions.  3. There appears to be no significant difference between the number of low-mass stars found within the central regions of the clusters as opposed to their outer regions. 4. The total number of high-mass stars in the clusters agrees very well with the expected number based on our knowledge of the initial mass function.",
        "watermark_text": "We present the conclusion of an assessment of archival Hubble Space Telescope ( HST ) statistics for two open complexes , NGC 6705 and NGC 6819 . We use these observations to predict ages , masses , radii , and distances for each star in both clusters using isochrone fit techniques .The resulting mass distributions are then compared with those predicted by theoretical theories . Our main results are : 1 .Both clusters have related age distributions but different mass distributions . 2 .The observed mass function slopes agree well with predictions making by normal IMF physics when we suppose that all stars more massive than 8 Msun were destroyed during supernovae explosions . 3 .There seems to be no major variation between the quantity of lowest - weight objects found within the inner regions of the clusters as opposed to their exterior areas . 4 .The total number of high - density stars in the clusters agrees very best with the expected number depending on our experience of the initial mass function .",
        "rewrite_text": "We present the findings from our assessment of archival Hubble Space Telescope (HST) data for the open clusters NGC 6705 and NGC 6819. Using these observations, we estimate the ages, masses, radii, and distances of each star within both clusters through isochrone fitting techniques. We then compare the resulting mass distributions with theoretical predictions. Our key conclusions are as follows: 1. Both clusters exhibit similar age distributions, yet their mass distributions differ. 2. The slopes of the observed mass functions align closely with predictions derived from standard initial mass function (IMF) theories, assuming that all stars exceeding 8 solar masses were lost during supernova explosions. 3. There is no significant difference in the number of low-mass objects found in the inner regions of the clusters compared to their outer areas. 4. The overall number of high-density stars in the clusters closely matches the expected figures based on our understanding of the initial mass function.",
        "ori-fast-z-score": -0.3418817293789138,
        "water-fast-z-score": 5.584068246522259,
        "rewrite-fast-z-score": -0.4472135954999579
    },
    {
        "original_text": "The origin and evolution of cosmic magnetic fields are one of the most important unsolved problems in astrophysics, which is closely related to many other fundamental issues such as star formation, galaxy formation and structure formation. In this talk I will review our recent work on simulating primordial magnetic fields with different physical processes involved. The first part focuses on the generation of seed magnetic fields during inflation by quantum fluctuations. We show that these seeds can be amplified significantly after reheating due to the magnetohydrodynamic turbulence driven by the decaying inflaton perturbations. Then we discuss how these seeds evolve into large-scale coherent magnetic fields through various mechanisms including inverse cascade, dynamo action and turbulent pumping. Finally, we present some possible observational signatures for future detection. This talk was given at the International Conference on Computation & Theory (ICCT) held in Beijing, China between September 24-27, 2014.",
        "watermark_text": "The origin and evolution of cosmic magnetic waves are one of the most important unsolved issues in astrophysics , which is closely related to many other fundamental issues such as galaxy formation , galaxy formation and shape formation . In this talk I will review our latest work on simulating primordial magnetic waves with various physical processes implicated .The first part involves on the generation of seed magnetic fields during inflation by quantum fluctuations . We suggest that these seeds can be amplified significantly after reheating due to the magnetohydrodynamic turbulence driven by the decaying inflaton perturbations .Then we explain how these seeds evolve into huge - scale coherent magnetic waves through several mechanisms namely inverse cascade , dynamo action and turbulent pumping . Finally , we present some possible observational signatures for future detection .This discussion was given at the International Conference on Computation & Theory ( ICCT ) holding in Beijing , China between September 24 - 27 , 2014 .",
        "rewrite_text": "The origin and evolution of cosmic magnetic waves represent one of the most significant unsolved problems in astrophysics, closely linked to other fundamental questions such as galaxy formation and the development of galactic structure. In this presentation, I will discuss our recent research on simulating primordial magnetic waves, incorporating various physical processes. The first part focuses on the generation of seed magnetic fields during inflation, driven by quantum fluctuations. We propose that these seed fields can undergo substantial amplification post-reheating due to magnetohydrodynamic turbulence resulting from decaying inflaton perturbations. Next, we describe how these seed fields evolve into large-scale coherent magnetic waves through several mechanisms, including inverse cascade, dynamo action, and turbulent pumping. Finally, I will outline potential observational signatures that could facilitate future detection of these phenomena. This discussion was presented at the International Conference on Computation & Theory (ICCT), held in Beijing, China, from September 24 to 27, 2014.",
        "ori-fast-z-score": 0.4923659639173309,
        "water-fast-z-score": 4.764608329895903,
        "rewrite-fast-z-score": 0.7071067811865476
    },
    {
        "original_text": "We study the ground-state properties of two-flavor color superconducting (2SC) quark matter at finite density and temperature by using an effective chiral model with vector interaction, which is derived from QCD under the mean-field approximation. We find that there exists a new type of 2SC phase where quarks are paired into diquark condensates with different colors but same flavor. This novel phase has been named as Larkin-Ovchinnikova-Fulde-Ferreell (LOFF) state because it was first proposed to describe superfluidity in nuclear systems. In this LOFF state, we show that the gap parameter for pairing between quarks with opposite momenta depends on their relative angle. The magnitude of the gap decreases rapidly when they move away from each other along the Fermi surface. As a result, the energy gap vanishes completely near the boundary of the Brillouin zone.",
        "watermark_text": "We research the ground - state properties of two - flavor color superconducting ( 2SC ) quark matter at finite density and heat by using an efficient chiral description with vector coupling , which is generated from QCD under the mean - field approximation . We see that there exists a new kind of 2SC phase where quarks are paired into diquark condensates with various shades but same flavor .This novel mode has been called as Larkin - Ovchinnikova - Fulde - Ferreell ( LOFF ) state because it was first suggested to explain superfluidity in nuclear systems . In this LOFF state , we find that the gap parameter for pairing between quarks with opposite momenta depends on their relative angle .The magnitude of the gap falls strongly when they go away from each other along the Fermi surface . As a result , the power gap vanishes totally near the boundary of the Brillouin zone .",
        "rewrite_text": "We investigate the ground-state properties of two-flavor color superconducting (2SC) quark matter at finite density and temperature using an efficient chiral description with vector coupling, derived from QCD under the mean-field approximation. Our findings reveal a novel type of 2SC phase in which quarks form diquark condensates that exhibit different orientations but share the same flavor. This intriguing state, referred to as the Larkin-Ovchinnikov-Fulde-Ferrell (LOFF) state, was initially proposed to account for superfluidity in nuclear systems. In the LOFF phase, we observe that the pairing gap between quarks with opposite momenta varies with their relative angle. Notably, the magnitude of the gap decreases significantly as the quarks move apart along the Fermi surface, ultimately vanishing completely near the edges of the Brillouin zone.",
        "ori-fast-z-score": -1.6924558427507104,
        "water-fast-z-score": 3.5151005964822444,
        "rewrite-fast-z-score": 0.6622661785325219
    },
    {
        "original_text": "We study the efficiency of cosmic ray (CR) acceleration by relativistic shocks using Monte Carlo simulations and analytical calculations. We find that, for strong shocks with Mach number M = 10 - 100, only about 1% CRs can be accelerated to ultra-high energy (UHE). This is because most particles are scattered back upstream before they gain enough energy to cross the shock front again. The low efficiency of UHE particle production leads to an upper limit on the maximum proton energy as well as the total CR luminosity produced by such shocks. Our results suggest that the observed fluxes of UHE protons cannot be explained solely by diffusive shock acceleration mechanism operating at cosmological shocks. However, our findings do not rule out other mechanisms proposed recently to explain the origin of UHE cosmic rays. \n \n Keywords: Cosmic Ray Acceleration, Diffusive Shock Acceleration, Relativistic Shocks",
        "watermark_text": "We research the performance of cosmic ray ( CR ) displacement by relativistic shocks using Monte Carlo simulations and mathematical calculations . We see that , for strong shocks with Mach number M = 10 - 100 , only about 1 % CRs can be enhanced to ultra - large energy ( UHE ) .This is because most grains are scattered backwards upstream before they get enough energy to pass the shock front again . The poor efficiency of UHE particle production gives to an upper limitation on the maximum proton power as well as the total CR luminosity generated by such shocks .Our results show that the known fluxes of UHE protons impossible be described solely by diffusive shock velocity process working at cosmological shocks . However , our findings do not leave out other mechanisms proposed lately to explain the origin of UHE cosmic rays .Keywords: Cosmic Ray Acceleration, Diffusive Shock Acceleration, Relativistic Shocks",
        "rewrite_text": "We investigate the efficiency of cosmic ray (CR) displacement induced by relativistic shocks through Monte Carlo simulations and mathematical analyses. Our findings indicate that, for strong shocks with Mach numbers ranging from 10 to 100, only about 1% of cosmic rays can achieve ultra-high energy (UHE). This limited enhancement occurs because most particles are redirected upstream before they accumulate sufficient energy to traverse the shock front a second time. Consequently, the low efficiency of UHE particle production imposes an upper limit on both the maximum proton power and the total CR luminosity generated by these shocks. Our results suggest that the observed fluxes of UHE protons cannot be solely accounted for by the diffusive shock acceleration process occurring at cosmological shocks. Nevertheless, our conclusions do not dismiss other recently proposed mechanisms that seek to explain the origin of UHE cosmic rays. \n\nKeywords: Cosmic Ray Acceleration, Diffusive Shock Acceleration, Relativistic Shocks",
        "ori-fast-z-score": -1.721892064184557,
        "water-fast-z-score": 5.430582663966679,
        "rewrite-fast-z-score": -0.2581988897471611
    }
]