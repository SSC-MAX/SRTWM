[
    {
        "original_text": "The assembly history of galaxies is one of the most important open questions in modern astrophysics, and it has been studied extensively using deep surveys at different wavelengths (e.g., optical/near-infrared). In this work we present an analysis of the stellar mass assembly for a sample of more than 100 000 massive galaxies selected from the VVDS-02h field observed with the VIMOS spectrograph on board of the Very Large Telescope between 0 < z < 5. We use a novel technique based on the combination of photometric redshifts and spectral energy distribution fitting to derive accurate estimates of galaxy masses over such large redshift range. Our results show that the evolution of the average stellar mass density can be described by two main phases: i) a rapid increase up to z ~ 2 followed by ii) a slower growth phase until today. This behaviour is consistent with previous studies but our data allow us to study in detail how the build-up of stellar mass proceeds as a function of galaxy properties like colour or morphology.",
        "watermark_text": "The assembly history of galaxies is one of the most important open questions in modern astrophysics, and it has been studied extensively using deep surveys at different wavelengths ( e. g., optical / nearly - infrared ).In this work we present an analysis of the star mass assembly for a sample of more than 100 thousand massive galaxies selected from the VVDS - 02h field observed with the VIMOS spectrograph on board of the Very Large Telescope between zero < z < 5.We use a new technique based on the combination of photometric redshifts and spectral energy distribution fitting to derive accurate estimates of galaxy masses over such large redshift range.Our results show that the evolution of the average stellar mass density can be described by 2 main stages : i ) a fast increase up to z ~ 2 followed by ii ) a slower growth stage until today.This behaviour is consistent with previous studies but our data allow us to study in detail how the build - up of stellar mass proceeds as a function of galaxy properties like colour or morphology."
    },
    {
        "original_text": "We consider a spherically symmetric solution to Einstein's equations in five dimensions with an extra dimension compactified on S 1 /Z 2 . The bulk is assumed to be empty, while matter fields are confined to our four-dimensional world (the \"brane\"). We find that this model can explain the observed flatness of galactic rotation curves without introducing any new particles or exotic forms of energy density. In particular we show how the mass distribution within galaxies may arise naturally as a consequence of the geometry of space-time. This work was supported by NSF grant PHY-0456728. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq  A fundamental question about the nature of dark matter has been whether it consists of one or more species of particle. If so, what are their masses? What interactions do they have with ordinary matter? How much dark matter does each galaxy contain? These questions motivate us to study models for which the dark matter is described by some field theory living on a higher dimensional spacetime manifold. \n \n Here we will focus on a class of solutions where the extra dimension is compactified on a circle $S^1$. Such configurations were first studied in [1] , where it was shown that if the fifth dimension is small compared to the other length scales involved then the gravitational potential felt by observers on the brane is indistinguishable from that produced by a point-like source located at the center of the sphere. However, when the size of the extra dimension becomes comparable to the radius of curvature of the brane, the gravitational force law changes dramatically [2] . \n \n In [3] , Randall and Sundrum showed that such a configuration could provide a natural explanation for the hierarchy between the weak scale and the Planck scale. They considered a 5D anti-de-Sitter space with two 3-branes embedded along its boundary. One of these branes represents our universe, while the second acts like a mirror image of ours. Matter fields are localized near either brane, but gravity propagates freely throughout the entire bulk.",
        "watermark_text": "We consider a spherically symmetric solution to Einstein ' s equations in 5 dimensions with an extra dimension compactified on S 1 / Z 2.The bulk is assumed to be empty, while matter fields are confined to our four - dimensions world ( the \" brane \" ).We find that this model can explain the observed flatness of galactic rotation curves without introducing any new particles or exotic forms of energetic density.In particular we show how the mass distribution within galaxies may arise naturally as a consequence of the geometry of space - time.This work was supported by NSF grant PHY - 0456728.PACS numbers : 04. 20. - q, 11. 10. - z, 98. 80. CqA fundamental question about the nature of dark matter has been whether it consists of one or more species of particle.If so, what are their masses?What interactions do they have with ordinary matter?How much dark matter does each galaxy hold?These questions motivate us to research models for which the dark matter is described by some field theory living on a higher dimensional spacetime manifold.Here we will focus on a class of solutions where the extra dimensional is compactified on a circular $ S ^ 1 $. Such configurations were first studied in [ 1 ], where it was shown that if the 5th dimension is small compared to the other length scales involved then the gravitational potential felt by observers on the brane is indistinguishable from that produced by a point - like source located at the center of the sphere.However, when the size of the extra dimension becomes comparable to the radius of curvature of the brane, the gravitational force law switches dramatically [ 2 ].In [ 3 ], Randall and Sundrum showed that such a configuration might provide a natural explanation for the hierarchy between the weak scale and the Planck term.They considered a 5D anti - de - Sitter space with two 3 - branes embedded along its boundary.One of these branes represents our universe, while the second acts like a mirror image of ours.Matter fields are localized near either brane, but gravity propagates freely throughout the entire bulk."
    },
    {
        "original_text": "We have investigated whether pulsar timing observations can be used to detect gravitational waves by observing the Shapiro effect, which is caused by the passage of gravitational waves through space-time around the Earth and its companion star (the Sun). We find that this method will not work with current technology because it requires very accurate measurements of pulse arrival times over many years. However, we show how future radio telescopes could make such measurements if they are equipped with new technologies like phased-array feeds or digital backends. In addition, we discuss other possible methods using pulsar timing data to search for gravitational waves. Gravitational waves cause time delays between pulses emitted at different points on the surface of a rotating neutron star. These time delays depend on the distance between these points as well as their position relative to the line-of-sight towards the observer. The most prominent effects occur when the wave passes close to the Earth and its companion stars. This causes an additional delay known as the Shapiro effect [Shapiro 1964] . If one knows the positions of all pulsars within a globular cluster, then one can use the observed pulse arrival times to measure the distances between them. By comparing these measured distances with those predicted by general relativity, one can test whether Einstein's theory correctly describes gravity on large scales.",
        "watermark_text": "We have investigated whether pulsar timing observations can be used to observe gravitational waves by observing the Shapiro effect, which is caused by the passing of gravitational waves through space - time around the Earth and its companion star ( the Sun ).We find that this method will not work with current technology because it demands very accuracy measurements of pulse arrival times over many years.However, we show how future radio telescopes could make such measurements if they are fitted with new technologies including phased - array feeds or digital backends.In addition, we talk other possible methods using pulsar timing data to hunt for gravitational waves.Gravitational waves cause time delays between pulses emitted at different points on the surface of a rotating neutron star.These time delays depend on the distance between these points as also as their position relative to the line - of - sight towards the observer.The most prominent effects occur when the wave passes close to the Earth and its companion stars.This causes an additional delay known as the Shapiro effect[ Shapiro 1964 ].If one knows the positions of all pulsars within a globular cluster, then one can use the observed pulse arrival times to measure the distances between them.By comparing these measured distances with those predicted by general relativity, one can test whether Einstein ' s theory correctly describes gravitational on large scales."
    },
    {
        "original_text": "The measurement was performed at the Cyclotrons and Accelerators Laboratory (CYCLONE) in JINR, Dubna using the proton beam with energy E = 1 GeV. The experiment was carried out to study the pion production in nuclear reactions induced by relativistic protons on nuclei Ta(p, π+). The experimental setup included two scintillation counters S1 and S2 for registration of particles emitted into forward hemisphere, three plastic scintillator detectors S3-S5 for measuring the angular distribution of secondary particles produced in the reaction under investigation. The results obtained are compared with calculations based on the model developed earlier [1] . \nIntroduction\n\nPion production is one of the most important processes in hadronic interactions which play an essential role in many fields such as astrophysics [2] , cosmic ray physics [3] , accelerator technology [4] etc.. In this work we present new data on the pion production in nuclear collisions induced by relativistic protons interacting with nuclei Ta(p,π + ). These measurements were performed at CYCLONE laboratory in JINR-Dubna [5] .\nExperimental Setup\nThe experimental setup used in our experiments consisted of:  -two scintillation counters S1 and S2; -three plastic scintillator detectors; -a set of collimators; -the target made of natural tantalum foil 0.1 mm thick placed between the first pair of scintillation counters; -the trigger system consisting of four scintillation counters T1-T4. \nThe layout of the experimental setup is shown schematically in Fig. 1 . The main parameters of the detector system are listed in Table I . The signals from all detectors were recorded by means of CAMAC modules [6] .",
        "watermark_text": "The measurement was performed at the Cyclotrons and Accelerators Laboratory ( CYCLONE ) in JINR, Dubna using the proton beam with energetic E = 1 GeV.The experiment was carried out to study the pion producing in nuclear reactions induced by relativistic protons on nuclei Ta ( p, π + ).The experimental setup included two scintillation counters S1 and S2 for registration of particles emission into forward hemisphere, 3 plastic scintillator detections S3 - S5 for measuring the angular distribution of secondary ones produced in the reaction under investigation.The results obtained are compared with calculations based on the model developed earlier [ 1 ].Introduction Pion production is one of the most significant processes in hadronic interactions which play an essential role in many fields such as astrophysics[ 2 ], cosmic ray physics[ 3 ], accelerator technology[ 4 ] etc.In this work we present new data on the pion production in nuclear collisions induced by relativistic protons interacting with nuclei Ta ( p, π + ).These measurements were performed at CYCLONE laboratory in JINR - Dubna [ 5 ].Experimental SetupThe experimental setup used in our experiments consisted of : - two scintillation counters S1 and S2 ; - three plastic scintillator detectors ; - a set of collimators ; - the target made of natural tantalum foil 0. 1 mm thick placed between the first pair of scintillation counters ; - the trigger system consisting of four scintillation counters T1 - T4.The layout of the experiment setup is shown schematically in Fig.1.The main parameters of the detection system are listed in Table I.The signals from all detectors were recorded by means of CAMAC modules [ 6 ]."
    },
    {
        "original_text": "We present an analytical approach to study the dynamics of the contact process on complex networks with arbitrary degree distributions, including scale-free (SF) ones. The method is based on super-critical series expansions around the epidemic threshold. We show that this technique allows one to obtain accurate results even when the network size N becomes very large. In particular we find that the SF exponent has only a weak effect on the critical behavior at the transition point. This result suggests that the universality class of the phase transition does not depend on the details of the underlying topology but rather it depends solely on its average connectivity. Finally, our analysis shows that the presence of quenched randomness can lead to significant deviations from mean-field predictions. \nI. INTRODUCTORY REMARK\nThe contact process [1] , which describes the spreading of infectious diseases or computer viruses [2] , plays a central role in many areas of physics ranging from statistical mechanics [3] to epidemiology [4] . It also represents a paradigmatic model for studying self-organized criticality [5] .\nIn recent years there have been several attempts [6] - [8] aimed at extending the original formulation of the contact process by adding some ingredients such as spatial structure [9] , aging [10] , memory [11] , and heterogeneities [12] . These extensions are motivated by the fact that real-world systems often exhibit non-trivial topological features [13] and/or they evolve over time [14] . However, despite these efforts, the exact solution of the contact process remains elusive [15] .\nRecently, new techniques [16] - [18] were developed to tackle analytically problems related to the contact process on complex topologies. Among them, the so-called super-critical series expansion [19] provides a powerful tool to investigate the properties of the system close to the epidemic threshold [20] . Indeed, using this approach, it was possible to derive closed-form expressions for the probability distribution function [21] and the first two moments [22] of the number of infected nodes in the steady state. Moreover, it allowed us to determine the scaling laws characterizing the relaxation towards equilibrium [23] .",
        "watermark_text": "We present an analytical approach to study the dynamics of the contact process on complex networks with arbitrary degree distributions, including scale - free ( SF ) ones.The method is based on super - critical series expansions round the epidemic threshold.We show that this technique permits one to obtain accurate outcomes even when the network size N gets very big.In particular we find that the SF exponent has only a weak effect on the critical behaviour at the transition point.This result suggests that the universality class of the phase transition does not depend on the details of the underlying topology but instead it relies solely on its average connectivity.Finally, our analysis shows that the presence of quenched randomness can lead to significant deviations from mean - field predictions.I. INTRODUCTORY REMARK The contact process[ 1 ], which describes the spreading of infectious diseases or computer viruses [ 2 ], plays a central role in many areas of physics ranging from statistical mechanics [ 3 ] to epidemiology [ 4 ].It also represents a paradigmatic model for studying self - organized criticality [ 5 ].In recent years there have been several attempts [ 6 ] -[ 8 ] aimed at extending the original formulation of the contact process by adding some ingredients such as spatial structure [ 9 ], aging [ 10 ], memory [ 11 ], and heterogeneities[ 12 ].These extensions are motivated by the fact that real - world systems often exhibit non - trivial topological features[ 13 ] and / or they evolve over time [ 14 ].However, despite these efforts, the exact solution of the contact procedure remains elusive [ 15 ].Recently, new techniques [ 16 ] - [ 18 ] were developed to tackle analytically problems related to the contact process on complex topologies.Among them, the so - called super - critical series expansion [ 19 ] provides a potent tool to investigate the properties of the system near to the epidemic threshold[ 20 ].Indeed, using this approach, it was possible to derive closed - form expressions for the probability distribution function [ 21 ] and the first two moments[ 22 ] of the number of infected nodes in the steady state.Moreover, it permitted us to determine the scaling laws characterizing the relaxation towards equilibrium[ 23 ]."
    },
    {
        "original_text": "We study the thermal effects of rotation on random classical zero-point radiation (ZPR) by using the canonical ensemble method and the Wigner distribution function. We find that, for an isolated system with angular momentum J = 0, there is no temperature effect due to ZPR; however, when J > 0, the rotational energy increases as T4 at high temperatures. This result agrees well with previous studies based on quantum mechanics. In addition, we show that the total entropy S(T ) decreases monotonically with increasing temperature T . The results are also compared with those obtained via the density matrix formalism. Finally, we discuss some possible applications of our findings. PACS: 03.65.Ud, 05.45.Mt, 11.10.Gh, 12.20.Gv \nI. INTRODUCTIO N\nClassical zero-point radiation (Z PR), which was first introduced by Planck [1] , has been studied extensively over many years [2] - [4] . It describes the vacuum fluctuations of electromagnetic fields [5] . Recently, it has attracted renewed interest because of its potential application in various areas such as astrophysics [6] , cosmology [7] , condensed matter physics [8] , and quantum optics [9] .\nIn this work, we consider the thermal effects of rotation induced by ZPR on an isolated system. To do so, we use the canonical ensemble method [10] and the Wigner distribution [11] . Our main finding is that, for an isolated sys tem with angular mo mentum J = 0, there exists no temperature ef fect due to ZPR; how ever, whe n J > 0, th e rota tional en erg y incr eas es as T 4 at h igh te mperatures. Th ese res ults agree w ell wit h pre viou s stu dies based o n qu ant um me chani cs [12] . In addi tion, we sh ow tha t th e tota l ent ro py S(T ) decr eases monotoni cally wi th inc reasin g temperatu re T . Th e resul",
        "watermark_text": "We study the thermal effects of rotation on randomly classical zero - point radiation ( ZPR ) by using the canonical ensemble method and the Wigner distribution function.We find that, for an enclosed system with angular momentum J = 0, there is no temperature affect due to ZPR ; however, when J > 0, the rotational energy increases as T4 at high temperatures.This result agrees well with previous studies based on quantum mechanics.In addition, we show that the total entropy S ( T ) decreases monotonically with increasing temperature T.The results are also compared with those achieved via the density matrix formalism.Finally, we discuss some possible applications of our findings.PACS : 03. 65. Ud, 05. 45. Mt, 11. 10. Gh, 12. 20. Gv I. INTRODUCTIO N Classical zero - point radiation ( Z PR ), which was first introduced by Planck[ 1 ], has been studied extensively over many years[ 2 ] - [ 4 ].It describes the vacuum fluctuations of electromagnetic fields[ 5 ].Recently, it has attracted renewed interest because of its potential application in various applications such as astrophysics[ 6 ], cosmology[ 7 ], condensed matter physics[ 8 ], and quantum optics[ 9 ].In this work, we consider the thermal effects of rotation induced by ZPR on an isolated system.To do so, we use the canonical ensemble method[ 10 ] and the Wigner distribution[ 11 ].Our main finding is that, for an isolated sys tem with angular mo mentum J = zero, there exists no temperature ef fect due to ZPR ; how ever, whe n J > 0, th e rota tional en erg y incr eas es as T 4 at h igh te mperatures.Th ese res ults agree w ell wit h pre viou s stu dies based o n qu ant um me chani cs[ 12 ].In addi tion, we sh ow tha t th e tota l ent ro py S ( T ) decr eases monotoni cally wi th inc reasin g temperatu re T.Th e resul"
    },
    {
        "original_text": "The gamma ray emission in the energy range 100 MeV to 10 GeV is studied using data taken by EGRET on board CGRO during its first four years of operation (1991) (1992) (1993) (1994) . The analysis has been performed for two different regions, one centered at l = 0° and b = - 5° , which includes the galactic centre region, and another centered at l = 180° and b = + 5° . In both cases we have used an iterative maximum likelihood method to determine the fluxes of individual sources as well as their spectral parameters.  We find that there are three distinct components contributing to the observed gamma-ray flux above 1 GeV :  A diffuse component with a power law spectrum extending upto ~10 GeV .\nA point source located near Sgr A* with a power law spectrum .\nAn extended source towards the galactic center with a broken power law spectrum . \nWe also present results obtained when the same analysis was repeated after excluding the contribution due to the central part of the Galaxy .",
        "watermark_text": "The gamma ray emission in the energy range 100 MeV to 10 GeV is studied using data taken by EGRET on board CGRO during its 1st four years of operation ( 1991 ) ( 1992 ) ( 1993 ) ( 1994 ).The analysis has been performed for two different regions, one centred at l = 0° and b = - 5°, which includes the galactic centre region, and another centered at l = 180° and b = + 5°.In both cases we have used an iterative maximum likelihood method to determine the fluxes of individual sources as well as their spectrum parameters.We find that there are 3 distinct components contributing to the observed gamma - ray flux above 1 GeV : A diffuse component with a power law spectrum extending upto ~ 10 GeV.A point source located near Sgr A * with a power law spectrum.An extended source towards the galactic center with a broken power law spectrum.We also present results obtained when the same analysis was repeated after excluding the contributor due to the central part of the Galaxy."
    },
    {
        "original_text": "We study the electrical excitation of nonlinear waves in a 2D channel with an applied voltage bias between two parallel metal plates separated by a dielectric layer. We show that, depending on the parameters of the system (the thickness of the dielectric layer, the density of electrons), different types of nonlinear waves can be excited. In particular, we find that for certain values of these parameters solitary wave solutions exist which are similar to those found earlier in 1D systems. \n \n The existence of such solitary waves is confirmed experimentally using time-resolved optical reflectivity measurements performed at room temperature on samples consisting of GaAs/AlGaAs quantum wells grown by molecular beam epitaxy. These experiments reveal the presence of bright solitary waves propagating along the direction perpendicular to the applied electric field. Their propagation velocities agree well with theoretical predictions based on numerical simulations of the underlying equations. \nThe results presented here may have important applications in semiconductor devices where it has been shown recently that the generation of solitary waves leads to improved performance characteristics.",
        "watermark_text": "We study the electrical excitation of nonlinear waves in a 2D channel with an applied voltage bias between 2 parallel metal plates separated by a dielectric layer.We show that, depending on the parameters of the system ( the thickness of the dielectric layer, the density of electrons ), different types of nonlinear waves can be excited.In particular, we find that for certain values of these parameters solitary wave solutions exist which are similarly to those found earlier in 1D systems.The existence of such solitary waves is confirmed experimentally via time - resolution optical reflectivity measurements performed at room temperature on samples consisting of GaAs / AlGaAs quantum wells grown by molecule beam epitaxy.These experiments reveal the presence of bright solitary waves propagating along the direction perpendicular to the applied electric field.Their propagation velocities agree well with theoretical expectations based on numerical simulations of the underlying equations.The results presented here may have important applications in semiconductor devices where it has been shown recently that the generation of lone waves leads to improved performance characteristics."
    },
    {
        "original_text": "A slide-o-cam transmission is an alternative to conventional geared transmissions in which the input and output shafts are connected by means of cams that rotate on their own axes, with no gears or other mechanical elements between them.  The main advantages of this type of transmission are:  • No backlash due to tooth meshing; • High efficiency (up to 98%); • Low noise levels; • Reduced weight and volume compared to traditional gearboxes; • Easy assembly and disassembly; • Possibility of using different types of motors as inputs. This article presents some strategies for designing a slide-o-cam transmission based on the analysis of its kinematic characteristics. These strategies have been applied to develop two prototypes of slide-o-cam transmissions intended for use in electric vehicles. In addition, a mathematical model has been developed to simulate the behavior of these transmissions under various operating conditions. Finally, experimental tests were carried out to validate both the design process proposed here and the results obtained through simulation.",
        "watermark_text": "A slide - o - cam transmission is an alternative to conventional geared transmissions in which the input and output shafts are linked by means of cams that rotate on their own axes, with no gears or other mechanical elements between them.The main advantages of this type of transmission are : •No backlash due to tooth meshing ; • High efficiency ( up to 98 % ) ; • Low noise levels ; • Reduced weight and volume compared to traditional gearboxes ; • Easy assembly and disassembly ; • Possibility of using different types of motors as inputs.This article presents some strategies for designing a slide - o - cam transmission based on the analysis of its kinematic traits.These strategies have been applied to develop 2 prototypes of slide - o - cam transmissions intended for use in electric vehicles.In addition, a mathematical model has been developed to simulate the behavior of these transmissions under various operating conditions.Finally, experimental tests were carried out to validate both the design procedure proposed here and the results obtained through simulation."
    },
    {
        "original_text": "We present the results of our analysis of the effects of cosmic rays on galaxy clusters, using cosmological hydrodynamic simulations with and without CRs. We find that the presence of CRs leads to an increase in gas temperature at large radii (r > 0.5Rvir) due to adiabatic compression of the ICM during cluster formation. The effect is more pronounced for higher values of the initial magnetic field strength. In addition we find that there are significant differences between the radial profiles of X-ray surface brightness obtained with and without CRs which can be used as observational signatures of their presence. Finally, we show that the inclusion of CRs has little impact on the global properties such as total mass or luminosity but does affect the distribution of metals within the cluster. This work was supported by NASA grant NAG5-9998. Cosmological hydrodynamical simulations were performed using Enzo developed by the Laboratory for Computational Astrophysics at the University of California, San Diego.",
        "watermark_text": "We present the results of our analysis of the effects of cosmic rays on galaxy clusters, using cosmological hydrodynamic simulations with and without CRs.We find that the presence of CRs leads to an increase in gas heat at large radii ( r > 0. 5Rvir ) due to adiabatic compression of the ICM during cluster formation.The effect is more pronounced for higher values of the early magnetic field strength.In addition we find that there are significant differences between the radial profiles of X - ray surface brightness obtained with and lacking CRs which can be used as observational signatures of their presence.Finally, we show that the inclusion of CRs has little impact on the global properties such as total mass or luminosity but does affect the distribution of metals within the cluster.This work was supported by NASA grant NAG5 - 9998.Cosmological hydrodynamical simulations were performed utilizing Enzo developed by the Laboratory for Computational Astrophysics at the University of California, San Diego."
    },
    {
        "original_text": "In this thesis, we study power control problems in cellular mobile radio systems with code division multiple access (CDMA). We consider the uplink scenario where each user transmits to its base station using an orthogonal spreading sequence and all users share the same frequency band. The objective is to minimize the total transmit power subject to individual quality-of-service constraints at each user's receiver. In order to obtain tractable results, we make use of tools from stochastic geometry which allow us to model the locations of both mobiles and interferers as point processes. Our main contributions are summarized below.  First, we derive closed-form expressions for the outage probability when the number of active users grows without bound. These expressions can be used to determine how many users can simultaneously communicate reliably over the network. Second, we propose distributed power control schemes that achieve these limits asymptotically under certain conditions. Third, we develop centralized power control algorithms that guarantee performance close to optimality even if only partial information about the channel gains or interference levels is available. Finally, we present simulation results illustrating our theoretical findings.",
        "watermark_text": "In this thesis, we study power control problems in cell mobile radio systems with code division multiple access ( CDMA ).We consider the uplink scenario where each user transmits to its base station using an orthogonal spreading sequence and all users share the same frequency frequency.The objective is to minimize the total transmit power subject to individual quality - of - service constraints at each user ' s receiver.In order to obtain tractable results, we make use of tools from stochastic geometry which allow us to model the sites of both mobiles and interferers as point processes.Our main contributions are summarized below.First, we derive closed - form expressions for the outage probability when the number of active uses grows without bound.These expressions can be used to determine how many users can simultaneously communicate reliably over the net.Second, we propose distributed power control schemes that accomplish these limits asymptotically under certain terms.Third, we develop centralized power control algorithms that guarantee performance close to optimality even if only partial information about the channel gains or interfering levels is available.Finally, we present simulation results illustrating our theory findings."
    },
    {
        "original_text": "The calibration and data products for GALEX are described in this document, which is intended to be used by astronomers who wish to use these data sets.  The main focus of this document is on describing how to obtain calibrated images (i.e., fluxes) from raw data files produced by GALEX's instruments.   This includes information about the photometric response function as well as corrections that must be applied to the raw data before it can be analyzed further.   ... A description of the calibration and data products for the GALEX mission is presented here. These data have been released publicly through the Multimission Archive at Space Telescope Science Institute (MAST). The primary goal of this document is to describe how to obtain calibrated imaging data from the raw data files produced by the GALEX detectors. In addition, we provide details regarding the photometric response functions and other corrections necessary to produce accurate results when analyzing the data.",
        "watermark_text": "The calibration and data products for GALEX are described in this document, which is intended to be used by astronomers who wish to utilize these data sets.The main focus of this document is on describing how to obtain calibrated imagery ( i. e., fluxes ) from source data files production by GALEX ' s instruments.This includes information about the photometric response function as well as corrections that must be applicable to the raw data before it can be analysis further..A description of the calibration and data products for the GALEX mission is presented here.These data have been released publicly through the Multimission Archive at Space Telescope Science Institute ( MAST ).The primary goal of this document is to describe how to get calibrated imaging data from the raw data files produced by the GALEX detectors.In addition, we give details regarding the photometric response functions and other corrections necessary to produce accurate results when analyzing the data."
    },
    {
        "original_text": "Fullerenes are spherical molecules composed entirely of sp2-hybridized carbons, which can be arranged in different ways to form various allotropes with unique properties. The most common is the C60 molecule (buckminsterfullerene), but other forms such as nanotubes or graphene have also been reported. Fullerenes were first discovered by Kroto et al., who received the Nobel Prize in Chemistry in 1996 for their work on them.  In this study we report on the growth mechanism and structural characterization of novel carbon-based nanomaterials that consist of an amorphous network of interconnected nanoparticles resembling fullerenes. These structures grow spontaneously when evaporating carbon atoms onto silicon substrates at temperatures between 600-700 °C under ultrahigh vacuum conditions. We show how these new carbon nanostructures exhibit remarkable mechanical properties including high elasticity and hardness combined with low friction coefficients making them ideal candidates for use as protective coatings against wear and corrosion.",
        "watermark_text": "Fullerenes are spherical molecules composed entirely of sp2 - hybridized carbons, which can be arranged in different ways to form various allotropes with unique properties.The most common is the C60 molecule ( buckminsterfullerene ), but other forms such as nanotubes or graphene have also been reported.Fullerenes were first discovered by Kroto et al., who received the Nobel Prize in Chemical in 1996 for their work on them.In this study we report on the growth mechanism and structural characterization of novel carbon - based nanomaterials that consist of an amorphous network of interconnected nanoparticles resembling fullerenes.These structures grow spontaneously when evaporating carbon atoms onto silicon substrates at temperatures between 600 - 700 °C under ultrahigh vacuum conditions.We show how these newly carbon nanostructures exhibit remarkable mechanical properties including high elasticity and hardness combined with low friction coefficients making them ideal candidates for use as protective coatings against wear and corrosion."
    },
    {
        "original_text": "We present an algorithm for consistent hypothesis testing in which we consider all possible hypotheses that are compatible with some given set of observations, and select those that maximize their posterior probability according to Bayes' theorem.  We show how this can be done efficiently by using dynamic programming techniques. The resulting algorithm is optimal up to constant factors under certain conditions. Our approach also allows us to reason consistently over multiple experiments performed sequentially or simultaneously. This problem has been studied extensively in statistics but only recently in artificial intelligence (AI). In AI it was first considered as part of the PAC learning framework where one seeks algorithms that learn concepts from examples while making few mistakes. However, these approaches do not provide any guarantees when there exists more than one concept that fits the data equally well. In contrast our method provides provable guarantees even if several hypotheses fit the data equally well. Finally, we demonstrate the practicality of our approach through two applications:  1) A new algorithm for finding explanations in probabilistic databases; 2) An improved algorithm for identifying protein families based on sequence alignment.",
        "watermark_text": "We present an algorithm for consistent hypothesis testing in which we consider all possible hypotheses that are compatible with some given group of observations, and select those that maximize their posterior probability according to Bayes ' theorem.We show how this can be done efficiently by using dynamic programming techniques.The resulting algorithm is optimal up to continuous factors under certain conditions.Our approach also allows us to reason consistently over multiple experimentation performed sequentially or simultaneously.This problem has been considered extensively in statistics but only recently in artificial intelligence ( AI ).In AI it was first considered as part of the PAC learning setting where one seeks algorithms that learn concepts from examples while making few mistakes.However, these approaches do not provide any guarantees when there exists more than one concept that suits the data evenly well.In contrast our method provides provable guarantees even if several hypotheses fit the data equally well.Finally, we demonstrate the practicality of our approach through two applications : 1 )A new algorithm for discovering explanations in probabilistic databases ; 2 ) An improved algorithm for identifying protein families based on sequence alignment."
    },
    {
        "original_text": "We present the results of our analysis on the time-averaged spectrum and light curve of GRB 090902B, which is one of the brightest bursts ever detected by Fermi/GBM (Gamma-ray Burst Monitor). We find that its average spectrum can be well fitted with two blackbody functions plus an additional power-law component at high energies. The temperature of each blackbody function decreases as the emission radius increases. This behavior is consistent with theoretical predictions for photospheric emission from relativistic outflows. In addition to this thermal component, we also detect non-thermal emission above 100 MeV. Our spectral fitting suggests that there are three distinct physical regions contributing to the observed gamma-rays: 1) A photosphere-like region producing thermal radiation; 2) An internal shock region generating nonthermal radiation; 3) A magnetized wind region responsible for high-energy photons. These findings provide new insights into the physics of GRBs. \n \n Keywords: Black body, Photon index, Power law",
        "watermark_text": "We present the results of our analysis on the time - averaged spectrum and light curve of GRB 090902B, which is one of the brightest bursts ever detected by Fermi / GBM ( Gamma - ray Burst Monitor ).We find that its average spectrum can be well fitted with 2 blackbody functions plus an additional power - law component at high energies.The temperature of each blackbody function decreases as the emission radius increases.This behavior is consistent with theoretical expectations for photospheric emission from relativistic outflows.In addition to this thermal component, we also detect non - heat emission above 100 MeV.Our spectral fitting suggests that there are 3 distinct physical regions contributing to the observed gamma - radiation : 1 ) A photosphere - like region producing thermal phenomena ; 2 ) An internal shock region generating nonthermal radiation ; three ) An magnetized wind region responsible for high - energy photons.These findings provide new insights into the physics of GRBs.Keywords : Black body, Photon index, Power law"
    },
    {
        "original_text": "We study the statistical properties of Barkhausen noise generated by an Ising spin system with random fields and competing interactions at its surface, using wavelets to analyze the time series produced by this model.  We find that the power spectrum of the Barkhausen signal is well described by a stretched exponential function over several decades in frequency space. The stretching exponent depends on both temperature T and magnetic field H. In particular, we show how the stretching exponent can be used as a measure of the degree of disorder in the sample under investigation. Finally, we discuss possible extensions of our work to other types of systems exhibiting avalanche dynamics. Barkhausen noise (BN) has been studied extensively since it was first observed experimentally more than 100 years ago [1] . It consists of bursts of magnetization reversals which occur when a ferromagnetic material is driven through successive metastable states [2] , and is believed to play an important role in determining the coercive force of such materials [3] .\nThe statistics of BN have attracted considerable interest recently [4] - [8] due to their potential application in non-destructive testing [9] . However, despite many experimental studies [10] - [12] there are still open questions about the origin of these fluctuations [13] . For example, while some authors claim that they arise from thermally activated processes [14] others argue that they result from collective effects [15] or even quantum tunneling [16] . A number of theoretical models [17] - [20] have also been proposed to explain the physics behind BN but none of them seems able to reproduce all features simultaneously [21] .",
        "watermark_text": "We study the statistical properties of Barkhausen noise generated by an Ising spin system with randomly fields and competing interactions at its surface, using wavelets to analyze the time series produced by this model.We find that the power spectrum of the Barkhausen signal is good described by a stretched exponential function over several decades in frequency space.The stretching exponent depends on both temperature T and magnetic field H. In particular, we show how the stretching exponent can be utilized as a measure of the degree of disorder in the specimen under investigation.Finally, we discuss potential extensions of our work to other types of systems exhibiting avalanche dynamics.Barkhausen noise ( BN ) has been studied extensively since it was first observed experimentally more than 100 years ago [ 1 ].It consists of bursts of magnetization reversals which occur when a ferromagnetic material is driven through succeeding metastable states[ 2 ], and is believed to play an important role in determining the coercive force of such materials [ 3 ].The statistics of BN have aroused considerable interest lately [ 4 ] -[ 8 ] due to their potential application in non - destructive testing [ 9 ].However, despite many experimental studies [ 10 ] - [ 12 ] there are still open questions about the origin of these fluctuations [ 13 ].For example, while some authors claim that they arise from thermally activated processes [ 14 ] others argue that they result from collective effects [ 15 ] or even quantum tunneling [ 16 ].A number of theoretical models [ 17 ] - [ 20 ] have additionally been proposed to explanation the physics behind BN but none of them seems able to reproduce all features simultaneously [ 21 ]."
    },
    {
        "original_text": "We study the spectrum statistics of random matrices with entries given by the sum over all paths in an infinite tree, which is obtained as a limit of finite rank deformations of large Wigner matrices. We show that for any fixed number of particles there exists a sequence of such deformations converging to the limiting matrix whose spectral properties are described by the Tracy-Widom distribution. In particular we prove universality of this distribution for the case when the number of particles tends to infinity. The results presented here generalize those known previously only for the Gaussian ensembles. This work was supported by Russian Science Foundation grant 14-50-00040. 1 Introduction.\nThe problem of statistical description of the energy levels of complex quantum systems has been studied extensively during last decades (see e.g., [1] ). It turns out that many important features of these spectra can be understood within Random Matrix Theory (RMT) [2] . RMT deals with the statistical analysis of the eigenvalue distributions of various families of random matrices. One of the most popular models considered in RMT is the so-called Wigner ensemble [3] , where one considers N ×N Hermitian matrices H = H † with independent identically distributed elements h ij having mean zero and variance 1/N . For example, if the probability density function p(h) of each element h ij decays fast enough at |h| → ∞ then it follows from the standard arguments [4] that the empirical measure µ N of the normalized eigenvectors of H converges weakly almost surely to some deterministic probability measure µ on the unit circle T = {z ∈ C : |z| = 1} called circular law. Moreover, under additional assumptions about the decay rate of p(h), the Stieltjes transform m N (z) := E TrH − z −1 of µ N converges pointwise almost surely to the Stieltjes transform M (z) of µ [5] .\nIn recent years much attention has been paid to the investigation of the local behavior of the spectrum near its edge [6] - [8] . In particular, it turned out [9] that the fluctuation statistics of the largest eigenvalues λ max i",
        "watermark_text": "We study the spectrum statistics of random matrices with entries given by the sum over all paths in an infinite tree, which is obtained as a limit of finite rank deformations of large Wigner matrices.We show that for any fixed number of particles there resides a series of such deformations converging to the limiting matrix whose spectrum properties are described by the Tracy - Widom distribution.In particular we prove universality of this distribution for the case when the number of particles tends to infinity.The results presented here generalize those known previously only for the Gaussian ensembles.This work was supported by Russia Science Federation grant 14 - 50 - 00040.1 Introduction.The problem of statistical description of the energy levels of complex quantum systems has been researched extensively during last decades ( see e. g., [ 1 ] ).It turns out that many important features of these spectra can be explained within Random matrices Theory ( RMT )[ 2 ].RMT deals with the statistical analysis of the eigenvalue distributions of various families of randomly matrices.One of the most popular models considered in RMT is the so - called Wigner ensemble [ 3 ], where one considers N ×N Shemitian matrices H = H † with independent identically distributed elements h ij having mean zero and variation 1 / N.For example, if the probability density function p ( h ) of each element h ij decays fast sufficiently at | h | → ∞ then it follows from the standard arguments[ 4 ] that the empirical measure µ N of the normalized eigenvectors of H converges weakly almost surely to some deterministic probability measure µ on the unit circle T = { z ∈ C : | z | = 1 } called circular law.Moreover, under additional assumptions about the decay rate of p ( h ), the Stieltjes transform m N ( z ) : = E TrH − z −1 of μ N converges pointwise almost surely to the Stieltjes transform M ( z ) of µ [ 5 ].In recent years much attention has been paid to the investigation of the local behaviour of the spectrum near its edge[ 6 ] - [ 8 ].In particular, it turned out [ 9 ] that the fluctuation statistics of the biggest eigenvalues λ maxi"
    },
    {
        "original_text": "We have studied the scaling behavior of two different types of surfaces, one made out of pyrex glass (a transparent material) and another made out of silicon dioxide (SiO2), which is an opaque material. The SiO2 surface was prepared by etching in hydrofluoric acid to remove all traces of metal contamination that could be present on its surface after being cut from a wafer. Both surfaces were then cleaned using standard cleaning procedures before they were subjected to particle bombardment at room temperature under ultra-high vacuum conditions.  We found that both surfaces exhibit similar scaling behaviors when we plot their respective roughness as a function of the number of deposited atoms per unit area for various incident angles ranging between 0°and 60°. However, there are some differences observed in the scaling exponents obtained for these two surfaces. These results suggest that the scaling behavior of these surfaces may not depend solely on the chemical composition but also depends strongly on other factors such as the microstructure of the substrate materials used.",
        "watermark_text": "We have studied the scaling behavior of two different types of surfaces, one made out of pyrex glass ( a translucent material ) and another made out of silicon dioxide ( SiO2 ), which is an opaque material.The SiO2 surface was prepared by etching in hydrofluoric acid to remove all traces of metal contamination that could be present on its interface after being cut from a wafer.Both surfaces were then cleaned utilizing standard cleaning procedures before they were subjected to particle bombardment at room temperature under ultra - high vacuum conditions.We found that both surfaces exhibit similarly scaling behaviors when we plot their respective roughness as a function of the number of deposited atoms per unit area for different incident angles ranging between zero°and 60°.However, there are some differences observed in the scaling exponents achieved for these two surfaces.These results suggest that the scaling behavior of these surfaces might not rely solely on the chemical composition but additionally depends strongly on other factors such as the microstructure of the substrate materials used."
    },
    {
        "original_text": "We present the results of our investigation into accretion disk continuum emission in black hole candidates (BHCs). We have developed an analytical model for calculating the spectrum emitted by a thin, optically thick accretion disk around a Schwarzschild black hole and applied it to several BHCs with known mass functions. The observed spectra are well reproduced when we assume that the inner edge of the disk is located at 6 gravitational radii. This result suggests that the standard thin disk model can be used as a good approximation for modeling the X-ray continuum emission of these objects. \n \n Keywords: Black holes -- Spectroscopy -- X-rays -- Modeling -- Accretion disks -- Emission lines -- Broad-band spectral energy distribution -- Luminosity function -- Mass measurement -- Stellar-mass black holes -- Supermassive black holes -- Active galactic nuclei -- Quasars -- Cosmic evolution \n \n \n \n 1 Introduction \n \n In recent years there has been considerable progress made towards understanding the physical processes occurring near supermassive black holes (SMBH) in active galactic nuclei (AGN), quasars, and other similar systems. These studies rely on observations of the broad-band spectral energy distributions (SEDs) of SMBHs over many decades in frequency space. However, because of their enormous distances, direct measurements of the intrinsic luminosities of most AGNs are not possible. Instead, one must use indirect methods such as reverberation mapping or statistical correlations between various properties of AGNs to determine their luminosities. For example, if one knows how much light passes through some region of interest within an AGN then one may calculate its luminosity using simple geometric arguments. Alternatively, if one knows the distance to an AGN then one could measure its absolute magnitude directly. Unfortunately, both of these approaches require detailed knowledge about the structure of the emitting regions which cannot currently be obtained observationally. Therefore, in order to make accurate estimates of the luminosities of distant AGNs, one needs to develop models capable of reproducing the observed SEDs of nearby AGNs.",
        "watermark_text": "We present the results of our investigation into accretion disk continuum emission in black hole candidates ( BHCs ).We have developed an analysis model for calculating the spectrum emitted by a thin, optically thick accretion disc around a Schwarzschild black string and applied it to several BHCs with known mass functions.The observed spectra are well reproduced when we assume that the inner edge of the disc is located at 6 gravitational radii.This result suggests that the standard thin disc model can be used as a good approximation for modeling the X - ray continuum emission of these objects.Keywords : Black holes - - Spectroscopy - - X - rays - - Modeling - - Accretion disks - - Emission lines - - Broad - band spectral energy distribution - - Luminosity function - - Mass measurement - - Stellar - mass black holes - - Supermassive black holes - - Active galactic nuclei - - Quasars - - Cosmic evolution 1 Introduction In recent years there has been considerable progress made towards understanding the physical processes occurring near supermassive black holes ( SMBH ) in active galactic nuclei ( AGN ), quasars, and other similar systems.These studies rely on observations of the broad - band spectrum energy distributions ( SEDs ) of SMBHs over long decades in frequency space.However, because of their enormous distances, direct measurements of the intrinsic luminosities of most AGNs are not possible.Instead, one must utilize indirect methods such as reverberation mapping or statistical correlations between various properties of AGNs to decide their luminosities.For example, if one knows how much light passes through some region of interest within an AGN then one might calculate its luminosity utilizing simple geometric arguments.Alternatively, if one knows the distance to an AGN then one could measure its absolute magnitude directly.Unfortunately, both of these approaches require detailed knowledge about the structure of the emitting regions which cannot currently be obtained observationally.Therefore, in order to make accurate estimates of the luminosities of distant AGNs, one needs to develop models capable of reproducing the observed SEDs of near AGNs."
    },
    {
        "original_text": "We report the observation of dynamic condensation of water vapor on crack tips during slow fracture experiments performed under vacuum conditions (10-6 mbar) and low temperature (77 K). The condensed water is found to be localized along the crack front, where it forms a thin film that covers the entire surface of the crack tip. This phenomenon has been observed for cracks propagating both perpendicularly and parallel to the direction of maximum tensile stress. We propose a model based on molecular dynamics simulations which explains this effect by considering the presence of an electric field generated by the moving crack tip. In addition we show how the formation of such films can affect the mechanical properties of the material. Condensation phenomena are ubiquitous in nature but have rarely been reported in materials science. Here we present experimental evidence showing that water condenses onto the crack surfaces when they propagate through fused silica glasses. These results were obtained using a combination of optical microscopy techniques with environmental scanning electron microscopy (ESEM), Raman spectroscopy and infrared reflection absorption spectroscopy (IRAS).",
        "watermark_text": "We report the observation of dynamic condensation of water vapor on crack tips during gradual fracture experiments performed under vacuum conditions ( 10 - 6 mbar ) and low temperature ( 77 K ).The condensed water is found to be localized along the crack front, where it forms a thin movie that covers the entire surface of the patch tip.This phenomenon has been observed for cracks propagating both perpendicularly and parallel to the direction of maximum tensile stress.We propose a system based on molecule dynamics simulations which explains this effect by considering the presence of an electrified field generated by the moving crack tip.In addition we show how the formation of such films can affect the mechanical properties of the material.Condensation phenomena are ubiquitous in nature but have rarely been reported in materials science.Here we present experimental evidence showing that water condenses upon the crack surfaces when they propagate through fused silica glasses.These results were obtained using a combination of optical microscopy techniques with environment scanning electron microscopy ( ESEM ), Raman spectroscopy and infrared reflection absorption spectroscopy ( IRAS )."
    },
    {
        "original_text": "The author considers an alternative approach to classical electrodynamics, which is based on the concept of \"pre-metricity\" introduced by Einstein in his work \"On the Electrodynamics of Moving Bodies\" (1905). The main idea behind this approach consists in introducing into consideration not only the usual electromagnetic field tensor Fμν but also its dual counterpart *Fμν . In order to obtain equations for both fields simultaneously one has to introduce additional terms into Lagrangian density L(Fμν ,*Fμν ) that are quadratic with respect to derivatives of these fields. It turns out that such modified Lagrangian leads to the following set of equations: \nwhere  is the d'Alembert operator,  is the energy-momentum tensor of matter fields, and  is the current four-vector describing the flow of electric charge. \nIn addition to the standard Maxwell's equations, Eqs. (1)-(3), there appears another equation -the so-called \"duality condition\":",
        "watermark_text": "The author considers an alternative approach to classical electrodynamics, which is based on the concept of \" pre - metricity \" introduced by Einstein in his work \" On the Electrodynamics of Moving Bodies \" ( 1905 ).The main idea behind this approach consists in introducing into considerationnot only the usual electromagnetic field tensor Fμνbut also its dual counterpart *Fμν.In order to obtain equations for both fields simultaneously one has to introduce additional terms into Lagrangian density L ( Fμν, * Fμν ) that are quadratic with respect to derivatives of these fields.It turns out that such modified Lagrangian leads to the following set of equations : where is the d ' Alembert operator, is the energy - momentum tensor of material fields, and is the current four - vector describing the flow of electric charge.In addition to the standard Maxwell ' s equations, Eqs.( 1 ) - ( 3 ), there appears another equation - the so - called \" duality condition \" :"
    },
    {
        "original_text": "We present an approach to the description of macroscopic configurations in terms of quantum states, which is based on the concept of entanglement entropy and its generalization for mixed states. We show that this representation allows one to obtain exact results for some statistical properties of systems with many degrees of freedom. In particular, we consider the problem of calculating the partition function of classical spin models at high temperatures. The proposed method can be used as a basis for constructing approximate algorithms for solving problems related to the calculation of thermodynamic characteristics of complex systems. Introduction.\nThe main goal of statistical mechanics is to describe the behavior of macroscopic objects (for example, gases) by using microscopic information about their constituents (atoms). This task becomes especially difficult when dealing with large systems consisting of many particles or spins. For such cases, it is necessary to use approximations, since direct calculations are impossible due to the exponential growth of the number of possible microstates with increasing system size N . One of these approaches is the so-called mean-field approximation [1] , according to which each particle interacts only with all other particles simultaneously; i.e., the interaction between different pairs of particles is neglected. However, even within this simplified model, the calculation of the partition function Z = Tr exp(−βH) (1) remains extremely complicated [2] .\nIn recent years, there has been growing interest in developing new methods for describing macroscopic configurations in terms similar to those used in quantum physics [3] - [8] . These studies were inspired by the fact that both classical and quantum descriptions have certain common features [9] : they are formulated in terms of wave functions ψ(x), where x denotes either positions of particles or spins, respectively. Moreover, the evolution of these wave functions obeys the same Schrödinger equation ih∂ t |ψ(t) = H|ψ(t) , where H is the corresponding Hamiltonian operator. It should also be noted that the density matrix ρ = |ψ(t) ψ(t)| plays the role of a probability distribution in both theories [10] .",
        "watermark_text": "We present an approach to the description of macroscopic configurations in terms of quantum states, which is based on the concept of entanglement entropy and its generalization for mixed states.We show that this representation allows one to obtain exact results for some statistical properties of systems with much degrees of freedom.In particular, we consider the problem of calculating the partition function of classical spin models at high temperatures.The proposed method can be used as a basis for constructing approximate algorithms for solution problems related to the calculation of thermodynamic qualities of complex systems.Introduction.The main goal of statistical mechanics is to describe the behaviour of macroscopic items ( for instance, gases ) by using microscopic information about their constituents ( atoms ).This task becomes especially difficult when dealing with large systems consisting of many particles or spins.For such cases, it is necessary to use approximations, since direct calculations are impossible owing to the exponential growth of the number of possible microstates with increasing system size N.One of these approaches is the so - called mean - field approximation[ 1 ], according to which each particle interacts only with all other particles concurrently ; i. e., the interaction between different pairs of particles is neglected.However, even within this simplified model, the calculation of the partition function Z = Tr exp ( minusβH ) ( 1 ) remains extremely complex [ 2 ].In recent years, there has been growing interest in developing new methods for describing macroscopic configurations in terms similar to those used in quantum physics[ 3 ] - [ 8 ].These studies were inspired by the fact that both classical and quantum descriptions have certain common features[ 9 ] : they are formulated in terms of wave functions ψ ( x ), where x denotes either positions of particles or spins, respectively.Moreover, the evolution of these wave functions obeys the same Schrödinger equation ih∂ t | ψ ( t )= H | ψ ( t ), where H is the corresponding Hamiltonian operator.It should also be noted that the density matrix ρ = | ψ ( t ) ψ ( t ) | plays the role of a probability distribution in both theories [ 10 ]."
    },
    {
        "original_text": "The segmentation clock is an oscillatory gene regulatory network that controls the periodic formation of segments in vertebrates, such as vertebrae and ribs.  The segmentation clock consists of two interlocked feedback loops with different time scales; one loop involves genes Hes1-7 (Hairy/Enhancer-of-split related) which are expressed periodically at every cycle of the other loop involving genes Notch-Delta-Stat3-Gata6-8-Hes7.  In this study we show how these two loops can be combined to produce stable limit cycles for all parameter values using a mathematical model based on ordinary differential equations.  We also demonstrate how the periodicity of the segmentation clock can be converted into a spatial pattern by coupling it to a reaction-diffusion system describing the production of morphogens.  Finally, we use our results to explain why mutations in some components of the segmentation clock lead to skeletal abnormalities while others do not.",
        "watermark_text": "The segmentation clock is an oscillatory gene regulatory network that controls the periodic formation of segments in vertebrates, such as vertebrae and ribs.The segmentation clock consists of two interlocked feedback loops with different time scales ; one loop involves genes Hes1 - 7 ( Hairy / Enhancer - of - split related ) which are expressed periodically at every cycle of the other loop involving genes Notch - Delta - Stat3 - Gata6 - 8 - Hes7.In this study we show how these two loops can be combined to produce stability limit cycles for all parameter values using a mathematical model based on normal differential equations.We also demonstrate how the periodicity of the segmentation clock can be converted into a spatial pattern by pairing it to a reaction - diffusion system describing the production of morphogens.Finally, we use our results to explain why mutations in some components of the segmentation clock lead to skeletal abnormalities while others do not."
    },
    {
        "original_text": "The evolution of galaxies is strongly influenced by their environment, but the physical processes that drive this are not well understood. In particular, it remains unclear how galaxy properties such as morphology or star formation rate depend on large-scale structure in the Universe.  This talk will present results from an ongoing study using data from the Sloan Digital Sky Survey (SDSS) to investigate these issues. The first part of my talk will focus on the relationship between galaxy clustering and luminosity/stellar mass. I will then discuss recent work investigating the dependence of galaxy properties on local density. Finally, I'll show some preliminary results exploring the connection between galaxy properties and dark matter halo masses. My research has been supported by NSF grant AST-0707766. I am currently a postdoctoral fellow at Harvard University working with Prof. David Weinberg. I received my Ph.D. from UCLA under the supervision of Dr. James Bullock.",
        "watermark_text": "The evolution of galaxies is strongly influenced by their environment, but the physical processes that drive this are not well understood.In particular, it remains unclear how galaxy properties such as morphology or star formation rate rely on large - scale structure in the Universe.This talk will present results from an continuing study using data from the Sloan Digital Sky Study ( SDSS ) to investigate these problems.The first part of my talk will focus on the relationship between galaxy clustering and luminosity / stellar mass.I will then discuss recent work investigating the dependence of galaxy properties on local density.Finally, I ' ll show some preliminary results exploring the connection between galaxy properties and dark material halo masses.My research has been supported by NSF grant AST - 0707766.I am currently a postdoctoral fellow at Harvard University working with Prof. David Weinberg.I received my Ph. D. from UCLA under the supervision of Dr. James Bullock."
    },
    {
        "original_text": "We report on spectropolarimetric observations of the M8+M9 binary star LHS 1070A,B (GJ 436) with ESPaDOnS at CFHT. The two stars are separated by only 0. ′′ 1 and have been known to be magnetically active for many years. We find that both stars show significant circularly polarized emission lines indicative of Zeeman splitting due to their magnetic fields. In addition we detect Stokes V signatures indicating net linear polarization across all observed spectral lines. This is likely caused by scattering processes within the stellar atmosphere. Using our new data set together with previously published photometric measurements we derive rotation periods of P A = 3.6 ± 0.1 days and P B = 4.2 ± 0.3 days for the primary and secondary component respectively. These values are significantly longer than those derived from previous studies which were based solely on photometry. Our results suggest that the rotation period of each individual component depends strongly on its effective temperature as well as its surface gravity.",
        "watermark_text": "We report on spectropolarimetric observations of the M8 + M9 binary star LHS 1070A, B ( GJ 436 ) with ESPaDOnS at CFHT.The two stars are separated by only 0.′ ′ 1and have been known to be magnetically active for long years.We find that both stars show significant circularly polarized emission lines indicative of Zeeman splitting owing to their magnetic fields.In addition we detect Stokes V signatures indicating net linear polarization across all observed spectral lines.This is likely caused by scattering processes inside the star atmosphere.Using our new data set together with previously published photometric measurements we derive rotation periods of P A = 3. 6 ± 0. 1 days and P B = four. 2 ± 0. 3 days for the primary and secondary component respectively.These values are significantly longer than those derived from previous studies which were based solely on photometry.Our results suggest that the rotation period of each individual constituent depends strongly on its effective temperature as also as its surface gravitational."
    },
    {
        "original_text": "We study the mechanical properties of disordered networks of fibers with different bending rigidities by means of numerical simulations based on molecular dynamics (MD) and Monte Carlo (MC). We find that the elastic moduli are strongly dependent on the bending rigidity, which is related to the persistence length of the fibers. The results show that the shear modulus increases as the bending rigidity decreases while the bulk modulus remains almost unchanged for all values of the bending rigidity studied here. In addition we observe that the distribution functions of forces acting between particles depend significantly on the bending rigidity. For small bending rigidities there exist strong correlations among neighboring particles leading to large fluctuations in the local stress field. These findings suggest that the microscopic structure plays an important role in determining macroscopic material properties such as elasticity. Disordered networks of fibers have been widely used to model various materials ranging from biological tissues to granular media [1-3]. However, it has not yet been fully understood how the microstructure affects their macroscopic behavior. Here we investigate this problem using computer simulation techniques.",
        "watermark_text": "We study the mechanical properties of disordered networks of fibers with different bending rigidities by means of numerical simulations based on molecular dynamics ( MD ) and Monte Carlo ( MC ).We find that the elastic moduli are strongly dependent on the bending rigidity, which is related to the persistence length of the fibers.The results show that the shear modulus increases as the bending rigidity decreases while the bulk modulus remains almost unchanged for all values of the bending rigidity studied here.In addition we observe that the distribution functions of forces acting between particles depend significantly on the bending rigidity.For small bending rigidities there exist strong correlations amongst neighboring particles leading to large fluctuations in the local stress field.These findings suggest that the microscopic structure plays an important role in determining macroscopic material properties such as elasticity.Disordered networks of fibers have been widely used to model various materials ranging from biological tissues to granular media[ 1 - 3 ].However, it has not yet been fully understood how the microstructure affects their macroscopic behavior.Here we investigate this problem using computer simulation methods."
    },
    {
        "original_text": "We present new results on the kinematics and dynamics of spiral arm streaming motions in the nearby grand-design galaxy NGC 5194 (M51). We use high-resolution near-IR integral field spectroscopy obtained with SINFONI at VLT to study the gas velocity fields, line-of-sight velocities, and mass surface density distributions along two different lines of sight through the central region of this interacting system. The main goal is to investigate whether or not there are systematic differences between these two viewing angles that could be related to an underlying gravitational potential perturbation caused by the companion galaxy NGC 5195. Our analysis shows that both sides of the nuclear ring exhibit similar large-scale streaming patterns which can be traced out to distances of about 1 kpc into the disk plane. However, we find significant deviations from circular rotation within the inner 100 pc radius around the nucleus. These non-circular motions appear to be dominated by radial inflow towards the center as well as counter-rotating components perpendicular to the major axis of the galactic bar.",
        "watermark_text": "We present fresh results on the kinematics and dynamics of spiral arm streaming motions in the nearby grand - design galaxy NGC 5194 ( M51 ).We utilize high - resolution near - IR integral field spectroscopy obtained with SINFONI at VLT to study the gas velocity fields, line - of - sight velocities, and mass surface density distributions along two different lines of sight through the central region of this interacting system.The main goal is to investigate either or not there are systematic differences between these 2 viewing angles that could be related to an underlying gravitational potential perturbation induced by the companion galaxy NGC 5195.Our analysis shows that both sides of the nuclear ring show similar large - scale streaming patterns which can be traced out to distances of about 1 kpc into the disk plane.However, we find significant deviations from circular rotation within the inner 100 pc radius around the nucleus.These non - circular motions appear to be dominated by radial inflow towards the center as also as counter - rotating components perpendicular to the major axis of the galactic bar."
    },
    {
        "original_text": "We study the slow wave resonance (SWR) effect for periodically layered media with an arbitrary number N of anisotropic layers, each characterized by its own permittivity tensor and thickness. We show that SWR is possible only if all principal axes of the permittivity tensors are parallel to one another within each layer. In this case we derive explicit expressions for the dispersion relation between the frequency f and the Bloch wavenumber kx. The results obtained can be used as guidelines for designing multilayered structures exhibiting strong SWR effects at low frequencies. \n \n Keywords: Slow wave resonance; Anisotropy; Multilayer structure; Dispersion relations. 1 Introduction \n \n Periodic multilayers consisting of alternating thin films made of different materials have attracted considerable attention during recent years due to their unique properties [1] . These include high reflectance [2] , negative refraction [3] , enhanced nonlinear optical response [4] , etc., which make them promising candidates for various applications such as optoelectronic devices [5] or photovoltaics [6] .\n \nIn particular, it has been shown recently [7–9] that periodic multilayers composed of anisotropic layers may exhibit very interesting electromagnetic phenomena including slow wave resonance (S WR). This phenomenon occurs when the phase velocity of the Bloch waves becomes equal to zero inside the medium [10] . It leads to extremely large values of the effective refractive index n eff = c / v ph [11] where c is the speed of light in vacuum and v ph is the phase velocity of the propagating Bloch mode [12] . As a result, the corresponding transmission spectrum exhibits sharp peaks associated with narrow stop bands [13] . Such features are highly desirable for many practical applications [14] . \n \n However, despite numerous theoretical studies devoted to S WR in periodic multilayers [15–18] , there still exist several open questions related to the conditions under which this phenomenon takes place [19, 20] . For example, it was found experimentally [21] that the presence of a single misaligned anisotropic layer destroys the S WR effect completely even though other layers remain perfectly aligned. On the other hand, numerical simulations [22] suggest that",
        "watermark_text": "We study the slow wave resonance ( SWR ) effect for periodically layered media with an arbitrary number N of anisotropic layers, each characterized by its own permittivity tensor and thickness.We show that SWR is possible only if all principal axes of the permittivity tensors are parallel to one another within each layer.In this case we derive explicit expressions for the dispersion relationship between the frequency f and the Bloch wavenumber kx.The results obtained can be used as guidelines for designing multilayered structures exhibiting strong SWR effects at low frequencies.Keywords : Slow wave resonance ; Anisotropy ; Multilayer structure ; Dispersion relations.1 Introduction Periodic multilayers consisting of alternating thin films made of different substances have attracted considerable attention during modern years due to their unique properties [ 1 ].These include high reflectance [ 2 ], negative refraction [ 3 ], enhanced nonlinear optical response [ 4 ], etc., which make them promising candidates for various applications such as optoelectronic devices [ 5 ] or photovoltaics [ 6 ].In particular, it has been shown recently [ 7 – 9 ] that periodic multilayers composed of anisotropic layers may exhibit very interesting electromagnetic phenomena including slow wave resonance ( S WR ).This phenomenon occurs when the phase velocity of the Bloch waves gets equal to 0 inside the medium [ 10 ].It leads to extremely large values of the efficient refractive index n eff = c / vph[ 11 ] where c is the speed of light in vacuum and v ph is the phase velocity of the propagating Bloch mode[ 12 ].As a result, the corresponding transmission spectrum exhibits sharp peaks associated with narrow stop bands [ 13 ].Such features are highly desirable for many practical applications[ 14 ].However, despite numerous theoretical studies devoted to S WR in periodic multilayers [ 15 – 18 ], there still exist several open questions related to the conditions under which this phenomenon takes place[ 19, 20 ].For example, it was found experimentally [ 21 ] that the presence of a single misaligned anisotropic layer destroys the SE WR effect completely even though other layers remain perfectly aligned.On the other hand, numerical simulations [ 22 ] suggest that"
    },
    {
        "original_text": "We present the results on charmless three-body decays of B mesons using data collected by the Belle experiment at KEKB in 2003-2007, corresponding to an integrated luminosity of 711 fb-1. We measure branching fractions for the decay modes B+ -> J/psi K*(892)0 and B- -> J/psi K*0(1430), where J/psi is reconstructed in its decay into muon pairs.  The measured values are  B+ -> J/psi: (4.6 +/- 0.7 +/- 1.1) x 10^-6; B->J/psi: (3.2 +/- 0.5 +/- 0.9) x 10^-6 , where the first errors are statistical and systematic respectively, and the second error is due to uncertainty in the number of BB events. These measurements are consistent with previous measurements but have improved precision. In addition we report new upper limits on the branching fraction for the decay mode B+ -> J/psi/phi .",
        "watermark_text": "We present the results on charmless three - body decays of B mesons using data collected by the Belle experiment at KEKB in 2003 - 2007, corresponding to an integrated luminosity of 711 fb - 1.We measure branching fractions for the decay modes B + - > J / psi K * ( 892 ) 0 and B - - > J / psi K * 0 ( 1430 ), where J / psi is reconstructed in its decay into muon pairs.The measured values are B + - > J / psi : ( 4. 6 + / - 0. 7 + / - 1. 1 ) x 10 ^ - 6 ; B - > J / psi : ( 3. 2 + / - 0. 5 + / - 0. 9 )x 10 ^ - 6, where the first errors are statistical and systematic respectively, and the 2nd error is due to uncertainty in the number of BB events.These measurements are consistent with previous measurements but have better precision.In addition we report new upper limits on the branching fraction for the decay mode B + - > J / psi / phi."
    },
    {
        "original_text": "We present an overview of the theory for vortices in trapped, dilute atomic gases at low temperatures. We discuss how these systems can be described by macroscopic wave functions and show that they are governed by nonlinear Schrödinger equations with external potentials. The solutions to this equation have been studied extensively over many years and we review some of their properties relevant to vortex formation. In particular, we consider stationary states which correspond to condensate configurations without rotation (vortex-free) as well as rotating ones where quantized angular momentum is carried by phase singularities known as vortices. Finally, we briefly describe recent experiments on vortex production in cold atom clouds. Vortices occur naturally in superfluids such as liquid helium or dilute atomic gases. They carry quantized angular momenta and play important roles in various physical phenomena including turbulence and quantum transport processes. Here we give an introduction into the theoretical description of vortices in trapped atomic gases.",
        "watermark_text": "We present an overview of the theory for vortices in trapped, dilute atomic gases at low heat.We discuss how these systems can be described by macroscopic wave functions and exhibit that they are governed by nonlinear Schrödinger equations with outside potentials.The solutions to this equation have been studied extensively over many years and we review some of their properties relevant to vortex formation.In particular, we think stationary states which correspond to condensate configurations without rotation ( vortex - freedom ) as well as rotating ones where quantized angular momentum is carried by phase singularities known as vortices.Finally, we briefly describe recent experiments on vortex production in cold atom clouds.Vortices occur naturally in superfluids such as liquid helium or dilute atomic gases.They carry quantized angular momenta and play key roles in various physical phenomena including turbulence and quantum transport processes.Here we give an introduction into the theoretical description of vortices in trapped atomic gases."
    },
    {
        "original_text": "We study the statistical properties of the local order parameter in systems undergoing a continuous phase transition, when quenched disorder is present. We show that these are described by a generalized multifractal spectrum which depends on both the strength and type of disorder as well as on the universality class of the clean system. In particular we consider the case of a first-order phase transition driven into second-order one by disorder. The results obtained for this model can be applied to describe the behavior of interfaces near wetting transitions in presence of quenched disorder. This work was supported by MIUR through FIRB project RBFR05EJYQ. PACS numbers: 05.65.+b, 64.60.Cn, 64.60.Fg, 64.60.Ht . \nI. INTRODUCTORY REMARK\nThe aim of this paper is to investigate how the presence of quenched impurities affects the statistical properties of the order-parameter fluctuations close to a continuous phase transition point. Our main interest will be focused on the so-called \"random fixed-points\" (RFP) [1] , i.e., those points where the renormalization-group flow of an effective field theory describing the effect of disorder stops because it becomes unstable against small perturbations [2] .\nIn general RFPs do not correspond to any physical situation since they represent singularities of the RG flows; however there exist some cases where such singularity appears only after many orders of perturbation expansion have been resummed [3] . For example, if the disorder distribution has a finite variance then the corresponding RFP corresponds to a stable fixed point [4] ; therefore its effects should appear only beyond all orders in perturbation theory [5] . On the other hand, if the disorder distribution is broad enough so that its moments diverge, then the RFP represents a genuine non-perturbative phenomenon [6] .",
        "watermark_text": "We study the statistical properties of the local order parameter in systems undergoing a continuous phase transition, when quenched disorder is present.We show that these are described by a generalized multifractal spectrum which depends on both the strength and kind of disorder as well as on the universality class of the clean system.In particular we consider the case of a first - order phase transition driven into second - order one by disorder.The results obtained for this model can be applied to describe the behavior of interfaces near wetting transitions in presence of quenched disorder.This work was supported by MIUR through FIRB project RBFR05EJYQ.PACS numbers : 05. 65. + b, 64. 60. Cn, 64. 60. Fg, 64. 60. Ht.I. INTRODUCTORY REMARKThe aim of this paper is to explore how the presence of quenched impurities effects the statistical properties of the order - parameter fluctuations close to a continuous phase transition point.Our main interest will be focused on the so - called \" randomly fixed - points \" ( RFP )[ 1 ], i. e., those points where the renormalization - group flow of an effective field theory describing the effect of disorder stops because it becomes unstable against little perturbations [ 2 ].In general RFPs do not correspond to any physical situation since they represent singularities of the RG flows ; however there exist some cases where such singularity appears only after many orders of perturbation expansion have been resummed [ 3 ].For example, if the disorder distribution has a finite variance then the corresponding RFP corresponds to a stability fixed point [ 4 ] ; therefore its effects should appear only past all orders in perturbation theory [ 5 ].On the other hand, if the disorder distribution is broad enough so that its moments diverge, then the RFP represents a genuine non - perturbative phenomenon[ 6 ]."
    },
    {
        "original_text": "We discuss the concept of particle number in quantum mechanics, with particular emphasis on its role as an indicator for quantum indistinguishability between particles. We show that this is not always true by considering two examples where it does not hold. The first example involves fermions which are distinguishable but have different spin states; we argue that these should be considered to belong to distinct species rather than being regarded as identical particles. In our second example, we consider bosons which can occupy the same state (e.g., photons) but are nevertheless distinguishable; here too they do not constitute a single species. Finally, we present arguments against identifying particle number with entropy or information content. This article is part of a series of articles intended to introduce some key concepts in physics through informal discussions. It may also serve as a useful guide for students preparing their own presentations. For more detailed explanations see the original papers cited below. \n \n Quantum mechanics has been developed over many decades since its birth at the beginning of 20th century. One of the most important aspects of quantum mechanics is the concept of particle number. Particles are fundamental building blocks of matter and energy. They come in various forms such as electrons, protons, neutrons, atoms, molecules etc.. Each type of particle carries certain properties like charge, mass, spin etc... \n \n What exactly is particle number? How is it related to other physical quantities? Why is it so important? These questions will be answered in this article.",
        "watermark_text": "We discuss the concept of particle number in quantum mechanics, with particular emphasis on its function as an indicator for quantum indistinguishability between particles.We show that this is not always true by considering two examples where it does not stand.The first example involves fermions which are distinguishable but have different spin states ; we argue that these should be considered to belong to distinct species rather than being regarded as identical particles.In our second example, we consider bosons which can occupy the same state ( e. g., photons ) but are nevertheless distinguishable ; here too they do not constitute a single species.Finally, we present argues against identifying particle number with entropy or info content.This article is part of a series of articles designed to introduction some key concepts in physics through informal discussions.It may also serve as a useful guide for students preparing their own presentations.For more detailed explanations see the original papers cited below.Quantum mechanics has been developed over many decades following its birth at the beginning of 20th century.One of the most important aspects of quantum mechanics is the concept of particle number.Particles are fundamental building blocks of matter and energy.They come in various forms such as electrons, protons, neutrons, atoms, molecules etc.Each type of particle carries certain properties like charge, mass, spin etc.What exactly is particle number?How is it related to other physical quantities?Why is it so important?These questions will be answered in this article."
    },
    {
        "original_text": "We study the effect of an external magnetic field on the modified Coulomb potential for two particles with opposite charges and masses, which are confined to move along one dimension. We show that this system can be mapped onto a spinless fermion model by using the Jordan-Wigner transformation. The ground state energy is calculated exactly within the framework of Bethe ansatz method. It turns out that there exists a critical value of the magnetic field strength beyond which the ground state becomes degenerate. This result agrees well with previous numerical calculations based on exact diagonalization technique. \n \n In addition we calculate the density-density correlation function as well as the momentum distribution function numerically. These results agree very well with those obtained analytically through the use of Bethe ansatz equations. Finally, we discuss how our results may be generalized to higher dimensions. Introduction:-In recent years considerable attention has been paid to the problem of strongly correlated electrons in low dimensional systems such as quantum wires or carbon nanotubes [1-3]. One of the most interesting phenomena observed experimentally in these systems is the fractional quantized Hall effect (FQHE) [4] . In particular it was shown that when the number of electrons N is odd ,the lowest Landau level(LLL) will contain only one electron per flux quanta [5] .The FQHEs have attracted much interest because they provide us with a unique opportunity to investigate many-body effects in condensed matter physics [6] .\nRecently, several authors [7-10] studied the properties of the modified coulomb interaction between two oppositely charged particles moving in a uniform magnetic field B perpendicularly to their plane of motion. They found that the ground-state energy depends crucially upon whether the total angular momentum J = L + S is zero or not where L is orbital angular momentum and S is spin angular momentum. For example if J=0 then the ground state energy is given by E0=−e2/lB+O(1/N),where lB=eB/mc is the magnetic length [11] .On the other hand if J=1/2 then the ground state energy takes the form E0",
        "watermark_text": "We study the effect of an external magnetic field on the modified Coulomb potential for two particles with opposite charges and masses, which are confined to move along one dimension.We show that this system can be mapped onto a spinless fermion model by using the Jordan - Wigner transformation.The ground state energy is calculated exactly within the frame of Bethe ansatz methodology.It turns out that there exists a critical value of the magnetic field strength past which the ground state becomes degenerate.This result agrees well with previous numerical calculations based on precise diagonalization technique.In addition we calculate the density - density correlation function as well as the momentum distribution distribution numerically.These results agree very well with those obtained analytically through the use of Bethe ansatz equations.Finally, we discuss how our results may be generalized to upper dimensions.Introduction : - In recent years considerable attention has been paid to the problem of strongly correlated electrons in low dimensional systems such as quantum wires or carbon nanotubes [ 1 - 3 ].One of the most interesting phenomena observed experimentally in these systems is the fractional quantized Hall effect ( FQHE )[ 4 ].In particular it was shown that when the number of electrons N is odd, the lowest Landau level ( LLL ) will contain only 1 electron per flux quanta[ 5 ]. The FQHEs have drawn much interest because they provide us with a unique opportunity to investigate many - body effects in condensed matter physics[ 6 ].Recently, several authors [ 7 - 10 ] studied the properties of the modification coulomb interface between 2 oppositely charged particles moving in a uniform magnetic field B perpendicularly to their plane of motion.They found that the ground - state energy depends crucially onto whether the total angular momentum J = L + S is zero or not where L is orbital angular moment and S is spin angular momentum.For example if J = 0 then the ground state energy is given by E0 = −e2 / lB + O ( 1 / N ), where lB = eB / mc is the magnetic length[ 11 ]. On the other hand if J = 1 / 2 then the ground state energy takes the shape E0"
    },
    {
        "original_text": "We present the results of our analysis of molecular gas mass estimates based on CO and HCN observations in nearby galaxies, using data obtained with the IRAM 30m telescope. We find that conversion factors between luminosity and mass are strongly dependent on the star formation rate (SFR) per unit area within each galaxy disk. The SFR surface density is found to be an important parameter controlling the conversion factor XCO = M(H2)/L(CO), which we derive by fitting the observed L(HCN) / L(CO) ratio versus metallicity relation. For low values of ΣSFR < 1M⊙ yr-1 kpc-2 , corresponding to quiescent disks or nuclear regions dominated by old stellar populations, we obtain XCO ≈ 2 × 10 20 cm−2 K−1 km−1 s. This value increases up to XCO ≈ 5×10 20 cm−2 K−1km−1s at high ΣSFR > 3M⊙yr-1kpc-2 . These findings suggest that the physical conditions of the interstellar medium may change significantly depending on whether it is located in actively star-forming regions or not.",
        "watermark_text": "We present the results of our analysis of molecular gas mass estimates based on CO and HCN observations in near galaxies, using data obtained with the IRAM 30m telescope.We find that converting factors between luminosity and mass are strong dependent on the star formation rate ( SFR ) id unit area within each galaxy disk.The SFR surface density is found to be an essential parameter controlling the conversion factor XCO = M ( H2 ) / L ( CO ), which we derive by fitting the observed L ( HCN ) / L ( CO ) ratio vs metallicity relation.For low values of ΣSFR [UNK] - 1kpc - 2.These findings suggest that the physical conditions of the interstellar medium may change significantly depending on whether it is situated in actively star - forming regions or not."
    },
    {
        "original_text": "We study the effect of electron-electron interactions (EEI) on the spin-flip rate due to phonons in semiconductor quantum dots. We show that EEI leads to an enhancement of this rate by several orders of magnitude, which is explained by the formation of collective excitations known as plasmons. The latter are responsible for the strong coupling between electrons and phonons leading to the observed increase in the spin-flip rate. Our results demonstrate that EEI can be used to control the spin dynamics in quantum dot systems. \nPACS numbers: 73.20.Dd, 74.78.Na, 78.67.Hc \nThe ability to manipulate spins in semiconductors has attracted considerable attention over recent years because it could lead to novel applications such as spin-based transistors or logic devices [1] . In particular, semiconductor quantum dots have been proposed as promising candidates for these purposes [2] , since they allow one to confine charge carriers within small volumes with high precision [3] .\nIn order to use quantum dots for spin manipulation, however, we need to understand how their spin states evolve under different conditions. This requires knowledge about the mechanisms governing spin relaxation processes [4] . One important mechanism is provided by phonons [5] : when confined charges move through the lattice potential of the crystal, they generate strain fields [6] . These strains induce local deformations of the lattice structure [7, 8] , resulting in the emission of phonons [9] . Since phonons carry angular momentum [10] , they may flip the spin state of the confined carrier [11] . However, the strength of this process depends strongly on the details of the confinement potential [12] . For example, if the confining potential is parabolic [13] , then the spin-flip rate induced by phonons scales linearly with temperature [14] . On the other hand, if the confining",
        "watermark_text": "We study the effect of electron - electron interactions ( EEI ) on the spin - flip rate due to phonons in semiconductor quantum dots.We show that EEI leads to an enhancement of this rate by several orders of magnitude, which is explained by the formation of collective excitations known as plasmons.The latter are responsible for the strong coupling between electrons and phonons resulting to the observed increase in the spin - flip rate.Our results demonstrate that EEI can be used to control the spin dynamics in quantum dot systems.PACS numbers : 73. 20. Dd, 74. 78. Na, 78. 67. HcThe ability to manipulate spins in semiconductors has attracted considerable attention over following years because it could lead to new applications such as spin - based transistors or reasoning devices[ 1 ].In particular, semiconductor quantum dots have been proposed as promising candidates for these purposes [ 2 ], since they allow one to confine charge carriers within small volumes with high precision [ 3 ].In order to use quantum dots for spin manipulation, however, we require to understand how their spin states evolve under different conditions.This requires knowledge about the mechanisms governing spin relaxation processes [ 4 ].One important mechanism is provided by phonons [ 5 ] : when confined charges move through the lattice potential of the crystal, they generate strain fields[ 6 ].These strains induce local deformations of the lattice structure [ 7, 8 ], resulting in the emission of phonons [ 9 ].Since phonons carry angular momentum[ 10 ], they may flip the spin state of the enclosed carrier[ 11 ].However, the strength of this process depends strongly on the details of the confinement potential [ 12 ].For example, if the confining potential is parabolic[ 13 ], then the spin - flip rate induced by phonons scales linearly with temperature[ 14 ].On the other hand, if the confining"
    },
    {
        "original_text": "We present an overview of the state-of-the-art methods for spectral analysis on spherical data, with emphasis on their applications to problems arising in geophysical sciences (e.g., global seismological tomography) and astrophysics (e.g., cosmic microwave background). We also discuss some recent advances in this area that have been made by our group at Columbia University. The main focus is on the development of new algorithms for computing accurate estimates of the power spectrum of signals defined over the surface of the unit sphere using only partial information about these signals. In particular, we consider two classes of methods: those based on the use of spherical harmonic expansions and those based on wavelet transforms. Finally, we briefly describe several open research questions related to the topic discussed here. Spherical data arise naturally in many areas of science including astronomy, meteorology, oceanography, geodesy, and medicine. For example, astronomers routinely collect large amounts of data describing the positions of celestial objects such as stars or galaxies; similarly, weather forecasters gather measurements of atmospheric pressure, temperature, humidity, wind speed, etc., at various locations around the globe. These types of data are often represented mathematically as functions defined over the surface of a sphere.",
        "watermark_text": "We present an overview of the state - of - the - art techniques for spectral analysis on sphere data, with emphasis on their applications to problems arising in geophysical sciences ( e. g., global seismological tomography ) and astrophysics ( e. g., cosmic microwave background ).We also discuss some recent advances in this area that have been made by our group at Columbia University.The main focus is on the development of novel algorithms for computing accurate estimates of the power spectrum of signals defined over the surface of the unit sphere utilizing only part information about these signals.In particular, we consider two classes of methods : those based on the use of spherical harmonic expansions and those based on wavelet transforms.Finally, we briefly describe several open research questions related to the topic discussed here.Spherical data arise naturally in many areas of science including astronomy, meteorology, oceanography, geodesy, and medicine.For example, astronomers routinely collect large amounts of data detailing the positions of celestial objects such as stars or galaxies ; similarly, weather forecasters gather measurements of atmospheric pressure, temperature, humidity, wind speed, etc., at various locations around the globe.These types of data are often represented mathematically as functions defined over the surface of a sphere."
    },
    {
        "original_text": "We present new observations of the kinematic properties of the dense gas associated with the young stellar cluster forming within the Ophiuchus molecular cloud (d = 140 pc). We used the Submillimeter Array to observe two fields, one centered on the infrared source IRAS 04368+2557 and another located about 1 arcmin away at the position of the Spitzer c2d survey target L1641N. The data reveal that both regions are characterized by complex velocity structures which we interpret as being due to multiple overlapping protostellar cores. In particular, our results show that:  -The region surrounding IRAS 04368+25570 is dominated by three distinct components separated by less than 0.1 pc along the line-of-sight.  -The region around L1641N contains several compact sources embedded in an extended envelope whose emission peaks at velocities between 5 and 10 km s-1 relative to the local standard of rest.   -Both regions contain numerous outflows driven by protostars still deeply embedded in their natal envelopes.",
        "watermark_text": "We present fresh observations of the kinematic properties of the dense gas associated with the young stellar cluster forming within the Ophiuchus molecular cloud ( d = 140 pc ).We used the Submillimeter Array to observe two fields, one centered on the infrared source IRAS 04368 + 2557 and another located about 1 arcmin away at the position of the Spitzer c2d survey target L1641N. The data reveal that both regions are characterized by complex velocity structures which we interpret as being due to multiple overlapping protostellar cores.In particular, our results show that : - The region surrounding IRAS 04368 + 25570 is dominated by three distinct components separated by fewer than 0. 1 pc along the line - of - sight.- The region around L1641N contains several compact sources embedded in an extended envelope whose emission peaks at velocities between five and 10 km s - 1 relative to the local standard of rest.- Both regions contain numerous outflows driven by protostars still deeply embedded in their natal envelopes."
    },
    {
        "original_text": "We study the entanglement properties of two qubits coupled by an antisymmetric anisotropic exchange interaction (AAEI) in a magnetic chain described by the Heisenberg model on the square lattice. We show that for certain values of the parameters, this system can be mapped onto a spin-1/2 XYZ chain and we calculate analytically its concurrence as well as the von Neumann entropy. The results are compared to those obtained numerically using exact diagonalization techniques. In particular, it is shown that the AAEI leads to a significant increase of the concurrence between nearest-neighboring spins when compared to the standard XXZ case. Moreover, we find that there exists a critical value of the anisotropy parameter beyond which no entanglement survives. Finally, we discuss how our findings could be tested experimentally. Introduction:-Entangled states play a crucial role in quantum information processing [1] . Therefore, understanding their generation mechanisms has been one of the main goals of many theoretical investigations [2] - [4] .\nIn recent years, much attention was paid to the investigation of entanglement in various types of spin chains [5] , including the so-called XXZ chain [6]- [8] . However, most studies were focused only on the ground state [9] or low lying excited states [10] of these systems. On the other hand, recently developed experimental techniques allow us to prepare highly excited states [11] . Thus, it becomes important to investigate also higher energy levels [12] .\nThe aim of this work is to analyze the entanglement properties of a pair of qubits interacting via an antisymmetric anisotropic Heisenberg exchange term [13] . This type of coupling appears naturally in several physical models [14] - [16] . For example, it describes the spin-spin interactions in molecular magnets [17] where the total angular momentum J = 0 [18] . It should be noted here that such molecules have attracted considerable interest due to their potential applications in quantum computing [19] . Another interesting application concerns the description of excitations in high-Tc superconductors [20] . Here, the presence of the antisymmetric anisotropic exchange term may lead to new phenomena [21] .",
        "watermark_text": "We study the entanglement properties of two qubits coupled by an antisymmetric anisotropic exchange interaction ( AAEI ) in a magnetic chain described by the Heisenberg model on the square lattice.We show that for certain values of the parameters, this scheme can be mapped onto a spin - one / two XYZ chain and we calculate analytically its concurrence as well as the von Neumann entropy.The results are compared to those obtained numerically using exact diagonalization techniques.In particular, it is shown that the AAEI leads to a significant increase of the concurrence between nearest - neighbouring spins when compared to the standard XXZ case.Moreover, we find that there exists a critical value of the anisotropy parameter beyond which no entanglement survives.Finally, we discuss how our findings could be tested experimentally.Introduction : - Entangled states play a crucial role in quantum information processing [ 1 ].Therefore, understanding their generation mechanisms has been one of the main goals of many theoretical investigations[ 2 ] - [ 4 ].In recent years, much attention was paid to the investigation of entanglement in various types of spin chains [ 5 ], including the so - named XXZ chain[ 6 ] - [ 8 ].However, most studies were focused only on the ground state [ 9 ] or low laying excited states [ 10 ] of these systems.On the other hand, recently developed experimental techniques allow us to prepare highly excited states [ 11 ].Thus, it becomes important to investigate also upper energy ones [ 12 ].The aim of this work is to analyze the entanglement properties of a pair of qubits interacting via an antisymmetric anisotropic Heisenberg exchange term [ 13 ].This type of coupling appears naturally in multiple physical models[ 14 ] -[ 16 ].For example, it describes the spin - spin interactions in molecular magnets [ 17 ] where the total angular moment J = 0[ 18 ].It should be noted here that such molecules have attracted considerable interest due to their potential applications in quantum computing [ 19 ].Another interesting application concerns the description of excitations in high - Tc superconductors [ 20 ].Here, the presence of the antisymmetric anisotropic exchange measure may lead to new phenomena [ 21 ]."
    },
    {
        "original_text": "Horizontal Gene Transfer (HGT) is an important evolutionary force that can increase genetic diversity and accelerate evolution, but it also has negative effects such as disrupting co-adapted gene complexes or introducing deleterious mutations into recipient genomes. In this study we investigate how HGT affects the mean fitness of unicells evolving under different environmental conditions using computational models. We find that HGT increases the mean fitness when cells are exposed to fluctuating environments with high levels of stressful events. However, if there are only mild fluctuations then HGT decreases the mean fitness because it introduces harmful mutations. Finally, for constant environments without any external stresses, HGT does not affect the mean fitness at all. Our results suggest that HGT may have played an important role during early stages of life's evolution by increasing its adaptability to changing environments. Horizontal Gene Transfer (HGT), which occurs between organisms sharing similar DNA sequences, is one of the most significant evolutionary forces known today [1] . It allows rapid acquisition of new genes and thus contributes to increased genetic diversity within species [2] , accelerates evolution [3] , and facilitates adaptation [4] .\nHowever, HGT also has some disadvantages including disruption of co-adapted gene complexes [5] and introduction of deleterious mutations [6] . Therefore, understanding the effect of HGT on population dynamics requires careful investigation [7, 8] . Previous studies suggested that HGT could be beneficial for populations living in fluctuating environments [9] while detrimental for those inhabiting stable ones [10] . Here we use computational models to explore these hypotheses further and show that HGT can either increase or decrease the mean fitness depending on the type of environment inhabited by the cell population.",
        "watermark_text": "Horizontal Gene Transfer ( HGT ) is an important evolutionary force that can increase genetic diversity and accelerate evolution, but it also has negative effects such as disrupting co - adapted gene complexes or introducing deleterious mutations into recipient genomes.In this study we investigate how HGT effects the mean fitness of unicells evolutionary under different environment conditions using computational models.We find that HGT increases the mean fitness when cells are exposed to fluctuating environments with high levels of stressful events.However, if there are only mild fluctuations then HGT reduces the average fitness because it introduces harmful mutations.Finally, for constant environments without any external stresses, HGT does not affect the mean fitness at all.Our results suggest that HGT may have played an key role during early phases of life ' s evolution by increasing its adaptability to changing environments.Horizontal Gene Transfer ( HGT ), which occurs between organisms sharing similar DNA sequences, is one of the most significant evolutionary forces known today [ 1 ].It allows rapid acquisition of new genes and thus contributes to increased gene diversity inside species[ 2 ], accelerates evolution [ 3 ], and facilitates adaptation[ 4 ].However, HGT also has some disadvantages including disruption of co - adapted gene complexes [ 5 ] and introduction of deleterious mutations [ six ].Therefore, understanding the effect of HGT on population dynamics requires careful investigation[ 7, 8 ].Previous studies suggested that HGT could be beneficial for populations living in fluctuating environments [ 9 ] while detrimental for those inhabiting stable ones [ 10 ].Here we utilize computational models to explore these hypotheses further and show that HGT can either rise or lower the mean fitness according on the type of environmental inhabited by the cell population."
    },
    {
        "original_text": "We present constrained realizations of the mass distribution in the nearby universe, based on the Millennium Run N-body simulation (Springel et al., 2005) combined with galaxy redshift surveys. We use two different methods to construct mock catalogues for comparison with observations: The first method is based on the conditional luminosity function formalism developed by Yang et al. (2003) , which we apply to galaxies selected from the Sloan Digital Sky Survey Data Release 7 (Abazajian et al., 2009 ). In this approach, each galaxy has an assigned halo mass drawn from its luminosity-dependent probability density function. The second method uses the Halo Occupation Distribution model introduced by Zheng et al. (2005) . Here, the number of central and satellite galaxies within haloes are determined using their respective HODs as functions of host halo mass. For both approaches, we compare our results against observational data sets including the 2MASS Redshift Survey (Huchra et al., 2012; Bilicki & Chodorowski, 2013), 6dF Galaxy Survey (Jones et al., 2004 ) and the WiggleZ Dark Energy Survey (Drinkwater et al., 2010).",
        "watermark_text": "We present constrained realizations of the mass distribution in the nearby universe, based on the Millennium Run N - body simulation ( Springel et al., 2005 ) combined with galaxy redshift surveys.We utilize two separate methods to construct mock catalogues for comparison with observations : The first method is based on the conditional luminosity function formalism derived by Yang imp al. ( 2003 ), which we apply to galaxies selected from the Sloan Digital Sky Survey Data Release 7 ( Abazajian et la., 2009 ).In this approach, each galaxy has an assigned halo mass pulled from its luminosity - dependent probability density function.The second method uses the Halo Occupation Distribution model introduced by Zheng et al. ( 2005 ).Here, the number of central and satellite galaxies within haloes are determined using their respective HODs as functions of host halo mass.For both approaches, we compare our outcomes against observational data sets including the 2MASS Redshift Survey ( Huchra et al., 2012 ; Bilicki & Chodorowski, 2013 ), 6dF Galaxy Tour ( Jones et al., 2004 ) and the WiggleZ Dark Energy Survey ( Drinkwater et al., 2010 )."
    },
    {
        "original_text": "We study the transverse momentum dependence of J/ψ and Υ production cross sections at RHIC energies within an effective field theory approach, which includes both elastic scattering off quarks as well as inelastic processes such as dissociation into open charm or bottom hadrons.  We find that the observed suppression pattern can be reproduced by including only elastic scattering for pT < 2 GeV/c while additional contributions are needed to describe data points with larger values of pT . The latter turn out to be dominated by inelastic processes like dissociation into open heavy flavor mesons. In particular we show that the inclusion of these effects leads to a significant reduction of the predicted nuclear modification factor RAA(pT ) compared to previous calculations based on purely elastic interactions. \nPACS numbers: 12.38.Mh, 25.75.-q, 11.10.Kk \nI. INTRODUCTORY REMAR K\nThe measurement of charmonium (J/ψ) and bottomonium (Υ) production is one of the most promising probes to investigate properties of hot and dense matter created in relativistic nucleus-nucleus collisions [1] . It has been suggested that the interaction between the produced quarkonia and the surrounding medium may lead to their partial melting [2] , i.e., to a decrease of the bound state masses due to color screening [3] .\nIn this work we present results obtained within an effective field theory framework [4] , where the relevant degrees of freedom are quarks and gluons rather than individual hadronic states. This allows us to calculate the total cross section for quarkonium production in terms of elementary partonic subprocesses involving light quarks q = u, d, s and gluons g. These include elastic scattering off quarks and gluon-gluon fusion leading to the formation of quarkonia via the creation of a virtual qq pair [5] . Furthermore, inelastic processes such as quarkonium dissociation into open heavy-flavor hadrons [6] have also been included [7, 8] .",
        "watermark_text": "We study the transverse momentum dependence of J / ψ and [UNK] production cross sections at RHIC energies within an effective field theory approach, which includes both elastic scattering off quarks as well as inelastic processes such as dissociation into open charm or bottom hadrons.We find that the observed suppression pattern can be reproduced by including only elastic scattering for pT < 2 GeV / ca while additional contributions are needed to describe data points with larger values of pT.The latter turn out to be dominated by inelastic processes including dissociation into open heavy taste mesons.In particular we show that the inclusion of these effects leads to a significant reduction of the predicted nuclear modification factor RAA ( pT ) compared to previous calculations based on purely elastic interactions.PACS numbers : 12. 38. Mh, 25. 75. - q, 11. 10. Kk I. INTRODUCTORY REMAR KThe measurement of charmonium ( J / ψ ) and bottomonium ( [UNK] ) production is 1 of the most promising probes to investigate properties of hot and dense matter created in relativistic nucleus - nucleus collisions [ 1 ].It has been suggested that the interaction between the produced quarkonia and the surrounding medium may result to their partial melting [ 2 ], i. ed., to a decrease of the bound state masses due to color screening [ 3 ].In this work we present outcomes obtained within an effective field theory framework [ 4 ], where the relevant degrees of freedom are quarks and gluons rather than individual hadronic states.This allows us to calculate the total cross section for quarkonium production in terms of elementary partonic subprocesses involving light quarks q = u, d, s and gluons g.These include elastic scattering off quarks and gluon - gluon fusion leading to the forming of quarkonia via the creation of a virtual qq pair [ 5 ].Furthermore, inelastic processes such as quarkonium dissociation into open heavy - flavor hadrons [ 6 ] have also been included [ 7, 8 ]."
    },
    {
        "original_text": "The authors report on observations made with the HESS telescope array, which detected emission at energies above 1TeV (1 teraelectronvolt) coming from an area within 0.2 degrees of the center of the galaxy M87.  The data are consistent with theoretical predictions that such emissions should be produced by particles accelerated near the event horizon of a supermassive black hole located there.   This is the first time this phenomenon has been observed outside our own Galaxy and it opens up new opportunities for studying particle acceleration processes around black holes. Black holes are among the most exotic objects known to science. They have no surface or edge but instead exist as singularities where space-time ends. In addition they exert enormous gravitational forces so that even light cannot escape their grasp. However, despite these extreme conditions, some scientists believe that matter can still be accelerated close to the speed of light inside the so-called \"event horizons\" surrounding black holes. Such high energy phenomena could produce extremely energetic photons called \"TeV gammas\" - short for Tera-Electron-Volt photons. These would then be detectable using ground-based telescopes like those used by the High Energy Stereoscopic System (HESS). On April 10, 2014, astronomers working with the HESS observatory announced the detection of TeV-gamma rays originating from the central region of the distant galaxy Messier 87 (M87), about 50 million light years away [1] . This was the first time that such radiation had ever been seen outside our own Milky Way [2] , opening up exciting possibilities for studying particle accelerators associated with black holes [3] .\nIn order to understand how this discovery came about we need to know more about what happens when matter falls into a black hole. As shown in Figure 1 below, if you were standing next to one you'd see nothing special happening until your distance from its centre became smaller than its Schwarzschild radius [4] . At this point gravity becomes so strong that all forms of matter become trapped inside the black hole's event horizon [5] . Inside the event horizon, however,...",
        "watermark_text": "The authors report on observations made with the HESS telescope array, which detected emission at energies above 1TeV ( 1 teraelectronvolt ) coming from an area within 0. 2 degrees of the center of the galaxy M87.The data are consistent with theoretical expectations that such emissions should be production by particles advanced near the event horizon of a supermassive black gap located there.This is the first time this phenomenon has been observed outside our own Galaxy and it opens up new opportunities for investigating particle acceleration processes around black holes.Black holes are among the most exotic objects known to science.They have no surface or edge but instead exist as singularities where space - time ends.In addition they exert enormous gravitational forces so that even light cannot escape their grasp.However, despite these extreme conditions, some scientists think that matter can still be accelerated close to the speed of light within the so - named \" event horizons \" surrounding black holes.Such high energy phenomena could produce extremely energetic photons called \" TeV gammas \" - short for Tera - Electron - Volt photons.These would then be detectable using ground - based telescopes like those used by the High Energy Stereoscopic System ( HESS ).On April 10, 2014, astronomers working with the HESS observatory announced the detection of TeV - gamma rays originating from the central area of the distance galaxy Messier 87 ( M87 ), about 50 million light years away [ 1 ].This was the first time that such radiation had yet been seen outside our own Milky Way[ 2 ], opening up exciting possibilities for studying particle accelerators associated with black holes [ 3 ].In order to understand how this discovery came about we need to know more about what comes when matter falls into a black hole.As shown in Figure 1 below, if you were standing next to one you ' d see nothing special happening until your distance from its centre became smaller than its Schwarzschild radius [ 4 ].At this point gravity becomes so strong that all forms of material become trapped inside the black hole ' s event horizon[ 5 ].Inside the event horizon, however,."
    },
    {
        "original_text": "We present an open-source code, called XSCORT (X-ray Spectral Code for Reprocessed Torus), which computes the reprocessing of radiation by optically-thick matter in the form of a torus and its associated wind. The code is written as a set of IDL routines that can be easily modified to study different geometries or physical conditions. We describe how we implemented our model using Monte Carlo techniques and discuss some tests performed with simulated data. Finally, we show examples of applications of this new tool to two well-studied objects, NGC 4151 and Mrk 509. \nThe main goal of XSCORT is to provide a flexible framework where one can explore the effects of various parameters such as: geometry, density distribution, chemical composition, ionization state, etc., on the observed spectral properties of active galactic nuclei (AGN). This will allow us to better understand their nature and evolution. \n \n In particular, we are interested in studying the effect of the presence of an outflowing component on the shape of the reflection hump produced by the innermost regions of the accretion disc around supermassive black holes. These winds may play an important role in shaping the broad-band continuum emission of these sources through absorption and/or scattering processes. They also affect the amount of material available to produce the reflected emission at larger distances from the central source.",
        "watermark_text": "We present an open - source code, called XSCORT ( X - ray Spectral Code for Reprocessed Torus ), which computes the reprocessing of radiation by optically - thick matter in the form of a torus and its associated wind.The code is written as a set of IDL routines that can be easily modified to study different geometries or physical conditions.We describe how we implemented our model utilizing Monte Thom techniques and discuss some tests performed with simulated data.Finally, we show examples of applications of this new tool to two well - studied objects, NGC 4151 and Mrk 509.The main goal of XSCORT is to provide a flexible structure where one can investigate the effects of various parameters such as : geometry, dense distribution, chemical composition, ionization state, also., on the observed spectral properties of active galactic nuclei ( AGN ).This will allow us to better understand their nature and evolution.In particular, we are interested in studying the effect of the presence of an outflowing component on the shape of the reflection hump produced by the innermost regions of the accretion disc around supermassive black holes.These winds may play an important role in shaping the broad - band continuum emission of these sources through absorption and / or scattering processes.They also affect the amount of material accessible to produce the reflected emission at bigger distances from the central source."
    },
    {
        "original_text": "The cosmological constant is one of the most important parameters in modern physics, and its value has been determined by observations to be extremely small but nonzero.  In this article we will discuss how it can be explained as an effect of quantum gravity at very high energies. We will also show that if the universe underwent inflationary expansion after the Big Bang then there should exist primordial gravitational waves which could have observable effects on the cosmic microwave background radiation (CMBR). Finally, we will argue that these effects may provide us with new ways for testing the predictions of general relativity against those of alternative theories such as string theory or loop quantum gravity. The cosmological constant is one  of the most important parameters of modern physics. Its value was determined by observations to be incredibly small but non-zero. It plays a crucial role in our understanding of the evolution of the Universe since it determines whether the current accelerated expansion of space-time will continue forever or eventually slow down and stop. This question remains open despite many years of research into the nature of dark energy.",
        "watermark_text": "The cosmological constant is 1 of the most important parameters in modern physics, and its value has been determined by measurements to be extremely small but nonzero.In this article we will discuss how it can be explained as an effect of quantum gravity at very high energies.We will also show that if the universe experienced inflationary expanding after the Big Bang then there should exist primordial gravity waves which could have observable effects on the cosmic microwave background radiation ( CMBR ).Finally, we will argue that these impacts may supply us with new ways for testing the expectations of general relativity against those of alternative theories such as string relativity or loop quantum gravity.The cosmological constant is 1 of the most important parameters of modern physics.Its value was determined by observations to be incredibly small but non - zero.It plays a crucial role in our interpretation of the evolution of the Universe since it determines whether the current accelerated expansion of space - time will continue forever or eventually slow down and stop.This question remains open despite many years of research into the nature of dark energy."
    },
    {
        "original_text": "We present the results of a numerical study on the relaxation dynamics of an initially straight contact line in a two-dimensional geometry, which is driven by surface tension and viscous dissipation at the moving interface between liquid and gas phases.  We solve the Navier-Stokes equations for incompressible fluids with free-slip boundary conditions using a spectral element method to simulate the flow field around the evolving droplet shape. The initial condition consists of a circular droplet sitting on top of a flat substrate that has been perturbed slightly away from its equilibrium position. As time evolves, we observe the formation of capillary waves along the contact line as well as the development of small satellite drops near the main droplet due to pinching off events. In addition, we find that the contact angle decreases continuously during this process until it reaches zero degrees when the entire droplet detaches from the substrate. Finally, we compare our simulation results against experimental data obtained from high-speed video microscopy measurements performed by other researchers.",
        "watermark_text": "We present the results of a numerical study on the relaxation dynamics of an initially straight contact line in a two - dimensional geometry, which is driven by surface tension and viscous dissipation at the moving interface between liquid and gas phases.We solve the Navier - Stokes equations for incompressible fluids with free - slip boundary conditions utilizing a spectral element method to simulate the flow field around the evolving droplet shape.The initial condition consists of a circular droplet sitting on top of a flattened substrate that has been perturbed slightly away from its equilibrium position.As time evolves, we observe the formation of capillary waves along the contact line as also as the development of little satellite drops near the main droplet due to pinching off events.In addition, we find that the contact angle decreases continuously during this procedure until it becomes zero ° when the entire droplet detaches from the substrate.Finally, we compare our simulation results against experimental data obtained from high - fast video microscopy measurements performed by other researchers."
    },
    {
        "original_text": "We present an exact solution to the classical equations of motion in two dimensions, which is interpreted as describing a rotating black hole with angular momentum J = M . The metric has the form ds2 = −dt2+(1+cosh2r)dθ2−r2dr2,\nwhere r and θ are polar coordinates on the plane. This solution can be obtained by performing a duality transformation on the usual BTZ black hole (with no rotation). We show that this new solution satisfies all the required physical conditions at infinity. In particular we find that it describes a regular black hole horizon located atr+ = √3M , where M is the mass parameter appearing in the original BTZ solution. Finally, we discuss some possible generalizations of our results. Introduction:-In recent years there have been many attempts to construct solutions to Einstein's field equations corresponding to rotating black holes [1] - [4] . One particularly interesting class of such solutions was found by Bañados, Teitelboim and Zanelli (BTZ), who showed how one could obtain a static black hole solution in three dimensional anti-de Sitter space-time [5] .\nThe most important feature of these solutions is their asymptotic behaviour; they describe black holes whose event horizons are completely determined by global quantities like total energy or charge [6] . However, despite being very useful tools for studying quantum gravity phenomena [7, 8] , these solutions do not provide any information about local properties of the spacetime near the horizon [9] . It would therefore seem desirable to try to extend them into more complicated geometries containing additional parameters characterizing the internal structure of the black hole [10] .\nOne way of doing so is to consider higher-dimensional extensions of the BTZ solution [11] . Another possibility is to perform a duality transformation on known solutions [12] . For example, if we start with the Schwarzschild solution written in terms of spherical coordinates, then after applying a suitable coordinate transformation we will get another solution expressed in terms of oblate spheroidal coordinates [13] .",
        "watermark_text": "We present an exactly solution to the classical equations of motion in two dimensions, which is interpreted as describing a rotating black hole with angular momentum J = M.The metric has the metric ds2 = −dt2 + ( 1 + cosh2r ) dθ2−r2dr2, where r and θ are polar coordinates on the plane.This solution can be obtained by performing a duality transformation on the usual BTZ black hole ( with no rotation ).We show that this new resolution satisfies all the required physical conditions at infinity.In particular we find that it describes a regular black hole horizon located atr + = √3M, where M is the mass parameter appearing in the original BTZ solution.Finally, we discuss some possible generalizations of our results.Introduction : - In recent years there have been many tries to construct solutions to Einstein ' s field equations corresponding to rotating black holes [ 1 ] - [ 4 ].One particularly interesting class of such solutions was found by Bañados, Teitelboim and Zanelli ( BTZ ), who showed how one could obtain a static dark hole solution in 3 dimensional anti - de Sitter space - time [ 5 ].The most important feature of these solutions is their asymptotic behaviour ; they describe dark holes whose event horizons are completely determined by global quantities including total energy or charge [ 6 ].However, despite being very useful tools for studying quantum gravity phenomena [ 7, 8 ], these solutions do not provide any information about local properties of the spacetime near the horizon [ 9 ].It would therefore seem desirable to attempt to expand them into more complex geometries containing additional parameters characterizing the inner structure of the pale hole [ 10 ].One way of doing so is to consider higher - dimension extensions of the BTZ solution [ 11 ].Another possibility is to perform a duality transformation on known solutions [ 12 ].For example, if we start with the Schwarzschild solve written in terms of spherical coordinates, then after applying a appropriate coordinate transformation we will obtain another solution expressed in terms of oblate spheroidal coordinates [ 13 ]."
    },
    {
        "original_text": "We present an analysis of the nonlocal phenomenology in magnetohydrodynamic (MHD) turbulence with strong magnetic field anisotropy, which is relevant to solar wind and space plasmas. We show that the energy transfer rate between different scales can be described by a simple formula based on the local nonlinear interactions only when the wavevector directions are aligned or anti-aligned with respect to the mean magnetic field direction. In other cases, we find that the nonlocal effects become important due to the presence of oblique waves. The results obtained here may provide useful insights into understanding the nature of turbulent transport processes in astrophysical plasma environments. Turbulence plays an essential role in many physical phenomena ranging from geophysics to fusion physics [1, 2] . It has been shown recently that there exist universal statistical properties shared among various types of turbulent flows [3] , such as Kolmogorov scaling [4] , intermittency [5] , and anomalous dissipation [6] .\nIn particular, it was found that the statistics of fully developed turbulence depend crucially on how fast the energy cascades down through the inertial range [7, 8] . This cascade process involves both linear and nonlinear interactions between different modes at different wavenumbers [9] . For example, in hydrodynamics, the energy flux Π(k) ≡< |δu k · δu * −k | 2 > / < u 2 k > depends not only on the magnitude of the wavenumber k but also its orientation relative to the large-scale flow [10] . Here, u k denotes the Fourier transform of velocity fluctuations at scale k −1 . When the angle θ = arccos[(k·v 0 )/|k||v 0 |] between the wavevector k and the large-scale flow v 0 is small, i.e., θ ≪ 1, the energy flux Π ∝ k −2/3 sin 2/3 θ [11] . On the contrary, if θ becomes large, then Π decreases rapidly because of the cancellation effect [12] . Similar behaviors have been observed in magnetohydrodynamics (MHD), where the energy flux Π �",
        "watermark_text": "We present an analysis of the nonlocal phenomenology in magnetohydrodynamic ( MHD ) turbulence with strongly magnetic field anisotropy, which is relevant to sun wind and space plasmas.We show that the energy transfer rate between different scales can be described by a simple formula based on the local nonlinear interactions only when the wavevector directions are aligned or anti - aligned with reference to the mean magnetic field direction.In other cases, we find that the nonlocal affects become important due to the presence of oblique waves.The results obtained here may provide helpful insights into understanding the nature of turbulent transport processes in astrophysical plasma environments.Turbulence plays an essential role in many physical phenomena ranging from geophysics to fusion phenomena [ 1, 2 ].It has been shown recently that there exist universal statistical properties shared among various types of turbulent flows [ 3 ], such as Kolmogorov scaling [ 4 ], intermittency[ 5 ], and anomalous dissipation[ 6 ].In particular, it was found that the statistics of fully developed turbulence depend crucially on how fast the energetic cascades down through the inertial range [ 7, 8 ].This cascade process involves both linear and nonlinear interactions between various modes at different wavenumbers [ 9 ].For example, in hydrodynamics, the energy flux Π ( k ) ≡ / depends not only on the magnitude of the wavenumber k but also its inclination relative to the big - scale flow [ 10 ].Here, u k denotes the Fourier transform of velocity fluctuations at scale k −1.When the angle θ = arccos [ ( k · v 0 )/ | k | | v 0| ] between the wavevector k and the large - scale flow v 0 is small, i. e., θ [UNK] 1, the energy flux Π [UNK] k −2 / three sin 2 / 3 θ [ 11 ].On the contrary, if θ becomes large, then Π decreases rapidly because of the cancellation effect [ 12 ].Similar behaviors have been observed in magnetohydrodynamics ( MHD ), where the energetic flux Π"
    },
    {
        "original_text": "Entropies are measures of uncertainty, and entropy power inequalities (EPIs) quantify the trade-off between information transmission rates in different communication channels.  In this work we present new proofs for EPIs based on information theory concepts such as mutual information and channel capacity.   We also show that these results can be used to prove Shannon's source coding theorem by applying them to an appropriate binary memoryless symmetric channel model. Finally, we discuss how our approach could potentially lead to improved bounds on the minimum distance of linear block codes over finite fields. Entropies are measures of uncertainty; entropy power inequalities (EPIS) quantify the tradeoff between information transmission rates in various communication channels. In this work we present novel proofs for EPIs using information-theory concepts like mutual information and channel capacity. We also demonstrate that these results may be utilized to verify Shannon's source coding theorem via their application to a suitable binary memoryless-symmetric channel model. Finally,we discuss how our technique might possibly yield better bounds on the minimal distance of linear block codes across finite fields.",
        "watermark_text": "Entropies are measures of uncertainty, and entropy power inequalities ( EPIs ) quantify the trade - off between information transmission rates in different communication channels.In this work we present fresh proofs for EPIs based on information theory concepts such as mutual information and channel capacity.We also show that these results can be used to prove Shannon ' s source coding theorem by applying them to an appropriate binary memoryless symmetric channel model.Finally, we discuss how our approach could potentially lead to improved bounds on the minimal distance of linear block codes over finite fields.Entropies are measures of uncertainty ; entropy power inequalities ( EPIS ) quantify the tradeoff between information transmission rates in various communication channels.In this work we present novel proofs for EPIs using information - theoretical concepts like mutual info and channel capacity.We also demonstrate that these results may be utilized to verify Shannon ' s source coding theorem via their applied to a appropriate binary memoryless - symmetric channel model.Finally, we discuss how our technique may possibly produce better bounds on the minimum distance of linear block codes across finite fields."
    },
    {
        "original_text": "We present the results of an analysis of the 2 Micron All Sky Survey (2MASS) data for quasars with broad absorption lines (BALQSOs). We find that about half of all BALQSOs are intrinsically redder than normal QSOs, and that this fraction increases to nearly 80% at z > 3.5. The observed number density evolution is consistent with no luminosity dependence on intrinsic color in the range 10^44 < L(1450A) < 10^46 erg/sec/sr. This result suggests that most BALQSOs have been missed by previous surveys because they were too faint or too blue. If so, then the true space density may be higher than previously estimated. \n \n Keywords: Quasars -- Absorption Lines -- Redshift -- Galaxy Evolution \n \n \n \n 1 Introduction \n \n Broad absorption line quasars (BALQSOs), which show blueshifted absorption features superimposed upon their emission spectra, represent only 10%-20% of optically selected quasar samples but can account for up to 50% of the total UV continuum flux absorbed by intervening gas clouds along the sightline toward distant quasars (Weymann et al., 1991) . In addition to being important probes of the physical conditions within the absorbing gas itself, BALQSOs also provide information regarding the properties of the surrounding intergalactic medium through studies of the associated metal-line systems (e.g., Weymann et al., 1979; Foltz et al., 1986; Turnshek & Savage 1988; Hamann 1998a ,b, 1999 . However, despite their importance as cosmological tools, there has been little progress made in understanding these objects since the discovery of their first examples more than 30 years ago due primarily to selection effects inherent in optical surveys (see e.g., Hewett & Foltz 2003 ) . \n \n Recently, several authors have suggested that many BALQSOs could be found among infrared-selected sources using large-area near-infrared sky surveys such as the Two-Micron All-Sky Survey (2MASS) (Cutri et",
        "watermark_text": "We present the results of an analysis of the 2 Micron All Sky Survey ( 2MASS ) data for quasars with broad absorption lines ( BALQSOs ).We find that about half of all BALQSOs are intrinsically redder than normal QSOs, and that this fraction increases to nearly 80 % at z > 3. 5.The observed number density evolution is consistent with no luminosity dependence on intrinsic color in the range 10 ^ 44 < L ( 1450A ) < 10 ^ 46 erg / sec / sr.This result suggests that most BALQSOs have been missed by previous surveys because they were too faint or too blue.If so, then the truth space density may be upper than previously estimated.Keywords : Quasars - - Absorption Lines - - Redshift - - Galaxy Evolution 1 Introduction Broad absorption line quasars ( BALQSOs ), which show blueshifted absorption features superimposed upon their emission spectra, represent only 10 % - 20 % of optically selected quasar samples but can account for up to 50 % of the total UV continuum flux absorbed by intervening gas clouds along the sightline toward distant quasars ( Weymann et al., 1991 ).In addition to being important probes of the physical conditions within the absorbing gas itself, BALQSOs also provide information concerning the properties of the surrounding intergalactic medium through studies of the associated metal - line systems ( e. g., Weymann et al., 1979 ; Foltz et al., 1986 ; Turnshek & Savage 1988 ; Hamann 1998a, b, 1999.However, despite their importance as cosmological tools, there has been little progress made in learning these items since the discovery of their first examples more than thirty years ago due primarily to selection effects inherent in optical surveys ( see e. g., Hewett & Foltz 2003 ).Recently, several authors have suggested that many BALQSOs could be found among infrared - selected sources using large - region near - infrared sky surveys such as the Two - Micron All - Sky Survey ( 2MASS ) ( Cutri et"
    },
    {
        "original_text": "We present the Hamiltonian formulation for general relativity with matter fields on an arbitrary spacetime manifold, including both classical and quantum aspects. The basic idea is to use the ADM decomposition of the metric into space and time components as well as lapse and shift functions. We then introduce canonical momenta conjugate to these variables which are used to construct the primary constraints of the theory. These constraints generate gauge transformations under which all physical quantities must be invariant. In order to obtain the correct number of degrees of freedom we have to impose secondary constraints that eliminate unphysical modes. Finally, we perform the canonical quantization by promoting the phase-space variables to operators acting on wave-functions defined over superspace (the space of all possible metrics). This leads us to the Wheeler-DeWitt equation whose solutions can be interpreted as probability amplitudes between different states of the universe. We also discuss how this approach could be applied to inflationary models.",
        "watermark_text": "We present the Hamiltonian formulation for general relativity with matter fields on an arbitrary spacetime manifold, including both classical and quantum aspects.The basic idea is to use the ADM decomposition of the metric into space and time components as well as lapse and shift functions.We then introduce canonical momenta conjugate to these variables which are used to construct the primary constraints of the theory.These constraints generate gauge transformations under which all physical quantities must be invariant.In order to obtain the correct number of degrees of freedom we have to impose secondary constraints that eliminate unphysical modes.Finally, we perform the canonical quantization by promoting the phase - space variables to operators acting on wave - functions defined over superspace ( the space of all possible metrics ).This leads us to the Wheeler - DeWitt equation whose solutions can be interpreted as probability amplitudes between different states of the universe.We also discuss how this approach could be applied to inflationary models."
    },
    {
        "original_text": "The effect of adding small amounts (0.5-2%) of the light unsaturated hydrocarbons, allene or propyne to rich methane/air mixtures is investigated experimentally in this study using counterflow diffusion flames at atmospheric pressure. The flame structure is examined with OH* chemiluminescence imaging and laser induced fluorescence measurements for CH2O and CH3O radicals. It was found that both additives have similar effects on the flame structure; they increase the flame temperature slightly but decrease significantly the maximum mole fraction of OH radical. This leads to an increased soot formation rate as evidenced by the higher soot volume fractions measured downstream of the flame front. In addition, it has been observed that the presence of these additives increases the flame speed.  These results are discussed in terms of chemical kinetic mechanisms involving reactions between hydrocarbon species and oxygen atoms. Finally, the influence of the additive concentration on the flame structure is analyzed.",
        "watermark_text": "The effect of addition small amounts ( 0. 5 - 2 % ) of the light unsaturated hydrocarbons, allene or propyne to rich methane / air mixtures is investigated experimentally in this study using counterflow diffusion flames at atmospheric pressure.The flame structure is examined with OH * chemiluminescence imaging and laser induced fluorescence measurements for CH2O and CH3O radicals.It was found that both additives have comparable effects on the flame structure ; they increase the flame temperature somewhat but decrease significantly the maximum mole fraction of OH radical.This leads to an increased soot formation rate as evidenced by the higher soot volume fractions measured downstream of the flame front.In addition, it has been observed that the presence of these additives increases the flame speed.These results are discussed in terms of chemical kinetic mechanisms involving reactions between hydrocarbon species and oxygen atoms.Finally, the influence of the additive concentration on the flame structure is examined."
    },
    {
        "original_text": "We present the results of our numerical simulations on the shallow-decay phase of GRB X-ray light curves, which are produced by the interaction between an ultra-relativistic jet and its surrounding medium in the framework of the internal shock model for GRBs. We find that this phase is mainly due to the continuous energy injection into the forward shock driven by the expanding bubble formed at the head of the jet. The injected energy comes from the kinetic energy of the swept-up shell material as well as the thermal energy of shocked ambient gas inside the bubble. Our simulation results show good agreement with observations both qualitatively and quantitatively. \n \n Keywords: Gamma-ray bursts (GRBs), Afterglow emission, Relativistic winds, Shock waves, Bubbles, Internal shocks, Wind-driven shells, Energy injection, Light curve modeling \n \n 1 Introduction \n \n In recent years, great progress has been made in understanding the origin of gamma-ray bursts (GRBs; see Piran 2004 , Zhang 2007a . It was found that most GRBs have their prompt emissions followed by a relatively smooth power-law decline lasting several hundred seconds known as the \"afterglow\" phase (Costa et al. 1997; van Paradijs et al. 1997) . This phase can be explained by synchrotron radiation from electrons accelerated behind the blast wave generated when the ejecta hits the circumburst medium (Sari et al. 1998 ). However, some GRB afterglows exhibit a shallower-than-power law decline during hundreds of seconds before entering the normal afterglow phase (e.g., Panaitescu & Kumar 2001; Nousek et al. 2006; Liang et al. 2007; Willingale et al. 2007) , which cannot be explained within the standard fireball model. Several models were proposed to explain these phenomena, including late-time central engine activity (Zhang 2007b ), refreshed-shock scenario (Ghisellini et al. 2007 ) and reverse shock emission (Kobayashi 2000; Kobayashi & Sari 2001) . Recently, Fan & Wei (2007) suggested that the shallow-decay phase",
        "watermark_text": "We present the results of our numerical simulations on the shallow - decay phase of GRB X - ray light curves, which are produced by the interaction between an ultra - relativistic jet and its surrounding medium in the framework of the internal shock model for GRBs.We find that this phase is mainly caused to the constant energy insertion into the forward shock driven by the expanding bubble formed at the head of the jet.The injected energy comes from the kinetic energy of the swept - up shell material as also as the thermal energy of shocked ambient gas within the bubble.Our simulation results show good agreement with observations both qualitatively and quantitatively.Keywords : Gamma - ray bursts ( GRBs ), Afterglow emission, Relativistic winds, Shock waves, Bubbles, Internal shocks, Wind - driven shells, Energy injection, Light curve modeling 1 Introduction In recent years, great progress has been made in understanding the origin of gamma - ray bursts ( GRBs ; see Piran 2004, Zhang 2007a.It was found that most GRBs have their prompt emissions followed by a relatively smooth power - law decline lasting many hundred seconds known as the \" afterglow \" phase ( Costa imp al. 1997 ; van Paradijs et al. 1997 ).This phase can be explained by synchrotron radiation from electrons accelerated behind the blast wave generated when the ejecta hits the circumburst medium ( Sari et al. 1998 ).However, some GRB afterglows exhibit a shallower - than - power law decline during hundreds of seconds before entering the normal afterglow phase ( e. g., Panaitescu & Kumar 2001 ; Nousek et al. 2006 ; Liang et al. 2007 ; Willingale et al. 2007 ), which cannot be explained within the standard fireball model.Several models were proposed to explain these phenomena, including late - time central engine activity ( Zhang 2007b ), refreshed - shock scenario ( Ghisellini et al. 2007 ) and reverse shock emission ( Kobayashi 2000 ; Kobayashi & Sari 2001 ).Recently, Fan & Wei ( 2007 ) suggested that the shallow - decay phase"
    },
    {
        "original_text": "The present work is devoted to the study of astrophysical plasma turbulence, with particular emphasis on its statistical properties at different scales. We consider both kinetic and fluid descriptions for the dynamics of collisionless plasmas, which are relevant for many space and laboratory applications. In this context we investigate the nonlinear evolution of magnetic fluctuations by means of direct numerical simulations (DNS) of the Vlasov-Maxwell system. The main results can be summarized as follows:  1. Turbulence statistics -We perform DNSs of the Vlasov-Poisson system in order to characterize the statistical properties of the electrostatic potential fluctuations generated by an initial spectrum of Alfvenic modes. Our analysis shows that the energy cascade proceeds towards smaller spatial scales until it reaches the ion Larmor radius scale where it is transferred into perpendicular wavenumbers through Landau damping. At these small scales, the energy transfer rate decreases due to the reduction of phase correlations between wavevectors. This process leads to the formation of intermittency in the distribution function of particles.  2. Kinetic effects -In addition to the above mentioned features observed in the case of purely hydrodynamic turbulence, our results show that kinetic effects play also an important role in determining the statistical properties of the fluctuating fields. Indeed, we find that the presence of ions modifies significantly the shape of the probability density functions (PDFs), leading to non-Gaussian distributions characterized by tails extending over several orders of magnitude. Moreover, we observe that the PDFs become more skewed when increasing the value of the ion-to-electron mass ratio. Finally, we discuss how the inclusion of kinetic effects affects the scaling laws characterizing the power spectra of the fluctuating fields. \n3. Fluid description -By performing DNSs of the Euler-",
        "watermark_text": "The present work is devoted to the study of astrophysical plasma turbulence, with particular emphasis on its statistical properties at different scales.We consider both kinetic and fluid descriptions for the dynamics of collisionless plasmas, which are relevant for many space and laboratory applications.In this context we investigate the nonlinear evolution of magnetic fluctuations by way of directly numerical simulations ( DNS ) of the Vlasov - Maxwell system.The main results can be summarized as follows :1.Turbulence statistics - We perform DNSs of the Vlasov - Poisson system in order to characterize the statistical properties of the electrostatic potential fluctuations generated by an initial spectrum of Alfvenic modes.Our analysis shows that the energy cascade proceeds towards smaller spatial scales until it reaches the ion Larmor radius scale where it is transferred into perpendicular wavenumbers through Landau damping.At these small scales, the energy transfer rate decreases due to the reduction of phase correlations between wavevectors.This process leads to the formation of intermittency in the distribution function of particles.2.Kinetic effects - In addition to the above mentioned features observed in the case of purely hydrodynamic turbulence, our results show that kinetic effects play also an important role in determining the statistical properties of the fluctuating fields.Indeed, we find that the presence of ions modifies significantly the shape of the likelihood density functions ( PDFs ), leading to non - Gaussian distributions characterized by tails extending over several orders of magnitude.Moreover, we observe that the PDFs become more skewed when raising the value of the ion - to - electron mass ratio.Finally, we discuss how the inclusion of kinetic effects affects the scaling laws characterizing the power spectra of the fluctuating fields.3.Fluid description - By performing DNSs of the Euler -"
    },
    {
        "original_text": "We present an ab initio tight-binding model for calculating the optical properties of semiconductor nanocrystals, which is based on the solution of the Bethe-Salpeter equation (BSE) within the framework of density functional theory (DFT). The BSE describes excitonic effects and allows to calculate absorption spectra with high accuracy. We show that our approach reproduces experimental results very well. In particular we find good agreement between calculated and measured absorption cross sections at low energies where quantum confinement dominates over electron-hole exchange interactions. Our method can be applied to any type of semiconductor material including doped systems as well as core-shell structures. Semiconductor nanocrystals are promising candidates for applications such as light-emitting diodes or solar cells due to their unique optoelectronic properties. However, it remains challenging to predict these properties accurately since they depend sensitively on the electronic structure of the system. Here we propose a new theoretical approach to tackle this problem by combining DFT calculations with the Bethe-Salpether equation (BSE), which takes into account excitonic effects beyond mean-field approaches like Kohn-Sham DFT. This enables us to obtain accurate predictions for the optical properties of semiconductor nanostructures.",
        "watermark_text": "We present an ab initio tight - binding model for calculating the optical properties of semiconductor nanocrystals, which is based on the solution of the Bethe - Salpeter equation ( BSE ) within the framework of density functional theory ( DFT ).The BSE describes excitonic effects and allows to calculate absorption spectra with high accuracy.We show that our approach reproduces experimental results very well.In particular we find good agreement between calculated and monitored absorption across sections at low energies where quantum confinement dominates over electron - hole exchange interactions.Our method can be applied to any type of semiconductor material including doped systems as well as core - shell structures.Semiconductor nanocrystals are promising candidates for applications such as light - emitting diodes or sun cells due to their unique optoelectronic properties.However, it remains challenging to predict these properties accurately since they depend sensitively on the electronic structure of the system.Here we propose a new theoretical approach to tackle this problem by combining DFT calculations with the Bethe - Salpether equation ( BSE ), which takes into consider excitonic effects beyond mean - field approaches like Kohn - Sham DFT.This enables us to obtain accurate predictions for the optical properties of semiconductor nanostructures."
    },
    {
        "original_text": "The spectrum of cosmic rays is determined by the energy distribution of particles accelerated at shocks formed during supernova explosions and their subsequent propagation through space.  The observed fluxes are consistent with theoretical predictions for shock acceleration if one assumes that most cosmic rays have been accelerated to energies above 10^15 eV (the \"knee\") but below 10^17 eV (the \"ankle\"). Above this energy there appears to be an additional component which may be due to some other mechanism such as magnetic reconnection or turbulence driven acceleration. This article reviews recent progress on understanding the origin of cosmic rays up to the highest energies detected so far. Cosmic ray observations show that they consist mainly of protons and helium nuclei with charge numbers Z=1-2. These ions can reach energies up to 10^{20}eV, corresponding to Lorentz factors of about 10^{10}. Their total power input into interstellar space amounts to about 10% of the solar luminosity.",
        "watermark_text": "The spectrum of cosmic rays is determined by the energy distribution of particles accelerated at shocks formed during supernova explosions and their ensuing propagation through space.The observed fluxes are consistent with theoretical predictions for shock acceleration if 1 assumes that most cosmic rays have been accelerated to energies above 10 ^ 15 eV ( the \" knee \" ) but below ten ^ 17 eV ( the \" ankle \" ).Above this energy there appears to be an additional component which might be due to some other mechanism such as magnetic reconnection or turbulence driven acceleration.This article reviews recent progress on understanding the source of cosmic rays up to the highest energies detected so far.Cosmic ray observations show that they consist mainly of protons and helium nuclei with charge counts Z = 1 - 2.These ions can reach energies up to 10 ^ { 20 } eV, corresponding to Lorentz factors of about 10 ^ { 10 }.Their total power input into interstellar space amounts to about 10 % of the solar luminosity."
    },
    {
        "original_text": "The structural, magnetic susceptibility (χ), electrical resistivity (), thermal conductivity () and specific heat capacity (C) measurements were performed on MgB2 single crystal samples doped by lithium (Li). The substitution of the magnesium atoms in MgB2 lattice by Li leads to an increase of Tmax = 39 K for x=0.1 up to Tmax = 43 K for x= 0.2 at ambient pressure. In addition, we have found that the critical temperature Tc increases monotonically as function of applied hydrostatic pressure P reaching its maximum value of 38.5 K at P = 1 GPa. We also studied the effect of carbon doping into MgB2 structure. It was shown that the introduction of C into MgB2 results in a decrease of both Tmax and Tc values down to 31 K and 27.7 K respectively. \n \n Keywords: Superconductor, MgB2, Lithium",
        "watermark_text": "The structural, magnetic susceptibility ( χ ), electrical resistivity ( ), heat conductivity ( ) and specific heat capacity ( C ) measurements were performed on MgB2 single crystal samples doped by lithium ( Li ).The substitution of the magnesium atoms in MgB2 lattice by Li leads to an rise of Tmax = 39 K for x = 0. 1 up to Tmax = 43 K for x = 0. 2 at ambient pressure.In addition, we have found that the critical temperature Tc increases monotonically as function of application hydrostatic pressure P reaching its highest value of 38. 5 K at P = 1 GPa.We also studied the effect of carbon doping into MgB2 structure.It was shown that the introduction of C into MgB2 results in a decrease of both Tmax and Tc values down to 31 K and 27. 7 Pak respectively.Keywords : Superconductor, MgB2, Lithium"
    },
    {
        "original_text": "Social tagging is an emerging technology that allows users to annotate resources with keywords or tags, which are then used by other users in their search and discovery processes. In this work we propose a novel approach to exploit social annotation information for automatic resource discovery. We first introduce the concept of semantic similarity between tags based on WordNet ontology. Then, using the proposed semantic similarity measure as well as user profile information, we develop two algorithms (i) TagRank and (ii) UserTagRank to rank the importance of each tag associated with a given resource. Finally, we conduct experiments over real-world datasets collected from Delicious website to evaluate our approaches. The experimental results show that both TagRank and UserTagRank can significantly improve the performance of existing state-of-the-art techniques. Keywords: Semantic Web, Social Tagging, Resource Discovery, Ranking Algorithms. 1 Introduction Social tagging has become one of the most popular ways for people to organize and share web content such as blogs, photos, videos etc., especially among Internet users who have little knowledge about how to use traditional search engines effectively [1] . Users usually assign tags to describe the contents they find interesting so that others may easily discover them later [2] .\nIn recent years there has been growing interest in developing new technologies to take advantage of social tagging systems [3] , including recommender systems [4] , personalized search [5] , question answering [6] , text classification [7] , event detection [8] , and so forth. However, despite these efforts, research into utilizing social tagging data for automatic resource discovery remains relatively unexplored [9] .",
        "watermark_text": "Social tagging is an emerging technology that allows users to annotate resources with keywords or tags, which are then used by other users in their search and discovery processes.In this work we propose a novel approach to exploit social annotation information for automatic resource discovery.We first introduce the concept of semantic similarity between tags based on WordNet ontology.Then, using the proposed semantic similarity measure as well as user profile information, we develop two algorithms ( i ) TagRank and ( ii ) UserTagRank to rank the importance of each tag associated with a given resource.Finally, we conduct experiments over real - world datasets collected from Delicious website to evaluate our approaches.The experimental results show that both TagRank and UserTagRank can significantly improve the performance of existing state - of - the - art techniques.Keywords : Semantic Web, Social Tagging, Resource Discovery, Ranking Algorithms.1 Introduction Social tagging has become one of the most prevalent ways for people to organise and share web content such as blogs, photos, videos etc., especially amongst Internet users who have little knowledge about how to use traditional search engines effectively [ 1 ].Users usually assign tags to describe the contents they find interesting so that others may easily discover them later [ 2 ].In recent years there has been growing interest in developing novel technologies to take use of social tagging systems[ 3 ], including recommender systems[ 4 ], personalized search [ 5 ], question answering [ 6 ], text classification [ 7 ], event detection[ 8 ], and so forth.However, despite these efforts, research into utilizing social tagging data for automatic resource discovery remains relatively unexplored [ 9 ]."
    },
    {
        "original_text": "The neutron dynamic structure factor (NDSF) is calculated by using molecular dynamics simulation and the density functional theory with generalized gradient approximation(GGA). The NDSF shows two peaks at low wave number region, which are assigned to the translational motion of methane molecules. At high wave number region, one peak appears around 2 Å-1 ,which corresponds to the libration mode of CH4 molecule. In addition, we find that there exists another peak near 3 Å-1 . This new peak can be explained as the result of the rotation of CH3 group against the C-H bond direction. We also calculate the partial structure factors Sij(Q), where i and j represent different atoms or groups. From these results, it is found that the main contribution comes from the correlation between carbon atom and hydrogen atom. Finally, we compare our theoretical results with experimental data obtained by Hwang et al..",
        "watermark_text": "The neutron dynamic structure factor ( NDSF ) is calculated by utilizing molecular dynamics simulation and the dense functional theory with generalized gradient approximation ( GGA ).The NDSF displays two peaks at low wave count region, which are assigned to the translational movement of methane molecules.At high wave number region, one peak appears around 2 Å - 1, which corresponds to the libration mode of CH4 molecule.In addition, we find that there exists another peak near 3 Å - 1.This new peak can be explained as the result of the rotation of CH3 group against the C - H bond direction.We also calculate the partial structure factors Sij ( Q ), where i and j represent different atoms or groups.From these results, it is found that the major contribution comes from the correlation between carbon atom and hydrogen atom.Finally, we compare our theoretical results with experimental data obtained by Hwang et al."
    },
    {
        "original_text": "We study the effects of selection biases in cluster samples, as well as covariance between observables, on scaling relations derived from X-ray data using mock galaxy clusters generated with the semi-analytic model GALFORM. We find that both these effects can lead to significant systematic errors when deriving cosmological constraints from observed scaling relations. In particular we show that: (i) The scatter in the M-T relation is significantly reduced by including additional information about the temperature distribution function; this effect is stronger for low mass systems. (ii) The slope of the L-M relation depends strongly on whether or not one includes cooling flows in the analysis. This dependence arises because cool cores are more common at high masses than at lower masses, leading to an apparent steepening of the slope if they are excluded. (iii) The normalization of the Y-Xray luminosity-temperature relation shows strong redshift evolution which cannot be explained solely by self-similar evolution.",
        "watermark_text": "We study the effects of selection biases in cluster specimens, as well as covariance between observables, on scaling relations derived from X - ray data using mock galaxy clusters generated with the semi - analytic model GALFORM.We find that both these effects can lead to significantly systematic errors when deriving cosmological constraints from observed scaling relations.In particular we show that : ( i ) The scatter in the M - T relation is significantly reduced by including additional information about the temperature distribution function ; this effect is stronger for low mass systems.( ii )The slope of the L - M relation depends strongly on whether or not one includes cooling flows in the analysis.This dependence arises because cool cores are more common at high masses than at lower masses, resulting to an apparent steepening of the slope if they are excluded.( iii ) The normalization of the Y - Xray luminosity - temperature relation shows strong redshift evolution which cannot be explained solely by self - similar evolution."
    },
    {
        "original_text": "The article presents an analysis of the results obtained in the study of the influence of various factors on the development and functioning of small businesses, which were carried out by Russian scientists over the past decade. The main conclusions are as follows: 1) Small business is one of the most important elements of economic growth; 2) In Russia there has been a significant increase in the number of small enterprises since the beginning of market reforms (from 1990 to 2010 their number increased more than ten times), but this process was accompanied by a decrease in the average size of these companies; 3) There have also been changes in the structure of small businesses; 4) Changes in the legal framework for regulating relations between state authorities and entrepreneurship contributed to the formation of new forms of interaction between them; 5) A positive effect of the reform can be seen in the fact that the share of small businesses in the total volume of industrial production has grown significantly; 6) However, despite all the advantages of small businesses, they still face many problems related both to external conditions and internal management issues; 7) It should be noted that the current situation with small businesses does not correspond fully to the potential of the sector.  8)",
        "watermark_text": "The article presents an analysis of the outcomes obtained in the study of the influence of various factors on the development and functioning of small companies, which were carried out by Russian scientists over the past decade.The main conclusions are as follows : 1 ) Small business is one of the most important elements of economy growth ; 2 ) For Russia there has been a significant increase in the number of small enterprises following the beginning of market reforms ( from 1990 to 2010 their number increased more than ten times ), but this process was accompanied by a decrease in the average size of these companies ; 3 ) There have also been changes in the structure of small businesses ; 4 ) Changes in the legal framework for regulating relations between state authorities and entrepreneurship contributed to the formation of new forms of interaction between them ; 5 ) A positive effect of the reform can be seen in the fact that the share of small businesses in the total volume of industrial production has grown substantially ; 6 ) However, despite all the advantages of small businesses, they still face many problems related both to external conditions and internal management issues ; 7 ) It should be noted that the current situation with small businesses does not correspond fully to the potential of the sector.8 )"
    },
    {
        "original_text": "We propose an algorithm that learns how to segment time series data into meaningful segments by using a combination of Recurrent Neural Network (RNN) Experts and Adaptive Variance Estimation (AVE). The proposed method is based on the idea that each expert in our ensemble has its own internal representation of the input sequence which can be used as prior knowledge when estimating the uncertainty associated with the prediction made by this particular expert. We show that such approach leads to better results than state-of-the-art methods both in terms of accuracy and computational efficiency. \nThe main contributions of this work are summarized below: \n1. A novel framework for modeling uncertain predictions produced by multiple RNN Experts.\n2. An efficient online training procedure for updating parameters of all Experts simultaneously.\n3. Extensive experiments conducted on several real-world datasets demonstrate superior performance of the proposed method over existing approaches. Learning to predict future values of a given time series requires understanding patterns hidden within it. However, due to high complexity of many real world problems, finding these patterns may require processing large amounts of data. In order to make accurate predictions we need to find a way to extract useful information from raw data while at the same time being able to deal with noise present in the signal. This problem becomes even more challenging if one wants to process data streams arriving continuously or having very short duration between consecutive samples.",
        "watermark_text": "We propose an algorithm that learns how to segment time serial data into meaningful segments by utilizing a combination of Recurrent Neural Network ( RNN ) Experts and Adaptive Variance Estimation ( AVE ).The proposed method is based on the idea that each expert in our ensemble has its own internal representation of the input sequence which can be used as prior knowledge when estimating the uncertainty involved with the prediction made by this particular expert.We show that such approach leads to better results than state - of - the - art methods both in terms of accurate and computational efficiency.The main contributions of this work are summarized below : 1.A novel framework for modeling uncertain predictions produced by multiple RNN Experts.2.An efficient online training procedure for updating parameters of all Experts simultaneously.3. Extensive experiments conducted on several real - world datasets demonstrate superior performance of the proposed method over existing approaches.Learning to predict future values of a given time series requires knowing patterns hidden inside it.However, due to high complexity of many actual world problems, finding these patterns may require processing large amounts of data.In order to make accurate predictions we require to find a means to extract useful information from raw data while at the same moment being able to deal with noise present in the signal.This problem becomes even more challenging if one wants to process data streams arriving continuously or having very brief duration between consecutive samples."
    },
    {
        "original_text": "The aim of this study was to develop and evaluate an algorithm that can be used to assess uncertainties associated with DVH computations using Monte Carlo (MC) simulations. The proposed approach is based on the concept of \"uncertainty bands\", which are defined as regions within which all possible values of a given quantity lie at some specified probability level. In order to demonstrate its feasibility, we applied our methodology to two clinical cases involving different treatment techniques. For each case, we performed MC calculations using various numbers of histories ranging between 1x10 5 and 2x10 6 . We then compared results obtained by applying our new technique against those produced by conventional methods such as the standard deviation or confidence intervals. Our findings indicate that the proposed method provides more accurate estimates than other approaches commonly employed in practice. This work has been presented at the International Conference on Medical Physics and Biomedical Engineering held in Singapore during August 2009. \n \n Keywords: Uncertainty bands, Dose Volume Histogram, Monte Carlo",
        "watermark_text": "The aim of this study was to develop and evaluate an algorithm that can be utilized to assess uncertainties associated with DVH computations using Monte Carlo ( MC ) simulations.The proposed approach is based on the concept of \" uncertainty bands \", which are defined as regions within which all possible values of a given quantity lie at some specified probability value.In order to demonstrate its feasibility, we applied our methodology to two clinical cases involving different treatment techniques.For each case, we performed MC calculations utilizing various numbers of histories ranging between 1x10 5 and 2x10 six.We then compared outcomes obtained by applying our new technique against those produced by traditional methods such as the standard deviation or confidence intervals.Our findings indicate that the proposed method provides more accurate estimates than other approaches commonly employed in practice.This work has been presented at the International Conference on Medical Physics and Biomedical Engineering held in Singapore during August 2009.Keywords : Uncertainty bands, Dose Volume Histogram, Monte Carlo"
    },
    {
        "original_text": "We present optical spectroscopic observations for the sample of 14 extreme high energy peaked BL Lac objects (EHBLs) selected by Costamante et al. (2013) . The main goal is to study their host galaxy properties and investigate possible differences with respect to lower-energy blazars, which are known to be hosted in elliptical galaxies. We find that all EHBLs have redshifts between 0.1 and 1.0, consistent with previous results on this class of sources. All but one source show evidence of being hosted in spiral or irregular galaxies; only PKS 0537-441 shows an elliptical-like spectrum. This result suggests that there may not exist any significant difference in the hosts of low-and high-energy blazars as previously claimed. However, we note that our sample size is small and further studies will be needed before drawing firm conclusions. \n \n Keywords: Blazar, Host Galaxy",
        "watermark_text": "We present optical spectroscopic measurements for the sample of 14 extreme high energy peaked BL Lac objects ( EHBLs ) selected by Costamante et al. ( 2013 ).The main goal is to study their host galaxy properties and investigate possible differences with relation to lower - energy blazars, which are known to be hosted in elliptical galaxies.We find that all EHBLs have redshifts between zero. 1 and 1. 0, consistent with previous values on this class of sources.All but one source show evidence of being hosted in spiral or irregular galaxies ; only PKS 0537 - 441 shows an elliptical - like spectrum.This result suggests that there might not exist any significant difference in the hosts of low - and high - energy blazars as previously claimed.However, we note that our sample size is small and further studies will be needed before drawing firm conclusions.Keywords : Blazar, Host Galaxy"
    },
    {
        "original_text": "The Marcus-Lushnikov process is the continuous-time analogue of the discrete-time Lévy walk model introduced by Montroll-Weiss in 1965 to describe diffusion-limited aggregation (DLA) on fractal surfaces.  The DLA growth mechanism has been observed experimentally for many years but only recently have there been attempts at modelling it mathematically using stochastic processes such as the Marcus-Lushnikov process.   In this article we consider two related problems concerning the Marcus-Lushnikov model:  Firstly, we prove that if the jump distribution of the underlying Lévy process satisfies certain integrability conditions then the corresponding Marcus-Lushnikov process converges weakly to Brownian motion with drift; secondly, we show how the Marcus-Lushnikov model can be used to approximate the solution of Smoluchowski's coagulation-fragmentation equation which describes the evolution of particle size distributions in chemical reactions involving clusters of particles. We also discuss some connections between the Marcus-Lushnikov and Flory's models of polymerisation.",
        "watermark_text": "The Marcus - Lushnikov process is the continuous - time analogue of the discrete - time Leévy walk model introduced by Montroll - Weiss in 1965 to describe diffusion - limited aggregation ( DLA ) on fractal surfaces.The DLA growth mechanism has been observed experimentally for long years but only recently have there been attempts at modelling it mathematically using stochastic processes such as the Marcus - Lushnikov process.In this article we consider two related problems concerning the Marcus - Lushnikov model :Firstly, we prove that if the jump distribution of the underlying Lévy process satisfies certain integrability conditions then the corresponding Marcus - Lushnikov procedure converges weak to Brownian motion with drift ; secondly, we show how the Marcus - Lushnikov model can be used to approximate the solution of Smoluchowski ' s coagulation - fragmentation equation which describes the evolution of particle size distributions in chemical reactions involving clusters of particles.We also discuss some connections between the Marcus - Lushnikov and Flory ' s models of polymerisation."
    },
    {
        "original_text": "We present the results of an investigation into the properties and evolution of transients that arise when initial conditions are generated using Lagrangian perturbation theory (LPT) for cosmological N-body simulations. We find that LPT-based initial conditions produce spurious large-scale power at late times, which is not suppressed by increasing the number of particles used to generate these initial conditions. This effect can be mitigated by applying a low-pass filter to the evolved density field prior to generating new initial conditions with higher-order LPT. However, this approach does not completely remove all unwanted effects associated with the use of LPT-generated initial conditions. In addition, we show how the choice of time step used to evolve the initial conditions affects their accuracy. Finally, we demonstrate that it is possible to construct accurate initial conditions for large-volume cosmological simulations without having to resort to expensive high-resolution hydrodynamic simulations. The generation of realistic initial conditions for cosmological N-body",
        "watermark_text": "We present the results of an investigation into the properties and evolution of transients that arise when initial conditions are generated using Lagrangian perturbation theory ( LPT ) for cosmological N - body simulations.We find that LPT - based initial conditions produce spurious large - scale power at late periods, which is not suppressed by increasing the number of particles utilized to generate these initial conditions.This effect can be mitigated by applying a low - pass filter to the evolved dense field prior to producing new early conditions with higher - order LPT.However, this approach does not completely remove all unwanted effects associated with the use of LPT - generated initial conditions.In addition, we show how the choice of time step used to evolve the initial conditions affects their precision.Finally, we demonstrate that it is possible to construct accurate initial conditions for large - volume cosmological simulations besides having to resort to expensive high - resolution hydrodynamic simulations.The generation of realistic initial conditions for cosmological N - body"
    },
    {
        "original_text": "We present new observations made with the Atacama Large Millimeter/submillimeter Array (ALMA) of two inter-network sunspots in active region NOAA AR 12192 on 2013 May 24 and 25, respectively. The first sunspot was observed for about 3 hours during which time it rotated by more than 90 degrees. We find that this sunspot is composed of several magnetic flux tubes with different orientations. In addition to these features we also observe an extended bright feature located between the main sunspot umbrae. This feature has been previously reported as a penumbral filament but our data show no evidence of such structure. Instead, we interpret this feature as a coronal rain blob. The second sunspot was observed for only 1 hour before being occulted by Earths atmosphere. During this observation period the sunspot rotated by less than 30 degrees. Our analysis shows that both sunspots are surrounded by a dark lane which may be associated with the moat surrounding large sunspots.",
        "watermark_text": "We present new observations made with the Atacama Large Millimeter / submillimeter Array ( ALMA ) of two inter - network sunspots in active area NOAA AR 12192 on 2013 May 24 and 25, respectively.The first sunspot was observed for about 3 hours during which period it rotated by more than 90 degrees.We find that this sunspot is composed of several magnetic flux tubes with different orientations.In addition to these features we also observe an extension bright one located between the main sunspot umbrae.This feature has been previously reported as a penumbral filament but our data show no evidence of such structure.Instead, we interpret this feature as a coronal rain blob.The second sunspot was observed for only 1 hour before being occulted by Earths air.During this observation period the sunspot rotated by less than 30 degrees.Our analysis shows that both sunspots are surrounded by a dark lane which might be associated with the moat surrounding large sunspots."
    },
    {
        "original_text": "We study the distribution of the largest fragment in a fragmentation process, which is an important quantity for understanding how to optimize data transmission over networks and storage systems.  We show that this distribution can be approximated by a power law with exponent 1 + 1/(2 - p), where p is the probability that two fragments merge into one when they are adjacent on disk (the so-called \"mergeability parameter\"). This result explains why previous studies have found different exponents depending on whether or not merging was allowed. The approximation also allows us to derive closed-form expressions for other quantities such as the mean size of the largest fragment and its variance. Finally, we use our results to explain some recent experimental findings about file sizes in peer-to-peer systems. In many applications involving data transmission over networks and distributed storage systems, it is useful to understand how large the largest fragment will become during the course of the system's evolution. For example, if a network node has to transmit a certain amount of information within a given time limit, then knowing what fraction of the total data needs to be transmitted at any point in time may help improve performance. Similarly, in distributed storage systems, knowing the expected size of the largest fragment helps determine how much space each node should reserve for storing replicas.",
        "watermark_text": "We study the distribution of the largest fragment in a fragmentation procedure, which is an important quantity for understanding how to optimize data transmission over nets and storage systems.We show that this distribution can be approximated by a power law with exponent 1 + 1 / ( 2 - p ), where p is the probability that 2 fragments merge into one when they are adjacent on disk ( the so - called \" mergeability parameter \" ).This result explains why previous studies have found different exponents depending on either or not merging was permitted.The approximation also allows us to derive closed - form expressions for other quantities such as the mean size of the largest fragment and its variance.Finally, we use our results to explain some latest experimental findings about file sizes in peer - to - supervisor systems.In many applications involving data transmission over networks and distributed storage systems, it is useful to understand how large the biggest fragment will become during the course of the system ' s evolution.For example, if a network node has to transmit a certain quantity of information within a given time limit, then knowing what fraction of the total data needs to be transmitted at any point in time may help improve performance.Similarly, in distributed storage systems, knowing the anticipated size of the largest fragment assists determine how much space each node should keep for storing replicas."
    },
    {
        "original_text": "We study the evaporation process of black holes (BHs) in an expanding universe by using the tunneling method and the WKB approximation. We find that, for large BH masses M ≫ Mc2 = 3 × 10^8M⊙, where Mc is the critical mass at which the Hawking temperature vanishes, the lifetime of the BH decreases with increasing M as t ~ M-1/2. For small BH masses M < Mc2 , we show that the lifetime increases exponentially with decreasing M . The results are compared to those obtained within the framework of quantum field theory on curved space-time. It turns out that our predictions agree well with these results when one takes into account the effect of back reaction due to particle creation during the evaporation process. \nPACS numbers: 04.20.-q; 98.80.Cq \nI. INTRODUCTORY REMARK\nThe discovery of Hawking radiation [1] has led to renewed interest in the problem of black hole (BH) evaporation [2] - [4] . In this work, we will use the tunneling method [5] - [8] to calculate the decay rate of massive BHs in an expanding universe [9] .\nII. BLACK HOLE EVAPORATION IN AN EXPANDING UNIVERSE\n\nA. Tunneling Method\nIn order to apply the tunneling method to the case of evaporating BHs, it is convenient to introduce new coordinates (t′, r′), related to the original ones (t,r) through the following transformations [10] :",
        "watermark_text": "We study the evaporation process of black holes ( BHs ) in an expanding universe by using the tunneling method and the WKB approximation.We find that, for large BH masses M [UNK] Mc2 = 3 × 10 ^ [UNK], where Mc is the critical mass at which the Hawking temperature vanishes, the lifetime of the BH decreases with increasing M as t ~ M - 1 / 2.For small BH masses M < Mc2, we show that the lifetime increases exponentially with declining M.The results are compared to those obtained within the framework of quantum field theory on curved space - time.It turns out that our predictions agree well with these results when one takes into account the affect of back reaction due to particle creation during the evaporation process.PACS numbers : 04. 20. - q ; 98. 80. Cq I. INTRODUCTORY REMARKThe discovery of Hawking radiation [ 1 ] has led to renewed interest in the problem of black hole ( BH ) evaporation [ 2 ] - [ 4 ].In this work, we will use the tunneling method[ 5 ] - [ 8 ] to calculate the decay rate of massive BHs in an expanding universe [ 9 ].II.BLACK HOLE EVAPORATION IN AN EXPANDING UNIVERSE A. Tunneling Method In order to apply the tunneling method to the case of evaporating BHs, it is convenient to introduce new coordinates ( t ′, r ′ ), related to the original ones ( t, r ) through the following transformations[ 10 ] :"
    },
    {
        "original_text": "We study the spin flip phenomenon during the inspiral phase of supermassive black holes (SMBHs) binaries, which is caused by gravitational radiation reaction and can be observed as an abrupt change of the orbital plane orientation with respect to the line-of-sight direction. We find that this effect may lead to significant changes in the waveform amplitude and polarization for certain orientations of SMBH spins. In particular, we show that it could significantly affect the detection efficiency of ground-based detectors such as Advanced LIGO/VIRGO. This work was supported by NSFC under Grants No. 11273005 and No. 11333002 . The authors are grateful to J.-P. Lasota for useful discussions on numerical relativity simulations. \n \n Introduction \n \n Supermassive black holes (SBHs), with masses ranging from $10^{6}$ to $10^{10}$ solar mass, reside at the center of most galaxies [1]. They have been found to exist in pairs or even clusters [2] , indicating that SBHs grow through multiple merger events [3] . During these processes, SBHs lose their angular momenta due to gravitational radiation emission [4] . As a result, they will eventually merge into one single object [5] .\n \nThe final stage of the merger process involves two spinning BHs orbiting each other [6] . Due to strong gravitational fields near the horizon, the Kerr metric [7] should be used instead of general relativity [8] . However, since the orbits of merging BHs are highly eccentric [9] , the effects of higher-order corrections to the Kerr solution become important [10] . These corrections include both post-Newtonian [11] terms and those arising from quantum gravity [12] . \n \n It has been shown that the inclusion of these corrections leads to precession of the orbital planes [13] . For example, if the initial spin vectors of the two BHs lie along the same axis but point opposite directions, then the orbital plane will precess around the total angular momentum vector [14] . If the initial spin axes are not aligned with the total angular momentum vector, then the orbital plane may undergo several complete rotations",
        "watermark_text": "We study the spin flip phenomenon during the inspiral phase of supermassive black holes ( SMBHs ) binaries, which is caused by gravity radiation reaction and can be observed as an abrupt change of the orbital plane orientation with respect to the line - of - sight direction.We find that this effect may lead to significant changes in the waveform amplitude and polarization for certain orientations of SMBH spins.In particular, we show that it could significantly affect the detector efficiency of ground - grounded detectors such as Advanced LIGO / VIRGO.This work was supported by NSFC under Grants No. 11273005 and No. 11333002.The authors are grateful to J. - P. Lasota for helpful discussions on numerical relativity simulations.Introduction Supermassive black holes ( SBHs ), with masses ranging from $ 10 ^ { 6 } $ to $ 10 ^ { 10 } $ solar mass, reside at the center of most galaxies[ 1 ].They have been found to exist in pairs or even clusters [ 2 ], indicating that SBHs grow through multiple merger events [ 3 ].During these processes, SBHs lose their angular momenta due to gravitational radiation emission [ 4 ].As a result, they will eventually merge into one single object [ 5 ].The final stage of the merger process involves two spinning BHs orbiting each other [ 6 ].Due to strong gravitational fields near the horizon, the Kerr metric [ 7 ] should be used instead of general relativity [ 8 ].However, since the orbits of merging BHs are highly eccentric [ 9 ], the effects of higher - order corrections to the Kerr solution become important [ 10 ].These corrections include both post - Newtonian [ 11 ] terms and those arising from quantum gravity[ 12 ].It has been shown that the inclusion of these corrections leads to precession of the orbital planes[ 13 ].For example, if the first spin vectors of the two BHs lay along the same axis but point opposite directions, then the orbital plane will precess around the total angular momentum vector [ 14 ].If the initial spin axes are not aligned with the total angular momentum vector, then the orbital plane might undergo several complete rotations"
    },
    {
        "original_text": "We study the obfuscation complexity of planar graphs, which is defined as the minimum number of edges that need to be removed in order for an adversary not to be able to distinguish between two isomorphic copies of the graph. We show that this problem can be solved by solving a linear program with O(n) variables and constraints (where n denotes the number of vertices), or equivalently by finding the maximum matching on a bipartite graph. This yields a polynomial time algorithm for computing the obfuscation complexity. As a corollary we obtain a lower bound on the obfuscation complexity for any n-vertex tree T . Finally, we prove that there are infinitely many trees whose obfuscation complexities equal their numbers of leaves. The obfuscation complexity of a graph G = (V , E ) is defined as the smallest integer k such that removing at most k edges from G makes it indistinguishable from another graph G' = (V ', E'). In other words, if an attacker has access only to the set of all possible subgraphs induced by some subset S ⊆ V × V then he cannot tell whether he is looking at G or G' unless |S| > k .\nIn this work we consider the case where G is a planar graph. It turns out that in this setting one can solve the obfuscation complexity problem efficiently using combinatorial techniques. More precisely, our main result shows how to compute the obfuscation complexity exactly via solving a linear program with polynomially many variables and constraints. \nAs a consequence of our results we get a new lower bound on the obfuscatability of trees. Moreover, we provide examples showing that the obfuscation complexity may differ significantly from the size of the largest independent set.",
        "watermark_text": "We study the obfuscation complexity of planar graphs, which is defined as the minimum number of edges that need to be removed in order for an adversary not to be able to distinguish between two isomorphic copies of the graph.We show that this issue can be solved by solving a linear programme with O ( n ) variables and constraints ( where n denotes the number of vertices ), or equivalently by finding the maximum matching on a bipartite graph.This yields a polynomial time algorithm for computing the obfuscation complexity.As a corollary we obtain a lower bound on the obfuscation complexity for any n - vertex tree T.Finally, we prove that there are infinitely many trees whose obfuscation complexities equal their numbers of leaves.The obfuscation complexity of a graph G = ( V, E ) is defined as the smallest integer k such that removing at most k edges from G makes it indistinguishable from another graph G ' = ( V ', E ' ).In other words, if an attacker has access only to the set of all potential subgraphs induced by some subset S ⊆ V × V then he lacks tell whether he is looking at G or G ' unless | S | > k.In this work we consider the case where G is a planar graph.It turns out that in this setting one can solve the obfuscation complexity issue efficiently using combinatorial methods.More precisely, our major result demonstrates how to compute the obfuscation complexity exactly via solving a linear program with polynomially many variables and restrictions.As a consequence of our results we get a new lesser bound on the obfuscatability of trees.Moreover, we provide examples showing that the obfuscation complexity may differ significantly from the size of the biggest independent set."
    },
    {
        "original_text": "We present an analysis of gravitational lensing data for the galaxy cluster Abell 1689, which is located at redshift z = 0.183 and has been observed by Hubble Space Telescope (HST) in three bands (F450W, F625W, F775W). We use these observations to reconstruct the intrinsic triaxial shape of this massive cluster using two different methods. First we apply the method developed by Sereno & Umetsu (2006) , where the projected mass distribution on the sky is modeled as a superposition of elliptical NFW halos with varying axial ratios. Second, we employ the technique proposed by Corless et al. (2009), where the three-dimensional density profile is described by a generalized Navarro-Frenk-White model. Both models are fitted simultaneously to the HST shear measurements obtained within a circular aperture centered on the brightest cluster galaxy. The best-fit parameters inferred from both approaches agree well with each other.",
        "watermark_text": "We present an analysis of gravitational lensing data for the galaxy cluster Abell 1689, which is located at redshift z = 0. 183 and has been observed by Hubble Space Telescope ( HST ) in 3 bands ( F450W, F625W, F775W ).We use these observations to reconstruct the intrinsic triaxial shape of this massive cluster utilizing two different methods.First we apply the methodology developed by Sereno & Umetsu ( 2006 ), where the projected mass distribution on the sky is modeled as a superposition of elliptical NFW halos with varying axial ratios.Second, we employ the technique proposed by Corless et al. ( 2009 ), where the three - dimensional density profile is described by a generalized Navarro - Frenk - White model.Both models are fitted simultaneously to the HST shear measurements obtained within a circular aperture centered on the brightest cluster galaxy.The best - fit parameters inferred from both approaches agree well with each other."
    },
    {
        "original_text": "We present the BLOX cluster sample based on optical data obtained with Megacam at CFHT (Canada-France-Hawaii Telescope) in combination with Xray data taken by Chandra or XMMNewton. We use photometric redshifts to select galaxy clusters over an area of 1 deg2 around the center of the field-of-view of the Advanced Camera for Surveys aboard Hubble Space Telescope (HST). Our selection is based on the detection significance of overdensities in color-color space as well as their luminosity function. In addition we require that all candidates are detected in X-rays. This yields a total number of 1253 candidate galaxy clusters between z=0.3 and 0.9. For each cluster we provide its position, redshift, richness estimate, mass estimates derived from weak lensing analysis, and temperature measurements inferred from X-ray observations. A detailed description of our method can be found in this article.",
        "watermark_text": "We present the BLOX cluster sample based on optical data obtained with Megacam at CFHT ( Canada - France - Hawaii Telescope ) in combination with Xray data taken by Chandra or XMMNewton.We utilize photometric redshifts to select galaxy clusters over an area of 1 deg2 around the center of the field - of - view of the Advanced Camera for Surveys upon Hubble Space Telescope ( HST ).Our selection is based on the detection significance of overdensities in color - color space as well as their luminosity function.In addition we require that all candidates are detected in X - rays.This yields a total number of 1253 candidate galaxy clusters between z = zero. 3 and zero. 9.For each cluster we provide its position, redshift, richness estimate, mass estimates derived from weak lensing analysis, and temperature measurements inferred from X - ray observations.A detailed description of our method can be found in this article."
    },
    {
        "original_text": "We present detailed spectral analysis for the type Ib supernova (SN) 1999dn, which was discovered on September 28th in NGC 3184 by Maza et al. (1999) . The photometric evolution is well reproduced with an exponential decay law and we find that the light curve can be explained as being powered by radioactive 56Ni synthesized during explosive nucleosynthesis. We have analyzed optical spectra obtained at various epochs after explosion using non-LTE time-dependent radiative transfer calculations based on our new code STELLA. In this work, we show results for models without hydrogen lines. Our best-fit model has a total ejecta mass of about 18M⊙ , consisting mainly of helium and carbon-oxygen mixture. This result suggests that SN 1999dn may belong to the class of super-luminous SNe Ia. Keywords: Supernovae, Radiation hydrodynamics, Time dependent",
        "watermark_text": "We present detailed spectral analysis for the type Ib supernova ( SN ) 1999dn, which was discovered on September 28th in NGC 3184 by Maza et al. ( 1999 ).The photometric evolution is well reproduced with an exponential decay law and we find that the light curve can be explained as being powered by radioactive 56Ni synthesized during explosive nucleosynthesis.We have analyzed optical spectra achieved at various epochs after explosion using non - LTE time - dependent radiative transfer calculations based on our new code STELLA.In this work, we show results for models without hydrogen lines.Our best - fit model has a total ejecta mass of about [UNK], consisting mainly of helium and carbon - oxygen mixture.This result suggests that SN 1999dn may belong to the class of super - luminous SNe Ia. Keywords : Supernovae, Radiation hydrodynamics, Time dependent"
    },
    {
        "original_text": "We study the critical behaviour of irreversible reaction systems with mass-action kinetics in one dimension, using Monte Carlo simulations and mean-field theory. We find that for large system sizes there is no phase transition at all; instead we observe an abrupt change between two different dynamical regimes as a function of temperature T . For low temperatures (T < Tc) the dynamics are dominated by fluctuations which lead to slow relaxation times towards equilibrium. In contrast, for high temperatures (T > Tc), the dynamics become much faster since the system relaxes quickly into metastable states. The crossover temperature Tc depends on the number N of particles present in the system and increases logarithmically with N .\nThe results presented here can be understood within the framework of the recently developed concept of \"active matter\". Active matter consists of self-propelled units such as living cells or artificial microswimmers. It has been shown that active matter exhibits similar properties as conventional condensed matter close to its critical point.",
        "watermark_text": "We study the critical behaviour of irreversible reaction systems with mass - action kinetics in 1 dimension, using Monte Carlo simulations and mean - field theory.We find that for large system sizes there is no phase transfer at all ; instead we observe an abrupt change between 2 different dynamical regimes as a function of temperature T.For low temperatures ( T Tc ), the dynamics become much quicker since the system relaxes quickly into metastable states.The crossover temperature Tc depends on the number N of particles presence in the system and increases logarithmically with N.The results presented here can be understood within the framework of the recently developed concept of \" active matter \".Active matter consists of self - propulsion units such as life cells or artificial microswimmers.It has been shown that active matter exhibits similar properties as traditional condensed ones close to its critical point."
    },
    {
        "original_text": "We investigated the dominant aerosol processes in the atmosphere using ground-based remote sensing and chemical analysis data collected at Kashiwa, Chiba Prefecture (Chiba), Japan, between September 2009 and March 2010 under severe air pollution conditions caused by anthropogenic emissions. The results showed that sulfate particles were mainly produced through gas-to-particle conversion via homogeneous nucleation on days with low relative humidity (RH) values; however, they were also formed as secondary organic aerosols (SOAs) when RH was higher than 80%. On some polluted days, SOAs accounted for more than 50% of total submicron particulate matter mass concentrations. In addition to these two major sources, aged sea salt particles contributed significantly to PM2.5 mass concentration levels. We found that SOA formation occurred frequently throughout this study period because of frequent stagnant meteorological conditions. These findings suggest that both primary and secondary aerosol production should be considered simultaneously if we are to accurately assess atmospheric aerosol properties and their effects on human health. \n \n Keywords: Aerosol process, Remote sensing, Chemical composition",
        "watermark_text": "We investigated the dominant aerosol processes in the atmosphere using ground - based remote sensing and chemistry analysis data collected at Kashiwa, Chiba Prefecture ( Chiba ), Japanese, between September 2009 and Mar 2010 under severe air pollution conditions caused by anthropogenic emissions.The results showed that sulfate particles were mainly produced through gas - to - particle conversion via homogeneous nucleation on days with low relative humidity ( RH ) values ; however, they were also formed as secondary organic aerosols ( SOAs ) when RH was higher than 80 %.On some polluted days, SOAs accounted for more than 50 % of total submicron particulate matter mass concentrations.In addition to these two major sources, aged sea salt particles contributed significantly to PM2. 05 mass concentration levels.We found that SOA structure occurred frequently throughout this study period because of frequent stagnant meteorological conditions.These findings suggest that both primary and secondary aerosol production should be considered concurrently if we are to accurately assess atmospheric aerosol properties and their effects on human health.Keywords : Aerosol process, Remote sensing, Chemical composition"
    },
    {
        "original_text": "We study the decoherence of macroscopic quantum superposition states in open systems, and show that it is possible to prepare such states with high fidelity using current experimental techniques.  We consider two different types of macroscopic superposition: coherent spin states (CSS) and Schrödinger cat states (SCS). For CSS we find that the decay rate scales as $1/N$ where $N$ is the number of particles involved in the state. This scaling law can be understood by considering the effect of spontaneous emission on each particle separately. In contrast for SCS the decay rate scales as $1/sqrt(N)$ which cannot be explained by treating individual particles independently. Instead we argue that this behavior arises due to collective effects between all particles in the system. Finally, we discuss how these results could be tested experimentally. Decoherence of macroscopic superposition states has been studied extensively over recent years [1–3] . It was shown theoretically [4] , and confirmed experimentally [5, 6] , that macroscopic superposition states are extremely fragile against environmental noise [7, 8] . The main reason behind their fragility lies in the fact that they involve many particles, so even small interactions with an environment lead to rapid loss of coherence [9] .\nIn this work we focus on studying the decoherence process of macroscopic superposition in open systems. Specifically, we consider two different types of superposition: coherent spin states [10] and Schrödinger cat-states [11] . Coherent spin states have already been prepared experimentally [12] while Schrödinger cat states remain elusive [13] . However, there exist proposals for preparing them [14–18] , and recently some progress towards realizing them has been made [19, 20] .  Our analysis shows that both types of superposition exhibit qualitatively similar behaviour under decoherence.",
        "watermark_text": "We study the decoherence of macroscopic quantum superposition states in open systems, and show that it is possible to prepare such states with high fidelity using current experimental techniques.We consider two different types of macroscopic superposition : coherent spin states ( CSS ) and Schrödinger cat states ( SCS ).For CSS we find that the decomposition rate scales as $ 1 / N $ where $ N $ is the number of particles involved in the state.This scaling law can be understood by considering the effect of spontaneous emission on each particle separately.In contrast for SCS the degradation rate scales as $ 1 / sqrt ( N ) $ which cannot be explained by treating individual particles independently.Instead we argue that this behavior arises due to collective effects between all particles in the complex.Finally, we discuss how these outcomes could be tested experimentally.Decoherence of macroscopic superposition states has been studied extensively over recent years [ 1 – 3 ].It was shown theoretically [ 4 ], and confirmed experimentally [ 5, 6 ], that macroscopic superposition states are extremely delicate against environmental noise[ 7, 8 ].The main reason behind their fragility lies in the fact that they involve numerous particles, so even tiny interactions with an environmental lead to rapid loss of coherence[ 9 ].In this work we focus on studying the decoherence process of macroscopic superposition in open systems.Specifically, we consider 2 different kinds of superposition : coherent spin states [ 10 ] and Schrödinger cat - ones [ 11 ].Coherent spin states have already been prepared experimentally[ 12 ] while Schrödinger cat states remain elusive[ 13 ].However, there exist proposals for preparing them[ 14 – 18 ], and recently some progress towards realizing them has been made [ 19, 20 ].Our analysis shows that both types of superposition exhibit qualitatively similarly behaviour under decoherence."
    },
    {
        "original_text": "We present an explicit formula for solutions to some classes of nonlinear fractional diffusion equations with variable coefficients and nonlocal initial conditions, which are expressed by means of the generalized Mittag-Leffler function Eα(−z) and the H-function. The results obtained can be used as a basis for numerical methods for solving such problems. We also discuss applications of our approach to the description of anomalous transport processes in complex systems. Introduction.\nThe theory of fractional calculus has been developed rapidly during recent years due to its numerous applications in various fields of science and engineering (see e.g., [1] - [4] ). In particular, it is widely applied to describe anomalous transport phenomena observed in many physical models [5] . For example, this approach was successfully employed to model subdiffusion [6] , superdiffusion [7] , and Lévy flights [8] .\nIn general, fractional differential equations have no exact analytical solution [9] . Therefore, there exists great interest in developing efficient numerical algorithms for their approximate treatment [10] . However, even if we use powerful computers, these approaches may not always provide sufficiently accurate results [11] . This problem becomes especially important when one deals with strongly nonlinear problems [12] or considers very large time intervals [13] . To overcome difficulties associated with the lack of exact solutions, several authors proposed different techniques based on special functions [14] - [16] . Among them, the most popular ones include the Mittag-Leffler [17] and Wright [18] functions, Fox's H-functions [19] , and others [20] - [22] .",
        "watermark_text": "We present an explicitly formula for solutions to some classes of nonlinear fractional diffusion equations with variable coefficients and nonlocal initial conditions, which are expressed by means of the generalized Mittag - Leffler function Eα ( −z ) and the H - function.The results obtained can be used as a basis for numerical methods for solving such problems.We also talk applications of our approach to the description of anomalous transport processes in complex systems.Introduction.The theory of fractional calculus has been developed rapidly during last years due to its many applications in various fields of science and engineering ( see e. g., [ 1 ] - [ 4 ] ).In particular, it is broadly applied to describe anomalous transport phenomena observed in many physical models [ 5 ].For example, this approach was successfully employed to model subdiffusion [ 6 ], superdiffusion [ seven ], and Lévy flights [ eight ].In general, fractional differential equations have no exact analytical solution [ 9 ].Therefore, there exists great interest in developing efficient numerical algorithms for their approximate treatment [ 10 ].However, even if we use powerful computers, these approaches might not necessarily provide sufficiently accurate results [ 11 ].This problem gets especially important when one deals with strong nonlinear problems [ 12 ] or considers very large time intervals[ 13 ].To overcome difficulties associated with the lack of exact solutions, several writers proposed different techniques based on special functions[ 14 ] -[ 16 ].Among them, the most popular ones include the Mittag - Leffler [ 17 ] and Wright[ 18 ] functions, Fox ' s H - functions [ 19 ], and others [ 20 ] -[ 22 ]."
    },
    {
        "original_text": "We present results on the orbital evolution of Jupiter and Saturn in an axisymmetric, viscously evolving protoplanetary disk with embedded planets. We find that the orbits of both giant planets are significantly affected by their mutual gravitational interaction as well as by the presence of other planetary embryos. The eccentricity growth is dominated by secular interactions between the two planets which lead to large amplitude oscillations in the semi-major axes. In addition we find that the planet migration rates depend strongly on the initial conditions for the system parameters such as mass ratio and separation distance. \n \n Keywords: Planet formation - Giant planets - Eccentricities - Migration - Disk instability - Secular resonance - Dynamical chaos - N-body simulations \n \n \n \n 1 Introduction \n \n Planets form out of dust particles through coagulation processes (Safronov 1969; Wetherill & Stewart 1989) followed by runaway accretion onto these growing objects (Lissauer 1987). This process leads to the formation of planetesimals whose masses range from 10$^{−6}$ M⊕ up to several Earth masses. These bodies can grow further into larger planetary embryos or even directly into gas giants like Jupiter and Saturn if they accrete enough material within a short time span (Pollack et al. 1996) . Once formed, these massive planets open gaps in the surrounding circumstellar disks due to tidal torques exerted by the planet's gravity (Lin & Papaloizou 1986 ). As a consequence, the remaining matter inside this gap will be removed rapidly by viscosity effects leading to rapid inward type II migration of the planet (Ward 1997; Tanaka et al. 2002 ) . \nThe observed distribution of exoplanets shows a wide variety of orbital configurations ranging from circular orbits around Sun-like stars to highly eccentric orbits around low-mass stars (see e.g., Marcy et al. (2005) , Udry & Santos 2007 , Winn et al. (2010 ), Johnson et al. (2011 ) and references therein). However, most of them have been found close to their host star where the detection probability increases dramatically because of the strong stellar",
        "watermark_text": "We present results on the orbital evolution of Jupiter and Saturn in an axisymmetric, viscously evolving protoplanetary disk with embedded worlds.We find that the orbits of both giant worlds are significantly affected by their mutual gravity interaction as well as by the existence of other planetary embryos.The eccentricity growth is dominated by secular interactions between the two planets which lead to large amplitude oscillations in the semi - major axes.In addition we find that the planet migration levels depend strongly on the beginning conditions for the system parameters such as mass ratio and separation distance.Keywords : Planet formation - Giant planets - Eccentricities - Migration - Disk instability - Secular resonance - Dynamical chaos - N - body simulations 1 Introduction Planets form out of dust particles through coagulation processes ( Safronov 1969 ; Wetherill & Stewart 1989 ) followed by runaway accretion onto these growing objects ( Lissauer 1987 ).This process leads to the formation of planetesimals whose masses range from 10 $ ^ { −6 } $ M⊕ up to several Earth masses.These bodies can grow further into larger planetary embryos or even directly into gas giants called Jupiter and Saturn if they accrete sufficient material within a short time span ( Pollack et al. 1996 ).Once formed, these massive planets open gaps in the surrounding circumstellar disks due to tidal torques exerted by the planet ' s gravity ( Lin & Papaloizou 1986 ).As a consequence, the remaining matter inside this gap will be removed rapidly by viscosity events leading to rapid inward type II migration of the planetary ( Ward 1997 ; Tanaka et al. 2002 ).The observed distribution of exoplanets shows a wide variety of orbital configurations ranging from circular configurations around Sun - like stars to highly eccentric configurations around low - mass stars ( see e. g., Marcy e al. ( 2005 ), Udry & Santos 2007, Winn et al. ( 2010 ), Johnson et al. ( 2011 ) and references therein ).However, most of them have been discovered close to their home star where the detection likelihood increases dramatically because of the strongly stellar"
    },
    {
        "original_text": "We present the first systematic survey of X-ray flares observed in gamma-ray burst (GRB) afterglows with the Swift satellite, which has been operating since 2004. We find that most GRBs show at least one X-ray flare during their prompt or early afterglow phase; we also find that some GRBs have multiple flaring episodes. The majority of these flares are soft, but there is evidence for both hard and very-hard flares as well. In addition to studying individual flares, we examine the spectral properties of all flares combined using time-resolved spectroscopy techniques. Our results indicate that the average spectrum can be described by an absorbed power law model with photon index Γ = 1.6 ± 0.1 and hydrogen column density NH = 2 × 10^22 cm^{-2}. \n \n Using this best-fit model, we calculate the total energy emitted in each flare over its duration. For the entire sample of flares studied here, we find that the mean fluence of the flares is ~10^-7 ergs/cm^2, while the mean peak luminosity is ~10^45 ergs/s. These values correspond to typical energies released in solar flares.",
        "watermark_text": "We present the first systematic survey of X - ray flares observed in gamma - burst burst ( GRB ) afterglows with the Swift satellite, which has been operating since 2004.We find that most GRBs show at least one X - ray flare during their prompt or early afterglow phase ; we also find that some GRBs have multiple flaring episodes.The majority of these flares are soft, but there is evidence for both hard and very - hard flares as well.In addition to studying individual flares, we examine the spectrum properties of all flares combined using time - resolved spectroscopy techniques.Our results indicate that the average spectrum can be described by an absorbed power law model with photon index Γ = 1. 6 ± 0. 1 andhydrogen column density NH = 2 × 10 ^ 22 cm ^ { - 2 }.Using this best - fit model, we calculate the total energy emitted in each flare over its length.For the entire sample of flares studied here, we find that the mean fluence of the flares is ~ 10 ^ - 7 ergs / cm ^ 2, while the peak peak luminosity is ~ 10 ^ 45 ergs / s.These values correspond to typical energies released in solar flares."
    },
    {
        "original_text": "We present the first results on transition region (TR) lines obtained by the Extreme Ultraviolet Imaging Spectrometer (EIS), aboard the Solar-B satellite, in active regions and quiet Sun areas. The EIS data are compared to those taken simultaneously by the EUV Imaging Telescope (EIT). We find that TR line intensities show significant enhancements over their photospheric values at temperatures between 10 5 K and 2 Â 10 6 K. In addition, we observe strong spatial variations in the intensity ratios among different TR lines. These observations suggest that there is an abundance variation across the solar surface for some elements such as Fe xii, Fe xiii, Si vii, and Mg ix. This work was supported by NASA grants NNG05GE73G and NNX07AQ85G. Hinode is a Japanese mission developed and launched by ISAS/JAXA, collaborating with NAOJ as domestic partner, NASA and STFC (UK) as international partners. Scientific operation of the Hinode mission is conducted by the Hinode science team organized at ISAS/JAXA.",
        "watermark_text": "We present the first results on transition region ( TR ) lines obtained by the Extreme Ultraviolet Imaging Spectrometer ( EIS ), aboard the Solar - B satellite, in active regions and quiet Sun areas.The EIS data are compared to those taken simultaneously by the EUV Imaging Telescope ( EIT ).We find that TR line intensities show significant enhancements over their photospheric values at temperatures between 10 05 K and 2 Â ten 6 K.In addition, we observe strong spatial variations in the intensity ratios amongst different TR lines.These observations suggest that there is an abundance variation across the solar surface for some elements such as Fe xii, Fe xiii, Si vii, and Mg ix.This work was supported by NASA grants NNG05GE73G and NNX07AQ85G. Hinode is a Japanese mission developed and launched by ISAS / JAXA, collaborating with NAOJ as domestic partnership, NASA and STFC ( UK ) as international partners.Scientific operation of the Hinode mission is conducted by the Hinode science team organized at ISAS / JAXA."
    },
    {
        "original_text": "We present new observations with Hubble Space Telescope (HST) and Spitzer Space Telescope to study the galaxy population in the cluster Abell 2744 at z = 0.308. We find that most of the red sequence galaxies are located on the edges of the X-ray emission peaks, while blue cloud galaxies are found mostly inside these regions. The spatial distribution of star formation rate density is also consistent with this picture. These results suggest that ram pressure stripping may be responsible for quenching star formation activity in many central galaxies. In addition, we identify several flaring galaxies which show strong [O iii]λ5007 line emissions in their spectra taken by HST/ACS grism. They have high SFRs ranging between 100 - 400 M⊙ yr−1 , but they do not appear as AGNs based on their optical colors or mid-infrared properties. Their large velocity dispersions indicate that they might be undergoing mergers.",
        "watermark_text": "We present fresh observations with Hubble Space Telescope ( HST ) and Spitzer Space Telescope to study the galaxy community in the cluster Abell 2744 at z = zero. 308.We find that most of the red sequence galaxies are located on the edges of the X - ray emitted peaks, while blue cloud galaxies are found mostly inside these regions.The spatial distribution of star forming rate density is also consistent with this picture.These results suggest that ram pressure stripping may be involved for quenching star formation activity in many central galaxies.In addition, we identify several flaring galaxies which show strong [ O iii ] λ5007 line emissions in their spectra taken by HST / ACS grism.They have high SFRs ranging between 100 - 400 [UNK] yr−1, but they do not appear as AGNs based on their optical colors or mid - infrared properties.Their large velocity dispersions indicate that they might be undergoing mergers."
    },
    {
        "original_text": "We report on the observation of electron doping in cuprate superconductors by interfacing them to manganite insulators through epitaxial growth and chemical bonding at interfaces.  The interface between La0.7Sr0.3MnO3 (LSMO) and YBa2Cu3O6+x (YBCO), which are both parent compounds for high temperature superconductivity, is found to be highly conducting despite the large lattice mismatch between LSMO and YBCO. This suggests that charge transfer across the interface occurs due to strong electronic hybridization rather than strain relaxation alone. We also find that the hole concentration in the YBCO layer can be controlled by varying the thickness of the LSMO layer grown on top of it. These results demonstrate an alternative approach towards engineering the carrier density in cuprate superconductors using oxide heterostructures. High-temperature superconductivity has been observed only in materials containing copper-oxygen planes known as CuO2 layers [1] . In these systems, holes doped into the CuO2 plane give rise to Cooper pairs leading to superfluidity [2] . However, the maximum critical temperature Tc = 92 K achieved so far in this class of materials is still well below the theoretical limit predicted by Bardeen-Cooper-Schrieffer theory [3] , raising questions about how to further enhance Tc [4] .\nIn recent years there have been significant efforts made to explore new routes toward enhancing Tc beyond its current record value [5] . One promising route involves introducing electrons into the CuO2 plane [6] . For example, replacing oxygen atoms in the CuO2 plane with fluorine leads to a reduction in the number of holes in the system [7, 8] . Alternatively, one may introduce electrons directly into the CuO2 plane by growing thin films of transition metal oxides such as SrTiO3 [9] or LaAlO3 [10] onto the surface of cuprate superconductors. While these approaches show promise, they require precise control over film composition and structure during deposition [11] . An alternative strategy would involve controlling the carrier density in cuprates without changing their crystal structures [12] .",
        "watermark_text": "We report on the observation of electron doping in cuprate superconductors by interfacing them to manganite insulators through epitaxial growth and chemical binding at interfaces.The interface between La0. 7Sr0. 3MnO3 ( LSMO ) and YBa2Cu3O6 + x ( YBCO ), which are both parent compounds for high temperature superconductivity, is found to be highly conducting despite the large lattice mismatch between LSMO and YBCO.This suggests that charge transfer across the interface occurs due to strongly electronic hybridization rather than strain relaxation alone.We also find that the hole concentration in the YBCO layer can be controlled by varying the thickness of the LSMO layer grown on top of it.These results demonstrate an alternative approach towards engineering the carrier density in cuprate superconductors using oxide heterostructures.High - temperature superconductivity has been observed only in materials holding copper - oxygen planes known as CuO2 layers [ 1 ].In these systems, holes doped into the CuO2 plane gain rise to Cooper couples leading to superfluidity [ 2 ].However, the maximum critical temperature Tc = 92 K achieved so far in this class of materials is nevertheless well below the theory limit predicted by Bardeen - Cooper - Schrieffer theory [ 3 ], raising questions about how to further enhance Tc [ four ].In recent years there have been substantial efforts done to explore new routes toward enhancing Tc beyond its current record value [ 5 ].One promising route involves introducing electrons into the CuO2 plane[ 6 ].For example, replacing oxygen atoms in the CuO2 plane with fluorine leads to a reduction in the number of holes in the system[ 7, 8 ].Alternatively, one may add electrons directly into the CuO2 plane by growing thin films of transition metal oxides such as SrTiO3[ 9 ] or LaAlO3 [ 10 ] onto the surface of cuprate superconductors.While these approaches show promise, they require exact control over film composition and structure during deposition[ 11 ].An alternative strategy would involve controlling the carrier density in cuprates without changing their crystal structures[ 12 ]."
    },
    {
        "original_text": "We study the geometry and topology of generalized Lagrangian submanifolds (GLSMs) in complex symplectic manifolds, focusing on GLSMs that are special Lagrangians with respect to some Kähler form. We show how these can be constructed as holomorphic sections of certain line bundles over moduli spaces of parabolic Higgs bundles. In particular we consider the case where the base is a partial flag variety. This leads us to define new families of Calabi-Yau varieties which have been studied by physicists recently. These varieties are obtained by taking products of Grassmannian manifolds or their quotients by finite groups. The main results of this thesis are:  1. A construction of GLSMs using parabolic Higgs bundles.  2. An explicit description of the cohomology ring of the total space of a vector bundle associated to a parabolic Higgs bundle.  3. A proof of mirror symmetry between two different types of GLSMs defined above when the base is a product of Grassmannians.",
        "watermark_text": "We study the geometry and topology of generalized Lagrangian submanifolds ( GLSMs ) in complex symplectic manifolds, focusing on GLSMs that are special Lagrangians with respect to some Kähler form.We show how these can be constructed as holomorphic sections of certain line bundles over moduli spaces of parabolic Higgs bundles.In particular we consider the case where the basis is a partial flag variety.This leads us to define new families of Calabi - Yau varieties which have been studied by physicists recently.These varieties are obtained by taking products of Grassmannian manifolds or their quotients by finite groups.The main results of this thesis are : 1.A construction of GLSMs using parabolic Higgs bundles.2.An explicit description of the cohomology ring of the total space of a vector bundle associated to a parabolic Higgs bundle.3.A proof of mirror symmetry between two different types of GLSMs defined above when the base is a product of Grassmannians."
    },
    {
        "original_text": "We report on the generation of an unprecedentedly broad spectrum (>10 THz) by using a novel type of fiber, which is based on a microstructured optical fiber with a suspended core surrounded by air holes filled with liquid. The suspended-core fiber supports two guided modes that are confined to different regions along its length. One mode propagates through the central region of the fiber where it experiences strong confinement due to the high index contrast between silica glass and air; this results in large effective nonlinearity. The other mode propagates outside the central region of the suspended core, where it sees only weak refractive-index guiding. This leads to low loss for both modes over a wide wavelength range. We demonstrate experimentally that these two modes can be coupled together efficiently via stimulated Raman scattering when pumped at 1.55 µm. As a result, we obtain a broadband continuum spanning more than 10 THz centered around 2.7 µm.",
        "watermark_text": "We report on the generation of an unprecedentedly wide spectrum ( > 10 THz ) by using a new type of fiber, which is based on a microstructured optical fabric with a suspended core surrounded by air holes filled with liquid.The suspended - core fiber supports two guided modes that are confined to different regions along its length.One mode propagates through the central region of the fiber where it experiences strong confinement due to the high index contrast between silica glass and air ; this results in large effective nonlinearity.The other mode propagates outside the central region of the suspension core, where it sees only weak refractive - index guiding.This leads to low loss for both modes over a broad wavelength range.We demonstrate experimentally that these 2 modes can be coupled jointly efficiently via stimulated Raman scattering when pumped at 1. 55 µm.As a result, we obtain a broadband continuum spanning more than 10 THz centered around 2. 7 µm."
    },
    {
        "original_text": "We report on the first simultaneous observations with XMM-Newton and Spitzer Space Telescope (SST) during an active state of the Galactic black hole candidate GRS 1915+105, which is known to show strong variability at all wavelengths. We find that there are two parallel tracks in the evolution of the source's luminosity between the near-infrared (NIR), optical/UV, soft/hard X-ray bands as well as radio wavebands. The NIR-optical track follows closely the hard X-ray light curve but lags behind by about 20 days; while the UV-X-ray track shows no lag compared to the hard X-ray light curve. This suggests that different physical processes may be responsible for these two tracks. In addition, we also found evidence for a hysteresis effect in both tracks. These results provide new insights into the physics of accretion flows onto supermassive black holes.",
        "watermark_text": "We report on the first simultaneous observations with XMM - Newton and Spitzer Space Telescope ( SST ) during an active state of the Galactic black hole candidate GRS 1915 + 105, which is known to show strong variability at all wavelengths.We find that there are two parallel tracks in the evolution of the source ' s luminosity between the near - infrared ( NIR ), optical / UV, soft / hard X - ray frequencies as ill as radio wavebands.The NIR - optical track follows closely the hard X - ray light curve but lags behind by about 20 days ; while the UV - X - ray track shows no lag compared to the hard X - ray light curve.This suggests that different physical processes may be responsible for these two tracks.In addition, we also discovered evidence for a hysteresis event in both tracks.These results provide new insights into the physics of accretion flows onto supermassive black holes."
    },
    {
        "original_text": "We report on results obtained by INTEGRAL observations during the 2005 outburst of the black hole candidate GRO J1655â€“40 (Nova Muscae 1991). The source was observed in the 20-100 keV range for about 100 days, starting at MJD 53000 and ending at MJD 53300. We have analyzed these data using both ISGRI and SPI instruments aboard INTEGRAL satellite. In addition to the main spectral component which is well described by a power law model modified by an exponential cutoff, we find that there are two additional components present in the spectrum. One of them has been previously reported by other authors but its origin remains unclear. Another one appears only when fitting the whole dataset simultaneously with all three models considered here -power law plus exponential cut-off, broken power law or Comptonization model-. This new feature can be interpreted either as a reflection hump produced by cold material surrounding the central X-ray source or as a broad iron line around 6.4 keV.",
        "watermark_text": "We report on results obtained by INTEGRAL observations during the 2005 outburst of the black hole candidate GRO J1655â€ “ 40( Nova Muscae 1991 ).The source was observed in the 20 - 100 keV range for about 100 days, starting at MJD 53000 and ending at MJD 54300.We have analyzed these data utilizing both ISGRI and SPI instruments aboard INTEGRAL satellite.In addition to the main spectral component which is well described by a power law model modified by an exponential cutoff, we find that there are 2 additional ones present in the spectrum.One of them has been previously reported by other authors but its source remains unclear.Another one appears only when fitting the whole dataset simultaneously with all 3 models considered here - power law plus exponential cut - off, broken power law or Comptonization model -.This new feature can be interpreted either as a reflection hump produced by cold material surrounding the central X - ray source or as a broad iron line around 6. 4 keV."
    },
    {
        "original_text": "We present new constraints on warm dark matter (WDM) models by combining the results of two recent surveys for gravitationally lensed quasars, SDSS and CFHTLS Wide. We find that the observed number density of lenses is consistent with predictions based on cold dark matter simulations but inconsistent at more than 3 sigma confidence level if we assume a standard thermal relic WDM model with mass mX = 1 keV. This result suggests either that the current WDM scenario needs to be modified or that there are other systematic effects which have not been taken into account in our analysis. The full text can be found at: http://arxiv.org/abs/astro-ph/0604070v1.pdf . \nThe existence of dark matter has now been established beyond reasonable doubt through its gravitational influence on visible matter. However, despite decades of research, little else about this mysterious substance is known. In particular, it remains unclear whether dark matter consists of one particle species only - as assumed in most theoretical studies -or whether it comprises several different particles. One possibility is that dark matter consists of weakly interacting massive particles (WIMPs), such as neutralinos predicted within supersymmetric extensions of the Standard Model [1] .\nIn order to test these scenarios observationally, astronomers look for signatures of dark matter in astrophysical objects like galaxies [2] , clusters [3] and quasars [4] . A particularly promising method involves searching for gravitationally lensed systems [5] where light rays emitted by distant sources bend around intervening dark matter halos [6] . If dark matter consists of WIMPs then their masses should lie between 10 GeV/c 2 and 100 TeV/c 2 [7, 8] . For example, the recently discovered galaxy cluster Abell 2218 [9] may contain a halo made up entirely of WIMPs [10] .",
        "watermark_text": "We present new constraints on warm dark matter ( WDM ) models by combining the results of two recent surveys for gravitationally lensed quasars, SDSS and CFHTLS Wide.We find that the observed number density of lenses is consistent with predictions based on cold dark matter simulations but inconsistent at more than 3 sigma confidence level if we assume a standard thermal relic WDM simulation with mass mX = 1 keV. This result suggests either that the current WDM scenario needs to be modified or that there are other systematic effects which have not been taken into account in our analysis.The full text can be found at : http : / / arxiv. org / abs / astro - ph / 0604070v1. pdf.The existence of dark matter has now been established beyond reasonable doubt through its gravitational influence on visible material.However, despite decades of research, little else about this mysterious substance is known.In particular, it remains unclear whether dark matter consists of single particle species only - as assumed in most theoretical studies - or whether it comprises several separate particles.One possibility is that dark matter consists of weakly interacting massive particles ( WIMPs ), such as neutralinos predicted inside supersymmetric extensions of the Graduate Model[ 1 ].In order to test these scenarios observationally, astronomers look for signatures of dark matter in astrophysical objects like galaxies [ 2 ], clusters [ 3 ] and quasars [ four ].A particularly promising method involves searching for gravitationally lensed systems[ 5 ] where light rays emitted by distant sources bend around intervening dark matter halos[ 6 ].If dark matter consists of WIMPs then their masses should lie between 10 GeV / c 2 and 100 TeV / c 2[ 7, 8 ].For example, the recently found galaxy cluster Abell 2218 [ 9 ] may contain a halo made up entirely of WIMPs [ 10 ]."
    },
    {
        "original_text": "We have studied the infrared (IR) properties of water and methanol maser sources in nearby galaxies using data obtained by the Infrared Space Observatory (ISO). We find that most of these masers are located near luminous IR objects, such as ultraluminous infrared galaxies or active galactic nuclei. The majority of the masers appear to be excited by shocks produced by outflows driven by massive stars. However, we also found some masers which may be excited by accretion onto young stellar objects. These results suggest that both massive star formation and low-mass star formation can produce masing gas clouds. Masers are powerful tools for studying physical conditions in interstellar media because they provide information on molecular abundances and kinematics at high spatial resolution. Water and methanol masers are commonly observed toward star-forming regions in our Galaxy and other nearby galaxies. They are thought to trace dense molecular gas where protostars form. Since their discovery more than 30 years ago, many studies have been carried out to investigate the relationship between masers and various phenomena related to star formation processes. \n \n In this study, we investigated the infrared (IR) environment around masers detected in nearby galaxies using ISO observations. Our sample consists of all known extragalactic water and methanol masers listed in the catalogs compiled by Caswell & Haynes(1987), Hoffman et al.(1989), and Pestalozzi et al. (2005) . Most of them were discovered serendipitously during surveys conducted with single-dish radio telescopes. Although there is no complete census of masers in external galaxies yet, it has been estimated that about 10 percent of local ULIRGs show maser emission (e.g., Gao 1996; Braatz et al. 1997 ). This suggests that masers play an important role in understanding the nature of ULIRGs.",
        "watermark_text": "We have studied the infrared ( IR ) properties of water and methanol maser sources in near galaxies using data obtained by the Infrared Space Observatory ( ISO ).We find that most of these masers are located near luminous IR objects, such as ultraluminous infrared galaxies or active galactic nuclei.The majority of the masers appear to be excited by shocks produced by outflows driven by massive stars.However, we also found some masers which may be excited by accretion upon young star objects.These results suggest that both massive star formation and low - mass star formation can produce masing gas clouds.Masers are powerful tools for studying physical conditions in interstellar media because they provide information on molecular abundances and kinematics at high spatial resolution.Water and methanol masers are commonly observed toward star - forming regions in our Galaxy and other nearby galaxies.They are thought to trace dense molecule gas where protostars form.Since their discovery more than 30 years ago, many studies have been carried out to explore the relationship between masers and various phenomena related to stellar formation processes.In this study, we investigated the infrared ( IR ) environment around masers detected in near galaxies using ISO observations.Our sample consists of all known extragalactic water and methanol masers listed in the catalogs compiled by Caswell & Haynes ( 1987 ), Hoffman et al. ( 1989 ), and Pestalozzi et al. ( 2005 ).Most of them were discovered serendipitously during surveys undertaken with single - dish radio telescopes.Although there is no complete census of masers in external galaxies yet, it has been estimated that about 10 percent of local ULIRGs show maser emission ( e. g., Gao 1996 ;Braatz et al. 1997 ).This suggests that masers play an important part in understanding the nature of ULIRGs."
    },
    {
        "original_text": "We have studied the spin relaxation and dephasing processes in semiconductor quantum dots (QDs) by solving numerically the full set of equations for electron-electron interactions within the framework of the equation-of-motion method. We found that, at low temperatures, the dominant mechanism responsible for spin relaxation is due to spin-flip scattering with acoustic phonons. The calculated results are compared favorably with available experimental data on QD ensembles. In addition, we show that the inclusion of exchange interaction between electrons leads to an increase in the spin relaxation time as well as to a reduction in its temperature dependence. \n \n Spin dynamics plays an important role in many physical phenomena such as magnetic resonance imaging [1] , magneto-optical effects [2] , and spintronics [3] . Semiconductor quantum dots (QDs), which can be viewed as artificial atoms [4] , provide us with unique opportunities to study spin relaxation and dephazing mechanisms [5] - [8] . Recently, there has been considerable interest in studying these issues both experimentally [9] - [11] and theoretically [12] - [16] .\nIn this work, we investigate spin relaxation and dephazation processes in QDs using the equation-of-motion (EOM) method [17] . This method allows one to take into account all possible contributions to the self-energy arising from different types of electron-electron interactions including direct Coulomb repulsion, exchange-correlation potential, Hartree-Fock corrections, and correlation energy [18] . It should be noted that our calculations were performed without any additional approximations beyond those used in previous studies based on the EOM formalism [19] - [21] . \nThe obtained numerical results demonstrate that, at low temperatures T < 10 K, the main contribution to spin relaxation comes from spin-flip scattering with acoustic-phonon modes [22] . At higher temperatures, however, other mechanisms become more significant leading to faster spin relaxation times. Our theoretical predictions agree reasonably well with existing experimental data on QD ensembles [23] . \n \n Finally, it was shown that the inclusion of exchange interactions between electrons leads to an enhancement of the spin relaxation rate as well as to a decrease in its temperature dependence [24] .",
        "watermark_text": "We have studied the spin relaxation and dephasing processes in semiconductor quantum dots ( QDs ) by solving numerically the full set of equations for electron - electron interactions within the framework of the equation - of - motion method.We found that, at low temperatures, the predominant mechanism involved for spin relaxation is owing to spin - flip scattering with acoustic phonons.The calculated results are compared favorably with available experimental data on QD ensembles.In addition, we show that the inclusion of exchange interaction between electrons leads to an rise in the spin relaxation period as also as to a reduction in its temperature dependence.Spin dynamics plays an important role in many physical phenomena such as magnetic resonance imaging[ 1 ], magneto - optical effects[ 2 ], and spintronics [ 3 ].Semiconductor quantum dots ( QDs ), which can be viewed as artificial atoms[ 4 ], provide us with unique opportunities to study spin relaxation and dephazing mechanisms [ 5 ] - [ 8 ].Recently, there has been considerable interest in studying these issues both experimentally [ 9 ] - [ 11 ] and theoretically [ 12 ] - [ 16 ].In this work, we investigate spin relaxation and dephazation processes in QDs using the equation - of - motion ( EOM ) method[ 17 ].This method allows one to take into account all possible contributions to the self - energetic arising from different types of electron - electron interactions like direct Coulomb repulsion, exchange - correlation potential, Hartree - Fock corrections, and correlation energy [ 18 ].It should be noted that our calculations were performed without any additional approximations outside those used in previous studies based on the EOM formalism[ 19 ] -[ 21 ].The obtained numerical results demonstrate that, at low heats T < 10 K, the main contribution to spin relaxation comes from spin - flip scattering with acoustic - phonon modes[ 22 ].At higher temperatures, however, other mechanisms become more significant leading to faster spin relaxation times.Our theoretical predictions agree reasonably well with existing experimental data on QD ensembles [ 23 ].Finally, it was shown that the inclusion of exchange interactions between electrons leads to an enhancement of the spin relaxation rate as also as to a decrease in its heat dependence [ 24 ]."
    },
    {
        "original_text": "We present new results on temporal variability in the ultraviolet (UV) emission observed by Cassini's Ultraviolet Imaging Spectrograph (UVIS). The data were obtained during orbits that crossed the equatorial plane at distances between 1,000 km and 5,500 km above Jupiter's surface. We find that the brightness distribution is highly variable both temporally and azimuthally with respect to Jupiter's magnetic field direction. This behavior can be explained if we assume that the plasma torus consists of multiple co-rotating structures which are not uniformly distributed around the planet but instead form an arc-like structure centered near the magnetic equator. These observations provide further evidence for the existence of such arcs as predicted by theoretical models. They also suggest that these arcs may have significant effects on the global magnetosphere-ionosphere coupling processes. \n \n Keywords: Jupiter, Saturn, Magnetospheres, Plasmas",
        "watermark_text": "We present fresh results on temporal variability in the ultraviolet ( UV ) emission observed by Cassini ' s Ultraviolet Imaging Spectrograph ( UVIS ).The data were obtained during orbits that crossed the equatorial plane at distances between 1, 000 km and five, 500 km above Jupiter ' s surface.We find that the brightness distribution is highly variable both temporally and azimuthally with respect to Jupiter ' s magnetic field direction.This behavior can be explained if we assume that the plasma torus consists of multiple co - rotating structures which are not uniformly distributed around the planet but instead form an arc - resembling structure centred near the magnetic equator.These observations provide further evidence for the existence of such arcs as predicted by theory models.They also suggest that these arcs might have significant effects on the global magnetosphere - ionosphere pairing processes.Keywords : Jupiter, Saturn, Magnetospheres, Plasmas"
    },
    {
        "original_text": "We present the results of our analysis of high-resolution optical spectra obtained with HST/STIS for four nearby (z<0.1), X-ray selected, Type Ib/c SNe in order to study their progenitor systems. We find that all four objects show evidence for dense CSM surrounding them at distances ranging between 0.01-0.2 pc. The presence of such material is consistent with theoretical expectations for post-low-velocity-bulge (post-LBV) Wolf-Rayet star winds. In addition we detect narrow emission features which are likely due to interaction between SN ejecta and this wind. These observations provide strong constraints on the nature of the progenitor systems: they require massive WR stars as well as binary companions capable of producing significant mass loss prior to explosion. This work was supported by NASA grant NAG5-10842. We have analyzed high resolution STIS/HST data for 4 nearby (z<0.1; Xray-selected) type Ibc supernovae in an attempt to determine the properties of their progenitor systems. All four objects exhibit dense circumstellar matter (CSM; nH>1020 cm-3 ) within 0.01-0.20 parsecs of the supernova site. Such densities are expected if these explosions occur following the ejection of a low velocity \"bulge\" during late stages of stellar evolution. Furthermore, we observe narrow emission features which may be associated with shock-heating of the CSM by the expanding supernova remnant. Our findings suggest that these events result from the deaths of massive Wolf Rayet stars surrounded by close binaries.",
        "watermark_text": "We present the results of our analysis of high - resolution optical spectra obtained with HST / STIS for four nearby ( z1020 cm - 3 ) within zero. 01 - 0. 20 parsecs of the supernova site.Such densities are expected if these explosions occur following the ejection of a low velocity \" bulge \" during late stages of stellar evolution.Furthermore, we observe narrow emission features which may be associated with shock - heating of the CSM by the expanding supernova remnant.Our findings suggest that these events result from the deaths of massive Wolves Rayet stars surrounded by close binaries."
    },
    {
        "original_text": "The Variable Star One-Shot project is an open-source software package for the analysis of astronomical data.  It was developed by members of the Harvard-Smithsonian Center for Astrophysics (CfA) in collaboration with researchers at other institutions around the world.   The goal of this project is to provide a single tool that can be used to analyze all types of astronomical data sets, including photometric time series, spectroscopic observations, images, etc., using state-of-the-art techniques such as image subtraction, cross correlation, period finding algorithms, spectral line fitting, etc.    This software has been released under the GNU General Public License v3.0 and is available on GitHub at: https://github.com/VariableStar/one-shot-astro .\nOne Shot Astro includes several tools which are useful for analyzing large amounts of astronomical data quickly and efficiently.   These include one-shot-datacleaner , which performs automated quality control checks on raw data files;   one-shot-mosaic , which creates mosaicked images from multiple dithered exposures;  one-shot-astrometry , which determines astrometric solutions for individual frames or entire mosaic images;    one-shot-photometry , which measures fluxes and/or magnitudes for stars across a field-of-view;    one-shot-pipeline , which automates the process of running these various tasks together into a pipeline;    one-shot-wikimapia , which allows users to create custom sky maps based on their own catalogs of objects.     In addition to these core packages, there are also many additional modules available through the one-shot-astro repository which allow users to perform more specialized analyses, such as:    one-shot-catalog , which provides access to a variety of different astrophysical databases via SQL queries;    one-shot-fastphot , which uses machine learning methods to measure stellar",
        "watermark_text": "The Variable Star One - Shot project is an open - source software package for the analysis of astronomical data.It was developed by members of the Harvard - Smithsonian Center for Astrophysics ( CfA ) in collaboration with researchers at other institutions around the globe.The goal of this project is to provide a single tool that can be used to analyze all types of astronomical data sets, including photometric time series, spectroscopic observations, imagery, etc., utilizing state - of - the - artwork techniques such as image subtraction, cross correlation, period finding algorithms, spectral line fitting, etc.This software has been released under the GNU General Public License v3. 0 and is available on GitHub at : https : / / github. com / VariableStar / one - shooter - astro.One Shot Astro includes several tools which are useful for analyzing large amounts of astronomical data quickly and efficiently.These include one - shot - datacleaner, which performs automated quality control checks on raw data files ; one - shot - mosaic, which creates mosaicked images from multiple dithered exposures ; one - shot - astrometry, which determines astrometric solutions for individual frames or entire mosaic images ; one - shot - photometry, which measures fluxes and / or magnitudes for stars across a field - of - view ; one - shot - pipeline, which automates the process of running these various tasks together into a pipeline ; one - shot - wikimapia, which allows users to create custom sky maps based on their own catalogs of objects.In addition to these core packages, there are also many additional modules available through the one - shot - astro repository which allow users to perform more specific analyses, such as : one - shot - catalogue, which provides access to a variety of different astrophysical databases via SQL queries ; one - shot - fastphot, which uses machine learning methods to measure stellar"
    },
    {
        "original_text": "We present near-infrared (NIR) spectroscopy of the black hole X-ray binary system A0620-00 obtained with the Subaru Telescope and Gemini Observatory in 2001-2002. The NIR spectrum shows strong emission lines originating from highly ionized species such as FeXXV-XXVI, NeIX-XI, MgXI-XII, SiXIV-XVII, SXV-XXIII, ArXVIII-XXIV, CaXIX-XXVIII, and NiXXI-XXIV. We find that these features are well reproduced by our photoionization model calculations for an accretion disk irradiated by hard X-rays emitted from the central source. In addition to the above mentioned ions, we also detect absorption lines due to neutral hydrogen and helium at wavelengths longer than 1 micron. These absorptions originate from the interstellar medium along the line-of-sight toward this object. \n \n Keywords: Near-infrared spectroscopy",
        "watermark_text": "We present near - infrared ( NIR ) spectroscopy of the black hole X - ray binary system A0620 - 00 obtained with the Subaru Telescope and Gemini Observatory in 2001 - 2002.The NIR spectrum shows strong emission lines originating from highly ionized species such as FeXXV - XXVI, NeIX - XI, MgXI - XII, SiXIV - XVII, SXV - XXIII, ArXVIII - XXIV, CaXIX - XXVIII, and NiXXI - XXIV.We find that these features are well reproduced by our photoionization model calculations for an accretion disc irradiated by hard X - cards emitted from the central source.In addition to the above mentioned ions, we also detect absorption lines owing to neutral hydrogen and helium at wavelengths farther than 1 micron.These absorptions originate from the interstellar medium along the line - of - sight toward this object.Keywords : Near - infrared spectroscopy"
    },
    {
        "original_text": "We present new radio continuum and H I absorption data for the dwarf irregular galaxy VIRGOHI 21, which is located at the edge of the virgo cluster. The galaxy has an optical diameter of about 1 kpc (0.3 arcmin) and shows no signs of star formation activity. We find that its neutral hydrogen mass amounts to M_HI = 2 x 10^{10} M_sol. Its total luminosity L_TOT = 3.5 x 10^{8} L_SOL corresponds to a B-band absolute magnitude MB = -18.7 mag. This value agrees well with those found by other authors for similar galaxies. From our analysis we conclude that this object may be considered as a candidate for a \"dark galaxy\". It contains only little or even no stars but still possesses a large amount of cold gas. If confirmed, it would provide further evidence for the existence of such objects.",
        "watermark_text": "We present new radio continuum and H I absorption data for the dwarf irregular galaxy VIRGOHI 21, which is located at the edge of the virgo cluster.The galaxy has an optical diameter of about 1 kpc ( 0. 3 arcmin ) and shows no signs of stellar formation activity.We find that its neutral hydrogen mass amounts to M _ HI = 2 × 10 ^ { 10 } M _ sol.Its total luminosity L _ TOT = 3. 5 x 10 ^ { 8 } L _ SOL corresponds to a B - band absolute magnitude MB = - 18. 7 mag.This value agrees well with those found by other writers for similar galaxies.From our analysis we conclude that this object may be considered as a candidate for a \" dark galaxy \".It contains only little or even no stars but still possesses a large amount of cold gas.If confirmed, it would provide further evidence for the presence of such objects."
    },
    {
        "original_text": "We present an efficient numerical scheme to solve the incompressible Navierstokes (NS) equations by using the lattice Boltzmann method with the Inverse Kinetic Approach (IKA). The IKA is based on the idea that the NS equation can be recovered as the equilibrium state in the Chapman-Enskog expansion, and it has been successfully applied to various fluid dynamics problems. We show how this concept can be implemented into the LBM framework. Numerical results are presented to demonstrate the accuracy and efficiency of our proposed algorithm. Finally we discuss some possible extensions of the current work. Keywords: Lattice Boltzmann Method; Inverse Kinetic Approximation; Incompressible Navier-Stokes; Computational Fluid Dynamics. 1 Introduction The lattice Boltzmann method (LBM), originally developed by Frisch et al [1] , is one of the most promising approaches to computational fluid dynamics (CFD). It is particularly suitable for parallel computing due to its inherent locality [2] . Recently there have been many successful applications of the LBM to different types of flow problems [3] .\nThe basic idea behind the LBM is to represent the distribution function f(x,t) at each node x of a regular grid by a finite number of particles moving along discrete velocities c i = ciΔt/Δx, where Δx and Δt denote respectively the spatial and temporal resolutions [4] . Then the evolution of these particles is governed by the following equation: \nwhere τ denotes the relaxation time which controls the rate of approaching towards the equilibrium distribution function f eq i\n. By choosing appropriate values of τ, the macroscopic quantities such as density ρ and velocity u can be obtained through moments of the distribution function:",
        "watermark_text": "We present an efficient number scheme to solve the incompressible Navierstokes ( NS ) equations by using the lattice Boltzmann methodology with the Inverse Kinetic Approach ( IKA ).The IKA is based on the idea that the NS equation can be recovered as the equilibrium state in the Chapman - Enskog expansion, and it has been effectively applied to various fluid dynamics problems.We show how this concept can be implemented into the LBM framework.Numerical results are presented to demonstrate the accuracy and efficiency of our proposed algorithm.Finally we discuss some possible extensions of the current work.Keywords : Lattice Boltzmann Method ; Inverse Kinetic Approximation ; Incompressible Navier - Stokes ; Computational Fluid Dynamics.1 Introduction The lattice Boltzmann method ( LBM ), originally developed by Frisch imp al[ 1 ], is one of the most promising approaches to computational fluid dynamics ( CFD ).It is particularly suitable for parallel programming due to its inherent locality [ 2 ].Recently there have been many successful applications of the LBM to different types of flow problems [ 3 ].The basic idea behind the LBM is to represent the distribution function f ( x, t ) at each node x of a regular grid by a infinite number of particles moving along discrete velocitiesc i = ciΔt / Δx, where Δx and Δt denote respectively the spatial and temporal resolutions[ 4 ].Then the evolution of these particles is governed by the following equation : where τ denotes the relaxation time which controls the rate of approaching towards the equilibrium distribution function f eq i.By choosing appropriate values of τ, the macroscopic quantities such as density ρ and velocity u can be attained through moments of the distribution function :"
    },
    {
        "original_text": "The metal-insulator phase diagram of the quasi-one dimensional organic conductor (TMTSF2)2SO3 has been investigated using infrared spectroscopy and scanning tunneling microscopy at temperatures down to 20 mK. The temperature dependence of the optical conductivity shows that the charge gap opens below TMI = 135 K, which is consistent with previous results obtained on single crystals grown under different conditions. In addition we find evidence for an additional energy scale associated with the formation of excitons near 50 meV. We show that this feature can be explained within a simple model based on electron-phonon interaction between molecular orbitals. Finally, our data reveal that the electronic structure changes significantly across the metal-insulator transition. This finding suggests that the insulating state may not simply result from localization effects but rather involves strong correlations among electrons. The metal-insulator phase diagram was studied in detail by infrared spectroscopy and scanning tunnel microscopy experiments performed on high-quality single crystals of (TMTSF)2SO3. Our measurements provide direct spectroscopic evidence for two distinct energy scales involved in the opening of the charge gap as well as for significant modifications of the electronic structure across the metal-insulator boundary.",
        "watermark_text": "The metal - insulator phase diagram of the quasi - one dimensional organic conductor ( TMTSF2 ) 2SO3 has been investigated using infrared spectroscopy and scanning tunneling microscopy at temperatures down to 20 mK.The temperature dependence of the optical conductivity shows that the charge gap opens below TMI = 135 K, which is consistent with previous results achieved on single crystals grown under different conditions.In addition we find evidence for an additional energy scale involved with the formation of excitons near 50 meV.We show that this feature can be explained inside a simple model based on electron - phonon interface between molecular orbitals.Finally, our data reveal that the electronic structure changes significantly throughout the metal - insulator transition.This finding suggests that the insulating state might not simply result from localization effects but instead involves strong correlations among electrons.The metal - insulator phase diagram was studied in detail by infrared spectroscopy and scanning tunnel microscopy experiments performed on highly - quality single crystals of ( TMTSF ) 2SO3.Our measurements provide direct spectroscopic evidence for 2 distinct energy scales involved in the opening of the charge gap as also as for significant modifications of the electronic structure across the metal - insulator boundary."
    },
    {
        "original_text": "We present an ab initio method for the calculation of phonon dispersion relations in solids, which is based on the direct solution of the Bethe-Salpeter equation (BSE) and includes electron-phonon interaction effects beyond the adiabatic approximation. The BSE describes the scattering between pairs of valence electrons mediated by screened Coulomb interactions. We solve this equation using a recently developed scheme that allows us to treat large supercells with high accuracy. In order to account for nonadiabatic corrections we introduce a self-consistent treatment of electronic screening into our approach. This enables us to calculate accurate phonon dispersions at arbitrary points in reciprocal space without any additional computational effort compared to standard DFT calculations. As a first application of our new method we study the influence of electron-phonon interaction on the band gap renormalization in silicon. Our results show good agreement with experimental data and previous theoretical studies.",
        "watermark_text": "We present an ab initio method for the calculation of phonon dispersion relations in solids, which is based on the directly solution of the Bethe - Salpeter equation ( BSE ) and includes electron - phonon interaction effects beyond the adiabatic approximation.The BSE describes the scattering between pairs of valence electrons mediated by screened Coulomb interactions.We solve this equation using a recently developed scheme that enables us to treat big supercells with high accuracy.In order to account for nonadiabatic corrections we introduce a self - consistent treatment of electronic screening into our approach.This enables us to calculate accurate phonon dispersions at arbitrary points in reciprocal space without any extra computational work compared to standard DFT calculations.As a first application of our new method we study the influence of electron - phonon interface on the band gap renormalization in silicon.Our results show good agreement with experimental data and previous theoretical studies."
    },
    {
        "original_text": "We study the effect of confinement on the structure and dynamics of a simple model system, namely an ensemble of N identical particles interacting via repulsive pair potentials confined in a volume V by two parallel impenetrable walls at distance L apart.  We use Monte Carlo simulations to calculate the density profiles for different values of the wall separation L and particle number N . The results show that the density profile is not affected significantly when increasing the wall separation beyond a certain value which depends on both the temperature T and the particle number N .  In addition we find that the self-diffusion coefficient D decreases with decreasing wall separation but increases again if one further reduces the wall separation below some critical value depending on the temperature T .\nThe observed behavior can be explained within the framework of mode-coupling theory (MCT) using a generalized version of MCT developed recently by us [Physica A, vol. 315, no. 1, pp. 39-48, (2003), Physica A, vol. 320, no. 3, pp. 633-646, (2004)].",
        "watermark_text": "We study the effect of confinement on the structure and dynamics of a simple model system, namely an ensemble of N identical particles interacting via repulsive pair potentials confined in a volume V by two parallel impenetrable walls at distance L apart.We use Monte Carlo simulations to calculate the density profiles for different values of the wall separation L and particle number N.The results show that the density profile is not impacted significantly when raising the wall separation past a certain value which depends on both the temperature T and the particle count N.In addition we find that the self - diffusion coefficient D decreases with decreasing wall separation but increases again if one further reduces the wall separation below some critical value depending on the temperature T.The observed behaviour can be explained within the framework of mode - coupling theory ( MCT ) using a generalized form of MCT derived recently by us[ Physica A, vol. 315, no. 1, pp. 39 - 48, ( 2003 ), Physica A, vol. 320, no. 3, pp.633 - 646, ( 2004 ) ]."
    },
    {
        "original_text": "The quantum group of isometries (QGI) was introduced by Connes as the universal object for deformations of classical groups, which are obtained via spectral triples on commutative C*-algebras.  In this talk we will discuss how to define QGI's using noncommutative geometry techniques such as operator algebras and von Neumann algebras.   We will also explain how these objects can be used to study the classification problem of Riemannian manifolds with positive scalar curvature. The Quantum Group of Isometries (QGI), first defined by Alain Connes, plays an important role in both classical and noncommutative geometry. It is the universal object for deforming classical Lie groups into their corresponding quantum groups. This talk will give an introduction to QGI’s and show that they can be studied through operator algebra theory and von Neumann algebras. Finally it will present some results about the classification problem of Riemannain manifolds with positive scalar curvatures.",
        "watermark_text": "The quantum group of isometries ( QGI ) was introduced by Connes as the universal object for deformations of classical groups, which are obtained via spectral triples on commutative C * - algebras.In this talk we will discuss how to define QGI ' s using noncommutative geometry techniques such as operator algebras and von Neumann algebras.We will also explain how these objects can be used to study the classification issue of Riemannian manifolds with positive scalar curvature.The Quantum Group of Isometries ( QGI ), first defined by Alain Connes, plays an key role in both classical and noncommutative geometry.It is the universal object for deforming classical Lie groups into their corresponding quantum groups.This talk will give an introduction to QGI ’ s and show that they can be studied through operator algebra theory and von Neumann algebras.Finally it will present some results about the classification problem of Riemannain manifolds with positive scalar curvatures."
    },
    {
        "original_text": "We study the electrodynamic properties of Josephson vortices (JVs) in hightemperature superconductors by solving numerically the time-dependent Ginzburg-Landau equations with an external magnetic field and current density. We find that JVs can be driven into motion by applying either a dc or ac electric field, which is consistent with previous experiments on YBa2Cu3O7-δ single crystals. The JV velocity increases linearly as the applied voltage increases for small voltages but saturates at large voltages due to the pinning effect. In addition, we show that the JV velocity decreases when increasing the temperature because of thermal fluctuations. Finally, we demonstrate that the JV dynamics are strongly affected by the anisotropy of the sample. \n \n Introduction \n \n High-temperature superconductivity has been discovered more than 30 years ago [1–3] . Since then, many theoretical models have been proposed to explain this phenomenon [4–9] , among them the so-called two-fluid model [10] . According to this theory, there exist two different types of charge carriers in these materials, namely electrons and holes [11] . These particles interact via attractive Coulomb forces [12] and form Cooper pairs [13] . When the material undergoes a phase transition below its critical temperature Tc, the Cooper pairs condense into a superfluid state [14] . This leads to macroscopic quantum phenomena such as zero resistance [15] and Meissner effect [16] . \n \n However, it was soon realized that the conventional Bardeen-Cooper-Schrieffer (BCS) theory [17] cannot fully account for all experimental observations [18] . For example, the BCS theory predicts that the energy gap between the ground-state and excited states should decrease rapidly near T = 0 K [19] . On the other hand, recent measurements [20] indicate that the energy gap remains almost constant down to very low temperatures [21] . To overcome this problem, several extensions of the original BCS theory were developed [22–24] . Among those theories, one of the most successful ones is the Eliashberg formalism [25] , where the electron-phonon interaction plays an important role [26] . It turns out that",
        "watermark_text": "We study the electrodynamic properties of Josephson vortices ( JVs ) in hightemperature superconductors by solving numerically the time - dependent Ginzburg - Landau equations with an external magnetic field and current density.We find that JVs can be driven into motion by application either a dc or ac electric field, which is consistent with previous experiments on YBa2Cu3O7 - δ single crystals.The JV velocity increases linearly as the applied voltage increases for small voltages but saturates at large voltages due to the pinning effect.In addition, we show that the JV velocity decreases when increasing the temperature because of thermal fluctuations.Finally, we demonstrate that the JV dynamics are strongly affected by the anisotropy of the sample.Introduction High - temperature superconductivity has been discovered more than thirty years ago [ 1 – 3 ].Since then, many theory models have been proposed to explain this phenomenon [ 4 – 9 ], among them the so - called two - fluid model [ 10 ].According to this theory, there remain two different types of charge carriers in these materials, like electrons and holes [ 11 ].These particles interact via attractive Coulomb forces [ 12 ] and form Cooper pairs [ 13 ].When the material undergoes a phase transition below its critical temperature Tc, the Cooper pairs condense into a superfluid state [ 14 ].This leads to macroscopic quantum phenomena such as zero resistance [ 15 ] and Meissner effect[ 16 ].However, it was soon realized that the conventional Bardeen - Cooper - Schrieffer ( BCS ) theory [ 17 ] cannot fully account for all experimental observations[ 18 ].For example, the BCS theory predicts that the energy gap between the ground - state and excited states should decrease rapidly near T =0 K[ 19 ].On the other hand, recent measurements [ 20 ] indicate that the energy gap remains almost constant down to very low heats [ 21 ].To overcome this problem, several extensions of the original BCS theory were developed [ 22 – 24 ].Among those theories, one of the most successful ones is the Eliashberg formalism[ 25 ], where the electron - phonon interaction plays an important role[ 26 ].It turns out that"
    },
    {
        "original_text": "We study parallelizable manifolds and their geometry within the context of generalized Lagrange spaces (GLS). We show that every parallelizable manifold is locally isomorphic to an open subset of some GLS, which we call its local model space. The main results are as follows:  1) Every parallelizable n-manifold admits a global coordinate system with n coordinates.  2) If M is a parallelizable n-manif old then there exists a unique vector bundle over M whose total space is diffeomorphic to R^n x M . 3) Let M be a parallelizable n-man ifold. Then for any point p ∈ M , there exist neighborhoods U of p and V of 0 in T_pM such that:  4) For each point p ∈ M , let π : E → M denote the vector bundle associated to M by Theorem 3.1. Then there exists a natural isomorphism between the fiber at p of this vector bundle and the tangent space TpM:",
        "watermark_text": "We study parallelizable manifolds and their geometry within the context of generalized Lagrange spaces ( GLS ).We show that every parallelizable manifold is locally isomorphic to an open subset of some GLS, which we call its local model space.The main results are as follows : 1 )Every parallelizable n - manifold admits a global coordinate system with n coordinates.2 )If M is a parallelizable n - manif old then there exists a unique vector bundle over M whose total space is diffeomorphic to R ^ n x M.3 ) Let M be a parallelizable n - man ifold.Then for any point p ∈ M, there exist neighborhoods U of p and V of 0 in T _ pM such that : 4 )For each point p ∈ M, let π : E → M denote the vector bundle associated to M by Theorem 3. 1.Then there exists a natural isomorphism between the fiber at p of this vector bundle and the tangent space TpM :"
    },
    {
        "original_text": "The self-consistent approach to the description of nuclear matter is reviewed and its application to other systems, such as atomic nuclei or quark-gluon plasma, discussed briefly. The main idea behind this method is that one should not consider only the mean field acting on particles but also take into account fluctuations around it. This leads to an infinite set of coupled equations for all orders of correlation functions which can be solved by truncation at some order. In particular we discuss how the results depend on the choice of the approximation scheme used. We show that the inclusion of higher-order correlations improves agreement with experimental data considerably. Finally, we present our recent results obtained within the framework of the relativistic random phase approximation (RRPA) including up to fourth-order correlations. These calculations are performed using realistic nucleonnucleon interactions derived from chiral effective theory. It turns out that the RRPA results agree well with available experimental information about excited states of medium-heavy nuclei.",
        "watermark_text": "The self - consistent approach to the description of nuclear matter is reviewed and its application to other systems, such as atomic nuclei or quark - gluon plasma, discussed briefly.The main idea behind this method is that one should not consider only the mean field acting on particles but also take into account fluctuations surrounding it.This leads to an infinite set of coupled equations for all orders of correlation functions which can be solved by truncation at some order.In particular we discuss how the results depend on the choice of the approximation system used.We show that the inclusion of higher - order correlations improves agreement with experimental data considerably.Finally, we present our recent findings obtained within the framework of the relativistic random phase approximation ( RRPA ) including up to fourth - order correlations.These calculations are performed using realistic nucleonnucleon interactions derived from chiral effective theory.It turns out that the RRPA results agree well with available experimental information about excited states of medium - heavy nuclei."
    },
    {
        "original_text": "We present an analysis of chemical equilibrium and disequilibrium processes occurring in the atmospheres of substellar mass objects (SMBOs). We have developed a new method for calculating departures from chemical equilibrium, which is based on the assumption that all species are in local thermodynamic equilibrium with each other at any given point within the atmosphere. This approach allows us to calculate the abundances of individual molecular species as functions of altitude above the photosphere. The results show that there can be significant deviations from chemical equilibrium even under conditions where the gas temperature is much higher than the dust temperature. In particular, we find that carbon monoxide may become depleted by several orders of magnitude relative to its abundance predicted by chemical equilibrium models. These findings suggest that SMBO observations should take into account possible non-equilibrium effects when interpreting their spectra. \n \n Keywords: Chemical equilibrium; Dust grains; Local thermodynamic equilibrium",
        "watermark_text": "We present an analysis of chemical equilibrium and disequilibrium processes occurring in the atmospheres of substellar mass objects ( SMBOs ).We have developed a new method for calculating departures from chemical equilibrium, which is based on the assumption that all species are in local thermodynamic balance with each other at any given point within the atmosphere.This approach allows us to calculate the abundances of single molecular species as functions of height above the photosphere.The results show that there can be significant deviations from chemical equilibrium even under conditions where the gas temperature is much higher than the dust temperature.In particular, we find that carbon monoxide may become depleted by several orders of coordination relative to its abundance forecast by chemistry equilibrium models.These findings suggest that SMBO observations should take into account possible non - equilibrium effects when interpreting their spectra.Keywords : Chemical equilibrium ; Dust grains ; Local thermodynamic equilibrium"
    },
    {
        "original_text": "We report on the measurement and analysis of diffusion coefficients for probe molecules embedded within polymer solutions using optical techniques.  The experiments were performed with two different types of probes, fluorescently labeled polystyrene spheres (PS) and dye doped poly(methyl methacrylate) (PMMA).  We find that both PS and PMMA exhibit anomalous subdiffusive behavior at low concentrations but normal diffusive behavior at higher concentrations.  In addition to measuring the mean square displacement as a function of time we also measure the distribution of displacements over many particles simultaneously.   This allows us to extract information about the underlying dynamics which is not possible by simply looking at the ensemble averaged MSD curve alone.  By fitting our data to an appropriate model we are able to determine the concentration dependence of the diffusion coefficient D0 and the exponent α characterizing the power law decay of the probability density function P(Δr). Our results show good agreement between theory and experiment when compared against predictions based upon the generalized Langevin equation (GLE).   These findings demonstrate how optical methods can be used to study complex systems such as concentrated polymer solutions where traditional light scattering techniques may fail due to multiple scattering effects.",
        "watermark_text": "We report on the measurement and analysis of diffusion coefficients for probe molecules embedded within polymer solutions using optical methods.The experiments were performed with two different types of probes, fluorescently designated polystyrene spheres ( PS ) and dye doped poly ( methyl methacrylate ) ( PMMA ).We find that both PS and PMMA exhibit anomalous subdiffusive behavior at small concentrations but normal diffusive behavior at upper concentrations.In addition to measuring the mean square displacement as a function of time we also measure the spread of displacements over many particles simultaneously.This allows us to extract information about the underlying dynamics which is not possible by simply looking at the ensemble averaged MSD curve solely.By fitting our data to an appropriate model we are able to determine the concentration dependence of the diffusion coefficient D0 and the exponent α characterizing the power law decay of the probability density function P ( Δr ).Our results show good agreement between theory and experiment when compared against predictions based upon the generalized Langevin equation ( GLE ).These findings demonstrate how optical methods can be used to study complex systems such as concentrated polymer solutions where traditional light scattering technologies may fail due to multiple scattering effects."
    },
    {
        "original_text": "The present work is devoted to study some properties of curves in P^3 having an exceptional secant plane, i.e., such that there exists a line intersecting them at two points and not passing through any other point on the curve.  We give necessary conditions for a curve to have an exceptional secant plane (Proposition 1). Then we prove that if a curve has an exceptional secant plane then it lies on a quadric surface (Theorem 2).  Finally, using this result, we show how one can construct all possible families of curves with an exceptional secant plane by means of their associated linear systems (Theorems 3-7).\nKey words: Curve, Secant Plane, Quadric Surface. Mathematics Subject Classification (2000): 14C20, 14D10, 32S15. The research leading to these results was supported by the Russian Foundation for Basic Research under grant No. 02-01-00962-a",
        "watermark_text": "The present work is devoted to study some properties of curves in P ^ 3 having an exceptional secant plane, i. e., such that there exists a line intersecting them at 2 points and not passing through any other point on the plane.We give necessary conditions for a curve to have an exceptional secant plane ( Proposition 1 ).Then we prove that if a curve has an exceptional secant plane then it lay on a quadric surface ( Theorem 2 ).Finally, using this result, we show how one can construct all possible families of curves with an exceptional secant plane by means of their associated linear systems ( Theorems 3 - 7 ).Key words : Curve, Secant Plane, Quadric Surface.Mathematics Subject Classification ( 2000 ) : 14C20, 14D10, 32S15.The research leading to these results was supported by the Russian Foundation for Basic Research under award No. 02 - 01 - 00962 - a"
    },
    {
        "original_text": "We present new high-resolution (0.5 arcsec) radio continuum observations at 1.4 GHz and 4.8 GHz made with the Australia Telescope Compact Array (ATCA). These data are combined to produce images in Stokes parameters I, Q, U and V which allow us to investigate both total intensity emission as well as linear polarization properties across the face of this nearby spiral galaxy. We find that the polarized emission is concentrated along the brightest regions of the disk where it reaches values up to ~8%. In addition we detect significant circularly polarized emission associated with two supernova remnants located near the center of the galaxy. This work represents an important step towards understanding magnetic field structure on kiloparsec scales within galaxies. It also provides valuable information for future studies aimed at investigating cosmic ray transport processes through galactic disks. \n \n Keywords: Radio astronomy, Galaxy evolution, Magnetic fields, Polarization",
        "watermark_text": "We present new high - resolution ( 0. 5 arcsec ) radio continuum observations at 1. 4 GHz and 4. 8 GHz made with the Australia Telescope Compact Array ( ATCA ).These data are combined to produce pictures in Stokes parameters I, Q, U and V which allow us to investigate both total intensity emission as nicely as linear polarization properties across the face of this nearby spiral galaxy.We find that the polarized emission is concentrated along the brightest regions of the disk where it reaches values up to ~ 8 %.In addition we detect significant circularly polarized emission involved with 2 supernova remnants located near the centre of the galaxy.This work represents an important step towards understanding magnetic field structure on kiloparsec levels within galaxies.It also offers valuable data for future studies aimed at investigating cosmic ray transport processes through galactic disks.Keywords : Radio astronomy, Galaxy evolution, Magnetic fields, Polarization"
    },
    {
        "original_text": "We present the results of multiepoch radial velocity (RV) observations for four late-type M dwarfs and three brown dwarf candidates with spectral types ranging between M3V-M8V, obtained using the High Accuracy Radial velocity Planet Searcher (HARPS). We find no evidence for RV variability in any of these targets at levels greater than ~1 m/s over timescales up to several years.  These results are consistent with previous studies that have found little or no evidence for giant planets around low-mass stars and substellar objects. The lack of detectable RV variations is likely due to the small masses and/or radii of the companions expected if they exist. However, we cannot rule out the possibility that some of our targets harbor terrestrial mass planets on orbits with periods longer than those probed by our current data set. Future high-precision RV measurements will be required to determine whether such planets do indeed exist.",
        "watermark_text": "We present the results of multiepoch radial velocity ( RV ) observations for four late - type M dwarfs and 3 brown neutron candidates with spectral types ranging between M3V - M8V, obtained using the High Accuracy Radial velocity Planet Searcher ( HARPS ).We find no proof for RV variability in any of these targets at levels greater than ~ 1 m / s over timescales up to several years.These results are consistent with previous studies that have found little or no evidence for giant worlds around low - mass stars and substellar objects.The lack of detectable RV variations is likely due to the tiny masses and / or radii of the companions expected if they exist.However, we cannot rule out the possibility that some of our targets harbor terrestrial mass worlds on orbits with periods longer than those probed by our current data set.Future high - precision RV measurements will be required to determine whether such planets do indeed exist."
    },
    {
        "original_text": "We present new near-infrared (NIR) observations for the radio-loud elliptical galaxy NGC 4261, obtained with the Subaru telescope. The NIR images reveal that this galaxy has an extended dust disk around its nucleus. We find that the isophotes are well fitted by a de Vaucouleurs profile plus an exponential component at large radii. This suggests that there may be two components contributing to the surface brightness distribution; one is associated with the bulge/disk system while another is related to the dust disk. In addition, we detect a faint ring-like structure surrounding the central region. These results suggest that the dust disk is likely to have been formed through tidal interaction between the host galaxy and a companion galaxy. Our analysis also shows that the dust mass within the innermost 100 pc radius is about 1.5 x 10^6 M_sol. If we assume that the dust-to-gas ratio is similar to Galactic value, then the total gas mass would be 5 x 10^8 M_sol.",
        "watermark_text": "We present new near - infrared ( NIR ) measurements for the radio - loud elliptical galaxy NGC 4261, obtained with the Subaru telescope.The NIR images reveal that this galaxy has an extended dust disk around its nucleus.We find that the isophotes are well fitted by a de Vaucouleurs profile plus an exponential contribution at large radii.This suggests that there may be 2 components contributing to the surface brightness distribution ; one is associated with the bulge / disc system while another is related to the dust disk.In addition, we detect a faint ring - like structure surrounding the center region.These results suggest that the dusty disk is likely to have been formed through tidal interaction between the home galaxy and a companion galaxy.Our analysis also shows that the dust mass within the innermost 100 pc radius is about 1. 5 x 10 ^ 6 M _ sol.If we assume that the dust - to - gas ratio is similar to Galactic value, then the total gas mass would be 5 x 10 ^ eight M _ sol."
    },
    {
        "original_text": "We report the discovery of massive outflows (1000 km s-1) in two post-starburst galaxies, which are thought to be progenitors of present-day elliptical galaxies. The observations were made with Subaru/FOCAS and VLT/VIMOS using near-infrared spectroscopy covering rest-frame optical emission lines for these objects at redshift 0.6. We found that both galaxies show strong [O III]5007Å/Hβ ratios indicating high ionization parameters. In addition, we detected blueshifted high-velocity components in Hα profiles as well as broad wings on their Hα line profiles. These results suggest that there is an energetic ionized gas flow driven by AGN and/or supernovae activity. This work was supported by Grants-in-Aid for Scientific Research from MEXT Japan (No. 20540230). Keywords: Emission-line galaxy, Galaxy evolution, Nearby galaxy",
        "watermark_text": "We report the discovery of massive outflows ( 1000 km s - 1 ) in two post - stellarburst galaxies, which are thought to be progenitors of present - day elliptical galaxies.The observations were made with Subaru / FOCAS and VLT / VIMOS utilizing near - infrared spectroscopy covering rest - frame optical emission lines for these objects at redshift 0. 6.We found that both galaxies show strong [ O III ] 5007Å / Hβ ratios indicating high ionization parameters.In addition, we detected blueshifted high - velocity components in Hα profiles as well as wide wings on their Hα line profiles.These results suggest that there is an energetic ionized gas flow driven by AGN and / or supernovae activity.This work was supported by Grants - in - Aid for Scientific Research from MEXT Japan ( No. 20540230 ).Keywords : Emission - line galaxy, Galaxy evolution, Nearby galaxy"
    },
    {
        "original_text": "We present an extension to the classical lubrication theory that accounts for shear thinning effects on both the fluid viscosity and the friction coefficient, which are assumed to be functions of local pressure only.  The resulting model is applied to study the effect of non-Newtonian rheology on the elastohydrodynamic (EHD) behavior of a circular contact between two elastic solids with different surface roughnesses under pure rolling conditions.  We show that the presence of shear thinning leads to significant changes in the predicted load-carrying capacity as well as the distribution of the normal stress across the contact area compared to those obtained using Newtonian models.  In particular, we find that the maximum value of the dimensionless pressure increases significantly when the fluids exhibit strong shear thinning characteristics.  Moreover, our results indicate that the inclusion of shear thinning effects can lead to substantial reductions in the magnitude of the dimensionless tangential stresses at the centerline of the contact region.  Finally, it should be noted that the proposed theoretical framework may also be used to investigate other important phenomena such as thermal effects or mixed lubrication regimes.",
        "watermark_text": "We present an extension to the classical lubrication theory that accounts for shear thinning effects on both the fluid viscosity and the friction coefficient, which are assumed to be functions of local pressure only.The resulting model is applied to study the effect of non - Newtonian rheology on the elastohydrodynamic ( EHD ) behavior of a circle contact between two elastic solids with different face roughnesses under pure rolling conditions.We show that the presence of shear thinning leads to significant shifts in the predicted burden - carrying capacity as also as the distribution of the normal stress across the contact region compared to those derived using Newtonian models.In particular, we find that the maximum value of the dimensionless pressure increases significantly when the flows exhibit strong shear thinning traits.Moreover, our results indicate that the inclusion of shear thinning effects can result to substantial reductions in the magnitude of the dimensionless tangential stresses at the centerline of the contact region.Finally, it should be noted that the suggested theoretical frame may also be utilized to probe other important phenomena such as thermal effects or mixed lubrication regimes."
    },
    {
        "original_text": "We present new maps of the circumstellar SiO (v=1, v=2) masers around the Mira variable R Leo obtained with the Very Long Baseline Array at 22 GHz and 43 GHz. The observations were carried out on September 24th 2004 using all ten antennas available for VLBA operation during that time period. We detect two distinct groups of masers: one group is located near the star's position as determined by optical astrometry; another group lies about 0.5 arcsec to the south-west of this location. Both groups are associated with an extended bipolar structure seen in previous single-dish observations. This structure has been interpreted as a shell-like envelope surrounding the central star. Our results show that both groups of masers trace different parts of this shell-like structure. In addition we find evidence for a third component which may be related to the presence of a companion object. \n \n Keywords: Masers",
        "watermark_text": "We present new maps of the circumstellar SiO ( v = 1, v = 2 ) masers around the Mira variable R Leo obtained with the Very Long Baseline Array at 22 GHz and 43 GHz.The observations were taken out on September 24th 2004 using all 10 antennas available for VLBA operation during that time period.We detect 2 distinct groups of masers : one group is located near the star ' s position as determined by optical astrometry ; another one lies about zero. 5 arcsec to the south - west of this location.Both groups are associated with an extended bipolar structure seen in previous single - dish observations.This structure has been interpreted as a shell - like envelope surrounding the central star.Our results show that both groups of masers track different parts of this shell - like structure.In addition we find evidence for a 3rd component which may be related to the existence of a companion object.Keywords : Masers"
    },
    {
        "original_text": "In this work, we propose an evolutionary neural gas model for input categorization and clustering in the context of self-organizing networks. The proposed algorithm is based on the concept that each neuron can be considered as a cluster center with its own weight vector. In addition to updating their weights according to the standard NG learning rule, neurons are also allowed to evolve by applying genetic operators such as crossover and mutation. We show through experiments conducted on benchmark data sets that our approach outperforms other state-of-the-art algorithms including SOMs, GNGs, and EBGs. Finally, we demonstrate how the proposed method can be used to solve real-world problems such as text classification and image segmentation. Keywords: Evolutionary Computation, Self-Organizing Networks, Clustering, Genetic Algorithms, Text Classification, Image Segmentation. 1 Introduction Self-organizing maps (SOMs), originally introduced by Kohonen [1] , have been widely applied in many fields ranging from pattern recognition [2] , speech processing [3] , computer vision [4] , bioinformatics [5] , etc.. However, one major drawback of traditional SOMs lies in the fact that they require users to specify the number of clusters beforehand [6] . To overcome this problem, several extensions of SOMs were developed [7, 8] .\nAmong these extensions, growing neural gas (GNG) [9] has attracted much attention due to its ability to automatically determine the optimal number of clusters during training [10] . Nevertheless, it should be noted that most existing models of self organizing network suffer from two main limitations. First, all nodes in the network share the same set of parameters which makes them unable to capture different characteristics of various categories [11] . Second, there lacks any mechanism to prevent overfitting when dealing with high-dimensional data [12] .",
        "watermark_text": "In this work, we propose an evolving neural gas model for input categorization and clustering in the context of self - organizing networks.The proposed algorithm is based on the concept that each neuron can be thought as a cluster centre with its own weight vector.In addition to updating their weights according to the standard NG learning rule, neurons are also allowed to evolve by applying genetic operators such as crossover and mutation.We show through experimentation conducted on benchmark data sets that our approach outperforms other state - of - the - art algorithms including SOMs, GNGs, and EBGs.Finally, we demonstrate how the proposed method can be used to solve real - life problems such as text classification and imagery segmentation.Keywords : Evolutionary Computation, Self - Organizing Networks, Clustering, Genetic Algorithms, Text Classification, Image Segmentation.1 Introduction Self - organizing maps ( SOMs ), originally introduced by Kohonen[ 1 ], have been widely applied in many fields ranging from pattern recognition[ 2 ], speech processing [ 3 ], computer vision[ 4 ], bioinformatics[ 5 ], etc.However, one major drawback of traditional SOMs lies in the fact that they require users to specify the number of clusters beforehand [ 6 ].To overcome this problem, several extensions of SOMs were developed [ 7, 8 ].Among these extensions, growing neural gas ( GNG )[ 9 ] has attracted much attention due to its ability to automatically determine the ideal number of clusters during training [ 10 ].Nevertheless, it should be noted that most extant models of self organizing network suffer from 2 main limitations.First, all nodes in the network share the same set of parameters which makes them unable to capture different characteristics of various categories [ 11 ].Second, there lacks any mechanism to avoid overfitting when dealing with high - dimension data [ 12 ]."
    },
    {
        "original_text": "We consider the problem of power allocation in discrete-input delay-limited fading channels with multiple users and time-varying channel gains. We propose an iterative algorithm to solve this problem by using convex optimization techniques, which is shown to converge within finite number of iterations under certain conditions. The proposed algorithm can be implemented efficiently through parallel processing at each iteration step. Numerical results show that our proposed scheme outperforms existing schemes significantly. \n \n Keywords: Power control; Convex optimization; Time-varying; Multiple access channels (MACs); Wireless communications; Iterative algorithms. 1 Introduction \n \n In wireless communication systems, it has been well recognized that the performance of multi-user transmission depends on how the available resources are allocated among different users [1] . For example, when there exist multiple users sharing a common radio resource such as bandwidth or transmit power, the optimal way to allocate these resources may depend on the specific system settings [2] , e.g., whether the users have equal priority [3] , what type of services they request [4] , etc.. Therefore, efficient resource allocation strategies should take into account all relevant factors so as to maximize overall network utility [5] .\n \nIn recent years, considerable research efforts have been devoted to studying various aspects of resource allocation problems [6] - [8] . Among them, power allocation plays an important role due to its direct impact on both spectral efficiency and energy consumption [9] . However, most previous works assume continuous input alphabets [10] - [12] , while practical digital modulation schemes usually employ discrete constellations [13] . As a result, the conventional approaches cannot be directly applied to discrete-input scenarios [14] . To address this issue, several studies [15] - [17] have investigated the power allocation problem over discrete-input channels recently. Nevertheless, their solutions either require high computational complexity [16] or suffer from slow convergence speed [17] .",
        "watermark_text": "We consider the problem of power allocation in discrete - input delay - limited fading channels with multiple users and time - varying channel gains.We propose an iterative algorithm to solve this issue by using convex optimization techniques, which is shown to converge inside finite number of iterations under certain conditions.The proposed algorithm can be applied efficiently through parallel processing at each iteration step.Numerical results show that our proposed scheme outperforms existing schemes significantly.Keywords : Power control ; Convex optimization ; Time - varying ; Multiple access channels ( MACs ) ; Wireless communications ; Iterative algorithms.1 Introduction In wireless communication systems, it has been well recognized that the performance of multiple - user transmission depends on how the available resources are allotted among different users[ 1 ].For example, when there exist multiple users sharing a common radio resource such as bandwidth or transmit power, the optimal method to allocate these users may depend on the particular system settings [ 2 ], e. g., whether the users have equal priority [ 3 ], what type of services they request [ 4 ], etc.Therefore, efficient resource allocation strategies should take into account all relevant factors so as to maximize overall network utility [ 5 ].In recent years, considerable research efforts have been devoted to studying various aspects of resource allocation problems [ 6 ] -[ 8 ].Among them, power allocation plays an important role due to its direct impact on both spectrum efficiency and energy consumption [ 9 ].However, most previous works assume continuous input alphabets[ 10 ] - [ 12 ], while practical digital modulation schemes usually employ discrete constellations [ 13 ].As a result, the conventional approaches cannot be direct applied to discrete - input scenarios [ 14 ].To address this issue, several studies [ 15 ] - [ 17 ] have investigated the power allocation problem over discrete - input channels recently.Nevertheless, their solutions either demand high computational complexity[ 16 ] or suffer from slow convergence speed [ 17 ]."
    },
    {
        "original_text": "We present the results of an analysis to determine rates, masses, spins, and luminosities for intermediate mass ratio inspiral (IMRI) events detectable with advanced gravitational wave detectors such as Advanced LIGO. We use Monte Carlo simulations to generate IMRIs in galactic binaries that are consistent with current observations of binary pulsars and X-ray binaries. The simulated systems evolve through three phases: detached phase, Roche lobe overflow phase, and common envelope phase. In our simulation we assume that all stars have solar metallicity and initial spin periods of 10 days. For each system generated, we calculate its signal-to-noise ratio using the stationary phase approximation. We find that there will be about one event per year within 100 Mpc with signal-to-noise ratios greater than 8. This is comparable to the rate expected for double neutron star mergers. However, unlike double neutron star mergers which occur at high redshifts, most IMRI events should be detected nearby.",
        "watermark_text": "We present the results of an analysis to decide rates, masses, spins, and luminosities for intermediate mass ratio inspiral ( IMRI ) events detectable with advanced gravitational wave detectors such as Advanced LIGO.We use Monte Carlo simulations to generate IMRIs in galactic binaries that are consistent with current observations of binary pulsars and X - ray binaries.The simulated systems evolve through three phases : detached phase, Roche lobe overflow phase, and common envelope phase.In our simulation we assume that all stars have solar metallicity and initial spin periods of ten days.For each system generated, we calculate its signal - to - noisy ratio using the stationary phase approximation.We find that there will be about 1 event per year within 100 Mpc with signal - to - noise ratios higher than 8.This is comparable to the rate expected for double neutron star mergers.However, unlike double neutron star mergers which occur at high redshifts, most IMRI events should be detected nearby."
    },
    {
        "original_text": "We present new measurements of the baryonic mass fractions (f bar ) in early-type galaxies, based on spatially resolved kinematics for a sample of 12 nearby elliptical/S0 galaxies observed with integral field spectroscopy at optical wavelengths.  We use these data to measure f bar , as well as the total stellar masses M * . The results are compared against predictions from semi-analytic models of galaxy formation within the standard ΛCDM cosmology. Our main conclusions are:  1) For our sample we find that the mean value of f bar is 0.16 ± 0.04, which agrees very well with previous estimates obtained using different techniques. 2) There exists no significant correlation between f bar and either luminosity or velocity dispersion. 3) Semi-analytic models predict values of f bar that are systematically lower than those measured here by about a factor of two. 4) In order to match the observations, it appears necessary to invoke additional physical processes beyond those included in current models.",
        "watermark_text": "We present fresh measurements of the baryonic mass fractions ( f bar ) in early - type galaxies, based on spatially resolved kinematics for a sample of 12 nearby elliptical / S0 galaxies observed with integral field spectroscopy at optical wavelengths.We use these data to measure f bar, as well as the total stellar masses M *.The results are compared against predictions from semi - analytic models of galaxy forming within the standard ΛCDM cosmology.Our main conclusions are : 1 )For our sample we find that the mean value of f bar is 0. 16 ± 0. 04, which agrees very well with previous estimates obtained using varying techniques.2 ) There exists no substantial correlation between f bar and neither luminosity or velocity dispersion.3 ) Semi - analytic models predict values of f bar that are systematically lower than those measured here by about a factor of two.4 )In order to match the observations, it appears necessary to invoke additional physical mechanisms beyond those contained in present models."
    },
    {
        "original_text": "We study droplet excitations in the 2D spin-glass model with nearest-neighbor interactions and random ferromagnetic bonds, which is known to have an infinite number of metastable states at zero temperature. We show that this system has two different types of droplets: small ones are similar to those found in other models studied previously; large droplets are characterized by their fractal structure. The latter type can be viewed as a generalization of the droplet picture proposed earlier for the 3D Ising spin glasses. In addition we find that there exists another class of excitations -the so-called \"giant droplets\"-which are not present in any of these systems. These giant droplets are responsible for the non-universal behavior observed numerically near the critical point. Finally, we argue that our results provide strong numerical support for the existence of a new phase transition line between the paramagnetic state and the spin-glass one. \nI. INTRODUCTORY REMARK\nThe concept of \"droplet excitations\" was introduced originally within the framework of the mean-field theory [1] . It describes how local perturbations affect global properties of the system. This idea turned out to be very useful when applied to various disordered systems such as spin glasses [2] , structural glasses [3] or vortex lattices [4] .\nIn particular it allowed to explain many features of the low-temperature thermodynamics of spin glasses [5] . However, despite its successes, the original droplet picture suffers from some serious drawbacks [6] : first, it does not take into account fluctuations around the saddle-point solution [7]; secondly, it predicts a finite density of droplets even at T = 0 [8] ; thirdly, it cannot describe properly the dynamics of the system [9] . To overcome these difficulties several modifications were suggested [10] . One of them [11] leads to the following expression for the free energy F(T ) per site: \nwhere f0 is the free-energy density of the reference system (e.g., the pure ferromagnet), Ns is the total number of spins, V is the volume occupied by each droplet",
        "watermark_text": "We study droplet excitations in the 2D spin - glass model with nearest - neighbour interactions and random ferromagnetic bonds, which is known to have an infinite number of metastable states at zero temperature.We show that this system has 2 different types of droplets : small ones are similar to those found in other models studied previously ; large droplets are characterized by their fractal structure.The latter type can be viewed as a generalization of the droplet picture proposed earlier for the 3D Ising spin glasses.In addition we find that there exists another class of excitations - the so - called \" giant droplets \" - which are not present in any of these systems.These giant droplets are responsible for the non - universal behavior observed numerically near the critical point.Finally, we argue that our outcomes provide strong numerical support for the existence of a new phase transition line between the paramagnetic state and the spin - glass one.I. INTRODUCTORY REMARK The concept of \" droplet excitations \" was introduced originally within the frame of the mean - field theory [ 1 ].It describes how local perturbations affect global properties of the complex.This idea turned out to be very useful when applied to various disordered systems such as spin glasses [ 2 ], structural glasses [ three ] or vortex lattices[ 4 ].In particular it allowed to explain many features of the low - temperature thermodynamics of spin glasses [ 5 ].However, despite its successes, the original droplet picture suffers from some serious drawbacks[ 6 ] : first, it does not take into account fluctuations round the saddle - point solve [ 7 ] ; secondly, it predicts a finite density of droplets even at T = 0[ 8 ] ; thirdly, it cannot describe properly the dynamics of the system [ 9 ].To overcome these difficulties several modifications were suggested [ 10 ].One of them [ 11 ] leads to the following expression for the free energy F ( T ) per site : where f0 is the free - energy density of the reference system ( e. g., the pure ferromagnet ), Ns is the total number of spins, V is the volume occupied by each droplet"
    },
    {
        "original_text": "The book is divided into three parts, each part containing several chapters. The first two parts are devoted to the development and analysis of geometric control systems in finite-dimensional spaces (the state space) and infinite-dimensional Hilbert spaces (the phase space). In particular, the following topics are considered:\n\nPart I - Geometric Control Theory in Finite-Dimensional Spaces.\n\nChapter 1 - Introduction to Geometric Control Theory.\n Chapter 2 - Basic Concepts of Differential Geometry.\n Chapter 3 - Lie Groups and Their Representations.\n Chapter 4 - Invariant Manifolds for Group Actions on Vector Fields.\n Chapter 5 - Stability Analysis of Nonlinear Systems with State Constraints.\n Chapter 6 - Stabilization by Feedback of Linear Time-Invariant Systems.\n Chapter 7 - Optimal Tracking Problems for Affine Systems.\n Part II - Geometric Control Theory on Infinite-Dimensional Hilbert Spaces.\n\n Chapter 8 - Generalized Euler-Lagrange Equations.\n Chapter 9 - Hamilton-Jacobi Equations.\n Chapter 10 - Pontryagin Maximum Principle.\n Chapter 11 - Optimal Control Problem for Discrete-Time Systems.\n Chapter 12 - Optimal Control Problem with Uncertain Dynamics.\n Chapter 13 - Optimal Control Problem under Stochastic Disturbances.\n Chapter 14 - Optimal Control Problem over Networks.\n Part III - Applications of Geometric Control Theory.\n\n Chapter 15 - Motion Planning for Mobile Robots.\n Chapter 16 - Robot Manipulation Tasks via Task Space Formulation.\n Chapter 17 - Visual Servoing Based on Image Feature Extraction.\n Chapter 18 - Model Predictive Control for Industrial Processes.",
        "watermark_text": "The book is divided into 3 parts, each one containing several chapters.The first two parts are devoted to the development and analysis of geometric control systems in finite - dimension spaces ( the state space ) and infinite - dimensional Hilbert systems ( the phase space ).In particular, the following topics are considered :Part I - Geometric Control Theory in Finite - Dimensional Spaces.Chapter 1 - Introduction to Geometric Control Theory.Chapter 2 - Basic Concepts of Differential Geometry.Chapter 3 - Lie Groups and Their Representations.Chapter 4 - Invariant Manifolds for Group Actions on Vector Fields.Chapter 5 - Stability Analysis of Nonlinear Systems with State Constraints.Chapter 6 - Stabilization by Feedback of Linear Time - Invariant Systems.Chapter 7 - Optimal Tracking Problems for Affine Systems.Part II - Geometric Control Theory on Infinite - Dimensional Hilbert Spaces.Chapter 8 - Generalized Euler - Lagrange Equations.Chapter 9 - Hamilton - Jacobi Equations.Chapter 10 - Pontryagin Maximum Principle.Chapter 11 - Optimal Control Problem for Discrete - Time Systems.Chapter 12 - Optimal Control Problem with Uncertain Dynamics.Chapter 13 - Optimal Control Problem under Stochastic Disturbances.Chapter 14 - Optimal Control Problem over Networks.Part III - Applications of Geometric Control Theory.Chapter 15 - Motion Planning for Mobile Robots.Chapter 16 - Robot Manipulation Tasks via Task Space Formulation.Chapter 17 - Visual Servoing Based on Image Feature Extraction.Chapter 18 - Model Predictive Control for Industrial Processes."
    },
    {
        "original_text": "We report on the observation of sporadic meteors with Suprime-Cam attached to Subaru Telescope in August, 2004. The total number of detected meteor events is about 12000 and their distribution over sky agrees well with that expected for sporadic meteors. We also found some interesting features such as clustering around bright stars (probably due to fragmentation) and an excess of faint meteors near the ecliptic plane. These results will be useful for understanding the physical processes involved in the formation of meteoroid streams. \n \n Keywords: Meteor shower, Suprime-Cam, Subaru telescope, Spacecraft debris \n \n \n \n Received September 30, 2005 Accepted December 16, 2005 Published January 31, 2006 Online publication date: February 3, 2006 \n \n We have observed sporadic meteors using Suprime-Cam mounted at the Cassegrain focus of the 8-meter Subaru Telescope in August 2004 when the Perseid meteor shower was active. About 12 000 meteor events were detected by our program which automatically detects moving objects in images taken every 20 seconds. Their spatial distribution shows good agreement with that predicted theoretically for sporadic meteors based on orbital elements obtained from radar observations. Some interesting features are also seen; e.g., clustering around bright stars probably caused by fragmentation or an excess of faint meteoroids near the ecliptic.",
        "watermark_text": "We report on the observation of sporadic meteors with Suprime - Cam attached to Subaru Telescope in August, 04.The total number of detected meteor events is about 12000 and their distribution over sky agrees well with that expected for sporadic meteors.We also discovered some interesting features such as clustering around bright stars ( likely due to fragmentation ) and an excess of faint meteors near the ecliptic plane.These results will be useful for understanding the physical processes involved in the formation of meteoroid streams.Keywords : Meteor shower, Suprime - Cam, Subaru telescope, Spacecraft debris Received September 30, 2005 Accepted December 16, 2005 Published January 31, 2006 Online publication date : February 3, 2006 We have observed sporadic meteors using Suprime - Cam mounted at the Cassegrain focus of the 8 - meter Subaru Telescope in August 2004 when the Perseid meteor shower was active.About 12 000 meteor events were detected by our program which automatically detects moving objects in pictures taken every 20 seconds.Their spatial distribution shows good agreement with that predicted theoretically for sporadic meteors based on orbital elements obtained from radar observations.Some interesting features are also seen ; e. g., clustering around bright stars likely caused by fragmentation or an excess of faintly meteoroids near the ecliptic."
    },
    {
        "original_text": "In this work, we present the design and analysis of space-time block codes (STBC) based on extended clifford algebras. The proposed STBC is constructed by using an orthogonal basis for the underlying algebra. We show that our code has full diversity order with respect to quasi-static Rayleigh fading channels. Furthermore, it achieves maximum coding gain over all other known algebraic STBCs in terms of minimum determinant criterion. Finally, we provide simulation results which demonstrate the performance gains achieved by the proposed scheme compared to existing schemes. Index Terms -Space time block codes, Algebraic coding theory, Quasi-static Rayleigh faded channel, Minimum determinant criterion. I. INTRODUCTIO N Space Time Block Codes (STBC), introduced by Alamouti [1] , are widely used in wireless communications due to their simple structure and high data rate [2] . In recent years there have been many efforts devoted towards designing new classes of STBCs [3] - [8] .\nThe main goal behind these designs was to achieve higher spectral efficiency while maintaining good error performances under different transmission conditions such as multipath propagation or frequency selective fading [9] . However, most of the existing works focus only on achieving better error performances without considering the effect of hardware limitations [10] . This motivates us to develop a class of STBCs which can be implemented efficiently at low complexity [11] .\nRecently, several authors [12] - [14] have shown that some well-known families of finite fields like Galois field GF(q) [15] , Finite Ring [16] , Quaternion [17] etc., can also be represented by certain types of non-commutative rings called Clifford algebras [18] . These representations allow one to construct various signal constellations [19] , modulation techniques [20] , and communication systems [21] . Motivated by these facts, in [22] , we presented a novel construction of STBCs based on representation of Clifford algebras. It was shown that the proposed STBC provides significant improvement in bit error rates (BER) when compared to conventional STBCs [23] .",
        "watermark_text": "In this work, we present the design and analysis of space - time block codes ( STBC ) based on extended clifford algebras.The proposed STBC is constructed by using an orthogonal base for the underlying algebra.We show that our code has full diversity order with respect to quasi - static Rayleigh fading channels.Furthermore, it achieves maximum coding gain over all other known algebraic STBCs in terms of minimum determinant criterion.Finally, we offer simulation results which demonstrate the performance gains achieved by the proposed system compared to current schemes.Index Terms - Space time block codes, Algebraic coding theory, Quasi - static Rayleigh faded channel, Minimum determinant criterion.I. INTRODUCTIO N Space Time Block Codes ( STBC ), introduced by Alamouti[ 1 ], are widely used in wireless communications due to their simple structure and highly data rate [ 2 ].In recent years there have been numerous efforts devoted towards designing fresh classes of STBCs [ 3 ] - [ 8 ].The main goal behind these designs was to achieve higher spectral efficiency while maintaining excellent error performances under different transmission conditions such as multipath propagation or frequency selective fading [ 9 ].However, most of the existing works concentrate only on achieving improving error performances unless considering the affect of hardware limitations [ 10 ].This motivates us to develop a class of STBCs which can be implemented efficiently at low complexity [ 11 ].Recently, several authors [ 12 ] - [ 14 ] have shown that some well - known families of infinite fields like Galois field GF ( q )[ 15 ], Finite Ring[ 16 ], Quaternion[ 17 ] etc., can also be represented by certain types of non - commutative rings called Clifford algebras[ 18 ].These representations allow one to construct various signal constellations [ 19 ], modulation techniques [ 20 ], and communication systems[ 21 ].Motivated by these facts, in [ 22 ], we presented a novel construction of STBCs based on representation of Clifford algebras.It was shown that the proposed STBC provides significant improvement in bit error rates ( BER ) when compared to traditional STBCs [ 23 ]."
    },
    {
        "original_text": "We present new observations of the distant galaxy cluster RX J1117.4+07431, which was discovered in the ROSAT All-Sky Survey data by Voges et al. (1999) . The cluster is located at redshift z = 0.485 ± 0.001 with an estimated mass M500 = 1.7 × 1013 h-1M⊙ within r500 = 2.1h-1Mpc . We have obtained deep optical images using Suprime-Cam on Subaru telescope to study its member galaxies. In addition we observed this cluster with Chandra ACIS-I for about 50 ks. Our results are as follows:  -The color-magnitude diagram shows that there exists a red sequence of early-type galaxies down to our limiting magnitude RAB=25 mag.  -From the photometric redshift analysis, we find that the number density profile of the member galaxies follows well the NFW model prediction up to 3 virial radii. -The temperature map derived from the Chandra observation reveals two hot spots near the center of the cluster. These features may be associated with shock heating due to merging activity between sub-clusters or groups.",
        "watermark_text": "We present new observations of the distant galaxy cluster RX J1117. 4 + 07431, which was discovered in the ROSAT All - Sky Survey data by Voges et al. ( 1999 ).The cluster is located at redshift z = 0. 485 ± 0. 001 with an estimated mass M500 = 1. 7 × 1013 h - [UNK] within r500 = 2. 1h - 1Mpc.We have obtained deep optical pictures using Suprime - Cam on Subaru telescope to study its membership galaxies.In addition we observed this cluster with Chandra ACIS - I for about 50 ks.Our results are as follows : - The color - magnitude diagram shows that there exists a red series of early - type galaxies down to our limiting magnitude RAB = 25 mag.- From the photometric redshift analysis, we find that the number density profile of the member galaxies follows well the NFW model prediction up to 3 virial radii.- The temperature map derived from the Chandra observation reveals 2 hot spots near the center of the cluster.These features may be associated with shock heating due to merging action between sub - clusters or groups."
    },
    {
        "original_text": "The fitting problem is one of the most important problems in cosmology, which has been studied for more than 50 years.  The main goal of this work was to study the effect of different types of initial conditions on the evolution of density perturbations in an expanding universe with a positive cosmological constant (dark energy).  We have used two methods to solve numerically the Einstein equations coupled to the matter fields:  the standard method based on the expansion of the metric tensor into spherical harmonics; and the new method developed by us that uses the expansion of the metric into Chebyshev polynomials.  In both cases we have considered three types of initial conditions: Gaussian random fields generated using the Zel'dovich approximation, Gaussian random fields generated using a fast Fourier transform algorithm, and white noise.  Our results show that all these models give similar predictions at late times when they are evolved up to z = 0.5.  However, there are some differences between them at early times.  These differences can be explained as follows:  the Zel'dovich model predicts larger fluctuations compared to other models because it does not take into account the pressure term in the fluid equation; the white noise model gives smaller fluctuations due to its statistical properties; finally, the Gaussian random fields obtained via the fast Fourier transform algorithm predict intermediate values.  This result shows that the choice of the initial conditions may affect significantly the final value of the power spectrum of primordial density fluctuations predicted by inflationary theories.",
        "watermark_text": "The fitting problem is one of the most important problems in cosmology, which has been studied for more than 50 years.The main goal of this work was to study the effect of different types of early conditions on the evolution of density perturbations in an expanding universe with a positive cosmological constant ( dark energetic ).We have used 2 methods to solve numerically the Einstein equations coupled to the matter fields : the standard method based on the expansion of the metric tensor into spherical harmonics ; and the new method developed by us that uses the expansion of the metric into Chebyshev polynomials.In both cases we have regarded three types of initial conditions : Gaussian random fields generated using the Zel ' dovich approximation, Gaussian random fields generated utilizing a fast Fourier transform algorithm, and white noise.Our results show that all these models give similar predictions at late times when they are evolved up to z = 0. 05.However, there are some differences between them at early times.These differences can be explained as follows : the Zel ' dovich model predicts larger fluctuations compared to other models because it does not take into account the pressure term in the flow equation ; the white noise model gives smaller fluctuations due to its statistical properties ; finally, the Gaussian random fields obtained via the fast Fourier transform algorithm predict intermediate values.This result shows that the choice of the initial conditions may affect significantly the final value of the power spectrum of primordial dense fluctuations predicted by inflationary theories."
    },
    {
        "original_text": "The authors have studied the growth rate and its fluctuations for different types of human cancer cells grown under controlled conditions, using an automated image analysis system to measure their size over time.  The results show that there is considerable variation between individual clones within each type of cell line as well as between different types of cell lines. This suggests that it may be possible to use this information to classify tumours into subtypes with distinct biological properties. In addition, they find evidence that the growth rates are correlated across generations of daughter cells, which could provide insight into how these correlations arise during tumorigenesis. Finally, by comparing the growth characteristics of normal and transformed cells, they conclude that transformation leads to increased heterogeneity among daughter cells. Cancer is characterized by uncontrolled proliferation of abnormal cells. Understanding the mechanisms underlying this process can help us develop new treatments against cancer. However, studying the dynamics of cancerous cell populations has been challenging because of difficulties associated with tracking large numbers of single cells simultaneously. Here we report our recent work on characterizing the growth behavior of thousands of individual cancer cells growing in culture dishes [1] . We used an automated imaging system to track the sizes of hundreds of thousands of cells belonging to several different types of human cancer cell lines ( Figure 1 ). Our results reveal significant differences in both average growth rates and growth fluctuations between different types of cell lines: some grow faster than others while also exhibiting larger fluctuations around their mean values [2] .\nWe found that the growth rates were highly variable even when measured at the level of individual clones derived from a common parent population [3] , suggesting that the observed phenotypic diversity might reflect genetic or epigenetic variations present in the original parental population [4] .  These findings suggest that it should be possible to use such measurements to classify tumors into subtypes based on their growth characteristics [5] .",
        "watermark_text": "The authors have studied the growth rate and its fluctuations for different kinds of human cancer cells grown under controlled conditions, using an automated image analytical system to monitor their size over time.The results show that there is considerable variation between single clones inside each type of cell line as also as between different kinds of cell lines.This suggests that it may be possible to use this information to classify tumours into subtypes with distinct biological properties.In addition, they discover evidence that the growth rates are correlated across generations of daughter cells, which could provide insight into how these correlations arise during tumorigenesis.Finally, by comparing the growth characteristics of normal and transformed cells, they conclude that transformation leads to raised heterogeneity among daughter lines.Cancer is characterized by uncontrolled proliferation of abnormal cells.Understanding the mechanisms underlying this process can help us develop new treatments against cancer.However, studying the dynamics of cancerous cell communities has been challenging because of difficulties involved with tracing large numbers of individual cells simultaneously.Here we report our recent work on characterizing the growing behavior of thousands of individual cancer cells growing in culture dishes [ 1 ].We used an automatic imaging system to track the sizes of hundreds of thousands of cells belonging to several different kinds of human cancer cell lines ( Figure 1 ).Our results reveal significant differences in both average growth rates and growth fluctuations between different types of cell lines : some grow faster than others while also exhibiting larger fluctuations surrounding their mean values [ 2 ].We found that the growth rates were highly variable even when measured at the scale of individual clones derived from a common parent population[ 3 ], suggesting that the observed phenotypic diversity might reflect genetic or epigenetic variations present in the original parental population[ 4 ].These findings suggest that it should be possible to use such measurements to classify tumors into subtypes based on their growth characteristics [ 5 ]."
    },
    {
        "original_text": "We study the weighted complexity function W(G) for graphs G with n vertices, which is defined as the minimum number of edges in any n-vertex subgraph H such that H contains all cycles of length at most k (k = 3, ...,n). We prove upper bounds on this function by using the concept of the determinant of an adjacency matrix A associated to G. In particular we show that if A has no zero rows or columns then W(G) <= 2n-1. This bound can be improved when A satisfies some additional conditions. Finally, we give examples showing how our results are sharp. The weighted complexity function W(G;k) (k=3,...,n), introduced by Chartrand et al., measures the minimum number of edges needed to make every cycle of length up to k in a given graph G. It was shown recently that W(G;3)=n-2 for any connected triangle-free planar graph G. In this note we improve these results by proving that W(G;3))<=n-1 for any connected triangle-free plane graph G.",
        "watermark_text": "We study the weighted complexity function W ( G ) for graphs G with n vertices, which is defined as the minimum number of edges in any n - vertex subgraph H such that H contains all cycles of length at most k ( k = 3,., n ).We prove upper bounds on this function by using the concept of the determinant of an adjacency matrix A associated to G. In particular we show that if A has no 0 rows or columns then W ( G ) < = 2n - 1.This bound can be improved when A satisfies some additional conditions.Finally, we give examples showing how our outcomes are sharp.The weighted complexity function W ( G ; k )( k = 3,., n ), introduced by Chartrand et al., measures the minimum number of edges needed to manufacture every cycle of length up to k in a given graph G. It was shown recently that W ( G ; 3 ) = n - 2 for any connected triangle - free planar graph G.In this note we improve these results by proving that W ( G ; 3 ) ) < = n - 1 for any connected triangle - free plane graph G."
    },
    {
        "original_text": "In this work, we investigate the trade-offs among processing gains and timing jitters for impulse radio ultra-wideband (IR-UWB) systems with different pulse shapes. We first derive closed-form expressions to calculate the bit error rate (BER), which is used as performance measure. Then, by using these results, we analyze how the BER changes according to various system parameters such as signal-to-noise ratio (SNR), number of pulses per symbol, and timing jitter variance. Finally, numerical examples are provided to verify our analysis. The main contributions of this study can be summarized as:  1 . Derivation of closed-form expression for calculating the BER.  2 . Analysis on the effect of timing jitter on IR-UWB systems.  3 . Numerical verification of analytical results. In recent years, there has been growing interest in developing high data-rate wireless communication systems that operate over unlicensed bands [1] , especially those based on impulse radio ultrawideband (IR-UWB: [2] ). Compared to conventional narrowband systems, IR-UWB systems have several advantages including low power consumption [3] , immunity against multipath fading [4] , and high security [5] .\nHowever, one major drawback of IR-UWB systems is their vulnerability to timing jitter [6] - [8] . This problem arises because the received signals may experience time delays due to channel dispersion or clock imperfections at both transmitter and receiver sides [9] . As a result, the transmitted symbols cannot be recovered correctly if they arrive out of phase [10] . Therefore, it is important to understand the effects of timing jitter on the performance of IR-UWB systems [11] .\nTo address this issue, many studies have investigated the impact of timing jitter on various aspects of IR-UWB systems [12]- [16] . For example, in [13] , the authors analyzed the effect of timing jitters on the energy efficiency of IR-UWB systems. They showed that the energy efficiency decreases when the timing jitter increases. Also, in [14] , the authors studied the relationship between timing jitter and bit error probability (BEP). However, most existing works only",
        "watermark_text": "In this work, we investigate the trade - offs amongst processing gains and timing jitters for impulse radio ultra - wideband ( IR - UWB ) systems with different pulse shapes.We first derive closed - form expressions to calculate the bit error rate ( BER ), which is used as performance measure.Then, by using these results, we analyze how the BER changes according to different system parameters such as signal - to - noisy ratio ( SNR ), number of pulses per symbol, and timing jitter variance.Finally, numerical examples are provided to confirm our analysis.The main contributions of this study can be summarized as : 1.Derivation of closed - form expression for calculating the BER.2.Analysis on the effect of timing jitter on IR - UWB systems.3.Numerical verification of analytical results.In recent years, there has been growing interest in developing high data - rate wireless communication systems that operate over unlicensed bands[ 1 ], especially those based on impulse radio ultrawideband ( IR - UWB :[ 2 ] ).Compared to conventional narrowband systems, IR - UWB systems have several advantages including low power consumption [ 3 ], immunity against multipath fading [ four ], and high security [ 5 ].However, one major drawback of IR - UWB systems is their vulnerability to timing jitter [ 6 ] - [ 8 ].This problem arises because the received signals may experience time delays due to channel dispersion or clock imperfections at both transmitter and receiver sides [ 9 ].As a result, the transmitted symbols cannot be retrieved correctly if they arrive out of phase [ 10 ].Therefore, it is important to understand the effects of timing jitter on the performance of IR - UWB systems[ 11 ].To address this issue, numerous studies have investigated the effect of timing jitter on different aspects of IR - UWB systems[ 12 ] - [ 16 ].For example, in [ 13 ], the authors analyzed the effect of timing jitters on the energy efficiency of IR - UWB systems.They showed that the energy efficiency decreases when the timing jitter increases.Also, in [ 14 ], the authors studied the relationship between timing jitter and bit error likelihood ( BEP ).However, most existing works only"
    },
    {
        "original_text": "The electromagnetic properties of high-temperature superconductors are studied in terms of two different theoretical approaches, namely the slave-boson theory (SBT) and the doped carrier theory (DCT). The SBT is based on an effective low-energy description of strongly correlated electrons by means of auxiliary bosonic degrees of freedom which represent collective charge excitations. In this approach we calculate the optical conductivity as well as the Hall coefficient for various values of doping concentration n. We find that both quantities exhibit nontrivial temperature dependence at low temperatures T . On the other hand, within DCT these physical observables can be calculated analytically using simple expressions valid only at zero temperature. Our results show that there exists significant quantitative difference between predictions made by these two models. This discrepancy may serve to discriminate between them experimentally. High-temperature superconductivity has been one of the most challenging problems in condensed matter physics over past decades [1] . Despite enormous experimental efforts [2] , its microscopic origin remains unknown. A number of competing theoretical scenarios have been proposed [3] but none of them could provide a complete explanation of all available data [4] .\nIn particular, it was suggested [5] that the mechanism responsible for high-temperature superconductivity might involve strong electron correlations [6] . These effects cannot be described within conventional Fermi-liquid theory [7, 8] because they lead to non-Fermi liquid behavior [9] such as power-law dependences of thermodynamic functions [10] or unusual transport phenomena [11] . To account for these features theoretically, several phenomenological models were developed [12] including the so-called slave-boson theory [13] . It describes the dynamics of strongly interacting fermions with spin S = 1/2 coupled to an additional set of bosonic fields representing collective charge fluctuations [14] . Within this framework, the ground state of the system corresponds to a Bose-Einstein condensation [15] of the bosons [16] . As a result, the fermionic quasiparticles acquire finite masses [17] leading to their disappearance above some critical temperature [18] .",
        "watermark_text": "The electromagnetic properties of high - temperature superconductors are studied in terms of 2 different theoretical approaches, namely the slave - boson theory ( SBT ) and the doped carrier theoretical ( DCT ).The SBT is based on an effective low - energy description of strongly correlated electrons by means of auxiliary bosonic degrees of freedom which represent collective charge excitations.In this approach we calculate the optical conductivity as also as the Hal coefficient for various values of doping concentrationn.We find that both amounts exhibit nontrivial temperature dependence at low heat T.On the other hand, within DCT these physical observables can be calculated analytically utilizing simple expressions valid only at 0 temperature.Our results show that there exists significant quantitative differential between predictions made by these two models.This discrepancy may serve to discriminate between them experimentally.High - temperature superconductivity has been one of the most challenging problems in condensed material physics over past decades [ 1 ].Despite enormous experimental efforts [ 2 ], its microscopic origin remains unknown.A number of competing theory scenarios have been proposed [ 3 ] but none of them would provide a complete explanation of all available data [ 4 ].In particular, it was suggested [ 5 ] that the mechanism responsible for high - heat superconductivity might involve strong electron correlations[ 6 ].These effects cannot be described within traditional Fermi - liquid theory [ 7, 8 ] because they lead to non - Fermi liquid behavior [ 9 ] such as power - law dependences of thermodynamic functions [ 10 ] or unusual transport phenomena[ 11 ].To account for these features theoretically, several phenomenological models were developed [ 12 ] including the so - voted slave - boson theory [ 13 ].It describes the dynamics of strong interacting fermions with spin S = 1 / two coupled to an additional set of bosonic fields representing collective charge fluctuations [ 14 ].Within this framework, the ground state of the system corresponds to a Bose - Einstein condensation [ 15 ] of the bosons[ 16 ].As a result, the fermionic quasiparticles acquire finite masses[ 17 ] leading to their disappearance above some critical temperature [ 18 ]."
    },
    {
        "original_text": "We present an analysis of galaxy morphologies, luminosities and environments for galaxies in the Abell 901;902 supercluster (z = 0.18) using data obtained with the Wide Field Imager on board the European Southern Observatory's Very Large Telescope. We find that the fraction of early-type galaxies increases strongly towards higher local densities within this supercluster. The morphological mix is also found to depend significantly on absolute magnitude; fainter galaxies are more likely to be late-types than brighter ones at fixed density. These results suggest that both environmental effects and internal processes play important roles in shaping the observed morphology-density relation. This work was supported by NASA grant NAG5-7697. -The distribution of all galaxies in our sample overlaid onto the X-ray emission detected by Chandra . Galaxies are colour-coded according to their spectroscopic redshifts as indicated in the legend.  -The projected number density profile of cluster members around Abell 902 , determined from the photometric redshift catalogue .  -The projected number density profiles of different morphological types around Abell 902 .   -The projected number density of brightest cluster galaxies ( M V < −20 ) around Abell 902 .\n-Figures showing the dependence of galaxy properties on distance from Abell 902 .",
        "watermark_text": "We present an analysis of galaxy morphologies, luminosities and environments for galaxies in the Abell 901 ; 902 supercluster ( z = 0. 18 ) utilizing data obtained with the Wide Field Imager on board the European Southern Observatory ' s Very Large Telescope.We find that the fraction of early - type galaxies increases strongly towards upper local densities inside this supercluster.The morphological mix is also found to depend significantly on absolute magnitude ; fainter galaxies are more likely to be late - types than brighter ones at fixed density.These results suggest that both environmental effects and internal processes play important roles in framing the observed morphology - density relation.This work was supported by NASA grant NAG5 - 7697.- The distribution of all galaxies in our sample overlaid onto the X - ray emission detected by Chandra.Galaxies are colour - coded according to their spectroscopic redshifts as indicated in the legend.- The projected numerical density profile of cluster members around Abell 902, determined from the photometric redshift catalogue.- The projected number density profiles of different morphological types around Abell 902.- The projected number density of brightest cluster galaxies ( M V < −20 ) around Abell 902.- Figures showing the dependence of galaxy properties on distance from Abell 902."
    },
    {
        "original_text": "We present new near-infrared photometry for the open cluster Westerlund 1, which is located in the Galactic bulge at a distance of 8 kpc (projected). We find that the red giant branch tip lies at K = 12.6 mag, corresponding to an age of about 10 Gyrs. The main sequence turn-off point occurs around K = 14.5 mag, indicating an age between 5 and 7 Gyrs. This places it among the oldest open clusters known. Using our data we derive a mean metallicity [Fe/H] = -1.3 ± 0.1 dex. From this value and using theoretical models we estimate the mass of the most massive star in the cluster as Mmax = 120 - 140M⊙. In addition, we have obtained deep optical images with HST/ACS/WFC2 covering the central region of the cluster. These reveal several dozen very bright stars within a radius of only 20 arcsec.",
        "watermark_text": "We present newly near - infrared photometry for the open cluster Westerlund 1, which is located in the Galactic bulge at a distance of 8 kpc ( projected ).We find that the red giant branch tip lies at K = 12. 6 mag, corresponding to an era of about 10 Gyrs.The main sequence turn - off point occurs around K = 14. 5 mag, indicating an age between five and 7 Gyrs.This places it among the oldest open clusters known.Using our data we derive a mean metallicity [ Fe / H ] = - 1. 3 ± 0. 1 dex.From this value and using theoretical models we estimate the mass of the most massive star in the cluster as Mmax = 120 - [UNK].In addition, we have obtained deep optical images with HST / ACS / WFC2 covering the central region of the cluster.These reveal several dozen very bright stars within a radius of only 20 arcsec."
    },
    {
        "original_text": "We present the set of equations describing the process of transient enhanced diffusion (TED) in shallow implanted layers, which is important to understand and control dopant profiles during semiconductor device fabrication.  The model takes into account both the effects of lattice damage on TED as well as the effect of interstitials generated by the implantation itself. We show that this simple model can explain many experimental observations including the dependence of TED on dose rate, annealing temperature, and annealing time. Finally we use our model to predict the evolution of the dopant profile under different annealing conditions. Transient enhanced diffusion (TED), i.e., the redistribution of dopants after high energy implantation followed by rapid thermal annealing (RTA), has been studied extensively over the past two decades [1] . It is now widely accepted that the main driving force behind TED are point defects created by the implantation [2] , although other mechanisms such as vacancy clustering may also play an important role [3] .\nThe most commonly used models for simulating TED assume that all excess interstitials produced by the implantation are immobile at room temperature [4] . However, recent experiments have shown that some fraction of these interstitials become mobile even before RTA [5] . This mobility leads to additional dopant redistribution [6] . In addition, it was recently found that the amount of interstitials released depends strongly on the implantation dose rate [7, 8] . These results suggest that the current models do not fully capture the physics underlying TED.",
        "watermark_text": "We present the set of equations describing the process of transient enhanced diffusion ( TED ) in shallow implanted layers, which is important to understand and control dopant profiles during semiconductor device fabrication.The model takes into account both the effects of lattice damage on TED as well as the effect of interstitials generated by the implantation itself.We show that this simple model can explain many experiments observations including the dependence of TED on dose rate, annealing temperature, and annealing time.Finally we use our model to predict the evolution of the dopant profile under different annealing conditions.Transient enhanced diffusion ( TED ), i. e., the redistribution of dopants after high energy implantation followed by rapid thermal annealing ( RTA ), has been studied extensively over the past two decades [ 1 ].It is now widely accepted that the major driving factor behind TED are point defects created by the implantation [ 2 ], though other mechanisms such as vacancy clustering may also play an important role [ 3 ].The most commonly utilized models for simulating TED assume that all excess interstitials produced by the implantation are immobile at room temperature[ 4 ].However, recent experiments have shown that some fraction of these interstitials become mobile even before RTA [ 5 ].This mobility leads to additional dopant redistribution [ 6 ].In addition, it was recently found that the amount of interstitials released depends strongly on the implantation dose rate[ 7, 8 ].These results suggest that the existing models do not fully capture the physics underlying TED."
    },
    {
        "original_text": "We present the first calculation of quark-quark scattering at next-to-leading order (NLO) accuracy within the framework of multiple parton scattering (MPI). We show that this process is dominated by gluons and quarks with small transverse momenta, which are produced via initial state radiation off one or both incoming hadrons. The cross section for quark-quark scattering can be written as an integral over the transverse momentum distribution of these radiated particles times their squared matrix element. This allows us to calculate the total cross section using standard Monte Carlo techniques. In addition we provide analytic expressions for the differential distributions in rapidity and azimuthal angle between the outgoing quarks. Our results agree well with those obtained numerically. Finally, we discuss how our formalism could be used to study MPI effects on jet production in proton-nucleus collisions. PACS numbers: 12.38.Qk, 13 .60.Le",
        "watermark_text": "We present the initial calculation of quark - quark scattering at next - to - leading order ( NLO ) accuracy within the framework of multi parton scattering ( MPI ).We show that this process is dominated by gluons and quarks with small transverse momenta, which are produced via early state radiation off one or both incoming hadrons.The cross section for quark - quark scattering can be written as an integral over the transverse moment distribution of these radiated particles times their squared matrix element.This allows us to calculate the total cross section utilizing standard Monte Carlo techniques.In addition we offer analytic expressions for the differential distributions in rapidity and azimuthal angle between the outgoing quarks.Our results agree well with those attained numerically.Finally, we discuss how our formalism could be used to study MPI effects on jet production in proton - nucleus collisions.PACS numbers : 12. 38. Qk, 13. 60. Le"
    },
    {
        "original_text": "We report on the temporal evolution of step fluctuations under electromigration conditions in Cu(111) and Ag(111). The experiments were performed by scanning tunneling microscopy (STM), which allows for direct observation of atomic-scale processes at surfaces. We find that, during current-induced mass transport along steps, the step edges fluctuate strongly with time. These fluctuations are characterized by an exponential growth followed by saturation after about 1 hour. In addition to this general behavior we observe different types of fluctuations depending on the applied voltage and temperature. For low voltages and temperatures below 300 K, the fluctuations show a sawtooth-like shape indicating periodic changes between two states. At higher voltages or temperatures above 400 K, the fluctuations become more irregular but still exhibit some periodicity. Finally, at high voltages and temperatures around 500 K, no regular pattern is observed anymore. Our results suggest that these fluctuations can be explained as a result of competition between diffusion and drift currents.",
        "watermark_text": "We report on the temporal evolution of step fluctuations under electromigration conditions in Cu ( 111 ) and Ag ( 111 ).The experiments were performed by scanning tunneling microscopy ( STM ), which allows for direct observation of atomic - scale processes at surfaces.We find that, during current - induced mass transport along steps, the step edges fluctuate strongly with time.These fluctuations are characterized by an exponential growth followed by saturation after about one hour.In addition to this general behavior we observe various types of fluctuations depending on the applied voltage and temperature.For low voltages and temperatures below 300 K, the fluctuations show a sawtooth - like shape indicating periodic changes between two states.At higher voltages or temperatures above 400 K, the fluctuations become more irregular but still exhibit some periodicity.Finally, at high voltages and temperatures around 500 K, no regular pattern is observed anymore.Our results suggest that these fluctuations can be explained as a result of competition between diffusion and drift currents."
    },
    {
        "original_text": "We present the results of an infrared survey of the Galactic plane using Spitzer/InfraRed Array Camera (IRAC) data in four mid-infrared bands centered at 3.6, 4.5, 5.8, and 8 microns. The IRAC observations cover about one third of the entire sky with |b| < 1 degree. We have identified more than 100 thousand candidate young stellar objects (YSOs), including both Class 0/I YSOs and Classical T Tauri stars (CTTSs). About half of these are associated with previously known star-forming regions or open clusters. Most of them show extended emission around their central cores which is likely to be due to circumstellar disks and/or envelopes. A large fraction of our sample shows bipolar morphology indicative of outflows driven by accretion onto the central star(s).\nThe spatial distribution of the newly discovered YSO candidates suggests that most of the recent massive star formation has occurred within the last few million years along the spiral arms of the Galaxy.",
        "watermark_text": "We present the results of an infrared survey of the Galactic plane using Spitzer / InfraRed Array Camera ( IRAC ) data in 4 mid - infrared bands centered at 3. 6, 4. 5, 5. 8, and 8 microns.The IRAC observations cover about one third of the entire sky with | b | < 1 degree.We have detected more than 100 thousand candidate young stellar objects ( YSOs ), including both Class 0 / I YSOs and Classical T Tauri stars ( CTTSs ).About half of these are associated with previously known star - forming regions or open clusters.Most of them show extended emission around their central cores which is likely to be owing to circumstellar disks and / or envelopes.A large fraction of our specimen shows bipolar morphology indicative of outflows driven by accretion onto the central star ( s ).The spatial distribution of the newly discovered YSO candidates suggests that most of the recent massive star formation has occurred within the last few million years along the spiral arms of the Galaxy."
    },
    {
        "original_text": "We present high spatial and spectral resolution observations of two IM stars, HD 163296 and MWC 480, obtained with the Submillimeter Array at 1.3 mm wavelength. We detect several compact sources in both objects that are associated with dusty disks or envelopes surrounding these young stellar objects. The disk masses derived for these systems range between 0.1 to 0.5 Msun. In addition we find evidence for an extended component in the vicinity of HD 163296 which may be related to its outflow activity. These results demonstrate that even massive protoplanetary disks can form planets like our own solar system. Keywords: Circumstellar matter - Stars: Herbig Ae/Be - Massive star formation - Planet formation - Protostars - Young stellar objects: General - Millimeter waves - Submillimeter waves - Nearby galaxies - Radio astronomy - High energy astrophysics",
        "watermark_text": "We present high spatial and spectrum resolution observations of two IM stars, HD 163296 and MWC 480, obtained with the Submillimeter Array at 1. 3 mm wavelength.We detect several compact sources in both objects that are associated with dust disks or envelopes around these young stellar objects.The disk masses derived for these systems range between 0. 1 to 0. 5 Msun.In addition we find evidence for an extended component in the vicinity of HD 163296 which may be related to its outflow activity.These results demonstrate that even massive protoplanetary discs can form worlds like our own solar system.Keywords : Circumstellar matter - Stars : Herbig Ae / Be - Massive star formation - Planet formation - Protostars - Young stellar objects : General - Millimeter waves - Submillimeter waves - Nearby galaxies - Radio astronomy - High energy astrophysics"
    },
    {
        "original_text": "The dielectric properties, phase transition behavior, and microstructure evolution were investigated for the (0.65[Pb(Ni-1/3Nb-2/3)O_3] -0.35PbTiO3) (PNT) ceramics with different sintering temperatures ranging from 850 to 1100 °C. The PNT samples exhibited high permittivity values up to ~10 4 , low loss tangent below 10 -2 , and large tunability over 30% under an electric field strength of 30 kV/cm at room temperature. With decreasing temperature down to 77 K, the permittivity increased slightly while the loss tangent decreased significantly due to the freezing out of mobile ions. At cryogenic temperatures, two relaxation processes were observed in the frequency range between 1 Hz and 100 kHz. The first process was attributed to the grain boundary effect; it shifted towards higher frequencies as the temperature decreased. The second process was associated with ferroelectric domain wall motion; its relaxation time constant remained almost unchanged when the temperature changed.",
        "watermark_text": "The dielectric properties, phase transition behavior, and microstructure evolution were investigated for the ( 0. 65 [ Pb ( Ni - 1 / 3Nb - 2 / 3 ) O _ three ] - 0. 35PbTiO3 ) ( PNT ) ceramics with different sintering temperatures ranging from 850 to 1100 °C.The PNT samples exhibited high permittivity values up to ~ 10 4, low lost tangent below ten - 2, and large tunability over 30 % under an electric field strength of 30 kV / cm at room temperature.With decreasing temperature down to 77 K, the permittivity increased somewhat while the loss tangent decreased significantly due to the freezing out of mobile ions.At cryogenic temperatures, two relaxation processes were observed in the frequency range between 1 Hz and 100 kHz.The first process was attributed to the grain boundary effect ; it shifted towards higher frequencies as the temperature decreased.The second process was associated with ferroelectric domain wall motion ; its relaxation time constant remained almost unchanged when the warming changed."
    },
    {
        "original_text": "The performance evaluation of object-oriented databases (OODBs) is an important issue in database research and development, but it has been difficult because there are many factors that affect their performances. In this study we propose VOODB as a generic discrete-event random simulation model for evaluating the performances of OODBs. The proposed model can be used with any OODB system by simply changing its configuration parameters. We have implemented our model using Visual Basic 6.0 on Windows NT 4.0 platform. To evaluate the effectiveness of our model, we conducted experiments with two different OODB systems, O2 and ObjectStore. Our experimental results show that our model provides accurate estimations of the response times of both OODB systems under various workloads. Keywords: Performance Evaluation, Database System, Object-Oriented Database Systems, Discrete Event Simulations, Response Time Prediction. 1 Introduction Object-oriented databases (OODBSs), which provide powerful data modeling capabilities such as inheritance, encapsulation, polymorphism, etc., have become increasingly popular recently [l] . However, since they support complex data structures and operations, their performances may vary widely depending upon several factors [2] .\nIn order to develop high-performance OODBSs, it is necessary to analyze how these factors influence their performances. Therefore, researchers have studied the performance evaluations of OODBSs extensively [3] ,[4],[5],[6],[7],[8],[9],[lo],[11],[12],[13],[14],[15],[16], [17] ,[18],[19], [20] ,[21], [22] ,[23], [24] ,[25], [26] ,[27], [28] ,[29], [30] ,[31], [32] ,[33], [34] ,[35], [36] , [37J, [38] , [39J, [40] , [411, [42] , [43J, [44] , [45J, [46] , [47J, [48] , [49J, [50] , [51J, [52J, [53J, [54J, [55J, [56J,",
        "watermark_text": "The performance evaluation of object - oriented databases ( OODBs ) is an important issue in database research and development, but it has been difficult because there are many factors that affect their performances.In this study we suggest VOODB as a generic discrete - event random simulation model for assessing the performances of OODBs.The proposed model can be used with any OODB system by simply changing its configuration parameters.We have enacted our model utilizing Visual Basic 6. 0 on Windows NT 4. 0 platform.To evaluate the effectiveness of our model, we performed experiments with two different OODB systems, O2 and ObjectStore.Our experimental results show that our model gives accurate estimations of the response periods of both OODB systems under several workloads.Keywords : Performance Evaluation, Database System, Object - Oriented Database Systems, Discrete Event Simulations, Response Time Prediction.1 Introduction Object - oriented databases ( OODBSs ), which provide powerful data modeling capabilities such as inheritance, encapsulation, polymorphism, etc., have become increasingly popular recently [ l ].However, since they support complicated data systems and operations, their performances may vary widely depending upon several factors [ 2 ].In order to develop high - performance OODBSs, it is necessary to analyze how these factors influence their performances.Therefore, researchers have studied the performance evaluations of OODBSs extensively [ 3 ], [ 4 ], [ 5 ], [ six ], [ 7 ], [ 8 ], [ 9 ], [ lo ], [ eleven ], [ twelve ], [ 13 ], [ 14 ], [ 15 ], [ 16 ], [ 17 ], [ 18 ], [ 19 ], [ 20 ], [ 21 ], [ 22 ], [ 23 ], [ 24 ], [ 25 ], [ 26 ], [ 27 ], [ 28 ], [ 29 ], [ 30 ], [ 31 ], [ 32 ],[ 33 ], [ 34 ], [ 35 ], [ 36 ], [ 37J, [ 38 ],[ 39J, [ 40 ], [ 411, [ 42 ], [ 43J, [ 44 ], [ 45J, [ 46 ], [ 47J, [ 48 ], [ 49J, [ 50 ],[ 51J, [ 52J, [ 53J, [ 54J, [ 55J, [ 56J,"
    },
    {
        "original_text": "We present the results on the super quantum mechanics (SQM) in dimer models with free fermion boundary conditions. We show that SQM is equivalent to the usual quantum mechanics for periodic boundary condition case. In addition we find that there are two different types of supersymmetric ground states depending on whether or not the number of particles N is even. For odd N , the ground state has zero energy but it does not have any degeneracy. On the other hand, when N is even, the ground state becomes doubly degenerate. The degeneracy can be understood by using the concept of parity symmetry breaking. Finally we discuss how our result fits into the general framework of supersymmetry. PACS: 11.10.Wx, 05.45.Mt, 11.15.Tk \nI. INTRODUCTORY REMARK\nIn this work we study the super quantum mechanics ( S Q M ) i n d im e r m odels w ith f ree fermi b oundary c o ndition s . T hese models were first introduced by Rokhsar et al [1] as an exactly solvable model which describes spin-1/2 Heisenberg antiferromagnet on a square lattice. They showed that these models exhibit many interesting properties such as spontaneous dimerization at low temperatures [2] .\nThe main purpose of this work is to investigate the effect of boundary conditions on the supersymmetric structure of the system. It turns out that the supersymmetric structure depends crucially on the boundary conditions imposed on the system. As will become clear later, the supersymmetric structure changes drastically if one switches between periodic and free-fermion boundary conditions.",
        "watermark_text": "We present the results on the super quantum mechanics ( SQM ) in dimer models with free fermion boundary conditions.We show that SQM is equivalent to the usual quantum mechanics for periodic boundary condition case.In addition we find that there are two different kinds of supersymmetric ground states depending on whether or not the number of particles N is even.For odd N, the ground state has 0 energy but it does not have any degeneracy.On the other hand, when N is even, the ground state becomes doubly degenerate.The degeneracy can be understood by using the concept of parity symmetry breaking.Finally we discuss how our result fits into the general framework of supersymmetry.PACS :11. 10. Wx, 05. 45. Mt, 11. 15. Tk I. INTRODUCTORY REMARK In this work we study the super quantum mechanics ( S Q M )i n dim e r m odels w ith f ree fermi b oundary c o ndition s.T hese models were first introduced by Rokhsar et al[ 1 ] as an exactly solvable model which describes spin - 1 / 2 Heisenberg antiferromagnet on a square lattice.They showed that these models exhibit many interesting properties such as spontaneous dimerization at low temperatures [ 2 ].The main purpose of this work is to explore the effect of boundary conditions on the supersymmetric structure of the system.It turns out that the supersymmetric structure depends crucially on the boundary conditions imposed on the complex.As will become clear later, the supersymmetric structure shifts drastically if one switches between periodic and free - fermion boundary conditions."
    },
    {
        "original_text": "We present an exact expression for the pressure tensor of a fluid confined by any external potential, which is valid at all temperatures. The result can be obtained as a special case of the virial expansion for the grand canonical partition function. We show that this expression reduces to known results when applied to specific potentials such as harmonic traps or periodic lattices. Finally we apply our general formula to calculate the equation of state of a gas of fermions with attractive interactions in two dimensions. In particular, we find that the system undergoes a phase transition into a superfluid state below some critical temperature Tc. This work was supported by NSF grant PHY-0456747 (M.A.) . \nI. INTRODUCTORY REMARK\nThe thermodynamic properties of many-body systems are often studied using statistical mechanics methods [1] , where one considers ensembles of particles interacting via a given potential energy V(r). For example, if the particles interact through short-range forces only, then it is possible to derive expressions for various physical quantities like density profiles [2] , compressibility [3] , heat capacity [4] , etc., starting from the microscopic definition of entropy S = -k B ln Z, where k B is Boltzmann's constant and Z is the partition function defined as:",
        "watermark_text": "We present an exact expression for the pressure tensor of a fluid confined by any external potential, which is valid at all heats.The result can be obtained as a special case of the virial expansion for the great canonical partition function.We show that this expression reduces to known results when applied to specific potentials such as harmonic traps or periodic lattices.Finally we apply our general formula to calculate the equation of state of a gas of fermions with attractive interactions in 2 dimensions.In particular, we find that the system undergoes a phase transition into a superfluid state below some critical temperature Tc.This work was supported by NSF grant PHY - 0456747 ( M. A. ).I. INTRODUCTORY REMARKThe thermodynamic properties of many - body systems are often studied using statistical mechanics methods[ 1 ], where one considers ensembles of particles interacting via a given potential energy V ( r ).For example, if the particles interact through short - range forces only, then it is possible to derive expressions for various physical quantities like density profiles[ 2 ], compressibility [ 3 ], heat capacity [ 4 ], etc., starting from the microscopic definition of entropy S = - k B ln Z, where k B is Boltzmann ' s constant and Z is the partition function defined as :"
    },
    {
        "original_text": "We consider the generalised Einstein condition in the context of parabolic geometries, which are Riemannian metrics on manifolds with an additional structure given by a torsion-free connection preserving the metric up to scale.  We show that this condition is equivalent to the existence of a certain family of vector fields satisfying some natural properties. In particular we prove that if such a family exists then it can be used to construct a new parabolic geometry whose underlying manifold has dimension one less than the original one. This result allows us to give a complete classification of all possible parabolic geometries on surfaces admitting a non-trivial Levi-Civita connection. Finally, using our results about the generalised Einstein condition, we study the problem of finding solutions to the vacuum field equations in four dimensions. The main tool here will be the so-called \"cone construction\" introduced by Eardley and Sachs. \nIntroduction\n\nIn this article we shall investigate the following question: \nWhat does the generalised Einstein condition mean?\n\nThe answer depends upon what you mean by \"geometries\". \n\nIf you have no idea whatsoever as to what I am talking about, read the first section below entitled \"Introduction\".\n\nParabolic geometries",
        "watermark_text": "We consider the generalised Einstein condition in the context of parabolic geometries, which are Riemannian metrics on manifolds with an additional structure given by a torsion - free connection preserving the metric up to scale.We show that this condition is equivalent to the existence of a certain family of vector fields satisfying some natural properties.In particular we prove that if such a family exists then it can be used to construct a new parabolic geometry whose underlying manifold has dimension one fewer than the old one.This result allows us to give a complete class of all possible parabolic geometries on surfaces admitting a non - trivial Levi - Civita link.Finally, using our results about the generalised Einstein condition, we study the problem of finding solutions to the vacuum field equations in 4 dimensions.The main tool here will be the so - called \" cone construction \" introduced by Eardley and Sachs.IntroductionIn this article we shall investigate the following question : What does the generalised Einstein condition mean?The solution depends upon what you mean by \" geometries \".If you have no idea whatsoever as to what I am talking about, read the first section below entitled \" Introduction \".Parabolic geometries"
    },
    {
        "original_text": "We present an analysis of the fundamental physical parameters (mass, luminosity and size) for a sample of young star clusters in the nearby spiral galaxy M33 using HST/ACS data. We find that these objects are consistent with being gravitationally bound open clusters or associations. The mass distribution is well described by a power law dN/dM ~ M^{-3} between 10^6 to 5 x 10^7 solar masses. This result suggests that cluster formation proceeds hierarchically on all scales within this range. In addition we find evidence for two distinct populations of massive clusters; one population has ages less than 100 Myr while another older population appears to be coeval at ages greater than 300 Myr. These results suggest that there may have been multiple episodes of intense cluster formation over the past few hundred million years. Finally, we compare our observations to theoretical models of cluster evolution and find good agreement when assuming a Kroupa IMF.",
        "watermark_text": "We present an analysis of the fundamental physical parameters ( mass, luminosity and size ) for a specimen of young star clusters in the nearby spiral galaxy M33 using HST / ACS data.We find that these objects are consistent with being gravitationally bound open clusters or associations.The mass distribution is good described by a power law dN / dM ~ M ^ { - three } between ten ^ six to five x 10 ^ 7 solar masses.This result suggests that cluster formation proceeds hierarchically on all scales within this range.In addition we find evidence for two distinct populations of massive clusters ; one population has ages less than 100 Myr while another older population appears to be coeval at ages greater than 300 Myr.These results suggest that there might have been multiple episodes of intense cluster forming over the past few hundred million years.Finally, we compare our observations to theoretical models of cluster evolution and find well agreement when assuming a Kroupa IMF."
    },
    {
        "original_text": "We study isospin-breaking effects on the production rate for heavy-light mesons (D, D*) and light-heavy mesons (D0, D0bar). We use an effective field theory approach to calculate these rates at leading order in perturbation theory. The results are compared with experimental data obtained by CLEO-c. \n \n Isospin symmetry plays an important role in hadronic physics. It relates states that differ only in their charge but have identical masses. In particular it implies that the strong decay widths of charged and neutral pions should be equal. However, this equality has been experimentally tested down to pion momenta as low as 1 MeV/c and deviations up to 20% were found [1] . These deviations can be explained within Chiral Perturbation Theory [2] , which predicts corrections proportional to powers of the momentum transfer between initial and final state particles. At higher energies, where the typical momentum transfers become larger than the chiral scale, one expects such corrections to vanish rapidly [3] .\n \nIn contrast, we consider here processes involving two heavy quarks close to threshold. Here, the typical momentum transfers are small enough so that non-perturbative contributions cannot be neglected anymore. As a consequence, even though the mass difference between charm and anti-charm quarks is tiny, there will still be significant differences between the corresponding cross sections [4] . \n \n This effect was first observed more than 20 years ago [5] when studying the production of charmed mesons in electron-positron collisions. Since then many experiments [6] - [8] have measured the ratio of the production rates for different combinations of heavy-meson pairs. While some of them find good agreement with theoretical predictions [9] based on Heavy Quark Effective Theory [10] , others disagree significantly [11] .",
        "watermark_text": "We study isospin - breaking effects on the production rate for heavy - light mesons ( D, D * ) and light - heavy mesons ( D0, D0bar ).We use an effective field theoretical approach to calculate these rates at leading order in perturbation theory.The results are compared with experimental data obtained by CLEO - c. Isospin symmetry plays an important role in hadronic physics.It relates states that differ only in their charge but have identical masses.In particular it implies that the strongly decay widths of charged and neutral pions should be equal.However, this equality has been experimentally tested down to pion momenta as low as 1 MeV / ca and deviations up to 20 % were found [ 1 ].These deviations can be explained within Chiral Perturbation Theory[ 2 ], which predicts corrections proportional to powers of the momentum transfer between initial and final state particles.At higher energies, where the typical momentum transfers become bigger than the chiral scale, one expects such corrections to vanish rapidly [ 3 ].In contrast, we consider here procedures involving 2 heavy quarks close to threshold.Here, the typical momentum transfers are small enough so that non - perturbative contributors cannot be neglected anymore.As a consequence, even though the mass difference between charm and anti - charm quarks is tiny, there will still be significant differences between the equivalent cross sections [ 4 ].This effect was first observed more than 20 years ago [ 5 ] when studying the production of charmed mesons in electron - positron collisions.Since then many experiments [ 6 ] - [ 8 ] have measured the ratio of the producing rates for different combinations of heavy - meson pairs.While some of them find good agreement with theoretical predictions [ 9 ] based on Heavy Quark Effective Theory [ 10 ], others disagree significantly [ 11 ]."
    },
    {
        "original_text": "We present an analysis of the distribution of gas, stars and dust in two nearby edge-on spirals with prominent bars (NGC 1365 and NGC 1530). We use high-resolution observations obtained by the Herschel Space Observatory to study the physical conditions of the interstellar medium along these systems. The main results are as follows:  - In both cases we find that the molecular hydrogen is concentrated on the leading edges of the bar, while atomic hydrogen follows closely the stellar light.  - The star formation rate peaks at the ends of the bar where the density of molecular hydrogen increases significantly. This suggests that the gravitational torques induced by the bar can trigger the collapse of dense clouds into new generations of young stars.  - The infrared emission associated with polycyclic aromatic hydrocarbons shows a clear correlation between the location of this component and the regions of active star formation. - The comparison of our data with hydrodynamical simulations indicates that the observed structure of the ISM may be explained if the bar potential has been able to drive significant amounts of cold gas towards its inner Lindblad resonance.",
        "watermark_text": "We present an analysis of the distribution of gas, stars and dust in two nearby edge - on spirals with conspicuous bars ( NGC 1365 and NGC 1530 ).We utilize high - detail observations obtained by the Herschel Space Observatory to study the physical conditions of the interstellar medium along these systems.The main results are as follows : - In both cases we find that the molecule hydrogen is concentrated on the leading ends of the bar, while atomic hydrogen follows closely the stellar light.- The star formation rate peaks at the ends of the bar where the density of molecules hydrogen increases significantly.This suggests that the gravity torques induced by the bar can stimulate the collapse of dense clouds into new generations of young stellar.- The infrared emission associated with polycyclic aromatic hydrocarbons shows a clear correlation between the location of this component and the regions of active star formation.- The comparison of our data with hydrodynamical simulations indicates that the observed structure of the ISM may be explained if the bar potential has been able to drive significant amounts of cold gas towards its inner Lindblad resonance."
    },
    {
        "original_text": "We present radiative transfer models for the dust distributions in two edge-on spiral galaxies, NGC 891 and NGC 4565. The model parameters are constrained by fitting to near-infrared (NIR) observations at 2.2 microns with NICMOS on HST as well as optical data obtained with WFPC-2. We find that both galaxies have significant amounts of dust distributed along their disks out to large distances above the midplane. In addition we detect an extended halo component around each galaxy which is best described by a spherical shell-like structure. For NGC 891 this component has a scale height of 1 kpc and extends up to 5 kpc above the disk plane. It contains about 10% of all dust mass within 10 kpc distance from the center. For NGC 4565 our results suggest a more complex geometry where the dust density decreases exponentially towards larger heights. This work was supported by NASA grant NAG5-7085.",
        "watermark_text": "We present radiative transfer models for the dust distributions in two edge - on spiral galaxies, NGC 891 and NGC 4565.The model parameters are constrained by fitting to nearly - infrared ( NIR ) measurements at 2. 2 microns with NICMOS on HST as ill as optical data obtained with WFPC - 2.We find that both galaxies have significant amounts of dust distributed along their disks out to large distances above the midplane.In addition we detect an extended halo component around each galaxy which is better described by a sphere shell - like structure.For NGC 891 this component has a scale height of 1 kpc and extends up to 5 kpc above the disk plane.It contains about 10 % of all dust mass within 10 kpc distant from the center.For NGC 4565 our findings suggest a more complicated geometry where the dust density decreases exponentially towards larger heights.This work was supported by NASA grant NAG5 - 7085."
    },
    {
        "original_text": "We study the nonlinear dynamics of infectious diseases transfer in a population, where individuals are divided into three classes: susceptible (S), infected (I) and recovered/removed (R). We consider two different models: SIR model and SEIR model. In both cases we assume that there is no birth or death in the population. The main goal of this work is to investigate how the disease spreads through the population depending on its parameters. For example, if the infection rate is too high then it may lead to an epidemic outbreak. On the other hand, if the recovery rate is very large compared to the infection rate then the number of infectives will decrease rapidly. Finally, we show some numerical simulations which illustrate our results. \n \n Keywords: Nonlinear dynamics, infectious diseases, tuberculosis, SIR model, SEIR model. 1 Introduction \n \n Many mathematical models have been developed over time to describe the spread of infectious diseases within populations [1–3] . These models can be used as tools to understand the transmission mechanisms of these diseases and help public health authorities make decisions about prevention strategies [4] .\n \nIn particular, many researchers have studied the effects of vaccination programs [5–7] , quarantine [8, 9] and isolation [10, 11] on the evolution of epidemics. Other studies focus on the impact of environmental factors such as temperature [12, 13] , humidity [14, 15] and rainfall [16] on the propagation of pathogens. \nThe majority of existing works use deterministic models based on ordinary differential equations [17] . However, stochastic models [18, 19] and agent-based models [20, 21] also exist. Agent-based models allow us to take into account individual behaviors [22] while stochastic models provide more realistic descriptions of random events [23] . \n \nIn this article, we propose new mathematical models describing the spread of infectious diseases in a closed population. Our aim is to analyze the influence of various parameters on the behavior of the system. More specifically, we want to determine whether the disease will die out naturally or cause an epidemic outbreak. To do so, we first introduce the basic reproduction number R0 [24] , which represents the average number",
        "watermark_text": "We study the nonlinear dynamics of infectious diseases transfer in a population, where individuals are divided into 3 classes : susceptible ( S ), infected ( I ) and recovered / removed ( R ).We consider two different models : SIR model and SEIR model.In both cases we expect that there is no birth or death in the population.The main goal of this work is to investigate how the disease spreads through the populace depending on its criteria.For example, if the infection rate is too high then it might lead to an epidemic outbreak.On the other hand, if the recovery rate is very large compared to the infection risk then the number of infectives will decrease rapidly.Finally, we show some numerical simulations which illustrate our results.Keywords : Nonlinear dynamics, infectious diseases, tuberculosis, SIR model, SEIR model.1 Introduction Many mathematical models have been developed over length to describe the spread of infected diseases within populations [ 1 – 3 ].These models can be used as tools to understand the transmission mechanisms of these diseases and help public health authorities make decisions about prevention strategies [ 4 ].In particular, many researchers have studied the impacts of vaccination plans [ 5 – 7 ], quarantine[ 8, 9 ] and isolation [ 10, 11 ] on the evolution of epidemics.Other studies focus on the impact of environmental factors such as temperature [ 12, 13 ], humidity[ 14, 15 ] and rainfall [ 16 ] on the propagation of pathogens.The majority of existing works utilize deterministic models based on normal differential equations[ 17 ].However, stochastic models[ 18, 19 ] and agent - based models [ 20, 21 ] also exist.Agent - based models allow us to take into account individual behaviors[ 22 ] while stochastic models offer more realistic descriptions of random events[ 23 ].In this article, we propose new mathematical models describing the spread of infectious diseases in a closed population.Our aim is to analyze the influence of various criteria on the behavior of the system.More specifically, we want to determine whether the disease will kill out naturally or cause an epidemic outbreak.To do so, we first introduce the basic reproduction quantity R0[ 24 ], which represents the average number"
    },
    {
        "original_text": "The renormalization group is used to study the effective action in quantum gravity, which describes how matter fields interact with gravitons.  The gravitational field equations are derived by varying this action with respect to the metric tensor. This approach leads to an understanding of why general relativity has no ultraviolet divergences at one-loop order (i.e., when only one graviton loop is included). It also provides insight into the physical meaning of the cosmological constant term that appears in Einstein's field equations. In addition, it allows us to calculate corrections to the classical theory due to higher-order terms in the expansion of the effective action about flat space-time. Finally, we discuss some open problems related to the application of these techniques to more complicated theories such as superstrings or supergravity. The renormalization group is applied to the problem of studying the effective action in quantum-gravitational systems. We derive the gravitational field equations by varying this action with regard to the metric tensor. These results provide insights into the physical meaning of both the cosmological constant appearing in Einstein's field equations and the corrections to the classical theory arising from higher-order terms in the effective-action expansion around flat spacetime.",
        "watermark_text": "The renormalization group is used to study the effective act in quantum gravity, which describes how matter fields interact with gravitons.The gravitational field equations are derived by varying this act with respect to the metric tensor.This approach leads to an understanding of why general relativity has no ultraviolet divergences at one - loop order ( i. e., when only 1 graviton loop is included ).It also provides insight into the physical meaning of the cosmological constant term that appears in Einstein ' s field equations.In addition, it permits us to calculate corrections to the classical theory due to higher - order terms in the expansion of the effective action about flat space - time.Finally, we discuss some open problems related to the application of these techniques to more complicated theories such as superstrings or supergravity.The renormalization group is applied to the problem of studying the effective action in quantum - gravitational systems.We derive the gravity field equations by varying this action with regard to the metric tensor.These results provide insights into the physical meaning of both the cosmological constant appearing in Einstein ' s field equations and the corrections to the classical theory arising from higher - order terms in the effective - action expansion around flat spacetime."
    },
    {
        "original_text": "We study the electromagnetic wave propagation through a bundle of closely-packed metallic single-walled carbon nanotubes (SWCNTs). The SWCNTs' diameter is assumed to be 1 nm and their length is taken as 10 microns. We use the finite element method for solving Maxwell's equations with appropriate boundary conditions at the ends of each tube. Our results show that there are two different regimes depending on the frequency range considered. In one regime, we find that the transmission coefficient decreases rapidly when increasing the number density of tubes. This behavior can be explained by considering the effect of multiple scattering between neighboring tubes. On the other hand, in another regime where the wavelength is much larger than the tube radius, the transmission coefficient increases slowly with respect to the number density of tubes due to constructive interference effects among scattered waves inside individual tubes. Finally, our numerical results indicate that the presence of defects such as vacancies or impurities may significantly affect the overall transmission properties of the system.",
        "watermark_text": "We study the electromagnetic wave propagation through a bundle of closely - packed metallic single - walled carbon nanotubes ( SWCNTs ).The SWCNTs ' diameter is assumed to be 1 nm and their length is taken as 10 microns.We use the finite element method for solving Maxwell ' s equations with appropriate boundary conditions at the ends of each tube.Our results show that there are two different regimes depending on the frequency range considered.In one regime, we find that the transmission coefficient decreases rapidly when increasing the number density of tubes.This behavior can be explained by considering the effect of multi scattering between neighboring tubes.On the other hand, in another regime where the wavelength is much larger than the tube radius, the transmitted coefficient increases slowly with respect to the number density of tubes due to constructive interference effects among scattered waves inside individual tubes.Finally, our numerical results indicate that the presence of defects such as vacancies or impurities may significantly affect the overall transmission properties of the system."
    },
    {
        "original_text": "We present the results of our numerical simulations of accreting black holes in which we have included general relativistic effects and radiative transfer using Monte Carlo techniques. We find that for low mass (M < 10 M_sun) black holes, there is an inner edge to the disk at about 3 Schwarzschild radii where the density drops sharply by several orders of magnitude. The temperature profile shows a sharp rise near this radius due to compression as well as heating by viscous dissipation. For higher masses (10 M_sun < M < 100 M_sun), the disks are optically thick throughout their extent with no clear evidence of any inner edge. In these cases, the temperature profiles show a gradual increase towards smaller radii. Finally, for very massive black holes (M > 100 M_sun), we find that the disks become geometrically thin but remain optically thick out to large distances.",
        "watermark_text": "We present the results of our numerical simulations of accreting dark holes in which we have included general relativistic effects and radiative transport using Monte Carlo techniques.We find that for low mass ( M 100 M _ sun ), we find that the disks become geometrically thin but remain optically thick out to large distances."
    },
    {
        "original_text": "We study the incoherent transport properties of a strongly correlated electron system, namely the periodic Anderson model (PAM) with strong hybridization between conduction and localized electrons. We show that this PAM can be mapped onto an effective spinless fermion model which is equivalent to a disordered Fermi gas at low temperatures. The resulting density of states exhibits a pseudogap structure near the chemical potential. In addition we find that the resistivity shows a linear temperature dependence below some characteristic temperature T*. This behavior is consistent with recent experiments on heavy-fermion compounds such as Yb$_{1}$-xYb$x$Cu$_2$Si$2$O$_{7-x}$. Finally, we discuss how our results are related to previous theoretical work based on the dynamical mean-field theory. PACS numbers: 71.27.+a, 72.25.+f, 74.78.+h",
        "watermark_text": "We study the incoherent transport properties of a strongly correlated electron complex, namely the periodic Anderson model ( PAM ) with strongly hybridization between conduction and localized electrons.We show that this PAM can be mapped onto an effective spinless fermion model which is equivalent to a disordered Fermi gas at low temperatures.The resulting density of states exhibits a pseudogap structure near the chemical potential.In addition we find that the resistivity shows a linear temperature dependence below some distinctive temperature T *.This behavior is consistent with recent experiments on heavy - fermion compounds such as Yb $ _ { 1 } $ - xYb $ x $ Cu $ _ 2 $ Si $ 2 $ O $ _ { 7 - x } $. Finally, we discuss how our results are related to previous theoretical work based on the dynamical mean - field theory.PACS numbers : 71. 27. + a, 72. 25. + f, 74. 78. + h"
    },
    {
        "original_text": "We present the results of an optical spectroscopic survey of radio galaxies in clusters at redshifts z=0.4-0.8, carried out with the William Herschel Telescope (WHT). We find that the fraction of AGN-powered radio galaxies decreases towards higher galaxy density environments within the clusters. This is consistent with previous studies which have found evidence for environmental quenching of star formation activity among massive galaxies. However we also find that there are many examples where powerful radio sources reside in dense regions without any obvious signs of being environmentally suppressed. These objects may be undergoing rapid evolution or they could represent a population of recently accreted field galaxies whose properties are still evolving to resemble those of their local counterparts. The sample consists of 20 radio galaxies selected from the VLA-COSMOS 3 GHz Large Project catalogue (Smolčić et al., 2009) using the following criteria: 1) They lie in one of four X-ray luminous clusters at 0.4 < z < 0.8; 2) Their radio luminosity lies above L(3GHz) = 10 25 W Hz-1; 3) They do not show strong emission lines indicative of ongoing nuclear activity; 4) They were observed during our WHT run on 2010 May 24-25.",
        "watermark_text": "We present the results of an optical spectroscopic survey of radio galaxies in clusters at redshifts z = 0. 4 - 0. 8, carried out with the William Herschel Telescope ( WHT ).We find that the fraction of AGN - powered radio galaxies decreases towards upper galaxy density environments inside the clusters.This is consistent with previous studies which have found evidence for environment quenching of star forming activity among massive galaxies.However we also find that there are many examples where powerful radio sources reside in dense regions lacking any obvious symptoms of being environmentally suppressed.These objects may be undergoing rapid evolution or they could represent a population of recently accreted field galaxies whose properties are still evolving to resemble those of their local counterparts.The sample consists of 20 radio galaxies selected from the VLA - COSMOS 3 GHz Big Project catalog ( Smolčić et al., 2009 ) using the following criteria : 1 ) They lie in one of four X - ray luminous clusters at 0. 4 < z < 0. 8 ; 2 ) Their radio luminosity lies above L ( 3GHz )= 10 25 W Hz - 1 ; 3 ) They do not show strong emission lines indicative of ongoing atomic activity ; 4 )They were observed during our WHT drive on 2010 Mai 24 - 25."
    },
    {
        "original_text": "We present new results on the evolution of the dust content in Lyman break galaxies (LBGs) using deep near-infrared data obtained by the UltraVISTA survey, which is part of the Sloan Digital Sky Survey III program. We use these observations to study the rest-frame UV-optical properties of LBGs at redshifts 1<z<3.5. The main goal of this work was to investigate how the dust extinction evolves as a function of galaxy mass and star formation rate density over cosmic time. Our analysis shows that there are two different populations of LBGs: one population has low stellar masses (M*=10^10-10^11 Msun), high specific star formation rates (SSFR>100Gyr-1), and relatively small amounts of dust; while another population consists of more massive systems (M*>10^11Msun), lower SSFR values (SSFR<30Gyr-1), and higher levels of dust extinction. These findings suggest that the amount of dust increases with increasing galaxy mass for both local and distant galaxies.",
        "watermark_text": "We present fresh results on the evolution of the dust content in Lyman break galaxies ( LBGs ) using deep near - infrared data obtained by the UltraVISTA survey, which is part of the Sloan Digital Sky Survey III program.We use these observations to study the rest - frame UV - optical properties of LBGs at redshifts 1100Gyr - 1 ), and relatively small amounts of dust ; while another population consists of more massive systems ( M * > 10 ^ 11Msun ), lower SSFR values ( SSFR < 30Gyr - 1 ), and higher levels of dust extinction.These findings suggest that the amount of dust increases with increasing galaxy mass for both local and distance galaxies."
    },
    {
        "original_text": "We present the luminosity function (LF) for galaxies in the local universe at rest-frame wavelengths between 3 and 24 microns, using data obtained with Spitzer Space Telescope's Infrared Array Camera (IRAC). We use two different methods to estimate the LF - one based on direct counts of galaxies within bins of absolute magnitude, and another that uses an analytic model fit to these galaxy counts. The results are consistent across both techniques. Our best-fit Schechter parameters are: M* = -19.6 +/- 0.1 mag., log(L/Lsun) * = 10.9 +/- 0.2 dex, and alpha = -1.3 +/- 0.4. These values agree well with previous determinations made by other authors over similar wavelength ranges. However, we find evidence for a significant excess number density of faint sources relative to predictions from our best-fit Schechte functions. This excess is most pronounced at longer wavelengths where it amounts to ~50% more objects than expected.",
        "watermark_text": "We present the luminosity function ( LF ) for galaxies in the local universe at rest - frame wavelengths between 3 and 24 microns, using data obtained with Spitzer Space Telescope ' s Infrared Array Camera ( IRAC ).We utilize two separate methods to estimate the LF - one based on direct counts of galaxies within bins of absolute magnitude, and another that uses an analytic model fit to these galaxy counts.The results are consistent across both techniques.Our best - fit Schechter parameters are : M * = - 19. 6 + / - 0. 1mag., log ( L / Lsun ) *= 10. 9 + / - 0. 2 dex, and alpha= - 1. 3 + / - 0. 4.These values agree well with previous determinations made by other authors over similar wavelength ranges.However, we find evidence for a significant excess number density of faint sources relative to predictions from our best - fit Schechte functions.This excess is most pronounced at longer wavelengths where it amounts to ~ 50 % more objects than predicted."
    },
    {
        "original_text": "The purpose of this study is to examine how an organisation can use Information Technology Infrastructure Library (ITIL) as a process optimisation tool within its service centre environment. The research focuses on the release management process at the IT service centre of Harz University and examines whether it complies with all relevant aspects of the ITIL framework. A case study approach was used to collect data through interviews and document analysis. This article presents the results of the investigation into the current state of the release management process at Harz University's IT service centre. It also provides recommendations for improving the process based on the findings. Keywords: information technology infrastructure library, process optimization, release management process, university, IT service centre, case study method. 1 Introduction Today, universities are increasingly relying on their computer systems to support teaching and research activities. As such, they need reliable services that meet user requirements [1] . However, many universities have experienced problems related to poor quality software releases [2] , which may lead to system failures or even loss of data [3] .\nIn order to avoid these issues, organisations should implement appropriate processes [4] . One widely accepted set of guidelines for managing information technology (IT) services is provided by the Information Technology Infrastructure Library [5] . According to [6] , ITIL has been adopted by more than 80% of Fortune 500 companies worldwide since 2003.",
        "watermark_text": "The purpose of this study is to examine how an organisation can use Information Technology Infrastructure Library ( ITIL ) as a process optimisation tool within its service centre environment.The research focuses on the release management procedure at the IT service centre of Harz University and examines whether it complies with all relevant aspects of the ITIL framework.A case study approach was used to collect data through interviews and document analysis.This article presents the results of the investigation into the current state of the release management procedure at Harz University ' s IT service centre.It also provides recommendations for improving the process based on the findings.Keywords : information technology infrastructure library, process optimization, release management process, university, IT service centre, case study method.1Introduction Today, universities are increasingly relying on their computer systems to support teachers and research activities.As such, they need reliable services that meet user requirements [ 1 ].However, many universities have experienced problems related to poor quality software releases [ 2 ], which may lead to system failures or even loss of data [ 3 ].In order to avoid these issues, organisations should implement appropriate processes [ 4 ].One widely accepted set of guidelines for managing information technology ( IT ) services is provided by the Information Technology Infrastructure Library[ 5 ].According to [ 6 ], ITIL has been adopted by more than 80 % of Fortune 500 companies worldwide since 2003."
    },
    {
        "original_text": "We present the results of our study on the possible existence and stability of terrestrial planets around the star Gliese 581, which is located at about 20 light-years away from Earth. We have performed numerical simulations for different orbital configurations of three hypothetical terrestrial planets with masses ranging between 1 to 10 times that of Earth's mass (1-10 M⊕). Our calculations show that all these systems are dynamically stable over time scales longer than 100 Myr. The most massive planet has an eccentric orbit with e=0.2 and its periastron distance ranges between 0.05 AU and 0.15 AU depending on the initial conditions used. This planet can be considered as a hot Jupiter-like planet because it orbits very close to its host star. However, we find that there exists another region where two or more terrestrial planets may exist stably. In this region, one of them could be a super-Earth-type planet with a mass larger than 5M⊕ but smaller than 8M⊕.",
        "watermark_text": "We present the results of our study on the possible existence and stability of terrestrial worlds around the stellar Gliese 581, which is situated at about 20 light - years away from Earth.We have performed numerical simulations for different orbital arrangements of three hypothetical terrestrial planets with masses ranging between one to ten times that of Earth ' s number ( 1 - 10 M⊕ ).Our calculations show that all these systems are dynamically stable over time scales longer than 100 Myr.The most massive planet has an eccentric orbit with e = 0. 2 and its periastron distance ranges between zero. 05 AU and 0. 15 AU depending on the beginning conditions used.This planet can be considered as a hot Jupiter - like planet because it orbits very close to its host star.However, we find that there exists another region where two or more terrestrial worlds may exist stably.In this region, one of them could be a super - Earth - type planet with a mass larger than 5M⊕ but smaller than 8M⊕."
    },
    {
        "original_text": "The aim of this book is to provide an overview on the state-of-the-art in on-line condition monitoring and fault diagnosis for industrial processes, with special emphasis on computational intelligence techniques such as neural networks (NNs), fuzzy logic systems (FLS) or evolutionary algorithms (EAs). The book covers both theoretical aspects and practical applications of these methods. It also discusses some recent advances in intelligent sensor technologies that are essential for successful implementation of on-line condition monitoring schemes. This book will be useful not only for researchers but also for engineers who want to apply computational intelligence techniques into their own research work. Contents include:  Chapter 1: Introduction to On-line Condition Monitoring.  Chapter 2: Intelligent Sensors for On-line Condition Monitoring.  Chapters 3-7: Neural Networks for Fault Diagnosis.  Chapters 8-10: Fuzzy Logic Systems for Fault Diagnosis.   Chapters 11-13: Evolutionary Algorithms for Fault Diagnosis.   ...",
        "watermark_text": "The aim of this book is to provide an overview on the state - of - the - art in on - line condition monitoring and defect diagnosis for industrial processes, with special emphasis on computational intelligence techniques such as neurons networks ( NNs ), fuzzy logic systems ( FLS ) or evolutionary algorithms ( EAs ).The book covers both theoretical aspects and practical applications of these techniques.It also discusses some recent advances in intelligent sensor technologies that are vital for effective implementation of on - line condition monitoring schemes.This book will be useful not only for researchers but also for engineers who want to apply computational intelligence techniques into their own research work.Contents include : Chapter 1 : Introduction to On - line Condition Monitoring.Chapter 2 : Intelligent Sensors for On - line Condition Monitoring.Chapters 3 - 7 : Neural Networks for Fault Diagnosis.Chapters 8 - 10 : Fuzzy Logic Systems for Fault Diagnosis.Chapters 11 - 13 : Evolutionary Algorithms for Fault Diagnosis.."
    },
    {
        "original_text": "We present results on gamma ray albedo of the Moon obtained with Fermi Large Area Telescope (LAT). The data set consists of more than 1 billion photons collected between August 4, 2008 and September 30, 2012 in the energy range 0.1 - 100 GeV. We find that the observed flux is consistent with previous measurements by EGRET but higher than those reported by AGILE and Fermi-GBM experiments. This discrepancy may be explained by different angular resolutions of these instruments. Our analysis shows no significant time variability for the total emission as well as its individual components. In addition to the previously known sources we detect several new point-like sources at high confidence level. These include two bright unidentified sources located near the lunar poles which are likely associated with dark matter annihilation or decay. \n \n Keywords: Gamma rays, Moon, Dark Matter, LAT, Fermi Observatory, Point Sources, Unidentified",
        "watermark_text": "We present results on gamma ray albedo of the Moon obtained with Fermi Large Region Telescope ( LAT ).The data set consists of more than 1 billion photons gathered between August 4, 2008 and September 30, 2012 in the energy range 0. 1 - 100 GeV.We find that the observed flux is consistent with previous measurements by EGRET but higher than those reported by AGILE and Fermi - GBM experiments.This discrepancy may be explained by various angular resolutions of these instruments.Our analysis shows no significant time variability for the total emission as well as its individual components.In addition to the previously known sources we detect multiple new point - like sources at highly confidence status.These include two bright unidentified sources located near the lunar poles which are likely associated with deep matter annihilation or decay.Keywords : Gamma rays, Moon, Dark Matter, LAT, Fermi Observatory, Point Sources, Unidentified"
    },
    {
        "original_text": "We study the possibility that electroweak symmetry breaking is triggered by strong dynamics at an ultraviolet (UV) fixed point, as suggested by gauge-Higgs unification models with warped extra dimensions. We show how this scenario can be realized within the framework of composite Higgs models based on strongly-coupled gauge theories. In particular we consider two different realizations of such scenarios: one where the Higgs arises as a pseudo-Nambu-Goldstone boson associated to spontaneous breaking of approximate global symmetries; another where it emerges as a bound state of new fermions charged under the Standard Model gauge group. The latter case leads to novel signatures for Higgs production through gluon fusion which are potentially observable at future colliders. Finally, we discuss possible implications of these results for cosmology. Gauge-Higgs unification provides a compelling explanation for why the weak scale is so much smaller than any other mass scale in nature [1] . It also offers a natural solution to the hierarchy problem between the Planck and TeV scales [2] , since quantum corrections to the Higgs potential are cut off at the UV scale [3] .\nIn order to realize this idea in practice, however, several challenges must be overcome [4] : i) the Higgs should arise naturally out of some strongly coupled sector; ii) the Higgs couplings to SM particles should agree with experiment; iii) there should exist a mechanism to generate masses for all SM fields without introducing large hierarchies among them. These issues have been addressed recently using the Randall-Sundrum model [5] , where the Higgs field lives on the IR brane while gravity propagates into the bulk [6] - [8] . This setup allows for a calculable description of the Higgs physics [9] , but introduces additional complications due to the presence of Kaluza-Klein gravitons [10] .",
        "watermark_text": "We study the possibility that electroweak symmetry breaking is triggered by strong dynamics at an ultraviolet ( UV ) fixed point, as suggested by gauge - Higgs unification models with warped extra dimensions.We show how this scenario can be realized within the framework of composite Higgs models based on strongly - coupled gauge theories.In particular we consider 2 different realizations of such scenarios : one where the Higgs arises as a pseudo - Nambu - Goldstone boson associated to spontaneous breaking of approximate global symmetries ; also where it emerges as a bound state of new fermions charged under the Standard Model gauge group.The latter case leads to novel signatures for Higgs production through gluon fusion which are potentially observable at future colliders.Finally, we discuss potential implications of these results for cosmology.Gauge - Higgs unification provides a compelling explanation for why the weak scale is so much smaller than any other mass scale in nature[ 1 ].It also offers a natural remedy to the hierarchy problem between the Planck and TeV scales [ 2 ], since quantum corrections to the Higgs potential are cut off at the UV scale [ 3 ].In order to realize this idea in practice, however, several challenges must be conquered [ 4 ] : i ) the Higgs should arise naturally out of some strong coupled sector ; ii ) the Higgs couplings to SM particles should agree with experimental ; iii ) there should exist a mechanism to generate masses for all SM fields without introducing large hierarchies among them.These issues have been addressed recently using the Randall - Sundrum model[ 5 ], where the Higgs field lives on the IR brane while gravitational propagates into the bulk[ 6 ] - [ 8 ].This setup allows for a calculable description of the Higgs physics[ 9 ], but introduces additional complications due to the presence of Kaluza - Klein gravitons [ 10 ]."
    },
    {
        "original_text": "The WiFeS instrument is an integral field spectrograph for the Australian National University 2.3m telescope at Siding Spring Observatory, Australia.  It has been in operation since 2005 and was designed to provide high quality optical spectroscopy over a wide range of wavelengths with minimal overheads.   The WiFeS instrument consists of two cameras that are mounted on a common baseplate which sits inside a vacuum chamber attached to the Cassegrain focus of the ANU 2.3m telescope.    Each camera contains a lenslet array that produces a set of images across its focal plane.  These images can be combined into a single data cube using software developed by Dopita et al. (2007).    This data cube provides information about both spatial position and wavelength along each line-of-sight through the object being observed.  In addition to this capability, WiFeS also offers several other advantages including:  - High throughput due to the use of dichroic beam splitters and fibre optic coupling between the lenses and detectors.  - Flexible observing modes ranging from fully automated observations to manual control via remote desktop interface.  - Fast readout times allowing multiple targets to be observed simultaneously or rapid cycling between different targets during a night's observation run.  - Low maintenance requirements as it does not require any moving parts within the vacuum enclosure.  - Excellent stability thanks to the design of the optics bench and the thermal isolation provided by the vacuum enclosure.  - Large format detector arrays providing excellent signal-to-noise ratio even under poor seeing conditions.  - Robust mechanical design ensuring long-term reliability...",
        "watermark_text": "The WiFeS instrument is an integral field spectrograph for the Australian National University II. 3m telescope at Siding Spring Observatory, Australia.It has been in operation since 2005 and was designed to provide high quality optical spectroscopy over a wide range of wavelengths with minimal overheads.The WiFeS instrument consists of two cameras that are mounted on a common baseplate which seats inside a vacuum chamber attached to the Cassegrain focus of the ANU 2. 3m telescope.Each camera contains a lenslet array that produces a set of imagery across its focal plane.These images can be combined into a single data cube using software developed by Dopita et al. ( 2007 ).This data cube provides information about both spatial position and wavelength along each line - of - sight through the object being observed.In addition to this capability, WiFeS also offers several other advantages including : - Higher throughput due to the use of dichroic beam splitters and fibre optic coupling between the lenses and detectors.- Flexible observing modes ranging from fully automated observations to manual control via remote desk interface.- Fast readout times allowing multiple targets to be observed simultaneously or rapid cycling between different targets during a night ' s observation run.- Low maintenance requirements as it does not require any moving parts within the vacuum enclosure.- Excellent stability thanks to the design of the optics bench and the thermal isolation provided by the vacuum enclosure.- Large format detector arrays providing excellent signal - to - noisy ratio also under bad seeing conditions.- Robust mechanical design ensuring long - term reliability."
    },
    {
        "original_text": "We present new measurements of line emission for the brightest cluster galaxies (BCGs) in clusters with z < 0.3, using data obtained by the Chandra X-ray Observatory. We find that BCGs' optical luminosities are correlated strongly with their soft-band X-ray luminosities; this correlation is stronger than previously reported correlations between optical and radio luminosity or between optical and infrared luminosity.  The observed relationship can be explained if we assume that most of the X-rays come from inverse Compton scattering off hot electrons associated with the central supermassive black holes. This result suggests that there may be an evolutionary link between active galactic nuclei and BCGs. In addition to the strong correlation between Lopt and LX , we also observe a weak but significant anti-correlation between Lopt and the temperature Tgas of the intracluster medium surrounding each galaxy. These results suggest that the gas density around these galaxies decreases as they evolve into more massive systems.",
        "watermark_text": "We present fresh measurements of line emission for the brightest cluster galaxies ( BCGs ) in clusters with z < zero. 3, utilizing data obtained by the Chandra X - ray Observatory.We find that BCGs ' optical luminosities are correlated heavily with their soft - band X - ray luminosities ; this correlation is stronger than previously reported correlations between optical and radio luminosity or between optical and infrared luminosity.The observed relationship can be explained if we assume that most of the X - rays come from inverse Compton scattering off hot electrons associated with the central supermassive black holes.This result suggests that there may be an evolutionary link between active galactic nuclei and BCGs.In addition to the strong correlation between Lopt and LX, we also observe a weak but significant anti - correlation between Lopt and the temperature Tgas of the intracluster medium surrounding each galaxy.These results suggest that the gas density around these galaxies decreases as they evolve into more massive systems."
    },
    {
        "original_text": "We have performed simulations of nova explosions using the hydrodynamic code VH-1, which includes nuclear burning and convection. We find that changes to reaction rates can significantly affect the results of these calculations. In particular, we show how different choices for the 12C(p,γ)13N rate lead to differences in the predicted light curve shapes.  The inclusion of this reaction is important because it affects the amount of 13N produced during the explosion. This isotope decays by electron capture into 14O, which then undergoes β+ decay back down to 14N. If there are too many electrons present at late times (due to an overabundance of 13N), they will be captured onto protons instead of being emitted as positrons; thus, less energy will be released than if no such process were occurring. Our results suggest that the current uncertainty in the 12C(p , γ )13N rate may cause errors in the predicted luminosity of up to 50%.",
        "watermark_text": "We have performed simulations of nova explosions using the hydrodynamic code VH - 1, which covers nuclear burning and convection.We find that changes to reaction rates can significantly affect the results of these calculations.In particular, we demonstrate how different choices for the 12C ( p, γ ) 13N rate lead to differences in the predicted light curve shapes.The inclusion of this reaction is important because it affects the quantity of 13N produced during the explosion.This isotope decays by electron capture into 14O, which then undergoes β + degradation back down to 14N. If there are too many electrons present at late times ( due to an overabundance of 13N ), they will be captured onto protons instead of being emitted as positrons ; thus, less energy will be released than if no such process were occurring.Our results suggest that the current uncertainty in the 12C ( p, γ ) 13N rate may cause errors in the predicted luminosity of up to 50 %."
    },
    {
        "original_text": "The Catalogue Archive and Transmission System (CATS) is an archive for astronomical data, which was established in 1988 by the National Astronomical Observatory of Japan (NAOJ). The main purpose of this system is to provide efficient access to astronomical data obtained at Japanese observatories. In addition, it provides services such as data distribution via FTP or HTTP protocols, data processing using remote computers, and data analysis tools on its web site. Since its establishment, CATS has been used widely not only within NAOJ but also outside NAOJ. Currently there are more than 1 million objects registered with CATS. This article describes how CATS works and what kind of information can be found in CATS. It also discusses some future plans for CATS. The Catalogue Archive and Transmissions System (CATS; Sugimoto et al., 2002 ) is an archive for astronomic data that was established in 1988 by National Astronomical Observatory of Japan(NAOJ; Okumura & Nakamura, 1997) . Its main purpose is to provide efficient accesses to astronomical data obtained mainly at Japanese observatories . In addition , it provides various kinds of services including data distribution through FTP/HTTP protocol , data processing using remote computers , and data analysis tools on their website .\nSince its establishment , CATS have been used widely both inside and outside NAOJ . Currently there are over one million objects registered with CATs . This article describes how CATs works and what kind of informations we can find in CATS . We will discuss about our future plan for CATS .",
        "watermark_text": "The Catalogue Archive and Transmission System ( CATS ) is an archive for astronomical data, which was established in 1988 by the National Astronomical Observatory of Japan ( NAOJ ).The main purpose of this system is to provide efficient access to astronomical data obtained at Japan observatories.In addition, it provides services such as data distribution via FTP or HTTP protocols, data processing utilizing remote computers, and data analysis tools on its website site.Since its establishment, CATS has been used widely not only within NAOJ but even outside NAOJ.Currently there are more than 1 million objects registered with CATS.This article describes how CATS works and what type of information can be found in CATS.It also discusses some future plans for CATS.The Catalogue Archive and Transmissions System ( CATS ; Sugimoto et al., 2002 ) is an archive for astronomic data that was established in 1988 by National Astronomical Observatory of Japanese ( NAOJ ; Okumura & Nakamura, 1997 ).Its main purpose is to give efficient accesses to astronomical data obtained mainly at Japanese observatories.In addition, it offers various types of services like data distribution through FTP / HTTP protocol, data processor using remote computers, and data analysis tools on their site.Since its establishment, CATS have been used extensively both indoor and outside NAOJ.Currently there are over 1 million objects registered with CATs.This article describes how CATs works and what kind of informations we can find in CATS.We will discuss about our next plan for CATS."
    },
    {
        "original_text": "We present an analysis of the worst-case time complexity for inserting n elements into a binary search tree using the Fibonacci-heap data structure, which is based on the so-called \"Young-Fibonacci insertions\". We show that this algorithm has O(n log n) worst-case running time and thus improves upon previous results by Chan et al., who showed that it takes at least Ω(n2/3) time to perform these operations in the worst case. The main idea behind our proof is to use amortized analysis techniques to bound the number of times we have to update the heap's size during each step of the algorithm. This allows us to prove that the total cost incurred over all steps is bounded by O(n log n). In addition, we also provide experimental evidence showing that our theoretical bounds are tight up to constant factors. \nIntroduction\n\nThe Fibonacci-heap data type was introduced by Fredman and Tarjan [FT86] as part of their work on efficient algorithms for finding minimum spanning trees (MSTs), shortest paths, and other related problems. It consists of a rooted binary tree with two additional fields associated with every node: its parent pointer and its rank value. Every node stores pointers to its left child and right child nodes; however, unlike ordinary binary trees, there can be more than one node with the same key stored under any given node. Each node maintains a counter called its rank, which indicates how many keys equal to or less than the key of the current node exist below it; if no such key exists then the rank field contains zero. \n \n For example, consider the following Fibonacci-heap storing the values 1 through 5:",
        "watermark_text": "We present an analysis of the worst - case time complexity for inserting n elements into a binary search tree using the Fibonacci - heap data structure, which is based on the so - called \" Young - Fibonacci insertions \".We show that this algorithm has O ( n log n ) worst - case running time and thus improves upon previous findings by Chan est al., who demonstrated that it takes at least [UNK] ( n2 / 3 ) time to perform these operations in the worst case.The main idea behind our proof is to utilize amortized analytical techniques to bound the number of occasions we have to update the heap ' s size during each stage of the algorithm.This allows us to prove that the total expense incurred over all steps is bounded by O ( n log n ).In addition, we also offer experimental evidence showing that our theory bounds are tight up to constant factors.Introduction The Fibonacci - heap data type was introduced by Fredman and Tarjan[ FT86 ] as part of their work on efficient algorithms for finding minimum spanning trees ( MSTs ), shortest paths, and other related problems.It consists of a rooted binary tree with two additional fields associated with every node : its root pointer and its rank value.Every node stores pointers to its left child and right kid nodes ; however, unlike normal binary trees, there can be more than one node with the same key stored under any given node.Each node maintains a counter called its rank, which indicates how many keys equivalent to or less than the key of the current node exist below it ; if no such key exists then the rank field contains zero.For example, consider the following Fibonacci - heap storing the values 1 through 5 :"
    },
    {
        "original_text": "We propose that the cosmic acceleration data can be explained by bulk-brane energy exchange between branes in higher dimensions, which is similar to the dark matter effect on our universe. We show how this mechanism works for both open and closed universes with positive cosmological constant. The model predicts an accelerating expansion rate at late time as well as a decelerated one at early times. This prediction agrees very well with current observations. In addition, we find that the present value of the Hubble parameter H0 = 72 ± 8 km s-1 Mpc-1 is consistent with recent measurements. Finally, we discuss some possible tests of the theory using future experiments such as SNAP satellite project. Introduction:-The discovery of accelerated expansion of the universe has been made recently [1] . It was found that the universe expands faster than expected if it were dominated only by normal matter [2] , so there must exist another component called \"dark energy\" [3] - [6] responsible for the observed phenomenon. However, the nature of dark energy remains unknown. Many models have been proposed to explain its origin [7] - [11] .\nIn this letter, we will consider a new approach based on the idea of extra dimensions [12] - [14] . According to these theories, our four-dimensional world may live on a three-dimensional surface (3-brane) embedded in a five dimensional space-time (bulk). If gravity propagates into the bulk then it could affect the motion of particles living on the 3-brane [15] - [17] . For example, if the gravitational field of a distant galaxy lives outside the 3-brane but inside the bulk, then its gravitational force would act upon us even though the galaxy itself does not appear directly in front of us [18] . Thus, the presence of extra dimensions leads to additional effects beyond those predicted by general relativity [19] - [21] .",
        "watermark_text": "We propose that the cosmic acceleration data can be explained by bulk - brane energetic exchange between branes in upper dimensions, which is similarly to the dark matter effect on our universe.We show how this mechanism works for both open and closed universes with positive cosmological constant.The model predicts an accelerating growth rate at late time as well as a decelerated rate at early times.This prediction agrees very well with current observations.In addition, we find that the present value of the Hubble parameter H0 = 72 ± 8 km s - 1 Mpc - 1 is consistent with recent measurements.Finally, we discuss some possible tests of the theory using future experiments such as SNAP satellite project.Introduction : - The discovery of accelerated expansion of the universe has been made lately [ 1 ].It was found that the universe expands faster than expected if it were dominated only by normal matter [ 2 ], so there must exist another component called \" dark energy \"[ 3 ] - [ 6 ] responsible for the observed phenomenon.However, the nature of dark energy remains unknown.Many models have been proposed to explain its origin[ 7 ] -[ 11 ].In this letter, we will consider a new approach based on the idea of extra dimensions[ 12 ] - [ 14 ].According to these theories, our four - dimensional world might live on a three - dimensional surface ( 3 - brane ) embedded in a 5 dimensional space - time ( bulk ).If gravity propagates into the bulk then it could affect the motion of particles living on the 3 - brane[ 15 ] -[ 17 ].For example, if the gravitational field of a distant galaxy lives outside the 3 - brane but inside the bulk, then its gravitational force would act upon us even though the galaxy itself does not appear directly in front of us[ 18 ].Thus, the presence of extra dimensions leads to additional affects beyond those predicted by general relativity[ 19 ] -[ 21 ]."
    },
    {
        "original_text": "We study the gravitational field generated by a massive scalar point source moving on an equatorial circular geodesic around a Schwarzschild black hole, and we evolve it numerically in two spatial dimensions (2+1) with the puncture method. We find that the perturbation is dominated by a single mode which grows exponentially as time goes on. The growth rate agrees well with the prediction based on quasinormal modes for this system. This result suggests that the exponential growth may be related to the instability of the scalar field near the horizon. In addition, we also show that the amplitude of the growing mode decreases rapidly when the mass of the scalar field increases. Finally, we discuss possible applications of our results to astrophysical phenomena such as gamma-ray bursts. \n \n Introduction \n \n Black holes are among the most fascinating objects predicted by general relativity. They have been studied extensively both theoretically and observationally over many decades [1] . One important aspect of their physics concerns how particles move close to them [2] , especially those that can escape from the black hole's gravity [3] . It has recently become clear that there exist some interesting physical processes taking place very close to the event horizon [4] - [6] . For example, if one considers a charged particle falling into a Reissner-Nordström black hole, then its motion will be unstable due to the so-called \"photon sphere effect\" [7, 8] . If the charge of the particle is sufficiently large, then the particle will eventually fall into the black hole after emitting photons [9] . Another interesting phenomenon occurs when a neutral particle falls into a Kerr black hole [10] . Here again, the motion becomes unstable because of the existence of the photon sphere [11] . However, unlike the case of a Reissner-Norström black hole, the emitted radiation now contains not only photons but also gravitons [12] . \n \n In recent years, much attention has been paid to studying the dynamics of fields outside black holes [13] - [17] . In particular, the problem of finding the spectrum of quasi-normal modes (QNMs), i.e., the characteristic frequencies at",
        "watermark_text": "We study the gravity field generated by a massive scalar point source moving on an equatorial circular geodesic around a Schwarzschild black hole, and we evolve it numerically in two spatial dimensions ( 2 + 1 ) with the puncture method.We find that the perturbation is dominated by a single mode which growth exponentially as rate goes on.The growth rate agrees well with the prediction based on quasinormal modes for this system.This result suggests that the exponential growth may be related to the instability of the scalar field near the horizon.In addition, we also show that the amplitude of the growing mode decreases rapidly when the mass of the scalar field increases.Finally, we discuss potential applications of our results to astrophysical phenomena such as gamma - ray bursts.Introduction Black holes are among the most fascinating objects predicted by general relativity.They have been studied extensively both theoretically and observationally over many decades [ 1 ].One important aspect of their physics concerns how particles move close to them [ 2 ], especially those that can escape from the black hole ' s gravity [ 3 ].It has recently become clear that there exist some interesting physical processes taking place very close to the event horizon[ 4 ] - [ 6 ].For example, if one considers a charged particle falling into a Reissner - Nordström black hole, then its motion will be instability due to the so - called \" photon sphere effect \"[ 7, 8 ].If the charge of the particle is sufficiently big, then the particle will eventually fall into the black hole after emitting photons [ 9 ].Another interesting phenomenon occurs when a neutral particle falls into a Kerr dark hole[ 10 ].Here again, the motion becomes unstable because of the existence of the photon sphere [ 11 ].However, unlike the case of a Reissner - Norström black hole, the emitted radiation now contains not only photons but also gravitons[ 12 ].In recent years, much attention has been paid to studying the dynamics of fields besides black holes [ 13 ] - [ 17 ].In particular, the problem of finding the spectrum of quasi - normal modes ( QNMs ), i. e., the characteristic frequencies at"
    },
    {
        "original_text": "We present an analysis of user attention to tags and resources in collaborative tagging communities, based on the data collected by Delicious.com over three years (2005-2007). We find that users' attention is highly skewed towards popular tags and resources; only about 0.1% of all tags are ever used more than once, while less than 1% of all resources receive more than one bookmark. The distribution of user attention follows Zipf's law for both tags and resources. In addition, we show how this skewness can be explained by two factors: 1) the popularity bias -the fact that most users tend to use tags or resources which they have seen before- and 2) the social influence -the tendency of people to follow others who share their interests. Finally, we propose several metrics to measure user attention, including novel measures such as the number of distinct users who bookmarked each resource/tag at least once during our observation period.",
        "watermark_text": "We present an analysis of user attention to tags and resources in collaborative tagging communities, based on the data collected by Delicious. com over three years ( 2005 - 07 ).We find that users ' attention is highly skewed towards popular tags and resources ; only about zero. 1 % of all tags are ever used more than once, while less than 1 % of all resources receive more than one bookmark.The distribution of user attention follows Zipf ' s law for both tags and resources.In addition, we show how this skewness can be explained by 2 factors : 1 ) the popularity prejudice - the fact that most users tend to use tags or resources which they have seen before - and 2 ) the socio influence - the tendency of people to follow others who share their interests.Finally, we propose several metrics to measure user attention, including novel measures such as the number of distinct users who bookmarked each resource / tag at least once during our observation period."
    },
    {
        "original_text": "BiFeO3 is an antiferromagnetic insulator with high Curie temperature (TC = 1103 K) that exhibits ferroelectricity at room temperature when doped or under pressure. Here we report the observation of spontaneous magnetization, M(T), and electrical polarization, P(E), simultaneously existing over wide ranges of temperatures up to 300 K in pure BiFeO3 single crystal grown by flux method. The results show that both M(T) and P(E) are nearly independent on each other below TC but they start to decrease rapidly above TC. We also found that the magnitude of M(T) decreases faster than that of P(E). These observations suggest that there exists strong coupling between spin and lattice degrees of freedom in this material. \n \n Keywords: Room-temperature multiferroic materials, BiFeO3, Electric polarization, Magnetic properties, Flux growth technique.",
        "watermark_text": "BiFeO3 is an antiferromagnetic insulator with highly Curie temperature ( TC = 1103 K ) that exhibits ferroelectricity at room temperature when doped or under pressure.Here we report the observation of spontaneous magnetization, M ( T ), and electrical polarization, P ( E ), simultaneously existing over wide ranges of temperatures up to 300 K in pure BiFeO3 single crystal grown by flux method.The results show that both M ( T ) and P ( E ) are nearly independent on each other below TC but they begin to decrease rapidly above TC.We also found that the magnitude of M ( T ) decreases faster than that of P ( E ).These observations suggest that there exists strong coupling between spin and lattice degrees of attention in this material.Keywords : Room - temperature multiferroic materials, BiFeO3, Electric polarization, Magnetic properties, Flux growth technique."
    },
    {
        "original_text": "We report the discovery of transient dust emission at mid-infrared wavelengths (5-20 microns) in two elliptical galaxies with active galactic nuclei (AGN). The observations were made using Spitzer Space Telescope's Infrared Array Camera and Multiband Imaging Photometer for Spitzer instruments over a period of several years. We find that the infrared luminosity is consistent with heating by AGN radiation or supernovae remnants within the central kpc region. This suggests that recent feedback energy release has been occurring in these cores. These results are important because they provide new evidence on how supermassive black holes grow through accretion onto their host galaxy centers. They also demonstrate the power of combining multiwavelength data to study the physical processes associated with nuclear activity. \n \n Keywords: Active galactic nucleus, Galaxy evolution, Mid-infrared, Nuclear starbursts \n \n 1. Introduction \n \n Supermassive black holes reside in the center of most massive galaxies. Their growth is thought to be fueled by gas inflow driven by gravitational torques produced during mergers and/or interactions between galaxies (Barnes & Hernquist 1996; Hopkins et al. 2006) . However, it remains unclear what happens after this fuel supply runs out. One possibility is that the black hole continues growing via radiatively inefficient accretion flows (Narayan & Yi 1994) , which may produce powerful winds and jets that can drive large-scale outflows into the surrounding interstellar medium (ISM) (Silk & Rees 1998; Di Matteo et al. 2005 ). Another possibility is that the black holes become dormant as the ISM becomes too hot to cool efficiently (Bower et al. 2006; Croton et al. 2006 ) until another merger event triggers renewed activity. Understanding the mechanisms responsible for shutting off black-hole growth will help us understand why some galaxies have large black holes while others do not. \n \n 2. Previous Work \n \n Several studies have shown that there exists an anti-correlation between the mass of the central supermassive black hole and the stellar velocity dispersion of its host galaxy bulge (Ferrar",
        "watermark_text": "We report the discovery of transient dust emission at medium - infrared wavelengths ( 5 - 20 microns ) in two elliptical galaxies with active galactic nuclei ( AGN ).The observations were made utilizing Spitzer Space Telescope ' s Infrared Array Camera and Multiband Imaging Photometer for Spitzer instruments over a period of several years.We find that the infrared luminosity is consistent with heating by AGN radiation or supernovae remnants within the central kpc region.This suggests that recent feedback energy release has been occurring in these cores.These results are important because they offer new proof on how supermassive dark holes grow through accretion upon their host galaxy centers.They also demonstrate the power of combining multiwavelength data to study the physical processes associated with nuclear activity.Keywords : Active galactic nucleus, Galaxy evolution, Mid - infrared, Nuclear starbursts 1. Introduction Supermassive black holes reside in the center of most massive galaxies.Their growth is thought to be fueled by gas inflow powered by gravitational torques produced during mergers and / or interactions between galaxies ( Barnes & Hernquist 1996 ; Hopkins et al. 2006 ).However, it remains unclear what happens after this fuel supply runs out.One possibility is that the black hole keeps growing via radiatively inefficient accretion flows ( Narayan & Yi 1994 ), which might produce powerful winds and jets that can drive large - scale outflows into the surrounding interstellar medium ( ISM ) ( Silk & Rees 1998 ; Di Matteo et al. 2005 ).Another possibility is that the black holes become dormant as the ISM gets too hot to cool efficiently ( Bower et al. 2006 ; Croton et al. 2006 ) until another merger event triggers renewed activity.Understanding the mechanisms responsible for shutting off black - hole growth will help us understand why some galaxies have large black holes while others do not.2.Previous Work Several studies have shown that there exists an anti - correlation between the mass of the central supermassive black hole and the stellar velocity dispersion of its host galaxy bulge ( Ferrar"
    },
    {
        "original_text": "We present the results of collisional modelling for two spatially resolved debris discs, HD 69830 and AU Mic. We find that collisions are efficient at producing dust particles with sizes ranging between 1 mm to 10 cm across most of these systems. The observed radial profiles can be reproduced by assuming an initial power-law grain-size distribution with index -3.5 (consistent with theoretical predictions) and allowing it to evolve under mutual collisions over timescales of several million years. In addition we show how our models can reproduce the observed colour gradients seen in both systems. Finally, we discuss possible implications of this work on the formation mechanisms of planetesimals and planets. Keywords: Debris discs - Collisions - Grain growth - Planets - Spatially resolved observations - Sizesize distributions - Dust grains - Asteroids - Cometary nuclei - Circumstellar disks - Planet formation",
        "watermark_text": "We present the results of collisional modelling for two spatially resolution debris disks, HD 69830 and AU Mic.We find that collisions are efficient at producing dust particles with sizes ranging between 1 millimetres to 10 cm across most of these systems.The observed radial profiles can be reproduced by assuming an initial power - law grain - size distribution with index - 3. 5 ( consistent with theory predictions ) and allowing it to evolve under mutual collisions over timescales of several million years.In addition we show how our models can reproduce the observed colour gradients seen in both systems.Finally, we discuss possible implications of this work on the forming mechanisms of planetesimals and planets.Keywords : Debris discs - Collisions - Grain growth - Planets - Spatially resolved observations - Sizesize distributions - Dust grains - Asteroids - Cometary nuclei - Circumstellar disks - Planet formation"
    },
    {
        "original_text": "We present the first detection of cosmic rays confined within fossil radio plasma bubbles, using deep Chandra X-ray observations and VLA radio data for Abell 2052 (z = 0.0395). The bubble is located at the center of an elliptical galaxy with a prominent dust lane that extends to its nucleus. We find that the bubble has a radius of ~40 kpc and contains hot gas with T ~ 1 keV. This temperature is significantly lower than expected if the bubble were filled by shock-heated ICM. Instead we argue that the bubble is filled with relativistic particles accelerated by shocks driven into the surrounding medium during the formation of the central galaxy. These particles are responsible for the observed synchrotron emission detected on large scales around the bubble. In addition, we detect diffuse soft X-rays extending beyond the bubble's edge which may be due to thermal conduction or mixing between the bubble and the surrounding ICM.",
        "watermark_text": "We present the initial detection of cosmic rays confined within fossil radio plasma bubbles, utilizing deep Chandra X - ray observations and VLA radio data for Abell 2052 ( z = 0. 0395 ).The bubble is located at the center of an elliptical galaxy with a prominent dust lane that extends to its nucleus.We find that the bubble has a radius of ~ 40 kpc and contains hot gas with T ~ 1 keV. This temperature is significantly lower than expected if the bubble were filled by shock - heated ICM.Instead we argue that the bubble is filled with relativistic particles accelerated by shocks driven into the surrounding medium during the formation of the central galaxy.These particles are responsible for the measured synchrotron emission detected on big scales around the bubble.In addition, we detect diffuse soft X - rays extending beyond the bubble ' s edge which may be due to thermal conduction or mixing between the bubble and the surrounding ICM."
    },
    {
        "original_text": "We propose an algorithm to find optimal hierarchical descriptors (OHDs) that can be used as fingerprints in complex networks, such as social and biological systems. The OHDs represent network structures at different levels of granularity by using a tree-like structure with nodes representing subnetworks or clusters. We show how these trees can be constructed efficiently based on modularity maximization algorithms. In addition, we introduce a novel concept called \"clustering coefficient\" which is useful when constructing OHDs. Finally, we demonstrate our method through several examples including synthetic benchmark data sets and real-world networks. Our results suggest that the proposed approach provides more accurate descriptions than existing methods. This work was supported by JSPS KAKENHI Grant Number JP26287040. Keywords: Hierarchical descriptor, Clustering coefficient, Modularity Maximization Algorithm, Tree Structure, Fingerprint, Network Description",
        "watermark_text": "We propose an algorithm to find optimal hierarchical descriptors ( OHDs ) that can be utilized as fingerprints in complex networks, such as social and biological systems.The OHDs represent network structures at different levels of granularity by using a tree - resembling structure with nodes representing subnetworks or clusters.We show how these trees can be constructed efficiently based on modularity maximization algorithms.In addition, we introduce a novel concept called \" clustering coefficient \" which is useful when constructing OHDs.Finally, we demonstrate our method through several examples including synthetic benchmark data sets and real - world networks.Our results suggest that the proposed approach provides more accurate descriptions than existing methods.This work was supported by JSPS KAKENHI Grant Number JP26287040.Keywords : Hierarchical descriptor, Clustering coefficient, Modularity Maximization Algorithm, Tree Structure, Fingerprint, Network Description"
    },
    {
        "original_text": "We study how galactic discs warp in response to tidal forces exerted by dark matter haloes and intergalactic gas filaments, using high-resolution cosmological simulations with radiative cooling and star formation. We find that the majority (>80%) of simulated galaxies have significant warping at z = 0. The amplitude of the warp increases with decreasing galaxy mass, but is independent of redshift for massive galaxies. Warp amplitudes are typically less than 10 kpc, which agrees well with observations. Our results suggest that most observed warps can be explained as being caused by external gravitational torques on galactic discs. This implies that there may not exist any intrinsic mechanism within galactic discs themselves that causes warps. In addition, we show that the presence of an AGN does not significantly affect the shape or strength of the warp. Finally, we demonstrate that our model predicts a correlation between the direction of the warp and the angular momentum vector of the host halo.",
        "watermark_text": "We study how galactic discs warp in response to tidal pressures exerted by dark material haloes and intergalactic gas filaments, using high - resolution cosmological simulations with radiative cooling and star formation.We find that the majority ( > 80 % ) of simulated galaxies have significant warping at z = zero.The amplitude of the warp increases with reducing galaxy mass, but is independent of redshift for massive galaxies.Warp amplitudes are typically less than 10 kpc, which agrees well with observations.Our results suggest that most observed warps can be explained as being caused by external gravitational torques on galactic discs.This implies that there might not exist any intrinsic mechanism inside galactic discs themselves that causes warps.In addition, we show that the presence of an AGN does not significantly affect the shape or strength of the warp.Finally, we demonstrate that our model predicts a correlation between the direction of the warp and the angular momentum vector of the host halo."
    },
    {
        "original_text": "We study the distribution of the total area swept out by a one-dimensional Brownian motion between two fixed times. We show that this distribution is given by an explicit formula involving the modified Bessel function I0(x). This result can be used to derive several interesting identities for special functions such as the Riemann zeta-function or the Hurwitz zeta-functions at even arguments. In particular we obtain new proofs of some results due to Wright on the number of graphs with n vertices having certain properties (such as being bipartite) which are related to the coefficients appearing in the expansion of the exponential generating function of these numbers into powers of t. Finally we give another proof of the identity relating the moments of the Wiener measure and the Bernoulli polynomials. The main tool will be the Feynman-Kac representation of the solution of the heat equation. Let Wt denote standard Brownian motion starting at 0. For any real number s > 0 let us consider the random variable A(s), defined as the total area swept out during the time interval [0,s] by the process Wt:",
        "watermark_text": "We study the distribution of the total area swept out by a 1 - dimension Brownian motion between two fixed times.We show that this distribution is given by an explicitly formula involving the modified Bessel function I0 ( x ).This result can be used to derive several interesting identities for special functions such as the Riemann zeta - function or the Hurwitz zeta - functions at even arguments.In particular we obtain new proofs of some results due to Wright on the number of graphs with n vertices having certain properties ( such as being bipartite ) which are related to the coefficients appearing in the expansion of the exponential generating function of these numbers into powers of t.Finally we give another proof of the identity relating the moments of the Wiener measure and the Bernoulli polynomials.The main tool will be the Feynman - Kac representation of the solution of the heat equation.Let Wt denote standard Brownian motion starting at 0.For any real number s > 0 let us consider the random variable A ( s ), defined as the total area swept out during the time interval [ 0, s ] by the process Wt :"
    },
    {
        "original_text": "We study the dynamics of the kinetic Ising model on square lattices with periodic boundary conditions by Monte Carlo simulations at finite temperatures T . We find that there is no static order parameter to characterize the dynamic phase transition, but we can define an effective conjugate field H conjugate to the magnetization M as follows: \nH = -ln(<M>)/T,\nwhere <M> denotes the average over all spins. The critical temperature Tc is determined by the condition dH/dT =0. In addition, we show that the fluctuation-dissipation theorem holds well near Tc. \nThe results are compared with those obtained by the mean-field approximation. \n\n\nI. INTRODUCTIO N\n\nIn recent years much attention has been paid to nonequilibrium phenomena such as relaxation processes after rapid changes of external parameters [1] , aging [2] , glassy behavior [3] , etc., because they play important roles not only in physics but also in biology [4] .\nAmong these topics, the kinetic Ising model [5] is one of the most popular models used to investigate non-equilibrium properties [6] . It describes the time evolution of spin variables S i (t) (i=1,...,N)\non a regular lattice under the influence of thermal fluctuations. Here t represents the number of Monte Carlo steps per site (MCS/s). At each step, every spin interacts with its nearest neighbors through exchange interactions J ij . Then it flips according to the Metropolis algorithm [7]:  if e -Sij / kBT > random number between 0 and 1 then flip S j else keep S j unchanged where k B is Boltzmann's constant and T is the absolute temperature. This process continues until equilibrium is reached or some other criterion is satisfied [8] .",
        "watermark_text": "We study the dynamics of the kinetic Ising model on square lattices with periodic border conditions by Monte Carlo simulations at finite temperatures T.We find that there is no static order parameter to characterize the dynamic phase transition, but we can define an effective conjugate field H conjugate to the magnetization M as follows : H = - ln ( ) / T, where denotes the average over all spins.The critical temperature Tc is determined by the condition dH / dT = 0.In addition, we show that the fluctuation - dissipation theorem stands well near Tc.The results are compared with those obtained by the mean - field approximation.I. INTRODUCTIO NIn recent years much attention has been paid to nonequilibrium phenomena such as relaxation processes after rapid changes of outside parameters [ 1 ], aging [ 2 ], glassy behaviour [ 3 ], etc., because they play important roles not only in physics but also in biology [ 4 ].Among these topics, the kinetic Ising model [ 5 ] is 1 of the most popular models used to investigate non - equilibrium properties [ six ].It describes the temporal evolution of spin variables S i ( t ) ( i = 1,., N ) on a regular lattice under the influence of thermal fluctuations.Here t represents the number of Monte Carlo steps per site ( MCS / s ).At each step, every spin interacts with its closest neighbors through exchange interactions J ij.Then it flips according to the Metropolis algorithm[ 7 ] : if e - Sij / kBT > random number between 0 and 1 then flip S j else keep S j unchanged where k B is Boltzmann ' s constant and T is the absolute temperature.This process continues until equilibrium is reached or some other criterion is satisfied [ 8 ]."
    },
    {
        "original_text": "Leopold Kronecker (1823-1901) est un mathématicien allemand qui s'est intéressé à la théorie des nombres, aux fonctions elliptiques ainsi qu'à l'algèbre linéaire. Il fut l'un des principaux fondateurs du groupe Bourbaki en 1934 avec André Weil, Jean Delsarte, René Decartes, Nicolas Bourbaki, Jean Dieudonné, Claude Chevalley, Élie Cartan, Jean-Louis Koszul, Samuel Eilenberg et Jacques-Louis Lions. En 1873, il publie dans le Journal für die reine und angewandte Mathematik une série d'articles sur les algèbres associatives et non associatives. Dans son article intitulé « Ueber die Theorie der endlichen Gruppen von Variabeln » [Kronecker, L., Ueber die Theorie der Endlichen Gruppen von Varien, JFM 5.2 (1875), p. 1–42], il introduit pour la première fois la notion d'algèbre associative finie.",
        "watermark_text": "Leopold Kronecker ( 1823 - 1901 ) est un mathématicien allemand qui s ' est intéressé à la théorie des nombres, aux fonctions elliptiques ainsi qu ' à l ' algèbre linéaire.Il fut l ' un des principaux fondateurs du groupe Bourbaki en 1934 avec André Weil, Jean Delsarte, René Decartes, Nicolas Bourbaki, Jean Dieudonné, Claude Chevalley, Élie Cartan, Jean - Louis Koszul, Samuel Eilenberg et Jacques - Louis Lions.En 1873, il publie dans le Journal für die reine und angewandte Mathematik une série d ' articles sur les algèbres associatives und non associatives.Dans son article intitulé « Ueber die Theorie der endlichen Gruppen von Variabeln »[ Kronecker, L., Ueber die Theorie der Endlichen Gruppen von Varien, JFM 5. 2 ( 1875 ), p. 1 – 42 ], il introduit pour la première fois la notion d ' algèbre associative finie."
    },
    {
        "original_text": "The radial distribution of the inner magnetospheric (IM) plasma pressure is studied by analyzing the magnetic field and particle measurements made onboard two satellites at low altitude in the equatorial plane for an intense geomagnetic storm that occurred between March 1-5, 1982 . The results show that there are significant differences in the IM plasma pressure profiles obtained with different satellites. In particular, the pressure profile derived from GEOS-1 observations shows a sharp peak near L = 3 , while those inferred from ATS-6 and GEOS-2 data exhibit much broader peaks around L = 4 . These discrepancies may be due to the fact that these satellites have different orbits which sample different regions of space. It is also found that the pressure profiles inferred from the three satellites agree well when they are shifted outward along the L-shell coordinate system. This suggests that the observed difference in the pressure profiles can be attributed mainly to the spatial variation of the pressure rather than temporal changes.",
        "watermark_text": "The radial distribution of the inner magnetospheric ( IM ) plasma pressure is studied by analyzing the magnetic field and particle observations made onboard two satellites at low height in the equatorial plane for an intensified geomagnetic storm that occurred between March 1 - five, 1982.The results show that there are significant differences in the IM plasma pressure patterns obtained with different spacecraft.In particular, the pressure profile derived from GEOS - 1 observations shows a sharp peak around L = 3, while those inferred from ATS - 6 and GOS - two data exhibit much wider peaks around L = 4.These discrepancies may be due to the fact that these satellites have different orbits which sample different regions of space.It is also found that the pressure profiles inferred from the three satellites agree well when they are shifted outward along the L - shell coordinate system.This suggests that the observed difference in the pressure profiles can be attributed mainly to the space variation of the pressure instead than timing changes."
    },
    {
        "original_text": "We report on the detection by Fermi Large Area Telescope (LAT) of prompt emission in gamma rays with energies above 100 MeV associated with GRB 080916C, one of the brightest bursts ever detected at high energy. The LAT data show that this emission is highly variable and peaks within 1 s after the onset of the burst. We find no evidence for spectral evolution during the first few hundred seconds following the trigger time. A simple power law fit to the LAT spectrum yields an index of -2.2 +/-.1 over the range 100 MeV - 10 GeV. This value is consistent with previous measurements made using Konus-Wind and AGILE satellites but differs significantly from those obtained by other instruments operating below 100 MeV. Our results are inconsistent with models which predict a softening of the photon spectrum as it evolves into the X-ray band. They also rule out scenarios where the high-energy photons originate solely from inverse Compton scattering off relativistic electrons accelerated in internal shocks. \n \n Keywords: Gamma-ray burst",
        "watermark_text": "We report on the detection by Fermi Large Area Telescope ( LAT ) of prompt emission in gamma rays with energies above 100 MeV associated with GRB 080916C, one of the brightest bursts ever detected at high energy.The LAT data show that this emission is highly variable and spikes within one s after the onset of the burst.We find no evidence for spectral evolution during the first few hundred seconds following the trigger period.A simple power law fit to the LAT spectrum yields an index of - 2. 2 + / -. 1 over the range 100 MeV - 10 GeV.This value is consistent with previous measurements made using Konus - Wind and AGILE satellites but differs significantly from those obtained by other instruments operating below 100 MeV.Our results are inconsistent with models which predict a softening of the photon spectrum as it evolves into the X - ray band.They also rule out scenarios where the high - energetic photons originate solely from inverse Compton scattering off relativistic electrons accelerated in internal shocks.Keywords : Gamma - ray burst"
    },
    {
        "original_text": "We present new near-infrared (NIR) observations of the young stellar cluster IC 1396 N, located in the Orion Nebula Cluster region. The data were obtained with the adaptive optics system NAOS-CONICA on the VLT telescope and cover an area of 0.5 arcmin2 around the central star HD 37022. We detect more than 100 point sources down to Ks = 18 mag within this field-of-view. Using these data we have constructed colour-magnitude diagrams for different areas inside our field-of-view. From these CMDs we find that there are two populations of stars which can be separated by their position in the diagrams: one population is redder and fainter while another has bluer colours and brighter magnitudes. These results suggest that the first group consists mainly of low mass pre-main sequence stars surrounded by circumstellar disks, whereas the second group contains mostly high mass main-sequence stars without any surrounding material.",
        "watermark_text": "We present newly near - infrared ( NIR ) observations of the young stellar cluster IC 1396 N, located in the Orion Nebula Cluster area.The data were obtained with the adaptive optics system NAOS - CONICA on the VLT telescope and cover an area of 0. 5 arcmin2 round the central star HD 37022.We detect more than 100 point sources down to Ks = 18 mag within this field - of - view.Using these data we have constructed colour - magnitude diagrams for various areas within our field - of - view.From these CMDs we find that there are two populations of stars which can be segregated by their position in the diagrams : one population is redder and fainter while another has bluer colors and brighter magnitudes.These results suggest that the first group consists mainly of low mass pre - major sequence stars surrounded by circumstellar discs, whereas the second one contains mostly high mass main - lines stars without any surrounding material."
    },
    {
        "original_text": "We present optical and near-infrared photometry of SN 2006bp, which was discovered on September 24th in NGC 6946 by amateur astronomer Brian Puckett (Puckett et al., 2007) . The supernova is located at an unusually large distance for its host galaxy, with a recession velocity of ~1000 km/sec. \n \n We find that the light curve can be well fit using a model consisting of three components: shock breakout emission, radioactive decay powered luminosity, and dust extinction. Using this model we derive physical parameters such as the progenitor radius, mass loss rate, and explosion energy. Our results are consistent with those found for other type-II SNe but suggest that the progenitor star had a lower initial mass than previously thought. This may indicate that there exists more diversity among progenitors of type-II SNe than has been realized so far. In addition to these findings, our observations provide new insights into the physics of shock breakout and early-time evolution of type-II SNe.",
        "watermark_text": "We present optical and near - infrared photometry of SN 2006bp, which was discovered on September 24th in NGC 6946 by amateur astronomer Brian Puckett ( Puckett et al., 2007 ).The supernova is located at an unusually large distance for its host galaxy, with a recession velocity of ~ 1000 km / sec.We find that the light curve can be good fit using a representation consisting of 3 components : shock breakout emission, radiation decay powered luminosity, and dust extinction.Using this model we derive physical parameters such as the progenitor radius, mass lost rate, and explosion energetic.Our results are consistent with those found for other type - II SNe but suggest that the progenitor star had a lower initial mass than previously thought.This may indicate that there remains more diversity amongst progenitors of type - II SNe than has been realized so far.In addition to these findings, our observations provide new insights into the physics of shock breakout and early - time evolution of type - II SNe."
    },
    {
        "original_text": "We present the results for the ground state energy and wave function obtained by solving numerically the Schrödinger equation with the potential V (r) = -1/(1+ar). The numerical solution is performed using the method based on the expansion in terms of B-splines, which allows to obtain very accurate results even if only few spline functions are used. We compare our results with those obtained within the framework of the variational approach. In particular we show that the use of the so-called \"symmetric heavy-light ansatz\" leads to an overestimation of the binding energies. \n \n Introduction \n \n In this work we consider the problem of finding the bound states of a particle moving in one dimension under the action of a short-range attractive interaction described by the following potential: \n \n \n \n V(x)=−V0 / [1+a x] , where V0 > 0 . \nThe corresponding Schrödinger equation reads as follows: \n \n Hψn = E n ψn , where H = − d 2 dx2 + V(x) , n denotes the quantum number associated with the radial part of the wavefunction and En its corresponding eigenvalue.",
        "watermark_text": "We present the results for the ground state energy and wave function obtained by solving numerically the Schrödinger equation with the potential V ( r ) = - 1 / ( 1 + ar ).The numerical solution is performed using the method based on the expansion in terms of B - splines, which allows to obtain very accurate results even if only few spline functions are used.We compare our results with those obtained within the frame of the variational approach.In particular we show that the use of the so - called \" symmetry heavy - light ansatz \" leads to an overestimation of the bonding energies.IntroductionIn this work we consider the problem of finding the bound states of a particle moving in one dimension under the action of a short - range attractive interface described by the following potential : V ( x ) = −V0 /[ 1 + a x ], where V0 > 0.The corresponding Schrödinger equation reads as follows : Hψn = E n ψn, where H = − d 2 dx2 + V ( x ), n denotes the quantum number associated with the radial part of the wavefunction and En its corresponding eigenvalue."
    },
    {
        "original_text": "The geometry of time is the study of how space-time evolves in time.  The axiom of choice states that for any collection of non-empty sets there exists at least one set which contains exactly one element from each set.   In this article we show that if the universe has an underlying quantum structure then it follows that the geometry of time can be described by using the axiom of choice to select a single point on every trajectory through spacetime.   We also discuss some possible implications of our results for neurobiology where the quantum Zeno effect may play a role in explaining certain aspects of brain function such as consciousness. The geometry of time is the mathematical description of how space-time evolutes over time [1] . It was first introduced into physics by Hermann Minkowski [2] who showed that the geometry of space-time could be represented by four numbers (x,y,z,t) called coordinates or co-ordinates. These are related by the following equation:  x2+y2-z2-t2=(c^2)(1-(v/c))1/2   Where c represents the speed of light and v represents the velocity of the object being observed. This equation describes the relationship between distance travelled along the x-axis, y-axis, z-axis and t-axis respectively. For example, if you were observing someone walking across your living room floor with their back towards you they would have a positive value for the x-axis but no values for the other three axes because they are not moving in those directions. If however you were watching them walk away from you they would have negative values for all three axes except the x-axis since they are still travelling forward in that direction. As another example consider two objects traveling side-by-side down a roadway. They will both travel at the same speed so their velocities will be equal. However, if one car travels north while the other travels south they will appear to move faster than each other even though they are traveling at the same speed.",
        "watermark_text": "The geometry of time is the study of how space - periods evolves in time.The axiom of choice states that for any collection of non - empty sets there exists at minimum one one which contains exactly one element from each set.In this article we show that if the universe has an underlying quantum structure then it follows that the geometry of time can be described by using the axiom of choosing to select a single point on every trajectory through spacetime.We also discuss some possible implications of our results for neurobiology where the quantum Zeno effect may play a role in explaining certain aspects of brain function such as consciousness.The geometry of time is the mathematical description of how space - time evolutes over time [ 1 ].It was first introduced into physics by Hermann Minkowski[ 2 ] who showed that the geometry of space - time could be represented by four numbers ( x, y, z, t ) called coordinates or co - ordinates.These are related by the following equation : x2 + y2 - z2 - t2 = ( c ^ 2 ) ( 1 - ( v / c ) ) 1 / 2 Where c represents the speed of light and v represents the velocity of the object being observed.This equation describes the relationship between distance travelled along the x - axis, y - axis, z - axis and t - axes respectively.For example, if you were noticing someone walking across your living room floor with their back towards you they would have a positive value for the x - axes but no values for the other three axes because they are not moving in those directions.If however you were monitoring them walk away from you they would have negative values for all three axes except the x - axis since they are still travelling forward in that direction.As another example consider two objects traveling side - by - side down a road.They will both travel at the same velocity so their velocities will be equal.However, if one car travels north while the other travels south they will appear to move faster than each other regardless though they are traveling at the same faster."
    },
    {
        "original_text": "We report on an experiment to measure the Casimir-Lifhsztz (CL) interaction between two gold-coated glass plates immersed in water at room temperature and pressure. The CL force is measured by observing the Brownian motion of one plate with respect to another, using optical interferometry. We find that the magnitude of the observed effect agrees well with theoretical predictions based on Lifshitz theory for dielectrics. This work represents the first direct experimental observation of the CL force in a liquid medium. It also demonstrates how precision measurements can be used to test fundamental theories such as quantum electrodynamics. \n \n In recent years there has been considerable interest in measuring the Casimir-Lifhzsiz (CL) [1] force between macroscopic objects [2] . Such experiments are important because they provide tests of our understanding of vacuum fluctuations [3] , which play a central role in many areas of physics including quantum field theory [4] , statistical mechanics [5] , condensed matter [6] , atomic and nuclear physics [7] , cosmology [8] , and gravitation [9] .\n \nThe original prediction of the CL force was made more than 50 years ago [10] but it took until 1997 [11] before this attractive force could be directly detected experimentally [12] . Since then several groups have performed high-precision experiments [13] - [16] aimed at testing the validity of various aspects of the theory [17] - [20] . \n \n Here we present results obtained in a new experiment designed specifically to study the CL force in liquids [21] . Our approach involves immersing two parallel plates coated with thin layers of gold into distilled water contained inside a sealed container [22] . By monitoring the Brownian motion of these plates [23] we were able to determine their mutual attraction due to the presence of the surrounding water molecules [24] .",
        "watermark_text": "We report on an experiment to measure the Casimir - Lifhsztz ( CL ) interaction between two gold - coated glass plates immersed in water at room temperature and pressure.The CL force is measured by observing the Brownian motion of 1 plate with relation to another, using optical interferometry.We find that the magnitude of the detected effect agrees well with theoretical predictions based on Lifshitz theory for dielectrics.This work represents the first directly experimental observation of the CL force in a fluid medium.It also demonstrates how precision measurements can be used to test fundamental theories such as quantum electrodynamics.In recent years there has been considerable interest in measuring the Casimir - Lifhzsiz ( CL )[ 1 ] force between macroscopic objects [ 2 ].Such experiments are important because they provide tests of our understanding of vacuum fluctuations [ 3 ], which play a central role in much areas of physics including quantum field theory [ 4 ], statistical mechanics[ 5 ], condensed matter[ 6 ], atomic and nuclear physics[ 7 ], cosmology[ 8 ], and gravitation[ 9 ].The original prediction of the CL force was made more than 50 years earlier [ 10 ] but it took until 1997[ 11 ] before this attractive force could be directly detected experimentally[ 12 ].Since then several groups have performed high - accuracy experiments [ 13 ] - [ 16 ] aimed at testing the legitimacy of various aspects of the theory [ 17 ] - [ 20 ].Here we present outcomes obtained in a new experiment planned specifically to study the CL force in liquids [ 21 ].Our approach involves immersing 2 parallel plates coated with thin layers of gold into distilled water contained inside a closed container [ 22 ].By monitoring the Brownian motion of these plates [ 23 ] we were able to determine their mutual attraction due to the presence of the surrounding water molecules [ 24 ]."
    },
    {
        "original_text": "We present the first measurement of the supermassive black hole (SMBH) mass function for both early-(elliptical/S0, Sa-Sb) and latetype (Scd-Sm) galaxies using data from the Millennium Galaxy Catalogue (MGC). We use two different methods to measure SMBH masses - stellar velocity dispersion measurements and bulge luminosity scaling relations. Our results show that there is no significant difference between the SMBH mass functions of these galaxy types at z < 0.1. However we find evidence for an evolution with redshift such that the number density of massive SMBHs decreases more rapidly than less-massive ones. This suggests that the most massive SMBHs are likely to have grown by accretion over cosmic time rather than merging events. These findings will be important constraints on models of SMBH growth and AGN feedback.",
        "watermark_text": "We present the first measurement of the supermassive black hole ( SMBH ) mass function for both early - ( elliptical / S0, Sa - Sb ) and latetype ( Scd - Sm ) galaxies utilizing data from the Millennium Galaxy Catalogue ( MGC ).We utilize two different methods to measure SMBH masses - stellar velocity dispersion measurements and bulge luminosity scaling relations.Our results show that there is no significant difference between the SMBH mass functions of these galaxy kinds at z < zero. 1.However we find evidence for an evolution with redshift such that the number density of massive SMBHs decreases more rapidly than fewer - massive ones.This suggests that the most massive SMBHs are probable to have grown by accretion over cosmic time rather than merging events.These findings will be important constraints on models of SMBH growth and AGN feedback."
    },
    {
        "original_text": "We present infrared spectral energy distributions (SEDs) for a sample of 23 galaxies at redshifts 0.6 < z < 1.0, selected to have strong rest-frame ultraviolet emission lines and high star formation rates. The SEDs are derived using Spitzer Infrared Spectrograph observations in the 3.6 - 8 micron range combined with ground-based near-infrared spectroscopy covering the wavelength range between 0.9-2.5 microns. We use these data to derive stellar masses, ages, dust extinction values, and star-formation histories for each galaxy. Our results show that most of our objects are young systems with ages less than 100 Myr old; however we also find evidence for older populations in some cases. Most of the galaxies appear to be experiencing moderate levels of dust obscuration with A V ~ 1-3 mag., although there is significant scatter among individual objects.",
        "watermark_text": "We present infrared spectral energy distributions ( SEDs ) for a sample of 23 galaxies at redshifts 0. 6 < z < 1. 0, selected to have strong rest - frame ultraviolet emission lines and high star formation rates.The SEDs are derived using Spitzer Infrared Spectrograph observations in the 3. 6 - 8 micron region combined with ground - based near - infrared spectroscopy covering the wavelength region between 0. 9 - 2. 5 microns.We use these data to derive star masses, ages, dust extinction values, and star - forming histories for each galaxy.Our results show that most of our objects are young systems with ages less than 100 Myr age ; however we also find evidence for aging populations in some cases.Most of the galaxies appear to be experiencing moderate levels of dust obscuration with A V ~ 1 - three mag., although there is significant scatter among individual objects."
    },
    {
        "original_text": "The Large Area Telescope (LAT) on the Fermi Gamma-ray Space Telescope will be launched in June 2008, with an expected launch date of August 7, 2007.  The LAT is designed to detect gamma rays between 20 MeV and 300 GeV over a large field-of-view (2 steradians), making it possible for the first time to study the entire sky at these energies every three hours. This talk will discuss how supernova remnants are likely to appear as sources of high-energy emission when observed by this new instrument. In particular I will focus on:  - How many remnants should we expect to see? - What types of remnants might show up? - What can we learn about particle acceleration mechanisms? - What can we do to prepare for the observations? - Other topics that may come up during discussion. The Large Area Telescope (L AT ) on the Fermi Gamma-ray Sp ace T elescope w ill b e la unched i n J une 2 008 , wi th an ex pected l aunch d ate o f A ugust 7 , 2 007 .",
        "watermark_text": "The Large Area Telescope ( LAT ) on the Fermi Gamma - ray Space Telescope will be launched in June 2008, with an anticipated launch date of August 7, 2007.The LAT is designed to detect gamma rays between 20 MeV and 300 GeV over a large field - of - sight ( 2 steradians ), making it possible for the first time to study the entire sky at these energies every three hours.This talk will discuss how supernova remnants are likely to appear as sources of high - energetic emission when observed by this new instrument.In particular I will focus on : - How many remnants should we expect to see?- What types of remnants might show up?- What can we learn about particle acceleration processes?- What can we do to plan for the observations?- Other topics that may come up during discussion.The Large Area Telescope ( L AT ) on the Fermi Gamma - ray Sp ace T elescope w ill b e la unchedi n J une 2 008, wi th an ex pected l aunch d ate o f A ugust 7, 2 007."
    },
    {
        "original_text": "The human genome is organized into chromatin, which consists of DNA wrapped around histone proteins and other associated factors. The folding of the chromatin fiber plays an important role in regulating gene expression by controlling access of transcription machinery to genes. In this review we discuss recent advances on how chromatin folds at different levels (from single nucleosome to chromosome) and its relation with human genome function. We also introduce some new concepts such as \"topological domains\" and \"chromosome territories\" that are emerging from high-throughput technologies. Finally, we provide examples for future research directions. Chromatin is the basic unit of eukaryotic chromosomes consisting of DNA wrapped around histones and other associated factors. It has been shown that chromatin structure plays an important role in regulation of gene expression through control of accessibility of transcription machinery to genes [1] . Recent studies have revealed that chromatin fibers fold into higher-order structures ranging from 30 nm fibers [2] , loops [3] , topologically associating domains [4] , and chromosome territories [5] .\nIn this review, we will first briefly describe the organization of chromatin fibers at various scales. Then we will focus on the relationship between chromatin folding and human genome functions including gene regulation, replication, repair, and recombination. Finally, we will give several examples for possible future research directions.",
        "watermark_text": "The human genome is organized into chromatin, which consists of DNA wrapped round histone proteins and other associated factors.The folding of the chromatin fibre plays an influential role in regulating genetic expression by controlling access of transcription machinery to genes.In this review we discuss recent advances on how chromatin folds at different levels ( from single nucleosome to chromosome ) and its relation with human genome function.We also introduce some new concepts such as \" topological domains \" and \" chromosome territories \" that are arising from high - throughput technologies.Finally, we provide examples for future research directions.Chromatin is the basic unit of eukaryotic chromosomes consisting of DNA wrapped around histones and other related factors.It has been shown that chromatin shape plays an important role in regulation of gene expression through control of accessibility of transcription machines to genes [ 1 ].Recent studies have revealed that chromatin fibers fold into higher - order shapes ranging from 30 nm fibers [ 2 ], loops[ 3 ], topologically associating domains[ 4 ], and chromosome territories [ 5 ].In this review, we will first briefly describe the organisation of chromatin fibers at various scales.Then we will focus on the relation between chromatin folding and human genome functions including gene regulation, replication, repair, and recombination.Finally, we will give several examples for possible future research directions."
    },
    {
        "original_text": "The present work is an attempt to show that the concept of time can be extended into a higher-dimensional space, and that this extension may have important consequences for our understanding of physical phenomena.  The author considers the possibility that there are five dimensions of space (four ordinary spatial dimensions plus one extra temporal dimension) which could explain some of the observed properties of matter such as entropy production and irreversibility.   In particular he shows how the existence of these additional dimensions would lead to a violation of the principle of entropy increase with time, and suggests that this might provide a possible explanation for the arrow of time. This article is available from: http://arxiv.org/abs/astro-ph/0403070v1. Introduction:  Time has always been considered by physicists as being fundamentally different from other quantities like position or velocity because it cannot be measured directly but only inferred indirectly through its effects on other measurable quantities.  However, recent developments in theoretical physics suggest that we should consider whether the concept of time itself needs to be modified so that it becomes more closely related to other fundamental concepts such as mass, charge and energy.  For example, string theory predicts that all particles are vibrating strings moving along a multidimensional space called \"space-time\" [1] .    Another approach involves considering the possibility that time is not just another quantity but rather part of a larger structure known as spacetime [2] , where the latter consists of both space and time together [3] .  According to this viewpoint, time is no longer regarded as something separate from space; instead they are viewed as two aspects of the same thing [4] .\nIn fact, many modern theories of quantum gravity predict that the universe contains at least three large scale dimensions - namely length, width and height [5] - while also containing a fourth small-scale dimension [6] .",
        "watermark_text": "The present work is an attempt to show that the concept of time can be extended into a higher - dimensional space, and that this extension may have important consequences for our understanding of physical phenomena.The author considers the possibility that there are five dimensions of space ( four ordinary spatial dimensions plus one extra temporal dimensional ) which possible explain some of the observed properties of matter such as entropy production and irreversibility.In particular he shows how the existence of these additional dimensions would lead to a violation of the rule of entropy increase with time, and proposes that this might provide a possible explanation for the arrow of time.This article is available from : http : / / arxiv. org / abs / astro - ph / 0403070v1.Introduction : Time has always been considered by physicists as being fundamentally different from other quantities like position or velocity because it cannot be monitored directly but only inferred indirectly through its effects on other measurable quantities.However, recent developments in theoretical physics suggest that we should consider whether the concept of time itself needs to be modified so that it becomes more closely related to other fundamental concepts such as mass, charge and energy.For example, string theory predicts that all particles are vibrating strings moving along a multipledimensional space called \" space - time \" [ 1 ].Another approach involves considering the possibility that time is not just another quantity but rather component of a larger structure known as spacetime[ 2 ], where the latter consists of both space and temporal together [ 3 ].According to this viewpoint, time is no longer regarded as something separate from space ; rather they are viewed as 2 aspects of the same thing [ 4 ].In fact, many modern theories of quantum gravity predict that the universe contains at least three big scale dimensions - notably length, width and height[ 5 ] - while also containing a fourth small - scale dimension[ 6 ]."
    },
    {
        "original_text": "We report the distance measurement toward the Galactic center using Very Long Baseline Array (VLBA) observations at 22 GHz and 43 GHz in combination with Japanese VLBI Exploration of Radio Astrometry (VERA). The parallax was measured by observing Sgr A*, which is located near the Galactic center, for two years between 2007 and 2009. We found that the distance to the Galactic center is R0 = 8 kpc ± 0.4 kpc. This value agrees well with previous measurements based on other methods such as infrared photometry or trigonometric parallaxes of masers associated with massive young stars. Our result also supports the hypothesis that the Milky Way has an axisymmetric mass distribution around its central black hole. \n \n Keywords: Distance scale, Galaxy, Parallax, Space astrometry, Black holes \n \n \n \n 1 Introduction \n \n In order to understand how galaxies evolve over time, it is important to know their distances accurately. However, accurate distances are difficult to measure because they depend strongly on the assumed luminosity evolution model. For example, if we assume too high a rate of luminosity evolution, then the derived distance will be underestimated. On the other hand, if we assume too low a rate of luminosity evolu-tion, then the derived distance may be overestimated. Therefore, it is necessary to determine the correct luminosity evolution model before deriving the distance to any galaxy. \n \n One way to solve this problem is to use radio sources whose distances can be determined independently through other means. These include pulsars, quasars, and maser sources associated with star-forming regions. Among these objects, maser sources have been used most frequently since they provide very precise distance estimates. Maser sources are usually associated with star forming regions where water vapor molecules form into microscopic crystals known as ice grains. When the ice grains grow larger than about one micron, they become unstable against gravitational collapse and begin emitting intense radiation. Since the emission line widths of maser sources are extremely narrow compared to those of normal radio",
        "watermark_text": "We report the distance measurement toward the Galactic center using Very Long Baseline Array ( VLBA ) observations at 22 GHz and 43 GHz in combination with Japanese VLBI Exploration of Radio Astrometry ( VERA ).The parallax was measured by observing Sgr A *, which is situated near the Galactic center, for 2 years between 2007 and 2009.We found that the distance to the Galactic center is R0 = 8 kpc ± zero. Four kpc.This value agrees well with previous measurements based on other methodology such as infrared photometry or trigonometric parallaxes of masers associated with massive new stars.Our result also supports the hypothesis that the Milky Path has an axisymmetric mass distribution round its central dark hole.Keywords : Distance scale, Galaxy, Parallax, Space astrometry, Black holes 1 IntroductionIn order to understand how galaxies evolve over time, it is important to know their distances accurately.However, accurate distances are hard to measure because they depend strongly on the assumed luminosity evolutionary model.For example, if we assume too high a rate of luminosity evolution, then the extracted distance will be underestimated.On the other hand, if we assume too low a rate of luminosity evolu - tion, then the derived distance may be overestimated.Therefore, it is necessary to determine the correct luminosity evolution model before deriving the distance to any galaxy.One way to solve this problem is to utilize radio sources whose distances can be determined independently through other means.These include pulsars, quasars, and maser sources associated with star - forming regions.Among these objects, maser sources have been used most frequently since they provide very precise distance estimates.Maser sources are usually associated with star forming regions where water vapor molecules form into microscopic crystals known as ice grains.When the ice grains grow bigger than about one micron, they become instability against gravity collapse and begin emitting intense radiation.Since the emission line widths of maser sources are extremely narrow compared to those of normal radio"
    },
    {
        "original_text": "We study damage propagation in an interface between two ordered phases of the confined Ising model (CIM) with random fields and quenched disorder, which is known to undergo a localization-delocalization transition as its temperature T crosses Tc = 1. We show that this transition can be observed by measuring the average size of avalanches triggered by local perturbations. The results are compared with those for the unperturbed CIM obtained using Monte Carlo simulations on large lattices. In particular we find that the distribution of avalanche sizes changes drastically across the transition point. This behavior is explained within the framework of the mean-field theory developed recently for the CIM. Finally, we discuss possible experimental realizations of our system. Introduction:-The phenomenon of phase coexistence has been studied extensively both theoretically [1] - [4] and experimentally [5] . It occurs when different thermodynamic states coexist in equilibrium [6] , or metastable states exist simultaneously [7] . A typical example is provided by water [8] where ice Ih and liquid water co-exist below 0 o C [9] .\nIn recent years there have been several studies [10] - [12] devoted to understanding how interfaces separating different phases evolve under external driving forces such as thermal fluctuations [13] , magnetic field [14] , mechanical stress [15] etc.. These investigations were motivated mainly by experiments performed on various materials [16] including ferroelectrics [17] , ferromagnets [18] , superconductors [19] , colloids [20] , granular media [21] , glasses [22] , foams [23] , and biological systems [24] . For instance, it was found [25] that the dynamics of domain walls in magnets [26] depends crucially on whether they are pinned [27] or not [28] . Similarly, the response of glassy [29] and jammed [30] systems to shear stresses [31] strongly depends on their preparation history [32] . On the other hand, the effect of quenched disorder [33] on the properties of interfaces [34] remains poorly understood [35] despite numerous theoretical [36] [38] and numerical [39] attempts made over the past few decades.\nRecently, the problem of interface evolution attracted renewed interest due to the discovery of new types of transitions occurring in spatially extended systems [40] [41]:",
        "watermark_text": "We study damage propagation in an interface between two ordered phases of the confined Ising model ( CIM ) with randomly fields and quenched disorder, which is known to undergo a localization - delocalization transition as its temperature T crosses Tc = 1.We show that this transition can be observed by measuring the average size of avalanches triggered by local perturbations.The results are compared with those for the unperturbed CIM obtained utilizing Monte Carlo simulations on big lattices.In particular we find that the distribution of avalanche sizes changes drastically throughout the transition point.This behavior is explained within the framework of the mean - field theory developed recently for the CIM.Finally, we discuss possible experimental realizations of our system.Introduction : - Thephenomenon of phase coexistence has been studied extensively both theoretically[ 1 ] -[ 4 ] and experimentally[ 5 ].It occurs when different thermodynamic states coexist in equilibrium[ 6 ], or metastable states exist simultaneously [ 7 ].A typical example is provided by water[ 8 ] where ice Ih and liquid water co - exist below zero o C[ 9 ].In recent years there have been various studies [ 10 ] - [ 12 ] devoted to understanding how interfaces separating different stages evolve under outside driving forces such as thermal fluctuations [ 13 ], magnetic field[ 14 ], mechanical stress [ 15 ] etc.These investigations were motivated mainly by experiments performed on various materials [ 16 ] including ferroelectrics[ 17 ], ferromagnets[ 18 ], superconductors[ 19 ], colloids [ 20 ], granular media[ 21 ], glasses [ 22 ], foams [ 23 ], and biological systems[ 24 ].For instance, it was found [ 25 ] that the dynamics of domain walls in magnets[ 26 ] depends crucially on whether they are pinned [ 27 ] or not [ 28 ].Similarly, the response of glassy [ 29 ] and jammed [ 30 ] systems to shear stresses [ 31 ] strongly depends on their preparation record [ 32 ].On the other hand, the effect of quenched disorder[ 33 ] on the properties of interfaces [ 34 ] remains poorly understood [ 35 ] despite numerous theoretical [ 36 ] [ 38 ] and numerical [ 39 ] attempts made over the past few decades.Recently, the problem of interface evolution attracted renewed interest due to the discovery of new types of transitions occurring in spatially extension systems[ 40 ][ 41 ] :"
    },
    {
        "original_text": "We present new results on tidal tails around interacting galaxies using deep optical images taken with HST/ACS for two fields, GEMS (Galaxy Evolution from Morphology and SEDs) and GOODS (Great Observatories Origins Deep Survey). We find that about half of all interacting pairs show clear signs of tidal features such as bridges or tails. The fraction is higher than previous studies because we use much deeper data to detect faint structures. In addition, we identify star forming regions along the tails by measuring their UV-optical colors. About one third of our sample shows strong star formation activity at least 1 kpc away from the galaxy centers. These star bursting regions are found only in systems where both components have similar masses within a factor of 3. This suggests that these interactions trigger star formation over large scales. Finally, we compare the properties of tidal tails between different interaction stages.",
        "watermark_text": "We present new results on tidal tails around interacting galaxies using deep optical images taken with HST / ACS for two fields, GEMS ( Galaxy Evolution from Morphology and SEDs ) and GOODS ( Great Observatories Origins Deep Survey ).We find that about half of all interacting pairs show clear signs of tidal features such as bridges or tails.The fraction is higher than previous studies because we use much deeper data to detect faint structures.In addition, we identify star forming regions along the tails by measuring their UV - optical colors.About one third of our sample shows strong star forming activity at least 1 kpc away from the galaxy centers.These star bursting regions are found only in systems where both components have similar masses within a factor of three.This suggests that these interactions trigger star forming over large scales.Finally, we compare the properties of tidal tails between different interface stages."
    },
    {
        "original_text": "We study the dynamics of an interacting tachyonic field in a spatially flat Friedmann-Robertson-Walker universe with zero spatial curvature, using numerical methods to solve the equations of motion.  We find that there are two distinct phases during which the energy density evolves differently; one phase is dominated by the kinetic energy of the fields while the other is dominated by their potential energies.  The transition between these phases occurs when the Hubble parameter becomes comparable to the mass scale associated with the interaction term.  During this transition period we observe oscillatory behavior in both the Hubble parameter and the energy densities of each individual field.  In addition, we find that the total energy density decreases more slowly than it would if only one component were present (i.e., either a single tachyonic or a single scalar field).  Finally, we show how our results can be used to construct viable inflationary models. We consider a model consisting of a tachyonic field coupled to another scalar field through a quartic self-interaction term.  Using numerical techniques, we examine the time-evolution of various quantities such as the Hubble parameter, the energy densities of each field individually, and the total energy density.  Our analysis reveals several interesting features including the presence of a transition region where the Hubble parameter becomes comparable...",
        "watermark_text": "We study the dynamics of an interacting tachyonic field in a spatially flat Friedmann - Robertson - Walker universe with zero spatial curvature, using numerical methods to solution the equations of motion.We find that there are two distinct phases during which the energetic density evolves differently ; one stage is dominated by the kinetic energy of the fields while the other is dominated by their possible energies.The transition between these phases occurs when the Hubble parameter becomes comparable to the mass scale associated with the interaction term.During this transition period we observe oscillatory behavior in both the Hubble parameter and the energy densities of each individual field.In addition, we find that the total energy density decreases more slowly than it would if only one component were present ( i. ed., whether a single tachyonic or a single scalar field ).Finally, we show how our results can be used to construct feasible inflationary models.We consider a model consisting of a tachyonic field coupled to another scalar field through a quartic self - interaction term.Using numerical techniques, we examine the time - evolution of various quantities such as the Hubble parameter, the energy densities of each field separately, and the overall energy density.Our analysis reveals several interesting features including the presence of a transition region where the Hubble parameter becomes comparable."
    },
    {
        "original_text": "We report on the first mid-infrared (MIR) laser light nulling experiment with an integrated optics approach based on silicon-on-insulator technology and suspended core fibers. The experimental setup consists of two fiber-coupled MIR lasers, one for each arm of a Michelson interferometer. A pair of suspended-core fibers is used to couple the output beams into a 2x2 multimode interference coupler (MMI). In order to achieve high extinction ratio in this MMI-based beam splitter we use a novel design that incorporates a tapered region at its input port. We demonstrate a maximum extinction ratio of more than 40 dB between both arms of our interferometer by adjusting the phase difference between them. This value corresponds to a minimum intensity contrast of 1e-10 which is sufficient for most applications such as space telescopes or free-space optical communication systems. Finally, we show how the performance can be further improved by optimizing the coupling efficiency through the suspended-core fibers.",
        "watermark_text": "We report on the first mid - infrared ( MIR ) laser light nulling experiment with an integrated optics approach based on silicon - on - insulator technology and suspended core fibers.The experimental setup consists of two fiber - coupled MIR lasers, one for each arm of a Michelson interferometer.A pair of suspended - core fibers is used to pair the output beams into a 2x2 multimode interfering coupler ( MMI ).In order to achieve high extinction ratio in this MMI - based beam splitter we use a new design that incorporates a tapered area at its input port.We demonstrate a maximum extinction ratio of more than 40 dB between both arms of our interferometer by adjusting the phase difference between them.This value corresponds to a minimal intensity contrast of 1e - 10 which is enough for most applications such as space telescopes or free - space optical communication systems.Finally, we show how the performance can be further improved by optimizing the coupling efficiency through the suspended - core fibers."
    },
    {
        "original_text": "We present novel examples of tree-level stable non-BPS D-branes in string theory, which are not associated with spacetime fermion zero modes and thus do not require the presence of orientifolds or other sources for tadpole cancellation. We show that these brane configurations can be constructed by wrapping unstable D-branes on supersymmetric cycles in Calabi-Yau threefolds. The resulting BPS states preserve half of the original supersymmetry but carry no net charge under any gauge group factor. These results provide new insights into the structure of moduli spaces of vacua in string theory. Introduction: In recent years there has been considerable interest in studying non-BPS D-brane (NBD) configurations in type II string theories [1] . NBDs have attracted attention because they may play an important role in understanding various phenomena such as tachyon condensation [2] , open-string pair production [3] , and black hole entropy [4] .\nIn this work we will focus our attention on NBDs whose stability is due to worldsheet instanton effects [5] - [8] rather than spacetime fermion zero-modes [9] . Such NBDs were first studied in [10] where it was shown that certain wrapped D3-branes could become stable at one-loop order without requiring the presence of orientifold planes [11] . Subsequently, several authors [12] - [16] have considered similar constructions involving different types of D-branes and compactifications. However, all of these works required some form of tadpole cancellation [17] so that the total RR-charge carried by the configuration vanishes. Tadpole cancellation conditions place strong constraints on the allowed values of fluxes and charges in the background geometry [18] . It would therefore be interesting if one could find examples of stable NBDs which did not require the presence of additional sources for tadpole cancellations.",
        "watermark_text": "We present novel examples of tree - level stable non - BPS D - branes in string theory, which are not associated with spacetime fermion zero modes and thus do not need the presence of orientifolds or other sources for tadpole cancellation.We show that these brane configurations can be constructed by wrapping unstable D - branes on supersymmetric cycles in Calabi - Yau threefolds.The resulting BPS states preserve half of the original supersymmetry but carry no net charge under any gauge group factor.These results provide new insights into the structure of moduli spaces of vacua in string theorist.Introduction : In recent years there has been considerable interest in studying un - BPS D - brane ( NBD ) configurations in type II string theories [ 1 ].NBDs have attracted attention because they might play an important role in understanding various phenomena such as tachyon condensation[ 2 ], open - string pair production[ 3 ], and black hole entropy [ 4 ].In this work we will concentrate our attention on NBDs whose stability is due to worldsheet instanton effects[ 5 ] - [ 8 ] rather than spacetime fermion zero - modes [ 9 ].Such NBDs were first studied in [ 10 ] where it was shown that certain wrapped D3 - branes could become stable at one - loop order without requiring the presence of orientifold planes[ 11 ].Subsequently, several authors [ 12 ] - [ 16 ] have considered similar constructions involving different kinds of D - branes and compactifications.However, all of these works required some form of tadpole cancellation [ 17 ] so that the final RR - charge carried by the configuration vanishes.Tadpole cancellation conditions place strong constraints on the allowed values of fluxes and charges in the background geometry[ 18 ].It would therefore be interesting if one would find examples of stability NBDs which did not require the presence of extra sources for tadpole cancellations."
    },
    {
        "original_text": "MgSiO3 perovskite has been studied by first-principles calculations and the semi-empirical P-V-T equation of state (EOS). The calculated results show that MgSiO3 perovskites have high bulk modulus, low compressibility, large volume expansion coefficient at high temperature, and small thermal expansivity in comparison with other oxides. These properties are very important for understanding geophysics phenomena such as earthquakes and volcanic activities.  In addition to these physical properties, we also investigated the electronic structure of MgSiO3 perovskitie using density functional theory (DFT) method. We found that there exists a charge transfer between Si4+ ions and O2-ions which leads to the formation of Si-O bonds. This charge transfer causes the change of bond length and bond angle of Si-O-Si network. Finally, we discussed the effect of oxygen vacancy on the structural stability of MgSiO3 perovksite.",
        "watermark_text": "MgSiO3 perovskite has been studied by first - principles calculations and the semi - empirical P - V - T equation of state ( EOS ).The calculated results show that MgSiO3 perovskites have high bulk modulus, low compressibility, large volume expansion coefficient at high temperature, and small thermal expansivity in compared with other oxides.These properties are very important for understanding geophysics phenomena such as earthquakes and volcano activities.In addition to these physical properties, we also investigated the electronic structure of MgSiO3 perovskitie using dense functional theory ( DFT ) method.We found that there exists a charge transfer between Si4 + ions and O2 - ions which leads to the formation of Si - O bonds.This charge transfer causes the change of bond length and bond angle of Si - O - S network.Finally, we discussed the effect of oxygen vacancy on the structural stability of MgSiO3 perovksite."
    },
    {
        "original_text": "We present an analysis of the dynamics of the four giant planets of our Solar System during their formation, using numerical simulations with N-body codes that include hydrodynamical effects (gas drag). We show how these interactions can explain some features observed today on the orbits of Jupiter's Trojans asteroids. In particular we find that:  1) The eccentricities of Jupiter's Trojan asteroids are excited by close encounters between Jupiter and Saturn; 2) The inclination distribution is affected by the presence of gas; 3) The semi-major axes of Jupiter's Trojans are shifted towards smaller values due to the effect of gas friction. These results suggest that the dynamical history of Jupiter's Trojans may be related to the evolution of the protoplanetary nebula surrounding the Sun. This work was supported by CONACyT grant No. 164713. We thank J. Laskar for providing us his code used to calculate the secular frequencies of the planetary systems. \n \n Keywords: Giant planet migration, Gas drag",
        "watermark_text": "We present an analysis of the dynamics of the four giant planets of our Active System during their formation, utilizing numerical simulations with N - body codes that include hydrodynamical effects ( gas drag ).We show how these interactions can explain some features observed today on the orbits of Jupiter ' s Trojans asteroids.In particular we find that : 1 )The eccentricities of Jupiter ' s Trojan asteroids are excited by near encounters between Jupiter and Saturn ; 2 ) The inclination distribution is affected by the presence of gas ; 3 ) The semi - major axes of Jupiter ' s Trojans are shifted towards smaller values due to the effect of gas friction.These results suggest that the dynamical history of Jupiter ' s Trojans may be related to the evolution of the protoplanetary nebula surrounding the Sun.This work was supported by CONACyT award No. 164713.We thank J. Laskar for supplying us his code used to calculate the secular frequencies of the planetary systems.Keywords : Giant planet migration, Gas drag"
    },
    {
        "original_text": "We study the effect of decoherence on quantum simulations of strongly correlated systems in one dimension, focusing on the case where the number of particles is large and the Hilbert space grows exponentially with this number. We show that for certain classes of Hamiltonians it is possible to perform efficient numerical calculations using tensor network methods even when the effects of decoherence are taken into account. In particular we consider two different types of errors which can be simulated by adding extra terms to the Hamiltonian describing the evolution of the system. The first type of error corresponds to local fluctuations in the energy levels of individual sites while the second type describes global fluctuations affecting all sites equally. For both cases we find that the resulting effective dynamics can still be efficiently described within the same class of tensor networks as before. This allows us to calculate the time dependence of observables such as correlation functions or entanglement entropy accurately despite the presence of noise.",
        "watermark_text": "We study the effect of decoherence on quantum simulations of strongly correlated systems in 1 dimension, focusing on the case where the number of particles is large and the Hilbert space grows exponentially with this number.We show that for certain classes of Hamiltonians it is possible to perform efficient numerical calculations using tensor network methods even when the effects of decoherence are taken into account.In particular we consider two different types of mistakes which can be simulated by adding extra terminology to the Hamiltonian detailing the evolution of the system.The first type of error corresponds to local fluctuations in the energetic levels of single sites while the 2nd type describes global fluctuations affecting all levels equally.For both cases we find that the resulting effective dynamics can still be efficiently described within the same class of tensor networks as before.This allows us to calculate the time dependence of observables such as correlation functions or entanglement entropy accurately despite the presence of noise."
    },
    {
        "original_text": "We study the effects on cosmic microwave background (CMB) temperature and polarization anisotropies induced by tensor perturbations in the early universe, which are generated through inflationary processes or other mechanisms. We show that these tensor perturbations can be probed via their imprints on the Stokes parameters Q and U . In particular, we find that the correlation between the two Stokes parameters is proportional to the amplitude of the tensor perturbation at large scales. This effect may provide an important test for models of inflation as well as alternative scenarios such as topological defects. \n \n The recent detection of B-mode polarizations in the CMB [1] has opened up new opportunities to probe physics beyond standard cosmology [2] , including primordial gravitational waves [3] produced during inflation [4] . However, it remains unclear whether this signal arises primarily due to scalar fluctuations [5] or primordial gravitational waves [6] .\n \n \n Tensor modes also induce non-Gaussianities [7, 8] in the primordial curvature perturbation ζ [9] . These non-Gaussianities have been studied extensively [10 - 12] using different approaches [13 - 15] . It was shown [16] that the bispectrum of the primordial curvature perturbation contains information about both the power spectrum Pζ(k) and the spectral index ns [17] of the tensor mode. Recently, Ref. [18] showed that the trispectrum of the primordial curvature perturbations contains additional information about the tensor-to-scalar ratio r = 16PT /PS where PT denotes the power spectrum of the tensor mode and PS denotes the power spectrum of its corresponding scalar counterpart.",
        "watermark_text": "We study the effects on cosmic microwave background ( CMB ) temperature and polarization anisotropies induced by tensor perturbations in the young universe, which are generated through inflationary processes or other mechanisms.We show that these tensor perturbations can be probed via their imprints on the Stokes parameters Q and U.In particular, we find that the correlation between the two Stokes parameters is proportional to the amplitude of the tensor perturbation at big scales.This effect may provide an important test for models of inflation as well as alternative scenarios such as topological faults.The recent detection of B - mode polarizations in the CMB [ 1 ] has opened up fresh opportunities to probe physics beyond standard cosmology [ 2 ], including primordial gravitational waves[ 3 ] produced during inflation [ 4 ].However, it remains unclear whether this signal arises primarily owing to scalar fluctuations [ 5 ] or primordial gravity waves [ 6 ].Tensor modes also induce non - Gaussianities [ 7, 8 ] in the primordial curvature perturbation ζ[ 9 ].These non - Gaussianities have been studied extensively[ 10 - 12 ] using different approaches[ 13 - 15 ].It was shown [ 16 ] that the bispectrum of the primordial curvature perturbation includes information about both the power spectrum Pζ ( k ) and the spectral index ns [ 17 ] of the tensor mode.Recently, Ref.[ 18 ] showed that the trispectrum of the primordial curvature perturbations contains additional information about the tensor - to - scalar ratio r = 16PT / PS where PT denotes the power spectrum of the tensor mode and PS denotes the power fringe of its corresponding scalar counterpart."
    },
    {
        "original_text": "We present an analysis of the kinetic Sunyaev-Zeldovich effect (kSZ) due to electrons in our galaxy, using data obtained with the Atacama Cosmology Telescope and the South Pole Telescope. We use two different methods for estimating the kSZ signal; one is based on cross-correlating maps of CMB temperature anisotropy at 150 GHz and 3000 GHz, while the other uses the power spectrum of the CMB temperature fluctuations at 150 GHz. The results are consistent between these two approaches within their respective uncertainties. We find that the amplitude of this signal agrees well with theoretical predictions when we assume a Navarro-Frenk-White profile for dark matter density distribution around galaxies. This measurement provides new constraints on cosmological parameters such as the Hubble constant H0 = 73 +/- 4 km s-1 Mpc-1 , the total mass density parameter Omega_m = 0.27 +/- 0.03 , and the equation-of-state w = -1.06 +/- 0.11 .",
        "watermark_text": "We present an analysis of the kinetic Sunyaev - Zeldovich effect ( kSZ ) due to electrons in our galaxy, using data obtained with the Atacama Cosmology Telescope and the South Pole Telescope.We utilize two different methods for estimating the kSZ signal ; one is based on cross - correlating maps of CMB temperature anisotropy at 150 GHz and 3000 GHz, while the other uses the power spectrum of the CMB temperature fluctuations at 150 GHz.The results are consistent between these 2 approaches inside their respective uncertainties.We find that the amplitude of this signal agrees well with theory predictions when we assume a Navarro - Frenk - White profile for dark matter density distribution around galaxies.This measurement provides new constraints on cosmological parameters such as the Hubble constant H0 = 73 + / - 4 km s - 1 Mpc - 1, the total mass density constant Omega _ m = 0. 27 + / - 0. 03, and the equation - of - state w = - 1. 06 + / - 0. 11."
    },
    {
        "original_text": "We present new measurements of the mean and scatter in the velocity dispersion-optical richness relation (VRR) for galaxy clusters selected by their red-sequence galaxies using data from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7). We use two different methods to measure cluster velocities, one based on spectroscopic observations of member galaxies and another that uses photometric redshift estimates of all galaxies within a fixed aperture centered on each cluster's brightest cluster galaxy (BGG).\nThe results are consistent with previous studies at low-redshift but show significant differences when compared to recent work done at higher redshifts. The discrepancies between our results and those presented in earlier works may be due to systematic effects associated with the measurement techniques used or could indicate evolution in the VRR over time. In either case, these results highlight the need for further investigation into this relationship as well as other scaling relations involving galaxy clusters. \n \n Keywords: galaxy cluster, optical richness",
        "watermark_text": "We present fresh measurements of the mean and scatter in the velocity dispersion - optical richness relation ( VRR ) for galaxy clusters selected by their red - sequence galaxies using data from the Sloan Digital Sky Survey Data Release 7 ( SDSS DR7 ).We utilize two different methods to measure cluster velocities, one based on spectroscopic observations of member galaxies and another that uses photometric redshift estimates of all galaxies within a fixed aperture centered on each cluster ' s brightest cluster galaxy ( BGG ).The results are consistent with previous studies at low - redshift but show significant differences when compared to recent work done at higher redshifts.The discrepancies between our results and those presented in earlier works may be owing to systematic effects associated with the measurement techniques used or could indicate evolution in the VRR over time.In either case, these results highlight the need for further investigation into this relation as well as other scaling relationships involving galaxy clusters.Keywords : galaxy cluster, optical richness"
    },
    {
        "original_text": "We have carried out an extensive spectroscopic survey for high redshift (z > 2) galaxies using the VLT/VIMOS instrument on the ESO Very Large Telescope, targeting sources selected by their strong rest-frame UV emission lines and photometric redshifts. We present here our results obtained with this sample at wavelengths ranging from radio to X-ray. The main goal is to investigate how star formation proceeds in these distant objects through detailed studies of their physical properties such as stellar masses, ages, metallicities or dust content. In particular we focus on two samples of Lyman-alpha emitting galaxies which are known to be very young systems undergoing intense bursts of star formation. Our analysis shows that they exhibit large amounts of cold gas but also significant quantities of dust. This suggests that the bulk of the observed infrared luminosity may not come directly from newly formed stars but rather from reprocessed light emitted by hot dust heated by older populations and/or AGN activity.",
        "watermark_text": "We have carried out an extensive spectroscopic survey for high redshift ( z > 2 ) galaxies using the VLT / VIMOS instrument on the ESO Very Large Telescope, targeting sources selected by their strong rest - frame UV emitted lines and photometric redshifts.We present here our findings obtained with this sample at wavelengths ranging from radio to X - ray.The main goal is to investigate how star formation proceeds in these distant objects through detailed studies of their physical properties such as star masses, years, metallicities or dust content.In particular we focus on 2 samples of Lyman - alpha emitting galaxies which are known to be very early systems undergoing intense bursts of star formation.Our analysis shows that they exhibit big amounts of cold gas but also significant quantities of dust.This suggests that the bulk of the observed infrared luminosity may not come straight from newly formed stars but rather from reprocessed light emitted by hot dust heated by older populations and / or AGN activity."
    },
    {
        "original_text": "We study the global structure and causal properties of (2 + 1)-dimensional Einstein spaces with nonnegative cosmological constant, which are locally conformally flat but not globally conformal to Minkowski space-time.  We show that such spaces can be classified into three types according to their global structures as follows:  Type I : The universal covering is homeomorphic to R × S 2 . Type II : The universal covering has infinitely many ends. Type III : The universal covering is compact. In particular,  we prove that any spacetime in Types I or II admits closed timelike curves if it contains an incomplete null geodesic segment whose endpoints have different values of the affine parameter along them.   As applications,   we give examples of complete solutions for each type by constructing explicit metrics on open subsets of the hyperbolic plane H 2 , the complex projective line CP1 , and the 3-sphere S3 respectively.    Keywords: Global structure, Causality, Closed timelike curve",
        "watermark_text": "We study the global structure and causal properties of ( 2 + 1 ) - dimension Einstein spaces with nonnegative cosmological constant, which are locally conformally flat but not globally conformal to Minkowski space - time.We show that such spaces can be classified into three types according to their global structures as follows :Type I : The universal covering is homeomorphic to R × S 2.Type II : The universal covering has infinitely many ends.Type III : The universal covering is compact.In particular, we prove that any spacetime in Types I or II admits closed timelike curves if it contains an incomplete null geodesic segment whose endpoints have different values of the affine parameter along them.As applications, we give examples of complete solutions for each type by constructing explicit metrics on open subsets of the hyperbolic plane H 2, the complicated projective line CP1, and the 3 - spherical S3 respectively.Keywords : Global structure, Causality, Closed timelike curve"
    },
    {
        "original_text": "We present an analysis of cosmogenic neutrino fluxes expected in IceCube for different models of cosmic ray sources and propagation, including recent results on anisotropy measurements by PAMELA and AMS-02 experiments. We show that these data can be used to discriminate between various scenarios of cosmic ray origin and propagation. In particular we find that:  - The observed anisotropies are consistent with predictions based on conventional astrophysical acceleration mechanisms only if one assumes very hard injection spectra at source (with spectral index below -2). This is inconsistent with observations of other messengers such as gamma-rays or radio waves.  - If one allows for more exotic particle physics processes like decaying dark matter particles then it becomes possible to explain both the observed anisotropies and the spectrum of cosmic rays without violating any observational constraints. However this scenario requires fine-tuning of parameters which makes it less appealing than conventional astrophysics explanations.",
        "watermark_text": "We present an analysis of cosmogenic neutrino fluxes expected in IceCube for different models of cosmic ray sources and propagation, including recent results on anisotropy measurements by PAMELA and AMS - 02 experiments.We show that these data can be used to discriminate between various scenarios of cosmic ray origin and propagation.In particular we find that : - The observed anisotropies are consistent with predictions based on conventional astrophysical acceleration mechanisms only if 1 assumes very hard injection spectra at source ( with spectral index below - two ).This is inconsistent with observations of other messengers such as gamma - rays or RF waves.- If one allows for more exotic particle physics processes like decaying dark matter particles then it gets possible to explain both the observed anisotropies and the spectrum of cosmic rays without violating any observational constraints.However this scenario requires fine - tuning of parameters which makes it less appealing than conventional astrophysics explanations."
    },
    {
        "original_text": "We study the non-adiabatic current through an open quantum dot connected to two leads with different chemical potentials, which is driven by time-dependent gate voltages applied on both sides of the dot. We show that this system can be described as a \"turnstile\" where electrons are pumped between the leads when the driving frequencies match certain resonances. The effect is robust against disorder and dephasing. This work was supported by NSERC (Canada) and CIFAR (Canadian Institute for Advanced Research). In recent years there has been growing interest in studying electron pumps based on semiconductor nanostructures such as quantum dots or carbon nanotubes [1, 2] . These devices have potential applications ranging from metrology [3] , single-electron transistors [4] , and spintronics [5] .\nIn these systems, charge carriers are transported across the device via sequential tunneling processes [6] . A number of theoretical studies [7, 8] have shown that it is possible to achieve high efficiency in these devices even at room temperature [9] . However, most previous works focused only on adiabatic pumping [10] , i.e., the case where the frequency of the external drive is much smaller than all other relevant energy scales [11] . Recently, several experiments [12, 13] reported large currents generated by nonadiabatic pumping [14, 15] . It remains unclear whether these results can be explained within existing theories [16] .\nHere we consider a simple model of a quantum dot connected to two metallic leads [see Fig. 1(a) ] [17] . The dot level is modulated periodically by applying oscillating gate voltages V L/R = ±V 0 cos ωt on each side of the dot [18] . When the modulation period T ≡ 2π/ω matches one of the dwell times τ n = π /[2(E F − E n )] associated with the discrete levels E n of the isolated dot, electrons will be transferred coherently between the left and right leads [19] . Here E F denotes the Fermi energy of the leads [20] . As illustrated schematically in Figs. 1(b-c), depending on",
        "watermark_text": "We study the non - adiabatic current through an open quantum dot connected to two leads with different chemical potentials, which is driven by time - dependent gate voltages applied on both sides of the dot.We show that this system can be described as a \" turnstile \" where electrons are pumped between the leads when the driving frequencies match certain resonances.The effect is robust against disorder and dephasing.This work was supported by NSERC ( Canadian ) and CIFAR ( Canadian Institute for Advanced Research ).In recent years there has been growing interest in learning electron pumps based on semiconductor nanostructures such as quantum dots or carbon nanotubes[ 1, 2 ].These devices have possible applications ranging from metrology [ 3 ], single - electron transistors[ 4 ], and spintronics [ 5 ].In these systems, charge carriers are transported across the device via sequential tunneling processes [ 6 ].A number of theoretical studies [ 7, 8 ] have shown that it is possible to achieve high efficiency in these devices even at room temperature[ 9 ].However, most previous works focused only on adiabatic pumping [ 10 ], i. e., the situation where the frequency of the outside drive is far smaller than all other relevant energy scales [ 11 ].Recently, several experiments [ 12, 13 ] reported big currents generated by nonadiabatic pumping [ 14, 15 ].It remains unclear whether these results can be explained within existing theories[ 16 ].Here we consider a simple model of a quantum dot connected to 2 metallic leads [ see Fig. 1 ( a ) ][ 17 ].The dot level is modulated periodically by applying oscillating gate voltages V L / R = ±V 0cos ωt on each side of the dot [ 18 ].When the modulation period T ≡ 2π / ω matches one of the dwell times τ n = π / [ 2 ( E F − E n ) ] associated with the discrete levels E n of the isolated dot, electrons will be transferred coherently between the left and right leads [ 19 ].Here E F denotes the Fermi energy of the leads [ 20 ].As illustrated schematically in Figs.1 ( b - c ), depending on"
    },
    {
        "original_text": "The Spitzer Bright Field (SBF) is an all-sky survey at 3.6, 4.5, 5.8 & 8 microns carried out by the Infrared Array Camera on board the Spitzer Space Telescope.  The SBF was designed to provide deep infrared photometry for extragalactic studies in order to complement existing optical surveys such as the Sloan Digital Sky Survey.   This dataset contains images taken with IRAC channel 1 (3.6 micron), channel 2 (4.5 micron), channel 3 (5.8 micron) and channel 4 (8 micron). Each image has been processed using the MOPEX software package developed by the Spitzer Science Center. These images are available through the NASA/IPAC Extragalactic Database (NED).  For more information about this project please see http://irsa.ipac.caltech.edu/data/SPITZER/docs/sbf/sbf-intro.html",
        "watermark_text": "The Spitzer Bright Field ( SBF ) is an all - sky survey at three. 6, 4. 5, 5. 8 & eight microns carried out by the Infrared Array Camera on board the Spitzer Space Telescope.The SBF was designed to offer deep infrared photometry for extragalactic studies in order to compliment existing optical surveys such as the Sloan Digital Sky Survey.This dataset contains images taken with IRAC channel 1 ( 3. 6 micron ), channel 2 ( 4. 5 micron ), channel 3 ( five. 8 micron ) and channel 4 ( 8 micron ).Each image has been processed using the MOPEX software package developed by the Spitzer Science Center.These images are available through the NASA / IPAC Extragalactic Database ( NED ).For more information about this project please view http : / / irsa. ipac. caltech. edu / data / SPITZER / docs / sbf / sbf - intro. html"
    },
    {
        "original_text": "We present an argument for why quantum mechanics is nonlocal, based on the fact that it allows one to predict with certainty whether or not a measurement will be made in any given experiment. We show how this can lead to superluminal communication between two parties sharing entangled particles by using only local operations and classical communication (LOCC). Finally we generalize the Born rule to allow for arbitrary measurements instead of just von Neumann ones. The usual formulation of quantum mechanics assumes that all experiments are performed under ideal conditions where no errors occur during the preparation of states or the execution of measurements. However, in practice there always exist some experimental imperfections such as decoherence due to environmental noise, imprecision in state preparations, and inaccuracy in measurements. In order to account for these effects, several approaches have been proposed including stochastic Schrödinger equations [1] , open systems [2] , and generalized probabilistic theories [3] . Here we consider another approach known as Quantum Bayesianism [4] .\nIn Quantum Bayesianism, the wave function is regarded as representing our knowledge about the system rather than describing its physical properties. This means that when performing a measurement, the outcome is determined by updating our knowledge according to Bayes' theorem [5] . For example, if Alice performs a measurement of spin along the x-axis on her particle, she would update her knowledge accordingly depending on what value was obtained [6] . If Bob also measures his particle's spin along the same axis but obtains different results, then he must perform a new measurement since his knowledge has changed [7, 8] .",
        "watermark_text": "We present an argument for why quantum mechanics is nonlocal, based on the fact that it permits one to predict with certainty whether or not a measurement will be made in any given experiment.We show how this can lead to superluminal communication between 2 parties sharing entangled particles by utilizing only local operations and classical communication ( LOCC ).Finally we generalize the Born rule to allow for arbitrary measurements rather of just von Neumann ones.The usual formulation of quantum mechanics assumes that all experiments are performed under ideal conditions where no errors occur during the preparation of states or the execution of measurements.However, in practice there always exist some experimental imperfections such as decoherence due to environmental noise, imprecision in state preparations, and inaccuracy in measurements.In order to account for these effects, several approaches have been proposed including stochastic Schrödinger equations[ 1 ], open systems[ 2 ], and generalized probabilistic theories[ 3 ].Here we consider another approach known as Quantum Bayesianism [ 4 ].In Quantum Bayesianism, the wave function is regarded as representing our knowing about the system rather than describing its physical properties.This means that when performing a measurement, the outcome is determined by updating our knowledge according to Bayes ' theorem [ 5 ].For example, if Alice performs a measurement of spin along the x - axis on her particle, she shall update her knowledge accordingly depending on what value was obtained [ 6 ].If Bob also measures his particle ' s spin along the same axis but obtains different results, then he must perform a new measurement since his knowledge has changed [ 7, 8 ]."
    },
    {
        "original_text": "We study the statistical properties of highly compressible turbulence by means of direct numerical simulations (DNS) at Mach numbers ranging between 10 and 100, using both isothermal and adiabatic equations of state for the gas.  We find that the scaling laws observed in incompressible flows are violated when the Mach number becomes large enough to produce shocks. In particular, we show that the energy spectrum exhibits an exponential decay with wavenumber k instead of the power-law behavior E(k) ~ k-5/3 predicted by Kolmogorov's theory. The intermittent nature of the flow is also investigated through the analysis of probability density functions (PDFs). It turns out that PDF tails become increasingly fat-tailed as M increases, which can be explained by invoking the presence of shock waves. Finally, we discuss how these results may affect our understanding of astrophysical phenomena such as supernova remnants or interstellar clouds.",
        "watermark_text": "We study the statistical properties of highly compressible turbulence by means of directly numerical simulations ( DNS ) at Mach numbers ranging between 10 and 100, using both isothermal and adiabatic equations of state for the gas.We find that the scaling laws observed in incompressible flows are violated when the Mach number becomes big enough to produce shocks.In particular, we show that the energy spectrum displays an exponential decay with wavenumber k instead of the power - law behaviour E ( k ) ~ k - 5 / three predicted by Kolmogorov ' s theory.The intermittent nature of the flow is also investigated through the analysis of probability density functions ( PDFs ).It turns out that PDF tails become increasingly fat - tailed as M rises, which can be explained by invoking the presence of shock waves.Finally, we discuss how these outcomes may affect our understanding of astrophysical phenomena such as supernova fragments or interstellar clouds."
    },
    {
        "original_text": "We present new multi-color photometric data for the globular cluster M75 (NGC6864) obtained with the Hubble Space Telescope Wide Field Camera 3, which allow us to study its horizontal branch stars in unprecedented detail. We find that the color distribution along the HB is bimodal, indicating two distinct populations of hot and cool HB stars. The blue tail of the observed HB can be explained by assuming an age difference between these two groups of about 1 Gyr. Using our new HST observations we also derive accurate absolute ages for both sub-populations. Our results show that the redder population has an age of 12.6 ± 0.2 Gyr while the bluer one is younger at 11.7 ± 0.1 Gyr. This finding supports previous suggestions that the redder part of the HB may have been formed during a second episode of star formation within this system. \n \n Keywords: Globular clusters; Horizontal branches",
        "watermark_text": "We present fresh multi - color photometric data for the globular cluster M75 ( NGC6864 ) obtained with the Hubble Space Telescope Wide Field Camera 3, which allow us to study its horizontal branch stars in unprecedented detail.We find that the colour distribution along the HB is bimodal, suggesting two distinct populations of hot and cool HB stars.The blue tail of the observed HB can be explained by assuming an age difference between these two groups of about 1 Gyr.Using our new HST observations we also derive accuracy absolute ages for both sub - populations.Our results show that the redder population has an age of 12. 6 ± 0. 2 Gyr while the bluer one is younger at 11. 7 past 0. 1 Gyr.This finding supports previous suggestions that the redder part of the HB may have been formed during a second episode of stellar formation within this system.Keywords : Globular clusters ; Horizontal branches"
    },
    {
        "original_text": "En este trabajo se estudia la existencia y estabilidad de agujeros de gusano en el espacio tiempo descrito por una solución exacta del campo gravitacional generado por un cuerpo esférico con simetría axial, que corresponde al caso más simple de agujero negro no rotante. Se muestra que los agujeros de gusano son estables bajo ciertas condiciones sobre las constantes cosmológicas involucradas. Además, se presenta una nueva clase de soluciones exactas para el problema de Einstein-Klein-Gordon en espacios homogéneos e isótropos. Estas soluciones corresponden a ondas escalares estacionarias localizadas alrededor de un punto singular donde existe una densidad infinita de energía escalar. Finalmente, se discute brevemente cómo estas soluciones pueden ser utilizadas como fuentes de radiación gravitatoria coherente. En este trabajo estudiamos la existencia y estabilidad de los llamados agujeros de gusano  en el espacio-tiempo descrito por una solución exacta correspondiente al campo gravitacional generado por una esfera con simetría axial. Esta solución corresponde al caso más sencillo posible de agujero negro sin rotación. Mostramos que estos agujeros de gusano resultan ser estables bajo determinadas condiciones sobre las constantes cosmológica involucradas.  También presentamos una nueva clase de soluciones exáctas para el problema de Klein-Gordon-Einstein en espacios homogéneos isotrópicos. Estas soluciones corresponden a olas escalares estacionarias localizdas alrededor de un punto singular en donde hay una densidad infinita de energía escalara. Por último discutimos brevemente cómo estas soluciones pueden utilizarse como fuentes de radiación gravitacional coherente.",
        "watermark_text": "En este trabajo se estudia la existencia y estabilidad de agujeros de gusano en el espacio tiempo descrito por una solución exacta del campo gravitacional generado por un cuerpo esférico con simetría axial, que corresponde al caso más simple de agujero negro no rotante.Se muestra que los agujeros de gusano son estables bajo ciertas condiciones sobre las constantes cosmológicas involucradas.Además, se presenta una nueva clase de soluciones exactas para el problema del Einstein - Klein - Gordon en espacios homogéneos e isótropos.Estas soluciones corresponden a ondas escalares estacionarias localizadas alrededor de un punto singular donde existe una densidad infinita de energía escalar.Finalmente, se discute brevemente cómo estas soluciones pueden ser utilizadas como fuentes de radiación gravitatoria coherente.En este trabajo estudiamos la existencia y estabilidad de los llamados agujeros de gusano en el espacio - tiempo descrito por una solución exacta correspondiente al campo gravitacional generado por una esfera con simetría axial.Esta solución corresponde al caso más sencillo posible de agujero negro sin rotación.Mostramos que estos agujeros de gusano resultan ser estables bajo determinadas condiciones sobre las constantes cosmológica involucradas.También presentamos una nueva clase de soluciones exáctas para el problema de Klein - Gordon - Einstein en espacios homogéneos isotrópicos.Estas soluciones corresponden a olas escalares estacionarias localizdas alrededor de un punto singular en donde hay una densidad infinita de energía escalara.Por último discutimos brevemente cómo estas soluciones pueden utilizarse como fuentes de radiación gravitacional coherente."
    },
    {
        "original_text": "We present the first dynamical mass measurement for an eclipsing binary system with one component that is still on its pre-main sequence (PMS). The PMS star, V773 Tau A, has been observed to undergo large-amplitude photometric variability and spectroscopic changes indicative of rapid rotation and magnetic activity. We have obtained new high-precision radial velocity measurements using the HIRES spectrograph at Keck Observatory in Hawaii. These data are combined with previously published observations spanning more than 20 years to produce a preliminary orbital solution. Using this orbit we calculate a dynamical mass for V773 Tau A of 0.84 ± 0.04M⊙. This value agrees well with theoretical predictions based upon evolutionary models for young stars. Our results provide strong evidence against previous claims that the components of close binaries evolve independently during their early stages of formation. In addition, our analysis provides further support for the hypothesis that the majority of short-period systems will merge within 10 million years due to tidal interactions between the two components. \n \n Keywords: Mass determination",
        "watermark_text": "We present the initial dynamical mass measurement for an eclipsing binary system with one component that is still on its pre - main sequence ( PMS ).The PMS star, V773 Tau A, has been observed to undergo large - amplitude photometric variability and spectroscopic changes indicative of rapid rotation and magnetic action.We have obtained new high - precision radial velocity measurements using the HIRES spectrograph at Keck telescope in Hawaii.These data are combined with previously published observations spanning more than 20 years to produce a preliminary orbital solution.Using this orbit we calculate a dynamical mass for V773 Tau A of 0. 84 ± zero. [UNK].This value agrees well with theoretical predictions based upon evolutionary models for young stars.Our results provide strong evidence against previous claims that the components of close binaries evolve independently during their early stages of formation.In addition, our analysis provides further support for the hypothesis that the majority of short - period systems will merge within 10 million ages due to tidal interactions between the 2 components.Keywords : Mass determination"
    },
    {
        "original_text": "The optical properties of single human erythrocytes (red blood cells, RBCs) are investigated using the combination of scanning flow cytometry with numerical simulations based on the Discrete Dipole Approximation method. The experimental results show that the forward-scattering intensity is strongly dependent on the refractive index contrast between the cell cytoplasm and surrounding medium as well as on the size distribution of the scatterers inside each cell. In addition to the main peak in the forward direction at small angles, we observe two additional peaks at larger scattering angles corresponding to higher-order multipolar contributions. We find good agreement between our measurements and calculations for both the angular dependence of the scattered intensity and its polarization state. Our results demonstrate that the DDA can be used successfully to model light scattering by biological particles such as RBCs. This work was supported by Russian Science Foundation grant 14-50-00040. \n \n Light scattering by biological objects plays an important role in many biomedical applications including diagnostics [1] , drug delivery [2] , tissue engineering [3] . Scattering characteristics depend not only on the shape but also on the internal structure of the particle [4] . For example, it has been shown recently [5] that the presence of submicron-sized inclusions within the cytoplasm of red blood cells leads to significant changes in their scattering pattern compared to homogeneous spherical models [6] .\nIn this Letter, we report on combined experimental and theoretical investigation of light scattering by individual human erythrocytes. Using scanning flow cytometry [7, 8] , we measure the angular dependence of the forward-scattered intensity I(θ), where θ denotes the angle between incident beam and scattered light. To interpret these data, we perform numerical simulations based on the discrete-dipole-approximation (DDA) [9] technique which allows us to calculate the scattering cross section of arbitrary-shaped dielectric particles [10] . \nWe have studied three types of samples prepared from freshly drawn venous blood taken from healthy donors after informed consent had been obtained according to the protocol approved by the local ethics committee. First sample contained intact RBCs suspended in phosphate-buffered",
        "watermark_text": "The optical properties of single human erythrocytes ( red blood cells, RBCs ) are investigated using the combination of scanning flow cytometry with numerical simulations based on the Discrete Dipole Approximation method.The experimental results show that the forward - scattering intensity is heavily dependent on the refractive index contrast between the cell cytoplasm and surrounding medium as ill as on the size distribution of the scatterers inside each cell.In addition to the main peak in the forward direction at small angles, we observe two additional tops at bigger scattering angles corresponding to upper - order multipolar contributions.We find good agreement between our measurements and calculations for both the angular dependence of the scattered intensity and its polarization state.Our results demonstrate that the DDA can be used successfully to model light scattering by biological particles such as RBCs.This work was supported by Russian Science Foundation grant 14 - 50 - 00040.Light scattering by biological objects plays an important role in much biomedical applications including diagnostics[ 1 ], drug delivery[ 2 ], tissue engineering [ 3 ].Scattering characteristics depend not only on the shape but also on the internal structure of the particle [ 4 ].For example, it has been shown recently [ 5 ] that the presence of submicron - sized inclusions inside the cytoplasm of red blood cells leads to significant changes in their scattering pattern compared to homogeneous spherical models[ 6 ].In this Letter, we report on combined experimental and theoretical investigation of light scattering by individual human erythrocytes.Using scanning flow cytometry [ 7, 8 ], we measure the angular dependence of the forward - scattered intensity I ( θ ), where θ denotes the angle between incident beam and scattered light.To interpret these data, we perform numerical simulations based on the discrete - dipole - approximation ( DDA )[ 9 ] technique which allows us to calculate the scattering across section of arbitrary - shaped dielectric particles [ 10 ].We have studied 3 types of specimens prepared from freshly drawn venous blood taken from healthy donations after informed permission had been gained according to the protocol approved by the local ethics committee.First sample contained intact RBCs suspended in phosphate - buffered"
    },
    {
        "original_text": "We present the results of spectral analysis for all Swift bursts with measured redshifts and durations longer than 2 s, using data obtained by the Burst Alert Telescope (BAT) on board Swift satellite. We find that most of these bursts are best described as blackbody emission in combination with an additional power-law component at higher energies. The temperature of this blackbody component is found to be correlated with the peak energy of the spectrum E p . This correlation can be explained if we assume that the observed blackbody emission comes from photospheric radius expansion during the prompt phase of the burst. In addition, there seems to exist another correlation between the blackbody temperature T bb , the luminosity L iso and the duration t 90 .\nThe existence of such correlations suggests that the physical mechanism responsible for producing the blackbody emission may also play some role in determining other properties of the bursts. \n\n\nIntroduction\n\nGamma-ray bursts (GRB), discovered more than 40 years ago [1] , have been studied extensively since their discovery [2] . However, many questions about them remain unanswered [3] . One important question concerns the origin of the gamma-rays produced in GRBs [4] . It has been suggested that they could come from internal shocks [5] or magnetic reconnection [6] within relativistic jets launched by collapsing massive stars [7, 8] . Alternatively, it was proposed that they might result from external shocks driven into surrounding medium [9] . Another open issue is whether GRBs are standard candles [10] . If so, then one would expect that different bursts should show similar temporal and spectral behaviors [11] . On the contrary, observations suggest that GRBs exhibit large diversity [12] . Finally, the nature of the progenitors of GRBs remains unknown [13] .",
        "watermark_text": "We present the results of spectral analysis for all Swift bursts with measured redshifts and durations longer than two s, utilizing data obtained by the Burst Alert Telescope ( BAT ) on board Swift satellite.We find that most of these bursts are best described as blackbody emission in combination with an additional power - law constituent at higher energies.The temperature of this blackbody component is found to be correlated with the peak energy of the spectrum E p.This correlation can be explained if we assume that the observed blackbody emitted comes from photospheric radius expansion during the prompt phase of the burst.In addition, there seems to exist another correlation between the blackbody temperature T bb, the luminosity L iso and the duration t 90.The existence of such correlations suggests that the physical mechanism responsible for producing the blackbody emission may also play some role in determining other properties of the bursts.Introduction Gamma - ray bursts ( GRB ), discovered more than 40 years ago [ 1 ], have been studied extensively since their discovery[ 2 ].However, many questions about them stay unanswered [ 3 ].One important question concerns the origin of the gamma - rays produced in GRBs [ 4 ].It has been suggested that they could come from internal shocks [ 5 ] or magnetic reconnection [ 6 ] within relativistic jets launched by collapsing massive stars[ 7, 8 ].Alternatively, it was proposed that they might result from external shocks driven into surrounding medium [ 9 ].Another open issue is whether GRBs are standard candles [ 10 ].If so, then one would expect that different bursts should show similarly temporal and spectrum behaviors [ 11 ].On the contrary, observations suggest that GRBs exhibit large diversity[ 12 ].Finally, the nature of the progenitors of GRBs remains unknown [ 13 ]."
    },
    {
        "original_text": "In this work, we consider decode-and forward (DF) cooperation among nodes in wireless networks and propose an optimal routing algorithm to maximize the network throughput by jointly optimizing source-to-destination routes as well as cooperative relay paths. We formulate the problem into mixed integer linear programming (MILP), which is NP-hard due to its combinatorial nature. To solve it efficiently, we develop two heuristic algorithms with polynomial time complexity. The first one uses a greedy approach that iteratively selects the best route between each pair of source destination pairs until all flows are routed. In order to further improve the performance, we also design another algorithm using simulated annealing technique. Extensive simulation results show that our proposed algorithms can achieve significant improvement over existing schemes. Index Terms- Cooperative communication, Optimum routing, Simulated annealing, Greedy algorithm. I. INTRODUCTIO N Cooperative communications have been widely studied recently because they provide higher data rates or longer transmission ranges than conventional non-cooperative systems [1] . In particular, decodeand-forward (DF) has attracted much attention since it does not require any extra power consumption at relays [2] .\nHowever, DF-based cooperative transmissions suffer from high end-to-end delay caused by multiple hops involved in forwarding packets [3] , especially when there exist many sources and destinations [4] . Therefore, how to find efficient cooperative relay paths becomes critical to reduce the overall end-to-end delay while maintaining good system performance [5] - [8] .",
        "watermark_text": "In this work, we consider decode - and forward ( DF ) cooperation among nodes in wireless networks and propose an ideal routing algorithm to maximize the network throughput by jointly optimizing source - to - destination routes as well as cooperative relay paths.We formulate the problem into mixed integer linear programming ( MILP ), which is NP - hard due to its combinatorial nature.To solve it efficiently, we develop two heuristic algorithms with polynomial time complexity.The first one uses a greedy approach that iteratively selects the better route between each pair of source destination ones until all flows are routed.In order to further improve the performance, we also design another algorithm using simulated annealing technology.Extensive simulation results show that our proposed algorithms can achieve significant improvement over existing schemes.Index Terms - Cooperative communication, Optimum routing, Simulated annealing, Greedy algorithm.I. INTRODUCTIO N Cooperative communications have been widely studied recently because they provide higher data speeds or longer transmission ranges than conventional non - cooperative systems[ 1 ].In particular, decodeand - forward ( DF ) has attracted much attention since it does not need any extra power consumption at relays[ 2 ].However, DF - based cooperative broadcasts suffer from high end - to - end delay caused by multiple hops involved in forwarding packets[ 3 ], especially when there exist many sources and destinations [ 4 ].Therefore, how to find efficient cooperative relay paths becomes critical to reduce the overall end - to - end delay while maintaining good system performance [ 5 ] - [ 8 ]."
    },
    {
        "original_text": "We study the cycle structure of elements in braid groups, and prove that any element can be written as a product of cycles whose lengths are bounded by some constant depending only on the number of strands. This is an extension to higher dimensions of results obtained for free groups by Magnus and Karrass-Solitar. \nTheorem 1 (Cycle decomposition). Let G = B_n(K) be a braid group with n strands over K. Then every g ∈ G has a unique expression as a product of disjoint cycles c_1, ..., c_k such that: \n1. The length of each cycle ci satisfies |ci| ≤ 2^{log_2 n} + 3.\n2. Each cycle ci contains at most one generator t_i which does not commute with its inverse.\n3. If there exists no generator t_i satisfying condition 2 then k = 0.\n4. No two generators appear simultaneously in different cycles.\n5. Every generator appears exactly once in each cycle it belongs to.\n6. For all i, |c_1 · ... · c_(i-1)| < |c_i|.",
        "watermark_text": "We study the cycle structure of elements in braid groups, and prove that any element can be written as a product of cycles whose lengths are bounded by some constant depending only on the number of strands.This is an extension to upper dimensions of results obtained for free groups by Magnus and Karrass - Solitar.Theorem 1 ( Cycle decomposition ).Let G = B _ n ( K ) be a braid group with n strings over K.Then every g ∈ G has a unique expression as a product of disjoint cycles c _ 1,., c _ k such that : 1.The length of each cycle ci satisfies | ci | ≤ 2 ^ { log _ 2 n } + three. 2.Each cycle ci contains at most one generator t _ i which does not commute with its inverse.3.If there exists no generator t _ i satisfying condition 2 then k = 0. 4.No two generators appear simultaneously in different cycles.5.Every generator appears exactly once in each cycle it belongs to.6.For all i, | c _ 1 ·. ·c _ ( i - 1 ) | < | c _ i |."
    },
    {
        "original_text": "We present near-infrared (NIR) imaging and spectroscopy of star formation activity in the Bok globule CB 54, which is located at a distance of about 1 kpc toward the Galactic anti-center direction. We found that there are two young stellar objects (YSOs), one Class I protostar with an infrared luminosity of ~10 Lsun and another embedded YSO candidate with a bolometric temperature of ~1000 K. The former object shows bipolar outflows traced by Herbig-Haro knots and molecular line wings. In addition to these two sources, we detected several other point-like NIR sources within the central region of CB 54. These may be low-mass pre-main-sequence stars or background galaxies. Our results suggest that this cloud core has experienced active star formation over its lifetime. \n \n Keywords: Star formation; Near-infrared spectroscopy; Bipolar outflow; Young stellar object",
        "watermark_text": "We present near - infrared ( NIR ) imaging and spectroscopy of star formation activity in the Bok globule CB 54, which is located at a distance of about 1 kpc toward the Galactic anti - center direction.We found that there are 2 young star objects ( YSOs ), 1 Class I protostar with an infrared luminosity of ~ 10 Lsun and another embedded YSO candidate with a bolometric temperature of ~ 1000 K.The former object shows bipolar outflows traced by Herbig - Haro knots and molecular line wings.In addition to these two sources, we detected multiple other point - like NIR sources inside the central region of CB 54.These may be low - mass pre - main - system stars or background galaxies.Our results suggest that this cloud core has experienced active stellar formation over its life.Keywords : Star formation ; Near - infrared spectroscopy ; Bipolar outflow ; Young stellar object"
    },
    {
        "original_text": "We study the possibility that there are two different lifetimes for neutral B mesons, one corresponding to the standard model and another to new physics beyond it.  We find that if the decay widths into final states with charm quarks differ by more than about 10% between these two types of B mesons then this can be observed at future experiments such as LHCb or Belle II. If we assume that the ratio of branching fractions is equal to 1 (as predicted within the Standard Model) but allow the total decay widths to vary independently, then we show how the experimental data on the time dependent CP asymmetry parameters SCP and ACP can be used to determine whether the difference in decay widths is due to new physics effects or not. Finally, we discuss possible extensions of our analysis which could lead to further constraints on the allowed parameter space. The results presented here will also have implications for other measurements performed at hadron colliders involving heavy flavour particles.",
        "watermark_text": "We study the possibility that there are 2 different lifetimes for neutral B mesons, one corresponding to the standard model and one to new physics beyond it.We find that if the decay widths into final states with charm quarks differ by more than about 10 % between these 2 types of Ba mesons then this can be observed at future experiments such as LHCb or Belle II.If we assume that the ratio of branching fractions is equal to 1 ( as predicted within the Standard Model ) but permit the total decay widths to vary independently, then we show how the experimental data on the time dependent CP asymmetry parameters SCP and ACP can be used to determine whether the difference in decay widths is due to new physics effects or not.Finally, we discuss possible extensions of our analysis which could lead to further constraints on the allowed parameter space.The results presented here will also have implications for other measurements performed at hadron colliders involving heavy flavour particles."
    },
    {
        "original_text": "The DualHeap selection algorithm is an efficient method for selecting the kth smallest element in a set S of n elements.  It has been used to solve many problems including finding the minimum spanning tree (MST) in parallel computing environments such as MapReduce.   In this article we present some new results on the DualHeap algorithm that shed light on its efficiency and inherent parallelism.    We show how it can be implemented using only O(logn) bits per element while still maintaining its efficiency guarantees.   This implementation requires no extra space beyond what is needed by the input data itself and thus fits well with modern storage devices like flash memory or hard disks where storing large amounts of data is cheap but accessing individual items may be expensive.   Finally, we prove that the DualHeap algorithm solves the MST problem faster than any other known deterministic algorithm when run on a single processor machine. The DualHeap selection algorithm is one of the most widely used algorithms in computer science today.",
        "watermark_text": "The DualHeap selection algorithm is an efficient method for selecting the kth smallest element in a set S of n elements.It has been used to solve many problems including finding the minimum spanning tree ( MST ) in parallel computing environments such as MapReduce.In this article we present some fresh results on the DualHeap algorithm that shed insight on its efficiency and inherent parallelism.We show how it can be implemented using only O ( logn ) bits per element while still maintaining its efficiency guarantees.This implementation requires no extra space beyond what is needed by the input data itself and thus fits well with modern storage devices like flash memory or disk disks where storing large amounts of data is cheap but accessing individual items may be expensive.Finally, we prove that the DualHeap algorithm solves the MST issue faster than any other known deterministic algorithm when run on a single processor machine.The DualHeap selection algorithm is one of the most commonly used algorithms in computer science today."
    },
    {
        "original_text": "We present an overview of the recent developments in understanding quantum critical phenomena beyond the standard Landau-Ginzburg-Wilson paradigm, focusing on fermion systems with strong electronic correlations and Mott insulating states. We discuss how these new ideas can be applied to understand unconventional superconductivity observed in many strongly correlated materials such as high-Tc cuprates, iron-based compounds, heavy-fermions, organic conductors, etc., which are all characterized by non-Fermi liquid behaviors at low temperatures. In particular we will focus our attention on the concept of \"multi-criticality\" recently proposed for describing the phase diagram of these complex materials near their quantum critical points (QCPs). The idea is that there exist multiple QCPs along different directions in the parameter space of the system, each associated with its own universality class. These QCPs may also have some common features due to the underlying symmetry group of the system.",
        "watermark_text": "We present an overview of the recent developments in understanding quantum critical phenomena outside the standard Landau - Ginzburg - Wilson paradigm, focusing on fermion systems with strong electronic correlations and Mott insulating states.We discuss how these fresh ideas can be applied to understand unconventional superconductivity observed in many strongly correlated materials such as high - Tc cuprates, iron - based compounds, heavy - fermions, organic conductors, etc., which are all characterized by non - Fermi liquid behaviors at low temperatures.In particular we will focus our attention on the concept of \" multiple - criticality \" recently proposed for describing the phase diagram of these complex materials near their quantum critical points ( QCPs ).The idea is that there exist multiple QCPs along different directions in the parameter space of the system, each associated with its own universality classification.These QCPs may also have some shared features due to the embedded symmetry group of the system."
    },
    {
        "original_text": "The first stars in the universe were born out of primordial gas clouds, which collapsed under their own gravity to form dense cores that ignited nuclear fusion and became hot white dwarfs.  The most massive of these early stars are now known as Population III (PopIII) stars.   In this work we present results for PopIII star formation using cosmological hydrodynamic simulations with radiative transfer calculations performed on an adaptive mesh refinement grid.  We find that PopIII stars can be formed by direct collapse of metal-free gas clouds at redshifts z > 20.  These stars have masses M * = 100 - 1000M⊙ and lifetimes t < 10Myr.  They evolve into black holes or pair-instability supernovae after consuming all available fuel within their convective envelopes.  Our results show that PopIII stars may contribute significantly to reionization of the intergalactic medium around redshift z ~ 15.",
        "watermark_text": "The first stars in the universe were born out of primordial gas clouds, which collapsed under their own gravitational to form dense cores that burned nuclear fusion and became hot whitish dwarfs.The most massive of these young stars are now known as Population III ( PopIII ) stars.In this work we present results for PopIII stellar formation using cosmological hydrodynamic simulations with radiative transfer calculations performed on an adaptive mesh refinement grid.We find that PopIII stars can be formed by direct collapse of metal - free gas clouds at redshifts z > 20.These stars have masses M * = 100 - [UNK] and lifetimes t < 10Myr.They evolve into black holes or pair - unstable supernovae after consuming all available fuel within their convective envelopes.Our results show that PopIII stars may contribute significantly to reionization of the intergalactic medium around redshift z ~ 15."
    },
    {
        "original_text": "We study the nonlinear evolution of baryonic acoustic oscillations (BAO) in an expanding universe using numerical simulations with N-body particles and hydrodynamic gas dynamics. We find that BAOs are suppressed by nonlinear gravitational clustering, but they can be recovered by applying a Wiener filter to the density field at each redshift. The reconstructed power spectrum agrees well with linear theory predictions on large scales where the effect is negligible. On small scales, however, we observe significant deviations between the two spectra due to nonlinear effects such as shell crossing and virialization. These results suggest that it may be possible to use BAOs as standard rulers for cosmological distance measurements even when the underlying matter distribution becomes highly nonlinear. In this work, we present our main findings below. \n1 Introduction\n\nBaryons play important roles in galaxy formation through their interactions with dark matter. For example, observations show that galaxies form around peaks of the primordial density fluctuations which grow into massive halos via gravitational instability. Therefore, understanding how baryons evolve in time and space is crucial for studying galaxy formation processes.\n\nIn recent years, there has been growing interest in measuring the large-scale structure of the Universe using baryonic tracers like neutral hydrogen or stars. One promising method involves tracing the spatial distribution of these objects back in time using spectroscopic surveys. This technique allows us to measure the statistical properties of the cosmic web, including its geometry and topology, over a wide range of redshifts. \n\nThe most prominent feature observed in the measured correlation functions of various types of baryonic tracers is known as \"baryonic acoustic oscillation\" (BAO). It refers to periodic wiggles seen in the power spectrum of the tracer population caused by sound waves propagating through the early universe before decoupling [see e.g., 1] . Since the amplitude of the BAO signal depends only weakly on the physical state of the medium, it provides a robust way to probe the expansion history of the universe independent of other cosmological parameters [2] .\nRecently, several groups have reported detections of the BAO signature in the correlation function of Lyman",
        "watermark_text": "We study the nonlinear evolution of baryonic acoustic oscillations ( BAO ) in an expanding universe using numerical simulations with N - body particles and hydrodynamic gas dynamics.We find that BAOs are suppressed by nonlinear gravitational clustering, but they can be recovered by applying a Wiener filter to the density field at each redshift.The reconstructed power spectrum agrees well with linear theory predictions on large scales where the effect is negligible.On small scales, however, we observe significant deviations between the 2 spectra due to nonlinear effects such as shell crossing and virialization.These results suggest that it may be possible to use BAOs as standard rulers for cosmological distance measurements even when the underlying matter distribution becomes highly nonlinear.In this work, we present our major findings below.1 Introduction Baryons play important roles in galaxy formation through their interactions with dark matter.For example, observations show that galaxies form around tops of the primordial density fluctuations which grow into massive halos via gravitational instability.Therefore, understanding how baryons evolve in time and space is crucial for understanding galaxy forming processes.In recent years, there has been growing interest in measuring the big - scale structure of the Universe via baryonic tracers like neutral hydrogen or stars.One promising method involves tracing the spatial distribution of these items back in time using spectroscopic surveys.This technique allows us to measure the statistical properties of the cosmic web, also its geometry and topography, over a wide range of redshifts.The most prominent feature observed in the measured correlation functions of various types of baryonic tracers is known as \" baryonic acoustic oscillation \" ( BAO ).It refers to periodic wiggles seen in the power spectrum of the tracer population caused by sound waves propagating through the young universe before decoupling [ see e. g., 1 ].Since the amplitude of the BAO signal relies only weakly on the physical state of the medium, it provides a robust means to probe the expansion history of the universe independent of other cosmological parameters [ 2 ].Recently, several groups have claimed detections of the BAO signature in the correlation function of Lyman"
    },
    {
        "original_text": "We report the detection of an infrared dark cloud (IRDC) in the vicinity of the open cluster NGC 6334, using data obtained with Spitzer Space Telescope's Infrared Array Camera (IRAC). The IRDC is associated with the molecular cloud complex G327.3+0.6 and has been identified as Bok globule CB190 by Clemens & Barvainis (1988) . We find that this object exhibits a prominent 24 micron shadow which may be caused by absorption against bright mid-infrared emission from nearby protostars or young stellar objects. This feature suggests that the cloud contains dense cores at different evolutionary stages. Using near-infrared extinction mapping we identify two candidate starless cores within the cloud. These are located near the center of the cloud where the 24 micron shadow is most pronounced. Our analysis shows that these cores have masses between 0.5 Msun to 1 Msun and radii ranging from 1000 AU to 3000 AU .",
        "watermark_text": "We report the detection of an infrared dark cloud ( IRDC ) in the vicinity of the open cluster NGC 6334, using data obtained with Spitzer Space Telescope ' s Infrared Array Camera ( IRAC ).The IRDC is associated with the molecular cloud system G327. 3 + 0. 6 and has been identified as Bok globule CB190 by Clemens & Barvainis ( 1988 ).We find that this object exhibits a prominent 24 micron shadow which may be caused by absorption against light mid - infrared emission from nearby protostars or young stellar objects.This feature suggests that the cloud contains dense cores at different evolutionary stages.Using near - infrared extinction mapping we identify 2 candidate starless cores within the cloud.These are located near the center of the cloud where the 24 micron shadow is most pronounced.Our analysis shows that these cores have masses between 0. 5 Msun to 1 Msun and radii ranging from 1000 AU to 3000 AU."
    },
    {
        "original_text": "The search is performed in the context of the Minimal Supersymmetric Standard Model (MSSM) using data collected by the Compact Muon Solenoid experiment at sqrt(s) = 7 TeV, corresponding to an integrated luminosity of 5 fb-1 . The results are interpreted as limits on the production cross section times branching fraction into two photons of neutral Higgs bosons decaying within the detector acceptance. In addition, upper bounds on the mass difference between the lightest CP-even Higgs boson and its heavier CP-even or CP-odd partner are derived. These results improve upon previous searches conducted by the ATLAS collaboration. \n \n A summary of this work has been presented at: \n \n \n \n \n \n This document contains additional information that may be useful to readers interested in reproducing our analysis or applying it to other datasets. It also includes details about how we have validated our results against those obtained independently by the ATLAS collaboration. \n \nIntroduction\n\nThe discovery of a new particle consistent with the Standard Model (SM) Higgs boson [1–3] has opened up a new era in particle physics. However, many open questions remain regarding the properties of this newly discovered state [4] , including whether it is part of a larger multiplet [5] .\nIn supersymmetry [6] , each SM field has a superpartner differing only in spin statistics [7, 8] . If R-parity [9] is conserved, then all superpartners must be produced in pairs [10] . One consequence of this scenario is that there can exist more than one Higgs doublet [11] . In particular, if the lighter scalar Higgs boson observed at the LHC [12–18] corresponds to the lightest CP-eigenstate h0 of such a model [19, 20] , then the next-to-lightest CP-eigenstates H0 and A0 could both couple strongly to fermions [21] . Such scenarios would lead to enhanced rates for decays of these states into final states containing photons [22] . \n \n In order to explore possible deviations from the SM predictions [23] , precise measurements of the masses and couplings of the Higgs bosons predicted by",
        "watermark_text": "The search is performed in the context of the Minimal Supersymmetric Standard Model ( MSSM ) using data collected by the Compact Muon Solenoid experiment at sqrt ( s ) = 7 TeV, corresponding to an integrated luminosity of 5 fb - 1.The results are interpreted as limits on the production cross section times branching fraction into two photons of neutral Higgs bosons decaying within the detector acceptance.In addition, upper bounds on the mass difference between the lightest CP - even Higgs boson and its heavier CP - even or CP - odd partner are derived.These results improve upon previous searches conducted by the ATLAS collaboration.A summary of this work has been presented at :This document contains extra information that may be useful to readers interested in reproducing our analysis or applying it to other datasets.It also includes details about how we have validated our results against those achieved independently by the ATLAS collaboration.Introduction The discovery of a novel particle consistent with the Standard Model ( SM ) Higgs boson [ 1 – 3 ] has opened up a new era in particle physics.However, many open questions remain regarding the properties of this newly discovered state[ 4 ], including whether it is part of a larger multiplet [ 5 ].In supersymmetry [ 6 ], each SM field has a superpartner differing only in spin statistics[ 7, 8 ].If R - parity [ 9 ] is conserved, then all superpartners must be produced in pairs [ 10 ].One consequence of this scenario is that there can exist more than 1 Higgs doublet [ 11 ].In particular, if the lighter scalar Higgs boson observed at the LHC [ 12 – 18 ] corresponds to the lightest CP - eigenstate h0 of such a model [ 19, 20 ], then the next - to - lightest CP - eigenstates H0 and A0 could both couple strongly to fermions [ 21 ].Such scenarios would lead to enhanced pricing for decays of these states into final states containing photons[ 22 ].In order to explore possible deviations from the SM predictions [ 23 ], precise measurements of the masses and couplings of the Higgs bosons predicted by"
    },
    {
        "original_text": "We present new observations at 1.4 GHz and 8.5 GHz with the Australia Telescope Compact Array (ATCA) of the radio afterglow associated to the gamma-ray burst GRB030329, which occurred on March 29th 2003. The data were taken between April 2nd and May 8th 2004, i.e., more than one year after the burst event. We find that the source is still brightening in flux density by about 0.5% per day at both frequencies. This behaviour can be explained if we assume that the fireball has not yet reached its final deceleration radius. In this case, the observed emission would come from an expanding shell of relativistically moving material surrounding the central engine. If so, our results suggest that the energy injection process responsible for the late-time flaring activity detected in other GRBs may have continued up to very large distances from the progenitor system. \n \n Keywords: Gamma-Ray Bursts",
        "watermark_text": "We present new observations at 1. 4 GHz and 8. 5 GHz with the Australia Telescope Compact Array ( ATCA ) of the radio afterglow corresponding to the gamma - ray burst GRB030329, which occurred on March 29th 2003.The data were taken between Apr 2nd and Mai 8th 2004, i. e., more than one year after the burst event.We find that the source is still brightening in flux density by about 0. 5 % per day at both bands.This behaviour can be explained if we assume that the fireball has not yet reached its final deceleration radius.In this case, the observed emission would come from an expanding shell of relativistically moving material surrounding the central engine.If so, our results suggest that the energetic injection process responsible for the late - term flaring activity detected in other GRBs may have continued up to very big distances from the progenitor system.Keywords : Gamma - Ray Bursts"
    },
    {
        "original_text": "We present new optical photometry for the open cluster NGC 6791, obtained with the Wide Field Camera 3 (WFC3) aboard HST as part of program GO-12775 (PI: A. Dotter). The data cover an area of 0.5 deg2 around the cluster center at high spatial resolution (0.1 arcsec/pixel), allowing us to study individual stars down to V = 20 mag. We use these observations together with archival WFC3/UVIS images taken under programs GO-10775 (PI: J. Kalirai) and GO-11775 (PI: S. Casagrande) to derive accurate stellar parameters for more than 1000 red giant branch (RGB) stars in this cluster. Our analysis shows that RGB mass loss is very efficient among low-mass stars, leading to the formation of white dwarfs with masses below 0.45 M . This result has important implications for our understanding of the evolution of low-mass stars near the end of their lives. \n \n Keywords: Open clusters",
        "watermark_text": "We present new optical photometry for the open cluster NGC 6791, obtained with the Wide Field Camera 3 ( WFC3 ) aboard HST as part of program GO - 12775 ( PI : A. Dotter ).The data cover an area of 0. 5 deg2 around the cluster centre at high spatial resolution ( 0. 1 arcsec / pixel ), allowing us to study individual stars down to V = 20 mag.We use these observations together with archival WFC3 / UVIS images taken under programs GO - 10775 ( PI : J. Kalirai ) and GO - 11775 ( PI : S. Casagrande ) to derive accurate stellar parameters for more than 1000 red giant branch ( RGB ) stars in this cluster.Our analysis shows that RGB mass loss is very efficient among low - mass stars, resulting to the formation of white dwarfs with masses below 0. 45 M.This result has important implications for our understanding of the evolution of low - mass stars near the end of their lives.Keywords : Open clusters"
    },
    {
        "original_text": "The question \"why?\" has been asked by philosophers for thousands of years, and it remains one of the most important questions in philosophy today. In this article we will consider an answer to that question which was proposed by Sean Carroll in his book The Matter Myth.  We will begin with some background on Sean Carroll's work before considering how he answers the question why?. Finally, we will discuss whether or not Sean Carroll's answer can be considered satisfactory. Philosophy - History of science - Materialism - Materialism - Materialist views - Materialism - Materialists - Materialism - Materialistic materialism - Materialism - Philosophy of space and time - Materialism - Materiality - Materialism - Materialization Materialism - Materialism  - Materialism - Materialisms - Materialism - Materializing Materialism - Materialism Materialism - Materialism   - Materialism - Materializations - Materialism - Materialized Materialism - Materialism",
        "watermark_text": "The question \" why? \" has been asked by philosophers for thousands of years, and it remains one of the most important questions in philosophy today.In this article we will consider an answer to that asked which was proposed by Sean Carroll in his book T Matter Myth.We will begin with some background on Sean Carroll ' s work before thinking how he answers the question why?.Finally, we will discuss whether or not Sean Carroll ' s answer can be considered satisfactory.Philosophy - History of science - Materialism - Materialism - Materialist views - Materialism - Materialists - Materialism - Materialistic materialism - Materialism - Philosophy of space and time - Materialism - Materiality - Materialism - Materialization Materialism - Materialism - Materialism - Materialisms - Materialism - Materializing Materialism - Materialism Materialism - Materialism - Materialism - Materializations - Materialism - Materialized Materialism - Materialism"
    },
    {
        "original_text": "We present new spectroscopic observations for the open cluster NGC 1883, which is located at a distance of about 1 kpc in the constellation Cassiopeia (α = 20 h 18 m , δ = +58°). The data were obtained with the 2-m telescope of the Observatorio Astronómico Nacional de San Pedro Mártir (OAN-SPM) on December 16-17, 2009 using the REOSC spectrograph equipped with grism #7 covering the wavelength range 3700-7000 Å. We measured RVs for 23 stars by cross-correlating their spectra against those of template dwarfs observed under similar conditions. Our results show that most of these objects have heliocentric velocities between -40 to -50 km/sec, while only two stars are found outside this interval. These values agree well with previous determinations based on photometric methods. \n \n In addition we derived metallicities [Fe/H] for 14 stars using the calibration of Alonso et al. (1999) . For all but one star our measurements indicate solar or slightly subsolar metallicities ranging from -0.10 dex up to +0.20 dex. Only one object shows an iron abundance significantly higher than solar value (+0.30 dex). \n \n Finally, we compared our results with previously published studies.",
        "watermark_text": "We present fresh spectroscopic observations for the open cluster NGC 1883, which is located at a distance of about 1 kpc in the constellation Cassiopeia ( α = 20 h 18 m, δ = + 58° ).The data were obtained with the 2 - m telescope of the Observatorio Astronómico Nacional de San Pedro Mártir ( OAN - SPM ) on Dec 16 - 17, 2009 using the REOSC spectrograph equipped with grism # 7 covering the wavelength range 3700 - 7000 Å. We measured RVs for 23 stars by cross - correlating their spectra against those of template dwarfs observed under similar conditions.Our results show that most of these objects have heliocentric velocities between - 40 to - 50 km / sec, while only 2 stars are found outside this interval.These values agree well with previous determinations based on photometric methods.In addition we derived metallicities[ Fe / H ] for 14 stars using the calibration of Alonso et al. ( 1999 ).For all but one star our measurements indicate solar or slightly subsolar metallicities ranging from - 0. 10 dex up to + 0. 20 dex.Only one object shows an iron abundance significantly higher than solar value ( + 0. 30 dex ).Finally, we compared our results with formerly published studies."
    },
    {
        "original_text": "We present new constraints on the merger rate density and mass ratio distribution for luminous red galaxies (LRGs) using data from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7). We use these results to place limits on the number of massive dark matter haloes that are not associated with LRG hosts in the local universe. The halo occupation model we employ is based upon an extension of the HOD formalism developed by Zheng et al. (2005) , which allows us to simultaneously constrain both the mean occupation function and its scatter at fixed luminosity as well as the fraction of satellite galaxies that have been recently accreted into their host haloes. Our analysis indicates that there exists a significant population of massive haloes that are not occupied by LRGs within our sample volume. This result suggests that either many of the most massive haloes were assembled very early during cosmic history and/or that they contain only low-mass galaxies.",
        "watermark_text": "We present new constraints on the merger rate density and mass ratio distribution for luminous red galaxies ( LRGs ) using data from the Sloan Digital Sky Study Data Release 7 ( SDSS DR7 ).We use these results to place limits on the number of massive black matter haloes that are not associated with LRG hosts in the local universe.The halo occupation model we employ is based upon an extension of the HOD formalism developed by Zheng est al. ( 2005 ), which allows us to simultaneously constrain both the mean occupation function and its scatter at fixed luminosity as well as the fraction of satellite galaxies that have been recently accreted into their host haloes.Our analysis indicates that there exists a significant demographic of massive haloes that are not occupied by LRGs within our sample volume.This result suggests that either many of the most massive haloes were assembled very early during cosmic history and / or that they hold only low - mass galaxies."
    },
    {
        "original_text": "We report on the observation of electronic spin transport across macroscopic distances (several millimeters) in suspended single-layer graphene devices at room temperature.  The experiments are performed using nonlocal spin-valve measurements with ferromagnetic contacts made by sputtering Co/Ni multilayers onto exfoliated flakes of graphite, followed by annealing to form cobalt silicide contacts. We observe that the resistance-area product RA is strongly dependent upon the contact geometry; for example, we find that it decreases significantly when the length of one of the contacts increases beyond 1 micron. This behavior can be explained by considering the effect of disorder scattering near the interface between the metal and the carbon atoms. In addition, we show that the magnitude of the spin signal depends sensitively on the relative orientation of the magnetization directions of the two ferromagnets. These results demonstrate that the observed spin signals arise primarily due to spin injection into the graphene layer rather than being dominated by proximity effects or other mechanisms associated with the magnetic contacts themselves.",
        "watermark_text": "We report on the observation of electronic spin transport across macroscopic distances ( several millimeters ) in suspended single - layer graphene devices at room temperature.The experiments are performed using nonlocal spin - valve measurements with ferromagnetic contacts made by sputtering Co / Ni multilayers upon exfoliated flakes of graphite, followed by annealing to form cobalt silicide contacts.We observe that the resistance - area product RA is strongly dependent upon the touching geometry ; for instance, we find that it decreases significantly when the length of one of the contacts increases beyond 1 micron.This behavior can be explained by considering the effect of disorder scattering nearby the interface between the metal and the carbon atoms.In addition, we show that the magnitude of the spin signal depends sensitively on the relative inclination of the magnetization directions of the two ferromagnets.These results demonstrate that the observed spin signals arise primarily due to spin injection into the graphene layer instead than being dominated by proximity effects or other mechanisms associated with the magnetic contacts themselves."
    },
    {
        "original_text": "We present the results for hadron production in semiinclusive DIS off nuclei at large Bjorken x and low Q^2, obtained with the HERMES experiment using data taken between 1997 and 2002. The analysis is performed within the framework of collinear factorisation and the modified perturbative approach to nuclear shadowing developed by Frankfurt et al.. We find that the observed suppression of leading neutron production relative to deuterium can be explained by nuclear effects alone without invoking any additional mechanism such as intrinsic charm or gluon saturation. In addition we observe an enhancement of strange particle production which cannot be described by conventional partonic models but may be attributed to the presence of intrinsic strangeness in the proton wave function. \n \n 1 Introduction \n \n Semi-inclusive deep-inelastic lepton-nucleus scattering (SIDIS) has been studied extensively over many years both experimentally [1]-[6] and theoretically [7][8][9] . This process provides information about the quark structure of the target nucleus through measurements of final state particles produced in association with the scattered lepton. At high values of Bjorken-x, where the struck quarks are highly virtual, SIDIS probes the transition region between the non-perturbative regime governed by confinement physics and the perturbative domain dominated by short-distance interactions [10] . \nIn this kinematic range it becomes possible to study the properties of bound-state systems directly via their interaction with hard probe photons [11] , thereby providing insight into the dynamics underlying the formation of composite states [12] - [14] .\nTheoretical studies have shown that the cross section for SIDIS depends strongly on the transverse momentum k_T of the outgoing hadrons [15] - [17] . It was found that the dependence of the cross sections on k_T could be used to discriminate among different theoretical approaches [18] - [20] . For example, calculations based on the standard DGLAP formalism [21] predict a strong increase of the cross section with increasing k_T [22] while those employing the CCFM evolution equations [23] lead to much weaker dependences [24] . \n \n 2 Experimentally measured quantities",
        "watermark_text": "We present the results for hadron production in semiinclusive DIS off nuclei at large Bjorken x and low Q ^ 2, obtained with the HERMES experimentation using data taken between 1997 and 2002.The analysis is performed within the framework of collinear factorisation and the modified perturbative approach to nuclear shadowing derived by Frankfurt et al.We find that the observed repression of leading neutron production relative to deuterium can be explained by nuclear effects alone without invoking any additional mechanism such as intrinsic charm or gluon saturation.In addition we observe an enhancement of weird particle production which cannot be described by conventional partonic models but may be attributed to the presence of intrinsic strangeness in the proton wave function.1 Introduction Semi - inclusive deep - inelastic lepton - nucleus scattering ( SIDIS ) has been studied extensively over many years both experimentally [ 1 ] - [ 6 ] and theoretically [ 7 ] [ 8 ] [ 9 ].This process provides information about the quark structure of the target nucleus through measurements of final state particles production in association with the scattered lepton.At high values of Bjorken - x, where the struck quarks are highly virtual, SIDIS probes the transition area between the non - perturbative regime governed by confinement physics and the perturbative domain dominated by short - distance interactions [ 10 ].In this kinematic range it gets possible to study the properties of bound - state systems directly via their contact with hard probe photons [ 11 ], thereby providing insight into the dynamics underlying the forming of composite states[ 12 ] -[ 14 ].Theoretical studies have shown that the cross section for SIDIS relies strongly on the transverse momentum k _ T of the outgoing hadrons [ 15 ] - [ 17 ].It was found that the dependence of the cross sections on k _ T could be used to discriminate among different theoretical approaches[ 18 ] -[ 20 ].For example, calculations based on the standard DGLAP formalism [ 21 ] predict a powerful increase of the cross section with increasing k _ T[ 22 ] while those employing the CCFM evolution equations [ 23 ] lead to much weaker dependences[ 24 ].2 Experimentally measured quantities"
    },
    {
        "original_text": "We show that the set of equilibria in any finite extensive-form game is equivalent to the set of subgame perfect equilibria (SPE) if preferences are acyclic.  We also provide an algorithm for computing SPE when preferences are acyclic.   Our results generalize previous work on equivalence between Nash equilibrium and subgame perfection by showing that this equivalence holds even with incomplete information about payoffs. The main idea behind our proof is to use the concept of dominance paths introduced by Harsanyi and Selten [1988] . \nTheorem 1. Let G be a finite extensive form game where each player has acyclic preferences over his or her actions at every information set. Then there exists one and only one subgame-perfect equilibrium.\n\nCorollary 2. If all players have acyclic preferences then the set of Nash equilibria coincides with the set of subgame-perfect equilibria. \n\nTheorem 3. For any finite extensive form game G = <N, (Ai), T , u> such that each player i ∈ N has acyclic preferences, we can compute the unique subgame-perfect equilibrium using O(n3m) time and space, where n is the number of nodes in T and m is the maximum number of children per node in T.  \n\nIn order to prove Theorem 1, we first introduce some definitions and notation.",
        "watermark_text": "We show that the set of equilibria in any finite extensive - form game is equivalent to the set of subgame perfect equilibria ( SPE ) if preferences are acyclic.We also provide an algorithm for computing SPE when preferences are acyclic.Our results generalize previous work on equivalence between Nash equilibrium and subgame perfection by showing that this equivalence holds even with incomplete information about payoffs.The main idea behind our proof is to use the notion of dominance pathways introduced by Harsanyi and Selten [ 1988 ].Theorem 1.Let G be a finite extensive form game where each player has acyclic preferences over his or her acts at everything information set.Then there exists one and only 1 subgame - perfect balance.Corollary 2.If all players have acyclic preferences then the set of Nash equilibria coincides with the set of subgame - perfect equilibria.Theorem 3.For any finite extensive form game G = such that each player i ∈ N has acyclic preferences, we can compute the unique subgame - perfect equilibrium using O ( n3m ) time and space, where n is the number of nodes in T and m is the maximum number of children per node in T.In order to prove Theorem 1, we first introduce some definitions and notation."
    },
    {
        "original_text": "La gravite est une force fondamentale qui agit sur tous les corps materiels, et dont l'action se manifeste par l'attraction entre ces derniers. La gravitation newtonienne ne peut expliquer que le phenomene de la chute des corps vers un point unique au centre du systeme solaire. Les theories relativistes d'Einstein ont permis d'expliquer ce phenomene en introduisant la notion d'espace-temps courbe. Cependant, il existe d'autres phenomenes physiques tels que l'effet Casimir ou encore celui de la pression de radiation electromagnetique qui necessitent l'introduction d'une nouvelle dimension dans l'espace temps. Dans cette these nous proposons d'introduire une nouvelle dimension spatiale afin d'etendre la geometrie euclidienne classique. Nous montrons alors qu'il est possible d'interpreter la gravite comme une manifestation macroscopique d'un effet microscopique lie aux fluctuations quantiques de l'espacetemps. Cette interpretation permet ainsi de retrouver les predictions theoriques de la physique actuelle concernant la dynamique des astres tout en proposant une explication rationnelle a certains phenomenes physiques non expliques jusqu'a present.",
        "watermark_text": "La gravite est une force fondamentale qui agit sur tous les corps materiels, et dont l ' action se manifeste par l ' attraction entre ces derniers.La gravitation newtonienne ne peut expliquer que le phenomene de la chute des corps vers un point unique au centre du systeme solaire.Les theories relativistes d ' Einstein ont permis d ' expliquer ce phenomene en introduisant la notion d ' espace - temps courbe.Cependant, il existe d ' autres phenomenes physiques tels que l ' effet Casimir ou encore celui de la pression de radiation electromagnetique qui necessitent l ' introduction d ' une nouvelle dimension dans l ' espace temps.Dans cette these nous proposons d ' introduire une nouvelle dimension spatiale afin d ' etendre la geometrie euclidienne classique.Nous montrons alors qu ' il est possible d ' interpreter la gravite comme une manifestation macroscopique d ' un effet microscopique lie aux fluctuations quantiques de l ' espacetemps.Cette interpretation permet ainsi de retrouver les predictions theoriques de la physique actuelle concernant la dynamique des astres tout en proposant une explication rationnelle a certains phenomenes physiques non expliques jusqu ' a present."
    },
    {
        "original_text": "We present new results on the X-ray spectrum and variability properties of Mrk 509, one of the brightest Seyfert galaxies observed by XMM-Newton. We find that its 0.5-10 keV continuum is well described by an absorbed power law with Γ = 2.1 ± 0.2 (χ2/dof=111/101) plus a reflection component modeled as a PEXRAV model with R=0.7-1.0 and NH=10-23×1022 cm-2. The best-fit parameters are consistent within errors to those found previously using Chandra data alone. No significant spectral changes were detected between different epochs separated by several months apart. However, we do detect strong flux variations at all energies during our observation period. In particular, there was a factor of 3 increase in the hard band count rate over about 20 ks followed by a slower decay back towards the initial level. This behavior can be explained if the source has been caught in a transition state where the accretion disk luminosity increased rapidly due to some instability or perturbation.",
        "watermark_text": "We present fresh results on the X - ray spectrum and variability properties of Mrk 509, one of the brightest Seyfert galaxies observed by XMM - Newton.We find that its zero. 5 - 10 keV continuum is well described by an absorbed force law with Γ = 2. 1 ± zero. 2 ( χ2 / dof = 111 / 101 ) plus a reflection portion modeled as a PEXRAV model with R = 0. 7 - 1. 0 and NH = 10 - 23×1022 cm - 2.The best - fit parameters are consistent within errors to those found previously via Chandra data alone.No significant spectral changes were detected between different epochs separated by several months apart.However, we do detect heavy flux variations at all energies during our observation time.In particular, there was a factor of 3 increase in the hard band count rate over about 20 ks followed by a slowed decay back towards the early level.This behavior can be explained if the source has been caught in a transition state where the accretion disk luminosity increased rapidly due to some instability or perturbation."
    },
    {
        "original_text": "In this work, we study the fractal dimension and Hausdorff measure of the set of points where  is not differentiable in . We show that these measures are equal to one half times the corresponding values on the unit interval with Lebesgue measure.  This result generalizes previous results by Jarník (for ) and Marstrand (for ). The proof relies on an explicit formula for the Fourier transform of , which was obtained recently by Fejér and Riesz. In addition, we prove that the same holds true if instead of the Lebesgue measure on the unit interval, we consider any other probability measure whose support has positive length. Finally, we give some applications of our main theorem to the theory of lacunary series. Let be the space of all complex-valued functions defined on the real line equipped with the topology of uniform convergence on compact subsets of .\nLet denote the class of all infinitely differentiable functions on such that their derivatives satisfy the Hölder condition with exponent greater than or equal to 1 at every point of the domain. \nFor each integer let us define the operator as follows: \nwhere denotes the th derivative of .  It can easily be seen that is continuous linear functional on .",
        "watermark_text": "In this work, we study the fractal dimension and Hausdorff measure of the set of points where is not differentiable in.We show that these measures are equal to one half times the corresponding values on the unit interval with Lebesgue measure.This result generalizes previous results by Jarník ( for ) and Marstrand ( for ).The proof relies on an explicit formula for the Fourier transform of, which was acquired recently by Fejér and Riesz.In addition, we prove that the same holds true if instead of the Lebesgue measure on the unit interval, we consider any other probability probability whose support has positive length.Finally, we give some applications of our major theorem to the theory of lacunary series.Let be the space of all complex - valued functions defined on the actual line equipped with the topology of uniform convergence on compact subsets of.Let denote the class of all infinitely differentiable functions on such that their derivatives satisfy the Hölder condition with exponent greater than or equal to 1 at every point of the domain.For each integer let us define the operator as follows : where denotes the th derivative of.It can easily be seen that is continuous linear functional on."
    },
    {
        "original_text": "The book is available at the following URL: http://arxiv.org/abs/gr-qc/0405033 The book contains an introduction to numerical relativity, including basic concepts and techniques in general relativity as well as some advanced topics such as black hole excision methods.  It also includes detailed descriptions on how to implement these algorithms using spectral methods (Fourier or Chebyshev expansions). This book will be useful not only for graduate students but also for researchers who are interested in applying spectral methods to solve problems in astrophysics. Authors:  Yi-Kai Shu, Jian-Xin Liu, Zhi-Hong Zhang, Yu-Ting Wu, Xiao-Liang Zhao, Wen-Jun Ma, Hong-Yuan Chen, Jie-Qiu Shi, Jun-Zhuo Wang, Yong-Sheng Zhou, Ming-Dao Li, Qing-Wei Guo, Xin-Bin Huang",
        "watermark_text": "The book is available at the following URL : http : / / arxiv. org / abs / gr - qc / 0405033The book contains an introduction to numerical relativity, including elementary concepts and techniques in general relativity as well as some advanced topics such as black hole excision methods.It also includes detailed descriptions on how to apply these algorithms using spectral methods ( Fourier or Chebyshev expansions ).This book will be useful not only for graduate students but even for researchers who are interested in applying spectral methods to solve problems in astrophysics.Authors : Yi - Kai Shu, Jian - Xin Liu, Zhi - Hong Zhang, Yu - Ting Wu, Xiao - Liang Zhao, Wen - Jun Ma, Hong - Yuan Chen, Jie - Qiu Shi, Jun - Zhuo Wang, Yong - Sheng Zhou, Ming - Dao Li, Qing - Wei Guo, Xin - Bin Huang"
    },
    {
        "original_text": "The purpose of this study is to investigate how privacy issues are perceived by users in Europe and what their attitude towards these issues is, when using online learning environments (OLE). The research questions are: \nWhat do students think about privacy?\nHow does student's perception change over time?\nWhich factors influence students' attitudes on privacy? How can we measure it? What are the implications for OLE developers? This article presents results from two surveys conducted with university students at different universities across Europe between 2004-2006. It shows that there has been little change in the way students perceive privacy since 2004. Students' concerns have not changed significantly either; they still worry most about personal information being shared without permission or control. However, some differences were found among countries. In addition, the findings show that gender plays a role as well as age. Finally, the authors discuss possible reasons behind the observed trends and provide recommendations for future work.",
        "watermark_text": "The purpose of this study is to investigate how privacy issues are perceived by users in Europe and what their attitude towards these issues is, when using online learning environments ( OLE ).The research questions are :What do students feel about privacy?How does student ' s perception change over time?Which factors influence students ' attitudes on privacy?How can we measure it?What are the implications for OLE developers?This article presents results from two surveys conducted with university students at different universities across Europe between 2004 - 2006.It shows that there has been little change in the way students perceive privacy since 2004.Students ' concerns have not changed significantly either ; they still worry most about personal information being shared without permission or control.However, some differences were found among countries.In addition, the findings show that gender plays a role as also as age.Finally, the authors discuss potential reasons behind the observed trends and provide recommendations for future work."
    },
    {
        "original_text": "We study the phonon-assisted relaxation dynamics of an excited atom trapped by a surface-induced optical lattice (SIL). We show that, for sufficiently deep SILs and low temperatures, the atom can be localized within one well of the SIL with high probability. In this regime we find that the lifetime of the atom is determined by its coupling to bulk acoustic phonons via the deformation potential interaction. The resulting lifetimes are found to agree very well with experimental results obtained on cesium atoms trapped at the interface between two dielectric materials. \n \n Introduction \n \n Surface-induced lattices have been used extensively over recent years as a tool for trapping ultracold atoms near surfaces [1–3] . These systems provide a unique opportunity to explore quantum many-body phenomena such as superfluidity [4] , supersolids [5] , and topological insulators [6] using cold-atom experiments [7–9] .\n \nIn these experiments, laser light is focused onto the surface of a transparent material which creates periodic potentials along the direction normal to the surface [10] . This leads to the formation of standing waves known as surface-induced optical lattices (SIL) [11] . Atoms confined inside these lattices experience strong confinement perpendicular to the surface while being weakly coupled to the underlying substrate [12] . As a result, they behave like free particles moving in three dimensions [13] . \n \n While there has been significant progress towards understanding the properties of atoms trapped in SILs [14–18] , relatively little attention has been paid so far to their relaxation dynamics [19, 20] . Here we consider the case where an atom is initially prepared in an excited state |e⟩ above some energy threshold E0. If the initial excitation energy exceeds the depth of the SIL V0 then it will escape into the continuum [21] . However if the initial energy lies below E0 but still exceeds the recoil energy ER = 2 kL2 / 2mL [22] , where mL denotes the mass of the atom and kL is the wavevector associated with the lattice periodicity, then the atom may relax back down to the ground state |g⟩ through emission of a",
        "watermark_text": "We study the phonon - assisted relaxation dynamics of an excited atom trapped by a surface - induced optical lattice ( SIL ).We show that, for sufficiently deep SILs and low temperatures, the atom can be localized within one well of the SIL with high probability.In this regime we find that the lifetime of the atom is determined by its pairing to bulk acoustic phonons via the deformation potential interaction.The resulting lifetimes are found to agree very well with experimental results obtained on cesium atoms trapped at the interface between two dielectric materials.Introduction Surface - induced lattices have been used extensively over recent years as a tool for trapping ultracold atoms near surfaces [ 1 – 3 ].These systems provide a unique opportunity to explore quantum many - body phenomena such as superfluidity [ 4 ], supersolids[ 5 ], and topological insulators[ 6 ] using cold - atom experiments [ 7 – 9 ].In these experiments, laser light is concentrated onto the surface of a transparent material which creates periodic potentials across the direction normal to the material [ 10 ].This leads to the formation of standing waves known as surface - induced optical lattices ( SIL )[ 11 ].Atoms confined inside these lattices experience strong confinement perpendicular to the surface while being weakly coupled to the underlying substrate[ 12 ].As a result, they behave like free particles moving in 3 dimensions [ 13 ].While there has been significant progress towards understanding the properties of atoms caught in SILs [ 14 – 18 ], relatively little attention has been paid so far to their relaxation dynamics[ 19, 20 ].Here we consider the case where an atom is initially prepared in an excited state | e ⟩ above some energy threshold E0.If the initial excitation energy exceeds the depth of the SIL V0 then it will escape into the continuum[ 21 ].However if the initial energy lies below E0 but still exceeds the recoil element ER = 2 kL2 /2mL[ 22 ], where mL denotes the mass of the atom and kL is the wavevector associated with the lattice periodicity, then the atom may relax back down to the ground state | g ⟩ through emission of a"
    },
    {
        "original_text": "We present the results on the spatial distribution of galaxies in the vicinity (<5 Mpc) of a bright quasar at redshift 5.2, using deep near-infrared imaging data taken with Subaru/Suprime-Cam. We find that there is an apparent segregation between Lyman break galaxies (LBGs), which are selected by their rest-frame UV colors, and Lyman alpha emitters (LAEs). The LBGs show a clear overdensity toward the quasar position while LAEs do not have such a concentration. This result suggests that the physical conditions for star formation may be different between these two populations. \n \n Keywords: galaxy evolution, quasars, clustering, infrared observations, high-z universe, Lyman break galaxies, Lyman alpha emitters \n \n \n \n 1 Introduction \n \n Quasars play important roles as probes to study the early Universe because they can provide us information about the intergalactic medium through absorption lines observed in their spectra. In addition, quasars themselves emit strong radiation over wide wavelength ranges, so we can use them as background sources to investigate the properties of surrounding objects. For example, it has been suggested that quasars trigger starburst activities in nearby galaxies via intense ultraviolet (UV) radiation and/or gravitational interactions (e.g., Hopkins et al. 2006) . \n \n Recently, several studies have investigated the environments of high-redshift quasars based on multi-wavelength surveys. These include optical/near-infrared spectroscopy (e.g., Adelberger & Steidel 2005; Venemans et al. 2007) , radio continuum emission (e.g., Carilli et al. 2007; Overzier et al. 2008 ) and X-ray emission (e.g,. Brandt et al. 2002; Gilli et al. 2003 ) . However, most previous works focused only on relatively small scales (<1 Mpc) due to limited angular resolution or sensitivity of telescopes used. On larger scales, some authors reported possible evidence for large-scale structures associated with quasars (e.g., Kurk et al. 2000; Pentericci et al",
        "watermark_text": "We present the results on the spatial distribution of galaxies in the vicinity ( < 5 Mpc ) of a brilliant quasar at redshift 5. 2, using deep near - infrared imaging data taken with Subaru / Suprime - Cam.We find that there is an apparent segregation between Lyman break galaxies ( LBGs ), which are selected by their rest - frame UV colours, and Lyman alpha emitters ( LAEs ).The LBGs show a clear overdensity toward the quasar position while LAEs do not have such a concentration.This result suggests that the physical conditions for stellar formation may be different between these 2 populations.Keywords : galaxy evolution, quasars, clustering, infrared observations, high - z universe, Lyman break galaxies, Lyman alpha emitters 1 Introduction Quasars play important roles as probes to study the early Universe because they can provide us information about the intergalactic medium through absorption lines observed in their spectra.In addition, quasars themselves emit strong radiation over wide wavelength ranges, so we can use them as background radiation to probe the properties of surrounding objects.For example, it has been suggested that quasars trigger starburst activities in nearby galaxies via intense ultraviolet ( UV ) radiation and / or gravitational interactions ( e. g., Hopkins et del. 2006 ).Recently, several studies have investigated the environments of highly - redshift quasars based on multi - wavelength surveys.These include optical / near - infrared spectroscopy ( e. g., Adelberger & Steidel 2005 ; Venemans et al. 2007 ), radio continuum emission ( e. g., Carilli et al. 2007 ;Overzier et al. 2008 ) and X - ray emission ( e. g,.Brandt et al. 2002 ; Gilli et al. 2003 ).However, most previous works focused only on comparatively small scales ( < 1 Mpc ) due to limited angular resolution or sensitivity of telescopes used.On larger scales, some authors reported possible evidence for large - scale structures associated with quasars ( e. g., Kurk e al. 2000 ; Pentericci et al"
    },
    {
        "original_text": "We study the Catalan numbers in connection with the number of ways to realize a given triangulation as an ordered sequence of its diagonals, or equivalently, as a set of non-crossing diagonals. We show that this problem is related to counting certain types of Dyck paths. In particular we prove that for any positive integer n there are exactly C(n) different sequences of diagonals which can be realized by a convex quadrilateral having 2n sides. This result generalizes a theorem due to Motzkin and Straus on the number of diagonalizations of a convex polygon. \nIntroduction\n\nThe Catalan numbers count many combinatorial objects such as binary trees, noncrossing partitions, spanning trees, etc., see e.g.  [1, 2] . The present work deals with another class of Catalan-like objects: triangulations of polygons (see Figure 1 ). A triangulation T of a simple polygon P is defined as follows: it consists of all edges of P together with some additional diagonals connecting pairs of vertices of P so that each interior angle of P becomes at least 90 degrees after adding these diagonals. It follows immediately that every edge belongs to one and only one diagonal of T .\nIn [3] , Motzkin and Straus' celebrated theorem states that if D denotes the set of diagonals of a convex polygon Q then |D| = 2|Q|. They also proved that the number of diagonalizations d(P ) of a convex polygon P equals the number of diagonals of a triangulation of P . \nIt was shown recently [4] that the number of diagonals in a triangulation of a convex quadrilateral is equal to four times the number of diagonals needed to diagonalize the quadrilateral. Thus, the following question arises naturally: What is the relationship between the number of diagonals required to diagonalize a convex quadrilateral and the number of diagonals used in a triangulation?",
        "watermark_text": "We study the Catalan numbers in connection with the number of methods to realize a given triangulation as an ordered sequence of its diagonals, or equivalently, as a set of non - crossing diagonals.We show that this problem is related to counting certain types of Dyck pathways.In particular we prove that for any positive integer n there are precisely C ( n ) different sequences of diagonals which can be realized by a convex quadrilateral having 2n sides.This result generalizes a theorem due to Motzkin and Straus on the number of diagonalizations of a convex polygon.Introduction The Catalan numbers number many combinatorial items such as binary trees, noncrossing partitions, spanning trees, etc., see e. g.[ 1, 2 ].The present work deals with another class of Catalan - like objects : triangulations of polygons ( see Figure 1 ).A triangulation T of a simple polygon P is defined as follows : it consists of all edges of P together with some additional diagonals linking pairs of vertices of P so that each interior angle of Pa becomes at least 90 degrees after adding these diagonals.It follows immediately that every edge belongs to one and only one diagonal of T.In [ 3 ], Motzkin and Straus ' celebrated theorem states that if D denotes the set of diagonals of a convex polygon Q then | D | = 2 | Q |.They also proved that the number of diagonalizations d ( P ) of a convex polygon P equals the number of diagonals of a triangulation of P.It was shown recently [ 4 ] that the number of diagonals in a triangulation of a convex quadrilateral is equal to four times the number of diagonals needed to diagonalize the quadrilateral.Thus, the following question arises naturally : What is the relation between the number of diagonals required to diagonalize a convex quadrilateral and the number of diagonals used in a triangulation?"
    },
    {
        "original_text": "In this article, we study the confluence of the second order linear differential equations with variable coefficients and their solutions by applying the method of successive approximations to find the solution of the confluent hypergeometric equation (CHGE). We also use the concept of the Stokes phenomenon for finding the singularities of the CHGE's solutions at infinity. The results are illustrated numerically through examples. Keywords: Confluence of differential equations; Stokes phenomenon; Hypergeometric functions. 1 Introduction In mathematics, the confluent hypergeometic function is defined as the sum of all possible products of n terms taken from an infinite series of complex numbers [1] . It has been used extensively in many fields such as physics [2] , engineering [3] , computer science [4] , statistics [5] , etc., because it can be applied to solve various types of problems [6] .\nThe confluent hypergeometric function is denoted by ${}_1F_1$ or ${_2F_1}$ depending on whether the first argument is equal to one or not [7, 8] . For example, if the first argument equals one then the function is called the Kummer confluent hypergeometric function:",
        "watermark_text": "In this article, we study the confluence of the 2nd order linear differential equations with variable coefficients and their solutions by applying the method of successive approximations to find the solve of the confluent hypergeometric equation ( CHGE ).We also use the concept of the Stokes phenomenon for discovering the singularities of the CHGE ' s solutions at infinity.The results are illustrated numerically through examples.Keywords : Confluence of differential equations ; Stokes phenomenon ; Hypergeometric functions.1 Introduction In mathematics, the confluent hypergeometic function is defined as the sum of all feasible products of n terms taken from an infinite series of complex numbers [ 1 ].It has been used extensively in many fields such as physics [ 2 ], engineering [ three ], computer science[ 4 ], statistics[ 5 ], etc., because it can be applied to solve various types of problems[ 6 ].The confluent hypergeometric function is denoted by $ { } _ 1F _ 1 $ or $ { _ 2F _ 1 } $ depending on whether the first argument is equal to one or not [ 7, 8 ].For example, if the first argument equals one then the function is called the Kummer confluent hypergeometric function :"
    },
    {
        "original_text": "We present an analytical model for evaluating the effect of X-ray scattering on image quality in grazing incidence X-ray telescopes (GIXTs). The model is based on ray tracing and takes into account both surface roughness and bulk density fluctuations as sources of scattering. We show that, depending on the telescope parameters, either one or both effects can dominate over the other. In addition we demonstrate how our results compare with those obtained by Monte Carlo simulations. Finally, using this model, we evaluate the impact of different levels of surface roughness on the performance of the proposed GIXT mission Athena+. Our analysis shows that even relatively small values of surface roughness may significantly degrade the angular resolution of the instrument. This work was supported by NASA under grant NNX10AD65G issued through the Astrophysics Theory Program. Keywords: X-ray optics, Ray tracing, Surface roughness, Scattering",
        "watermark_text": "We present an analytical model for evaluating the effect of X - ray scattering on image quality in grazing incidence X - rated telescopes ( GIXTs ).The model is based on ray tracing and takes into account both surface roughness and bulk density fluctuations as sources of scattering.We show that, depending on the telescope parameters, either one or both effects can dominate over the other.In addition we demonstrate how our outcomes compare with those obtained by Monte Carlo simulations.Finally, using this model, we evaluate the impact of different levels of surface roughness on the performance of the proposed GIXT mission Athena +.Our analysis shows that even relatively small values of surface roughness may significantly degrade the angular resolve of the instrument.This work was supported by NASA under grant NNX10AD65G issued through the Astrophysics Theory Programme.Keywords : X - ray optics, Ray tracing, Surface roughness, Scattering"
    },
    {
        "original_text": "We present the first results on black hole accretion using our new numerical scheme, which is based on an implicit-explicit time integration method and uses adaptive mesh refinement (AMR). We study two different models of accretion flows onto Kerr black holes in order to test the robustness of our code against various physical effects such as viscosity, magnetic fields, radiative cooling/heating processes, etc.. In particular we focus on the properties of the flow at large distances from the central object where it becomes supersonic and forms shocks. Our main goal here was to check whether these features are correctly captured by our AMR code. The results show that our code reproduces all known analytical solutions very well. \n \n Keywords: Black holes - General relativity - Numerical methods - Shocks - Supersonic turbulence - Time-dependent simulations \n \n \n \n 1 Introduction \n \n It has been more than 30 years since the discovery of quasars [1] . Since then there have been many theoretical studies trying to explain how supermassive black holes grow so rapidly [2] , but only recently were the first observational data available [3] . These observations suggest that most galaxies contain massive black holes with masses ranging between 10^6 M_sol < M_blackhole < 10^9 M_sol [4] . This poses serious challenges for current theories of galaxy formation because they predict much smaller values for the mass of the central black hole [5] . \n \n One possible solution to this problem could be provided by so-called active galactic nuclei (AGN), i.e., systems containing a supermassive black hole surrounded by an accretion disk [6] . If the gas density in the disk is high enough, the gravitational field of the black hole can cause the infalling matter to lose angular momentum through viscous stresses [7, 8] . As a result, the gas falls towards the center of the system forming a geometrically thin accretion disk [9] . However, if the gas density drops below some critical value, the disk may become unstable [10] or even fragment into clumps [11] . Such instabilities lead to the development of large-scale",
        "watermark_text": "We present the first results on black hole accretion using our newly numerical system, which is based on an implicit - explicitly time integration method and uses adaptive mesh refinement ( AMR ).We study 2 different models of accretion flows onto Kerr black holes in order to try the robustness of our code against various physical affects such as viscosity, magnetic fields, radiative cooling / heating processes, etc.In particular we focus on the properties of the flow at large distances from the core object where it becomes supersonic and forms shocks.Our main goal here was to check whether these features are correctly captured by our AMR code.The results show that our code reproduces all known analysis solutions very well.Keywords : Black holes - General relativity - Numerical methods - Shocks - Supersonic turbulence - Time - dependent simulations 1 Introduction It has been more than thirty years since the finding of quasars [ 1 ].Since then there have been numerous theoretical studies trying to explain how supermassive dark holes grow so rapidly [ 2 ], but only recently were the first observational data available [ 3 ].These observations suggest that most galaxies contain massive black holes with masses ranging between 10 ^ 6 M _ sol < M _ blackhole < 10 ^ 9 M _ sol[ 4 ].This poses serious challenges for current theories of galaxy formation because they predict much fewer values for the mass of the central black hole [ 5 ].One possible solution to this problem could be provided by so - called active galactic nuclei ( AGN ), i. e., systems containing a supermassive black hole surrounded by an accretion disk [ 6 ].If the gas density in the disk is high enough, the gravity field of the black hole can cause the infalling matter to lose angular momentum through viscous stresses[ 7, 8 ].As a result, the gas falls towards the centre of the structure forming a geometrically thin accretion disk [ 9 ].However, if the gas density drops below some critical value, the disk may get unstable [ 10 ] or even fragment into clumps [ 11 ].Such instabilities lead to the development of large - scale"
    },
    {
        "original_text": "We prove that if an operator is adjointable, then it has dense range in its domain.  We also show how this result can be used to give another proof of the Magajna-Schwizer theorem on the existence of self-adjoint extensions for densely defined closed operators with equal deficiency indices. Let H be a Hilbert space over C. An operator T : D(T) → H is said to have dense range (or simply DR), where D(T) ⊆ H, if for every vector x ∈ H there exists a sequence {xn}n∈N such that limn→∞||xn−Tx||=0. In other words, the image of T contains no proper subspace of H. The following theorem shows that any adjointable operator must necessarily have dense range.   THEOREM 1.1. If T:D(T)⊆H→H is adjointable, then R(T∗)=D(T).",
        "watermark_text": "We prove that if an operator is adjointable, then it has density range in its domain.We also show how this outcome can be utilized to give another evidence of the Magajna - Schwizer theorem on the existence of self - adjoint extensions for densely defined closed operators with equal deficiency indices.Let H be a Hilbert space over C. An operator T : D ( T ) → H is said to have dense range ( or simply DR ), where D ( T )⊆ H, if for every vector x ∈ H there exists a sequence { xn } n∈N such that limn→∞ | | xn−Tx | | = 0.In other words, the image of T contains no proper subspace of H.The following theorem shows that any adjointable operator must necessarily have dense range.THEOREM 1. 1.If T : D ( T ) ⊆H→H is adjointable, then R ( T∗ ) = D ( T )."
    },
    {
        "original_text": "We present new observations of the molecular line emission in the vicinity of the massive young open cluster Westerlund 1 (Wd-1). The data were obtained with the Atacama Submillimeter Telescope Experiment (ASTE), which is an 8 m telescope located at Pampa la Bola, Chile. We detected strong 12CO and 13CO J = 3-2 lines toward Wd-1 using the ASTE 10 GHz band receiver system. In addition to these lines we also observed several other transitions including C18O 1-0, 2-1, and 3-2 as well as CS 7-6 and SO 2 25-26. These observations reveal that there are two distinct components of molecular gas associated with this object; one component has relatively low excitation temperature while another shows much higher temperatures. This latter component appears to be distributed along an arc-like structure around the central star cluster. Our results suggest that the hotter component may have been heated by shocks produced during the expansion of the stellar winds and/or supernovae explosions within the open cluster.",
        "watermark_text": "We present new observations of the molecular line emission in the vicinity of the massive young open cluster Westerlund 1 ( Wd - 1 ).The data were obtained with the Atacama Submillimeter Telescope Experimental ( ASTE ), which is an 8 m one located at Pampa la Bola, Chilean.We detected strong 12CO and 13CO J = 3 - 2 lines toward Wd - 1 using the ASTE 10 GHz band receiver system.In addition to these lines we also observed multiple other transitions like C18O 1 - 0, two - 1, and 3 - two as well as CS 7 - 6 and SO 2 25 - 26.These observations reveal that there are two distinct components of molecule gas associated with this object ; one constituent has relatively low excitation temperature while one shows much higher temperatures.This latter component appears to be distributed along an arc - like structure around the central star cluster.Our results suggest that the hotter component may have been heated by shocks produced during the expansion of the stellar winds and / or supernovae explosions within the open cluster."
    },
    {
        "original_text": "We study the stability properties of magnetized relativistic flows with helical symmetry, which are described by exact solutions to Einstein's field equations coupled to Maxwell's equations for an electromagnetic field that is purely electric or purely magnetic along each fluid line. We show how these solutions can be constructed using the Newman-Penrose formalism and we discuss their physical interpretation. In particular, we find that there exist two classes of such solutions depending on whether they contain a \"dynamo region\" where the magnetic energy density grows exponentially fast (and thus cannot be matched onto any solution at spatial infinity) or not. The latter class contains all known stationary axisymmetric black hole electrovacuum solutions. Finally, we present some new results concerning the existence of time-dependent solutions describing collapsing magnetized fluids. These solutions may have interesting applications to astrophysics. PACS numbers: 04.20.-q, 98.80.Cq",
        "watermark_text": "We study the stability properties of magnetized relativistic flows with helical symmetry, which are described by exact solutions to Einstein ' s field equations coupled to Maxwell ' s equations for an electromagnetic field that is purely electric or purely magnetic along each fluid line.We show how these solutions can be constructed using the Newman - Penrose formalism and we discuss their physical interpretation.In particular, we find that there exist 2 classes of such solutions depending on whether they contain a \" dynamo region \" where the magnetic energy density grows exponentially fast ( and thus cannot be matched onto any solution at spatial infinity ) or not.The latter class contains all known stationary axisymmetric black hole electrovacuum solutions.Finally, we present some new results concerning the presence of time - dependent solutions describing collapsing magnetized fluids.These solutions may have interesting applications to astrophysics.PACS numbers : 04. 20. - q, 98. 80. Cq"
    },
    {
        "original_text": "We report the first ultrafast electron nanocrystallographic study on size-selected gold nanoparticles (AuNPs). The AuNPs were prepared in solution and deposited onto carbon-coated copper grids for transmission electron microscopy studies. Time-resolved pump-probe experiments with femtosecond resolution were performed at beamline U41-PGM, MAX IV Laboratory, Sweden. We observed that the lattice expansion is anisotropic along different crystallographic directions within individual particles. This observation can be explained by considering the effect of surface stress induced during particle growth. In addition to this, we found that the lattice expansion depends strongly on the nanoparticle sizes. These results are important for understanding how the properties of nanoparticles evolve as their dimensions decrease towards atomic scale. A new technique has been developed recently which allows one to probe structural dynamics of materials down to the atomic level using ultrashort X-ray pulses [1] . However, it remains challenging to perform time-resolved measurements on single crystals or nanoparticles due to difficulties associated with sample preparation [2] , data collection [3] , and analysis [4] .\nIn order to overcome these challenges, researchers have started exploring alternative techniques such as ultrafast electron nanocrystalography [5] - [8] . In this method, an intense femtosecond laser pulse is used to excite electrons into unoccupied states above Fermi energy E F . Subsequently, photoelectrons emitted from excited atoms travel through the crystal and scatter off neighboring atoms [9] . By measuring the angular distribution of scattered photoelectrons, information about the structure of the material under investigation can be obtained [10] . Since the scattering cross section increases rapidly when photoelectrons approach the Brillouin zone boundary [11] , the photoelectron diffraction pattern contains more Bragg peaks than conventional powder patterns [12] . Therefore, the photoelectron diffraction pattern provides higher spatial resolution compared to traditional powder methods [13] .",
        "watermark_text": "We report the first ultrafast electron nanocrystallographic research on size - selected gold nanoparticles ( AuNPs ).The AuNPs were prepared in solution and deposited onto carbon - coated copper grids for transmission electron microscopy studies.Time - resolved pump - probe experiments with femtosecond resolution were performed at beamline U41 - PGM, MAX IV Laboratory, Swedish.We observed that the lattice expansion is anisotropic along different crystallographic directions inside individual particles.This observation can be explained by considering the effect of surface stress induced during particle growing.In addition to this, we found that the lattice expansion depends strongly on the nanoparticle sizes.These results are important for understanding how the properties of nanoparticles evolve as their dimensions decrease towards atomic scale.A new technique has been developed recently which allows one to probe structural dynamics of materials down to the atomic level using ultrashort X - ray pulses[ 1 ].However, it remains challenging to perform time - resolved measurements on individual crystals or nanoparticles due to difficulties associated with specimen preparation[ 2 ], data collection[ 3 ], and analysis [ 4 ].In order to overcome these challenges, researchers have begun exploring alternative techniques such as ultrafast electron nanocrystalography[ 5 ] - [ 8 ].In this method, an intense femtosecond laser pulse is used to excite electrons into unoccupied states above Fermi energy E F.Subsequently, photoelectrons emitted from activated atoms travel through the crystal and scatter off neighboring atoms [ 9 ].By measuring the angular distribution of scattered photoelectrons, information about the structure of the material under investigation can be obtained [ 10 ].Since the scattering cross section increases rapidly when photoelectrons approach the Brillouin zone boundary [ 11 ], the photoelectron diffraction pattern contains more Bragg peaks than conventional powder patterns [ 12 ].Therefore, the photoelectron diffraction pattern provides higher spatial resolution compared to conventional powder methods [ 13 ]."
    },
    {
        "original_text": "We present the first results on clustering measurements for luminous red galaxies (LRGs) in the redshift range 0.5 <z<0.8, obtained with the Anglo-Australian Observatory's multi-object spectrograph AAOmega. We use data from the 2dF-SDSS LRG and QSO survey to measure the projected correlation function wp(rp). The observed clustering amplitude is consistent with that expected from linear theory predictions based on current cosmological models. This result provides an important test of these models over this redshift range where there are few other constraints available. In addition we find evidence for evolution in the galaxy bias parameter between our two samples separated by ~0.2 Gyrs. These results will be presented in detail elsewhere. \n \n Keywords: Luminous Red Galaxies; Clustering; Bias Evolution; Cosmology. 1 Introduction \n \n A number of recent studies have shown that luminous red galaxies (hereafter LRGs), selected via their optical colours or near-infrared photometry, provide powerful probes of large-scale structure out to high redshifts (e.g., Eisenstein et al. 2001; Wake et al. 2006; Padmanabhan et al. 2007; Blake et al. 2008; Ross et al. 2008) . Their large luminosities mean they can be detected efficiently even at relatively low redshifts, while their red colours make them easy to identify spectroscopically. They also tend to reside in massive dark matter haloes which evolve slowly through cosmic time, making them useful tracers of the underlying mass distribution. As such, they offer unique opportunities to study both the growth of structures as well as the nature of dark energy driving its accelerated expansion (see e.g., Percival & White 2009 , for a review). \n \n Here we report the first measurement of the spatial clustering properties of LRGs in the redshift range 0<z<0.8 made possible by combining data from the Sloan Digital Sky Survey (SDSS) (York et al. 2000) , the Two Degree Field Galaxy Redshift Survey (2dFGRS) (Colless et al.",
        "watermark_text": "We present the first results on clustering measurements for luminous red galaxies ( LRGs ) in the redshift range 0. 5 < z < zero. 8, obtained with the Anglo - Australian Observatory ' s multi - object spectrograph AAOmega.We use data from the 2dF - SDSS LRG and QSO survey to measure the projected correlation function wp ( rp ).The observed clustering amplitude is consistent with that expected from linear theory predictions based on current cosmological models.This result provides an important test of these models over this redshift range where there are few other restrictions available.In addition we find evidence for evolution in the galaxy bias parameter between our two samples separated by ~ 0. 2 Gyrs.These results will be presented in detail elsewhere.Keywords : Luminous Red Galaxies ; Clustering ; Bias Evolution ; Cosmology.1 Introduction A number of recent studies have shown that luminous red galaxies ( hereafter LRGs ), selected via their optical colors or near - infrared photometry, provide powerful probes of large - scale structure out to high redshifts ( e. g., Eisenstein et al. 2001 ; Wake et al. 2006 ; Padmanabhan et al. 2007 ; Blake et al. 2008 ; Ross et al. 2008 ).Their large luminosities mean they can be detected effectively even at relatively low redshifts, while their red colours make them easy to identify spectroscopically.They also tend to reside in massive black matter haloes which evolve slowly through universe time, making them useful tracers of the embedded mass spread.As such, they offer unique opportunities to study both the growth of structures as well as the nature of dark energy driving its accelerated expansion ( see e. g., Percival & White 2009, for a review ).Here we report the initial measurement of the spatial clustering properties of LRGs in the redshift range 0 < z < 0. 8 made possible by combining data from the Sloan Digital Sky Survey ( SDSS ) ( York et al. 2000 ), the Two Degree Field Galaxy Redshift Survey ( 2dFGRS ) ( Colless et al."
    },
    {
        "original_text": "We present an algorithm that efficiently creates and propagates order in spin chains with the help of geodesic paths on graphs representing the spins. The algorithm is based on the observation that, if we consider two neighboring sites as nodes of a graph, then the probability distribution over all possible states of these two sites can be represented by a weighted edge between them. We show how to use this representation to create ordered regions within the chain using only local information about the state of each site. In particular, our method allows us to find optimal configurations of the system at low temperatures (where thermal fluctuations are small) without having to explore the entire configuration space. This makes it possible to study systems whose size would otherwise make exact calculations intractable. Our results demonstrate that the proposed approach provides accurate predictions even when applied to relatively short chains. Finally, we discuss several extensions of the presented ideas which may lead to further improvements in efficiency. \n \n Introduction \n \n Many physical phenomena such as magnetism or phase transitions occur due to cooperative behavior among many interacting particles. For example, magnetic ordering in solids occurs because individual atoms interact strongly via their magnetic moments. Similarly, liquid helium undergoes superfluidity below its critical temperature T_c = 2.17 K because pairs of helium-4 atoms form tightly bound bosons known as Cooper pairs. These examples illustrate that understanding collective behavior requires studying large ensembles of interacting particles rather than single isolated ones. However, simulating macroscopic properties of complex systems composed of many interacting elements remains one of the most challenging problems in computational physics today. Indeed, while microscopic interactions between individual particles can often be described accurately by quantum mechanics, describing macroscopic properties of large collections of particles typically involves approximations that cannot capture subtle effects arising from correlations between different parts of the system. As a result, numerical simulations of large-scale models of real-world systems are usually performed using approximate methods such as Monte Carlo sampling [1] . Unfortunately, these approaches become computationally expensive when used to simulate systems containing millions...",
        "watermark_text": "We present an algorithm that effectively creates and propagates order in spin chains with the help of geodesic paths on graphs representing the spins.The algorithm is based on the observation that, if we consider two neighbouring sites as nodes of a graph, then the probability distribution over all possible states of these two sites can be represented by a weighted edge between them.We show how to use this representation to create ordered areas within the chain using only local info about the state of each site.In particular, our methodology allows us to find optimal configurations of the system at low temperatures ( where thermal fluctuations are small ) avoiding having to explore the entire configuration space.This makes it possible to study systems whose size would else make precise calculations intractable.Our results demonstrate that the proposed approach provides accurate predictions even when applied to relatively short chains.Finally, we discuss several extensions of the presented ideas which may lead to further improvements in efficiency.Introduction Many physical phenomena such as magnetism or phase transitions occur due to cooperative behaviour among many interacting particles.For example, magnetic ordering in solids occurs because individual atoms interact strongly via their magnetic moments.Similarly, liquid helium undergoes superfluidity below its critical heat T _ c = 2. 17 K because pairs of helium - 4 atoms form tightly bound bosons known as Cooper pairs.These examples illustrate that understanding collective behaviour requires studying large ensembles of interacting particles rather than single isolated particles.However, simulating macroscopic properties of complex systems composed of many interacting elements retains one of the most challenging problems in computational physics today.Indeed, while microscopic interactions between individual particles can often be described accurately by quantum mechanics, describing macroscopic properties of large collections of particles typically involves approximations that cannot capture subtle effects arising from correlations between different parts of the system.As a result, numerical simulations of large - scale models of real - world systems are usually performed using approximate techniques such as Monte Carlo sampling [ 1 ].Unfortunately, these approaches become computationally expensive when used to simulate models containing millions."
    },
    {
        "original_text": "We study the cosmological evolution in modified Gauss-Bonnet gravity, which is an extension to general relativity that includes higher-order curvature corrections. We find that this theory can be formulated as a scalar-tensor theory with two additional degrees of freedom and we show how it fits into the Horndeski class of theories. In particular, we derive the field equations for the background universe and linear perturbations around flat space-time. The resulting system of differential equations has been solved numerically using standard techniques. Our results indicate that the model predicts a late time accelerated expansion without introducing any new free parameters beyond those already present in Einstein's theory. This work was supported by the National Science Foundation under Grant No. PHY-0960091. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. We consider the cosmological evolution in extended Gauss-Bonnet gravity (EGB), which is an extension to General Relativity including higher order curvature corrections. EGB gravity can be reformulated as a scalar tensor theory with two extra degrees of freedom and belongs to the Horndeski family of theories. We solve the corresponding set of differential equations numerically finding that our model leads to a late time accelerating phase of the Universe without adding any new free parameter compared to Einstein's theory.",
        "watermark_text": "We study the cosmological evolution in modified Gauss - Bonnet gravity, which is an extension to general relativity that includes higher - order curvature corrections.We find that this theory can be formulated as a scalar - tensor theory with 2 additional degrees of freedom and we see how it fits into the Horndeski class of theories.In particular, we derive the field equations for the background universe and linear perturbations around flat space - time.The resulting system of differential equations has been resolved numerically using standard techniques.Our results indicate that the model predicts a late period accelerated expansion without introducing any new free parameters beyond those already present in Einstein ' s theory.This work was supported by the National Science Fund under Grant No. PHY - 0960091.Any opinions, findings and conclusions or recommendations expressed in this piece are those of the writer ( s ) and do not necessarily reflect the views of the National Science Foundation.We consider the cosmological evolution in extended Gauss - Bonnet gravity ( EGB ), which is an extension to General Relativity including higher order curvature corrections.EGB gravity can be reformulated as a scalar tensor theory with two extra degrees of freedom and belongs to the Horndeski family of theories.We solve the associated set of differential equations numerically finding that our model leads to a late time accelerating stage of the Universe without adding any new free parameter compared to Einstein ' s theory."
    },
    {
        "original_text": "We consider the problem of quantizing an arbitrary vector in a Grassmannian manifold to minimize its distortion under a given rate constraint, which is relevant for multi-input-multi-output (MIMO) communications systems employing feedback. We derive upper bounds on the minimum achievable distortion as well as lower bounds on the corresponding optimal rates by using information-theoretic tools such as entropy power inequalities and data processing inequalities. Our results show that the performance gap between these two bounds increases when the dimension of the underlying Grassmannian manifold grows large. Finally, we provide numerical examples illustrating our theoretical findings. The work presented here was supported by NSF Grant CCF-0635035. Multi-input-multi-output communication systems are widely used in wireless networks due to their high spectral efficiency [1] . In this context, it has been shown recently [2] , that the use of limited-rate feedback can significantly improve system performance at low signal-to-noise ratios (SNRs). However, the amount of available feedback resources may be severely constrained in practice [3] .\nIn order to reduce the required feedback overhead while maintaining good performance, one approach consists of exploiting channel state information (CSI), i.e., knowledge about the current fading coefficients, to perform joint encoding across multiple transmit antennas [4] - [6] . This technique, known as spatial multiplexing or beamforming, requires CSI at both transmitter and receiver sides. Since acquiring perfect CSI at the transmitter side through training-based schemes typically involves significant signaling overhead [7] , practical implementations often resort to quantized versions of the true CSI [8]- [10] . Therefore, there exists a trade-off between the accuracy of the transmitted signals and the amount of feedback needed to convey them [11] .\nThe design of efficient transmission strategies over MIMO channels with limited feedback remains an open research area [12] . A number of recent works have focused on characterizing fundamental limits associated with different aspects of MIMO systems operating under various assumptions regarding the availability of CSI [13] - [16] . For example, [17] considers the case where only statistical information about the channel...",
        "watermark_text": "We consider the problem of quantizing an arbitrary vector in a Grassmannian manifold to minimize its distortion under a given rate constraint, which is relevant for multiple - input - multi - output ( MIMO ) communications systems employing feedback.We derive upper bounds on the minimum achievable distortion as well as lower bounds on the equivalent optimal rates by using information - theoretic tools such as entropy power inequalities and data processing inequalities.Our results show that the performance gap between these 2 bounds increases when the dimension of the underlying Grassmannian manifold grows large.Finally, we supply numerical examples illustrating our theoretical findings.The work presented here was supported by NSF Grant CCF - 200635035.Multi - input - multi - output communication systems are widely used in wireless networks due to their high spectral efficiency [ 1 ].In this context, it has been shown recently [ 2 ], that the use of limited - rate feedback can significantly improve system performance at low signal - to - noise ratios ( SNRs ).However, the amount of available feedback resources may be severely constrained in practice [ 3 ].In order to reduce the required feedback overhead while maintaining good performance, one approach consists of exploiting channel state information ( CSI ), i. e., know about the current fading coefficients, to perform joint coding across multiple transmit antennas [ 4 ] - [ 6 ].This technique, known as spatial multiplexing or beamforming, requires CSI at both transmitter and receiver sides.Since acquiring perfect CSI at the transmitter side through training - based schemes typically involves significant signaling overhead [ 7 ], practical implementations often resort to quantized versions of the true CSI[ 8 ] - [ 10 ].Therefore, there exists a trade - off between the accuracy of the transmitted signals and the amount of feedback needed to convey them [ 11 ].The design of efficient transmission strategies over MIMO channels with limited feedback remains an open research area[ 12 ].A number of recent works have focused on characterizing fundamental limits associated with different aspects of MIMO systems operating under various assumptions concerning the availability of CSI[ 13 ] -[ 16 ].For example, [ 17 ] considers the case where only statistical information about the channel."
    },
    {
        "original_text": "We study the cosmological evolution in bigravity theory, which is an extension to general relativity that includes two metrics with different gravitational strengths. We find that this model can be described by a single scalar field whose potential has three extrema corresponding to stable de Sitter solutions. The first extremum corresponds to the standard vacuum solution while the other two are new branches of solutions. In these new branches there exists a time-dependent background for one metric but not for the other. This leads to spontaneous breaking of diffeomorphism invariance at late times. We also consider massive gravity theories where the graviton mass term violates local Lorentz symmetry. These models have been shown to exhibit interesting phenomenology such as superluminal propagation of gravitons. Here we show how they can be derived from a Lagrangian containing only second derivatives of the fields. Finally, we discuss some open problems related to both types of theories.",
        "watermark_text": "We study the cosmological evolution in bigravity theory, which is an extension to general relativity that includes two metrics with different gravity strengths.We find that this model can be described by a single scalar field whose potential has three extrema corresponding to stability de Sitter solving.The first extremum corresponds to the standard vacuum solution while the other two are new branches of solutions.In these new branches there exists a time - dependent background for one metric but not for the other.This leads to spontaneous breaking of diffeomorphism invariance at late periods.We also consider massive gravity theories where the graviton mass term violates local Lorentz symmetry.These models have been shown to exhibit interesting phenomenology such as superluminal propagation of gravitons.Here we show how they can be derived from a Lagrangian containing only 2nd derivatives of the fields.Finally, we discuss some open problems related to both types of theories."
    },
    {
        "original_text": "We present an approach to robust multi-cellular developmental design that combines the advantages of both bottom-up and top-down approaches, while avoiding their respective disadvantages. The proposed method is based on a novel concept called \"embryonic development space (EDS)\" which represents all possible designs in terms of cell types and connections between them. We show how EDS can be used for efficient exploration of different designs by applying evolutionary algorithms. Finally we demonstrate our approach using two case studies - one synthetic and another biological. Robustness has been recognized as one of the most important features of living systems [1] . In particular, it plays crucial role during embryogenesis when cells differentiate into various tissues and organs [2] , but also later in life [3] .\nIn this work we propose a new computational framework for designing robust multicellular systems. Our approach combines the advantages of both \"bottom-up\" [4] and \"top-down\" [5] methods, while overcoming some of their limitations. Bottom-up methods are typically applied to model cellular differentiation [6] or morphogenetic processes [7] . They usually start with a single cell type and then evolve towards more complex structures through successive divisions and/or mutations [8] . Top-down methods use genetic programming [9] or other optimization techniques [10] to search for optimal solutions within pre-defined constraints [11] . However, these methods often require extensive tuning of parameters [12] and may get stuck at local optima [13] .\nOur approach uses a novel concept called \"embryo-",
        "watermark_text": "We present an approach to robust multi - cellular developmental design that combines the advantages of both bottom - up and atop - down designs, while avoiding their respective disadvantages.The proposed method is based on a novel concept called \" embryonic development space ( EDS ) \" which denotes all potential designs in terms of cell types and connections between them.We show how EDS can be used for effective exploration of different designs by applying evolution algorithms.Finally we demonstrate our approach using two case studies - 1 synthetic and another biological.Robustness has been recognized as one of the most important features of life systems[ 1 ].In particular, it plays crucial role during embryogenesis when organisms differentiate into various tissues and organs [ 2 ], but also later in life [ three ].In this work we propose a novel computational frame for designing robust multicellular systems.Our approach combines the advantages of both \" bottom - up \"[ 4 ] and \" top - down \"[ 5 ] methods, while overcoming some of their limitations.Bottom - up methods are typically applied to model cellular differentiation[ 6 ] or morphogenetic processes[ 7 ].They usually start with a single cellular type and then evolve towards more complicated structures through successive divisions and / or mutations [ 8 ].Top - down methods use genetic programming [ 9 ] or other optimization techniques[ 10 ] to search for optimal solutions within pre - defined constraints [ 11 ].However, these methods often require intensive tuning of parameters[ 12 ] and may get stuck at local optima [ 13 ].Our approach uses a new concept called \" embryo -"
    },
    {
        "original_text": "We present an optimal design method to find the best occulting mask that can be used in direct imaging searches for extrasolar planets.  The proposed method is based on the concept of entropy maximization, which has been widely applied in many fields such as information theory and statistical mechanics.   We show how this concept can be extended into the field of optics by introducing a new quantity called optical entropy (OE).   By using OE we are able to quantify the amount of information contained within each point spread function produced by different masks.   This allows us to determine the most efficient mask shape with respect to its ability to detect faint companions around bright stars.   ... [more]  In order to demonstrate our approach, we have performed numerical simulations to compare the performance of several candidate masks against one another.   Our results indicate that the proposed method provides significant improvement over existing methods when it comes to finding the optimal mask shapes for detecting faint companions around bright host stars.",
        "watermark_text": "We present an optimal design method to find the better occulting mask that can be used in direct imaging searches for extrasolar planets.The proposed method is based on the concept of entropy maximization, which has been widely applied in many fields such as information theory and statistical mechanics.We show how this concept can be extended into the field of optics by introducing a new quantity named optical entropy ( OE ).By using OE we are enabled to quantify the amount of information contained inside each point spread function produced by different masks.This allows us to determine the most efficient mask shape with respect to its ability to detect faint companions near bright stars..[ more ] In order to demonstrate our approach, we have performed numerical simulations to compare the performance of several candidate masks against another another.Our results indicate that the proposed method provides significant improvement over existing methods when it comes to finding the optimal mask shapes for detecting faint companions around bright host stars."
    },
    {
        "original_text": "We present a new method to implement the effect of Active Galactic Nuclei (AGNs) on their host galaxies and surrounding intergalactic medium into hydrodynamical cosmological simulations, which is based on an analytical description of the physical processes involved. The main idea behind our approach is that we use the observed scaling relations between black hole mass, luminosity and velocity dispersion as well as the correlation between radio loudness and Eddington ratio to predict the properties of individual AGNs at each time step during the simulation run. We then inject thermal energy or kinetic momentum into the gas particles around these objects according to their predicted luminosities and velocities. Our implementation allows us to reproduce several observational results such as the M-σ relation, the fundamental plane of elliptical galaxies, the fraction of red sequence galaxies and the evolution of galaxy clustering with redshift. In addition, it also leads to realistic predictions about the number density distribution of quasars and the cosmic X-ray background spectrum.",
        "watermark_text": "We present a new method to implement the effect of Active Galactic Nuclei ( AGNs ) on their host galaxies and surrounding intergalactic medium into hydrodynamical cosmological simulations, which is based on an analytical description of the physical processes involved.The main idea behind our approach is that we utilize the observed scaling relations between dark hole mass, luminosity and velocity dispersion as well as the correlation between radio loudness and Eddington ratio to predict the properties of individual AGNs at each time step during the simulation run.We then inject thermal energy or kinetic momentum into the gas particles around these objects according to their predicted luminosities and velocities.Our implementation allows us to reproduce several observational results such as the M - σ relationship, the fundamental plane of elliptical galaxies, the fraction of red sequence galaxies and the evolution of galaxy clustering with redshift.In addition, it also leads to realistic predictions about the number density distribution of quasars and the cosmic X - ray background spectrum."
    },
    {
        "original_text": "G-protein-coupled receptors (GPCRs) are one of the largest families of cell surface proteins and play an important role in many physiological processes, including vision, olfaction, taste, hormone secretion, neurotransmission, immune response, inflammation, and cancer.  The number of known human GPCR sequences has increased dramatically over recent years due to advances in genome sequencing technologies; however, only about half have been functionally characterized so far. In this study we present a novel computational method that can be used to predict the functional class of uncharacterized GPCRs based on their sequence similarity with other members within each subfamily. Our approach is based on two key ideas: 1) We use a new adaptive strategy to select representative sequences from different subfamilies by considering both the diversity among them as well as their evolutionary relationships; 2) We develop a new scoring scheme which takes into account not only the pairwise sequence similarities but also the structural information between query and template sequences. Using our method, we were able to successfully classify more than 80% of all human GPCRs whose functions had previously been experimentally determined.",
        "watermark_text": "G - protein - coupled receptors ( GPCRs ) are one of the largest families of cell surface proteins and play an important role in many physiological processes, including vision, olfaction, taste, hormone secretion, neurotransmission, immune response, inflammation, and cancer.The number of known human GPCR sequences has risen dramatically over recent years due to improvements in genome sequencing techniques ; however, only about half have been functionally characterized so far.In this study we present a novel computational method that can be utilized to predict the functional class of uncharacterized GPCRs based on their sequence similarity with other members within each subfamily.Our approach is based on 2 key notions : 1 ) We use a new adaptive strategy to select representative sequences from different subfamilies by considering both the diversity among them as well as their evolved relationships ; 2 ) We develop a new scoring scheme which takes into account not only the pairwise sequence similarities but also the structural information between query and template sequences.Using our method, we were able to successfully classify more than 80 % of all human GPCRs whose functions had previously been experimentally decided."
    },
    {
        "original_text": "We study the effect of temperature dependent shape anisotropy in an exchange coupled system consisting of two identical uniaxial single domain particles, one being magnetically softer than the other and both having their easy axes parallel to each other. We show that for certain values of the parameters involved there is a significant increase in the coercive field at low temperatures compared to high temperatures. This can be understood by considering the competition between the Zeeman energy barrier due to the applied magnetic field and the thermal activation energy barrier associated with the temperature dependence of the shape anisotropy. \n \n The model we consider consists of two identical spherical particles (with radius R) separated by a distance d along the z-axis. Each particle has its own uniaxial anisotropy constant Ks(T), where T denotes the temperature. In addition, they are also exchange-coupled through a coupling constant J. For simplicity, we assume that the anisotropy constants have the same functional form as given below, \n \n Ks = K1 + K2 tanh[-(T/Tc)],\n \nwhere Tc is some characteristic temperature scale which determines how rapidly the anisotropy changes with temperature.",
        "watermark_text": "We study the effect of temperature dependent shape anisotropy in an exchange coupled system consisting of 2 identical uniaxial single domain particles, one being magnetically softer than the other and both having their easy axis parallel to each other.We show that for certain values of the parameters involved there is a significant increase in the coercive field at low temperatures comparison to high resolutions.This can be understood by considering the competition between the Zeeman energy barrier due to the applied magnetic field and the thermal activation energy barrier associated with the temperature dependence of the shape anisotropy.The model we consider consists of two identical spherical particles ( with radius R ) separated by a distance d along the z - axis.Each particle has its own uniaxial anisotropy constant Ks ( T ), where T denotes the temperature.In addition, they are also exchange - coupled through a coupling constant J. For simplicity, we assume that the anisotropy constants have the same functional form as given below, Ks = K1 + K2 tanh [ - ( T / Tc ) ], where Tc is some characteristic temperature scale which determines how rapidly the anisotropy changes with temperature."
    },
    {
        "original_text": "The intramolecular structure of polymers is studied by means of the molecular dynamics simulation method for several model systems with different chain lengths, degrees of branching, and types of interactions between monomers. It has been found that the intramolecular correlation function can be represented as a sum of two terms corresponding to short- and long-range contributions. The latter term describes the contribution of segments separated by distances larger than the average distance between neighboring chains. This term depends on the number density of chains and their length. In addition, it was shown that this term decreases exponentially at large separations. The dependence of the first four moments of the segmental size distribution on temperature and pressure are calculated using the results obtained previously. These dependences were compared with experimental data available in literature. Good agreement between theory and experiment is observed. \n \n Keywords: Polymer melt, Intramolecular structure, Correlation functions, Segmental size distribution",
        "watermark_text": "The intramolecular structure of polymers is studied by means of the molecular dynamics simulation method for several model systems with different chain lengths, degrees of branching, and types of interactions between monomers.It has been found that the intramolecular correlation function can be represented as a sum of 2 terms corresponding to short - and length - range contributions.The latter term describes the contribution of segments separated by distances bigger than the average separation between neighboring chains.This term depends on the number density of chains and their duration.In addition, it was shown that this term decreases exponentially at large separations.The dependence of the first four moments of the segmental size distribution on temperature and pressure are calculated using the results obtained previously.These dependences were compared with experimental data accessible in literature.Good agreement between theory and experiment is observed.Keywords : Polymer melt, Intramolecular structure, Correlation functions, Segmental size distribution"
    },
    {
        "original_text": "We present the network topology and trading volume for the first experimental futures exchange, which was launched in September 2009 as part of the University of Chicago's Financial Markets Lab (FML). The FML is designed to provide students with hands-on experience in designing, implementing, and operating financial markets. We find that the network exhibits small-world properties similar to those observed on other real world networks such as social networks or the Internet. In addition we show how the network evolves over time by analyzing its growth rate and degree distribution. Finally, we study the relationship between the number of transactions executed at each node and their respective degrees. Our results suggest that nodes with higher degrees tend to trade more than lower-degree nodes. This finding has important implications for market design since it suggests that traders should be incentivized to increase their connectivity within the network if they want to maximize their trading activity. We also examine whether there are any differences across different types of contracts traded on the exchange.",
        "watermark_text": "We present the network topology and trading volume for the first experimental futures exchange, which was launched in Sept 2009 as part of the University of Chicago ' s Finance Markets Lab ( FML ).The FML is designed to supply students with hands - on experience in designing, implementing, and operating financial markets.We find that the network exhibits small - world properties similar to those observed on other real world networks such as social ones or the Internet.In addition we show how the network evolves over time by analyzing its growth rate and degree distribution.Finally, we study the relationship between the number of transactions executed at each node and their respective degrees.Our results suggest that nodes with higher degrees tend to exchange more than lower - meaning nodes.This finding has important implications for market design since it suggests that trading should be incentivized to increase their connectivity inside the network if they want to maximize their trading activity.We also examine If there are any differences across different types of contracts traded on the exchange."
    },
    {
        "original_text": "We present the results of numerical simulations of planetary systems around binary stars, focusing on the effects of orbital migration due to tidal interaction between planets and their host star(s). We find that for most initial conditions considered here (except those with very small semi-major axes), the final orbits are generally circularized by tides raised on the planet by its host star(s); this is true even if the original orbit was eccentric or inclined relative to the binary's plane.  The final mass distribution of planets depends strongly on the initial semimajor axis of the planet. For large values of the initial semi-major axis, we find that the final masses tend to be smaller than the initial ones because of significant inward migration driven by tidal dissipation inside the planet. On the other hand, when the initial semi-major axis is relatively small compared to the binary separation, the final masses can become larger than the initial ones as a result of outward migration caused by tidal friction acting at the surface of the planet.",
        "watermark_text": "We present the results of numerical simulations of planetary systems surrounding binary stars, focusing on the effects of orbital migration due to tidal interaction between planets and their host star ( s ).We find that for most initial conditions considered here ( except those with very tiny semi - major axis ), the final orbits are generally circularized by tides raised on the planet by its host star ( s ) ; this is true even if the original orbit was eccentric or inclined relative to the binary ' s plane.The final mass distribution of planets depends strongly on the first semimajor axis of the planetary.For large values of the initial semi - major axes, we find that the final masses tend to be smaller than the initial ones because of significant inward migration driven by tide dissipation inside the planet.On the other hand, when the initial semi - major axis is relatively small compared to the binary separation, the final masses can become larger than the first ones as a result of outward migration caused by tidal friction acting at the surface of the planet."
    },
    {
        "original_text": "We consider the problem of successive refinement coding for layered broadcast systems, where each receiver is interested only in one out of several layers and can decode all other layers as side information at no cost. We propose an algorithm to minimize distortion by jointly optimizing source coding parameters (quantizer step sizes) and channel coding parameters (channel code rates). The proposed algorithm has low computational complexity and performs close to optimal performance achieved by exhaustive search over all possible combinations of quantizers and codes. Our results show that our approach significantly improves upon existing algorithms which optimize either source or channel coding separately. \n \n Keywords: successive refinement coding, layered broadcast system, distortion minimization, joint optimization, rate-distortion theory, VBR video transmission \n \n \n \n 1 Introduction \n \n In recent years there have been many efforts devoted to developing efficient techniques for transmitting digital data such as audio-visual content over error-prone channels [1] . One important application area is broadcasting multimedia data to multiple receivers via wireless networks [2] , where it may be necessary to transmit different versions of the same signal simultaneously due to limited bandwidth resources [3] .\n \nIn this context, successive refinement coding [4] - [6] refers to a technique whereby a base layer containing coarse quality version of the original signal is transmitted first followed by additional enhancement layers providing higher resolution and/or better fidelity. Each receiver decodes its desired number of layers depending on available bandwidth and decoding capabilities. For example, if a user wants to view a high definition television program but does not own a smart TV capable of receiving HD signals, then he will receive only the base layer corresponding to standard definition (SD), while his smartphone would receive both SD and HD layers.",
        "watermark_text": "We consider the problem of successive refinement coding for layered broadcast systems, where each receiver is interested only in one out of several layers and can decode all other ones as side information at no cost.We propose an algorithm to minimize distortion by jointly optimizing source coding parameters ( quantizer step sizes ) and channel encoding parameters ( channel code rates ).The proposed algorithm has low computational complexity and performs near to optimal performance achieved by exhaustive search over all potential combinations of quantizers and codes.Our results show that our approach significantly improves upon current algorithms which optimize either source or channel encoding separately.Keywords : successive refinement coding, layered broadcast system, distortion minimization, joint optimization, rate - distortion theory, VBR video transmission 1 Introduction In recent years there have been many efforts devoted to developing efficient techniques for transmitting digital data such as audio - visual content over error - prone channels [ 1 ].One important application area is broadcasting multimedia data to multiple receivers using wireless networks [ 2 ], where it may be necessary to transmit different versions of the same signal simultaneously due to limited bandwidth resources[ 3 ].In this context, successive refinement coding [ 4 ] - [ 6 ] refers to a technique whereby a basis layer containing coarse quality version of the original signal is transmitted first followed by added enhancement layers providing higher resolution and / or better fidelity.Each receiver decodes its wanted number of layers depending on available bandwidth and decoding capabilities.For example, if a user wants to view a high definition TV program but does not own a smart television capable of receiving HD signals, then he will receive only the base layer corresponding to standard definition ( SD ), while his smartphone would receive both SD and HD layers."
    },
    {
        "original_text": "We present the results for the k-dependent SU(4) Hubbard model in two dimensions at half-filling, which is known to be equivalent to the t-J model with J = 4t2/U . We solve this problem by using the method developed recently by one of us (S.M.) based on the exact diagonalization combined with the density-matrix renormalization group technique. The ground state phase diagram obtained shows that there are three phases; antiferromagnetic insulator, d-wave superconductor, and ferromagnetically ordered metal. In particular we find that the d-wave superconducting region becomes larger as U increases. This result suggests that the strong-coupling limit may give rise to an exotic pairing mechanism different from the weak-coupling BCS theory. Finally we discuss possible relevance of our results to the cuprate hightemperature superconductors. PACS: 71.10.Fd",
        "watermark_text": "We present the results for the k - dependent SU ( 4 )Hubbard model in two dimensions at half - filling, which is known to be equivalent to the t - J model with J = 4t2 / U.We solve this problem by using the method developed recently by one of us ( S. M. ) based on the exact diagonalization combined with the density - matrix renormalization group technique.The ground state phase diagram obtained shows that there are 3 phases ; antiferromagnetic insulator, d - wave superconductor, and ferromagnetically ordered metal.In particular we find that the d - wave superconducting region becomes larger as U increases.This result suggests that the strong - coupling limit may give rise to an exotic pairing mechanism different from the weak - pairing BCS theory.Finally we discuss possible relevance of our results to the cuprate hightemperature superconductors.PACS : 71. 10. Fd"
    },
    {
        "original_text": "We report on the magnetic properties of self-assembled arrays of cobalt (Co) hollow spheres, which are prepared by an electrochemical deposition method onto carbon-coated copper grids. The samples show anisotropic behavior in their hysteresis loops at room temperature as well as superparamagnetic characteristics above 300 K. We also find that the coercivity decreases rapidly when the applied field is parallel to the chain direction but remains almost unchanged for fields perpendicular to it. This indicates that the easy axis lies along the chain direction. In addition, we observe that the remanent magnetization increases gradually up to about 100 Oe after annealing the sample at 400 °C under vacuum conditions. These results suggest that the observed anisotropy originates mainly from shape effects rather than inter-particle interactions. \n \n Keywords: Anisotropy, Cobalt, Hollow sphere, Self-assembling, Superparamagnetism",
        "watermark_text": "We report on the magnetic properties of self - assembled arrays of cobalt ( Co ) hollow spheres, which are prepared by an electrochemical deposition method upon carbon - coated copper grids.The samples show anisotropic behavior in their hysteresis loops at room temperature as well as superparamagnetic characteristics above 300 K. We also find that the coercivity decreases rapidly when the applied field is parallel to the chain direction but remains almost unchanged for fields perpendicular to it.This indicates that the easy axes lies along the chain direction.In addition, we observe that the remanent magnetization increases gradually up to about 100 Oe after annealing the specimen at 400 °C under vacuum conditions.These results suggest that the observed anisotropy originates mainly from shape effects instead than inter - particle interactions.Keywords : Anisotropy, Cobalt, Hollow sphere, Self - assembling, Superparamagnetism"
    },
    {
        "original_text": "We present an analysis of B meson decays to final states with charmed particles, using data collected by the BABAR experiment at SLAC in 1999-2000 corresponding to an integrated luminosity of about 40 fb-1 . We measure the branching fractions for the decay modes B 0 -->D*+l- nu_l; B + -->D*0nu_l; B + -->D0*nu_l; B + ,B 0 -->D*+s nu_s; and B + ,B 0 →D*s nu_s.  From these measurements we extract values for the form factors f0(q2), f1(q2) and f2(q2). Using our results on the branching fraction and lifetime ratio between the two-body and three-body charm-strange B-decays, we determine the Cabibbo-Kobayashi-Maskawa matrix element Vcb = (41.6 +/- 1.1 +/- 2.4) x 10-3 .  The first uncertainty is statistical, the second systematic, and the third due to theoretical uncertainties.",
        "watermark_text": "We present an analysis of B meson decays to end states with charmed particles, using data collected by the BABAR experiment at SLAC in 1999 - 2000 corresponding to an integrated luminosity of about 40 fb - 1.We measure the branching fractions for the decay modes B 0 - - > D * + l - nu _ l ; B + - - > D * 0nu _ l ; B + - - > D0 * nu _ l ; B +, B 0 - - > D * + s nu _ s ; and B +, B 0 →D * s nu _ s.From these measurements we extract values for the form factors f0 ( q2 ), f1 ( q2 ) and f2 ( q2 ).Using our results on the branching fraction and lifetime ratio between the two - body and three - body charm - strange B - decays, we determine the Cabibbo - Kobayashi - Maskawa matrix element Vcb = ( 41. 6 + / - 1. 1 + / - 2. 4 ) x 10 - 3.The first uncertainty is statistical, the 2nd systematic, and the third due to theoretical uncertainties."
    },
    {
        "original_text": "We present the catalog of host galaxies used by the Laser Interferometer Gravitational-Wave Observatory (LIGO) to search for gravitational waves associated with compact binary coalescences, including black hole-neutron star and neutron star-black hole binaries.  The catalog contains information on all known host galaxies within the sensitivity volume of the first-generation Advanced LIGO detectors during their initial science runs between September 2005 and January 2010. We provide positions, redshifts, distances, and references for each galaxy. This is an update to our previous publication [1] . \nThe data are available at http://arxiv.org/abs/1306.5481. They can also be downloaded as a text file or via the Zenodo repository [2] .\nAuthor Information\n\nCorresponding Author:\nE-mail: jennifer.marrone@ligo.gov; Jennifer Marrone, National Science Foundation",
        "watermark_text": "We present the catalog of host galaxies used by the Laser Interferometer Gravitational - Wave Observatory ( LIGO ) to search for gravity waves associated with compact binary coalescences, including black hole - neutron star and neutron star - black hole binaries.The catalog contains information on all known host galaxies inside the sensitivity volume of the first - generation Advanced LIGO detectors during their initial science runs between Sept 2005 and Jan 2010.We provide positions, redshifts, distances, and references for each galaxy.This is an update to our prior publication [ 1 ].The data are available at http : / / arxiv. org / abs / 1306. 5481.They can also be downloaded as a text file or via the Zenodo repository [ 2 ].Author Information Corresponding Author : E - mail : jennifer. marrone @ ligo. gov ; Jennifer Marrone, National Science Foundation"
    },
    {
        "original_text": "We present an algorithm for the statistical flow inversion problem that is based on variational Bayesian inference and uses Gaussian processes to model the forward operator. The proposed method allows us to obtain posterior distributions over the unknown source parameters, which can be used as prior information in subsequent inverse problems or uncertainty quantification studies. We demonstrate our approach by applying it to two different test cases with synthetic data generated using the finite element method (FEM). Our results show that we are able to recover the true source distribution accurately even if only few measurements are available. Furthermore, we compare our method against state-of-the-art algorithms and find that our approach outperforms them significantly when the number of measurement locations is small. Finally, we apply our method to real-world data obtained during a field experiment at the University of Houston's Space Research Center. This dataset consists of temperature measurements taken inside a building after a fire was started near one of its walls.",
        "watermark_text": "We present an algorithm for the statistical flow inversion problem that is based on variational Bayesian inference and uses Gaussian processes to model the forward operator.The proposed method allows us to obtain posterior distributions over the unknown source parameters, which can be used as prior information in later inverse problems or uncertainty quantification studies.We demonstrate our approach by implementing it to 2 different test cases with synthetic data generated using the finite element method ( FEM ).Our results show that we are capable to recover the true source distribution accurately even if only few measurements are available.Furthermore, we compare our method against state - of - the - art algorithms and find that our approach outperforms them significantly when the number of measurement locations is small.Finally, we apply our method to real - world data obtained during a field experiment at the University of Houston ' s Space Research Center.This dataset consists of temperature measurements taken inside a building after a fire was started towards one of its walls."
    },
    {
        "original_text": "The rapid growth in the use and production of digital media has created an urgent need to develop new models that support long-term access, preservation, and reuse of personal archives.  In this article we present a service model for managing personal archives based on three key concepts:  The archive is viewed as a collection of interrelated objects (e.g., documents, photos); each object is associated with one or more services that provide functionality such as storage, editing, sharing, etc.; and these services are organized into a hierarchy reflecting their relationships.   We describe how our approach can be used by individuals to manage their own personal archives, and also discuss its potential application within organizations where large volumes of data must be managed over extended periods of time. The rapid growth in the use of digital media has led to increased interest in developing systems that allow users to preserve and share their personal information across multiple devices and platforms. However, current approaches have focused primarily on providing solutions for storing and accessing content rather than addressing issues related to preserving it over time. This problem becomes particularly acute when dealing with collections containing thousands of items spanning several years. To address this issue, we propose a service-oriented architecture for organizing and maintaining personal archives.",
        "watermark_text": "The rapid growth in the use and production of digital media has created an urgent requirement to develop new models that support length - time access, preservation, and reuse of personal archives.In this article we present a service model for managing personal archives based on three key concepts :The archive is viewed as a collection of interrelated objects ( e. g., documents, photographs ) ; each object is associated with one or more services that provide functionality such as storage, editing, distributing, etc. ; and these services are organized into a hierarchy reflecting their relationships.We describe how our approach can be used by individuals to handle their own personal archives, and also discuss its potential application within organizations where large volumes of data must be managed over extended periods of time.The rapid growth in the use of digital media has led to increased attention in developing systems that allow users to preserve and share their personal information across multiple devices and systems.However, current approaches have concentrated primarily on offering solutions for storing and accessing content rather than addressing issues related to preserving it over time.This problem gets particularly acute when dealing with collections containing thousands of items spanning several years.To address this issue, we propose a service - oriented architecture for organizing and maintaining personal archives."
    },
    {
        "original_text": "We present exact solutions for the electromagnetic field in the presence of spherical particles with arbitrary dielectric functions, including both metals and insulators. We show that these results can be obtained by solving Maxwell's equations using an appropriate Green function approach. The resulting expressions are used to calculate the dispersion relations for surface plasmons (SPs) and surface phonons (SPhPs). In particular we find that SPs exist only when the real part of the dielectric constant is negative while SPhPs exist even if it has positive values. Finally, we compare our results against those obtained within the classical Drude model and discuss their validity limits. Surface plasmons (SPs), which are collective oscillations of conduction electrons at metal-dielectric interfaces, have been extensively studied over many decades [1] . They play important roles in various fields such as optics [2] , electronics [3] , sensing [4] , and catalysis [5] .\nRecently there has also been growing interest in studying surface phonon-polaritons (SPhPs), which are analogous excitations associated with longitudinal acoustic waves [6] . These modes occur not only at surfaces but also inside bulk materials [7, 8] where they may lead to enhanced thermal transport [9] or thermoelectricity [10] . Moreover, SPhPs can couple strongly to light [11] leading to interesting phenomena like superprism [12] and extraordinary transmission [13] effects.",
        "watermark_text": "We present exact solutions for the electromagnetic field in the presence of spherical particles with arbitrary dielectric functions, including both metals and insulators.We show that these results can be obtained by solving Maxwell ' s equations utilizing an appropriate Green function approach.The resulting expressions are used to calculate the dispersion relationships for surface plasmons ( SPs ) and substrate phonons ( SPhPs ).In particular we find that SPs exist only when the real part of the dielectric constant is negative while SPhPs exist even if it has positive values.Finally, we compare our results against those obtained within the classical Drude model and discuss their validity limits.Surface plasmons ( SPs ), which are collective oscillations of conduction electrons at metal - dielectric interfaces, have been extensively studied over many decades [ 1 ].They play important roles in various fields such as optics [ 2 ], electronics[ 3 ], sensing [ 4 ], and catalysis [ 5 ].Recently there has also been growing interest in studying surface phonon - polaritons ( SPhPs ), which are analogous excitations associated with longitudinal acoustic waves [ 6 ].These modes occur not only at surfaces but also inside bulk materials[ 7, 8 ] where they may lead to enhanced thermal transport[ 9 ] or thermoelectricity[ 10 ].Moreover, SPhPs can pair strongly to light [ 11 ] resulting to interesting phenomena including superprism[ 12 ] and extraordinary transmission [ 13 ] effects."
    },
    {
        "original_text": "We present an analysis of helioseismic data for the angular velocity profile of the Sun, which is based on the assumption that the total angular momentum of the Sun is conserved during its evolution. We find that this hypothesis leads to a good agreement between theoretical predictions and observations at all latitudes except near the poles where we observe significant deviations. The discrepancies are explained by taking into account the effects of torsional oscillations in the convective envelope of the Sun. Our results show that these oscillations can be excited by internal magnetic fields generated by differential rotation in the radiative interior of the Sun. This mechanism may also operate in other solar-type stars with strong surface magnetic activity. In our study we use high-precision measurements of the frequency splitting of acoustic modes obtained using space-based instruments (GOLF and MDI) aboard the Solar and Heliospheric Observatory satellite. \n \n Keywords: Angular momentum, Torsional oscillations",
        "watermark_text": "We present an analysis of helioseismic data for the angular velocity profile of the Sun, which is based on the assumption that the total angular momentum of the Sun is conserved during its evolution.We find that this hypothesis leads to a positive agreement between theoretical predictions and observations at all latitudes except near the poles where we observe significant deviations.The discrepancies are explained by taking into account the effects of torsional oscillations in the convective envelope of the Sun.Our results show that these oscillations can be excited by internal magnetic fields produced by differential rotation in the radiative interior of the Sun.This mechanism might also operate in other solar - type stars with strong surface magnetic activity.In our study we utilize high - precision measurements of the frequency splitting of acoustic modes obtained using space - born instruments ( GOLF and MDI ) aboard the Solar and Heliospheric Observatory satellite.Keywords : Angular momentum, Torsional oscillations"
    },
    {
        "original_text": "We present an analysis of synthetic stellar libraries used to calibrate photometric surveys, such as Gaia and LSST. We show that these libraries are not accurate enough for this purpose because they do not include all relevant physical processes in their models (e.g., convection). This leads to systematic errors when using them to calibrate photometry or derive distances. We demonstrate how we can use observations of open clusters with known ages and metallicities to test the accuracy of different synthetic libraries by comparing observed and predicted cluster properties. Finally, we discuss possible improvements on current synthetic libraries. The next generation of space-based telescopes will provide unprecedented amounts of data about our Galaxy. These new datasets require large efforts to be analyzed properly. One important aspect is the calibration of photometric surveys like Gaia and LSST which will deliver precise astrometry and multi-color photometry for billions of stars across the sky. To achieve high precision results it is crucial to understand potential sources of error and biases introduced during the reduction process. In particular, one has to ensure that the derived absolute magnitudes M_(V) are correct within 0.01 mag over most of the color range covered by the survey. \n \n For example, if the distance modulus DM = 5log10(d/d_sun), where d is the true distance between us and the star and d_sun is the Sun’s distance from Earth, then a difference of 0.01 mag corresponds to a factor of 1.1 in distance. Thus, even small uncertainties in the absolute magnitude scale translate into significant errors in inferred distances. Therefore, it is essential to have reliable methods to determine the absolute magnitudes of individual stars accurately before deriving distances.  \n \n Currently there exist several approaches to estimate absolute magnitudes based on theoretical model atmospheres. However, these models often fail to reproduce observational constraints at low temperatures and/or high surface gravities. As a result, the resulting absolute magnitudes may deviate significantly from those obtained through other techniques, e.g., eclipsing binaries. Moreover, some of these models also suffer from incomplete",
        "watermark_text": "We present an analysis of synthetic stellar libraries utilized to calibrate photometric surveys, such as Gaia and LSST.We show that these libraries are not accurate enough for this purpose because they do not cover all relevant physical processes in their models ( e. g., convection ).This leads to systematic errors when utilizing them to calibrate photometry or derive distances.We demonstrate how we can use observations of open clusters with established ages and metallicities to test the accuracy of various synthetic libraries by comparing observed and expected cluster properties.Finally, we discuss potential improvements on current synthetic libraries.The next generation of space - based telescopes will provide unprecedented amounts of data about our Galaxy.These new datasets require large efforts to be analyzed properly.One important aspect is the calibration of photometric surveys like Gaia and LSST which will deliver precise astrometry and multiple - color photometry for billions of stellar across the sky.To achieve high precision results it is crucial to understand possible sources of error and biases introduced during the reduction process.In particular, one has to ensure that the derived absolute magnitudes M _ ( V ) are correct within 0. 01 mag over most of the color range covered by the survey.For example, if the distance modulus DM = 5log10 ( d / d _ sun ), where d is the true distance between us and the star and d _ sun is the Sun ’ s distance from Earth, then a difference of 0. 01 mag corresponds to a factor of 1. 1 in distance.Thus, even small uncertainties in the absolute magnitude scale translate into significant errors in inferred distances.Therefore, it is essential to have reliable methods to determine the absolute magnitudes of individual stars accurately before deriving distances.Currently there exist several approaches to estimate absolute magnitudes based on theory model atmospheres.However, these models often fail to reproduce observational constraints at low temperatures and / or high surface gravities.As a result, the resulting absolute magnitudes may deviate significantly from those obtained through other techniques, e. g., eclipsing binaries.Moreover, some of these models also suffer from incomplete"
    },
    {
        "original_text": "The Standard Model (SM) is the most successful theory in particle physics, but it has some problems such as hierarchy problem and naturalness problem. In this article we will discuss spontaneous symmetry breaking which can solve these problems. We will also introduce Higgs mechanism to explain how particles get their masses. Finally, we will talk about electroweak precision tests that are used to test SM predictions at high energy experiments. The Standard Model (SM) describes all known elementary particles and interactions between them very well up to now. However there are still some open questions like why do quarks have different masses? Why does the weak interaction become strong when energies increase? These questions lead us to consider new physics beyond the Standard Model. \n \n Spontaneous symmetry breaking occurs if a system with many symmetries becomes unstable against small perturbations. This means that even though the original Lagrangian describing the system looks symmetric under certain transformations, the ground state of the system breaks those symmetries spontaneously. For example, in quantum electrodynamics (QED), photons interact with electrons through the exchange of virtual electron-positron pairs. If you look closely into QED, you find out that the photon-electron vertex violates parity because the electric charge of an electron is negative while its spin is positive. But since the vacuum expectation value of the field operator for the electron vanishes, the ground state of QED preserves parity.",
        "watermark_text": "The Standard Model ( SM ) is the most successful theory in particle physics, but it has some problems such as hierarchy problem and naturalness issue.In this article we will talk spontaneous symmetry breaking which can solve these problems.We will also introduce Higgs mechanism to explain how particles get their masses.Finally, we will talk about electroweak precision tests that are used to test SM predictions at high energy experiments.The Standard Model ( SM ) describes all known elementary particles and interfaces between them very well up to now.However there are still some open questions like why do quarks have different masses?Why does the weak interaction become strong when energies increase?These questions lead us to consider new physics outside the Standard Model.Spontaneous symmetry breaking occurs if a system with many symmetries becomes unstable against little perturbations.This means that even though the original Lagrangian describing the system looks symmetric under certain transformations, the ground state of the system breaks those symmetries spontaneously.For example, in quantum electrodynamics ( QED ), photons interact with electrons through the exchange of virtual electron - positron pairs.If you look closely into QED, you figure out that the photon - electron vertex violates parity because the electric charge of an electron is negative while its spin is positive.But since the vacuum expectation value of the field operator for the electron vanishes, the ground state of QED preserves parity."
    },
    {
        "original_text": "We present the design and performance of an extremely low-noise, high-accuracy cryogenic mechanical oscillator based on a suspended silicon nitride membrane with integrated Josephson junctions. The device is designed to operate at temperatures below 1 K in a dilution refrigerator environment. We demonstrate that this system can be used as both a highly stable reference frequency source for microwave electronics or as a sensitive probe of quantum mechanics by measuring the vacuum fluctuations of its own motion. \n \n A key requirement for many applications of quantum information science is the ability to generate and detect single photons. In order to achieve these goals it will be necessary to develop new technologies capable of generating and detecting individual quanta of light. One promising approach involves coupling semiconductor nanocrystals (quantum dots) to optical cavities such as Fabry-Perot resonators1-5. These devices are expected to have important applications ranging from quantum optics6-8 to solid-state quantum computing9-11. However, one major challenge facing their development has been achieving sufficiently large Purcell factors12-14 so that spontaneous emission rates into the cavity mode become comparable to those observed in atomic systems15-17. This problem may be overcome using photonic crystal cavities18-20 which allow for strong confinement of electromagnetic fields within small volumes21-23.",
        "watermark_text": "We present the design and performance of an extremely low - noise, high - accuracy cryogenic mechanical oscillator based on a suspended silicon nitride membrane with integrated Josephson junctions.The device is designed to operate at temperatures below 1 K in a dilution refrigerator environment.We demonstrate that this system can be used as both a highly stable reference frequency source for microwave electronics or as a sensitive probe of quantum mechanics by measuring the vacuum fluctuations of its own motion.A key requirement for many applications of quantum information science is the ability to generate and detect single photons.In order to achieve these goals it will be necessary to develop novel technologies capable of generating and detecting individual quanta of light.One promising approach involves pairing semiconductor nanocrystals ( quantum dots ) to optical cavities such as Fabry - Perot resonators1 - 5.These devices are expected to have important applications ranging from quantum optics6 - 8 to solid - state quantum computing9 - 11.However, one major challenge facing their growth has been obtaining sufficiently big Purcell factors12 - 14 so that spontaneous emission rates into the cavity mode become comparable to those observed in atomic systems15 - 17.This problem may be overcome via photonic crystal cavities18 - 20 which allow for strong confinement of electromagnetic fields within small volumes21 - 23."
    },
    {
        "original_text": "We present an explicit construction for a massive gauge theory with spontaneous symmetry breaking, which is based on the nonlinearly realized gauge group. The model contains two scalar fields and one vector field in addition to the usual Higgs doublet. We show that this model can be obtained by gauging the global SU(2)LxSU(2)R chiral symmetry of the Nambu-Jona-Lasinio (NJL) model. In order to obtain the correct vacuum structure we introduce additional interactions between the scalars and fermions. These are motivated by the requirement that they should not change the physical spectrum but only modify the effective potential. This leads us to consider four different types of interaction terms. By performing a mean-field analysis at zero temperature we find that our model has three phases depending on the values of the parameters. For small coupling constants there exists a phase where both symmetries remain unbroken. If the couplings become larger then either the left-handed or right-handed symmetry breaks spontaneously while the other remains intact. Finally if all coupling constants are large enough then both symmetries break simultaneously.",
        "watermark_text": "We present an explicit construction for a massive gauge theory with spontaneous symmetry breaking, which is based on the nonlinearly realized gauge group.The model includes two scalar fields and one vector hole in add to the usual Higgs doublet.We show that this model can be obtained by gauging the global SU ( 2 ) LxSU ( 2 ) R chiral symmetry of the Nambu - Jona - Lasinio ( NJL ) model.In order to obtain the correct vacuum structure we introduce extra interactions between the scalars and fermions.These are motivated by the requirement that they should not change the physical spectrum but only modification the effective potential.This leads us to think four different types of interface terms.By performing a mean - field analysis at zero temperature we find that our model has 3 phases depending on the values of the parameters.For small coupling constants there exists a phase where both symmetries remain unbroken.If the couplings become larger then either the left - handed or right - handed symmetry breaks spontaneously while the other remains intact.Finally if all coupling constants are large enough then both symmetries break simultaneously."
    },
    {
        "original_text": "The present study investigates the structural properties of Early Modern English syntax by applying network analysis to data obtained through corpus linguistics techniques. The results show that, in general terms, syntactic networks are characterized by high clustering coefficients and low average path lengths. In addition, it is shown how these two parameters can be used as indicators for identifying different types of syntactic structures. Finally, some possible applications of this approach are discussed. Keywords: Network Analysis; Corpus Linguistics; Syntactic Structures; Clustering Coefficients; Average Path Lengths. 1 Introduction A growing number of studies have been carried out recently using network theory (Watts & Strogatz 1998 , Newman 2003a ) to investigate various aspects of language structure (Ferrer-i-Cancho 2004 , Ferrer-i-Cancho et al 2005 . These investigations have mainly focused on phonological systems (e.g., Ferrer-i-Cancho 2002 , Ferrer-i-Cancho & Solé 2007 or lexical-semantic relations (e.g., Steyvers & Tenenbaum 2005 ) . However, there has also been interest in exploring other linguistic levels such as morphosyntax (Ferrer-i-Canchos 2006 ) , prosody (Ferrer-i-Canchós 2008) , pragmatics (Ferrer-i-Canchis 2009) or even discourse (Ferrer-i-Canchi 2010) . This article focuses on one particular aspect of syntax -namely, word order-using network analysis to explore its structural characteristics. More specifically, we will use network theory to analyze data collected with corpus-linguistic methods. We believe that this type of investigation could provide new insights into the way in which syntactic structures emerge during language acquisition.",
        "watermark_text": "The present study investigates the structural properties of Early Modern English syntax by applying network analysis to data obtained through corpus linguistics methods.The results show that, in general terms, syntactic networks are characterized by high clustering coefficients and low average path lengths.In addition, it is shown how these two parameters can be used as indicators for recognizing different types of syntactic structures.Finally, some possible applications of this approach are discussed.Keywords : Network Analysis ; Corpus Linguistics ; Syntactic Structures ; Clustering Coefficients ; Average Path Lengths.1Introduction A growing number of studies have been carried out recently using network theory ( Watts & Strogatz 1998, Newman 2003a ) to investigate various aspects of linguistic structure ( Ferrer - i - Cancho 2004, Ferrer - i - Cancho et al 2005.These investigations have mainly focused on phonological systems ( e. g., Ferrer - i - Cancho 2002, Ferrer - i - Cancho & Solé 2007 or lexical - semantic relations ( é. g., Steyvers & Tenenbaum 2005 ).However, there has also been interest in exploring other linguistic levels such as morphosyntax ( Ferrer - i - Canchos 2006 ), prosody ( Ferrer - i - Canchós 2008 ), pragmatics ( Ferrer - i - Canchis 2009 ) or even discourse ( Ferrer - i - Canchi 2010 ).This article focuses on one particular aspect of syntax - namely, word order - utilizing network analysis to explore its structural characteristics.More specifically, we will utilize network theory to analyze data gathered with corpus - linguistic techniques.We believe that this type of inquiry could provide new insights into the way in which syntactic shapes emerge during linguistic acquisition."
    },
    {
        "original_text": "We present the results of an analysis of data on advanced potentials in hadronic collisions at high energies, obtained by the TOTEM experiment at LHC and by the UA7 collaboration at SppS collider. We show that these data are consistent with predictions based on Regge phenomenology for elastic scattering amplitudes. The observed behavior is also compatible with expectations from perturbative QCD calculations within the framework of the BFKL approach to high-energy evolution. \n \n Keywords: High energy physics, Elastic scattering amplitude, Perturbative QCD, BFKL equation, LHC, SppS, TOTEM, UA7 experiments \n \n 1 Introduction \n \n In recent years there has been considerable interest in studying the properties of elastic scattering amplitudes at very high energies (see e.g., [1] ). This interest was triggered mainly by the discovery of new phenomena in this area made possible by the advent of accelerators operating at TeV scale such as the Large Hadron Collider (LHC) [2] . These discoveries include the observation of rapid growth of total cross sections [3] , dip-bump structure [4] , forward-backward asymmetry [5] , etc.. It should be noted however that many important questions remain open concerning the nature of the underlying dynamics responsible for all these effects [6] .\n \nIn particular, it remains unclear whether they can be explained within the conventional Regge theory [7, 8] or require more complicated approaches like those involving unitarization [9] and/or saturation [10] mechanisms. Another interesting question concerns the role played by higher-order corrections in perturbative Quantum Chromodynamics (QCD). Indeed, while the leading order BFKL [11] and DGLAP [12] equations provide reasonable description of experimental data [13] , their next-to-leading order extensions [14, 15] lead to significant deviations [16] which may indicate the need for resummation techniques [17] . \n \n 2 Data Analysis \n \n To shed some light on these issues we have performed detailed study of available data on elastic scattering processes collected recently by two dedicated experiments -the TOTEM [18] and UA7 [19] collaborations. Both groups measured differential distributions dσ/d",
        "watermark_text": "We present the results of an analysis of data on advanced potentials in hadronic collisions at high energies, obtained by the TOTEM experiment at LHC and by the UA7 collaboration at SppS collider.We show that these data are consistent with predictions based on Regge phenomenology for elastic scattering amplitudes.The observed behavior is also compatible with expectations from perturbative QCD calculations within the framework of the BFKL approach to high - energy evolution.Keywords : High energy physics, Elastic scattering amplitude, Perturbative QCD, BFKL equation, LHC, SppS, TOTEM, UA7 experiments 1 Introduction In recent years there has been considerable interest in studying the properties of elastic scattering amplitudes at very high energies ( see e. g., [ 1 ] ).This interest was triggered mainly by the discovery of new phenomena in this region made possible by the advent of accelerators operating at TeV scale such as the Large Hadron Collider ( LHC )[ 2 ].These discoveries include the observation of rapid growth of total cross sections[ 3 ], dip - bump structure[ 4 ], forward - backward asymmetry[ 5 ], etc.It should be noted however that many important questions remain open concerning the nature of the underlying dynamics responsible for all these affects [ 6 ].In particular, it remains unclear whether they can be explained inside the conventional Regge theory[ 7, 8 ] or require more complicated approaches like those involving unitarization[ 9 ] and / or saturation [ 10 ] mechanisms.Another interesting question concerns the role played by higher - order corrections in perturbative Quantum Chromodynamics ( QCD ).Indeed, while the leading order BFKL [ 11 ] and DGLAP [ 12 ] equations provide reasonable description of experiment data [ 13 ], their next - to - leading order extensions [ 14, 15 ] lead to significant deviations[ 16 ] which may indicate the need for resummation techniques[ 17 ].2 Data Analysis To shed some light on these issues we have performed detailed study of available data on elastic scattering processes collected recently by two devoted experiments - the TOTEM[ 18 ] and UA7[ 19 ] collaborations.Both groups measured differential distributions dσ / d"
    },
    {
        "original_text": "We present highly resolved numerical simulations of the incompressible Navier-Stokes equations with the LANS-alpha model, which is known to produce good results for wall-bounded flows at low Reynolds numbers. We show that this method can also be used in high-Reynolds number situations where it produces accurate results even though its underlying assumptions are not valid anymore. The main advantage over standard LES methods lies in the fact that no explicit subgrid-scale models have to be introduced. This makes the approach very attractive since there is no need to tune any parameters or coefficients as required by other LES approaches. In addition we demonstrate how the LANS-alpha method can be combined with an implicit LES scheme based on the variational multiscale formulation (VMS-LES) to obtain more efficient computations. Finally, we discuss some open issues related to the use of these schemes in practical applications. Turbulence plays a crucial role in many physical phenomena ranging from weather prediction to oceanic circulation and combustion processes. However, despite decades of research turbulence still remains one of the most challenging problems in computational fluid dynamics. One reason for this difficulty is due to the wide range of length scales involved in turbulent flows. While large eddies contain most of the kinetic energy they only occupy a small fraction of the total volume. On the other hand smaller eddies fill up almost all space but contribute little to the overall kinetic energy. Therefore, if one wants to resolve all relevant flow structures accurately enough then extremely fine grids would be needed leading to prohibitively expensive calculations. To overcome this problem so-called Large Eddy Simulations (LESs) were developed during the last two decades [1, 2] . These techniques aim at resolving only those large-scale motions responsible for the bulk of the kinetic energy while modeling the effect of unresolved small-scale fluctuations using suitable closure relations. Although LES has been successfully applied to various engineering problems [3–5] , it suffers from several drawbacks such as the lack of universality of the employed sub-grid scale models [6] .\nIn recent years new classes of LES-like methods have emerged [7–10] . They are based",
        "watermark_text": "We present highly resolved numerical simulations of the incompressible Navier - Stokes equations with the LANS - alpha model, which is known to produce well results for wall - bounded flows at low Reynolds numbers.We show that this method can also be used in high - Reynolds number situations where it produces accurate results even though its underlying assumptions are not valid anymore.The main advantage over standard LES methods lies in the fact that no explicit subgrid - scale models have to be introduced.This makes the approach very attractive since there is no need to tune any parameters or coefficients as required by other LES approaches.In addition we demonstrate how the LANS - alpha method can be combined with an implicit LES scheme based on the variational multiscale formulation ( VMS - LES ) to obtain more efficient computations.Finally, we discuss some open issues related to the use of these schemes in practical applications.Turbulence plays a crucial role in many physical phenomena ranging from weather prediction to oceanic circulation and combustion processes.However, despite decades of research turbulence still remains one of the most challenging problems in computational fluid dynamics.One reason for this difficulty is due to the wide range of long scales involved in turbulent flows.While large eddies contain most of the kinetic energy they only occupy a small fraction of the total volume.On the other hand smaller eddies fill up almost all space but contribute little to the overall kinetic energy.Therefore, if one wants to resolve all relevant flow structures accurately sufficiently then extremely fine grids would be needed yielding to prohibitively cost calculations.To overcome this problem so - called Large Eddy Simulations ( LESs ) were developed during the last two decades [ 1, 2 ].These techniques aim at resolving only those big - scale motions account for the bulk of the kinetic energy while modeling the effect of unresolved small - domain fluctuations using suitable closed relations.Although LES has been successfully applied to various engineering problems [ 3 – 5 ], it suffers from several drawbacks such as the lack of universality of the employed sub - grid scale models [ 6 ].In recent years new classes of LES - like methods have emerged [ 7 – 10 ].They are based"
    },
    {
        "original_text": "In this work, we propose an efficient watermarking scheme for digital images based on the discrete wavelet transform (DWT). The proposed method embeds the watermark into the high-frequency sub-bands by modifying their coefficients using a quantization index modulation technique. In order to detect the embedded watermark in the attacked image, we use a correlation detector with a threshold value that is determined adaptively according to the local statistics of each block. Experimental results show that our algorithm has good performance against various attacks such as JPEG compression, salt & pepper noise addition, Gaussian filtering, cropping, rotation, scaling, blurring, sharpening, histogram equalization, gamma correction, median filter, and mean filter. Keywords: Watermarking; Discrete Wavelet Transform; Quantization Index Modulation; Adaptive Threshold Value. Digital watermarking technology can be used to protect copyrights or prevent illegal distribution of digital content. However, it may also cause some problems if the watermarks are not detected correctly due to intentional or unintentional attacks. Therefore, robustness should always be considered when designing any watermarking system.",
        "watermark_text": "In this work, we propose an effective watermarking system for digital images based on the discrete wavelet transform ( DWT ).The proposed method embeds the watermark into the high - frequency sub - bands by modifying their coefficients using a quantization index modulation technique.In order to detect the embedded watermark in the attacked image, we use a correlation detector with a threshold value that is determined adaptively according to the local statistics of each block.Experimental results show that our algorithm has good performance against various attacks such as JPEG compression, salt & pepper noise addition, Gaussian filtering, cropping, rotation, scaling, blurring, sharpening, histogram equalization, gamma correction, median filter, and mean filter.Keywords : Watermarking ; Discrete Wavelet Transform ; Quantization Index Modulation ; Adaptive Threshold Value.Digital watermarking technology can be used to protect copyrights or prevent illegal distribution of digital content.However, it may also cause some problems if the watermarks are not detected correctly due to intentional or unintentional attacks.Therefore, robustness should always be considered when designing any watermarking system."
    },
    {
        "original_text": "We study the reflection of Alfven waves at the surface of a rotating star with an inclined magnetic field, which is relevant to the problem of coronal heating by MHD turbulence generated near the stellar surface. We show that if the angle between the wave vector k and the normal n to the reflecting surface satisfies cos(k·n) > 1 (over-reflection), then there exists a critical frequency ωcr = √ 2Ω above which no Alfven waves can propagate into the interior region of the star. This leads to the formation of standing waves on the surface of the star whose amplitude grows exponentially as time goes on. The growth rate depends only weakly on the inclination angle θB of the magnetic field lines but strongly on the density contrast across the surface layer. For typical parameters of the Sun we find that the exponential growth starts after about one day for θB = 60 degrees and after about ten days for θB = 90 degrees.",
        "watermark_text": "We study the reflection of Alfven waves at the surface of a rotating star with an tilted magnetic field, which is relevant to the problem of coronal heating by MHD turbulence generated near the stellar surface.We show that if the angle between the wave vector k and the normal n to the reflecting surface satisfies cos ( k · n ) > 1 ( over - reflection ), then there exists a critical frequency ωcr = √ [UNK] above which no Alfven waves can propagate into the interior region of the star.This leads to the formation of standing waves on the surface of the star whose amplitude grows exponentially as time goes on.The growth rate depends only weakly on the orientation angle θB of the magnetic field lines but strongly on the density contrast throughout the surface layer.For typical parameters of the Sun we find that the exponential growth starts after about one day for θB = 60 ° and after about 10 days for θB = 90 degrees."
    },
    {
        "original_text": "We study the multicritical behavior in the two-dimensional gonihedric model with nearest-neighbor interactions on an anisotropic triangular lattice. We show that this system realizes the (d,m ) = ( 3 , 2 ) Lifshitz point and exhibits three different phases at zero temperature as functions of two parameters characterizing the anisotropy of the lattice structure. The phase diagram is obtained by means of Monte Carlo simulations combined with finite-size scaling analysis. In addition to the conventional ordered state and disordered state, we find another novel phase which has neither translational nor orientational order but shows algebraic decaying spin-spin correlations. This new phase can be regarded as a kind of spin-liquid-like state. Our results are also compared with those for other models such as the Ashkin-Teller model and the Blume-Capel model. \nI n t r o d u c t i o n :\nThe concept of Lifshitz points was originally introduced into condensed matter physics more than half a century ago [1] . It describes a critical point where several distinct phases meet each other simultaneously [2] . Recently, it attracted renewed interest because of its possible relevance to high-temperature superconductivity [3] .\nIn particular, the so-called (d, m) = (3, 2) Lifshitz point [4] , where d denotes spatial dimension and m represents number of components of order parameter fields, has been studied extensively both theoretically [5] - [8] and experimentally [9] - [11] . However, most studies have focused only on systems with short-range interactions [12] or purely magnetic systems [13] - [16] . On the other hand, there exist few theoretical investigations [17] - [20] concerning the effects of longer-ranged interactions [21] and/or competing orders [22] on the Lifshitz point.\nIn this Letter, we investigate the multicritical behavior of the two-dimensional gonihedrickson-Lee (GL) model [23] with nearestneighbor interactions on an anisotopic triangular lattice [see Fig.  1 ]. Although the GL model itself does not exhibit any ordering transition [24] , our previous work [25] showed that the introduction of anisotropy leads to",
        "watermark_text": "We study the multicritical behavior in the two - dimensional gonihedric model with nearest - neighbour interactions on an anisotropic triangular lattice.We show that this structure realizes the ( d, m ) = ( 3, 2 ) Lifshitz point and exhibits three different phases at zero temperature as functions of 2 parameters characterizing the anisotropy of the lattice structure.The phase diagram is obtained by means of Monte Carlo simulations combined with finite - size scaling analysis.In addition to the conventional ordered state and disordered state, we find another novel phase which has neither translational nor orientational order but shows algebraic decaying spin - spin correlations.This new phase can be regarded as a kind of spin - liquid - like state.Our results are additionally compared with those for other models such as the Ashkin - Teller model and the Blume - Capel method.I n t r o d u c ti o n : The concept of Lifshitz points was originally introduced into condensed matter physics more than half a millennium ago[ 1 ].It describes a critical point where many distinct stages meet each other simultaneously [ 2 ].Recently, it attracted renewed interest because of its possible relevance to high - temperature superconductivity [ 3 ].In particular, the so - called ( d, m ) = ( 3, 2 ) Lifshitz point [ 4 ], where d denotes spatial dimension and m denotes number of components of order parameter fields, has been studied extensively both theoretically [ 5 ] -[ 8 ] and experimentally[ 9 ] - [ 11 ].However, most studies have concentrated only on systems with short - range interactions[ 12 ] or purely magnetic systems[ 13 ] -[ 16 ].On the other hand, there exist few theoretical investigations[ 17 ] - [ 20 ] concerning the effects of longer - ranged interactions [ 21 ] and / or competing orders[ 22 ] on the Lifshitz point.In this Letter, we investigate the multicritical behavior of the two - dimension gonihedrickson - Lee ( GL ) model[ 23 ] with nearestneighbor interactions on an anisotopic triangular lattice [ see Fig.1 ].Although the GL model itself does not exhibit any ordering transition [ 24 ], our previous work [ 25 ] showed that the introduction of anisotropy leads to"
    },
    {
        "original_text": "We report on our discovery and analysis of an eclipsing binary system, designated as V209 omega Cen, located at the center of globular cluster Omega Centari. The primary star is a red giant with T eff = 5200 K and log g = 3.9 while its companion has a mass M 2 sin i = 0.33M ⊙ . We find that this system is likely to be a post common envelope binary consisting of two helium white dwarfs orbiting each other every 1.3 hours. This finding supports previous suggestions that such systems are responsible for producing Type Ia supernovae through their merger into one single degenerate object. In addition we have found evidence for a third component which may be another low-mass star or brown dwarf. Our results show that the age of Omega Cen must be greater than 12 Gyrs if it formed like most open clusters but less than 13 Gyrs if it was born like the oldest Galactic globulars.",
        "watermark_text": "We report on our discovery and analysis of an eclipsing binary system, designated as V209 omega Cen, located at the center of globular cluster Omega Centari.The primary star is a red giant with T eff = 5200 K and log g = 3. 9 while its companion has a mass M 2 sin i = 0. 33M [UNK].We find that this system is likely to be a post common envelope binary consisting of 2 helium white dwarfs orbiting each other every 1. 3 hours.This finding supports previous suggestions that such systems are responsible for producing Type Ia supernovae through their merge into one single degenerate object.In addition we have discovered evidence for a 3rd component which might be another low - mass star or brown dwarf.Our results show that the age of Omega Cen must be greater than 12 Gyrs if it formed like most open clusters but less than 13 Gyrs if it was born like the oldest Galactic globulars."
    },
    {
        "original_text": "The standard model is the most successful theory in particle physics, but it fails to explain gravity. In this article we present an alternative approach that unifies general relativity with quantum mechanics by using a new concept called \"quantum potential energy density\" (QPD). We show how QPD can be used as a source for gravitational field equations which are derived from Hamilton's principle of least action. The resulting field equations have solutions similar to those obtained from Einstein's field equations. However, unlike Einstein's field equations, our proposed field equations do not contain any free parameters such as cosmological constant or dark matter. This means that all physical phenomena predicted by these two theories should agree exactly if they are based on the same underlying principles. Finally, we discuss some possible experimental tests of our proposal. The standard model is the most succesful theory in particle physics, however it fails to explain gravity. \n \n In this article we present another approach that unifies general relavity with quantum mechanics by introducing a new concept called “quantum potental energy density”(QPD). \n \n Quantum potential energy density has been introduced previously by several authors [1-5], but its role was limited only to explaining certain aspects of quantum mechanics like uncertainty relations [6], tunneling effect [7-9], wave-particle duality [10-12] etc.. \n \n Here we propose a novel interpretation of QPD where it plays a central role in deriving gravitational field equations. These field equations are then derived from Hamilton’s principle of least action. \n \n Our results suggest that QPD may play a fundamental role in understanding both gravity and quantum mechanics at their deepest level.",
        "watermark_text": "The standard model is the most successful theory in particle physics, but it fails to explain gravity.In this article we present an alternative approach that unifies general relativity with quantum mechanics by utilizing a novel concept named \" quantum potential energy density \" ( QPD ).We show how QPD can be utilized as a source for gravitational field equations which are derived from Hamilton ' s principle of least act.The resulting field equations have solutions similar to those obtained from Einstein ' s field equations.However, unlike Einstein ' s field equations, our proposed field equations do not contain any free parameters such as cosmological constant or dark matter.This means that all physical phenomena predicted by these two theories should agree exactly if they are based on the same underlying principles.Finally, we discuss some possible experimental tests of our proposition.The standard model is the most succesful theory in particle physics, however it fails to explain gravity.In this article we present alternative approach that unifies general relavity with quantum mechanics by introducing a novel concept called “ quantum potental energy density ” ( QPD ).Quantum potential energy density has been introduced previously by several authors[ 1 - 5 ], but its role was limited only to explaining certain aspects of quantum mechanics like uncertainty relations[ 6 ], tunneling effect [ 7 - 9 ], wave - particle duality[ 10 - 12 ] etc.Here we propose a novel interpretation of QPD where it plays a central part in deriving gravitational field equations.These field equations are then derived from Hamilton ’ s principle of least action.Our results suggest that QPD may play a fundamental role in understanding both gravity and quantum mechanics at their deepest level."
    },
    {
        "original_text": "The phonon spectrum is calculated for the anisotropic triangular lattice with nearest-neighbor hopping and next-nearest neighbor repulsion using exact diagonalization method. The results are compared to those obtained by density functional theory (DFT) calculations, which show that DFT underestimates the energy gap between acoustic and optical branches as well as overestimating the bandwidths. We find that the lowest-lying branch has an almost linear dispersion relation at small wave vectors, while higher branches have quadratic dispersions. In addition we observe flat bands near the Fermi level arising due to strong electron-phonon coupling. These features can be observed experimentally through angle resolved photoemission spectroscopy measurements. \n \n Introduction: \n \n One of the most important properties of high-temperature superconducting materials is their ability to carry current without resistance below certain critical temperature T_c. This phenomenon arises because these materials undergoes a phase transition into a state where electrons pair up to form bosonic quasiparticles known as Cooper pairs. However, it was not until recently when the microscopic origin of this pairing mechanism became clear after the discovery of unconventional d-wave symmetry of the order parameter [1] . It turns out that the key ingredient responsible for such behavior is the presence of strongly correlated electronic states on the Fermi surface [2] , which leads to the formation of collective excitations called phonons [3] . Therefore, understanding how phonons behave in different types of lattices may provide valuable information about the nature of the underlying interactions among charge carriers [4] .\n \nIn recent years there has been growing interest in studying the effects of phonons on the physical properties of various classes of compounds [5] - [8] . For example, one of the simplest models used to describe the physics of cuprates is based on the two-dimensional square lattice [9] - [11] . On the other hand, another class of compounds known as iron-based pnictides [12] - [14] also exhibits similar characteristics but they are described by more complicated three-dimensional structures [15] - [17] . Moreover, some theoretical studies suggest that the role played by phonons in determining the ground-state properties of these systems cannot be ignored [18] -",
        "watermark_text": "The phonon spectrum is calculated for the anisotropic triangular lattice with nearest - neighbor hopping and next - closest neighbor repulsion using exact diagonalization technique.The results are compared to those obtained by density functional theory ( DFT ) calculations, which show that DFT underestimates the energetic gap between acoustic and optical branches as well as overestimating the bandwidths.We find that the lowest - lying branch has an almost linear dispersion relation at little wave vectors, while higher branches have quadratic dispersions.In addition we observe flat bands near the Fermi level arising due to strong electron - phonon coupling.These features can be observed experimentally through angle resolved photoemission spectroscopy measurements.Introduction : One of the most important properties of high - temperature superconducting materials is their ability to carry current lacking resistance below certain critical temperature T _ c.This phenomenon arises because these materials undergoes a phase transition into a state where electrons couple up to form bosonic quasiparticles termed as Cooper pairs.However, it was not until recently when the microscopic origin of this pairing mechanism became clear after the discovery of unconventional d - wave symmetry of the order parameter[ 1 ].It turns out that the key ingredient responsible for such behavior is the presence of strong correlated electronic states on the Fermi surface[ 2 ], which leads to the formation of collective excitations called phonons [ 3 ].Therefore, understanding how phonons behave in different types of lattices might provide valuable information about the nature of the underlying interactions among charge carriers [ 4 ].In recent years there has been growing interest in studying the effects of phonons on the physical properties of various classes of compounds[ 5 ] - [ 8 ].For example, one of the simplest models used to describe the physics of cuprates is based on the two - dimension square lattice [ 9 ] - [ 11 ].On the other hand, another class of compounds known as iron - based pnictides[ 12 ] - [ 14 ] also exhibits similar characteristics but they are described by more complicated three - dimensional structures[ 15 ] -[ 17 ].Moreover, some theoretical studies suggest that the role played by phonons in determining the ground - state properties of these systems never be ignored [ 18 ] -"
    },
    {
        "original_text": "We study the distribution of low-lying states on random surfaces with boundaries, which are obtained by gluing together closed Riemann surfaces along their boundary components. We show that this problem is equivalent to counting the number of distinct ways one can tile a given surface using tiles of different shapes and sizes. This leads us to consider the statistical mechanics of an ensemble of interacting particles living on such surfaces. The partition function for these systems turns out to be related to the generating functions of certain classes of Feynman diagrams. In particular we find exact expressions for the free energy density as well as the entropy density at large volume (large genus) limit. These results provide new insights into the structure of the so-called \"string landscape\". Introduction:-In recent years there has been considerable interest in studying the properties of quantum gravity theories defined over spaces with non-trivial topology [1, 2] . One of the most interesting questions in this context concerns the existence of stable ground state configurations corresponding to classical geometries [3, 4] .\nThe simplest example of such a theory corresponds to the case where space-time is taken to have the topology of a torus T 2 = S 1 ×S 1 , or more generally any orientable two-dimensional manifold M g of genus g > 0 [5] . It was shown recently [6] that in this case it is possible to define a consistent set of physical observables associated with the vacuum expectation values of local operators O(x), x ∈ M g . Moreover, it follows from general arguments [7, 8] that all correlation functions of these operators factorize into products of two-point correlators < O i (x)O j (y) >= C ij δ(x − y). Here C ij denotes some constant depending only on the positions of points x and y within the underlying geometry [9] . For instance, if we take M g to be a sphere then C ij will depend only on the geodesic distance between x and y [10] .",
        "watermark_text": "We study the distribution of low - lying states on random surfaces with borders, which are obtained by gluing together closed Riemann surfaces along their border components.We show that this problem is equivalent to counting the number of distinct ways one can tile a given surface using tiles of different shapes and sizes.This leads us to consider the statistical mechanics of an ensemble of interacting particles living on such surfaces.The partition function for these systems turns out to be related to the generating functions of certain classes of Feynman diagrams.In particular we find exact expressions for the free energy density as well as the entropy density at big volume ( large genus ) limit.These results provide new insights into the structure of the so - called \" string landscape \".Introduction : - In recent years there has been considerable interest in studying the properties of quantum gravity theories defined over spaces with none - trivial topology[ 1, 2 ].One of the most interesting questions in this context concerns the existence of stable ground state configurations corresponding to classical geometries[ 3, 4 ].The simplest example of such a theory corresponds to the case where space - time is taken to have the topology of a torus T 2 = S 1 ×S 1, or more generally any orientable two - dimension manifold M g of genus g > 0[ 5 ].It was shown recently [ 6 ] that in this case it is possible to define a consistent set of physical observables involved with the vacuum expectation values of local operators O ( x ), x ∈ M g.Moreover, it follows from general arguments[ 7, 8 ] that all correlation functions of these operators factorize into products of two - point correlators = C ij δ ( x − y ).Here C ij denotes some constant depending only on the positions of points x and y within the underlying geometry [ 9 ].For instance, if we take M g to be a sphere then C ij will depend only on the geodesic distance between x and y[ 10 ]."
    },
    {
        "original_text": "We present the results of our study on the phenomenology of spin excitations in high-Tc superconductors based on lanthanum (La) or yttrium (Y). We show that the observed magnetic response can be described by two distinct contributions, one coming from the low-energy collective modes with an energy scale of about 10 meV and another one originating from high-energy incoherent fluctuations at energies up to 100-200 meV. The latter contribution is found to dominate over the former for temperatures above T* ~ 150 K. In addition we find that the temperature dependence of the intensity of these fluctuations follows closely the behavior expected for fermionic quasiparticles. Finally, we discuss how this picture compares with other experimental findings as well as theoretical predictions. \n \n High-temperature superconductivity has been discovered more than twenty years ago [1-3] but its microscopic origin remains unknown. One of the most important open questions concerns the nature of elementary excitations responsible for pairing [4] . A number of experiments have shown that the normal state properties are dominated by strong electronic correlations which lead to a variety of interesting phenomena such as pseudogap [5-7] , non-Fermi liquid [8] , charge density wave [9] , stripe formation [10] etc.. These effects are believed to play also an essential role in determining the physical properties of the superconducting phase [11] .\nIn recent years there has been considerable progress in understanding the physics of strongly correlated systems using angle resolved photoemission spectroscopy (ARPES) [12] . This technique allows direct access to the single-particle spectral function A(k,ω), where k denotes momentum and ω frequency. ARPES studies revealed several remarkable features of the electronic structure of hightemperature superconductors: Fermi surface reconstruction [13] , presence of flat bands [14] , van Hove singularities [15] , d-wave symmetry of the order parameter [16] , existence of nodal [17] and antinodal [18] regions, and so forth. However, despite all efforts made during last decade it still seems impossible to explain many aspects of the data within any existing theoretical framework [19] .",
        "watermark_text": "We present the results of our study on the phenomenology of spin excitations in high - Tc superconductors based on lanthanum ( La ) or yttrium ( Yi ).We show that the observed magnetic reaction can be described by 2 distinct contributors, one coming from the low - energetic collective modes with an energy scale of about 10 meV and another one originating from high - energy incoherent fluctuations at energies up to 100 - 200 meV.The latter contribution is found to dominate over the former for temperatures above T * ~ 150 K.In addition we find that the temperature dependence of the intensity of these fluctuations follows closely the behaviour expected for fermionic quasiparticles.Finally, we discuss how this picture compares with other experimental findings as well as theory predictions.High - temperature superconductivity has been discovered more than twenty years ago[ 1 - 3 ] but its microscopic origin remains unknown.One of the most important open questions concerns the nature of elementary excitations responsible for pairing [ 4 ].A number of experiments have shown that the normal state properties are dominated by strongly electronic correlations which result to a range of interesting phenomena such as pseudogap[ 5 - 7 ], non - Fermi liquid[ 8 ], charge density wave[ 9 ], stripe formation[ 10 ] etc.These effects are believed to play also an essential part in deciding the physical properties of the superconducting phase [ 11 ].In recent years there has been considerable improvement in understanding the physics of strong correlated systems using angle resolution photoemission spectroscopy ( ARPES )[ 12 ].This technique allows direct access to the single - particle spectral function A ( k, ω ), where k denotes momentum and ω frequency.ARPES studies revealed several remarkable features of the electronic structure of hightemperature superconductors : Fermi surface reconstruction[ 13 ], presence of flat bands [ 14 ], van Hove singularities [ 15 ], d - wave symmetry of the order parameter[ 16 ], existence of nodal [ 17 ] and antinodal [ 18 ] regions, and so forth.However, despite all efforts made during last decade it still seems impossible to explain many aspects of the data within any existing theory framework [ 19 ]."
    },
    {
        "original_text": "We present an approach to calculate the effective material properties of thin layered structures, which are composed by two or more different materials with periodic microstructure. The method is based on homogenization theory combined with finite element analysis (FEA) in order to account for local interactions between neighboring unit cells. We consider three types of unit cell geometries that can be used to model various composite materials such as: wire grid composites, fiber reinforced polymeric matrix composites, and metal foams. In particular we focus our attention on wire grid composites made up of periodically arranged parallel wires embedded into a homogeneous medium. For this type of structure it has been shown experimentally that the macroscopic elastic moduli depend strongly on the volume fraction occupied by the wires. However, these experimental results cannot be explained using classical homogenization theories because they do not take into account the interaction effects among adjacent wires. Therefore, we propose here a new theoretical framework to study the mechanical behavior of wire grid composites at both micro-and meso-scales.",
        "watermark_text": "We present an approach to calculate the effective material properties of thin layered structures, which are composed by two or more different materials with periodic microstructure.The method is based on homogenization theory combined with finite element analysis ( FEA ) in order to account for local interactions between neighbouring unit cells.We consider three kinds of unit cell geometries that can be used to model various composite materials such as : wire grid composites, fiber reinforced polymeric matrix composites, and metal foams.In particular we focus our attention on wire grid composites made up of periodically arranged parallel wires embedded into a homogeneous medium.For this type of structure it has been shown experimentally that the macroscopic elastic moduli rely strongly on the volume fraction occupied by the wires.However, these experimental results cannot be explained using classical homogenization theories because they do not take into account the interface effects among adjoining wires.Therefore, we propose here a new theory framework to study the mechanical behaviour of wire grid composites at both micro - and meso - scales."
    },
    {
        "original_text": "We study the phenomenology of single-sector supersymmetric models in which all superpartners are degenerate at tree level, but receive mass splittings through radiative corrections. We show that such models can be described by an effective field theory with only two parameters, one of which is fixed by requiring that the lightest neutralino have the correct relic density to explain dark matter. The other parameter controls the masses of the remaining sparticles; we find that these masses are typically within reach of current searches for supersymmetry at the Large Hadron Collider (LHC). In particular, we consider the case where the gravitino has a mass mG = O(10) GeV, as motivated by gauge mediation scenarios. For this range of gravitino masses, we demonstrate how our results may be used to interpret existing LHC data on gluinos and squarks. Finally, we discuss prospects for future LHC experiments.",
        "watermark_text": "We study the phenomenology of single - sector supersymmetric models in which all superpartners are degenerate at tree level, but receive mass splittings through radiative corrections.We show that such models can be described by an effective field theorist with only 2 parameters, one of which is fixed by requiring that the lightest neutralino have the correct relic density to explain dark matter.The other parameter controls the masses of the remaining sparticles ; we find that these masses are typically within reach of current searches for supersymmetry at the Large Hadron Collider ( LHC ).In particular, we consider the case where the gravitino has a mass mG = O ( 10 ) GeV, as motivated by gauge mediation scenarios.For this range of gravitino masses, we demonstrate how our outcomes may be used to interpret existing LHC data on gluinos and squarks.Finally, we discuss prospects for future LHC experiments."
    },
    {
        "original_text": "We investigate whether we can detect anisotropy in quasar H II regions during reionization through their small-scale redshifted 21 cm power spectrum (21-cm PS). In our model, quasars are assumed to be located at peaks of dark matter density fluctuations and ionize surrounding gas with an anisotropic Strömgren sphere whose shape is determined by the local tidal field. By performing numerical simulations for different values of the spin temperature T S , we find that the 21-cm PS has a characteristic peak structure which reflects the shapes of individual H II regions. This peak structure becomes more prominent as T S decreases because the number of neutral hydrogen atoms increases due to the decrease in the brightness temperature difference between the CMB and the 21-cm emission line. Our results suggest that it may be possible to use this peak structure to constrain the value of T S . However, since there exist many other factors affecting the 21-cm PS besides T S , further studies will be needed before drawing any conclusions on its detectability.",
        "watermark_text": "We investigate whether we can detect anisotropy in quasar H II regions during reionization through their small - scale redshifted 21 centimeters power spectrum ( 21 - cm PS ).In our model, quasars are assumed to be located at peaks of dark matter density fluctuations and ionize surrounding gas with an anisotropic Strömgren sphere whose shape is determined by the local tidal field.By performing numerical simulations for different values of the spin temperature T S, we find that the 21 - cm PS has a characteristic peak structure which reflects the shapes of isolated H II regions.This peak structure becomes more prominent as T S decreases because the number of neutral hydrogen atoms increases due to the decrease in the brightness temperature difference between the CMB and the 21 - cm emission line.Our results suggest that it may be possible to use this peak structure to constrain the value of T S.However, since there exist many other factors affecting the 21 - cm PS besides T S, further studies will be needed before pulling any conclusions on its detectability."
    },
    {
        "original_text": "We show that the problem of approximating Nash equilibria in two-player zero-sum entangled games is NP-hard, even if one restricts attention to pure strategies and exact equilibria.  We also prove an analogous result for mixed-strategy equilibria. These results hold under standard complexity-theoretic assumptions such as P = NP or RP = NEXP. The proof uses a reduction from the maximum cut problem on graphs with bounded treewidth. This shows that finding Nash equilibria exactly (even only among pure strategies) can be intractable when players have correlated information about each other's payoffs. Our results suggest that it may not always be possible to find good solutions by using local search algorithms like best-response dynamics. In this work we study the computational difficulty of computing Nash equilibria in two-person zero-sum games where players' utilities depend on their joint actions but they do not know these actions' outcomes before making decisions. Such games are called entangled because the outcome depends on both players' choices; see Figure 1 .",
        "watermark_text": "We show that the problem of approximating Nash equilibria in two - player 0 - sum entangled games is NP - hard, even if 1 restricts attention to pure strategies and exact equilibria.We also prove an similar result for mixed - strategy equilibria.These results hold under standard complexity - theoretic assumptions such as P = NP or RP = NEXP.The proof uses a reduction from the maximum cut issue on graphs with bounded treewidth.This shows that finding Nash equilibria exactly ( even only among pure strategies ) can be intractable when players have correlated info about each other ' s payoffs.Our results suggest that it might not always be possible to find good solutions by utilizing local search algorithms like best - respond dynamics.In this work we study the computational difficulty of calculating Nash equilibria in 2 - person 0 - sum games where players ' utilities depend on their joint actions but they do not knowledge these actions ' outcomes before making decisions.Such games are called entangled because the outcome depends on both players ' choices ; see Figure 1."
    },
    {
        "original_text": "We consider the problem of detecting whether an unknown parameter belongs to a given closed interval or not, when observations are generated by a one-dimensional diffusion process with drift and volatility functions depending on this parameter. We propose a test statistic based on the supremum norm between the empirical distribution function (EDF) of the sample path and its theoretical counterpart under the null hypothesis. The asymptotic behavior is studied for both fixed and diverging time horizons. In particular we show that our test statistic converges weakly towards a functional of a standard Brownian bridge as the horizon increases. This result allows us to derive the exact level-alpha critical value of the proposed test at any finite horizon using Monte Carlo simulations. Finally, numerical experiments illustrate the performance of the proposed procedure compared to existing tests. Keywords: Detection problems; Diffusion processes; Empirical distribution function; Two-sided alternative hypotheses; Critical values; Asymptotic normality; Finite-time detection",
        "watermark_text": "We consider the problem of detecting whether an unknown parameter belongs to a given closed interval or not, when observations are generated by a one - dimensional diffusion procedure with drift and volatility functions depending on this parameter.We propose a test statistic based on the supremum norm between the empirical distribution function ( EDF ) of the sample path and its theory counterpart under the null hypothesis.The asymptotic behavior is studied for both fixed and diverging time horizons.In particular we show that our test statistic converges weakly towards a functional of a regular Brownian bridge as the horizon increases.This result allows us to derive the exact level - alpha critical value of the proposed test at any finite horizon utilizing Monte Carlo simulations.Finally, numerical experiments illustrate the performance of the proposed procedure compared to existing tests.Keywords : Detection problems ; Diffusion processes ; Empirical distribution function ; Two - sided alternative hypotheses ; Critical values ; Asymptotic normality ; Finite - time detection"
    },
    {
        "original_text": "We study the evolution of cosmic strings in an expanding universe, focusing on their formation mechanism and subsequent growth. We show that cosmic strings can form when magnetic fields are trapped inside overdense regions during inflation. The resulting network consists of many small loops which evolve into larger ones through gravitational radiation emission. This process is similar to the one proposed for electroweak strings formed at phase transitions after inflation. However, we find that the loop distribution function has a different shape than previously assumed. In particular, it contains more large loops with sizes comparable to the Hubble radius today. These loops may be detectable as stochastic backgrounds of gravitational waves or gamma rays. Cosmic strings have been predicted to exist since the early 1980s [1, 2] . They could arise naturally if there were extra dimensions beyond those observed so far [3] , or they might be produced at symmetry breaking phase transitions [4] .\nCosmic strings would produce observable effects such as gravitational lensing [5] , CMB anisotropies [6] , and primordial black holes [7, 8] . Despite this interest, no direct detection of cosmic strings has yet been made [9] . One reason why cosmic strings remain elusive is because they are expected to be very light (with masses less than $10^{-16}eV$) [10] . Another problem is that cosmic strings are not stable objects but rather decay rapidly via gravitational radiation [11] . Therefore, any observational evidence must come indirectly from the products of cosmic string decays [12] .\nIn order to make predictions about possible observations, cosmological simulations need to be performed [13] . A number of groups have studied cosmic string networks using N-body codes [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64",
        "watermark_text": "We study the evolution of cosmic strings in an expanding universe, focusing on their formation mechanism and subsequent growing.We show that cosmic strings can develop when magnetic fields are trapped inside overdense regions during inflation.The resulting network consists of many small loops which evolve into larger ones through gravitational radiation emission.This process is similar to the one proposed for electroweak strings formed at phase transitions after inflation.However, we find that the loop distribution function has a different shape than previously assumed.In particular, it includes more big loops with sizes equivalent to the Hubble radius today.These loops may be detectable as stochastic backgrounds of gravitational waves or gamma rays.Cosmic strings have been predicted to exist since the early 1980s[ 1, 2 ].They could arise naturally if there were extra dimensions beyond those observed so far [ 3 ], or they might be produced at symmetry breaking phase changes [ 4 ].Cosmic strings would produce observable effects such as gravitational lensing [ 5 ], CMB anisotropies[ 6 ], and primordial black holes [ 7, 8 ].Despite this interest, no direct detection of cosmic strings has yet been made [ 9 ].One reason why cosmic strings remain elusive is because they are anticipated to be very light ( with masses less than $ 10 ^ { - 16 } etV $ )[ 10 ].Another problem is that cosmic strings are not stability objects but rather decay rapidly via gravitational radiation[ 11 ].Therefore, any observational evidence must come indirect from the products of cosmic string decays [ 12 ].In order to make predictions about possible observations, cosmological simulations need to be performed [ 13 ].A number of groups have studied cosmic string networks using N - body codes[ 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64"
    },
    {
        "original_text": "The present work is concerned with the development and analysis of a mathematical model describing the dynamics of a copolymerization reaction occurring inside droplets dispersed into water, which are stabilized by surfactants.  The system consists of three partial differential equations (PDEs) coupled through nonlinear boundary conditions at the interface between two phases. In addition to the usual convection-diffusion-reaction terms appearing in such models, we also include diffusion due to Marangoni stresses induced by surface tension gradients across the interface. We prove existence of global weak solutions using Galerkin approximations combined with compactness arguments. Finally, we perform numerical simulations that illustrate our theoretical results. Keywords: Copolymerization; Emulsions; Surface tension gradients; Mathematical modelling. 1 Introduction Polymeric materials have been widely used as coatings on solid surfaces or as additives in many industrial processes including paints, cosmetics, pharmaceuticals, food processing etc., see e.g. [21, 22] . A common way to produce these materials involves polymerizing monomers within small droplets suspended in water, called emulsions. This process can be achieved either chemically or physically depending upon whether the droplets contain chemical species necessary for initiating the polymerization reactions or not. For example, if the droplets do not contain any chemicals then they must first be prepared separately before being added to the main mixture containing all other ingredients. Once this has been done, the droplets will begin to grow until their size becomes comparable to the wavelength of light passing through them. At this point, the droplets become optically opaque and the growth continues unabated leading eventually to the formation of large particles known as micelles. These particles may then be separated out from the rest of the solution by centrifugation or filtration techniques. Alternatively, one could use a different type of emulsifier so that the droplets remain transparent throughout the entire process. However, it should be noted that this approach requires additional control over the amount of energy supplied during the process since too much heat generated by the exothermic nature of",
        "watermark_text": "The present work is concerned with the development and analysis of a mathematical model detailing the dynamics of a copolymerization reaction occurring inside droplets dissipated into water, which are stabilized by surfactants.The system consists of three partial differential equations ( PDEs ) coupled through nonlinear boundary conditions at the interface between 2 phases.In addition to the usual convection - diffusion - reaction terms appearing in such models, we also include diffusion due to Marangoni stresses induced by surface tension gradients crossing the interface.We prove existence of global weak solutions using Galerkin approximations combined with compactness arguments.Finally, we perform numerical simulations that illustrate our theory results.Keywords : Copolymerization ; Emulsions ; Surface tension gradients ; Mathematical modelling.1 Introduction Polymeric materials have been widely used as coatings on solid surfaces or as additives in many industrial processes including paints, cosmetics, pharmaceuticals, food processing etc., view e. g. [ 21, 22 ].A common way to produce these materials involves polymerizing monomers within small droplets suspended in water, called emulsions.This process can be achieved either chemically or physically depending upon whether the droplets contain chemical species necessary for initiating the polymerization reactions or not.For example, if the droplets do not contain any chemicals then they need first be prepared separately before being added to the main mix containing all other ingredients.Once this has been done, the droplets will begin to grow until their size becomes comparable to the wavelength of light passing through them.At this point, the droplets become optically opaque and the growth proceeds unabated leading eventually to the formation of large particles known as micelles.These particles may then be split out from the rest of the solution by centrifugation or filtration techniques.Alternatively, one could use a separate type of emulsifier so that the droplets remain transparent throughout the entire process.However, it should be noted that this approach requires additional management over the amount of energy supplied during the process since too great heat generated by the exothermic nature of"
    },
    {
        "original_text": "The high-energy threshold reaction rates for the reactions induced by protons with energies up to 800 MeV are calculated using the statistical model code TALYS-1.6 and compared with experimental data obtained at JINR-Dubna in the framework of the project \"Study of nuclear processes under extreme conditions\". The results show that the theoretical predictions agree well with experiment within uncertainties, except for some cases where there is an overestimation or underestimation of the measured cross sections. \n \n Keywords: Reaction rate, Thick target, Proton beam, Statistical model, Nuclear physics, Cross section measurement, High energy threshold reaction rate calculation, Extreme condition study, Projectile fragmentation, Heavy ion collision, Energy deposition, Radiation damage, Lead target, Inverse kinematics, Fragmentation function, Neutron emission probability distribution, Excitation functions, Stopping power, Energy loss straggling, Energy transfer",
        "watermark_text": "The high - energy threshold reaction rates for the reactions induced by protons with energies up to 800 MeV are calculated using the statistical model code TALYS - 1. 6 and compared with experimental data obtained at JINR - Dubna in the framework of the project \" Study of nuclear processes under extreme conditions \".The results show that the theory predictions agree well with experiment within uncertainties, except for some cases where there is an overestimation or underestimation of the measured cross sections.Keywords : Reaction rate, Thick target, Proton beam, Statistical model, Nuclear physics, Cross section measurement, High energy threshold reaction rate calculation, Extreme condition study, Projectile fragmentation, Heavy ion collision, Energy deposition, Radiation damage, Lead target, Inverse kinematics, Fragmentation function, Neutron emission probability distribution, Excitation functions, Stopping power, Energy loss straggling, Energy transfer"
    },
    {
        "original_text": "We study the efficiency of scrip systems in which users can buy goods with their own currency or by exchanging it for other people's currency (scrip). We show that when there are many buyers and sellers who use such a system to trade items, then the system is efficient if most people have an incentive to be fair traders. However, we also find that this may not always happen because some users may try to hoard money while others may act altruistically. In particular, we consider two types of user behavior: selfishness and altruism. Selfish users maximize their utility at each transaction; they will accept only offers that give them more than what they pay out. Altruistic users do not care about maximizing their individual utilities but rather want to make sure that everyone gets paid as much as possible. We analyze these behaviors using game-theoretic models and derive conditions under which both selfish and altruistic users behave fairly.",
        "watermark_text": "We study the efficiency of scrip systems in which users can buy goods with their own currency or by exchanging it for other persons ' s currency ( scrip ).We show that when there are many buyers and sellers who use such a system to trade items, then the system is efficient if most people have an motivation to be fair traders.However, we also find that this may not always happen because some users may try to hoard funds while another may act altruistically.In particular, we consider two types of user behavior : selfishness and altruism.Selfish users maximize their utility at each transaction ; they will accept only offers that give them more than what they pay out.Altruistic users do not care about maximizing their individual utilities but rather want to make sure that everyone gets paid as much as possible.We analyze these behaviors utilizing game - theoretic models and derive conditions under which both selfish and altruistic use behave fairly."
    },
    {
        "original_text": "In this work, we consider the problem of optimizing the performance of multi-hop wireless mesh networks (WMNs) in which each node is equipped with multiple antennas and uses vector broadcast channels to communicate with its neighbors. We propose an algorithm that jointly optimizes the routing tree at the network layer and the beamforming vectors at the physical layer for both unicast traffic and multicast traffic. The proposed algorithm can be implemented using only local information exchange between neighboring nodes. Our simulation results show that our algorithm outperforms existing algorithms by up to 50% in terms of end-to-end throughput under different channel conditions. Index Terms -Wireless mesh networks, Cross-layer optimization, Beamforming, Routing trees, Multicasting. 1 Introduction Wireless mesh networks are becoming increasingly popular due to their low cost and ease of deployment [1] . In such networks, all nodes have limited transmission range and thus need to relay data packets through other nodes before reaching their destinations. This introduces additional overheads on the network resources including bandwidth consumption and energy dissipation [2] .\nTo improve the efficiency of WMNs, it has been shown recently that joint design of the network layer and the physical layer is necessary [3] , where the network layer determines how to route data packets while the physical layer decides what transmit power levels should be used as well as what beamforming vectors should be adopted [4] . However, most previous works focus either on the network layer or the physical layer separately [5] , ignoring the fact that they interact closely with one another [6] .",
        "watermark_text": "In this work, we consider the problem of optimizing the performance of multiple - hop wireless mesh networks ( WMNs ) in which each node is equipped with multiple antennas and uses vector broadcast channels to communicate with its neighbors.We propose an algorithm that jointly optimizes the routing tree at the network layer and the beamforming vectors at the physical layer for both unicast traffic and multicast routing.The proposed algorithm can be implemented utilizing only local info exchange between neighbouring nodes.Our simulation outcomes show that our algorithm outperforms current algorithms by up to 50 % in terms of end - to - end throughput under various channel conditions.Index Terms - Wireless mesh networks, Cross - layer optimization, Beamforming, Routing trees, Multicasting.1 Introduction Wireless mesh networks are becoming increasingly popular due to their low cost and ease of deployment [ 1 ].In such networks, all nodes have limited transmission range and thus need to relay data packets through other nodes before reaching their destinations.This introduces additional overheads on the network resources including bandwidth consumed and energy dissipation [ 2 ].To improve the efficiency of WMNs, it has been shown recently that joint design of the network layer and the physical one is necessary[ 3 ], where the network layer determines how to route data packets while the physical layer decides what transmit power levels should be used as also as what beamforming vectors should be adopted [ 4 ].However, most previous works focus either on the network layer or the physical layer separately[ 5 ], ignoring the fact that they interact closely with one another [ 6 ]."
    },
    {
        "original_text": "We present the results of an analysis of high-resolution observations in Hα and Ca II K lines obtained by Hinode/SOT on 2007 May 24, when a large sunspot group was observed at disk center. The main feature is a bright point-like structure (a light bridge) located between two pores. We find that this light bridge has a temperature about 1000K higher than its surroundings. This result suggests that magnetic reconnection may be taking place there. In addition to the light bridge we also observe small-scale structures such as spicules and fibrils which are probably related to the magnetic field configuration around the light bridge. These features can provide important information for understanding the formation mechanism of light bridges. \n \n Keywords: Light bridge, Sunspots, Solar atmosphere, Magnetic fields, Spicule, Fibrils, Reconnection, Hinode, SOT, Hα line, CaII K line",
        "watermark_text": "We present the results of an analysis of high - resolution observations in Hα and Ca II K lines obtained by Hinode / SOT on 2007 Mai 24, when a large sunspot group was observed at disk center.The main feature is a bright point - like structure ( a light bridge ) located between two pores.We find that this light bridge has a temperature about 1000K greater than its surroundings.This result suggests that magnetic reconnection may be taking place there.In addition to the light bridge we also observe small - scale structures such as spicules and fibrils which are likely related to the magnetic field configuration around the light bridge.These features can provide important data for understanding the formation mechanism of light bridges.Keywords : Light bridge, Sunspots, Solar atmosphere, Magnetic fields, Spicule, Fibrils, Reconnection, Hinode, SOT, Hα line, CaII K line"
    },
    {
        "original_text": "We present an analysis of optical and infrared photometric data obtained during the recent (2006-2008) outbursts of the dwarf novae system V2051 Oph, which is one of only three known to have exhibited both superoutbursts and normal outbursts in its lifetime.  We find that the light curve of this object shows many similarities with those observed for other SU UMa-type systems but also some significant differences. In particular we note that there are no clear signs of rebrightening following either the first or second superoutburst; nor do we see any evidence for a double-humped structure in the light curves at all phases of these events. The lack of such features may be due to the fact that our observations were made when the system was relatively faint compared to previous studies. However, it should be noted that the orbital period of V2051 Oph is significantly longer than most other SU UMa stars so that the mass transfer rate will be lower by about a factor of ten.",
        "watermark_text": "We present an analysis of optical and infrared photometric data obtained during the recent ( 2006 - 2008 ) outbursts of the dwarf novae system V2051 Oph, which is one of only three known to have exhibited both superoutbursts and normal outbursts in its lifetime.We find that the light curve of this object shows many similarities with those observed for other SU UMa - type systems but also some significant differences.In particular we note that there are no clear signs of rebrightening following either the first or second superoutburst ; nor do we see any evidence for a double - humped structure in the light curves at all stages of these events.The lack of such features may be due to the fact that our observations were made when the system was relatively faint compared to previous studies.However, it should be noted that the orbital period of V2051 Oph is significantly longer than most other SU UMa stars so that the mass transfer rate will be lower by about a factor of 10."
    },
    {
        "original_text": "We present the first fully self-consistent, atomistic quantum transport calculations for ballistic graphene nanoribbons (GNRs) with realistic band structure and electrostatic potential profiles using nonequilibrium Green's function formalism in combination with density functional theory (DFT). We show that the GNRs' electronic properties are strongly dependent on their widths as well as edge structures. The calculated current-voltage characteristics reveal several interesting features such as negative differential resistance at low bias voltages due to resonant tunneling through localized states near the Fermi level. In addition, we find that the presence of hydrogen passivation layers can significantly enhance the device performance by suppressing the backscattering effect caused by defects or impurities along the edges. \n \n Keywords: Ballistic transport, Graphene nanoribbon, Nonequilibrium Green's functions, Density functional theory, Quantum transport calculation. 1 Introduction \n \n Graphene is an emerging material which has attracted considerable attention recently because it exhibits unique physical properties [1] . It consists of carbon atoms arranged into a honeycomb lattice where each carbon atom forms covalent bonds with three neighboring carbons [2] . Due to its two-dimensional nature, graphene shows high carrier mobility [3] , thermal conductivity [4] , mechanical strength [5] , optical transparency [6] , and flexibility [7] . These remarkable properties make graphene promising candidates for future nanoelectronic devices [8] .\n \nGraphene nanoribbons (G-NR), i.e., strips of graphene with finite width [9] , have been proposed as building blocks for various applications including transistors [10] , interconnects [11] , photodetectors [12] , solar cells [13] , sensors [14] , etc.. Compared to conventional silicon-based electronics [15] , GNRs offer many advantages [16] : they exhibit higher electron mobilities [17] ; they allow better control over the charge carriers [18] ; they provide more design freedom [19] ; and they enable new functionality [20] . However, there still exist some challenges associated with practical realization of GNRs [21] . For example, the fabrication process requires precise control of ribbon width [22] and edge roughness [23] . Moreover, the electrical properties of GNRs depend sensitively",
        "watermark_text": "We present the first fully self - consistent, atomistic quantum transport calculations for ballistic graphene nanoribbons ( GNRs ) with realistic band structure and electricalstatic potential profiles utilizing nonequilibrium Green ' s function formalism in combination with density functional theory ( DFT ).We show that the GNRs ' electronic properties are strongly dependent on their widths as well as edge structures.The calculated current - voltage characteristics reveal several interesting features such as negative differential resistance at low bias voltages owing to resonant tunneling through localized states near the Fermi level.In addition, we find that the presence of hydrogen passivation layers can significantly enhance the device performance by suppressing the backscattering influence caused by faults or impurities along the edges.Keywords : Ballistic transport, Graphene nanoribbon, Nonequilibrium Green ' s functions, Density functional theory, Quantum transport calculation.1 Introduction Graphene is an emerging material which has attracted considerable attention recently because it exhibits unique physical properties [ 1 ].It consists of carbon atoms ordered into a honeycomb lattice where each carbon atom forms covalent bonds with three neighboring carbons[ 2 ].Due to its two - dimensional nature, graphene shows high carrier mobility[ 3 ], thermal conductivity[ 4 ], mechanical strength[ 5 ], optical transparency[ 6 ], and flexibility[ 7 ].These remarkable properties make graphene promising candidates for future nanoelectronic devices [ 8 ].Graphene nanoribbons ( G - NR ), i. e., strips of graphene with finite width[ 9 ], have been proposed as building blocks for various applications including transistors[ 10 ], interconnects [ 11 ], photodetectors[ 12 ], solar cells[ 13 ], sensors [ 14 ], etc.Compared to conventional silicon - based electronics [ 15 ], GNRs offer many advantages[ 16 ] : they exhibit higher electron mobilities [ 17 ] ; they allow better power over the charge carriers [ 18 ] ; they provide more design freedom[ 19 ] ; and they enable new functionality[ 20 ].However, there still exist some challenges associated with practical realization of GNRs [ 21 ].For example, the fabrication process requires exact control of ribbon width[ 22 ] and edge roughness[ 23 ].Moreover, the electrical properties of GNRs depend sensitively"
    },
    {
        "original_text": "We present the results of an unbiased survey for compact HII regions in the southern Galactic plane using data obtained with the Australia Telescope Compact Array (ATCA). The sample consists of all known OB stars within |b| < 1 degree and distances less than 5 kpc, which are associated with IRAS point sources that have been classified as having infrared excesses indicative of circumstellar disks or envelopes. We detect over 100 new compact HII regions at frequencies between 2.1 GHz and 6.0 GHz. These objects range in size from 0.01 pc to 0.5 pc and their luminosities vary by more than four orders of magnitude. Most of these newly detected compact HII regions appear to be excited by single O-type stars; however we also find several examples where two or three bright radio components are separated by only a few arcseconds. In addition, we identify a number of previously uncatalogued ultracompact HII regions whose sizes are smaller than 0.01 pc.",
        "watermark_text": "We present the results of an unbiased survey for compact HII regions in the south Galactic plane using data obtained with the Australian Telescope Compact Array ( ATCA ).The sample consists of all known OB stars inside | b | < one degree and miles less than 5 kpc, which are associated with IRAS point sources that have been classified as having infrared excesses indicative of circumstellar disks or envelopes.We detect over 100 new compact HII regions at frequencies between two. 1 GHz and 6. 0 GHz.These objects range in size from zero. 01 pc to zero. 5 pc and their luminosities vary by more than four orders of magnitude.Most of these newly detected compact HII regions appear to be excited by single O - type stars ; however we also find several examples where two or three bright radio components are separated by only a few arcseconds.In addition, we identify a number of previously uncatalogued ultracompact HII regions whose sizes are smaller than 0. 01 pc."
    },
    {
        "original_text": "We present an analysis of the X-ray properties of a sample of 12 hyper-luminous infrared galaxies (HLIRGs) observed with XMM-Newton, using data obtained in AO-1 and AO-2. The HLIRG sample is selected to have L(8-1000um)>10^12L_sun , where L(8-1000um), is derived by integrating over the best-fit SEDs for each source. We find that all sources are detected at >5 sigma significance in the 0.3-10 keV band; however only two objects show evidence for significant absorption above Galactic levels. For these two absorbed systems we derive column densities NH = 1.7 x 10^23 cm^{-2} and 2.1 x 10^22 cm^{-2} respectively. Using the hardness ratio HR=H-S/H+S, where H and S represent counts in the 3-7keV and 0.3-2keV bands respectively, we find no correlation between HR and either luminosity or redshift. This suggests that there may be little evolution in the intrinsic spectral shape of this population out to z=2.6.",
        "watermark_text": "We present an analysis of the X - ray properties of a sample of 12 hyper - luminous infrared galaxies ( HLIRGs ) observed with XMM - Newton, using data obtained in AO - 1 and AO - 2.The HLIRG sample is selected to have L ( 8 - 1000um ) > 10 ^ 12L _ sun, where L ( 8 - 1000um ), is derived by integrating over the best - fit SEDs for each source.We find that all sources are detected at > 5 sigma importance in the 0. 3 - 10 keV band ; however only two objects show evidence for significant absorption above Galactic levels.For these two absorbed systems we derive column densities NH = 1. 7 × 10 ^ 23 centimeters ^ { - 2 } and two. 1 x 10 ^ 22 cm ^ { - 2 } respectively.Using the hardness ratio HR = H - S / H + S, where H and S represent counts in the 3 - 7keV and 0. 3 - 2keV bands respectively, we find no correlation between HR and either luminosity or redshift.This suggests that there may be little evolution in the intrinsic spectral shape of this population out to z = 2. 6."
    },
    {
        "original_text": "The chemical compositions of the type II Cepheid variables are investigated by using high-resolution spectra obtained with Subaru/HDS, Keck/HIRES, VLT/UVES, and McDonald/DEIMOS spectrographs.  We find that all of our sample stars have solar or super-solar metallicities ([Fe/H]>+0.2). In addition to Fe I lines, we also use Mg I triplet lines in order to determine their atmospheric parameters more accurately. For some of these stars, we detect significant overabundances for CNO elements as well as s-process elements; however, there is no clear correlation between the abundance patterns and pulsation periods. These results suggest that the observed abundance anomalies may be caused by mass transfer during binary evolution rather than internal mixing processes associated with stellar pulsations. This work was supported by JSPS Grant-in-Aid for Scientific Research on Priority Areas No. 16071203.",
        "watermark_text": "The chemical compositions of the type II Cepheid variables are investigated by using high - resolution spectra obtained with Subaru / HDS, Keck / HIRES, VLT / UVES, and McDonald / DEIMOS spectrographs.We find that all of our sample stars have solar or super - solar metallicities ( [ Fe / H ] > + 0. 2 ).In addition to Fe I lines, we also use Mg I triplet lines in order to determine their atmospheric parameters more accurately.For some of these stars, we detect significant overabundances for CNO elements as also as s - procedure elements ; however, there is no clear correlation between the abundance patterns and pulsation periods.These results suggest that the observed abundance anomalies may be caused by mass transport during binary evolutionary rather than internal mixing mechanisms associated with stellar pulsations.This work was supported by JSPS Grant - in - Aid for Science Research on Priority Areas No. 16071203."
    },
    {
        "original_text": "We study the problem of finding an optimal set of points on the unit circle that are equidistant to each other and have minimum angular separation between them, known as the Costas array or Costas configuration.  We show how this problem can be formulated as a convex optimization problem with linear constraints over the space of probability measures supported by the unit circle. This formulation allows us to use tools from convex analysis for solving it efficiently. In particular we provide a polynomial time algorithm which computes an approximate solution within any desired accuracy. The proposed method is based on the Frank-Wolfe (FW) algorithm combined with the Sinkhorn-Knopp scaling technique. Finally, numerical experiments demonstrate the efficiency of our approach compared to existing methods. Keywords: Convex Optimization; Probability Measures; Frank Wolfe Algorithm; Scaling Technique; Unit Circle; Costas Array; Costas Configuration.",
        "watermark_text": "We study the problem of finding an optimal set of points on the unit circle that are equidistant to each other and have minimum angular separation between them, known as the Costas array or Costas configuration.We show how this issue can be formulated as a convex optimization problem with linear limits over the space of probability measures supported by the unit circle.This formulation enables us to use tools from convex analysis for fixing it efficiently.In particular we provide a polynomial time algorithm which computes an approximate solution within any requested accuracy.The proposed method is based on the Frank - Wolfe ( FW ) algorithm combined with the Sinkhorn - Knopp scaling technique.Finally, numerical experiments demonstrate the efficiency of our approach compared to existing methods.Keywords : Convex Optimization ; Probability Measures ; Frank Wolfe Algorithm ; Scaling Technique ; Unit Circle ; Costas Array ; Costas Configuration."
    },
    {
        "original_text": "We present the discovery and analysis of two double neutron stars (DNSs) with masses in excess of 2 M_sun, PSR J0737-3039A/B and PSR B1913+16. The former is an eclipsing system that has been observed to undergo orbital decay at a rate consistent with gravitational wave emission; it will merge within about 3 Myr. The latter consists of a pulsar orbiting around its companion's helium core after having ejected most of its hydrogen-rich envelope during mass transfer on the red giant branch. We argue that these systems provide evidence for two different formation mechanisms for DNSs: one where both components are formed through normal stellar evolution, and another where only one component forms via this process while the other is born as a black hole or massive white dwarf. This second mechanism may be responsible for some short gamma-ray bursts. DOI: 10.1103/PhysRevD.76.084011",
        "watermark_text": "We present the discovery and analysis of two double neutron stars ( DNSs ) with masses in excess of 2 M _ sun, PSR J0737 - 3039A / B and PSR B1913 + 16.The former is an eclipsing system that has been observed to undergo orbital decay at a rate consistent with gravitational wave emission ; it will merge within about three Myr.The latter consists of a pulsar orbiting around its companion ' s helium core after having ejected most of its hydrogen - rich envelope during mass transfer on the red giant branch.We argue that these systems provide evidence for two different forming mechanisms for DNSs : one where both components are formed through normal stellar evolutionary, and another where only 1 component forms via this process while the other is born as a black hole or massive white dwarf.This second mechanism may be responsible for some brief gamma - ray bursts.DOI : 10. 1103 / PhysRevD. 76. 084011"
    },
    {
        "original_text": "We have measured the space velocities for eight globular clusters in the southern hemisphere with galactic latitudes less than 20 degrees, using proper motions and radial velocities obtained by various authors over the past decade or so.  The sample includes four open clusters (NGC 2420 , NGC 2516 , NGC 2682 , and NGC 6705 ) as well as four globulars . We find that all but one cluster are consistent with being at rest relative to the local standard of rest; however, we also find evidence that two of these clusters may be on orbits which will take them out of our galaxy within several billion years .  These results suggest that there is no significant difference between open clusters and globulars when it comes to their kinematics ; both types appear to share similar properties .\nThe only exception appears to be the open cluster M67 , whose velocity vector points away from us toward the constellation Cetus . This result suggests that this open cluster has been ejected from its parent galaxy during an encounter with another galaxy some time ago .",
        "watermark_text": "We have measured the space velocities for eight globular clusters in the south hemisphere with galactic latitudes less than 20 degrees, utilizing proper motions and radial velocities obtained by various authors over the past decade or so.The sample includes 4 open clusters ( NGC 2420, NGC 2516, NGC 2682, and NGC 6705 ) as well as 4 globulars.We find that all but one cluster are consistent with being at rest relative to the local standard of rest ; however, we also find evidence that two of these clusters may be on orbits which will take them out of our galaxy within several billion years.These results suggest that there is no significant difference between open clusters and globulars when it comes to their kinematics ; both kinds appear to share similarly properties.The only exception appears to be the open cluster M67, whose velocity vector points away from We toward the constellation Cetus.This result suggests that this open cluster has been ejected from its parent galaxy during an encounter with different galaxy some time ago."
    },
    {
        "original_text": "We present an exact quantum-mechanical treatment for the dynamics of open systems in which the system is coupled to many harmonic oscillators representing its surrounding environment.  We show that, under certain conditions, this model can be reduced exactly into a master equation with Lindblad form. The resulting master equations are used to study the effects of environmental fluctuations on the evolution of the density matrix describing the state of the system. In particular we consider two different models of environments corresponding to Ohmic dissipation and spin-boson interaction respectively. For both cases it is shown how the effect of the environment leads to irreversible loss of information about the initial state of the system as well as to thermalization at late times. Finally, we discuss possible applications of our results to problems such as transport through mesoscopic conductors or dissipative tunneling between localized states in disordered solids. Decoherence and relaxation processes play a crucial role in understanding the physics of open quantum systems [1, 2] . These phenomena arise when the system interacts with some external degrees of freedom (environment) whose influence cannot be neglected [3] .\nIn recent years there has been considerable interest in developing theoretical methods capable of treating these effects beyond the perturbative regime [4] . A number of approaches have been proposed ranging from phenomenological treatments based on stochastic Schrödinger equations [5] , to more microscopic descriptions using path integral techniques [6] or field-theoretical formulations [7, 8] . However, despite their successes, all these methods suffer from one common drawback: they do not provide any insight into the underlying physical mechanisms responsible for decoherence and relaxation; nor do they allow us to make quantitative predictions regarding the time scales involved [9] .\nRecently, several authors [10 -12] have suggested that the problem may be tackled within the framework of quantum mechanics itself. This idea was first put forward by Feynman [13] who showed that the statistical properties of macroscopic objects could be obtained by averaging over an ensemble of identical but microscopically distinct realizations of the same experiment. More recently, Leggett [14] introduced a method...",
        "watermark_text": "We present an exactly quantum - mechanical treatment for the dynamics of open systems in which the system is coupled to many harmonic oscillators representing its surrounding environmental.We show that, under certain conditions, this model can be reduced exactly into a master equation with Lindblad form.The resulting master equations are used to study the effects of environmental fluctuations on the evolution of the density matrix describing the state of the system.In particular we consider 2 different models of environments corresponding to Ohmic dissipation and spin - boson interaction respectively.For both cases it is shown how the effect of the environmental leads to irreversible loss of information about the initial state of the system as well as to thermalization at late times.Finally, we discuss possible applications of our results to problems such as transfer through mesoscopic conductors or dissipative tunneling between localized states in disordered solids.Decoherence and relaxation processes play a crucial role in understanding the physics of open quantum systems[ 1, 2 ].These phenomena arise when the system interacts with some external degrees of freedom ( environmental ) whose influence cannot be neglected [ 3 ].In recent years there has been considerable interest in developing theoretical methods capable of treating these affects beyond the perturbative regime [ 4 ].A number of approaches have been proposed ranging from phenomenological treatments based on stochastic Schrödinger equations [ 5 ], to more microscopic descriptions using pathway integral methods [ 6 ] or field - theoretical formulations [ 7, 8 ].However, despite their successes, all these methods suffer from 1 common drawback : they do not offer any insight into the underlying physiological mechanisms responsible for decoherence and relaxation ; nor do they allow us to make quantitative predictions regarding the time scales involved [ 9 ].Recently, several authors [ 10 - 12 ] have suggested that the issue may be tackled within the framework of quantum mechanics itself.This idea was originally put forward by Feynman[ 13 ] who showed that the statistical properties of macroscopic objects could be obtained by averaging over an ensemble of identical but microscopically distinct realizations of the same experiment.More recently, Leggett [ 14 ] introduced a method."
    },
    {
        "original_text": "The concept of zero point energy is introduced in this article, which describes how it can be used to explain some aspects of the big bang theory. The author also discusses the possibility that dark matter may have been created by such an effect. Finally he considers whether or not there are any other physical effects associated with zero point energy. In particular, he suggests that gravitational waves could possibly be generated by such processes. This article was originally published on ArXiv.org as part of the author's PhD thesis at Imperial College London. It has since been updated for publication here. Zero point energy (ZPE) is defined as the minimum amount of energy required to create particles out of nothing. Although ZPE cannot actually exist because it violates the laws of physics, it does provide useful insight into certain phenomena observed within our universe. For example, if we consider the expansion of space-time during the early stages of the universe's existence, then it seems reasonable to assume that the volume of space increased exponentially over time due to the rapid release of ZPE. If so, then the total mass-energy density would decrease rapidly until all available ZPE had been released. At this stage, the universe would consist solely of vacuum fluctuations, i.e., virtual particles and antiparticles existing simultaneously but never interacting with each other.",
        "watermark_text": "The concept of zero point energy is introduced in this article, which describes how it can be used to explain some aspects of the big bang theory.The writer also discusses the possibility that dark matter may have been created by such an effect.Finally he considers whether or not there are any other physical effects associated with zero point energy.In particular, he suggests that gravity waves could possibly be generated by such processes.This article was originally published on ArXiv. org as part of the author ' s PhD thesis at Imperial College London.It has since been updated for publication here.Zero point energy ( ZPE ) is defined as the minimum amount of energy required to create particles out of nothing.Although ZPE cannot actually exist because it violates the laws of physics, it does provide useful insight into certain phenomena observed inside our universe.For example, if we consider the expansion of space - time during the early phases of the universe ' s presence, then it seems reasonable to assume that the volume of space increased exponentially over time due to the rapid release of ZPE.If so, then the total mass - energy density would decrease rapidly until all possible ZPE had been released.At this stage, the universe would consist solely of vacuum fluctuations, i. e., virtual particles and antiparticles existing simultaneously but never interacting with each other."
    },
    {
        "original_text": "We present an open-source framework, called Bubblesched, that allows to build portable thread schedulers for hierarchical multiprocessors (HMPs). The main idea is to use bubbles as scheduling units and schedule them on different levels in HMP hierarchy using a set of rules. We have implemented two schedulers: one based on work stealing and another one based on load balancing. Both schedulers are able to run efficiently on top of Bubblesched without any modifications. Our experimental results show that both schedulers outperform state-of-the-art solutions by up to 3Â times when running parallel applications with fine-grained tasks. In addition, we demonstrate how our scheduler can be used to implement efficient task-parallel algorithms such as graph coloring or matrix multiplication. This research was supported by Russian Science Foundation grant 14-50-00040. We present an opensource framework, called Bubblesched: it allows to build portable threadschedulers for hierarchicalmultiprocessors(HMPs)andrunefficientlyonthemwithoutanymodifications.Theframeworkusesbubblesastheschedu-lingsunitsandschedulethemonthelevelsofHMPhierarchyusingasetofrules.Wehaveimplementedtwo-schedulers:onebasedonstealingworkandanotheronesupportedbyloadbalancing.BothschedulersexecutesuccessfullyontopofBubbleschedwithouthavingtobemodified.Ourexperimentalresultsshowthatbothschedulersoutperformstate-oftheartsolutionsupto3timeswhenrunningparallelapplicationswithfinegrainetasks.Inaddition,weillustratethattheframeworkcanbeusedtomakeefficienttask-parallelandalgorithmssuchastask-coloringanoregularmatrixmultiplication.",
        "watermark_text": "We present an open - source framework, called Bubblesched, that permits to build portable thread schedulers for hierarchical multiprocessors ( HMPs ).The main idea is to utilize bubbles as scheduling units and schedule them on different levels in HMP hierarchy utilizing a set of rules.We have implemented two schedulers : one based on work stealing and another one based on load balancing.Both schedulers are able to run efficiently on top of Bubblesched without any modifications.Our experimental results show that both schedulers outperform state - of - the - art solutions by up to threeÂ times when running parallel applications with fine - grained tasks.In addition, we demonstrate how our scheduler can be used to implement efficient task - parallel algorithms such as graph coloring or matrix multiplication.This research was supported by Russian Science Federation grant 14 - 50 - 00040.We present an opensource framework, called Bubblesched : it allows to build portable threadschedulers for hierarchicalmultiprocessors ( HMPs ) andrunefficientlyonthemwithoutanymodifications.Theframeworkusesbubblesastheschedu - lingsunitsandschedulethemonthelevelsofHMPhierarchyusingasetofrules.Wehaveimplementedtwo - schedulers : 1basedonstealingworkandanotheronesupportedbyloadbalancing.BothschedulersexecutesuccessfullyontopofBubbleschedwithouthavingtobemodified.Ourexperimentalresultsshowthatbothschedulersoutperformstate - oftheartsolutionsupto3timeswhenrunningparallelapplicationswithfinegrainetasks.Inaddition, weillustratethattheframeworkcanbeusedtomakeefficienttask - parallelandalgorithmssuchastask - coloringanoregularmatrixmultiplication."
    },
    {
        "original_text": "We report on observations made by the High Energy Stereoscopic System (H.E.S. S.) telescope array in Namibia, which detected very-high-energy (VHE) gamma rays from the distant blazar  1ES1102-232 at redshift z = 0.186. The source was observed for more than 50 hours between September 2005 and March 2006 using data taken simultaneously with four telescopes. A total excess of 12 events above background were found within an energy range of 400 GeV to 20 TeV. No significant variability is seen during this period. We present results from spectral analysis performed over different time intervals as well as broadband modelling of the multi-wavelength spectrum including radio through X-ray measurements. This work demonstrates that H.E.S.  S. can detect sources beyond redshifts previously accessible only to ground-based Cherenkov telescopes. It also shows how such observations are important for understanding the physics of these extreme objects.",
        "watermark_text": "We report on observations made by the High Energy Stereoscopic System ( H. E. S. S. ) telescope array in Namibia, which detected very - high - energy ( VHE ) gamma rays from the distant blazar 1ES1102 - 232 at redshift z = 0. 186.The source was observed for more than 50 hours between Sept 2005 and March 2006 using data taken simultaneously with 4 telescopes.A total excess of 12 events above background were found within an energy range of 400 GeV to 20 TeV. No significant variability is seen during this period.We present results from spectral analysis performed over different time intervals as also as broadband modelling of the multiple - wavelength spectrum including radio through X - ray observations.This work demonstrates that H. E. S. S. can detect sources beyond redshifts formerly accessible only to ground - based Cherenkov telescopes.It also shows how such observations are important for understanding the physics of these extreme objects."
    },
    {
        "original_text": "We present an analysis of the logarithmic corrections to the leading order predictions for the electromagnetic form factor ratios, R = F2(q2)/F1(q2), and their dependence on the momentum transfer q2. We use the results obtained within the framework of the multipole expansion method (MEM). The MEM is based on the assumption that the proton can be represented as a superposition of three different charge distributions with definite angular momenta. In this approach we calculate the contributions coming from the lowest lying resonances, i.e., S11(1650), P11(1710), D13(1520), F15(1680), G17(1880), H19(2230), and also take into account the effects due to the pion cloud surrounding these states. Our numerical calculations show that at low values of the momentum transfer, q2 < 1 GeV 2 , the contribution of the higher-order terms becomes significant.",
        "watermark_text": "We present an analysis of the logarithmic corrections to the leading order predictions for the electromagnetic form factor ratios, R = F2 ( q2 ) / F1 ( q2 ), and their dependence on the momentum transport q2.We use the outcomes obtained within the framework of the multipole expansion method ( MEM ).The MEM is based on the assumption that the proton can be represented as a superposition of 3 different charge distributions with definite angular momenta.In this approach we calculate the contributions coming from the least lying resonances, i. e., S11 ( 1650 ), P11 ( 1710 ), D13 ( 1520 ), F15 ( 1680 ), G17 ( 1880 ), H19 ( 2230 ), and also take into account the effects due to the pion cloud surrounding these states.Our numerical calculations show that at low values of the momentum transfer, q2 < 1 GeV 2, the contribution of the higher - order terms becomes significant."
    },
    {
        "original_text": "The question is not new, but it has been recently revived by the publication of two papers in Nature and Science that claim to show that biodiversity loss leads to ecosystem collapse.  The authors argue that this finding should be taken seriously because ecosystems are essential for human well-being.   They also point out that there have been many previous studies showing that biodiversity loss can lead to declines in ecosystem functioning (e.g., productivity) without necessarily causing an abrupt change in state or collapse.    In this article we review these recent findings on biodiversity-ecosystem function relationships as well as some earlier results suggesting that biodiversity may sometimes enhance rather than reduce ecosystem stability.  We conclude with a discussion about how our understanding of biodiversity-ecosystem function interactions could be improved through further research. Biodiversity loss is one of humanity's greatest challenges today. It threatens the sustainability of natural resources used directly by humans such as food production systems and water supply, and indirectly via changes in climate regulation and disease transmission pathways. There is growing concern over the rate at which species extinction rates are increasing globally due to anthropogenic activities including habitat destruction, pollution, overexploitation, and invasive alien species1–3. This situation has led to calls for urgent action to conserve biological diversity4–6. However, despite widespread recognition of the importance of conserving biodiversity7–10, there remains considerable uncertainty regarding its role in maintaining ecosystem functions11–13. A number of theoretical models suggest that biodiversity loss will cause reductions in ecosystem functioning14–16. For example, Tilman et al. (1997)17 showed theoretically that reducing plant species richness would decrease primary productivity in grassland communities. Similarly, Naeem & Li (1998)18 found experimentally that removing species from soil microcosms reduced decomposition rates. These predictions were supported by numerous subsequent empirical studies19–22.",
        "watermark_text": "The question is not new, but it has been recently revived by the publication of two papers in Nature and Scientist that claim to show that diversity loss leads to ecosystem collapse.The writers argue that this discovery should be taken seriously because ecosystems are essential for human well - being.They also point out that there have been many previous studies demonstrating that biodiversity loss can lead to declines in ecosystem functioning ( e. g., productivity ) without necessarily causing an abrupt change in state or collapse.In this article we review these recent findings on biodiversity - ecosystem function relationships as also as some earlier results suggesting that ecosystem may sometimes enhance instead than reduce ecosystem stability.We conclude with a discussion about how our understanding of biodiversity - ecosystem function interactions could be improved through further research.Biodiversity loss is one of humanity ' s greatest challenges today.It threatens the sustainability of natural resources used direct by humans such as food producing systems and water supply, and indirectly via changes in climate regulation and disease transmission pathways.There is growing concern over the rate at which species extinction levels are increasing globally owing to anthropogenic activities including habitat destruction, pollution, overexploitation, and invasive alien species1 – 3.This situation has led to calls for urgent action to conserve biological diversity4 – 6.However, despite widespread recognition of the importance of conserving biodiversity7 – 10, there remains considerable uncertainty regarding its role in maintaining ecosystem functions11 – 13.A number of theoretical models suggest that biodiversity loss will cause reductions in ecosystem functioning14 – 2016.For example, Tilman et al. ( 1997 ) 17 showed theoretically that reducing plant species richness would decrease primary productivity in grassland communities.Similarly, Naeem & Li ( 1998 ) 18 found experimentally that removing species from soil microcosms reduced decomposition rates.These predictions were supported by numerous later empirical studies19 – 22."
    },
    {
        "original_text": "We study the orbital evolution and stability properties of oligarchic co-orbitals in the Solar System, i.e., bodies with masses comparable to that of Jupiter which are trapped on orbits close to those of Neptune or Uranus for billions of years.  We show how these objects can be identified by their long-term dynamical behavior as well as by their current positions relative to Neptune's orbit. The existence of such bodies is confirmed by numerical integrations over timescales up to 10 billion years using the symplectic N-body code SyMBA. In addition we find that there exist at least two other stable regions where oligarchs may reside. These results suggest that the Solar System contains several dozen oligarchic co-orbitals:  - At least four known trans-Neptunian objects (Pluto, Charon, Haumea, Makemake) have been found to exhibit this type of dynamics; - There exists another region around 30 AU containing three additional bodies (Sedna, 2000 CR 105 , 2003 SQ 317 ); - Finally, our simulations indicate that there might also be an additional group of oligarchs located between 50-60 AU.",
        "watermark_text": "We study the orbital evolution and stability properties of oligarchic co - orbitals in the Solar System, i. e., bodies with masses comparable to that of Jupiter which are trapped on orbits close to those of Neptune or Uranus for billions of years.We show how these objects can be identified by their long - term dynamical behaviour as well as by their present positions relative to Neptune ' s orbit.The existence of such bodies is confirmed by numerical integrations over timescales up to 10 billion years using the symplectic N - body code SyMBA.In addition we find that there exist at minimum two other stable regions where oligarchs may reside.These results suggest that the Solar System contains several dozen oligarchic co - orbitals : - At least four known trans - Neptunian objects ( Pluto, Charon, Haumea, Makemake ) have been found to exhibit this type of dynamics ; - There exists another region around 30 AU containing three additional bodies ( Sedna, 2000 CR 105, 2003 SQ 317 ) ; - Finally, our simulations indicate that there might also be an additional group of oligarchs located between 50 - 60 AU."
    },
    {
        "original_text": "We study the production of a sterile species in an open system with two stable particles and one unstable particle, where the decay products are not observed.  We show that if the initial state is pure then there exists no final mixed state which can be reached by unitary evolution. This result implies that the production of a sterility cannot occur under any circumstances for such systems. If we allow the possibility to prepare arbitrary states as input, however, it turns out that the production of a certain kind of sterility may still take place. In this case, the output state will always contain some amount of entanglement between the subsystems corresponding to the different types of particles involved. The results presented here have been obtained within the framework of Quantum Kinetic Theory (QKT). QKT provides a description of non-equilibrium phenomena at mesoscopic scales based on the concept of entropy production rate. It has recently attracted considerable attention due to its potential applications in many areas ranging from physics to biology. \nI. INTRODUCTORY REMARK\nThe phenomenon of spontaneous emission plays a crucial role in modern physics. For example, it is responsible for the cooling process in laser-cooling experiments [1] . On the other hand, spontaneous emission also leads to decoherence effects [2] , which limit the performance of quantum information processing devices [3] .\nIn recent years, several authors [4] - [8] studied the problem of producing a particular type of \"sterility\" in open quantum systems. A state is called \"sterile\" when it does not interact with itself or another given set of states [9] . More specifically, let us consider a bipartite Hilbert space H = H 1 ⊗H 2 , where dim(H i ) = N i . Then, a density matrix ρ ∈ B(H) is said to be \"sterile\" wrt. a subset S ⊆ H iff Tr[ρσ] = 0 for all σ ∈ S. Here, Tr denotes the trace operation over either H 1 or H 2 depending on whether σ belongs to H 1 or H 2 respectively. Note that the notion of \"ster",
        "watermark_text": "We study the production of a sterile species in an open system with 2 stable particles and one unstable one, where the decay products are not observed.We show that if the first state is pure then there exists no last mixed one which can be reached by unitary evolution.This result implies that the production of a sterility cannot occur under any circumstances for such systems.If we allow the possibility to prepare arbitrary states as input, however, it turns out that the production of a certain kind of sterility might still take place.In this case, the output state will always include some amount of entanglement between the subsystems corresponding to the different types of particles involved.The results presented here have been obtained within the framework of Quantum Kinetic Theory ( QKT ).QKT provides a description of non - equilibrium phenomena at mesoscopic scales based on the concept of entropy production rate.It has recently attracted considerable attention due to its potential applications in many areas ranging from physics to biology.I. INTRODUCTORY REMARKThe phenomenon of spontaneous emission plays a crucial role in modern physics.For example, it is responsible for the cooling procedure in laser - cooling experiments [ 1 ].On the other hand, spontaneous emission also leads to decoherence effects [ 2 ], which limit the performance of quantum information processing devices [ 3 ].In recent years, several authors [ 4 ] - [ 8 ] studied the problem of generating a particular type of \" sterility \" in open quantum systems.A state is called \" sterile \" when it does not interact with itself or others given set of states [ 9 ].More specifically, let us consider a bipartite Hilbert space H = H 1 [UNK] 2, where dim ( H i )= Ni.Then, a density matrix ρ ∈ B ( H ) is said to be \" sterile \" wrt.a subset S ⊆ H iff Tr [ ρσ ] = 0 for all σ ∈ S. Here, Tr denotes the trace operation over either H 1 or HC 2 depending on whether σ belongs to H 1 or H 2 respectively.Note that the notion of \" ster"
    },
    {
        "original_text": "We report on the detection and characterization of a massive galaxy cluster, Abell S1063 (z = 0.90), using data obtained with the Wide Field Camera 3 (WFC3) aboard Hubble Space Telescope (HST). The cluster was discovered as part of an ongoing survey for distant clusters carried out by our team within the framework of the UKIRT Infrared Deep Sky Survey Data Release 8 (UKIDSS DR8). We use photometric redshifts to select galaxies that are likely members of this structure over a large area around its center. Using these candidates we identify two brightest cluster galaxies (BCGs) separated by about 1 arcmin along the line-of-sight. These BCGs have magnitudes mF160B = 20.6 ± 0.1 mag and mF140W = 21.0 ± 0.2 mag respectively. Their colors suggest they are both early-type galaxies.",
        "watermark_text": "We report on the detection and characterization of a massive galaxy cluster, Abell S1063 ( z = 0. 90 ), using data obtained with the Wide Field Camera 3 ( WFC3 ) upon Hubble Space Telescope ( HST ).The cluster was discovered as part of an ongoing survey for remote clusters carried out by our team within the frame of the UKIRT Infrared Deep Sky Survey Data Release 8 ( UKIDSS DR8 ).We use photometric redshifts to select galaxies that are probably members of this structure over a large region around its center.Using these candidates we identify two brightest cluster galaxies ( BCGs ) separated by about one arcmin along the line - of - sight.These BCGs have magnitudes mF160B = 20. 6 ± 0. 1 mag and mF140W = 21. 0 ± 0. 2 mag respectively.Their colors suggest they are both early - type galaxies."
    },
    {
        "original_text": "We present an update on our previous work (Jarosik et al., 2006) where we used Bayesian methods to analyze the polarization data obtained by Wilkinson Microwave Anisotropy Probe (WMAP). We use the same likelihood function as in Jarosik et al. (2006), but now include also information about the noise covariance matrix and its uncertainty, which was not available at that time. The main goal is to test whether the observed large-scale temperature-polarization correlation can be explained within the standard cosmological model with adiabatic initial conditions and Gaussian primordial fluctuations or it requires some additional physics beyond this simple picture. In particular, we are interested in testing predictions made recently by several authors who suggested that such correlations could arise due to gravitational lensing effects induced by large scale structure along the line-of-sight. Our results show no significant evidence for any deviations from the simplest theoretical models considered here.",
        "watermark_text": "We present an update on our prior work ( Jarosik et al., 2006 ) where we used Bayesian methods to analyze the polarization data obtained by Wilkinson Microwave Anisotropy Probe ( WMAP ).We use the same likelihood function as in Jarosik et al. ( 2006 ), but now include also information about the noisy covariance matrix and its uncertainty, which was not available at that time.The main goal is to test whether the recorded large - scale temperature - polarization correlation can be understood within the standard cosmological model with adiabatic initial conditions and Gaussian primordial fluctuations or it needs some additional physics beyond this simple picture.In particular, we are interested in checking predictions made recently by several authors who suggested that such correlations could arise owing to gravitational lensing influences induced by large scale structure along the line - of - sight.Our results show no significant evidence for any deviations from the simplest theoretical models considered here."
    },
    {
        "original_text": "We study the encoding problem for iterated function systems (IFS) on solenoids by unitary representations of wavelet groups, which are infinite-dimensional Lie groups generated by affine transformations of the real line. We show that if an IFS satisfies certain conditions then it can be encoded into a unitary representation of its associated wavelet group. This result is applied to prove that every self-similar fractal set with finite local complexity has a unique invariant measure up to scaling factors. The proof relies on the fact that any such fractal set can be approximated by a sequence of compact sets whose boundaries have zero Lebesgue measures. In particular, we obtain a new characterization of self-affine carpets as those fractals satisfying this condition. Finally, we give examples showing how our results apply to some well-known fractals including Sierpinski gasket, Koch snowflake, von Koch curve, and Menger sponge.",
        "watermark_text": "We study the encoding problem for iterated function systems ( IFS ) on solenoids by unitary representations of wavelet groups, which are infinite - dimensional Lie groups generated by affine transformations of the real line.We show that if an IFS satisfies certain conditions then it can be encoded into a unitary representation of its associated wavelet group.This result is applied to prove that every self - similar fractal set with finite local complexity has a unique invariant measure up to scaling factors.The proof relies on the fact that any such fractal set can be approximated by a sequence of compact sets whose boundaries have 0 Lebesgue measures.In particular, we obtain a novel characterization of self - affine carpets as those fractals fulfilling this condition.Finally, we give examples showing how our outcomes apply to some well - known fractals including Sierpinski gasket, Koch snowflake, von Koch curve, and Menger sponge."
    },
    {
        "original_text": "We study the vulnerability of interdependent networks under cascading failures, where nodes are subject to random attacks and their neighbors can fail as well due to loss of connectivity. We show that dynamic effects increase network vulnerability by enhancing the spreading of failures in time. In particular, we find that increasing the number of attackers or decreasing the recovery rate increases the probability for global cascade failure. Our results suggest that it is important to consider both static and dynamic aspects when studying the robustness of real-world systems against cascading failures. Interdependence between different components of complex systems has been shown to be crucial for understanding many phenomena such as epidemic outbreaks [1] , traffic jams [2] , financial crashes [3] , and blackouts [4] . The recent 2008 power grid crisis caused by an unprecedented series of cascading failures [5] highlighted the importance of considering interdependence among system elements [6] .\nIn this work, we focus on interdependent networks [7, 8] , which consist of two types of nodes: source (S) and target (T). Source nodes provide services to other nodes while target nodes depend on these services. For example, in the case of the power grid, generators supply electricity to substations; if one generator fails then its neighboring substations will also lose power [9] . Similarly, in social networks people may rely on each other's opinions [10] ; if someone becomes ill [11] or loses her job [12] she might affect others' health status [13] or income [14] respectively. Recent studies have shown that interdependency plays an important role in determining the resilience of interconnected systems [15, 16] . However, most previous works focused only on static properties [17] , i.e., they assumed that all links remain stable over time [18] . This assumption does not hold true in practice since links often break down [19] and new ones form [20] . Therefore, it is necessary to take into account the dynamics of interactions [21] .",
        "watermark_text": "We study the vulnerability of interdependent networks under cascading failures, where nodes are subject to randomly attacks and their neighbors can fail as much due to loss of connectivity.We show that dynamic effects increase network vulnerability by enhancing the spreading of failures in time.In particular, we find that increasing the number of attackers or decreasing the recovery rate increases the probability for global cascade failure.Our results suggest that it is important to consider both static and active aspects when studying the robustness of real - world systems against cascading failures.Interdependence between different components of complex systems has been shown to be crucial for explaining many phenomena such as epidemic outbreaks [ 1 ], traffic jams [ two ], finance crashes [ three ], and blackouts [ four ].The recent 2008 power grid crisis caused by an unprecedented series of cascading failures [ 5 ] highlighted the importance of consideration interdependence amongst system elements [ 6 ].In this work, we focus on interdependent networks [ 7, 8 ], which consist of 2 types of nodes : source ( S ) and target ( T ).Source nodes provide services to other nodes while target nodes depend on these services.For example, in the case of the power grid, generators supply electricity to substations ; if 1 generator fails then its neighboring substations will also lose power [ 9 ].Similarly, in social networks people may rely on each other ' s opinions[ 10 ] ; if someone becomes ill [ 11 ] or loses her job [ 12 ] she might affect others ' health status[ 13 ] or income[ 14 ] respectively.Recent studies have shown that interdependency plays an key role in determining the resilience of interconnected systems[ 15, 16 ].However, most previous works focused only on static properties [ 17 ], i. e., they assumed that all links remain stable over time [ 18 ].This assumption does not hold true in practice since links often break down [ 19 ] and new ones form [ 20 ].Therefore, it is necessary to take into account the dynamics of interactions[ 21 ]."
    },
    {
        "original_text": "We present multiwavelength observations for a sample of X-ray selected star forming galaxies (SFGs) in the Chandra Deep Field-South (CDF-S). The sample consists of 16 SFGs with spectroscopic redshifts between 1 and 3, which were detected by both the soft-band (0.5-2 keV) and hard-band (2-8 keV) surveys conducted by the Advanced CCD Imaging Spectrometer on board XMM-Newton. We have obtained optical spectroscopy using the Keck telescope to measure their stellar masses and SFRs as well as near-infrared photometry taken with the Infrared Array Camera aboard Spitzer Space Telescope to estimate dust extinction. Our results show that these SFGs are massive systems with M* = 1013 -1014M⊙ at z ~ 2 -3. They also exhibit high specific star-formation rates ranging from 10^(-3) yr-1 to 10^(1) yr-1, indicating intense ongoing star formation activity.",
        "watermark_text": "We present multiwavelength observations for a sample of X - ray selected star forming galaxies ( SFGs ) in the Chandra Deep Field - South ( CDF - S ).The sample consists of 16 SFGs with spectroscopic redshifts between 1 and 3, which were detected by both the soft - band ( zero. 5 - 2 keV ) and hard - band ( 2 - 8 keV ) surveys conducted by the Advanced CCD Imaging Spectrometer on board XMM - Newton.We have obtained optical spectroscopy using the Keck telescope to measure their star masses and SFRs as well as near - infrared photometry taken with the Infrared Array Camera aboard Spitzer Space Telescope to estimate dust extinction.Our results show that these SFGs are massive systems with M * = 1013 - [UNK] at z ~ 2 - 3.They also exhibit high specific star - formation rates ranging from 10 ^ ( - 3 ) yr - 1 to 10 ^ ( 1 ) yr - 1, indicating intense ongoing star formation activity."
    },
    {
        "original_text": "We present an analysis of the mass-metallicity relation (MMR) in galaxies, using data from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7). We use two different methods to estimate galaxy masses -the stellar-mass-to-light ratio method and the dynamical mass method-which are both calibrated against direct measurements of galaxy masses obtained by gravitational lensing. The MMR is found to be well described by a power law with index -0.25 ± 0.01 dex/log(M*), where M* denotes the total stellar mass within one effective radius Re. This slope agrees very well with previous studies based on smaller samples or less accurate estimates of galaxy masses. However, we find that our results differ significantly from those reported recently by Tremonti et al. (2004) , who claim a shallower slope of -0.16 ± 0.02 dex/log(M*) (a factor of 2 difference at high masses).\nThe origin of this discrepancy can be traced back to differences between the sample selection criteria used in these works. In particular, Tremonti et al. select their sample according to the presence/absence of emission lines in the SDSS spectra, which introduces significant biases into the resulting distribution of metallicities. Our results show no evidence for such biases: when restricting ourselves to only star-forming galaxies, as done by Tremonti et",
        "watermark_text": "We present an analysis of the mass - metallicity relation ( MMR ) in galaxies, using data from the Sloan Digital Sky Survey Data Release 7 ( SDSS DR7 ).We utilize two separate methods to estimate galaxy masses - the stellar - mass - to - light ratio method and the dynamical mass method - which are both calibrated against directly measurements of galaxy masses obtained by gravity lensing.The MMR is found to be well described by a power law with index - zero. 25 ± zero. 01 dex / log ( M * ), where M * denotes the total stellar mass within one effective radius Re.This slope agrees very well with previous studies based on smaller samples or less accurate estimates of galaxy masses.However, we find that our results differ significantly from those published recently by Tremonti et al. ( 2004 ), who assert a shallower slope of - 0. 16 ± 0. 02 dex / log ( MI * ) ( a factor of two difference at high masses ).The origin of this discrepancy can be traced back to differences between the sample selection criteria used in these works.In particular, Tremonti et al. select their specimen according to the presence / absence of emission lines in the SDSS spectra, which introduces significant biases into the ensuing distribution of metallicities.Our results show no evidence for such biases : when restricting ourselves to only star - forming galaxies, as done by Tremonti et"
    },
    {
        "original_text": "We present the results of our numerical simulations of magnetorotational collapse (MRC) in primordial stars with initial masses between 100 and 1000 M⊙, which are formed at redshifts z = 20 − 30. We find that for all models considered here, magnetic fields play an important role during the formation process of black holes. The final mass of the central object is determined by the strength of the magnetic field. For weak magnetic fields (B < 10^10 G), we obtain stellar-mass black holes; while for stronger fields (B > 10^{10}G), supermassive black holes form. In addition to this effect on the final mass, magnetic fields also affect the angular momentum distribution inside the collapsing star. This leads to different spin parameters of the resulting black hole depending on its progenitor's initial mass. \n \n Keywords: Black Hole, Primordial Star Formation, Magnetohydrodynamics",
        "watermark_text": "We present the results of our numerical simulations of magnetorotational collapse ( MRC ) in primordial stars with initial masses between 100 and 1000 [UNK], which are formed at redshifts z = 20 − 30.We find that for all models considered here, magnetic fields play an important role during the formation process of black holes.The final mass of the central object is determined by the strength of the magnetic field.For weak magnetic fields ( B 10 ^ { 10 } G ), supermassive black holes form.In addition to this effect on the final mass, magnetic fields also effect the angular momentum spread inside the collapsing star.This leads to different spin parameters of the resulting dark hole depending on its progenitor ' s initial mass.Keywords : Black Hole, Primordial Star Formation, Magnetohydrodynamics"
    },
    {
        "original_text": "We study the possibility that black holes can be retained in binary systems by gravitational radiation reaction even if their initial velocities are very large, and we find that this is possible for certain ranges of parameters.  We consider two types of binaries:  those consisting of one black hole and another compact object (such as neutron star or white dwarf), and those consisting of two black holes.   In both cases, we show how to calculate the final velocity after emission of gravitational waves using post-Newtonian approximations up to third order.  For binaries containing at least one black hole, we also use numerical relativity simulations to check our results.  Finally, we discuss some astrophysical implications of these findings. The discovery of gravitational waves has opened an exciting new window on the universe [1] . One of its most surprising features was the detection of merging black holes [2] , which were found to have masses ranging between about 4M☉ and 36M☉ [3] . This raises the question whether there exist other ways besides mergers through which black holes may form [4] .\nIn particular, it would be interesting to know what happens when a black hole moves into a binary system composed of either another black hole or a nonblack-hole companion [5] . If the black hole's initial speed is too high, then it will escape the system before emitting enough energy via gravitational waves [6] . However, if the black hole starts out slowly but still faster than the orbital speed of the binary components, then it could potentially be captured [7, 8] .  Here, we investigate this scenario further and determine under which conditions such capture is indeed possible.",
        "watermark_text": "We study the possibility that black holes can be retained in binary systems by gravity radiation reaction even if their initial velocities are very large, and we find that this is possible for particular ranges of parameters.We consider 2 types of binaries : those consisting of 1 black hole and another compact object ( such as neutron star or white dwarf ), and those consisting of 2 black holes.In both cases, we demonstrate how to calculate the ultimate velocity after emission of gravity waves utilizing post - Newtonian approximations up to 3rd order.For binaries containing at least one black hole, we also utilize numerical relativity simulations to check our results.Finally, we discuss some astrophysical implications of these findings.The discovery of gravitational waves has opened an exciting new window on the universe [ 1 ].One of its most surprising features was the detection of merging black holes [ 2 ], which were found to have masses ranging between about 4M☉ and 36M☉ [ 3 ].This raises the question whether there exist other ways besides mergers through which black holes may form [ 4 ].In particular, it would be interesting to know what occurs when a black hole moves into a binary system composed of either another black hole or a nonblack - hole partner [ 5 ].If the black hole ' s initial speed is too high, then it will avoid the system before emitting enough energy via gravitational waves [ 6 ].However, if the black hole starts out slowly but yet faster than the orbital speed of the binary components, then it could potentially be captured [ 7, 8 ].Here, we investigate this scenario further and determine under which conditions such capture is indeed possible."
    },
    {
        "original_text": "We present the results of cosmological simulations that follow the growth of supermassive black holes (SMBHs) by stochastic gas inflow, including radiative feedback effects on their surroundings. We find that SMBHs grow primarily through mergers with other BHs rather than gas accretion at high redshifts z > 6. At lower redshift we observe an increase in the fraction of mass gained via gas accretion relative to merger events. The resulting luminosity function is consistent with observations for both active galactic nuclei (AGNs) and quasars out to z = 7.5. Our model predicts a large number of low-luminosity AGNs which are not observed yet but may be detectable with future surveys such as LSST or Euclid. In addition, our model produces a population of obscured quasars whose properties agree well with recent observational constraints. Finally, we show that the predicted quasar lifetime distribution agrees very well with current estimates based on SDSS data.",
        "watermark_text": "We present the results of cosmological simulations that follow the growth of supermassive black holes ( SMBHs ) by stochastic gas inflow, including radiative feedback effects on their surroundings.We find that SMBHs grow primarily through mergers with other BHs rather than gas accretion at highly redshifts z > 6.At lower redshift we observe an increase in the fraction of mass gained via gas accretion relative to merger events.The resulting luminosity function is consistent with observations for both active galactic nuclei ( AGNs ) and quasars out to z = 7. 5.Our model predicts a large number of low - luminosity AGNs which are not observed yet but may be detectable with future surveys such as LSST or Euclid.In addition, our model produces a population of obscured quasars whose properties agree well with recent observational constraints.Finally, we show that the predicted quasar life distribution agrees very well with present estimates based on SDSS data."
    },
    {
        "original_text": "We study the decay modes of neutrinos into unparticles, as well as their elastic scattering off electrons mediated by virtual unparticles. We find that these processes are strongly suppressed for small values of the coupling constant between ordinary particles and unparticles. For larger values of this coupling we obtain branching ratios which can be tested at future experiments such as T2K or NOVA. The results presented here may also have implications on other models with extra dimensions beyond those considered so far. \n \n Introduction \n \n In recent years there has been an increasing interest in theories where new physics is described by fields whose excitations do not carry standard model (SM) charges [1] . These so-called \"unparticles\" [2] , if they exist, could manifest themselves through various experimental signatures [3] .\n \nIn particular, it was shown [4] that decays of SM particles to pairs of unparticles would lead to deviations from the expected exponential behavior of the corresponding lifetimes. This effect should be observable experimentally [5] . Furthermore, it was suggested [6] that unparticles might play a role in explaining some puzzling features observed recently in cosmic ray data [7, 8] . \n \n Another interesting possibility is that unparticles couple directly to SM fermions [9] . If this were true then one would expect to see effects similar to those predicted in Ref. [10] for Kaluza-Klein gravitons coupled to leptons. Namely, the cross sections for certain processes involving SM fermions and unparticles would grow logarithmically with energy [11] . Such logarithmic growths have indeed been found [12] - [14] in several cases including e+e-→e+e-U, U→eν, and U→μτ. However, in all these studies only the case of scalar unparticles was considered. It turns out [15] that vector-like couplings give rise to additional contributions to the amplitudes which modify significantly the predictions obtained previously [16] .",
        "watermark_text": "We study the decay modes of neutrinos into unparticles, as well as their elastic scattering off electrons mediated by virtual unparticles.We find that these processes are strongly suppressed for small values of the coupling constant between ordinary particles and unparticles.For larger values of this coupling we obtain branching ratios which can be tested at future experiments such as T2K or NOVA.The results presented here might also have implications on other models with extra dimensions beyond those considered so long.Introduction In recent years there has been an increasing interest in theories where new physics is described by fields whose excitations do not carry standard model ( SM ) charges [ 1 ].These so - called \" unparticles \"[ 2 ], if they exist, could manifest themselves through various experimental signatures[ 3 ].In particular, it was shown [ 4 ] that decays of SM particles to pairs of unparticles would lead to deviations from the expected exponential behaviour of the corresponding lifetimes.This effect should be observable experimentally[ 5 ].Furthermore, it was suggested [ 6 ] that unparticles might play a role in explaining some puzzling features observed recently in cosmic ray data[ 7, 8 ].Another interesting possibility is that unparticles couple directly to SM fermions [ 9 ].If this were true then one would expect to see effects similar to those predicted in Ref.[ 10 ] for Kaluza - Klein gravitons coupled to leptons.Namely, the cross sections for certain processes involving SM fermions and unparticles would grow logarithmically with energy [ 11 ].Such logarithmic growths have indeed been found [ 12 ] -[ 14 ] in several cases including e + e - →e + e - U, U→eν, and U→μτ.However, in all these studies only the case of scalar nonparticles was considered.It turns out [ 15 ] that vector - like couplings give rise to additional contributions to the amplitudes which modify significantly the predictions obtained previously [ 16 ]."
    },
    {
        "original_text": "The inter-hourly-variability index is proposed to measure geomagnetic activity on hourly basis, which can be used as an indicator for solar wind speed variation over time scales longer than one day.  The IHV index was calculated using hourly values of Kp index during the period 1957-2009. It shows that there are two peaks at about 1965-1970 and 1990-1995 . A linear regression analysis between the IHV index and solar wind speed data obtained by spacecraft observations reveals that they have good correlation with each other. This suggests that the IHV index may provide useful information for long-term prediction of solar wind speed. Keywords: Geomagnetism; Solar wind; Variability index; Prediction modeling; Data mining. 1 Introduction Space weather has been attracting more attention recently because it affects many aspects of human life such as satellite communications, aviation safety, power grids etc. (e.g., [1] ). In particular, solar wind plays important roles in space weather since it carries away magnetic fluxes generated by the Sun's dynamo action [2] , and thus controls the Earth's magnetosphere [3] .\nSolar wind is driven out from the Sun by coronal mass ejections [4] . Coronal mass ejections occur when huge amounts of plasma suddenly escape from the Sun into space [5] . They usually last several hours [6] . Therefore, solar wind speed varies significantly within 24 h [7, 8] . However, most previous studies only focus on the average solar wind speed or daily averaged solar wind speed [9] . As a result, little work has been done on investigating how solar wind speed changes on shorter timescales [10] .",
        "watermark_text": "The inter - hourly - variability index is proposed to measure geomagnetic activity on hourly basis, which can be used as an indicator for solar wind speed variation over time scales longer than one day.The IHV index was calculated using hourly values of Kp index during the period 1957 - 09.It shows that there are 2 peaks at about 1965 - 70 and 1990 - 1995.A linear regression analysis between the IHV index and solar wind speed data obtained by spacecraft observations reveals that they have well correlation with each other.This suggests that the IHV index might provide helpful information for long - term prediction of solar wind speed.Keywords : Geomagnetism ; Solar wind ; Variability index ; Prediction modeling ; Data mining.1 Introduction Space weather has been attracting more attention recently because it affects many aspects of human life such as satellite telecommunications, aviation safety, power grids etc.( e. g., [ 1 ] ).In particular, solar wind plays important roles in space weather given it carries away magnetic fluxes generated by the Sun ' s dynamo activity [ 2 ], and thus controls the Earth ' s magnetosphere [ 3 ].Solar wind is driven out from the Sun by coronal mass ejections [ 4 ].Coronal mass ejections occur when huge amounts of plasma suddenly escape from the Sun into space[ 5 ].They usually last several hours [ 6 ].Therefore, solar wind speed varies significantly within 24 h [ 7, 8 ].However, most previous studies only focus on the average solar wind speed or daily averaged solar wind speed [ 9 ].As a result, little work has been done on investigating how sun wind speed shifts on shorter timescales [ 10 ]."
    },
    {
        "original_text": "We present an explicit calculation of the non-perturbative renormalisation constant for the chromomagnetic operator in heavy quark effective theory (HQET). We use this to calculate the leading order contribution to the mass difference between the ground state vector mesons containing a b-quark, i.e., $B^*$- $B$ mixing. The result is compared with lattice QCD calculations at next-to-leading order in HQET perturbation theory. Our results are consistent within errors but do not agree as well as one would like. This may be due to missing higher-order corrections or systematic uncertainties inherent in both approaches. \n \n Introduction \n \n In recent years there has been considerable interest in studying hadronic systems containing a single heavy quark using the framework provided by heavy quark effective theory (HQT) [1] . One important application of HQT is to study the properties of heavy-light mesons such as the bottomonium system [2] , which can then be used to test our understanding of nonrelativistic quantum mechanics [3] .\n \nIn particular, it is interesting to consider how the masses of these states depend on their spin. For example, the lowest lying bb states have spin-parity J P = 0+ and 1− respectively [4] . These two states mix under the weak interaction through the emission and absorption of virtual gluons [5] . At tree level we find that the lightest physical eigenstate is given by:",
        "watermark_text": "We present an explicit calculation of the non - perturbative renormalisation constant for the chromomagnetic operator in heavy quark effective theory ( HQET ).We use this to calculate the leading order contribution to the mass differential between the ground state vector mesons holding a b - quark, i. e., $ B ^ * $ - $ B $ mixing.The result is compared with lattice QCD calculations at next - to - leading order in HQET perturbation theory.Our results are consistent within errors but do not agree as well as one might like.This may be due to missing higher - order corrections or systematic uncertainties inherent in both approaches.Introduction In recent years there has been considerable attention in studying hadronic models containing a single heavy quark using the frame provided by heavy quark effective theory ( HQT )[ 1 ].One important application of HQT is to study the properties of heavy - light mesons such as the bottomonium system [ 2 ], which can then be used to test our understanding of nonrelativistic quantum mechanics [ 3 ].In particular, it is interesting to think how the masses of these states depend on their spin.For example, the least lying bb states have spin - parity J P = 0 + and 1− respectively [ 4 ].These two states mix under the weak interaction through the emission and absorption of virtual gluons [ 5 ].At tree level we find that the lightest physical eigenstate is given by :"
    },
    {
        "original_text": "We show that correlation clustering is NP-hard to approximate within any constant factor, even for graphs with maximum degree three and clusters of size at most four.  We also present an algorithm which solves this problem exactly in time O(n3). Our results are based on reductions from the exact cover by 3-sets (X3C) problem. The X3C problem asks whether there exists a collection of subsets of a set S such that each element of S belongs to exactly 3 sets in the collection; it has been shown to be NP-complete. For more information about our work see http://arxiv.org/abs/1206.0571 . \nCorrelation clustering is one of several problems studied under the umbrella of \"clustering\"; these include k-means clustering, spectral clustering, and graph partitioning. It was introduced independently by Bansal et al., Blum et al., and Dasgupta et al. as follows.   Given a weighted undirected graph G = (V, E), where V denotes the vertices and E denotes the edges, we say that two vertices u, v ∈ V are adjacent if they share an edge e ∈ E. A cluster C ⊆ V is defined as a subset of nodes whose pairwise distances satisfy some threshold t > 0. More formally, given a distance function d : V × V → R+ , let dist(u,v) denote the shortest path between u and v; then, C is said to be a valid cluster if and only if for all pairs of nodes u, v ∈ C:  dist(u,v)  ≤ t",
        "watermark_text": "We show that correlation clustering is NP - hard to estimate within any consistent factor, even for graphs with maximum degree three and clusters of size at most four.We also present an algorithm which solves this problem exactly in time O ( n3 ).Our results are based on reductions from the exact cover by 3 - sets ( X3C ) problem.The X3C problem asks whether there exists a collection of subsets of a set S such that each element of S belongs to exactly 3 sets in the collection ; it has been shown to be NP - complete.For more information about our work read http : / / arxiv. org / abs / 1206. 0571.Correlation clustering is one of several problems studied under the umbrella of \" clustering \" ; these include k - means clustering, spectral clustering, and graph partitioning.It was introduced separately by Bansal et al., Blum et al., and Dasgupta et al. as follows.Given a weighted undirected graph G = ( V, E ), where V denotes the vertices and E denotes the edges, we say that two vertices u, v ∈ V are adjacent if they share an edge e beneath E. A cluster C ⊆ V is defined as a subset of nodes whose pairwise distances satisfy some threshold t > 0.More formally, given a distance function d :V × V → R +, let dist ( u, v ) denote the shortest pathway between u and v ; then, C is said to be a valid cluster if and only if for all pairs of nodes u, v ∈ C :dist ( u, v ) ≤ t"
    },
    {
        "original_text": "We have investigated charge injection capability (CIC) of Suzaku X-ray Imaging Spectrometer (XIS). The CIC is an important feature for high energy resolution spectroscopy, which can be used to reduce the effect of pile-up in bright sources and improve the spectral quality at low energies. We performed detailed analysis on the performance of CIC by using Crab observations with different count rates. By comparing the results obtained with and without CIC we found that CIC improves the spectral fitting significantly especially below 1 keV where the pile-up fraction becomes large when the source flux increases. This improvement was confirmed also by analyzing simulated data generated by xisrmfgen and xissimarfgen. Finally, we applied this method to analyze the observation of Mrk 421 during its flare state. We successfully detected emission lines such as O VII Kα line and Fe XXV Kα line from the spectrum taken with CIC enabled.  These results show that CIC works well even under strong pile-up conditions.",
        "watermark_text": "We have investigated charge injection capability ( CIC ) of Suzaku X - ray Imaging Spectrometer ( XIS ).The CIC is an important feature for high energy resolution spectroscopy, which can be used to lower the effect of pile - up in light sources and improve the spectrum quality at low energies.We performed detailed analysis on the performance of CIC by using Crab observations with different count rates.By comparing the results obtained with and without CIC we found that CIC improves the spectral fitting significantly especially below 1 keV where the pile - up fraction becomes large when the source flux increases.This improvement was confirmed also by examining simulated data generated by xisrmfgen and xissimarfgen.Finally, we applied this method to analyze the observation of Mrk 421 during its flare status.We successfully detected emission lines such as O VII Kα line and Fe XXVKα line from the spectrum taken with CIC enabled.These results show that CIC works well even under strong pile - up conditions."
    },
    {
        "original_text": "We present an ab initio study of the electronic and magnetic structure of volborthite, CaFe3(PO4)2(OH)3·H2O (CFPOH), which is one of the most important minerals in geological sciences as it forms at low temperatures under hydrothermal conditions. Volborthite has been studied extensively by neutron scattering experiments but its microscopic origin remains controversial. We show that the ground state of CFPOH can be described within density functional theory using the generalized gradient approximation plus Hubbard U method for Fe-3d orbitals. The calculated spin wave spectrum agrees well with experimental data obtained by inelastic neutron scattering measurements. In addition we find that the magnetocrystalline anisotropy energy is dominated by spin-orbit coupling effects. Finally, we discuss how our results are related to previous theoretical studies based on different approximations. V olborthite, CaF e 3 (P O 4 ) 2 (OH) 3 ·H 2 O (C F P OH ), is one of the most impor-tant minerals in geological sciences because it forms at low tem-peratures under hydrothermal conditions [1] . It was first discovered in 1832 [2] , however, only recently have detailed structural investigations revealed that this mineral belongs to the family of compounds known as \"Kagome\" materials [3] .\nVolborthite crystallizes into a layered structure consisting of alternating kagome planes of iron ions and phosphate groups [4] . This arrangement leads to interesting physical phenomena such as geometric frustration [5] or quantum fluctuations [6] . For example, recent neutron scattering experiments suggest that volborthite undergoes a phase transition below T N = 5 K [7, 8] where the spins order ferrimagnetically along the c-axis [9] . However, there exists no consensus about the nature of this ordering [10] : while some authors claim that the system orders collinearly [11, 12] others argue that non-collinearity plays an essential role [13, 14] .",
        "watermark_text": "We present an ab initio study of the electronic and magnetic structure of volborthite, CaFe3 ( PO4 ) 2 ( OH ) 3 · H2O ( CFPOH ), which is one of the most important minerals in geological sciences as it forms at low temperatures under hydrothermal conditions.Volborthite has been studied extensively by neutron scattering experiments but its microscopic origin remains controversial.We show that the ground state of CFPOH can be described within dense functional theory utilizing the generalized gradient approximation plus Hubbard U method for Fe - 3d orbitals.The calculated spin wave spectral agrees well with experiment data obtained by inelastic neutron scattering measurements.In addition we find that the magnetocrystalline anisotropy energy is dominated by spin - orbit coupling effects.Finally, we discuss how our outcomes are related to previous theoretical studies based on different approximations.V olborthite, CaF e 3 ( P O 4 ) 2 ( OH ) 3 · H 2 O ( C F P OH ), is one of the most impor - tant minerals in geological sciences because it forms at low tem - peratures under hydrothermal conditions[ 1 ].It was first discovered in 1832 [ 2 ], however, only recently have detailed structural investigations revealed that this mineral belongs to the family of compounds known as \" Kagome \" materials [ 3 ].Volborthite crystallizes into a layered structure consisting of alternating kagome planes of iron ions and phosphate groups [ 4 ].This arrangement leads to interesting physical phenomena such as geometric frustration [ 5 ] or quantum fluctuations [ 6 ].For example, recent neutron scattering experiments suggest that volborthite undergoes a phase transition below T N = 5 K[ 7, 8 ] where the spins order ferrimagnetically along the c - axis [ 9 ].However, there exists no consensus about the nature of this ordering [ 10 ] : while some authors claim that the structure orders collinearly [ 11, twelve ] another argue that non - collinearity plays an essential role[ 13, 14 ]."
    },
    {
        "original_text": "We report on spectroscopic observations made with the Nordic Optical Telescope (NOT) and the William Herschel Telescope (WHT). The NOT data were obtained during two observing runs, one in August 2002 and another in September 2003. We used the ALFOSC instrument to obtain time-resolved spectroscopy covering the wavelength range 3700-7000 Å at a resolution of about 1 Å . The WHT data were taken between October 2004 and January 2005 using ISIS spectrographs equipped with gratings R600B and R1200R giving a spectral coverage of 3600-9200 Å at a resolving power of about 1000. In total we have collected more than 100 spectra for this object. All our new data are presented along with previously published results by Vogt et al. (1987) , Vogt & Hatzes (1991), Vogt et al. (1994a-c) . Our analysis shows that the system is composed of an M4V star orbited by a white dwarf companion.",
        "watermark_text": "We report on spectroscopic observations made with the Nordic Optical Telescope ( NOT ) and the William Herschel Telescope ( WHT ).The NOT data were obtained during 2 observing runs, one in August 2002 and another in September 03.We used the ALFOSC instrument to obtain time - resolved spectroscopy covering the wavelength range 3700 - 7000 Å at a resolution of about 1 Å.The WHT data were taken between Oct 2004 and Jan 2005 using ISIS spectrographs equipped with gratings R600B and R1200R yielding a spectral coverage of 3600 - 9200 Å at a resolving power of about 1000.In total we have gathered more than 100 spectra for this object.All our new data are presented alongside with previously published results by Vogt et al. ( 1987 ), Vogt & Hatzes ( 1991 ), Vogt et al. ( 1994a - c ).Our analysis shows that the system is composed of an M4V star orbited by a white dwarf companion."
    },
    {
        "original_text": "We present an algorithm for learning the parameters of a probabilistic model by optimizing its log-likelihood using Monte Carlo (MC) sampling, which we call Parametric Learning with MC Sampling or PLMS. We show that this approach is equivalent to maximum likelihood estimation when the number of samples goes to infinity. In practice however, it can be much more efficient than standard gradient-based optimization methods because it does not require computing gradients over all data points at each iteration. Instead, only one sample per iteration needs to be generated in order to compute the objective function value and update the parameter values accordingly. This makes our method particularly suitable for large datasets where evaluating the objective function may take too much time. Our experiments on synthetic and real-world datasets demonstrate that PLMS outperforms state-of-the-art algorithms such as stochastic gradient descent and Adam in terms of both accuracy and efficiency. Code available at: https://github.com/sunyuan-chen/PLMS",
        "watermark_text": "We present an algorithm for learning the parameters of a probabilistic model by optimizing its log - likelihood using Monte Carlo ( MC ) sampling, which we call Parametric Learning with MC Sampling or PLMS.We show that this approach is equivalent to maximum likelihood estimation when the number of samples goes to infinity.In practice however, it can be much more efficient than standard gradient - based optimization methods because it does not require calculating gradients over all data points at each iteration.Instead, only 1 sample per iteration needs to be generated in order to compute the objective function value and update the parameter functions accordingly.This makes our methodology particularly suitable for big datasets where assessing the objective function might take too much time.Our experiments on synthetic and real - world datasets demonstrate that PLMS outperforms state - of - the - art algorithms such as stochastic gradient descent and Adam in terms of both accuracy and efficiency.Code available at : https : / / github. com / sunyuan - chen / PLMS"
    },
    {
        "original_text": "We present the results on the interband, intraband and excitonic transitions for Si and Ge nanocrystals (NCs) embedded into Al2O3 matrix by using first-principles calculations based on density functional theory within local-density approximation. The NC size is varied between 1 nm to 5 nm with an interval of 0.5 nm. We find that the optical gap decreases as we increase the NC size due to quantum confinement effect. In addition, we observe that the lowest energy peak shifts towards higher energies when increasing the NC size which can be attributed to the surface states. Furthermore, our calculated results show that the oscillator strength increases significantly at smaller sizes while it decreases rapidly at larger sizes. Finally, we also investigate the influence of strain on the electronic structure of these systems. Our findings are expected to provide useful information about the design of optoelectronic devices such as solar cells or photodetectors. \n \n Keywords: Silicon Nanocrystal, Germanium Nanocrystal, Optical properties",
        "watermark_text": "We present the results on the interband, intraband and excitonic transitions for Si and Ge nanocrystals ( NCs ) embedded into Al2O3 matrix by using first - principles calculations based on density functional theory within local - density approximation.The NC size is varied between 1 nm to 5 nm with an interval of zero. 5 nm.We find that the optical gap decreases as we raise the NC size due to quantum cage effect.In addition, we observe that the least energy peak shifts towards higher energies when increasing the NC size which can be attributed to the surface states.Furthermore, our calculated results show that the oscillator strength increases significantly at smaller sizes while it decreases rapidly at larger sizes.Finally, we also investigate the influence of strain on the electronic structure of these systems.Our findings are likely to provide useful information about the design of optoelectronic products such as solar cells or photodetectors.Keywords : Silicon Nanocrystal, Germanium Nanocrystal, Optical properties"
    },
    {
        "original_text": "The brain is an organ that has evolved to be dynamic and plastic, constantly changing its structure in response to internal and external stimuli.  The human brain can change throughout life by forming new connections between neurons or eliminating existing ones.   This ability allows humans to adapt to their environment and learn continuously.   However, this flexibility also makes it vulnerable to damage caused by disease, trauma, aging, etc., which may lead to neurological disorders such as Alzheimer's Disease, Parkinson's Disease, Huntington's Disease, Epilepsy, Traumatic Brain Injury, Multiple Sclerosis, etc.   In recent years there have been significant advances in neuroscience research aimed at understanding how the brain works and developing treatments for these diseases.   One approach involves using neural prosthetic devices to replace damaged parts of the brain with artificial components that are capable of performing similar functions.   Neural prosthetics are electronic systems designed to interface directly with the nervous system to restore lost function due to injury or disease.   These devices include microelectrodes implanted into the brain tissue to record electrical activity; stimulating electrodes placed on or near nerves to deliver electrical stimulation; and wireless communication links used to transmit data recorded by the recording electrodes and/or control signals generated by the stimulating electrodes back to a computer located outside the body.   ...",
        "watermark_text": "The brain is an organ that has evolved to be active and plastic, constantly changing its structure in response to internal and external stimuli.The human brain can change throughout life by forming new connections between neurons or eliminating existing ones.This ability enables humans to adapt to their environment and learn continuously.However, this flexibility also makes it vulnerable to damage caused by disease, trauma, aging, etc., which may result to neurological disorders such as Alzheimer ' s Disease, Parkinson ' s Disease, Huntington ' s Disease, Epilepsy, Traumatic mind Injury, Multi Sclerosis, etc.In recent years there have been significant advances in neuroscience research aimed at understanding how the brain works and developing treatments for these diseases.One approach involves using neural prosthetic devices to replace damaged parts of the brain with artificial components that are capable of performing similar functions.Neural prosthetics are electronic systems designed to interface directly with the nervous system to restore lost function due to injury or disease.These devices include microelectrodes implanted into the brain tissue to record electrical events ; stimulating electrodes placed on or near nerves to deliver electrical stimulation ; and wireless communication links used to transmit data recorded by the recording electrodes and / or control signals generated by the stimulating electrodes back to a computer located outside the body.."
    },
    {
        "original_text": "We report on the polarization dependent photoluminescence (PL) and Raman scattering spectra of CdSe/CdS core/shell quantum dots in solution at room temperature. The PL spectrum shows that the emission is polarized along the direction perpendicular to the excitation light, which can be explained by the selection rules for dipole transitions between electronic states with different angular momenta. In addition we observe an anisotropic broadening of the Stokes linewidths as well as a splitting into two components when exciting circularly polarized light. These effects are attributed to the presence of exciton fine structure due to spin-orbit coupling. We also find evidence for a strong electron-phonon interaction leading to phonon sidebands in both the Stokes and anti-Stokes parts of the Raman spectrum. Finally, we show how these results can be used to determine the orientation of individual QDs embedded in a polymer matrix. Polarized luminescence measurements have been performed on single QD emitters using confocal microscopy.",
        "watermark_text": "We report on the polarization dependent photoluminescence ( PL ) and Raman scattering spectra of CdSe / CdS core / shell quantum dots in solution at room temperature.The PL spectrum shows that the emission is polarized along the orientation perpendicular to the excitation light, which can be explained by the selection rules for dipole transitions between electronic states with different angular momenta.In addition we observe an anisotropic broadening of the Stokes linewidths as well as a splitting into 2 components when exciting circularly polarized light.These effects are attributed to the presence of exciton fine structure due to spin - orbit coupling.We also find proof for a strong electron - phonon interaction leading to phonon sidebands in both the Stokes and anti - Stokes parts of the Raman spectrum.Finally, we show how these results can be used to determine the inclination of individual QDs embedded in a polymer matrix.Polarized luminescence measurements have been performed on single QD emitters utilizing confocal microscopy."
    },
    {
        "original_text": "We present an approach to dependability analysis that is hierarchical in nature, and can be applied to any cache-based storage architecture. The main idea behind our approach is the use of a set of models at different levels of abstraction to represent the system under study. We show how these models are used together with simulation experiments to perform dependability evaluation on a commercial cache-based RAID storage architecture. Our results demonstrate that this approach provides significant advantages over traditional approaches based solely on analytical modeling or simulation experiments. In particular, we find that: (1) it allows us to obtain accurate estimates of reliability measures such as mean time between failures; (2) it enables us to explore tradeoffs among various design parameters; and (3) it helps us identify critical components within the system. Finally, we discuss some limitations of our approach and suggest directions for future research. Caching has been widely adopted by modern computer systems to improve performance through reducing access latency. However, caching introduces new challenges related to data consistency management and fault tolerance. This article presents a novel approach to dependability analysis of cache-based storage architectures.",
        "watermark_text": "We present an approach to dependability analysis that is hierarchical in character, and can be applied to any cache - based storage architecture.The main idea behind our approach is the use of a set of models at different levels of abstraction to represent the system under study.We show how these models are used together with simulation experiments to perform dependability evaluation on a commercial cache - based RAID storage architecture.Our results demonstrate that this approach offers significant advantages over conventional approaches based solely on analysis modeling or simulation experimentation.In particular, we find that : ( 1 ) it allows us to obtain accurate estimates of reliability measures such as mean time between failures ; ( 2 ) it enables us to explore tradeoffs among various design parameters ; and ( 3 ) it helps us identify critical components inside the system.Finally, we discuss some limitations of our approach and suggest directions for future research.Caching has been widely adopted by modern computer systems to improve performance through reducing access latency.However, caching introduces new challenges related to data consistency management and fault tolerance.This article presents a novel approach to dependability analysis of cache - based storage architectures."
    },
    {
        "original_text": "We present new spectroscopic observations for eight red giant stars in the nearby dwarf spheroidal galaxy, Leo II (D = 3 Mpc). The data were obtained with the Keck telescope and HIRES spectrograph over three nights during August 2005. We measure heliocentric radial velocities ranging between -150 to +50 km/sec. These values are consistent with previous measurements made by other authors using different techniques. Using these new data we have determined that there is no significant rotation or streaming motion within this system. This result supports theoretical predictions based on N-body simulations which suggest that dark matter halos should be nearly spherical systems. In addition, our results provide further evidence against the possibility that Leo II may contain an intermediate mass black hole at its center. \n \n Keywords: Dwarf galaxies; Black holes; Dark Matter Halos; Rotation Curves; Stellar Kinematics; Spherical Symmetry",
        "watermark_text": "We present fresh spectroscopic observations for eight red giant stars in the nearby dwarf spheroidal galaxy, Leo II ( D = 3 Mpc ).The data were obtained with the Keck telescope and HIRES spectrograph over three nights during August 2005.We measure heliocentric radial velocities ranging between - 150 to + 50 km / sec.These values are consistent with previous measurements made by other authors using different methods.Using these new data we have determined that there is no significant rotation or streaming motion inside this system.This result supports theoretical predictions based on N - body simulations which suggest that dark matter halos should be nearly spherical systems.In addition, our results provide further evidence against the possibility that Leo II may include an intermediate mass dark hole at its center.Keywords : Dwarf galaxies ; Black holes ; Dark Matter Halos ; Rotation Curves ; Stellar Kinematics ; Spherical Symmetry"
    },
    {
        "original_text": "The origin and evolution of cosmic magnetic fields are one of the most important unsolved problems in astrophysics, which is closely related to many other fundamental issues such as star formation, galaxy formation and structure formation. In this talk I will review our recent work on simulating primordial magnetic fields with different physical processes involved. The first part focuses on the generation of seed magnetic fields during inflation by quantum fluctuations. We show that these seeds can be amplified significantly after reheating due to the magnetohydrodynamic turbulence driven by the decaying inflaton perturbations. Then we discuss how these seeds evolve into large-scale coherent magnetic fields through various mechanisms including inverse cascade, dynamo action and turbulent pumping. Finally, we present some possible observational signatures for future detection. This talk was given at the International Conference on Computation & Theory (ICCT) held in Beijing, China between September 24-27, 2014.",
        "watermark_text": "The origin and evolution of cosmic magnetic fields are one of the most significant unsolved problems in astrophysics, which is closely related to many other fundamental issues such as star formation, galaxy formation and structure formation.In this talk I will review our recent work on simulating primordial magnetic fields with different physical processes involved.The first part focuses on the generation of seed magnetic fields during inflation by quantum fluctuations.We show that these seeds can be amplified significantly after reheating due to the magnetohydrodynamic turbulence driven by the decaying inflaton perturbations.Then we discuss how these seeds evolve into large - level coherent magnetic fields through various mechanisms including inverse cascade, dynamo acting and turbulent pumping.Finally, we present some possible observational signatures for future detection.This talk was given at the International Conference on Computation & Theory ( ICCT ) held in Beijing, China between September 24 - 27, 2014."
    },
    {
        "original_text": "We present an improved abundance determination for the black hole binary nova Sco X-1, based on high-resolution optical spectroscopy obtained with UVES at VLT-UT2 in November 2004 and January 2005. The new data are combined with previously published results to derive abundances for CNO elements as well as FeI and FeII lines. We find that our best-fit model is consistent with previous studies within their uncertainties. However, we obtain significantly lower values for carbon and oxygen than those reported by Gies & Bolton (1986) . This discrepancy may be due to differences between the adopted atmospheric models or atomic data used in these two analyses. \n \n Keywords: Black holes - Abundance ratios - X-ray binaries - Spectroscopy - Ultraviolet space observatories - Variability - Velocity fields - Stellar winds - Mass transfer -X-ray emission - Accretion disks - Novae - Supernovae",
        "watermark_text": "We present an better abundance determination for the dark hole binary nova Sco X - 1, based on high - resolution optical spectroscopy obtained with UVES at VLT - UT2 in Nov 2004 and Jan 2005.The new data are combined with previously publication results to derive abundances for CNO elements as well as FeI and FII lines.We find that our best - fit model is consistent with previous studies within their uncertainties.However, we obtain significantly lower values for carbon and oxygen than those reported by Gies & Bolton ( 1986 ).This discrepancy may be due to differences between the adopted atmospheric models or atomic data utilized in these two analyses.Keywords : Black holes - Abundance ratios - X - ray binaries - Spectroscopy - Ultraviolet space observatories - Variability - Velocity fields - Stellar winds - Mass transfer - X - ray emission - Accretion disks - Novae - Supernovae"
    },
    {
        "original_text": "We report on near-infrared observations of an extremely red, faint source in the field of view of the Hubble Space Telescope's Wide Field Planetary Camera 2 (WFPC2). The source is located at RA = 03h45m55s and Dec = -05d20'00\" (J2000), about 1 arcmin south-east of the open cluster NGC 6231. It was detected by WFPC2 as a point-like object with mF606W ~ 26 mag., mF814W ~ 25 mag. (Vega system) and mH ~ 20 mag.. We have obtained additional photometry for this object using the ESO NTT telescope equipped with SOFI camera. Our results show that it has very red colors (R-I > 5 mag.) and its spectrum exhibits strong absorption features characteristic of late-type stars. Its absolute magnitude M(K) = -4.3 ± 0.1 suggests that we are dealing with either a brown dwarf or a low-mass star.",
        "watermark_text": "We report on near - infrared observations of an extremely red, dim source in the field of view of the Hubble Space Telescope ' s Wide Field Planetary Camera 2 ( WFPC2 ).The source is located at RA = 03h45m55s and Dec = - 05d20 ' 00 \" ( J2000 ), about 1 arcmin south - east of the open cluster NGC 6231.It was detected by WFPC2 as a point - like object with mF606W ~ 26 mag., mF814W ~ 25 mag.( Vega system ) and mH ~ 20 mag.We have obtained extra photometry for this object using the ESO NTT telescope equipped with SOFI camera.Our results show that it has very red colors ( R - I > 5 mag. ) and its spectrum exhibits strong absorbing features typical of late - type stars.Its absolute magnitude M ( K )= - 4. 3 ± 0. 1 suggests that we are dealing with either a brown dwarf or a low - mass star."
    },
    {
        "original_text": "We present the results of N-body simulations for open and globular star clusters with different initial conditions, including primordial binaries in various proportions (from 0 to 100%). We find that the fraction of binaries among all stars decreases as the cluster evolves due to dynamical interactions between single and binary stars. The decrease is more pronounced if there are initially many hard binaries or few soft ones. In addition, we show how the number of binaries depends on their binding energy distribution at birth. Finally, we compare our results with observations of real open and globular clusters. Our main conclusions are:  1) Open clusters have fewer binaries than globulars because they lose most of them during early evolution.  2) Binaries can be destroyed by three-body encounters even when the total number of binaries remains constant.  3) Hard binaries dominate over soft ones after several relaxation timescales t rh .",
        "watermark_text": "We present the results of N - body simulations for open and globular star clusters with different initial conditions, including primordial binaries in various proportions ( from 0 to 100 % ).We find that the fraction of binaries among all stars decreases as the cluster evolves due to dynamical interactions between single and cluster stars.The decrease is more pronounced if there are originally many hard binaries or few soft ones.In addition, we show how the number of binaries depends on their bond energy spread at birth.Finally, we compare our results with observations of actual open and globular clusters.Our main conclusions are : 1 ) Open clusters have fewer binaries than globulars because they lose most of them during early evolution.2 ) Binaries can be destroyed by three - body encounters even when the total number of binaries remains constant.3 ) Hard binaries dominate over soft ones after several relaxation timescales t rh."
    },
    {
        "original_text": "In this paper, we propose an autonomous distributed admission control scheme to improve the performance and fairness in wireless local area networks (WLANs). The proposed scheme is based on the concept that each station maintains its own queue length information by using the packet inter-arrival time at the physical layer. In addition, it uses the number of active stations as well as their transmission rates to determine whether or not new connections are admitted into the network. We show through simulation results that our scheme can achieve better throughput than existing schemes while maintaining good fairness among competing stations. Keywords: Wireless Local Area Networks, Packet Inter-Arrival Time, Fairness, Throughput Improvement. 1 Introduction With the rapid development of mobile computing devices such as laptops, PDAs, smart phones etc., there has been growing interest in providing high quality services over wireless local area networks (WLANS) [1] . However, due to limited bandwidth resources available in WLANs, efficient resource management becomes crucially important [2] .\nThe most widely used medium access control protocol in current commercial WLAN products is the IEEE 802.11 Distributed Coordination Function (DCF), which provides both contention-based channel access mechanism called Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) [3] , and contention-free service via Point Coordinated Function (PCF) [4] . Although CSMA/CA allows multiple stations to share the same radio channel simultaneously without any centralized coordination, it suffers from poor system performance when the traffic load increases [5] . This problem is mainly caused by the hidden terminal effect [6] where two nodes may transmit packets to one another simultaneously causing collisions. To alleviate these problems, several approaches have been proposed [7 -10] . Among them, the authors in [8] introduced a simple but effective method known as Virtual Reservation Channel (VRC) to reduce the probability of collision between data frames transmitted by different stations. They also presented a modified version of VRC [9] to further enhance the performance of CSMA/CA under heavy loads. However, all these works assume that the number of active stations within the",
        "watermark_text": "In this paper, we propose an autonomous distributed admission control system to improve the performance and fairness in wireless local area networks ( WLANs ).The proposed scheme is based on the concept that each station maintains its own queue length information by utilizing the packet inter - arrival time at the physical layer.In addition, it uses the number of active stations as well as their transmission speeds to decide whether or not new connections are admitted into the network.We show through simulation results that our scheme can accomplish better throughput than existing ones while maintaining good fairness among competing stations.Keywords : Wireless Local Area Networks, Packet Inter - Arrival Time, Fairness, Throughput Improvement.1 Introduction With the rapid development of mobile computing devices such as laptops, PDAs, smart phones etc., there has been growing interest in providing high quality services over wireless local area networks ( WLANS )[ 1 ].However, due to limited bandwidth resources available in WLANs, efficient resource management becomes crucially important [ 2 ].The most widely used medium access control protocol in current commercial WLAN products is the IEEE 802. 11 Distributed Coordination Function ( DCF ), which offers both contention - based channel access mechanism called Carrier Sense Multi Access with Collision Avoidance ( CSMA / CA )[ 3 ], and contention - free service via Point Coordinated Function ( PCF )[ 4 ].Although CSMA / CA allows multiple stations to share the same radio channel simultaneously without any centralized coordination, it suffers from poor system performance when the traffic load increases [ 5 ].This problem is mainly caused by the hidden terminal effect[ 6 ] where two nodes may transmit packets to one another simultaneously causing collisions.To alleviate these problems, several approaches have been proposed [ 7 - 10 ].Among them, the authors in [ 8 ] introduced a simple but effective method known as Virtual Reservation Channel ( VRC ) to reduce the probability of collision between data frames transmitted by different stations.They also presented a modified form of VRC[ 9 ] to further enhance the performance of CSMA / CA under heavy loads.However, all these works assume that the number of active stations within the"
    },
    {
        "original_text": "We present new observations and analysis of the infrared emission lines in the spectra of two yellow hypergiants, IRC+10420 and AFGL2136. We find that these objects have very high mass-loss rates (10^-6 to 10^-5 Msun/yr) with outflow velocities ranging between 100-200 km/sec. The observed line profiles are consistent with an expanding shell model for the wind. In addition we detect several forbidden transitions which indicate the presence of highly ionized species such as Fe + , Si ++ , S ++ . These ions may be formed by photoionization or collisional ionization processes within the stellar winds. \n \n Keywords: Yellow Hypergiants; Circumstellar Envelopes; Mass loss rate; Outflows; Emission Lines; IRAS 08544-4431. Astronomy & Astrophysics manuscript no. aa20031118 May 31, 2003 \nThe chemical composition of the circumstellar-envelope",
        "watermark_text": "We present new observations and analysis of the infrared emission lines in the spectra of two yellow hypergiants, IRC + 10420 and AFGL2136.We find that these objects have very high weight - loss rates ( 10 ^ - 6 to 10 ^ - 5 Msun / yr ) with outflow velocities ranging between 100 - 200 km / sec.The observed line profiles are consistent with an expanding shell model for the breeze.In addition we detect several forbidden transitions which indicate the presence of highly ionized species such as Fe +, Si + +, S + +.These ions may be formed by photoionization or collisional ionization processes within the star winds.Keywords : Yellow Hypergiants ; Circumstellar Envelopes ; Mass loss rate ; Outflows ; Emission Lines ; IRAS 08544 - 4431.Astronomy & Astrophysics manuscript no. aa20031118May 31, 2003The chemical composition of the circumstellar - envelope"
    },
    {
        "original_text": "We present an analysis of the transition between first stars and second stars, which are formed by gravitational collapse of primordial gas clouds with masses ranging from 10^4 M_sol to 10^6 M_sol.  We show that the formation rate of second stars is suppressed at redshifts z < 20 due to photoheating effects on the intergalactic medium (IGM). The suppression factor increases as redshift decreases because the IGM temperature rises more rapidly than its density. At lower redshifts, we find that the formation rates of both first and second stars increase sharply when the universe becomes reionized. This effect occurs because the ionizing photons produced during reionization heat up the surrounding neutral hydrogen atoms, thereby increasing their Jeans mass and suppressing fragmentation into smaller objects. Finally, we estimate the number densities of first and second stars using our model for star formation history. Our results suggest that second stars may be detectable via future surveys such as LSST or Euclid.",
        "watermark_text": "We present an analysis of the transition between first stars and second stars, which are formed by gravitational collapse of primordial gas clouds with masses ranging from 10 ^ 4 M _ sol to 10 ^ 6 M _ sol.We show that the forming rate of second stars is suppressed at redshifts z < 20 due to photoheating results on the intergalactic medium ( IGM ).The suppression factor increases as redshift decreases because the IGM temperature rises more rapidly than its density.At lower redshifts, we find that the formation rates of both first and 2nd stars increase sharply when the universe becomes reionized.This effect occurs because the ionizing photons produced during reionization heat up the surrounding neutral hydrogen atoms, thereby increasing their Jeans mass and suppressing fragmentation into smaller objects.Finally, we estimate the number densities of first and 2nd stars using our model for star formation history.Our results suggest that second stars may be detectable using future surveys such as LSST or Euclid."
    },
    {
        "original_text": "We present photoionization models for the heliosheath, which is the region between the termination shock (TS) at ~100 AU and the solar wind termination shock (SWTS). The SWTS is located beyond 1 AU in the solar system's frame but within 0.3 AU in the rest frame of the Sun. We use these models to constrain the boundary conditions of the heliosphere using interstellar neutral hydrogen data obtained with the Lyman-alpha instrument on board the Solar Wind Anisotropy Probe (SWAP), as well as in situ measurements made near Earth during the Voyager 2 mission. Our results show that the TS distance decreases with increasing solar activity; this effect can be explained by an increase in the density of the solar wind plasma. For low solar activity levels we find that the TS distance agrees very well with previous estimates based on observations of energetic particles.",
        "watermark_text": "We present photoionization models for the heliosheath, which is the region between the termination shock ( TS ) at ~ 100 AU and the solar wind termination shock ( SWTS ).The SWTS is located beyond 1 AU in the solar system ' s frame but within 0. 3 AU in the rest frame of the Sun.We use these models to constrain the boundary conditions of the heliosphere utilizing interstellar neutral hydrogen data obtained with the Lyman - alpha instrument on board the Solar Wind Anisotropy Probe ( SWAP ), as well as in situ measurements made near Earth during the Voyager 2 mission.Our results show that the TS distance decreases with increasing solar activity ; this effect can be explained by an increase in the density of the solar wind plasma.For low solar activity levels we find that the TS distance agrees very well with previous estimates based on observations of energetic particles."
    },
    {
        "original_text": "Spin-based electronics is an emerging field that has attracted considerable attention in recent years, due to its potential for applications such as high-density data storage and high-speed information processing.  In this review article we discuss the basic concepts underlying bipolar spintronic devices based on semiconductor heterostructures with ferromagnetic contacts. We first introduce the physics behind spin injection into semiconductors using tunnel barriers or Schottky diodes. Then we describe how these injected spins can be manipulated by means of external magnetic fields and/or electric currents. Finally, we present some examples of spintronic devices including spin-LEDs, spin transistors, and spin-logic circuits. The main focus will be put on GaAs-based structures but also other materials systems are discussed briefly. This article is intended to provide a comprehensive overview of the state-of-the-art research in the field of bipolar spintronics. It should serve both as a guide for newcomers interested in learning about the fundamentals of spin transport phenomena at interfaces between metals and semiconductors, and as a reference source for researchers working in related areas.",
        "watermark_text": "Spin - based electronics is an emerging field that has attracted considerable attention in recent years, due to its prospects for applications such as high - density data storage and highly - speed information processing.In this review article we discuss the basic concepts behind bipolar spintronic devices based on semiconductor heterostructures with ferromagnetic contacts.We first introduce the physics behind spin injection into semiconductors using tunnel barriers or Schottky diodes.Then we describe how these injected spins can be manipulated by means of outside magnetic fields and / or electric currents.Finally, we present some examples of spintronic devices including spin - LEDs, spin transistors, and spin - logic circuits.The main focus will be put on GaAs - based structures but also other materials systems are discussed briefly.This article is intended to provide a comprehensive overview of the state - of - the - artwork research in the field of bipolar spintronics.It should serve both as a guide for newcomers interested in learning about the fundamentals of spin transport phenomena at interfaces between metals and semiconductors, and as a reference source for researchers working in related areas."
    },
    {
        "original_text": "We present the results obtained by applying the semi-analytic code VESPA to model the evolution of galaxies in the Millennium Simulation, including chemical enrichment as well as dust extinction effects on their observed properties.  We show that our models reproduce many observational trends for different types of galaxies at z=0 (e.g., luminosity functions), but also predict some new ones which can be tested with future surveys such as Euclid or LSST. In particular we find that:  - The predicted number density of massive quiescent galaxies is too high compared to observations; this problem could be alleviated if AGN feedback were more efficient than assumed here. - Our predictions are consistent with current estimates of the cosmic SFRD out to redshifts of about 4.5, although they tend to overpredict it slightly beyond that redshift. - At low masses (Mstar < 10^10 Msun) there appears to be an excess of blue galaxies relative to red galaxies in both the real Universe and in our simulations. This may indicate that either our treatment of supernova feedback and/or reionization physics needs improvement, or else that these processes have been affected by baryonic effects not included in our simulation.",
        "watermark_text": "We present the results obtained by applying the semi - analytic code VESPA to model the evolution of galaxies in the Millennium Simulation, including chemical enrichment as also as dust extinction effects on their observed properties.We show that our models reproduce many observational tendencies for different forms of galaxies at z = zero ( e. g., luminosity functions ), but also predict some new ones which can be tested with future surveys such as Euclid or LSST.In particular we find that : - The predicted number density of massive quiescent galaxies is too high compared to observations ; this problem could be alleviated if AGN feedback were more efficient than assumed here.- Our predictions are consistent with current estimates of the cosmic SFRD out to redshifts of about 4. 5, although they tend to overpredict it slightly beyond that redshift.- At low masses ( Mstar < 10 ^ 10 Msun ) there appears to be an excess of blue galaxies relative to reddish galaxies in both the real Universe and in our simulations.This may indicate that either our treatment of supernova feedback and / or reionization physicist needs improvement, or else that these processes have been impacted by baryonic effects not included in our simulation."
    },
    {
        "original_text": "We study the charm quark fragmentation into hadrons in perturbative QCD by using an effective coupling constant, which is determined so as to reproduce the experimental data on the total cross section for e+e-annihilation into hadrons at high energies.  We find that our results are consistent with those obtained within the framework of the conventional parton model and also with recent measurements performed by CLEO collaboration. The present analysis suggests that the charm quark fragmentation function can be well described by the Peterson form factor multiplied by a simple exponential function. \nPACS numbers: 11.10.Kk, 12.38.Qk, 13 .60.Hb \nI. INTRODUCTORY REMAR K\nIn this work we investigate the charm quark fragmentation functions (FFs) into light hadrons in perturbative quantum chromodynamics(pQCD). In particular, we use an effective coupling constant, αeff , which is determined so as t o reproduce the experimental data on thetotal cross section for e + e-annihilation into hadronsthat have been measured recentlybyCLEOcollaboration [1] .\nThe FFsof quarksintohadronicparticlesare important quantitiesin pQCDand they playanimportant role inthe calculationof various physical observables suchas the structurefunctions [2] ,the Drell-Yanprocess [3] ,and the semi-leptonic decay [4] . It hasbeen shownthat the FFsof quarksintohadronscan be calculatedperturbatively [5] - [8] . However, it shouldbe notedthatthe calculationsrequire veryhighenergy scales [9] . Therefore,it would be usefulto determineαefffromexperimentaldataat relativelylowenergies [10] .",
        "watermark_text": "We study the charm quark fragmentation into hadrons in perturbative QCD by utilizing an effective coupling constant, which is determined so as to reproduce the experiment data on the total cross section for e + e - annihilation into hadrons at high energies.We find that our results are consistent with those obtained within the framework of the traditional parton paradigm and additionally with recent measurements performed by CLEO collaboration.The present analysis suggests that the charm quark fragmentation function can be well described by the Peterson form factor multiplied by a simple exponential factor.PACS numbers : 11. 10. Kk, 12. 38. Qk, 13. 60. Hb I. INTRODUCTORY REMAR KIn this work we investigate the charm quark fragmentation functions ( FFs ) into light hadrons in perturbative quantum chromodynamics ( pQCD ).In particular, we use an effective coupling constant, αeff, which is determined so as t o reproduce the experimental data on thetotal cross section for e + e - annihilation into hadronsthat have been measured recentlybyCLEOcollaboration[ 1 ].The FFsof quarksintohadronicparticlesare important quantitiesin pQCDand they playanimportant role inthe calculationof various physical observables suchas the structurefunctions[ 2 ], the Drell - Yanprocess[ 3 ], and the semi - leptonic decay[ 4 ].It hasbeen shownthat the FFsof quarksintohadronscan be calculatedperturbatively [ 5 ] -[ 8 ].However, it shouldbe notedthatthe calculationsrequire veryhighenergy scales [ 9 ].Therefore, it would be usefulto determineαefffromexperimentaldataat relativelylowenergies [ 10 ]."
    },
    {
        "original_text": "We introduce the notion of covering homology, which is an extension of ordinary homology to infinite graphs and simplicial complexes. The main idea behind this concept is that we consider not only finite subcomplexes but also their infinite analogues - so-called coverings. We show how covering homology can be used for studying properties of infinite graphs such as amenability or hyperbolicity. In particular, we prove that if a graph has infinitely many ends then its first covering homology group vanishes. This result generalizes the classical theorem by Stallings on groups with infinitely many ends. Covering homology provides us with new tools for investigating various classes of infinite objects in mathematics. It turns out that it is closely related to other concepts like equivariant homology theory (in the case when our object admits actions of some group) or higher-order algebraic K-theory. Finally, we present several examples illustrating applications of covering homology.",
        "watermark_text": "We introduce the notion of covering homology, which is an extension of ordinary homology to infinite graphs and simplicial complexes.The main idea behind this concept is that we consider not only finite subcomplexes but also their endless analogues - so - named coverings.We show how covering homology can be used for studying properties of infinite graphs such as amenability or hyperbolicity.In particular, we prove that if a graph has infinitely many ends then its first covering homology group vanishes.This result generalizes the classical theorem by Stallings on groups with infinitely numerous ends.Covering homology provides us with fresh tools for investigating various classes of infinite items in mathematics.It turns out that it is well related to other concepts like equivariant homology theory ( in the case when our object admits actions of some group ) or upper - order algebraic K - theory.Finally, we present several examples illustrating applications of coverage homology."
    },
    {
        "original_text": "We report on an experimental study of the spin-dependent properties of a two-dimensional electron system in GaAs/AlGaAs quantum wells by means of polarized light scattering (PL) and magneto-optical spectroscopy (Raman). The PL experiments are performed at low temperatures, where we observe circularly polarized emission with opposite helicity for right- and left-circularly polarized excitation. We show that this effect is due to the presence of a strong exchange interaction which leads to a splitting of the excitonic states into two branches corresponding to different spins of the carriers. In addition, we find that the degree of circular polarization depends strongly on temperature and magnetic field strength. By comparing our results with those obtained by polarized Raman scattering under similar conditions, we demonstrate that both techniques provide complementary information about the electronic structure of the investigated samples. Our findings can be used as input parameters for theoretical models describing the transport phenomena in semiconductor nanostructures.",
        "watermark_text": "We report on an experimental study of the spin - dependent properties of a two - dimensional electron system in GaAs / AlGaAs quantum wells by means of polarized light scattering ( PL ) and magneto - optical spectroscopy ( Raman ).The PL experiments are performed at low temperatures, where we observe circularly polarized emission with opposite helicity for right - and left - circularly polarized excitation.We show that this effect is due to the existence of a strong exchange interaction which results to a splitting of the excitonic states into two branches corresponding to separate spins of the carriers.In addition, we find that the degree of circular polarization depends strongly on temperature and magnetic field strengthening.By comparing our results with those obtained by polarized Raman scattering under similar conditions, we demonstrate that both techniques provide complementary information about the electronic structure of the investigated samples.Our findings can be used as input parameters for theoretical models describing the transfer phenomena in semiconductor nanostructures."
    },
    {
        "original_text": "We present the first version of our new code, WHAM (Weno-Hybrid Arbitrary Mesh), which is based on the recently developed weighted essentially non-oscillatory (WENO) schemes for solving hyperbolic conservation laws in one dimension and multi-dimensions.  The main idea behind this method is to use high-order spatial reconstruction with an adaptive mesh refinement technique to achieve high accuracy at low computational cost. We have implemented several different versions of the WENO algorithm into our code including the fifth-order WENO-Z scheme as well as the third- and fifth-order WENO-JS schemes. In addition we also implement the fourth-order Runge-Kutta time integration scheme along with the Harten-Lax-van Leer contact discontinuity capturing scheme to handle discontinuities arising during hydrodynamic evolution. Our results show that all these algorithms are able to produce accurate solutions when compared against exact or reference solutions.",
        "watermark_text": "We present the first version of our new code, WHAM ( Weno - Hybrid Arbitrary Mesh ), which is based on the recently developed weighted essentially non - oscillatory ( WENO ) schemes for solving hyperbolic conservation laws in one dimension and multi - dimensions.The main idea behind this method is to utilize high - order spatial reconstruction with an adaptive mesh refinement technique to achieve maximum accuracy at low computational price.We have implemented several different versions of the WENO algorithm into our code including the 5th - order WENO - Z scheme as ill as the third - and fifth - order WENO - JS schemes.In addition we also implement the fourth - order Runge - Kutta time integration scheme along with the Harten - Lax - van Leer contact discontinuity capturing scheme to handle discontinuities arising during hydrodynamic evolution.Our results show that all these algorithms are able to produce accurate solutions when compared against exact or reference solutions."
    },
    {
        "original_text": "We report on electrical transport measurements through individual biphenyl dithiol molecules connected to gold electrodes by using scanning tunneling microscopy break-junction technique at room-temperature (RT) and low temperatures down to 4 K. The current–voltage characteristics show clear signatures for molecular conduction, such as Coulomb blockade peaks and negative differential resistance regions. We find that the junction conductance depends strongly on the tilt angle between the molecule backbone and the substrate normal. This is explained by an anisotropic coupling strength between the molecule and the metal contacts which leads to different transmission probabilities along the two main axes of the molecule. In addition we observe a strong temperature dependence of the junction conductance with a maximum around 50 K. These results are discussed within a model based on electron-phonon scattering processes. Biphenyl dithiol (BDT), one of the most studied organic semiconductors, has been used extensively in field-effect transistors1-5 and other electronic devices6-8 due to its high charge carrier mobility9-11. However, despite intensive research efforts12-17 only few studies have investigated the electrical properties of BDT-based single-molecule junctures18-20. Herein, we present detailed investigations of the electrical transport behavior of individual BDT molecules contacted via Au(111) surfaces by means of scanning tunneling microscopy breakjunction experiments21-23. Our data reveal pronounced features characteristic for molecular conduction24-26 including Coulomb blockade peaks27-29 and negative differential resistance30-32. Furthermore, our study reveals a strong influence of the molecular orientation relative to the substrate surface on the junction conductance33-35. Finally, we demonstrate a significant temperature dependent change of the junction conductance36-38.",
        "watermark_text": "We report on electrical transfer measurements through individual biphenyl dithiol molecules connected to gold electrodes by using scanning tunneling microscopy break - junction technique at room - temperature ( RT ) and low temperatures down to 4 K. The current – voltage characteristics show clear signatures for molecular conduction, such as Coulomb blockade peaks and negative differential resistance regions.We find that the junction conductance depends strongly on the tilt angle between the molecule backbone and the substrate normal.This is explained by an anisotropic coupling strength between the molecule and the metal contacts which leads to different transmission probabilities along the 2 main axes of the molecule.In addition we observe a strong temperature dependence of the junction conductance with a maximum around 50 K. These results are discussed within a model based on electron - phonon scattering processes.Biphenyl dithiol ( BDT ), one of the most studied organic semiconductors, has been used extensively in field - effect transistors1 - 5 and other electrical devices6 - 8 due to its high charge carrier mobility9 - 11.However, despite intensive research efforts12 - 17 only few studies have investigated the electrical properties of BDT - based single - molecule junctures18 - 20.Herein, we present detailed investigations of the electrical transport behavior of individual BDT molecules contacted using Au ( 111 ) surfaces by means of scanning tunneling microscopy breakjunction experiments21 - 23.Our data reveal pronounced features characteristic for molecular conduction24 - 26 including Coulomb blockade peaks27 - 29 and negative differential resistance30 - 32.Furthermore, our study reveals a strong influence of the molecular orientation relative to the substrate surface on the junction conductance33 - 35.Finally, we demonstrate a significant temperature dependent change of the junction conductance36 - 38."
    },
    {
        "original_text": "We study the mechanical response to uniaxial compression and extension of an elastic-plastic continuum model with a nonlinear kinematic hardening rule, which is motivated by recent experiments on metallic glasses. The plastic deformation mechanism consists of localized shear-transformation zones (STZs) that are randomly distributed throughout the sample volume at zero stress. We show that this simple model can reproduce many features observed experimentally such as serrated yielding, strain softening after yield, and pronounced anisotropy during flow. In particular we find that the STZ density increases rapidly near the onset of plasticity but then decreases slowly until it reaches its steady-state value. This behavior leads to a characteristic peak in the macroscopic stress-strain curve just before the final collapse into a densely packed state. Finally, we discuss how our results relate to previous theoretical work based on mean-field approximations. DOI: 10.1103/PhysRevE.77.020101",
        "watermark_text": "We study the mechanical response to uniaxial compression and extension of an elastic - plastic continuum model with a nonlinear kinematic hardening rule, which is motivated by recent experiments on metallic glasses.The plastic deformation mechanism consists of localized shear - transformation zones ( STZs ) that are randomly distributed across the sample volume at 0 stress.We show that this simple model can reproduce many features observed experimentally such as serrated yielding, tension softening after yield, and pronounced anisotropy during flow.In particular we find that the STZ density increases rapidly near the onset of plasticity but then decreases slowly until it reaches its steady - state value.This behavior leads to a characteristic peak in the macroscopic stress - strain curve just before the final collapse into a densely crowded state.Finally, we discuss how our results relate to previous theoretical work based on mean - field approximations.DOI : 10. 1103 / PhysRevE. 77. 020101"
    },
    {
        "original_text": "We present new observations and analysis of the pulsar–disk system PSR 1257+12, which is one of only two known systems in which a millisecond radio pulsar orbits around an evolved star (a white dwarf). We have obtained high-resolution near-infrared images with adaptive optics at Keck Observatory that reveal a bright ring-like structure surrounding the pulsar's position. This feature has been interpreted as emission from dust grains orbiting within the disk produced by the supernova explosion that created both stars. \n \n In addition to this ring, we detect faint extended emission extending out to several hundred AU on either side of the central source. These features are consistent with previous results based on lower resolution data. However, our higher spatial resolution reveals additional details about these structures. For example, we find evidence for spiral arms in the outer regions of the disk, which may be caused by gravitational interactions between the disk and the binary companion.",
        "watermark_text": "We present fresh observations and analysis of the pulsar – disk system PSR 1257 + 12, which is one of only two known systems in which a millisecond radio pulsar orbits around an evolved star ( a white dwarf ).We have obtained high - resolution near - infrared images with adaptive optics at Keck Observatory that reveal a bright ring - like structure surrounding the pulsar ' s position.This feature has been interpreted as emission from dust grains orbiting within the disc produced by the supernova explosion that created both stars.In addition to this ring, we detect faint extended emission extending out to several hundred AU on either side of the central source.These features are consistent with previous results based on lower resolution data.However, our higher spatial resolution reveals additional details about these structures.For example, we find evidence for spiral arms in the outer regions of the disc, which may be caused by gravity interactions between the disk and the binary companion."
    },
    {
        "original_text": "We study the propagation of surface waves in a layered medium with different signs of nonlinear coefficients and show that, under certain conditions, localized solutions exist which are similar to those known as gap solitons in periodic structures. The existence domain for these solutions is determined by solving an eigenvalue problem numerically. We also present results on the stability properties of such solutions against small perturbations. Surface wave localization can be observed experimentally using optical waveguide arrays or photonic crystals. In this work we consider the case when two layers have opposite signs of nonlinearities (e.g., one positive and another negative). This situation occurs naturally if the material parameters change sign across some interface between media. For example, it may happen near the boundary between materials with normal dispersion and anomalous dispersion. \n \n We demonstrate that there exists a class of localized solutions which resemble gap solitons in periodic systems. These solutions appear due to the interplay between linear and nonlinear effects. They exist only within a finite range of frequencies and decay exponentially away from their center point. Their amplitude depends strongly on the ratio of the amplitudes of the incident and reflected waves.",
        "watermark_text": "We study the propagation of surface waves in a layered medium with different signs of nonlinear coefficients and show that, under certain conditions, localized solutions exist which are similar to those known as gap solitons in periodic structures.The existence domain for these solutions is determined by solving an eigenvalue problem numerically.We also present results on the stability properties of such solutions against little perturbations.Surface wave localization can be observed experimentally using optical waveguide arrays or photonic crystals.In this work we consider the case when two layers have opposite signs of nonlinearities ( e. g., one positive and one negative ).This situation occurs naturally if the material parameters change sign along some interface between media.For example, it may happen near the boundary between materials with normal dispersion and anomalous dispersion.We demonstrate that there remains a class of localized solutions which resemble gap solitons in periodic systems.These solutions appear due to the interplay between linear and nonlinear effects.They exist only within a finite range of frequencies and decay exponentially away from their center point.Their amplitude depends strongly on the ratio of the amplitudes of the incident and reflected waves."
    },
    {
        "original_text": "We report on the observation and analysis of molecular bound states in ultracold cesium atoms trapped by an optical lattice potential. The molecules are created using magnetic field induced Feshbach resonances at temperatures below 1 microkelvin. We measure their binding energies as functions of both magnetic field strength and laser intensity. These measurements allow us to determine the scattering length between two fermionic atoms with high precision. In addition we observe that the molecule formation rate is strongly enhanced when the trapping lasers are detuned into resonance with excited vibrational levels of the atomic ground state. This effect can be explained by stimulated emission processes which lead to rapid relaxation towards deeply bound molecular states. Finally we demonstrate how these results can be used for precise determination of the s-wave scattering lengths between different spin species. Our work opens up new possibilities for studying quantum many-body phenomena such as superfluidity or supersolidity in systems of interacting fermions. \n \n We present experimental data obtained during our study of ultracold cesium (Cs) atoms confined within an optical lattice trap. Using magnetic field induced Feshback resonances we create weakly bound Cs2 dimer molecules out of pairs of fermionic atoms. By measuring the binding energy of the molecules as function of magnetic field strength and laser power density we obtain accurate values for the scattering length between two Cs atoms. Furthermore we find that the molecule formation process is strongly enhanced if the trapping lasers have a frequency close to one of the atomic transitions. This effect can be understood by considering stimulated emission processes leading to fast relaxation towards deeply bound molecular levels.",
        "watermark_text": "We report on the observation and analysis of molecular bonded states in ultracold cesium atoms trapped by an optical lattice potential.The molecules are created using magnetic field induced Feshbach resonances at temperatures below one microkelvin.We measure their binding energies as functions of both magnetic field strength and laser intensity.These measurements allow us to determine the scattering length between two fermionic atoms with high precision.In addition we observe that the molecule formation rate is strongly enhanced when the trapping lasers are detuned into resonance with excited vibrational levels of the atomic ground state.This effect can be explained by stimulated emission processes which lead to rapid relaxation towards deeply bound molecular states.Finally we demonstrate how these results can be used for precise determination of the s - wave scattering lengths between different spin species.Our work opens up new possibilities for studying quantum many - body phenomena such as superfluidity or supersolidity in systems of interacting fermions.We present experimental data obtained during our study of ultracold cesium ( Cs ) atoms confined inside an optical lattice trap.Using magnetic field induced Feshback resonances we create weakly bound Cs2 dimer molecules out of pairs of fermionic atoms.By measuring the binding energy of the molecules as function of magnetic field strength and laser power density we obtain accurate values for the scattering length between 2 Cs atoms.Furthermore we find that the molecular formation process is heavily enhanced if the trapping lasers have a frequency close to one of the atomic transitions.This effect can be understood by considering stimulated emission processes leading to fast relaxation towards deeply bound molecular levels."
    },
    {
        "original_text": "We present Spitzer Space Telescope observations in the mid- to far-infrared (5.8 - 160 microns) for a sample of distant galaxies selected by their rest-frame ultraviolet luminosity density at 1600 angstroms, and compare these flux densities with those predicted using models that include dust extinction.  We find that the observed infrared emission is generally higher than expected based on the UV continuum slope alone; this excess emission can be explained if there are significant amounts of cold dust associated with star formation activity in these systems.   The results suggest that the majority of the energy produced by young stars may not escape into intergalactic space but instead is reprocessed by interstellar dust grains before being re-radiated in the infrared. This work was supported by NASA through grants NAG5-9998 and NAS8-38252 issued by JPL/Caltech under contract NAS8-39073. It has been assigned the following DOI: 10.1086/505283",
        "watermark_text": "We present Spitzer Space Telescope observations in the mid - to far - infrared ( 5. 8 - 160 microns ) for a sample of remote galaxies selected by their rest - frame ultraviolet luminosity density at 1600 angstroms, and compare these flux densities with those predicted using models that include dust extinction.We find that the observed infrared emission is generally higher than expected based on the UV continuum slope alone ; this excess emission can be explained if there are significant levels of cold dust involved with stellar formation action in these systems.The results suggest that the majority of the energy produced by early stars may not flee into intergalactic space but instead is reprocessed by interstellar dust grains before being re - radiated in the infrared.This work was supported by NASA through grants NAG5 - 9998 and NASA8 - 38252 issued by JPL / Caltech under contractor NAS8 - 39073.It has been assigned the following DOI : 10. 1086 / 505283"
    },
    {
        "original_text": "We report on the detection and characterization of microwave continuum emission from air shower plasmas using data collected by the LOPES experiment in Germany during 2004-2006. The observed signal is consistent with that expected for coherent Cherenkov radiation emitted by relativistic electrons accelerated to energies up to 100 MeV within the showers, as predicted by theory. We find no evidence for any significant contribution from incoherent synchrotron or bremsstrahlung processes. These results provide new insights into the physics of cosmic ray interactions at high energy. They also demonstrate the potential utility of radio techniques for studying atmospheric phenomena such as thunderstorms. \n \n Keywords: Cosmic rays, Radio waves, Air showers, Coherence, Synchrotron radiation \n \n \n \n 1 Introduction \n \n In recent years there has been growing interest in developing novel methods for detecting ultra-high-energy (UHE) cosmic rays based upon their interaction with Earth's atmosphere [1] . One promising technique involves measuring the radio-frequency (RF) emission produced when UHE particles interact with molecules in the upper atmosphere [2] , which can be detected remotely over large areas [3] .\n \nThe most prominent feature of this RF emission is an intense broadband pulse lasting several microseconds [4] . This pulse arises because the charged particle cascade generated by each primary cosmic ray interacts strongly with the geomagnetic field, causing it to emit coherently across a wide range of frequencies [5] . However, other mechanisms may contribute significantly to the total RF emission [6] . \n \n Here we present observations made with the Low-Frequency Array (LOFAR), one component of the International LOFAR Telescope [7] . Our analysis focuses primarily on measurements taken between 2004 and 2006 with the Long Wavelength Array (LWA) [8] , a phased array consisting of 144 dual-polarized dipole antennas operating at wavelengths ranging from 10 m to 80 m [9] . During these three years, LWA was deployed near Karthaus Township, Germany [10] , where it recorded signals from more than 20 million cosmic-ray-induced air showers [11] .",
        "watermark_text": "We report on the detection and characterization of microwave continuum emission from air shower plasmas using data collected by the LOPES experiment in German during 2004 - 2006.The observed signal is consistent with that expected for coherent Cherenkov radiation emitted by relativistic electrons accelerated to energies up to 100 MeV within the showers, as predicted by theory.We find no proof for any significant contribution from incoherent synchrotron or bremsstrahlung processes.These results provide new insights into the physics of cosmic ray interactions at high energy.They also demonstrate the possible utility of radio techniques for studying atmospheric phenomena such as thunderstorms.Keywords : Cosmic rays, Radio waves, Air showers, Coherence, Synchrotron radiation 1 Introduction In recent years there has been growing interest in developing new methods for detectoring ultra - highly - energy ( UHE ) galaxies rays based upon their interaction with Earth ' s atmosphere[ 1 ].One promising technique involves measuring the radio - frequency ( RF ) emission produced when UHE particles interact with molecules in the higher atmosphere[ 2 ], which can be detected remotely over large areas[ 3 ].The most prominent feature of this RF emission is an intense broadband pulse lasting several microseconds [ 4 ].This pulse arises because the charged particle cascade generated by each primary cosmic ray interacts strongly with the geomagnetic field, causing it to emit coherently across a wide range of frequencies [ 5 ].However, other mechanisms may contribute significantly to the total RF emission [ 6 ].Here we present observations made with the Low - Frequency Array ( LOFAR ), 1 component of the International LOFAR Telescope [ 7 ].Our analysis focuses primarily on measurements taken between 2004 and 2006 with the Long Wavelength Array ( LWA )[ 8 ], a phased array consisting of 144 dual - polarized dipole antennas operating at wavelengths ranging from 10 m to 80 m [ 9 ].During these three years, LWA was deployed near Karthaus Township, Germany[ 10 ], where it recorded signals from more than 20 million cosmic - ray - induced air showers[ 11 ]."
    },
    {
        "original_text": "We propose DNA hash pooling (DHP) as an efficient data structure for storing large volumes of biological sequences in compressed form, with applications to sequence alignment, database search, and genome assembly. DHP is based on the concept that similar sequences have common substrings which can be represented by short binary codes called hashes. The main idea behind our approach is to store all possible hashes instead of storing each individual sequence separately. We show how this method can be used to compress large collections of biological sequences into small files while still allowing fast searches using standard string matching algorithms such as Boyer-Moore-Horspool or Rabin-Karp. In addition we present several novel applications of DHP including a new algorithm for finding exact matches between two sets of sequences without any prior knowledge about their lengths. Finally, we demonstrate the usefulness of DHP through experiments conducted on real-world datasets containing millions of human genomes.",
        "watermark_text": "We propose DNA hash pooling ( DHP ) as an efficient data structure for storing big volumes of bio sequences in compressed form, with applications to sequence alignment, database search, and genome assembly.DHP is based on the concept that comparable sequences have common substrings which can be represented by short binary codes called hashes.The main idea behind our approach is to store all possible hashes rather of storing each single sequence separately.We show how this method can be used to compress big collections of biological sequences into little files while still enabling fast searches via standard string matching algorithms such as Boyer - Moore - Horspool or Rabin - Karp.In addition we present several novel applications of DHP including a novel algorithm for finding exact matches between two sets of sequences without any previous knowledge about their lengths.Finally, we demonstrate the usefulness of DHP through experiments conducted on real - world datasets containing millions of human genomes."
    },
    {
        "original_text": "We present new observations of water maser emission toward the nuclear disk (ND) and circumnuclear ring (CNR) of NGC 1068, made with the Very Long Baseline Array at 22 GHz. The CNR is detected for the first time in water maser emission; it has an extent of ~1 kpc along its major axis and contains several hundred individual maser spots. We find that the distribution of maser luminosities follows closely that of infrared continuum emission observed by Spitzer Space Telescope. This suggests that both are tracing similar physical conditions within the molecular gas. In addition to the CNR, we detect maser emission associated with two other structures: a bright spot located near the center of the ND and a second fainter region extending over ~500 pc southward from this central position. These three regions have different kinematics, suggesting they may be physically distinct components. Finally, we report on the detection of methanol maser emission coincident with one of these water maser features.",
        "watermark_text": "We present new observations of water maser emission toward the nuclear disk ( ND ) and circumnuclear ring ( CNR ) of NGC 1068, made with the Very Long Baseline Array at 22 GHz.The CNR is detected for the first time in water maser emission ; it has an amount of ~ 1 kpc along its main axis and contains several hundred individual maser spots.We find that the distribution of maser luminosities follows closely that of infrared continuum emission observed by Spitzer Space Telescope.This suggests that both are tracing similarly physical conditions within the molecular gas.In addition to the CNR, we detect maser emission associated with 2 other structures : a bright point located near the center of the ND and a second fainter region extending over ~ 500 pc southward from this central position.These three regions have different kinematics, suggesting they may be physically distinct components.Finally, we report on the detection of methanol maser emission coincident with one of these water maser features."
    },
    {
        "original_text": "We study the Minimal Supersymmetric Standard Model (MSSM) in which all scalar superpartners are assumed to be very massive, and we show that it is possible for this model to have light neutralinos as dark matter candidates while still being consistent with current experimental bounds on supersymmetry.  We find that there exists an upper bound on the mass of the lightest neutralino, mχ0 1 < 104 GeV/c2 , above which no solution can exist within our framework. This limit arises because the LSP must decay into gravitinos before Big Bang Nucleosynthesis; if its lifetime exceeds 1s then too much entropy will be produced by late decays to satisfy observational constraints. The lower bound on mχ0 1 depends upon tanβ . For large values of tanβ , mχ0 1 > 60GeV/c2 ; however, for small values of tanβ , solutions with mχ0 1 = O(10GeV/c2 ) may occur.",
        "watermark_text": "We study the Minimal Supersymmetric Standard Model ( MSSM ) in which all scalar superpartners are presumed to be very massive, and we show that it is possible for this model to have light neutralinos as dark matter candidates while still being consistent with current experimental bounds on supersymmetry.We find that there exists an higher bound on the mass of the lightest neutralino, mχ0 1 60GeV / c2 ; however, for tiny values of tanβ, solutions with mχ0 1 = O ( 10GeV / c2 ) may occur."
    },
    {
        "original_text": "The first law of thermodynamics is usually presented as an assertion about entropy, but it can be derived in other ways.  This article presents one such derivation using statistical mechanics and information theory.   The result is that entropy is defined by the amount of uncertainty associated with a system's state (or lack thereof).   Entropy increases when there are more possible states for which we cannot predict what will happen to the system.   In this sense, entropy measures how much our knowledge decreases when we learn something new about the world around us.   ...   ...   ...   ...   The second law of thermodynamics asserts that entropy always increases over time.   However, if you look closely at the definition of entropy given above, you'll see that it's not clear whether or not entropy actually does increase over time.   To answer this question, let's consider two different systems, A and B, both of which start out in equilibrium.   System A has only one possible configuration while system B has many possible configurations.   If we were able to observe these systems, we'd find that they have exactly the same energy levels and temperatures.   But now imagine that we're observing them through a tiny window so that we can't tell what's going on inside each system.   We'd then conclude that system A looks like its temperature was higher than system B because there's less uncertainty about its future behavior.   Now suppose that we let system A evolve into system C, where all particles are arranged in perfect order.   Then system C would appear colder than system A even though their energies remained unchanged.   So far we've seen that entropy doesn't necessarily increase over time.   It could decrease instead....",
        "watermark_text": "The first law of thermodynamics is usually presented as an assertion about entropy, but it can be derived in other ways.This article presents one such derivation using statistical mechanics and information theory.The result is that entropy is defined by the amount of uncertainty associated with a system ' s state ( or without thereof ).Entropy increases when there are more possible states for which we cannot predict what will happen to the system.In this sense, entropy measures how much our knowledge decreases when we learn something new about the world around us.....The second law of thermodynamics asserts that entropy always rises over time.However, if you look closely at the definition of entropy given above, you ' ll see that it ' s not clear whether or not entropy actually does increase over time.To answer this question, let ' s consider 2 different systems, A and B, both of which start out in balance.System A has only one possible configuration while system B has many possible configurations.If we were able to observe these systems, we ' d find that they have exactly the same energy levels and temperatures.But now imagine that we ' re observing them through a tiny window so that we can ' t know what ' s coming on inside each system.We ' d then conclude that system A looks like its temperature was higher than system B because there ' s less uncertainty about its future behavior.Now suppose that we let system A evolve into system C, where all particles are arranged in perfect order.Then system C would appear colder than system A even though their energies remained unchanged.So far we ' ve seen that entropy doesn ' t necessarily rise over time.It could reduce instead."
    },
    {
        "original_text": "We study the evolutionarily stable strategy (ESS) and its stability properties for a class of ultimatum games with two-sided incomplete information, where one player is informed about his opponent's type while the other has no such information. We show that there exists a unique ESS which coincides with the Nash equilibrium if the set of types is finite or compactly supported on [0, 1] . If this set contains unbounded elements then we prove that the ESS may be unstable under small perturbations of the payoff functions. In particular, it can be shown that any ESS must satisfy certain conditions related to the distribution function of the types. Finally, we present some numerical examples illustrating our results. The evolutionary game theory studies how strategies evolve over time when players interact repeatedly within large populations. It provides a natural framework for analyzing strategic interactions between self-interested agents who are unable to commit themselves ex-ante but have the opportunity to learn by observing past play. A typical example of such situation arises in bargaining problems where each agent makes offers sequentially without knowing what proposals will be made by their opponents. This problem was first studied by Guth et al. (1982) , who introduced the so-called ultimatum game as a model of bargaining between two selfish individuals. In this game, Player 1 proposes a division of a fixed amount of money M into shares x and y = M −x offered to himself and Player 2 respectively; Player 2 either accepts or rejects the offer. If he accepts, both players receive their respective shares according to the proposal; otherwise they get nothing. Since the seminal work of Guth et al., many authors have investigated various aspects of the ultimatum game including existence and multiplicity of equilibria, efficiency loss due to lack of commitment power etc. (see e.g. Binmore & Shaked, 1993; Ochs & Roth, 1989) . However, all these works assume complete information among the players.",
        "watermark_text": "We study the evolutionarily steady strategy ( ESS ) and its stability properties for a class of ultimatum games with two - sided incomplete information, where one player is informed about his opponent ' s type while the other has no such information.We show that there exists a unique ESS which coincides with the Nash equilibrium if the set of types is finite or compactly supported on [ 0, 1 ].If this set contains unbounded elements then we prove that the ESS may be unstable under little perturbations of the payoff functions.In particular, it can be shown that any ESS must satisfy certain conditions related to the distribution function of the types.Finally, we present some numerical examples illustrating our results.The evolutionary game theory studies how strategies develop over time when players interact repeatedly within large populations.It provides a natural framework for analyzing strategic interactions between self - interested agents who are unable to commit themselves ex - ante but have the chance to learn by observing past play.A typical example of such situation arises in bargaining problems where each agent makes offers sequentially without learning what proposals will be made by their opponents.This problem was first studied by Guth et al. ( 1982 ), who introduced the so - called ultimatum game as a model of bargaining between 2 selfish individuals.In this game, Player 1 proposes a division of a fixed amount of amount M into shares x and y = M −x offered to himself and Player 2 respectively ; Player 2 either accepts or rejects the offer.If he accepts, both players receive their respective shares according to the proposal ; otherwise they get nothing.Since the seminal work of Guth et al., many writers have investigated various aspects of the ultimatum game including existence and multiplicity of equilibria, efficiency loss due to lack of commitment power etc.( see e. g. Binmore & Shaked, 1993 ; Ochs & Roth, 1989 ).However, all these works assume complete information among the musicians."
    },
    {
        "original_text": "We present deep radio observations at 1.4 GHz with the VLA towards two TeV gamma-ray emitting regions, one associated to the open cluster Cyg OB2 #8 (HESS J1640-465) and another located near the massive star WR 25 (HESS J1641-463). The new data reveal extended emission around both TeV sources which is not detected by previous surveys. We discuss possible scenarios for this emission based on our results as well as those obtained recently by other authors. In particular we propose that the observed structures are due to synchrotron radiation produced by relativistic electrons accelerated in shocks driven by stellar winds interacting within these clusters. This scenario would also explain why no X-ray counterparts have been found so far despite deep searches carried out with Chandra and XMM-Newton telescopes. Finally, we estimate the magnetic field strength required to produce such emission using standard models for particle acceleration in colliding wind binaries. \nIntroduction\n\nThe Cygnus OB2 association contains more than 100 OB stars distributed over an area of about 50 square degrees centered at l = 80°and b = 1° (  Fig.   1a ). It has been suggested that many of them could be members of binary systems or even multiple systems (e.g., Knödlseder 2000; Wright et al. 2010) . These objects can drive powerful winds into their surroundings creating strong shocks where particles may be accelerated up to very high energies. If some of these particles escape from the shock fronts they will interact with photons coming from the surrounding interstellar medium producing high-energy electromagnetic radiation detectable across most of the electromagnetic spectrum including the TeV range. \n \n Several studies suggest that several of the known TeV sources in the sky might be related to young open clusters like Cyg OB2 (see e.g., Aharonian et al. 2005a ,b, 2007a . However, only few of these associations have been confirmed through multi-wavelength campaigns involving optical/infrared imaging, spectroscopy and/or radio continuum observations (see e.g. , Reimer & Böttcher 2006 , Castro-Tirado et al",
        "watermark_text": "We present deep radio observations at 1. 4 GHz with the VLA towards two TeV gamma - ray emitting regions, one associated to the open constellation Cyg OB2 # 8 ( HESS J1640 - 465 ) and another located near the massive star WR 25 ( HESS J1641 - 463 ).The new data reveal extended emission surrounding both TeV sources which is not detected by previous surveys.We discuss possible scenarios for this emission based on our results as well as those obtained lately by other authors.In particular we propose that the observed structures are due to synchrotron radiation produced by relativistic electrons accelerated in shocks powered by stellar winds interacting within these clusters.This scenario would also answer why no X - ray counterparts have been found so far despite deep searches carried out with Chandra and XMM - Newton telescopes.Finally, we estimate the magnetic field strength needed to produce such emission using standard models for particle acceleration in colliding wind binaries.Introduction The Cygnus OB2 association contains more than 100 OB stars distributed over an area of about 50 square degrees centered at l = 80°and b = 1° ( Fig. 1a ).It has been suggested that several of them could be part of binary systems or even multiple ones ( e. g., Knödlseder 2000 ; Wright et al. 2010 ).These objects can drive powerful winds into their surroundings creating strong shocks where particles may be accelerated up to very high energies.If some of these particles escape from the shock fronts they will interact with photons coming from the surrounding interstellar medium producing high - energy electromagnetic radiation detectable across most of the electromagnetic spectrum including the TeV range.Several studies suggest that several of the known TeV sources in the sky might be related to young open clusters like Cyg OB2 ( see e. g., Aharonian et al. 2005a, b, 2007a.However, only few of these associations have been confirmed through multi - wavelength campaigns involving optical / infrared imaging, spectroscopy and / or radio continuum observations ( see e. g., Reimer & Böttcher 2006, Castro - Tirado imp al"
    },
    {
        "original_text": "We report on an analysis of archival Chandra data for the central region of the nearby starburst galaxy M82 (NGC 3034). We find that there are two bright, point-like sources in this field which have been previously identified as ULXs (Ultra-Luminous X-Ray Sources) by Swartz et al. (2004) . The first source is located at RA = 12 h 54 m 55 s .6 and Dec = 69°59'45'' with a count rate of 1.1 x 10^-3 counts sec-1. This source has a luminosity of 2 x 10^39 erg/sec assuming it lies at 8 kpc distance. The second source is located at RA=12h54m55s.7 and Dec=69°59'46'' with a count rate 0.9 x 10^-3 countssec-1. It also has a luminosity of about 2 x 10^39erg/sec if it lies at 8kpc. Both these sources appear to be variable over timescales ranging between hours and days.  These results suggest that both sources may contain black holes accreting close to their Eddington limit.",
        "watermark_text": "We report on an analysis of archival Chandra data for the central area of the nearby starburst galaxy M82 ( NGC 3034 ).We find that there are 2 bright, point - like sources in this field which have been previously identified as ULXs ( Ultra - Luminous X - Ray Sources ) by Swartz est al. ( 2004 ).The first source is located at RA = 12 h 54 m 55 s. 6 and Dec = 69°59 ' 45 ' ' with a count rate of 1. 1 × 10 ^ - three counts sec - 1.This source has a luminosity of 2 x 10 ^ 39 erg / sec assuming it lies at 8 kpc distance.The second source is located at RA = 12h54m55s. 7 and Dec = 69°59 ' 46 ' ' with a count rate 0. 9 × 10 ^ - 3 countssec - 1.It also has a luminosity of about 2 x 10 ^ 39erg / sec if it lies at 8kpc.Both these sources appear to be variable over timescales ranging between hours and days.These results suggest that both sources may contain black holes accreting close to their Eddington limit."
    },
    {
        "original_text": "We calculate the two-loop beta function for the coupling constant of the AdS5xS5 superstring theory and show that it is proportional to the one-loop result, which implies that there are no non-trivial fixed points at any finite value of the string coupling constant.  We also find that the dilaton field has an imaginary part when we take into account the higher-order terms beyond the leading order approximation. This indicates that our results may be valid only within some limited region of the parameter space where the imaginary part of the dilaton can be neglected. The present work was motivated by the recent study on the gauge/gravity correspondence between N=4 super Yang-Mills (SYM) theories with 16 supercharges and type IIB strings on AdS5xS5G5 backgrounds [1] . In this context, the existence of nontrivial fixed points would correspond to the conformal invariance of the dual SYM theories [2] , while the imaginary part of the dilatonic scalar fields would indicate the instability of the corresponding solutions [3] .\nIn Ref. [4] , the authors have calculated the one-loop beta functions for both the metric tensor and the dilaton field using the Green-Schwarz formalism [5] . They found that these beta functions do not vanish even if they are evaluated at vanishing values of the string coupling constants. However, their calculations were performed under the assumption that all the fermionic contributions vanish identically [6] . It turns out that such an assumption does not hold true [7, 8] . Therefore, it seems necessary to perform more detailed analysis taking into account the effects due to the fermions as well as those coming from the bosons.",
        "watermark_text": "We calculate the two - loop beta function for the coupling constant of the AdS5xS5 superstring theory and show that it is proportional to the one - loop result, which implies that there are no non - trivial fixed points at any finite value of the string coupling constant.We also find that the dilaton field has an imaginary part when we take into account the higher - order terms beyond the leader order approximation.This indicates that our outcomes may be valid only within some limited region of the parameter space where the imaginary part of the dilaton can be neglected.The present work was motivated by the recent research on the gauge / gravity correspondence between N = 4 super Yang - Mills ( SYM ) theories with 16 supercharges and type IIB strings on AdS5xS5G5 backgrounds[ 1 ].In this context, the existence of nontrivial fixed points would correspond to the conformal invariance of the dual SYM theories [ 2 ], while the imaginary portion of the dilatonic scalar fields would indicate the instability of the corresponding solutions [ 3 ].In Ref.[ 4 ], the authors have calculated the one - loop beta functions for both the metric tensor and the dilaton field using the Green - Schwarz formalism [ 5 ].They found that these beta functions do not vanish even if they are evaluated at vanishing values of the string pairing constants.However, their calculations were done under the assumption that all the fermionic contributions vanish identically [ 6 ].It turns out that such an assertion does not hold true [ 7, 8 ].Therefore, it seems necessary to perform more detailed analysis taking into account the effects due to the fermions as well as those coming from the bosons."
    },
    {
        "original_text": "We present the results on substructure analysis for a sample of 62 galaxy clusters observed with XMM-Newton and Chandra, selected from the Wide-field Infrared Survey Explorer (WISE) All-Sky survey. We use two different methods to identify substructures within each cluster: the Dressler & Shectman test and the Voronoi Tessellation technique. The main goal is to investigate how these techniques perform when applied to X-ray data only or combined with infrared photometry. Our findings show that both tests are able to detect significant substructures in most cases; however, they also highlight some differences between them. For example, we find that the Dressler & Shechter method tends to overestimate the number of substructures compared to the VTT one. Moreover, by combining optical/infrared information with X-ray data, it is possible to improve the detection efficiency up to 30%. Finally, we compare our results with those obtained using other samples of galaxy clusters detected through their Sunyaev-Zeldovich effect.",
        "watermark_text": "We present the results on substructure analysis for a sample of 62 galaxy clusters observed with XMM - Newton and Chandra, chosen from the Wide - field Infrared Survey Explorer ( WISE ) All - Sky survey.We utilize two different methods to identify substructures within each cluster : the Dressler & Shectman test and the Voronoi Tessellation technique.The main goal is to investigate how these techniques perform when applicable to X - ray data only or combined with infrared photometry.Our findings show that both tests are able to detect significant substructures in most cases ; however, they also highlight some differences between them.For example, we find that the Dressler & Shechter method tends to overestimate the number of substructures compared to the VTT one.Moreover, by combining optical / infrared information with X - ray data, it is possible to improve the detector efficiency up to 30 %.Finally, we compare our results with those obtained using other samples of galaxy clusters detected through their Sunyaev - Zeldovich influence."
    },
    {
        "original_text": "We introduce the concept of neutral networks, which are graphs that represent relationships between sequences and shapes in an unsupervised manner. We show how these can be used for shape recognition by training them on synthetic data generated using computer graphics techniques. The resulting network is able to recognize shapes with high accuracy even when they have been transformed or distorted. Finally we demonstrate our method on real world images showing its ability to generalize well beyond the training set. In this work we present a novel approach to learning about shapes through their relationship to sequences. Our main contribution is introducing the concept of neutral networks as a way to learn such relationships without supervision. Neutral networks are graphs whose nodes correspond to sequences (e.g., strings) and edges connect similar sequences. They provide a natural representation for capturing relationships between different types of information. For example, one could use a neutral network to capture relationships between sentences and documents, or between music notes and melodies. Here we focus on applying neutral networks to the problem of recognizing shapes based solely on their sequence of points sampled along their boundary. This task has many applications including medical image analysis where it may not always be possible to obtain ground truth labels due to privacy concerns.",
        "watermark_text": "We introduce the concept of neutral networks, which are graphs that representation relationships between sequences and shapes in an unsupervised manner.We show how these can be used for shape recognition by training them on synthetic data generated utilizing computer graphics techniques.The resulting network is able to recognise shapes with high accuracy even when they have been transformed or distorted.Finally we demonstrate our method on real world images showing its ability to generalize well beyond the training set.In this work we present a new approach to learning about shapes through their relationship to sequences.Our main contribution is introducing the concept of neutral networks as a means to learn such relationships without supervision.Neutral networks are graphs whose nodes correspond to sequences ( e. g., strings ) and edges connect similar sequences.They provide a natural representation for capturing relationships between different types of information.For example, one could use a neutral network to capture relations between sentences and documents, or between music notes and tunes.Here we focus on applying neutral networks to the problem of recognition shapes based solely on their series of points sampled along their border.This task has many applications including medical image analysis where it may not always be possible to obtain ground true labels due to private concerns."
    },
    {
        "original_text": "We present an efficient data redistribution scheme that allows the parallel execution of computations on dynamically resized computational domains in distributed memory environments. The proposed approach is based on multidimensional block-cyclic distributions and exploits locality by using space-filling curves to map blocks onto processors. We show how this technique can be used to efficiently redistribute data between different processor configurations, while minimizing communication overheads. Our experimental results demonstrate significant performance improvements over existing approaches when executing applications with dynamic load balancing requirements. In particular, we achieve speedups up to 3Â compared to state-of-the-art techniques such as the one presented in [1] . \nIntroduction\n\nParallel computing has become increasingly important due to its ability to solve large problems faster than serial computers [2] , but it also presents new challenges related to the distribution of work among multiple processing units [3] .\nIn order to take advantage of parallelism, many algorithms are designed so that they can run simultaneously on several processors [4] . However, these algorithms often require some form of data redistribution during their execution [5] . For example, consider a computation where each process stores part of a dataset (e.g., matrix) [6] . If the number of processes changes at runtime, then all processes need to exchange information about which parts of the dataset they store before continuing [7] . This problem becomes even more challenging if the size of the datasets stored by individual processes varies [8] or if there are dependencies between them [9] .",
        "watermark_text": "We present an efficient data redistribution scheme that allows the parallel execution of computations on dynamically resized computational domains in distributed memory environments.The proposed approach is based on multidimensional block - cyclic distributions and exploits locality by using space - filling curves to map blocks upon processors.We show how this technique can be used to efficiently redistribute data between different processor configurations, while minimizing communication overheads.Our experimental results demonstrate significant performance improvements over existing approaches when executing applications with dynamic burden balancing requirements.In particular, we achieve speedups up to threeÂ compared to state - of - the - artwork techniques such as the one presented in [ 1 ].Introduction Parallel computing has become increasingly important due to its ability to solution large problems faster than serial computers [ 2 ], but it also presents new challenges related to the distribution of work among multiple processing units [ 3 ].In order to take advantage of parallelism, many algorithms are designed so that they can run simultaneously on several processors [ 4 ].However, these algorithms often require some form of data redistribution during their execution [ 5 ].For example, consider a computation where each process storage part of a dataset ( e. g., matrix )[ 6 ].If the number of processes changes at runtime, then all processes need to exchange information about which portions of the dataset they store before proceeding [ 7 ].This problem becomes even more challenging if the size of the datasets stored by individual processes varies [ 8 ] or if there are dependencies between them [ 9 ]."
    },
    {
        "original_text": "We present new near-infrared integral field spectroscopy (IFS) data for the brightest galaxy in the cluster Abell 2218, which is known to be interacting with its nearest neighbor, the radio-quiet quasar I Zw 1 at z = 0.0625. We find that this galaxy has an extended low-surface-brightness component surrounding it, extending out to about 10 kpc on both sides along the major axis. This feature shows no evidence of rotation but does show some velocity structure consistent with infalling gas or tidal debris. In addition we detect two compact objects within 5 kpc of the center of the galaxy. One of these appears to have a very high surface brightness and may represent a nuclear starburst; however, the other one displays much lower surface brightness and could possibly be associated with a supermassive black hole binary system. These results are discussed in terms of possible evolutionary scenarios for this interacting pair.",
        "watermark_text": "We present newly near - infrared integral field spectroscopy ( IFS ) data for the brightest galaxy in the cluster Abell 2218, which is known to be interacting with its nearest neighbor, the radio - quiet quasar IZw 1 at z = 0. 0625.We find that this galaxy has an extended low - surface - brightness component surrounding it, extending out to about 10 kpc on both sides along the major axis.This feature shows no evidence of rotation but does show some velocity structure accordance with infalling gas or tidal debris.In addition we detect 2 compact objects within 5 kpc of the center of the galaxy.One of these appears to have a very steep surface brightness and may represent a nuclear starburst ; however, the other another displays much lower surface brightness and could possibly be associated with a supermassive black hole binary system.These results are discussed in terms of possible evolutionary situations for this interacting pair."
    },
    {
        "original_text": "We report the discovery of a new satellite galaxy, dubbed \"A pair of bootes\" (ApoBootes), orbiting around our Galaxy at a distance of about 300 kpc in projection and with an estimated mass of 1.5 x 10^10 M_sun . ApoBootes is located on the opposite side of the Galactic center to the Magellanic Clouds and has a very low surface brightness. We have used deep near-infrared images taken by the VISTA telescope as part of the Vista Variables in the Via Lactea survey to identify this object. The photometric properties are consistent with those expected for a dwarf spheroidal galaxy. This work was supported by the Australian Research Council Discovery Project funding scheme under grant DP130104011. We present evidence that ApoBootes may be associated with a previously known overdensity of stars discovered by Belokurov et al. (2007) using SDSS data.",
        "watermark_text": "We report the discovery of a new satellite galaxy, dubbed \" A pair of bootes \" ( ApoBootes ), orbiting near our Galaxy at a distance of about 300 kpc in projection and with an estimated mass of one. 5 × 10 ^ 10 M _ sun.ApoBootes is located on the opposite side of the Galactic center to the Magellanic Clouds and has a very low side brightness.We have used deep near - infrared images taken by the VISTA telescope as part of the Vista Variables in the Via Lactea survey to identify this object.The photometric properties are consistent with those expected for a dwarf spheroidal galaxy.This work was supported by the Australian Research Council Discovery Project funding scheme under grant DP130104011.We present evidence that ApoBootes may be associated with a previously known overdensity of stars discovered by Belokurov imp al. ( 2007 ) via SDSS data."
    },
    {
        "original_text": "We present Spitzer Infrared Spectrograph (IRS) observations of the nearby, interacting galaxy pair Mrk 297. The system consists of two galaxies separated by ~3 kpc in projection; one is an elliptical galaxy with a bright nuclear point source, while the other has a Seyfert 2 nucleus surrounded by extended emission lines. We detect several molecular hydrogen transitions including H$_2$ S(0), S(1), S(2), S(3), S(4), S(5), S(6), S(7), S(8), S(9), S(10), S(11), S(12), S(13), S(14), S(15), S(16), S(17), S(18), S(19), S(20). These are detected over a wide range of spatial scales ranging from <100 pc to >500 pc.",
        "watermark_text": "We present Spitzer Infrared Spectrograph ( IRS ) observations of the nearby, interacting galaxy pair Mrk 297.The system consists of two galaxies separated by ~ 3 kpc in projection ; one is an elliptical galaxy with a brilliant nuclear point source, while the other has a Seyfert 2 nucleus surrounded by extended emitted lines.We detect several molecular hydrogen transitions like H $ _ 2 $ S ( 0 ), S ( 1 ), S ( 2 ), S ( 3 ), S ( 4 ), S ( 5 ), S ( 6 ), S ( 7 ), S ( 8 ), S ( 9 ), S ( 10 ), S ( 11 ), S ( 12 ), S ( 13 ), S ( 14 ), S ( 15 ), S ( 16 ), S ( 17 ), S ( 18 ), S ( 19 ), S ( 20 ).These are detected over a wide range of spatial scales ranging from 500 pc."
    },
    {
        "original_text": "We have investigated the frequency distribution of semi-major axis (SMA) for wide binaries with separations greater than 1000 AU in order to test cosmogonies and dynamical evolution models. We used data obtained by the Two Micron All Sky Survey (2MASS), which is complete down to Ks = 12 mag, corresponding to masses as low as 0.1 M⊙ at distances up to 1 kpc. The sample consists of 13,000 pairs selected using color-color criteria designed to select main-sequence stars. Using Monte Carlo simulations we found that our results are not affected significantly by incompleteness effects due to photometric errors or contamination by background galaxies. Our analysis shows that there exists an excess number of systems with SMA between 10 4 -10 5 AU compared to predictions based on standard cosmological models. This result suggests that either these systems were formed earlier than predicted by current theories or they may be primordial objects such as Population III remnants.",
        "watermark_text": "We have investigated the frequency distribution of semi - major axis ( SMA ) for wide binaries with separations greater than 1000 AU in order to test cosmogonies and dynamical evolution models.We utilized data obtained by the Two Micron All Sky Survey ( 2MASS ), which is complete down to Ks = 12 mag, corresponding to masses as low as 0. 1 [UNK] at distances up to 1 kpc.The sample consists of 13, 000 pairs selected using color - color criteria designed to select main - chain stars.Using Monte Carlo simulations we found that our findings are not affected significantly by incompleteness effects due to photometric errors or pollution by background galaxies.Our analysis shows that there exists an excess number of systems with SMA between ten 4 - 10 5 AU compared to predictions based on standard cosmological models.This result suggests that either these systems were formed earlier than predicted by present theories or they may be primordial objects such as Population III remnants."
    },
    {
        "original_text": "Quantum repeaters are proposed to overcome the loss in quantum communication channels by using entangled photons and linear optics elements such as beam splitters, phase shifters, and single-photon detectors.  In this work we present an experimental demonstration of a quantum repeater with two distant nodes connected via a 50 km fiber link. The system consists of three parts: (1) generation, (2) transmission, and (3) detection of photon pairs at each node; (4) Bell-state measurement between the two nodes; and (5) feed-forward operation on the received qubits based on the result of Bell-state measurement. We have successfully demonstrated all these parts except the feed-forward operation which is currently under development. Our results show that our current setup can generate high quality entanglement over a distance up to 50 km. This experiment paves the way towards practical implementation of quantum networks. Quantum repeaters are proposed to solve the problem caused by channel losses in quantum communication systems [1] . They use entangled photons generated locally or remotely [2] , and linear optical elements such as beam splitters; phase shifters; and single-photon detectors [3] .\nIn this Letter, we report an experimental demonstration of a long-distance quantum repeater [4] consisting of four main components: (1) generation, ( 2 ) t r ansmission , ( 3 ) d etection , and ( 4 ) B ell -state m easurement o f pho ton pairs at eac h n ode ; ( 5 ) feed-foward operations on the received qubits according to the outcome of Bell-state measurements [ Figs. 1(a) , 1(b), and 2]. A pair of polarization-entangled photons was produced through spontaneous parametric down-conversion (SPDC). One photon acted as signal while another one served as idler. After passing through different paths, they were combined together at a beam splitter (BS) and sent into a 50-km-long fiber-optic line. At both ends of the fiber-optic line, photon-number resolving avalanche photodiodes (APDs) detected the",
        "watermark_text": "Quantum repeaters are proposed to overcome the loss in quantum communication channels by using entangled photons and linear optics elements such as beam splitters, phase shifters, and single - photon detectors.In this work we present an experimental demonstration of a quantum repeater with two distant nodes connected via a 50 km fibre link.The system consists of three parts : ( 1 ) generation, ( 2 ) transmission, and ( 3 ) detector of photon pairs at each node ; ( 4 ) Bell - state measurement between the two nodes ; and ( 5 ) feed - forward operation on the received qubits based on the result of Bell - state measurement.We have successfully shown all these portions except the feed - front operation which is currently under development.Our results show that our present setup can generate high quality entanglement over a distance up to 50 km.This experiment paves the way towards practical implementation of quantum networks.Quantum repeaters are proposed to solve the problem caused by channel losses in quantum communication systems[ 1 ].They use entangled photons generated locally or remotely [ 2 ], and linear optical elements such as beam splitters ; phase shifters ; and single - photon detections [ three ].In this Letter, we report an experimental demonstration of a long - distance quantum repeater[ 4 ] consisting of four main components : ( 1 ) generation, ( 2 ) t r ansmission, ( 3 ) d etection, and ( 4 ) B ell- statem easuremento f pho ton pairs at eac h n ode ; ( 5 ) feed - foward operations on the received qubits according to the outcome of Bell - state measurements [ Figs. 1 ( a ), 1 ( b ), and 2 ].A pair of polarization - entangled photons was produced through spontaneous parametric down - convert ( SPDC ).One photon acted as signal while another one served as idler.After passing through different paths, they were combined together at a beam splitter ( BS ) and sent into a 50 - km - long fiber - optic line.At both ends of the fiber - optic line, photon - number resolving avalanche photodiodes ( APDs ) detected the"
    },
    {
        "original_text": "We give explicit formulae for the product of two Ozsvath-Szab o 4-dimensional manifold invariants in terms of their associated modular forms and theta functions.  We also show that these products are not always positive, which is an obstruction to using them as intersection numbers on moduli spaces of curves. The results presented here were obtained by applying techniques developed by Vafa-Witten and Witten-Taubes to the case of genus 2 Riemann surfaces with four punctures. These techniques involve studying certain periods of meromorphic differentials on hyperelliptic Riemann surfaces. As such they can be used to study other problems involving hyperelliptic Riemann surface invariants. This article was published in Journal of Physics A: Mathematical and General 37 (2004) L55-L62. URL: http://arxiv.org/abs/0406.0366v1 . \nAuthors: David J. Jeffrey1 , Michael A. McMullen2 .\nAffiliation: 1University of California Santa Cruz, Santa Cruz, CA 95064, USA; 2University",
        "watermark_text": "We give direct formulae for the product of two Ozsvath - Szab o four - dimensional manifold invariants in terms of their corresponding modular forms and theta functions.We also show that these products are not always favorable, which is an obstruction to using them as intersection numbers on moduli spaces of curves.The results presented here were obtained by application techniques derived by Vafa - Witten and Witten - Taubes to the case of genus 2 Riemann surfaces with four punctures.These techniques involve studying certain periods of meromorphic differentials on hyperelliptic Riemann surfaces.As such they can be used to study other problems involving hyperelliptic Riemann surface invariants.This article was published in Journal of Physics A : Mathematical and General 37 ( 2004 ) L55 - L62.URL : http : / / arxiv. org / abs / 0406. 0366v1.Authors : David J. Jeffrey1, Michael A. McMullen2.Affiliation : 1University of California Santa Cruz, Santa Cruz, CA 95064, USA ; 2University"
    },
    {
        "original_text": "We present the results of an extensive survey for absorption lines in high-resolution spectra of quasars at redshifts z < 0.3, obtained with HST/STIS (the Hubble Space Telescope Spectrograph). The sample consists of 12 QSOs observed over a total exposure time of about 1 Ms. We detect more than 1000 Lyman alpha forest absorbers along each line-of-sight to these QSOs; we also find that most sight-lines show strong absorption by high-ionization species such as C IV and Si IV. In addition, we identify several hundred systems showing absorption due to highly ionized oxygen, O VI . These are among the strongest known O VI absorbers anywhere in the universe. By combining our data set with previous surveys, we obtain new constraints on the physical conditions of this gas phase. Our main conclusions are:  -The number density of O VI absorbers per unit redshift is n(O VI) = 2.6 +/- 0.4 x 10^-3 cm^-3 , which corresponds to a mean separation between absorber pairs of r = 4.1 +/- 0.5 h-1 Gpc.  -Most O VI absorbers have temperatures T ~ 10 5 K and densities log ne/cm -3 > 13.8. About half of them appear to be associated with galaxies within 50 kpc projected distance. -There appears to be no correlation between the properties of O VI absorbers and those of their host galaxy population.",
        "watermark_text": "We present the results of an extensive survey for absorption lines in high - resolved spectra of quasars at redshifts z 13. 8.About half of them appear to be associated with galaxies within 50 kpc projected distance.- There appears to be no correlation between the properties of O VI absorbers and those of their host galaxy population."
    },
    {
        "original_text": "We present new observations at 1 mm and 3 mm wavelengths toward two Giant Molecular Clouds (GMC) in the Small Magellanic: Cloud, LMC N11B and 30 Doradus. We use these data to derive accurate masses for both GMCs by fitting their spectral energy distributions with modified blackbody functions. The derived masses are M(LMC N11B) = 2.1 x 10^6 M_sol and M(30 Doradus) = 5.2 x 10^7 M_sol . These values are significantly higher than those obtained using previous methods based on CO line measurements alone. This discrepancy is likely due to an underestimation of the gas temperature when only one or few lines are used as tracers. Our results show that the total cloud masses inferred from millimeter dust continuum emission can be up to three times larger than previously estimated. Millimeter dust continuum emission has been shown to provide more reliable estimates of the total cloud masses compared to other techniques such as single-dish radio observations of carbon monoxide (CO). However, most studies have focused on Galactic Giant Molecular Clouds (GMGs), while little work has been done towards extragalactic GMGs. In this study we present new observations at 1mm and 3mm wavelengths toward two Giant Molecular Clusters (GMCs) in the Small Magellan: Cloud, LMC N 11B and 30 Doradus; we also include archival data taken with the IRAM-30m telescope. Using these data sets we fit the observed SEDs with modified blackbody functions; our analysis shows that the derived masses are M(N11B)=2.1x10^6M_sol and M(Doradus)=5.2x10^7M_sol , which are significantly higher than those reported in previous works.",
        "watermark_text": "We present fresh observations at one mm and 3 mm wavelengths toward two Giant Molecular Clouds ( GMC ) in the Small Magellanic : Cloud, LMC N11B and 30 Doradus.We use these data to derive accurate masses for both GMCs by fitting their spectral energetic distributions with modified blackbody functions.The derived masses are M ( LMC N11B )= 2. 1 x 10 ^ 6 M _ sol and M ( 30 Doradus )= 5. 2 x 10 ^ 7 M _ sol.These values are significantly greater than those obtained using prior methods based on CO line measurements alone.This discrepancy is likely due to an underestimation of the gas heat when only 1 or few lines are utilized as tracers.Our results show that the total cloud masses inferred from millimeter dust continuum emission can be up to 3 times bigger than previously estimated.Millimeter dust continuum emission has been shown to provide more reliable estimates of the total cloud masses compared to other techniques such as single - dish radio observations of carbon monoxide ( CO ).However, most studies have focused on Galactic Giant Molecular Clouds ( GMGs ), while little work has been put towards extragalactic GMGs.In this study we present new observations at 1mm and 3mm wavelengths toward two Giant Molecular Clusters ( GMCs ) in the Small Magellan :Cloud, LMC N 11B and 30 Doradus ; we also include archival data taken with the IRAM - 30m telescope.Using these data sets we fit the observed SEDs with modified blackbody functions ; our analytical shows that the derived masses are M ( N11B ) = 2. 1x10 ^ 6M _ sol and M ( Doradus ) = 5. 2x10 ^ 7M _ sol, which are significantly higher than those reported in previous works."
    },
    {
        "original_text": "We study the effect of adding a constant five-form field strength to type IIB supergravity on AdS5xS5 and its dual N=4 supersymmetric Yang-Mills theory in four dimensions. We find that this leads to an additional term in the action which is proportional to the volume form of S5, but does not affect any other fields or equations of motion. The resulting solution has a non-vanishing dilaton at infinity, corresponding to a deformation of the conformal symmetry group by a scale transformation. This can be interpreted as giving rise to a mass gap for all states except those transforming trivially under the unbroken SO(4) subgroup of SU (4). In particular we show how this mechanism allows one to generate masses for all gauge bosons without breaking supersymmetry. We also discuss some possible generalizations of our results. Introduction: It was shown recently [1] , using the gauged linear sigma model approach [2] , that it is possible to deform the maximally supersymmetric Yang-Mills (MSYM) theory in 4-dimensions such that only the vector multiplets acquire masses while preserving N = 1 supersymmetry. The authors showed that there are two different ways of doing this: either by turning on a constant three-form H-flux [3] or by introducing a constant fived-form F -flux [4] . They found that both these solutions preserve half of the original supersymmetries. However, they did not consider the possibility of having both types of fluxes simultaneously turned on. Here we will fill this gap and present new solutions where both H-and F -fluxes are turned on. These solutions have been obtained within the context of type IIA string theory compactified on K3 × T 2 [5] .\nThe plan of the paper goes as follows. First we review briefly the work done in ref. [1] . Then we introduce the ansatz for the metric and the forms when both H- and F -fluxes exist together. Next we solve the Einstein's equation and obtain the explicit expression for the metric. Finally we compute the spectrum",
        "watermark_text": "We study the effect of adding a fixed five - form field strong to type IIB supergravity on AdS5xS5 and its dual N = 4 supersymmetric Yang - Mills theory in 4 dimensions.We find that this leads to an additional term in the action which is proportional to the volume form of S5, but does not impact any other fields or equations of motion.The resulting solution has a non - vanishing dilaton at infinity, corresponding to a deformation of the conformal symmetric group by a scale transformation.This can be interpreted as giving rise to a mass gap for all states except those transforming trivially under the unbroken SO ( 4 ) subgroup of SU ( 4 ).In particular we show how this mechanism permits one to generate masses for all gauge bosons without cracking supersymmetry.We also discuss some potential generalizations of our results.Introduction : It was shown recently [ 1 ], using the gauged linear sigma model approach [ 2 ], that it is possible to deform the maximally supersymmetric Yang - Mills ( MSYM ) theory in four - dimensions such that only the vector multiplets acquire masses while preserving N = 1 supersymmetry.The authors showed that there are 2 different methods of doing this : either by switching on a consistent three - format H - flux [ 3 ] or by introducing a consistent fived - form F - flux [ 4 ].They found that both these solutions preserve half of the original supersymmetries.However, they did not consider the possibility of having both types of fluxes simultaneously turned on.Here we will fill this gap and present new solutions where both H - and F - fluxes are switched on.These solutions have been obtained within the context of type IIA string theory compactified on K3 × T 2[ 5 ].The plan of the paper goes as follows.First we review briefly the work done in ref.[ 1 ].Then we introduce the ansatz for the metric and the forms when both H - and F - fluxes exist together.Next we solve the Einstein ' s equation and obtain the explicitly expression for the metric.Finally we compute the spectrum"
    },
    {
        "original_text": "We use the Millennium Simulation to study how close pairs of galaxies evolve into galaxy clusters, and we show that they are good proxies for mergers between dark matter halos.  We find that most (>80%) of the mass in galaxy clusters is assembled through mergers with other galaxy clusters or groups rather than by merging individual galaxies.   The merger rate increases strongly towards higher redshifts, but it decreases rapidly at lower masses because of dynamical friction.    Our results suggest that galaxy cluster formation can be studied using large samples of close galaxy pairs selected from optical surveys such as SDSS. This work was supported by NASA grant NAG5-12140. We thank J. S. Bullock, A. Kravtsov, D. Cohn, R. H. Richstone, B. Tinker, E. Tozzi, P. van Kampen, and W. Zhang for useful discussions.",
        "watermark_text": "We use the Millennium Simulation to study how near pairs of galaxies evolve into galaxy clusters, and we show that they are good proxies for mergers between dark matter halos.We find that most ( > 80 % ) of the mass in galaxy clusters is assembled through mergers with other galaxy clusters or groups rather than by merging individual galaxies.The merger rate increases strongly towards higher redshifts, but it reduces rapidly at lesser masses because of dynamical friction.Our results suggest that galaxy cluster formation can be studied using large samples of close galaxy couples selected from optical surveys such as SDSS.This work was supported by NASA grant NAG5 - 12140.We thank J. S. Bullock, A. Kravtsov, D. Cohn, R. H. Richstone, B. Tinker, E. Tozzi, P. van Kampen, and W. Zhang for useful discussions."
    },
    {
        "original_text": "We show that, in addition to gravitational waves and neutrinos, there is an additional source of energy loss during the final stages of stellar evolution which has been largely ignored by previous authors. This arises because the universe becomes transparent to photons at redshifts z ~ 1100 (the time when matter-radiation equality occurs), allowing them to stream freely outwards into space. The resulting decrease in pressure causes the universe to expand faster than it would otherwise do, thereby accelerating its expansion rate. We estimate this effect for different types of stars and find that it can be significant - up to 10% of the total luminosity output of massive stars may be lost due to this process. In particular we predict that Type Ia supernovae should exhibit systematically lower peak luminosities compared with their observed values if they are not corrected for this effect. Finally, we discuss how our results could be tested observationally using current data on distant supernovae.",
        "watermark_text": "We show that, in addition to gravity waves and neutrinos, there is an extra source of energy loss during the final stages of star evolution which has been largely ignored by previous authors.This arises because the universe becomes transparent to photons at redshifts z ~ 1100 ( the time when matter - radiation equality happens ), allowing them to stream freely outwards into space.The resulting decrease in pressure causes the universe to expand quicker than it would otherwise do, thereby accelerating its expansion rate.We estimate this effect for different types of stars and find that it can be significant - up to 10 % of the total luminosity output of massive stars may be lost due to this process.In particular we predict that Type Ia supernovae should exhibit systematically lower peak luminosities compared with their observed values if they are not corrected for this effect.Finally, we discuss how our outcomes could be tested observationally using current data on distant supernovae."
    },
    {
        "original_text": "We show that inflationary perturbations are generated by quantum fluctuations in the inflaton field, which can be understood as the cosmological version of the Schwinger effect.  We also discuss how this mechanism is related to other proposals for generating primordial density fluctuations and present some new results on its phenomenology. The recent detection of temperature anisotropies in the cosmic microwave background radiation (CMBR) has provided strong evidence for an early phase of accelerated expansion known as inflation [1] . In addition, it has been shown [2] that these observations are consistent with predictions based on slow-roll models [3] , where the energy density decreases slowly during inflation due to friction-like effects [4] .\nIn order to explain why such a period of rapid expansion occurred, one usually invokes a scalar field called \"inflaton\" whose potential V(φ) drives inflation when it becomes flat enough [5] . However, there exists no compelling theoretical reason for choosing any particular form for V(φ). For example, if we assume that V(φ) = m 2 φ 2 /2 + λφ 4 /4!, then the resulting dynamics will depend crucially on whether or not the mass term dominates over the quartic self-interaction [6] . This ambiguity leads us to consider more general forms for V(φ), including those containing higher-order terms [7, 8] .",
        "watermark_text": "We show that inflationary perturbations are generated by quantum fluctuations in the inflaton field, which can be understood as the cosmological version of the Schwinger effect.We also discuss how this mechanism is related to other proposals for generating primordial density fluctuations and present some new results on its phenomenology.The recent detection of temperature anisotropies in the cosmic microwave background radiation ( CMBR ) has provided strong evidence for an early stage of accelerated expanding known as inflation [ 1 ].In addition, it has been shown [ 2 ] that these observations are consistent with predictions based on slow - turn models [ 3 ], where the energetic density decreases slowly during inflation due to friction - like effects [ 4 ].In order to explain why such a period of rapid expansion occurred, one usually invokes a scalar field called \" inflaton \" whose potential V ( φ ) drives inflation when it becomes flat enough [ 5 ].However, there exists no convincing theoretical reason for choosing any particular form for V ( φ ).For example, if we assume that V ( φ ) = m 2 φ 2 / 2+λφ 4 / 4!, then the resulting dynamics will depend crucially on whether or not the mass term dominates over the quartic self - interaction[ 6 ].This ambiguity leads us to think more general forms for V ( φ ), including those containing higher - order terms [ 7, 8 ]."
    },
    {
        "original_text": "The multifractal nature of the human heartbeat has been studied by many authors, but most studies have focused on short time series (typically less than one hour). In this work we study the scaling properties of long-term recordings of the electrocardiograms (ECG) of healthy subjects during sleep using wavelet transforms to calculate the singularity spectrum f(α), which characterizes the degree of multifractality present in each signal.  We find that all signals are characterized by a broad range of exponents α indicating strong multifractality. The width Δα of these spectra decreases with increasing recording length T as Δα~T-1/2 for T<10 hours and Δα~T-3/4 for T>10 hours. This indicates that the ECGs become more monofractal-like when longer recordings are considered. Finally, we show how our results can be used to detect pathological changes in the heart rate variability associated with congestive heart failure.",
        "watermark_text": "The multifractal nature of the human heartbeat has been studied by many authors, but most studies have focused on short time series ( typically less than one hour ).In this work we study the scaling properties of length - term recordings of the electrocardiograms ( ECG ) of healthy subjects during sleep using wavelet transforms to calculate the singularity spectrum f ( α ), which characterizes the degree of multifractality present in each signal.We find that all signals are characterized by a broad range of exponents α indicating strong multifractality.The width Δα of these spectra decreases with increasing recording length T as Δα ~ T - 1 / 2 for T10 hours.This indicates that the ECGs become more monofractal - like when longer recordings are considered.Finally, we show how our results can be used to detect pathological changes in the heartbeat rate variability associated with congestive heart failure."
    },
    {
        "original_text": "Carbon nanotubes (CNTs) are promising materials for field emission devices due to their unique physical and chemical properties, such as high aspect ratio, low work function, and excellent mechanical strength.  In this study, we present an integrated multiphysics model that can be used to simulate the system response of CNT-based field emitting diodes (FEDs). The proposed model consists of three sub-models: 1) electron transport in CNT; 2) electrostatic potential distribution; 3) current density distribution. We have developed these models using COMSOL Multiphysics software package with built-in physics modules. To verify our simulation results, we fabricated a CNT-FED device by growing vertically aligned CNTs onto silicon substrate via plasma-enhanced chemical vapor deposition method followed by sputtering gold film over them. Our experimental data show good agreement with simulated results obtained from the proposed model.",
        "watermark_text": "Carbon nanotubes ( CNTs ) are promising materials for field emission devices due to their unique physical and chemistry properties, such as high aspect ratio, low work function, and excellent mechanical strength.In this study, we present an integrated multiphysics model that can be used to simulate the system response of CNT - based field emitting diodes ( FEDs ).The proposed model consists of 3 sub - models : 1 ) electron transport in CNT ; 2 ) electrostatic potential distribution ; three ) current density density.We have developed these models utilizing COMSOL Multiphysics software package with built - in physics modules.To verify our simulation results, we fabricated a CNT - FED device by growing vertically aligned CNTs upon silicon substrate via plasma - enhanced chemical vapor deposition method followed by sputtering gold film over them.Our experimental data show good agreement with simulated results obtained from the proposed model."
    },
    {
        "original_text": "We study the geometry of harmonic maps into spheres with values in vector bundles over Riemann surfaces. We prove that if such a map is not constant then it has no critical points outside its singular set (Theorem 1). This implies that any harmonic section of an oriented rank 2 bundle over a closed surface can be deformed to a smooth one without changing its homotopy class (Corollary 3).\nIn particular we show how this result leads to new proofs for some results about instantons on 4-dimensional manifolds due to Donaldson [D1] , [D2] . In fact our proof gives more information than those given by Donaldson's arguments since it allows us to control the behavior of the harmonic section near its singularities. Finally we give examples showing that these results are sharp. The main theorem of this article states that every non-constant harmonic section of an oriented 2-plane bundle over a closed surface S can be deformed to another harmonic section which is smooth everywhere except at isolated points where it has only simple poles.",
        "watermark_text": "We study the geometry of harmonic maps into spheres with values in vector bundles over Riemann surfaces.We prove that if such a map is not consistent then it has no critical points outside its unique set ( Theorem 1 ).This implies that any harmonic section of an oriented rank 2 bundle over a shut surface can be deformed to a smooth one without changing its homotopy classification ( Corollary three ).In particular we show how this outcome leads to fresh proofs for some results about instantons on 4 - dimension manifolds due to Donaldson[ D1 ], [ D2 ].In fact our proof gives more knowledge than those given by Donaldson ' s arguments since it permits us to control the behavior of the harmonic section near its singularities.Finally we give examples showing that these results are sharp.The main theorem of this article states that every non - constant harmonic section of an oriented two - plane bundle over a closed surface S can be deformed to another harmonic chapter which is smoothly everywhere except at isolated points where it has only simple poles."
    },
    {
        "original_text": "We study the formation and control of Liesegang patterns in an electrochemical system by applying external electric fields to modulate the local concentration gradients during precipitation reactions.  We show that, under certain conditions, the applied field can be used as a guiding field to direct the growth of precipitate bands along specific directions. The results are explained using a simple model based on the competition between diffusion and reaction rates at different locations within the sample. This work provides new insights into how chemical systems may self-organize through interactions with their environment. Chemical systems often exhibit complex spatial structures such as stripes or rings which form spontaneously without any externally imposed symmetry breaking [1] . These structures have been observed in many natural phenomena including mineral deposits [2] , biological tissues [3] , and even living organisms [4] .\nThe most famous example is the so-called \"Liesegang ring\" formed when two solutions containing metal ions react chemically [5] . In this case, the initial solution contains both cations (e.g., Ag+) and anions (e.g., Cl-). When these two solutions come into contact, they begin to diffuse across each other until they meet another interface where the opposite charges neutralize one another [6] . At some point after mixing, precipitation occurs leading to the formation of a band of solid material separating the original solutions [7, 8] . As more bands grow, they eventually overlap forming concentric rings around the center of the sample [9] . Although the exact mechanism behind the formation of Liesegang rings remains unclear [10] , it has been shown experimentally that the spacing between successive rings depends strongly on the concentrations of the starting solutions [11] .",
        "watermark_text": "We study the formation and control of Liesegang patterns in an electrochemical system by applying external electric fields to modulate the local concentration gradients during precipitation reactions.We show that, under certain conditions, the applied field can be used as a guiding field to direct the growth of precipitate groups along specific directions.The results are explained using a simple model based on the competition between diffusion and reaction rates at different locations inside the sample.This work provides new insights into how chemistry systems might self - organize through interactions with their environment.Chemical systems often exhibit complex spatial structures such as stripes or rings which form spontaneously without any externally imposed symmetrical breaking [ 1 ].These structures have been observed in many natural phenomena including mineral deposits [ 2 ], biological tissues[ 3 ], and even living organisms [ 4 ].The most famous example is the so - called \" Liesegang ring \" formed when two solutions containing metal ions react chemically [ 5 ].In this case, the initial solution contains both cations ( e. g., Ag + ) and anions ( e. g., Cl - ).When these two solutions come into contact, they start to diffuse along each other until they meet another interface where the opposite charges neutralize along another [ 6 ].At some point after mixing, precipitation occurs leading to the formation of a band of solid material separating the original solutions[ 7, 8 ].As more bands grow, they eventually overlap forming concentric circles around the centre of the sample [ 9 ].Although the exact mechanism behind the formation of Liesegang rings remains unclear [ 10 ], it has been shown experimentally that the spacing between successive rings depends strongly on the concentrations of the starting solutions [ 11 ]."
    },
    {
        "original_text": "We present an approach to predict the structural network organization in the cerebral cortex based on local node features, such as their position within the brain's surface or volume, and global topological characteristics. We use this method to study how different types of nodes are connected with each other across species (human, macaque monkey) and modalities (diffusion MRI tractography). Our results show that our model can accurately reproduce known patterns of cortico-cortical connections between areas, including those observed in humans but not yet described for monkeys. The proposed framework is general enough to be applied to any type of data where information about individual nodes' positions and pairwise interactions exists. This includes both anatomical and functional imaging datasets, which will allow us to investigate the relationship between structure and function at multiple scales. \n \n Introduction \n \n Brain connectomics aims to map all neuronal elements into a single comprehensive description of the human brain [1] . In recent years, advances in neuroimaging techniques have allowed researchers to obtain detailed maps of the brain's structural [2] , metabolic [3] , and functional [4] architecture. These new technologies provide unprecedented opportunities to understand how the brain works by studying its large-scale organization [5] .\n \nHowever, despite these advancements, there remains significant uncertainty regarding the precise nature of the relationships among neurons [6] . For example, it has been shown that some regions of the brain communicate more frequently than others [7-9], while others exhibit higher levels of synchrony [10] . However, we still do not know whether these differences reflect specific wiring rules [11] or simply arise due to random fluctuations [12] . \n \n Here, we propose a novel computational framework to address this problem using machine learning methods [13] . Specifically, we aim to develop models capable of predicting the strength of connection between pairs of nodes given only information about their location and topology [14] . To achieve this goal, we first construct a set of training examples consisting of pairs of nodes whose interaction strengths are known [15] . Then, we train a classifier to learn the mapping between node features and edge weights [16] . Finally, we apply the trained model to unseen test cases [17] to infer unknown interactions",
        "watermark_text": "We present an approach to predict the structural network organization in the cerebral cortex based on local node characteristics, such as their position within the brain ' s surface or volume, and global topological characteristics.We use this method to study how different types of nodes are connected with each other across species ( human, macaque monkey ) and modalities ( diffusion MRI tractography ).Our results show that our model can accurately reproduce known patterns of cortico - cortical links between regions, including those observed in humans but not yet described for monkeys.The proposed framework is general enough to be applied to any type of data where info about individual nodes ' positions and pairwise interactions exists.This includes both anatomical and functional imaging datasets, which will enable us to investigate the relationship between structure and function at multiple scales.Introduction Brain connectomics aims to map all neuronal elements into a single comprehensive description of the human brain[ 1 ].In recent years, advances in neuroimaging techniques have allowed researchers to obtain detailed maps of the brain ' s structural [ 2 ], metabolic[ 3 ], and functional[ 4 ] architecture.These new technologies provide unprecedented opportunities to understand how the brain works by studying its large - scale organization[ 5 ].However, despite these advancements, there remains significant uncertainty regarding the precise nature of the relations among neurons [ 6 ].For example, it has been shown that some regions of the brain communicate more frequently than others [ 7 - 9 ], while others exhibit higher levels of synchrony [ 10 ].However, we still do not know whether these differences reflect particular wiring rules [ 11 ] or simply arise owing to random fluctuations [ 12 ].Here, we propose a new computational framework to address this problem using machine learning methods [ 13 ].Specifically, we aim to develop models capable of predicting the strength of connection between pairs of nodes given only information about their location and topology [ 14 ].To achieve this goal, we first construct a set of training examples consisting of pairs of nodes whose interaction strengths are known [ 15 ].Then, we train a classifier to learn the mapping between node features and edge weights [ 16 ].Finally, we apply the trained model to unseen test cases [ 17 ] to infer unidentified interactions"
    },
    {
        "original_text": "The aim of this thesis is the study and development of computational methods for prolongation structures, which are used as tools in geometric analysis. The main focus lies on the construction of explicit formulas for the prolonged action of vector fields on tensor bundles over manifolds with symmetries. In particular we consider Lie groups acting by diffeomorphisms on Riemannian or pseudo-Riemannian manifolds. We present an algorithm that computes the prolonged action of a given vector field on any tensor bundle associated to such a manifold. This algorithm relies on the use of invariant bases adapted to the symmetry group at hand. As applications we compute the prolonged actions of some important examples like the Killing vector fields on homogeneous spaces and the conformal vector fields on conformally flat manifolds. Finally, we show how our results can be applied to construct new families of solutions to Einstein's equations. Keywords: Geometric Analysis, Manifold Symmetry Group",
        "watermark_text": "The aim of this thesis is the study and development of computational methods for prolongation structures, which are utilized as tools in geometry analysis.The main focus lies on the building of explicit formulas for the prolonged act of vector fields on tensor bundles over manifolds with symmetries.In particular we consider Lie groups acting by diffeomorphisms on Riemannian or meta - Riemannian manifolds.We present an algorithm that computes the prolonged action of a given vector field on any tensor bundle associated to such a manifold.This algorithm relies on the use of invariant bases adapted to the symmetric group at hand.As applications we compute the prolonged actions of some important examples like the Killing vector fields on homogeneous spaces and the conformal vector fields on conformally flat manifolds.Finally, we show how our results can be applied to construct new families of solving to Einstein ' s equations.Keywords : Geometric Analysis, Manifold Symmetry Group"
    },
    {
        "original_text": "We consider strings propagating on curved backgrounds, with emphasis on their role as sigma-models. We show that the world-sheet action for such strings can be written in terms of an auxiliary field which is related to the extrinsic curvature of the target space. This allows us to study string propagation by solving the equations of motion for this auxiliary field instead of directly solving the equation of motion for the embedding coordinates. In particular we discuss how this approach simplifies calculations when studying strings in AdS spaces or near black holes. Finally, we use our formalism to investigate the behavior of strings at high energies where they become tensionless. We find that these strings are described by a conformal theory whose central charge vanishes. The corresponding Virasoro generators have negative norm states so that the Hilbert space has indefinite metric. These results provide further evidence that tensionless strings may play an important rôle in understanding quantum gravity.",
        "watermark_text": "We consider strings propagating on curved backgrounds, with emphasis on their role as sigma - models.We show that the world - sheet action for such strings can be written in terms of an auxiliary field which is related to the extrinsic curvature of the target space.This allows us to study string propagation by solving the equations of movement for this auxiliary field instead of directly solving the equation of motion for the embedding coordinates.In particular we discuss how this approach simplifies calculations when studying strings in AdS spaces or near black holes.Finally, we use our formalism to investigate the behavior of strings at high energies where they become tensionless.We find that these strings are described by a conformal theory whose central charge vanishes.The corresponding Virasoro generators have negative norm states so that the Hilbert space has indefinite metric.These results provide further evidence that tensionless strands may play an important rôle in understanding quantum gravity."
    },
    {
        "original_text": "We present new photometric data for the globular cluster NGC 5466, obtained with the Wide Field Imager at the MPG/ESO 2.2 m telescope in La Silla Observatory (Chile). The observations were carried out on two nights under good seeing conditions. We used the HST/WFPC2 archive images to calibrate our instrumental magnitudes into the standard Johnson-Cousins system. Our results show that there is an excess of blue straggler stars over what would be expected by extrapolating the main sequence turn-off point towards fainter luminosities. This result confirms previous findings based on ground-based photometry. \n \n Keywords: Globular clusters; Blue stragglers; Photometry; ESO 2.2 m; Wide Field Imager. 1 Introduction \n \n In this work we report new photometric data for one of the most studied Galactic globular clusters: NGC 5466. It was discovered by William Herschel during his famous survey of the southern sky [1] . Its distance has been estimated using several methods [2] , giving values ranging between 8 kpc [3] and 12 kpc [4] . These estimates are consistent within their errors but they do not agree with those derived from the analysis of its red giant branch [5] which suggest a larger value of about 16 kpc [6] .\n \nThe first detailed study of the cluster was performed by Trumpler [7] who found it to have a core radius of 3 arcmin and a half-mass relaxation time of 4 Gyrs. Later studies [8] confirmed these results. More recently [9] determined the structural parameters of the cluster finding a core radius of 5.3 arcmin and a concentration parameter c = log(r t /r c ) = 0.6 ± 0.1 where r t is the tidal radius and r c is the core radius. They also found evidence of mass segregation among the brightest stars. \nNGC 5466 shows a bimodal colour distribution [10] as well as a double peaked radial profile [11] . Both features can be explained if the cluster contains both old and intermediate age populations [12] . Indeed, spectroscopic studies",
        "watermark_text": "We present new photometric data for the globular cluster NGC 5466, obtained with the Wide Variety Imager at the MPG / ESO II. 2 m telescope in La Silla Observatory ( Chile ).The observations were taken out on two evenings under good seeing circumstances.We used the HST / WFPC2 archive images to calibrate our instrumental magnitudes into the standard Johnson - Cousins system.Our results show that there is an excess of blue straggler stars over what would be anticipated by extrapolating the main sequence turn - off point towards fainter luminosities.This result confirms previous findings based on ground - based photometry.Keywords : Globular clusters ; Blue stragglers ; Photometry ; ESO 2. 2 m ; Wide Field Imager.1 IntroductionIn this work we report fresh photometric data for one of the most studied Galactic globular clusters : NGC 5466.It was discovered by William Herschel during his famous survey of the south sky[ 1 ].Its distance has been estimated via several methods [ 2 ], giving values ranging between 8 kpc [ 3 ] and 12 kpc [ 4 ].These estimates are consistent within their errors but they do not agree with those derived from the analysis of its red giant branch[ 5 ] which suggest a larger value of about 16 kpc [ 6 ].The first detailed study of the cluster was performed by Trumpler[ 7 ] who found it to have a core radius of 3 arcmin and a half - mass relaxation time of 4 Gyrs.Later studies [ 8 ] confirmed these results.More recently [ 9 ] determined the structural parameters of the cluster finding a core radius of 5. 3 arcmin and a concentration parameter c = log ( r t / rc )= 0. 6 ± 0. 1 where r t is the tidal radius and r c is the core radius.They also found evidence of mass segregation among the brightest stars.NGC 5466 shows a bimodal color distribution [ 10 ] as well as a twice peaked radial profile [ 11 ].Both features can be explained if the cluster contains both old and intermediate age populations [ 12 ].Indeed, spectroscopic studies"
    },
    {
        "original_text": "We present new measurements of the angular diameter variations for two classical Cepheids: Y Ophiuchi (Y Oph) and Alpha Persei (alpha Per). These stars are among the brightest in their class, making them ideal targets to study using infrared interferometry. We used the FLUOR instrument on the CHARA array at Mount Wilson Observatory to obtain high-precision visibility data over several pulsation cycles. The observations were performed simultaneously in H-band (1.6 microns), K-band (2.0 microns), and L-band (3.8 microns).\nThe results show that both stars have extended atmospheres which vary significantly during the pulsations cycle. In particular we find that:  - For Y Oph, our best-fit model is consistent with an atmosphere extending up to about 1 AU above its photosphere.  - For alpha Per, our best-fit models suggest that the star has an extended atmosphere reaching out to more than 2 AU above its photosphere.",
        "watermark_text": "We present new measurements of the angular diameter variations for 2 classical Cepheids : Y Ophiuchi ( Y Oph ) and Alpha Persei ( alpha Per ).These stars are among the brightest in their class, becoming them ideal targets to study using infrared interferometry.We used the FLUOR instrument on the CHARA array at Mt Wilson Observatory to obtain high - precision visibility data over several pulsation cycles.The observations were performed simultaneously in H - band ( 1. 6 microns ), K - band ( 2. 0 microns ), and L - band ( three. 8 microns ).The results show that both stars have extended atmospheres which vary significantly during the pulsations cycle.In particular we find that : - For Y Oph, our best - fit model is consistent with an atmosphere extending up to about 1 AU above its photosphere. -For alpha Per, our best - fit models suggest that the star has an extended atmosphere reaching out to more than 2 AU above its photosphere."
    },
    {
        "original_text": "We present the results of our Spitzer Space Telescope survey for protostars and young stellar objects (YSOs) in three nearby, intermediate mass star-forming regions: NGC 1333, Serpens South, and Perseus North. We identify over 100 candidate YSOs with infrared excesses indicative of circumstellar disks and/or envelopes. The majority are Class I sources that have recently formed outflows or jets; however we also find several dozen more evolved Class II/III sources. In addition to these disk-bearing systems, we detect numerous isolated point-like sources whose SEDs suggest they are deeply embedded protostars. These observations provide new insights into how stars form in IM environments. Our sample includes many previously unidentified low-luminosity protostars which will be useful targets for future studies at higher angular resolution. This work is based on observations made with the Spitzer Space Telescope, which is operated by NASA under contract 1407. Support for this work was provided by NASA through an award issued by JPL/Caltech. \n \n Keywords: Protostar",
        "watermark_text": "We present the results of our Spitzer Space Telescope survey for protostars and young stellar objects ( YSOs ) in three nearby, intermediate mass star - forming regions : NGC 1333, Serpens South, and Perseus North.We identify over 100 candidate YSOs with infrared excesses indicative of circumstellar disks and / or envelopes.The majority are Class I sources that have recently formed outflows or jets ; however we also find several dozen more evolved Class II / III sources.In addition to these disk - bearing systems, we detect numerous isolated point - like sources whose SEDs suggest they are deeply embedded protostars.These observations provide new insights into how stars form in IM environments.Our sample includes many previously unidentified low - luminosity protostars which will be useful targets for future studies at upper angular resolution.This work is based on observations made with the Spitzer Satellite Telescope, which is operated by NASA under contract 1407.Support for this work was provided by NASA through an award issued by JPL / Caltech.Keywords : Protostar"
    },
    {
        "original_text": "We present an analytical model to study decoherence and relaxation processes in a few coupled superconducting quantum interference devices (SQUID) immersed into a phonon bath at low temperatures. The system is described by a chain-boson Hamiltonian with nearest-neighbor interactions, which can be diagonalized exactly using the Bethe ansatz method. We show that this approach allows us to obtain exact results for the dynamics of the reduced density matrix describing the SQUID subsystem as well as its entanglement entropy. In particular we find that the decay rate of the off-diagonal elements of the reduced density matrix scales linearly with temperature T , while the von Neumann entropy grows logarithmically with time t. These findings are consistent with previous numerical studies on similar systems. \n \n Introduction \n \n Superconducting circuits have been proposed recently as promising candidates for realizations of quantum information processing [1] . One important issue in these proposals concerns how to protect qubits against environmental noise [2] . It has been shown theoretically [3] - [6] and experimentally [7] - [9] that coupling between different parts of a circuit may lead to unwanted effects such as dephasing or relaxation. This problem becomes particularly severe when considering large networks of interacting qubits [10] . \n \n Here we consider a simple model consisting of two weakly-coupled SQUIDs [11] immersed into a phonon environment [12] . Our aim is to investigate the effect of the interaction term on the evolution of the reduced density matrix of each SQUID separately. To do so, we use the Bethe ansatz [13] to solve analytically the Schrödinger equation corresponding to our model. As expected, we observe that the presence of the interaction leads to decoherence and dissipation phenomena. Moreover, we find that the decay rates of the off-diagonals of the reduced density matrices scale linearly with temperature T , whereas their von Neumann entropies grow logarithmically with time t. \nModel\n\nThe total Hamiltonian H = H0 + V describes the system composed of N = 2 SQUIDs coupled via a weak tunneling amplitude J immersed into a phonon reservoir at zero temperature.",
        "watermark_text": "We present an analytical model to study decoherence and relaxation systems in a few coupled superconducting quantum interference devices ( SQUID ) immersed into a phonon bath at low temperatures.The system is described by a chain - boson Hamiltonian with nearest - neighbour interactions, which can be diagonalized exactly using the Bethe ansatz method.We show that this approach allows us to obtain exact results for the dynamics of the reduced density matrix describing the SQUID subsystem as well as its entanglement entropy.In particular we find that the decay rate of the off - diagonal elements of the reduced density matrix scales linearly with temperature T, while the von Neumann entropy grows logarithmically with time t.These findings are consistent with previous numerical studies on comparable systems.Introduction Superconducting circuits have been proposed recently as promising candidates for realizations of quantum information processing [ 1 ].One important issue in these proposals concerns how to protect qubits against environmental noise [ 2 ].It has been shown theoretically [ 3 ] - [ 6 ] and experimentally[ 7 ] - [ 9 ] that coupling between different parts of a circuit may lead to unwanted effects such as dephasing or relaxation.This problem gets particularly severe when considering big networks of interacting qubits [ 10 ].Here we consider a simple model consisting of two weakly - coupled SQUIDs[ 11 ] immersed into a phonon environment[ 12 ].Our aim is to investigate the impact of the interaction terminology on the evolution of the reduced density matrix of each SQUID separately.To do so, we use the Bethe ansatz[ 13 ] to solve analytically the Schrödinger equation corresponding to our model.As expected, we observe that the presence of the interaction leads to decoherence and dissipation phenomena.Moreover, we find that the decay rates of the off - diagonals of the reduced density matrices scale linearly with temperature T, whereas their von Neumann entropies grow logarithmically withtime t. ModelThe total Hamiltonian H = H0 + V describes the system composed of N = 2 SQUIDs coupled via a weak tunneling amplitudeJ immersed into a phonon reservoir at zero temperature."
    },
    {
        "original_text": "We report on our photometric and spectroscopic monitoring campaign of the young open cluster NGC 2024 (the Orion Nebula Cluster) aimed at detecting new low-mass members with masses down to ~0.1 Msun. We have discovered one such object which we call JW 380. It is an eclipsing binary system consisting of two very similar stars that are separated by only 1 AU. The primary star has a mass of about 0.25 Msun while its companion has a mass of about 15 percent less. Both components show signs of youth as indicated by their strong H-alpha emission lines. Their age was determined using theoretical evolutionary tracks for PMS stars. Our results suggest that this system is younger than 2 Myr old. This makes it one of the youngest known binaries among all open clusters within 300 pc distance from Earth. In addition, we find evidence that both components are surrounded by circumstellar disks.",
        "watermark_text": "We report on our photometric and spectroscopic measuring campaign of the young open cluster NGC 2024 ( the Orion Nebula Cluster ) aimed at detecting new low - mass members with masses down to ~ 0. 1 Msun.We have discovered one such object which we call JW 380.It is an eclipsing binary structure consisting of two very similarly stars that are apart by only 1 AU.The primary star has a mass of about 0. 25 Msun while its companion has a mass of about 15 percent less.Both components show signs of youth as indicated by their strength H - alpha emission lines.Their age was determined utilizing theoretical evolution tracks for PMS stars.Our results suggest that this system is younger than 2 Myr old.This makes it one of the youngest known binaries among all open clusters within 300 ppc distance from Earth.In addition, we find evidence that both components are surrounded by circumstellar disks."
    },
    {
        "original_text": "The pressure-induced insulator-metal (IMT) phase transition is studied by means of the first-principles calculations based on density functional theory within local spin-density approximation and generalized gradient approximations. The calculated results show that the IMT occurs at about 20 GPa for both LSDA and PBE functionals, which are consistent with previous theoretical studies. However, it should be noted that there exists an obvious difference between these two methods when calculating the electronic structure near Fermi level. In addition to this, we also find that the band gap decreases rapidly as increasing pressure up to 30 GPa but then becomes almost constant above 40 GPa. Finally, our calculation shows that the volume collapse takes place around 50 GPa. \n \n Keywords: Pressure-induced insulator-metal transition; First-principles calculations; Local spin-density approximation; Generalized gradient approximations; Electronic structure; Band gap",
        "watermark_text": "The pressure - induced insulator - metal ( IMT ) phase transition is studied by means of the first - principles calculations based on density functional theory within local spin - dense approximation and generalized gradient approximations.The calculated results show that the IMT occurs at about 20 GPa for both LSDA and PBE functionals, which are consistent with previously theoretical studies.However, it should be noted that there remains an obvious contrast between these two methods when calculating the electronic structure near Fermi level.In addition to this, we also find that the band gap drops rapidly as increasing pressure up to 30 GPabut then becomes almost constant above 40 GPa.Finally, our calculation shows that the volume crash takes happen around 50 GPa.Keywords : Pressure - induced insulator - metal transition ; First - principles calculations ; Local spin - density approximation ; Generalized gradient approximations ; Electronic structure ; Band gap"
    },
    {
        "original_text": "We present the results on morphology and luminosity function for the most luminous galaxy clusters in the Universe, selected by their X-ray emission (the RCS2 sample). We find that these objects are characterized by an elliptical shape with axial ratio q = 0.7 ± 0.1 and by a steep luminosity function dN/dL ∝ L−2.5±0.3 . The observed properties suggest that they may be identified as fossil groups or proto-clusters at z > 1.0 .\nThe data used here were obtained during our observing runs performed at ESO telescopes under programs IDs: 073.A-0505(B), 078.A-0518(C) and 079.A-0739(D) . In this work we study the morphological and photometric properties of the brightest galaxy clusters in the universe. These systems have been detected through their X-ray emission using the ROSAT All Sky Survey (RASS; Voges et al., 1999) , and then followed up spectroscopically to confirm their redshifts and measure their velocity dispersions (see e.g. Rosati et al. , 1998 , Gladders & Yee 2005 , Eisenhardt et al. , 2008 . They represent some of the most massive structures known so far in the universe, being able to host several thousands of galaxies each one. Their high mass makes them ideal targets to investigate how such large scale structures form and evolve over time.",
        "watermark_text": "We present the results on morphology and luminosity function for the most luminous galaxy clusters in the Universe, selected by their X - ray emission ( the RCS2 sample ).We find that these objects are characterized by an elliptical shape with axial ratio q = zero. 7 ± zero. 1 and by a steep luminosity function dN / dL [UNK] L−2. 5±0. 3.The observed properties suggest that they may be identified as fossil groups or proto - clusters at z > 1. 0.The data used here were obtained during our observing runs done at ESO telescopes under programs IDs : 073. A - 0505 ( B ), 078. A - 0518 ( C ) and 079. A - 0739 ( D ).In this work we study the morphological and photometric properties of the brightest galaxy clusters in the universe.These systems have been detected through their X - ray emission using the ROSAT All Sky Survey ( RASS ; Voges et al., 1999 ), and then followed up spectroscopically to confirm their redshifts and measure their velocity dispersions ( see e. g. Rosati et al., 1998, Gladders & Yee 2005, Eisenhardt et al., 2008.They represent some of the most massive structures known so long in the universe, being able to host several thousands of galaxies each one.Their high mass makes them ideal targets to explore how such big scale structures form and evolve over time."
    },
    {
        "original_text": "We present an improved factorization formula for the fragmentation functions (FFs) of hadrons containing one heavy quark, which is valid in both leading order and next-to-leading order QCD perturbation theory. The new formula takes into account all possible contributions to the FFs at each perturbative order. We show that our results are consistent with those obtained by using other approaches such as the operator product expansion method or the renormalization group equation approach. Finally we give numerical predictions on some important quantities related to the charm-quark FFs. PACS numbers: 12.38.Qk, 13.25.Gv, 11.15.Tk \nI. INTRODUCTORY REMARK\nThe fragmentation function D(z), where z = Phadron/Pquark , describes how quarks fragment into hadrons when they are produced in hard processes like deep-inelastic scattering [1] . It plays an essential role in understanding many phenomena observed experimentally [2] .\nIn this work, we will study the fragmentation functions of hadronic states containing only one heavy quark. In particular, we consider the case of charmed-meson production in e + e-annihilation processes:",
        "watermark_text": "We present an improved factorization formula for the fragmentation functions ( FFs ) of hadrons containing 1 heavy quark, which is valid in both leading order and next - to - leading order QCD perturbation theory.The new formula takes into account all potential contributions to the FFs at each perturbative order.We show that our outcomes are consistent with those obtained by using other approaches such as the operator product expanding method or the renormalization group equation approach.Finally we give quantitative predictions on some important amounts related to the charm - quark FFs.PACS numbers : 12. 38. Qk, 13. 25. Gv, 11. 15. Tk I. INTRODUCTORY REMARKThe fragmentation function D ( z ), where z = Phadron / Pquark, describes how quarks split into hadrons when they are produced in difficult processes like deep - inelastic scattering [ 1 ].It plays an essential role in understanding many phenomena observed experimentally [ 2 ].In this work, we will study the fragmentation functions of hadronic states containing only one heavy quark.In particular, we consider the case of charmed - meson production in e + e - annihilation processes :"
    },
    {
        "original_text": "We study the classical counterparts of macroscopic tunneling phenomena, which are observed in many-body systems with competing interactions. We consider an ensemble of interacting particles on a ring threaded by a magnetic flux. The competition between nearest-neighbor attraction and next-to-nearest neighbor repulsion leads to the formation of localized states (breathers) that can be either pinned or mobile depending on their energy. In particular we show how these breather solutions evolve into spatially extended structures when they become unstable due to collisions with other breathers. Finally, we discuss the possibility for such excitations to form stable bound states. This work is supported by NSF grant DMR-0704520. PACS numbers: 05.45.Mt, 02.10.Yn, 11.30.Pb, 03.65.Nk . \nI. INTRODUCTORY REMARK\nMacroscopic tunneling refers to the phenomenon where a large number of microscopic degrees of freedom coherently contribute to transport across potential barriers [1] , leading to novel physical effects like superfluidity [2] , Josephson effect [3] , Bose-Einstein condensation [4] , etc.. Macroscopic tunneling has been studied extensively both theoretically [5] - [8] as well as experimentally [9] - [11] .\nIn this manuscript we present results concerning the classical counterpart of macroscopic quantum tunneling [12] . More specifically, we investigate the properties of a system consisting of N identical particles moving along a one-dimensional ring threaded by a constant magnetic field. Each particle interacts with its two neighbors via repulsive potentials while it experiences attractive forces from all remaining particles. Such a model was introduced originally by Calogero [13] who showed that the ground state consists of equally spaced particles forming a Wigner crystal [14] . It turns out that the presence of a weak external periodic driving force breaks the translational symmetry of the lattice [15] , giving rise to new types of collective excitations [16] . These excitations have been shown to exhibit features similar to those found in macroscopic quantum tunneling [17] - [20] . For example, if the amplitude of the external drive exceeds",
        "watermark_text": "We study the classical counterparts of macroscopic tunneling phenomena, which are observed in many - body systems with competitive interactions.We consider an ensemble of interacting particles on a ring threaded by a magnetic flux.The competition between nearest - neighbor attraction and next - to - closest neighbor repulsion leads to the formation of localized states ( breathers ) that can be either pinned or mobile depending on their energy.In particular we show how these breather solutions develop into spatially extended structures when they become unstable due to collisions with other breathers.Finally, we discuss the possibility for such excitations to form stable bound states.This work is supported by NSF grant DMR - 0704520.PACS numbers : 05. 45. Mt, 02. 10. Yn, 11. 30. Pb, 03. 65. Nk.I. INTRODUCTORY REMARKMacroscopic tunneling refers to the phenomenon where a large number of microscopic degrees of freedom coherently participate to transport across potential barriers[ 1 ], leading to novel physical effects like superfluidity [ 2 ], Josephson effect [ 3 ], Bose - Einstein condensation [ 4 ], etc.Macroscopic tunneling has been studied extensively both theoretically [ 5 ] -[ 8 ] as well as experimentally [ 9 ] - [ 11 ].In this manuscript we present results concerning the classical counterpart of macroscopic quantum tunneling[ 12 ].More specifically, we investigate the properties of a system consisting of N identical particles moving along a one - dimension ring threaded by a consistent magnetic field.Each particle interacts with its two neighbors via repulsive potentials while it experiences attractive forces from all remaining particles.Such a model was introduced originally by Calogero[ 13 ] who showed that the ground state consists of equally spaced particles forming a Wigner crystal[ 14 ].It turns out that the presence of a weak external periodic driving force breaks the translational symmetry of the lattice [ 15 ], giving rise to new types of collective excitations [ 16 ].These excitations have been shown to exhibit characteristics similar to those found in macroscopic quantum tunneling[ 17 ] - [ 20 ].For example, if the amplitude of the external driver exceeds"
    },
    {
        "original_text": "The purpose of this article is to present an overview of some recent results in quantum field theory (QFT) on curved spaces with noncommutative coordinates. The main motivation for studying QFTs on such spaces comes from string theories which are formulated as open strings attached to D-branes whose positions can be described by noncommuting matrices. In particular we will focus our attention on the so-called Groenewold-Moyal plane which is defined as the space generated by two non-commuting coordinates satisfying the commutation relations [qμ(x), qν(y)] = iθμνρqρ(xy). We will show that it is possible to define a covariant derivative operator acting on fields living on the GroenewoldMoyal plane. This allows us to introduce a notion of spinor fields on the Groenewold- Moyal plane. Moreover we will discuss how one can construct gauge invariant actions for these fields. Finally we will study the action of the discrete symmetries C,P,T and CP T .",
        "watermark_text": "The purpose of this article is to present an overview of some recent results in quantum field theoretical ( QFT ) on curved spaces with nonecommutative coordinates.The main motivation for studying QFTs on such spaces comes from string theories which are formulated as open strings attached to D - branes whose positions can be described by noncommuting matrices.In particular we will focus our attention on the so - called Groenewold - Moyal aircraft which is defined as the space generated by 2 non - commuting coordinates satisfying the commutation relations [ qμ ( x ), qν ( y ) ] = iθμνρqρ ( xy ).We will show that it is possible to define a covariant derivative operator acting on fields living on the GroenewoldMoyal plane.This allows us to introduce a notion of spinor fields on the Groenewold - Moyal plane.Moreover we will discuss how one can construct gauge invariant actions for these fields.Finally we will study the action of the discrete symmetries C, P, T and CP T."
    },
    {
        "original_text": "We present the first measurement of single-transverse-spin asymmetries (SSA) for hadronic dijets produced at midrapidity in p+p collisions at sqrt(sNN) = 5.02 TeV using data collected by the CMS experiment during 2012 corresponding to an integrated luminosity of 2.3 fb-1 . The SSAs are extracted as functions of jet transverse momentum and rapidity, azimuthal angle between jets, and event centrality. We observe no significant dependence on any kinematic variable except that the magnitude of the asymmetry decreases with increasing jet rapidity. Our results are compared to theoretical predictions based on perturbative QCD calculations including higher-order corrections and parton distribution function uncertainties. \nThe measured values agree well within experimental and theoretical uncertainties. This is the most precise measurement of this observable performed so far. \n \n Introduction \n \n Single transverse-spin asymmetries have been observed in several processes involving polarized protons or neutrons [1] , such as inclusive pion production [2] , semi-inclusive deep-inelastic scattering [3] , Drell-Yan lepton pair production [4] , prompt photon production [5] , and direct photons [6] . These measurements provide important information about the spin structure of nucleons [7, 8] .\n \nIn particular, they can be used to test the validity of factorization theorems [9] which relate hard-scattering cross sections to partonic distributions inside the proton [10] . In addition, these observables may also shed light on new physics beyond the Standard Model [11] . \n \n For example, it has recently been suggested [12] that large single-spin asymmetries could arise due to the interference of two amplitudes describing different helicities of quarks emitted from longitudinally polarized gluons in high-energy pp collisions. Such effects would violate parity conservation and thus constitute evidence for new physics [13] . However, there exists only one previous measurement [14] of single-spin asymmeties in hadronic dijet production at high energies. That study was carried out at RHIC [15] where the center-of-mass energy per nucleon-nucleon collision √sNN=200 GeV is much lower",
        "watermark_text": "We present the initial measurement of single - transverse - spin asymmetries ( SSA ) for hadronic dijets produced at midrapidity in p + p collisions at sqrt ( sNN )= 5. 02 TeV using data collected by the CMS experiment during 2012 corresponding to an integrated luminosity of 2. 3 fb - 1.The SSAs are extracted as functions of jet transverse momentum and rapidity, azimuthal aspect between jets, and event centrality.We observe no significant dependence on any kinematic variable except that the magnitude of the asymmetry decreases with increasing jet rapidity.Our results are compared to theoretical predictions based on perturbative QCD calculations including higher - order corrections and partialon distribution function uncertainties.The measured values agree well within experimental and theory uncertainties.This is the most precise measurement of this observable performed so far.Introduction Single transverse - spin asymmetries have been observed in several processes involving polarized protons or neutrons [ 1 ], such as inclusive pion production[ 2 ], semi - inclusive deep - inelastic scattering [ 3 ], Drell - Yan lepton pair production[ 4 ], prompt photon production[ 5 ], and direct photons [ 6 ].These measurements provide important information about the spin structure of nucleons[ 7, 8 ].In particular, they can be used to test the validity of factorization theorems [ 9 ] which relate difficult - scattering across sections to partonic distributions within the proton [ ten ].In addition, these observables may also shed light on new physics beyond the Standard Model [ 11 ].For example, it has recently been suggested [ 12 ] that big single - spin asymmetries could arise due to the interference of two amplitudes describing different helicities of quarks emitted from longitudinally polarized gluons in high - energy pp collisions.Such effects would violate parity conservation and thus represent evidence for new physics[ 13 ].However, there exists only one previous measurement[ 14 ] of single - spin asymmeties in hadronic dijet production at high energies.That study was carried out at RHIC[ 15 ] where the center - of - mass energy per nucleon - nucleon collision √sNN = 200 GeV is much lower"
    },
    {
        "original_text": "We present an approach to the analysis of metabolic networks based on information-theoretic concepts, in particular Shannon's entropy measure. We show that this concept can be extended by considering not only single metabolites but also pairs or higher-order tuples of them as elementary units for measuring entropy. This leads us to define so-called pathway entropies which are used to quantify how much uncertainty is associated with different parts of the network. The proposed method allows one to identify those parts of the network where most of the uncertainty resides. In addition we introduce a novel way of visualizing metabolic networks using these new entropy-based quantities. Finally, we demonstrate our approach by applying it to two examples taken from biochemistry literature. Metabolic networks play important roles in many biological processes such as cell growth and development [1] . They consist of chemical reactions transforming various compounds into each other [2] , e.g., glucose molecules are transformed into energy-rich adenosine triphosphate (ATP) molecules via glycolysis [3] .\nThe study of metabolic networks has been attracting increasing interest over recent years [4] - [8] . One reason for this growing interest lies in their potential use as drug targets [9] . Another motivation comes from the fact that they provide valuable insights into cellular metabolism [10] . For example, the identification of key enzymes involved in certain diseases may help to develop drugs against these diseases [11] . Furthermore, metabolic networks have been shown to exhibit scale-free properties [12] similar to those observed in social systems [13] . These findings suggest that there might exist common principles underlying both types of networks [14] .\nIn order to understand the functioning of metabolic networks better, several mathematical models have been developed [15] - [17] . Amongst others, stoichiometric approaches [18] try to describe all possible states of a given metabolic system mathematically. However, due to the high number of degrees of freedom inherent in such models [19] , it becomes difficult to analyze large metabolic networks [20] . Therefore, alternative methods have been suggested [21] - [23] .",
        "watermark_text": "We present an approach to the analysis of metabolic networks based on information - theoretic concepts, in particular Shannon ' s entropy measure.We show that this concept can be extended by considering not only single metabolites but also pairs or upper - order tuples of them as elementary units for measuring entropy.This leads us to define so - called pathway entropies which are used to quantify how lot uncertainty is associated with different portions of the network.The proposed method permits one to identify those parts of the network where most of the uncertainty resides.In addition we introduce a novel way of visualizing metabolic networks utilizing these new entropy - derived quantities.Finally, we demonstrate our approach by implementing it to 2 examples taken from biochemistry literature.Metabolic networks play important roles in many biological functions such as cell growth and development [ 1 ].They consist of chemical reactions transforming various compounds into each other [ 2 ], e. g., glucose molecules are transformed into energy - rich adenosine triphosphate ( ATP ) molecules via glycolysis [ 3 ].The study of metabolic networks has been attracting increasing interest over following years[ 4 ] - [ 8 ].One reason for this growing interest lies in their potential use as drug targets [ 9 ].Another motivation comes from the fact that they provide valuable inputs into cellular metabolism [ 10 ].For example, the identification of key enzymes involved in certain diseases might help to develop drugs against these diseases[ 11 ].Furthermore, metabolic networks have been shown to exhibit scale - free properties [ 12 ] similar to those observed in social structures [ 13 ].These findings suggest that there might exist shared principles underlying both types of networks [ 14 ].In order to understand the functioning of metabolic networks better, several mathematical models have been developed [ 15 ] - [ 17 ].Amongst others, stoichiometric approaches [ 18 ] try to describe all potential states of a given metabolic system mathematically.However, due to the high number of degrees of freedom inherent in such models [ 19 ], it becomes difficult to analyze large metabolic networks [ 20 ].Therefore, alternative methods have been suggested [ 21 ] -[ 23 ]."
    },
    {
        "original_text": "We study noise-induced phase transitions in systems with multiplicative white Gaussian, Poissonian or Lévy noise. We show that for all these three types of noise there is an optimal noise intensity at which the system undergoes a transition to a state where it performs better than without noise. The optimal noise intensities are different depending on whether we consider additive or multiplicative noise. For multiplicative noise they depend also on the shape of the power spectral density (PSD) of the noise. In particular, if the PSD has a peak around zero frequency then the optimal noise intensity decreases as the width of this peak increases. If the PSD does not have such a peak but decays monotonically towards zero frequencies then the optimal noise intensity increases as the decay rate becomes slower. Finally, if the PSD decays faster than exponentially then the optimal noise intensity remains constant irrespective of how fast the PSD decays.",
        "watermark_text": "We study noise - induced phase transitions in systems with multiplicative white Gaussian, Poissonian or Lévy noise.We show that for all these three types of noise there is an optimal noise intensity at which the system undergoes a transition to a state where it performs better than without noisy.The optimal noise intensities are different depending on either we consider additive or multiplicative noise.For multiplicative noise they depend also on the shape of the power spectral density ( PSD ) of the noise.In particular, if the PSD has a peak around zero frequency then the ideal noise intensity decreases as the width of this peak increases.If the PSD does not have such a peak but decays monotonically towards 0 frequencies then the optimal noise intensity increases as the degradation rate becomes slower.Finally, if the PSD decays faster than exponentially then the optimal noise intensity remains constant irrespective of how rapid the PSD decays."
    },
    {
        "original_text": "We report the growth of millimeter-thick vertically aligned single-walled carbon-nanotube forests on SiO 2 /Si substrates by chemical vapor deposition using Fe nanoparticles as catalysts at temperatures between 700 °C and 850 °C in Ar/H 2 . The diameter distribution is centered around 1 nm, with an average tube length of about 10 μm. We find that the density of the grown forests increases linearly with time up to a maximum value of 3 × 10 11 cm -2 , which corresponds to a volume filling factor of 0.7 for the tubes. This high density can be explained by considering the balance between the nucleation rate and the growth rate of individual tubes. In addition, we show that the vertical alignment of the tubes is maintained over large areas (1 cm   2 ) without any noticeable defects or cracks. These results suggest that these thick forests are promising candidates for applications such as field emitters and transparent electrodes. \n \n Carbon nanotubes have attracted considerable attention because they exhibit unique physical properties [1]. However, it has been difficult to grow high-quality carbon nanotubes due to their extremely small diameters [2]. Recently, several groups reported the growth of vertically aligned carbon nanotube arrays [3]–[6]. Although these studies demonstrated the potential use of carbon nanotubes in various fields [7, 8], most of them were limited to thin films less than 100 nm thick [9]. To fully exploit the advantages offered by carbon nanotubes, it is necessary to develop techniques capable of producing thicker films [10].",
        "watermark_text": "We report the growth of millimeter - thick vertically aligned single - walled carbon - nanotube forests on SiO 2 / S substrates by chemical vapor deposition using Fe nanoparticles as catalysts at temperatures between 700 °C and 850 °C in Ar / H 2.The diameter distribution is centered around 1 nm, with an average tube duration of about 10 μm.We find that the density of the grown forests increases linearly with time up to a maximum value of three × 10 11 cm - 2, which corresponds to a volume filling factor of zero. 7 for the tubes.This high density can be explained by considering the balance between the nucleation rate and the growth rate of single tubes.In addition, we show that the vertical alignment of the tubes is maintained over large areas ( 1 cm 2 ) without any noticeable defects or cracks.These results suggest that these dense forests are promising candidates for uses such as field emitters and translucent electrodes.Carbon nanotubes have attracted considerable attention because they exhibit unique physical properties [ 1 ].However, it has been difficult to grow high - quality carbon nanotubes due to their extremely small dimensions [ 2 ].Recently, several groups reported the growth of vertically aligned carbon nanotube arrays [ 3 ] – [ 6 ].Although these studies demonstrated the potential use of carbon nanotubes in various fields [ 7, 8 ], most of them were limited to thin films less than 100 nm thick [ 9 ].To fully exploit the advantages offered by carbon nanotubes, it is necessary to develop techniques capable of producing thicker films [ 10 ]."
    },
    {
        "original_text": "The lectures were given by David Gross at the Cargese Summer Institute in Corsica, France during August 2005.  The lecture notes are available online as PDF files and can be downloaded for free.   These lecture notes cover topics such as:  - Introduction to string theory - Gauge fields and gauge symmetries - Supersymmetry - Supergravity - String field theories - D-branes - Open strings - Closed strings - Tachyons - Bosonic open strings - Fermionic open strings - Vacuum expectation values - Energy-momentum tensors - Interactions between branes - General relativity - Gravity induced on a brane - Black holes - Cosmology - Time evolution - Conformal invariance - Renormalization group flow - Dualities - M-theory - Other approaches - Comments on future directions - References - Index   This is an excellent resource for learning about many aspects of modern theoretical physics including superstrings, supergravities, black holes, cosmology, time evolution, conformal invariance, renormalization group flows, dualities, M-theory, other approaches etc...",
        "watermark_text": "The lectures were given by Dave Gross at the Cargese Summer Institute in Corsica, France during Aug 2005.The lecture notes are online online as PDF files and can be downloaded for free.These lecture notes cover topics such as : - Introduction to string theorist - Gauge fields and gauge symmetries - Supersymmetry - Supergravity - String field theories - D - branes - Open strings - Closed strings - Tachyons - Bosonic open strings - Fermionic open strings - Vacuum expectation values - Energy - momentum tensors - Interactions between branes - General relativity - Gravity induced on a brane - Black holes - Cosmology - Time evolution - Conformal invariance - Renormalization group flow - Dualities - M - theory - Other approaches - Comments on future directions - References - IndexThis is an excellent source for learning about many aspects of modern theoretical physics including superstrings, supergravities, tone holes, cosmology, time evolution, conformal invariance, renormalization group flows, dualities, M - theory, other approaches etc."
    },
    {
        "original_text": "We study the dynamics of open quantum systems in one dimension, focusing on their ability to generate entanglement between distant sites and how this is affected by decoherence.  We consider two different models for the system-environment interaction: (i) an environment that couples locally with each site; and (ii) an environment that couples globally with all sites simultaneously. In both cases we find that there are regimes where the system can be driven into highly entangled states even when it starts out unentangled or only weakly entangled. This occurs because the environment acts as a source of noise which drives the system towards its ground state. The effect of local coupling is more pronounced than global coupling since the former allows for faster relaxation timescales. Finally, we show that these results hold true also if the initial state has some degree of spatial correlations. Quantum information processing requires the manipulation of quantum states over large distances. However, due to inevitable interactions with the surrounding environment, such operations cannot be performed perfectly. Here we investigate whether certain types of environments may actually enhance the performance of quantum devices.",
        "watermark_text": "We study the dynamics of open quantum systems in one dimension, focusing on their ability to generate entanglement between distant sites and how this is affected by decoherence.We consider two different models for the system - environmental interaction : ( i ) an environment that couples locally with each site ; and ( ii ) an environment that couples globally with all sites simultaneously.In both cases we find that there are regimes where the system can be driven into highly entangled states even when it starts out unentangled or only weakly entangled.This occurs because the environment acts as a source of noise which drives the system towards its ground state.The effect of local coupling is more pronounced than global coupling since the former allows for faster relaxation timescales.Finally, we show that these results hold true also if the initial state has some degree of spatial correlations.Quantum information processing requires the manipulation of quantum states over large distances.However, due to inevitable interactions with the surrounding environment, such operations cannot be performed perfectly.Here we investigate whether certain kinds of environments may actually enhance the performance of quantum devices."
    },
    {
        "original_text": "We present the results for positronium ground state energy and wave function obtained by solving relativistic Schrödinger equation with Coulomb potential using variational method. The calculations are performed within two different approximations, namely nonrelativistic limit (NR) and first order perturbation theory (PT1). In NR approximation we use Hylleraas type trial wave functions which include spin dependent terms up to second power of inter particle distance. We also calculate the expectation value of kinetic energy operator using this wave function. In PT1 approximation we use Hyllraas type trial wave functions including spin dependent terms up to third power of inter particle distance alongwith one electron Dirac orbitals as basis set. Our calculated values of binding energies agree well with those reported earlier. \n\n\nThe author is grateful to Prof. S. K. Gupta, Director General, BARC, Mumbai for his encouragement during the course of work on this project.",
        "watermark_text": "We present the results for positronium ground state energy and wave function obtained by solving relativistic Schrödinger equation with Coulomb potential using variational methodology.The calculations are performed inside two different approximations, namely nonrelativistic limit ( NR ) and first order perturbation theorist ( PT1 ).In NR approximation we use Hylleraas type trial wave functions which include spin dependent terms up to second power of inter particle distance.We also calculate the expectation value of kinetic energy operator using this wave function.In PT1 approximation we use Hyllraas type trial wave functions including spin dependent terminology up to third power of inter particle distance alongwith one electron Dirac orbitals as base set.Our calculated values of binding energies accord well with those reported earlier.The author is grateful to Prof. S. K. Gupta, Direction General, BARC, Mumbai for his encouragement during the process of work on this project."
    },
    {
        "original_text": "We present the results of our study on coriolis effects on the global oscillation modes (g-modes) in magnetized white dwarfs using one-dimensional, fully compressible numerical simulations with realistic equation-of-state and opacities. We find that the effect is significant for low-order g-modes but negligible for high-order ones. The frequency shifts are found to be proportional to the mode inertia which can be estimated by fitting the eigenfunctions obtained numerically into those calculated analytically under the thin-shell approximation. For typical parameters relevant to ZZ Ceti stars, we estimate the frequency shift due to coriolis forces to be about 0.1 % at most. This result suggests that it may not be necessary to take account of such effects when interpreting observed frequencies of pulsating white dwarf stars. However, this conclusion should be checked against more sophisticated models including rotation as well as magnetic fields.",
        "watermark_text": "We present the results of our study on coriolis effects on the global oscillation modes ( g - modes ) in magnetized white dwarfs utilizing one - dimension, full compressible numerical simulations with real equation - of - state and opacities.We find that the effect is significant for low - order g - modes but negligible for highly - order ones.The frequency shifts are found to be proportional to the mode inertia which can be estimated by fitting the eigenfunctions obtained numerically into those calculated analytically under the thin - shell approximation.For typical parameters relevant to ZZ Ceti stars, we estimate the frequency change due to coriolis forces to be about 0. 1 % at most.This result suggests that it might not be necessary to take account of such effects when interpreting observed frequencies of pulsating whitish dwarf stars.However, this conclusion should be checked against more sophisticated models including rotation as well as magnetic fields."
    },
    {
        "original_text": "We study the effects of general relativity on gravitational wave bursts produced by extreme mass ratio inspirals (EMRIs). We show that, for EMRI systems with total masses M = 10^6M_solar and compact object masses m = 1M_neutron star, the orbital period is less than one second at distances greater than 100 AU. This implies that these sources are likely to be detected as continuous waves rather than short-duration bursts. The detection rate of such events depends strongly upon their luminosities; we find that they may occur up to several times per year within our galaxy. These results suggest that EMRIs could provide an important source of information about supermassive black holes. \n \n Keywords: Black hole, Compact binary system, General relativity, Gravitational wave, Inspiralling neutron star, Relativity theory \n \n \n \n INTRODUCTION \n \n In recent years there has been considerable interest in studying the properties of gravitational radiation emitted during the final stages of stellar evolution when a massive star collapses into a black hole or neutron star [1] . Such processes can produce extremely energetic signals which will be detectable out to cosmological distances using future space-based detectors [2] , including LISA [3] . However, it remains unclear how many of these events should actually be observed [4] . \n \n One possible class of objects which might emit strong gravitational waves are known as \"extreme-mass-ratio inspirals\" (EMRIs) [5] . Here, a small compact object spirals into a much more massive black hole or neutron star over millions of orbits before being destroyed [6] . For example, if a solar mass star were to spiral into a ten million solar mass black hole then its orbit would shrink down to just a few kilometres before merging [7, 8] . If this process occurs close enough to the event horizon then the resulting signal will have very high frequencies [9] . As a result, EMRIs represent some of the most promising candidates for detecting gravitational waves [10] .",
        "watermark_text": "We study the effects of general relativity on gravitational wave bursts produced by extreme mass ratio inspirals ( EMRIs ).We show that, for EMRI systems with total masses M = 10 ^ 6M _ solar and compact object masses m = 1M _ neutron star, the orbital period is less than one second at distances larger than 100 AU.This implies that these sources are likely to be detected as continuous waves instead than short - duration bursts.The detection rate of such events depends strongly upon their luminosities ; we find that they may occur up to several times per year within our galaxy.These results suggest that EMRIs could provide an important source of information about supermassive looking holes.Keywords : Black hole, Compact binary system, General relativity, Gravitational wave, Inspiralling neutron star, Relativity theory INTRODUCTION In recent years there has been considerable interest in studying the properties of gravity radiation emitted during the final stages of stellar evolution when a massive star collapses into a black hole or neutron star[ 1 ].Such processes can produce extremely energetic signals which will be detectable out to cosmological distances using future space - born detectors [ 2 ], including LISA [ 3 ].However, it remains unclear how many of these incidents should actually be observed [ 4 ].One possible class of objects which might emit strong gravitational waves are known as \" extreme - mass - ratio inspirals \" ( EMRIs )[ 5 ].Here, a small compact object spirals into a much more massive black hole or nuclear star over millions of orbits before being destroyed [ 6 ].For example, if a solar mass star were to spiral into a 10 million solar weight black hole then its orbit would shrink down to just a few kilometres before merging [ 7, eight ].If this process occurs close enough to the event horizon then the resulting signal will have very high frequencies [ 9 ].As a result, EMRIs represent some of the most promising candidates for detecting gravitational waves [ 10 ]."
    },
    {
        "original_text": "We present the results of our photometric and spectroscopic study of the blue plume (BP) stars in four nearby dwarf spheroidal galaxies, Draco, Ursa Minor, Sculptor, and Carina. The BP is defined as an excess over the main sequence turn-off at B − V = 0.4 mag for metal-poor populations with [Fe/H] < −1 dex. We find that the BPs are composed of two distinct components; one component follows the same color-magnitude relation as Galactic globular clusters while another component shows bluer colors than expected by theoretical models. Our analysis suggests that these two components have different origins. One possibility is that they represent a mixture of old and intermediate-age populations. Another possibility is that the bluer component represents a younger generation of stars formed during recent star formation events. In this case, we expect to see some evidence of ongoing star formation activity such as Hα emission lines and/or UV upturn features. However, no clear signatures of ongoing star formation were found among the BP stars. \n \n Instead, we propose that the bluer component may be explained by binary evolution effects on the horizontal branch. If so, then the BP can be used as a tracer of binary fraction in low-metallicity environments.",
        "watermark_text": "We present the results of our photometric and spectroscopic study of the blue plume ( BP ) stars in 4 nearby dwarf spheroidal galaxies, Draco, Ursa Minor, Sculptor, and Carina.The BP is defined as an excess over the main sequence turn - off at B − V = 0. 4 mag for metal - poor populations with [ Fe / H ] < −1 dex.We find that the BPs are composed of 2 distinct components ; one component follows the same colour - magnitude relation as Galactic globular clusters while another component shows bluer colors than expected by theoretical models.Our analysis suggests that these 2 components have different origins.One possibility is that they represent a mixture of old and intermediate - age populations.Another possibility is that the bluer component represents a younger generation of stars formed during recent star formation events.In this case, we expect to witness some evidence of ongoing stellar formation activity such as Hα emission lines and / or UV upturn features.However, no clear signatures of ongoing stellar formation were found among the BP stars.Instead, we propose that the bluer component may be explained by binary evolutionary effects on the horizontal branch.If so, then the BP can be used as a tracer of binary fraction in low - metallicity environments."
    },
    {
        "original_text": "We consider the problem of scheduling jobs on parallel machines with probabilistic anonymity constraints, where each job has to be scheduled in such a way that its execution time is hidden among other jobs. We show how this problem can be solved by using admissible schedulers for the underlying deterministic problem. In particular we present two algorithms based on list-scheduling and randomization respectively. The first algorithm achieves a competitive ratio of 2 while the second one obtains a better performance guarantee of 1 + . Both results are tight up to constant factors. Finally, we provide some experimental evidence showing that our randomized algorithm performs well also in practice. Probabilistic anonymity arises naturally when considering privacy issues related to data mining or computational social choice problems. For example, suppose that there exists a set of n users who have to submit their preferences over m alternatives (e.g., candidates) before a certain deadline T. Each user i submits her preference profile Pi = {(ai1 , bi1 ), . . . , (aim , bim )}, where aij denotes the utility she derives from alternative j and bij indicates whether she likes it or not. Then, if all profiles are submitted simultaneously at time t, they should be processed so as to hide which user prefers what alternative. This means that no information about individual preferences should be revealed until after the deadline T.",
        "watermark_text": "We consider the problem of scheduling jobs on parallel machines with probabilistic anonymity constraints, where each job has to be scheduled in such a way that its execution time is concealed among other jobs.We show how this issue can be solved by using admissible schedulers for the underlying deterministic issue.In particular we present 2 algorithms based on list - scheduling and randomization respectively.The first algorithm achieves a competitive ratio of two while the second one obtains a better performance guarantee of one +.Both results are tight up to constant considerations.Finally, we provide some experimental evidence showing that our randomized algorithm performs well also in practice.Probabilistic anonymity arises naturally when considering privacy issues related to data mining or computational social choice problems.For example, suppose that there exists a set of n users who have to submit their preferences over m alternatives ( e. g., candidates ) before a certain deadline T. Each user i submits her preference profile Pi = { ( ai1, bi1 ),..., ( aim, bim ) }, where aij denotes the utility she derives from alternative j and bij indicates whether she likes it or not.Then, if all profiles are submitted simultaneously at time t, they should be processed so as to hide which user prefers what alternative.This means that no information about individual preferences should be revealed until after the deadline T."
    },
    {
        "original_text": "In this article, we study self-dual vertex operator super algebras with central charge c = 24k for k ∈ N>0. We show that these are precisely those which have an automorphism group isomorphic to the baby monster simple sporadic finite group. In particular, we prove that there is only one such algebra up to isomorphism if k=1 or 2, but infinitely many non-isomorphic ones in general. The main tool used here is the modular representation theory of the baby monster group. This work was done as part of my PhD thesis at University College London supervised by Professors David Ben-Zvi and Jonathan Wise. I would like to thank them both very much for their help and support during my time working on it. Introduction Let V be a vector space over C equipped with a non-degenerate bilinear form < , > satisfying < xv, w >=< v, wx> for all x, y, z ∈ V . Then V is called a symplectic vector space. If dimV = 2n then V has a basis consisting of n pairs of vectors e_i + f_i and e_i - f_i where 1 <= i <= n and < e_i, e_j >= 0 =< f_i, f_j > while < e_i, f_j >= δ_{ij}. For more information see [FH91] .\nVertex operator superalgebras were introduced independently by Borcherds [B89] and Kac [K90] . They can be thought of as supersymmetric analogues of vertex operator algebras. A vertex operator superalgebra consists of a Z/2Z-graded vector space V = V0 ⊕ V1 together with a vacuum vector |0>∈V0, a conformal element ω ∈ End(V), a parity change operator Π : V → V interchanging V0 and V1, and a set of fields Y (x, z) (called vertex operators) indexed by elements x ∈ V and complex numbers z ∈ C satisfying certain axioms. These axioms include the Jacobi identity, associativity relations, commutator formulae, and various other conditions",
        "watermark_text": "In this article, we study self - dual vertex operator super algebras with central charge c = 24k for k ∈ N > 0.We show that these are precisely those which have an automorphism group isomorphic to the baby monster simply sporadic finite group.In particular, we prove that there is only one such algebra up to isomorphism if k = one or 2, but infinitely many non - isomorphic things in general.The main tool used here is the modular representation theorist of the baby monster group.This work was done as part of my doctoral thesis at University College London supervised by Professors David Ben - Zvi and Jonathan Wise.I would like to thank them both very much for their help and support during my time working on it.Introduction Let V be a vector space over C equipped with a non - degenerate bilinear format satisfying = for all x, y, z ∈ V.Then V is called a symplectic vector space.If dimV = 2n then V has a base consisting of n pairs of vectors e _ i +f _ i and e _ i - f _ i where 1 = 0= while = δ _ { ij }.For more information see [ FH91 ].Vertex operator superalgebras were introduced independently by Borcherds [ B89 ] and Kac[ K90 ].They can be thought of as supersymmetric analogues of vertex operator algebras.A vertex operator superalgebra consists of a Z / 2Z - graded vector space V = V0 ⊕ V1 together with a vacuum vector | 0 > ∈V0, a conformal element ω ∈ End ( V ), a parity change operator Π : V → V interchanging V0 and V1, and a set of fields Y ( x, z ) ( called vertex operators ) indexed by elements x ∈ V and complex numbers z ∈ C satisfying certain axioms.These axioms include the Jacobi identity, associativity relations, commutator formulae, and various other conditions"
    },
    {
        "original_text": "We study stability properties of the splay state for a class of pulse-coupled networks with time delays and nonlinear coupling functions. We show that, under certain conditions on the parameters of the system, there exists an unstable periodic orbit embedded into the basin of attraction of the splay state. This result is illustrated by numerical simulations. PACS numbers: 05.45.Mt, 47.55.Jk, 87.19 .Hj\nI. INTRODUCTIO N\nPulse-coupled neural networks are widely used to model various phenomena observed in neuroscience [1] , such as synchronization [2] - [4] , pattern formation [5] - [8] , or information processing [9] .\nIn this work we consider a particular type of pulse-coupled systems known as delay-differential equations (DDEs) [10] - [12] . In these models each node can be described by its own internal dynamics which evolve continuously in time but interact only at discrete times when pulses are transmitted between nodes. The transmission of pulses may take some finite amount of time depending on the distance between two interacting neurons [13] . Such interactions lead to appearance of time delays in DDEs describing the evolution of the whole system [14] - [16] . Time-delayed feedbacks play important role in many biological processes [17] - [19] including brain activity [20] - [22] . For example, it has been shown experimentally [23] that the presence of time delays leads to generation of rhythmic patterns in neuronal cultures [24] . It was also demonstrated [25] that time delays have significant effect on the collective behavior of populations of coupled oscillators [26] - [28] . Another interesting feature of DDE-based models is their ability to describe nonlocal interactions [29] - [31] . Nonlinearity of couplings plays another important role in modeling real-world problems [32] - [35] . Indeed, recent experimental studies [36] suggest that synaptic connections between neurons are not linear [37] . Moreover, they often exhibit saturation effects [38] - [41] . These facts motivate us to investigate the influence of both time delays and nonlinearities on the dynamical behavior of pulse-coupled networks.\nThe main goal of our research is to analyze the stability",
        "watermark_text": "We study stability properties of the splay state for a class of pulse - coupled networks with time delays and nonlinear coupling functions.We show that, under certain conditions on the parameters of the system, there exists an unstable periodic orbit embedded into the basin of attraction of the splay state.This result is illustrated by numerical simulations.PACS numbers : 05. 45. Mt, 47. 55. Jk, 87. 19. Hj I. INTRODUCTIO N Pulse - coupled neural networks are widely used to model various phenomena observed in neuroscience[ 1 ], such as synchronization[ 2 ] - [ 4 ], pattern formation[ 5 ] -[ 8 ], or information processing [ 9 ].In this work we consider a particular type of pulse - coupled structures known as delay - derivative equations ( DDEs )[ 10 ] -[ 12 ].In these models each node can be described by its own internal dynamics which evolve continuously in time but interact only at discrete times when pulses are transmitted between nodes.The transmission of pulses may take some finite amount of duration depending on the distance between 2 interacting neurons [ 13 ].Such interactions lead to appearance of time delays in DDEs describing the evolution of the whole system[ 14 ] -[ 16 ].Time - delayed feedbacks play important role in many biological processes[ 17 ] - [ 19 ] including brain activity [ 20 ] -[ 22 ].For example, it has been shown experimentally [ 23 ] that the presence of time delays leads to generation of rhythm patterns in neuronal cultures [ 24 ].It was also demonstrated [ 25 ] that time delays have significant effect on the collective behavior of populations of coupled oscillators [ 26 ] - [ 28 ].Another interesting feature of DDE - based models is their ability to describe nonlocal interactions[ 29 ] -[ 31 ].Nonlinearity of couplings plays another important role in modeling real - world problems [ 32 ] - [ 35 ].Indeed, recent experimental studies [ 36 ] suggest that synaptic connections between neurons are not linear [ 37 ].Moreover, they often exhibit saturation effects[ 38 ] - [ 41 ].These facts motivate us to investigate the influence of both time delays and nonlinearities on the dynamical behavior of pulse - coupled networks.The main goal of our research is to analyze the stability"
    },
    {
        "original_text": "We present the results of an analysis of magnetic field evolution, temperature variation, and plasma flow velocity observed by Hinode/SOT/SP (Solar Optical Telescope Spectro-Polarimeter) on September 24-25, 2007 during solar minimum period. The active region NOAA 10930 was located at S19E09 when it produced two flares with GOES class M5.7 and M1.0 respectively. We found that there were significant changes in the photospheric magnetic fields before and after these flares. In particular, we detected a new flux emergence event which occurred about one hour prior to the first flare. This newly emerged flux led to the formation of a coronal hole overlying the active region. After the second flare, the polarity inversion line moved toward the center of the active region where the strongest magnetic shear existed. During this time interval, we also found a rapid decrease in the intensity of the Fe xxi emission lines near the footpoints of the loops connecting opposite-polarities. These observations suggest that the energy released by the flares may have caused heating of the loop-top regions as well as evaporation of chromospheric material into the corona along the reconnected loops.",
        "watermark_text": "We present the results of an analysis of magnetic field evolution, temperature variation, and plasma flow velocity observed by Hinode / SOT / SP ( Solar Optical Telescope Spectro - Polarimeter ) on September 24 - 25, 2007 during solar minimum period.The active region NOAA 10930 was located at S19E09 when it produced 2 flares with GOES class M5. 7 and M1. 0 respectively.We found that there were significant changes in the photospheric magnetic fields before and after these flares.In particular, we detected a fresh flux emergence effect which occurred about one hour prior to the initial flare.This newly emerged flux led to the formation of a coronal hole overlying the active region.After the second flare, the polarity inversion line moved toward the center of the active region where the strongest magnetic shear existed.During this time interval, we also discovered a rapid decrease in the intensity of the Fe xxi emission lines towards the footpoints of the loops connecting opposite - polarities.These observations suggest that the energy released by the flares may have induced heating of the loop - top regions as also as evaporation of chromospheric matter into the corona along the reconnected loops."
    },
    {
        "original_text": "We present an explicit expression for the effective potential in terms of renormalization group functions, which is valid to all orders in perturbation theory and can be used as input into numerical calculations.  We show that this result agrees with previous results obtained by other methods at one-loop order. The new formula has several advantages over existing expressions:  It does not require any additional approximations beyond those inherent in the use of perturbation theory; it allows us to calculate the effective potential directly without having to solve complicated integral equations first; finally, we are able to obtain the full dependence on temperature and chemical potentials simultaneously. This work was supported by the U.S. Department of Energy under Contract No. DE-AC02-76SF00515. In recent years there have been many attempts to determine the effective potential Veff(T) = ln Z(T), where T denotes the temperature, using various techniques such as the imaginary time formalism [1] , the real time formalism [2] or the functional renormalization group (FRG) [3] . These approaches provide useful information about the phase structure of quantum field theories but they usually involve some kind of approximation scheme. For example, in the FRG approach one often uses truncations of the exact flow equation [4] .\nIn this letter we will derive an explicit expression for Veff(T) in terms of renormalisation group functions [5] . Our method is based on the observation [6] that the effective action Γk(φ) (where k denotes the momentum scale) satisfies a differential equation known as the Wetterich equation [7, 8] \nHere Rk(Γk; φ) is called the regulator function and describes how the infrared modes are suppressed when integrating out high energy degrees of freedom. By solving Eq. (1) numerically [9] one obtains the running coupling constants gk(φ). Using these quantities together with the corresponding β-functions one can then compute Veff(T) according to",
        "watermark_text": "We present an explicit expression for the effective potential in terms of renormalization group functions, which is valid to all orders in perturbation theory and can be used as input into number calculations.We show that this result agrees with previous ones obtained by other methods at one - loop order.The new formula has several advantages over existing expressions : It does not require any new approximations beyond those inherent in the usage of perturbation theory ; it enables us to calculate the effective potential directly without having to solution complicated integral equations first ; finally, we are able to obtain the full dependence on temperature and chemical potentials simultaneously.This work was supported by the U. S. Department of Energy under Contract No. DE - AC02 - 76SF00515.In recent years there have been many attempts to determine the effective potential Veff ( T )= ln Z ( T ), where T denotes the temperature, using various techniques such as the imaginary time formalism[ 1 ], the real time formalism[ 2 ] or the functional renormalization group ( FRG )[ 3 ].These approaches provide useful information about the phase structure of quantum field theories but they usually involve some kind of approximation scheme.For example, in the FRG approach one often utilizes truncations of the exact flow equation [ 4 ].In this letter we will derive an explicitly expression for Veff ( T ) in terms of renormalisation group functions [ 5 ].Our method is based on the observation [ 6 ] that the effective action Γk ( φ )( where k denotes the momentum scale ) satisfies a differential equation known as the Wetterich equation[ 7, 8 ] Here Rk ( Γk ; φ ) is called the regulator function and describes how the infrared modes are suppressed when integrating out high energy degrees of freedom.By solving Eq.( 1 ) numerically [ 9 ] one obtains the running coupling constants gk ( φ ).Using these quantities together with the corresponding β - functions one can then compute Veff ( T ) according to"
    },
    {
        "original_text": "We study the second-order correlation function for an atom interacting with two modes of light, one resonant and another off-resonant to atomic transition frequency. We show that higher order antibunching can be observed when the atom is initially prepared in an excited state or ground state superposition. The effect is more pronounced if the initial state has some population on the excited state. This phenomenon may have applications in quantum information processing. \n \n Introduction:-In recent years there has been considerable interest in studying nonclassical properties of radiation fields generated by atoms [1] . In particular, it was shown that the photon statistics of such systems are governed by the first-order coherence function g (1) (τ) [2] , which describes bunching behavior at short times and anti-bunching at longer times [3] . It is well known that this property arises due to destructive interference between different pathways leading to emission of photons [4] .\nRecently, several authors studied the effects of spontaneous emission on the second-order correlation functions [5] - [8] . They showed that the presence of spontaneous emission leads to sub-Poissonian statistics [6]-[8] . However, these studies were restricted only to the case where the atom interacts with a single mode of field. On the other hand, many experiments involving atoms interacting simultaneously with multiple modes of electromagnetic field have also been performed [9] - [11] . For example, in Ref. [10] , the authors investigated the influence of vacuum fluctuations on the fluorescence spectrum of a three-level system driven by two laser beams. In addition, they found that the intensity noise of the emitted light depends strongly on the relative phase difference between the driving lasers. Motivated by these experimental results we consider here the problem of calculating the second-order correlation function of an atom interacting simultaneously with two modes of light [12] .",
        "watermark_text": "We study the second - order correlation function for an atom interacting with two modes of light, one resonant and another off - resonant to atomic transition frequency.We show that higher order antibunching can be observed when the atom is initially prepared in an excited state or ground state superposition.The effect is more pronounced if the initial state has some population on the excited one.This phenomenon may have applications in quantum information processing.Introduction : - In recent years there has been considerable interest in studying nonclassical properties of radiation fields generated by atoms[ 1 ].In particular, it was shown that the photon statistics of such systems are governed by the first - order coherence function g ( 1 ) ( τ )[ 2 ], which describes bunching behavior at short times and anti - bunching at longer times [ 3 ].It is well known that this property arises due to destructive interference between different paths leading to emission of photons[ 4 ].Recently, several authors studied the effects of spontaneous emission on the second - order correlation functions[ 5 ] - [ 8 ].They showed that the presence of spontaneous emission leads to sub - Poissonian statistics[ 6 ] - [ 8 ].However, these studies were restricted only to the case where the atom interacts with a single mode of field.On the other hand, many experiments involving atoms interacting simultaneously with multiple modes of electromagnetic field have also been done [ 9 ] - [ 11 ].For example, in Ref.[ 10 ], the authors investigated the influence of vacuum fluctuations on the fluorescence spectrum of a 3 - level system driven by 2 laser beams.In addition, they found that the intensity noise of the emitted light depends strongly on the relative phase differential between the driving lasers.Motivated by these experimental results we consider here the problem of calculating the second - order correlation function of an atom interacting simultaneously with 2 modes of light [ 12 ]."
    },
    {
        "original_text": "We have performed in-orbit focal adjustment (IFA) for the infrared camera onboard AKARI satellite using its own data taken in orbit. The IFA was carried out by comparing the observed point spread function (PSF) and that simulated based on ray tracing analysis, which is one of the most accurate methods to determine the best focus position. We found that the PSFs were not always consistent between different bands even after the IFA had been completed. This inconsistency may be caused by some errors in the optical design or manufacturing process. In addition, we also found that there are still some problems remaining in the calibration accuracy of the detector pixel size. These results will help us improve our understanding about the performance of the instrument as well as provide useful information for future space missions. Keywords: Space mission, Focal adjustment, Point spread function, Ray tracing analysis, Infrared astronomy, Infrared camera",
        "watermark_text": "We have performed in - orbit focal adjustment ( IFA ) for the infrared camera onboard AKARI satellite using its own data taken in orbit.The IFA was carried out by comparing the observed point spread function ( PSF ) and that simulated based on ray tracking analysis, which is one of the most accuracy methods to determine the best focus position.We found that the PSFs were not always consistent between different bands even after the IFA had been completed.This inconsistency may be caused by some mistakes in the optical design or manufacturing process.In addition, we also found that there are still some problems remaining in the calibration accuracy of the detector pixel size.These results will help We improve our understanding about the performance of the instrument as also as provide useful information for future space missions.Keywords : Space mission, Focal adjustment, Point spread function, Ray tracing analysis, Infrared astronomy, Infrared camera"
    },
    {
        "original_text": "We study the properties of Bose-Einstein condensates (BECs) with an arbitrary number N of particles trapped by a harmonic oscillator and exposed to a disordered external potential. We show that, for any strength of disorder, there is always a finite fraction of atoms localized at each site of the lattice. The localization length decreases as the disorder increases but remains macroscopic even when the disorder becomes very large compared to the interatomic interaction energy. This result holds true both in one dimension and higher dimensions.  In particular we find that the critical disorder above which all states are localized scales like 1/N in 1D and 1/d in 2D and 3D where d is the spatial dimension. Our results provide a microscopic understanding of recent experiments on ultracold atomic gases in optical lattices. Introduction:-Recent experimental advances have made it possible to create quantum degenerate gases of bosons or fermions confined in periodic potentials [1] . These systems can be described theoretically using the framework of the Bose-Hubbard model [2] , which has been extensively studied over the past decade [3] .\nIn this work we consider the case of a gas of interacting bosons in a disordered potential. Disorder leads to Anderson localization [4] : eigenstates become exponentially localized around their initial position if the disorder exceeds some threshold value [5] . It was recently shown experimentally [6] that such a system exhibits a transition between extended Bloch-like states and localized Wannier-Stark ladders [7, 8] . However, these experiments were performed only in the weak-disorder regime, i.e., when the disorder amplitude V0 is much smaller than the characteristic hopping matrix element J. Here we investigate how the presence of interactions affects the physics of strongly disordered systems.",
        "watermark_text": "We study the properties of Bose - Einstein condensates ( BECs ) with an arbitrary number N of particles trapped by a harmonic oscillator and exposed to a disordered external potential.We show that, for any strength of disorder, there is always a finite fraction of atoms localized at each site of the lattice.The localization length decreases as the disorder increases but remains macroscopic even when the disorder becomes very large compared to the interatomic interaction energy.This result holds true both in 1 dimension and upper dimensions.In particular we find that the critical disorder above which all states are localized scales like 1 / N in 1D and 1 / d in 2D and 3D where d is the space dimension.Our results provide a microscopic understanding of recent experiments on ultracold atomic gases in optical lattices.Introduction : - Recent experimental advances have made it possible to create quantum degenerate gases of bosons or fermions confined in periodic potentials[ 1 ].These systems can be described theoretically using the framework of the Bose - Hubbard model [ 2 ], which has been extensively studied over the past decade [ 3 ].In this work we consider the case of a gas of interacting bosons in a disordered potential.Disorder leads to Anderson localization[ 4 ] : eigenstates become exponentially localized around their initial position if the disorder exceeds some threshold value [ 5 ].It was recently shown experimentally [ 6 ] that such a system exhibits a transition between extended Bloch - like states and localized Wannier - Stark ladders [ 7, 8 ].However, these experiments were performed only in the weak - disorder regime, i. e., when the disturbance amplitude V0 is greatly smaller than the characteristic hopping matrix element J.Here we investigate how the presence of interactions affects the physics of strong disordered systems."
    },
    {
        "original_text": "We present new X-ray data on the eclipsing polar, V2301 Oph (=V1429 Aql), obtained with XMM-Newton in 2003 and 2004 . The light curve shows two partial eclipses at orbital phases 0.85-0.95 and 0.65-0.75 which are interpreted as occultations by the accretion curtain. We find that the eclipse profiles change significantly between the two epochs. In particular, we detect an additional dip during phase 0.9-1.0 in 2004 which is not seen in 2003. This feature may be associated with the presence of a third body orbiting around the system. The spectrum can be described well using a combination of a blackbody component for the white dwarf and a power law model for the hard emission. From our spectral fits to both datasets we derive values for the temperature T wd = 16000 ± 1000 K and luminosity L x = 1.1 × 1031 erg s−1 for the white dwarf.",
        "watermark_text": "We present new X - ray data on the eclipsing polar, V2301 Oph ( = V1429 Aql ), obtained with XMM - Newton in 2003 and 2004.The light curve shows 2 partial eclipses at orbital phases 0. 85 - 0. 95 and zero. 65 - 0. 75 which are interpreted as occultations by the accretion curtain.We find that the eclipse profiles change significantly between the two epochs.In particular, we detect an extra dip during stage 0. 9 - 1. 0 in 2004 which is not seen in 2003.This feature may be associated with the presence of a third body orbiting around the system.The spectrum can be described well using a combination of a blackbody constituent for the white dwarf and a power law model for the hard emission.From our spectral fits to both datasets we derive values for the temperature T wd = 16000 ± 1000 K and luminosity L x = 1. 1 x 1031 erg s−1 for the white dwarf."
    },
    {
        "original_text": "The Axion Dark Matter Search (ADMX) experiment is designed to search for dark matter in the form of axions, which are hypothetical particles predicted by theories beyond the Standard Model.  The ADMX experiment consists of two main components: an antenna and a microwave cavity system that can be tuned over a wide range of frequencies.   In this thesis we present results obtained with the first phase of the experiment using data taken between September 2005 and March 2007.    We report limits on the coupling strength of axions to photons as well as limits on the mass of axions produced via Primakoff conversion inside a strong magnetic field.  These results improve upon previous experimental bounds by more than one order of magnitude. This work was performed under the auspices of the U.S Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344. The Axion Dark Matter Search experiment is designed to search directly for dark matter in the universe in the form of axionic particles. The experiment consists of two main parts: an antenna and a microwave resonator system that can be tunable across a large frequency range. In this dissertation I will discuss our recent results from the first stage of the experiment.",
        "watermark_text": "The Axion Dark Matter Search ( ADMX ) experiment is designed to search for dark material in the form of axions, which are hypothetical particles predicted by theories beyond the Graduate Model.The ADMX experiment consists of 2 main components : an antenna and a microwave cavity system that can be tuned over a wide range of frequencies.In this thesis we present results obtained with the initial phase of the experiment utilizing data taken between Sept 2005 and Mar 2007.We report limits on the coupling strength of axions to photons as also as limits on the mass of axions produced via Primakoff converted inside a strong magnetic field.These results improve upon previous experimental bounds by more than one order of magnitude.This work was performed under the auspices of the U. S Department of Energy by Larry Livermore National Laboratory under Contract DE - AC52 - 07NA27344.The Axion Dark Matter Search experiment is designed to seek directly for dark material in the universe in the form of axionic particles.The experiment consists of 2 main parts : an antenna and a microwave resonator system that can be tunable across a large frequency range.In this dissertation I will discuss our recent results from the first stage of the experiment."
    },
    {
        "original_text": "We study the dynamics of random Boolean networks (RBNs) by analyzing their attractors and basins, which are determined by the network's state transition matrix. We show that the number of states in an RBN is bounded above by its average sensitivity (AS), defined as the expected Hamming distance between two randomly chosen nodes at time t+1 given they differed on one node at time t. This bound can be used to estimate the size of the basin of attraction for any fixed point or cycle. In addition, we prove that if AS = 1 then there exists only one attractor with probability one. Finally, we present simulation results showing how our bounds compare against exact values obtained through exhaustive search over small networks. Random Boolean Networks (RBNs) have been widely studied since Kauffman introduced them in 1969 [1] . They consist of N binary-valued nodes connected together into a directed graph where each edge has a weight equal to either 0 or 1. The value of each node i at time step t + 1 depends on the values of all other nodes j at time step t according to some function fji(xj). For example, in Figure 1 , node 2 takes input from both nodes 1 and 3 while node 4 takes no inputs. A sequence of states x1, x2, ..., xt, ... is called an orbit when xi+1 = fi(xi) for every i > 0. An orbit is said to converge to a fixed point or cycle if it eventually repeats itself after a finite number of steps [2] .\nThe behavior of an RBN is completely specified by its adjacency matrix Mij, whose elements represent the weights of edges connecting node i to node j. If Mij = 1, then node i receives input from node j; otherwise, node i does not receive input from node j. Since the output of each node is determined solely by its current state and the states of its neighbors,...",
        "watermark_text": "We study the dynamics of random Boolean networks ( RBNs ) by analyzing their attractors and basins, which are determined by the network ' s state transition matrix.We show that the number of states in an RBN is bounded above by its average sensitivity ( AS ), defined as the expected Hamming distance between 2 randomly selected nodes at time t + 1 given they differed on one node at life t.This bound can be used to estimate the size of the basin of interest for any fixed point or cycle.In addition, we prove that if AS = 1 then there exists only one attractor with probability 1.Finally, we present simulation results showing how our bounds compare against precise values obtained through exhaustive search over small networks.Random Boolean Networks ( RBNs ) have been widely studied since Kauffman introduced them in 1969[ 1 ].They consist of N binary - valued nodes connected together into a directed graph where each edge has a weight equal to whether 0 or 1.The value of each node i at time step t + 1 depends on the values of all other nodes j at time step t according to some function fji ( xj ).For example, in Figure 1, node 2 takes input from both nodes one and 3 while node 4 takes no inputs.A sequence of states x1, x2,., xt,.is called an orbit when xi + 1 = fi ( xi ) for every i > 0.An orbit is said to converge to a fixed point or cycle if it eventually repeats itself after a finite number of steps [ 2 ].The behavior of an RBN is completely specified by its adjacency matrix Mij, whose elements representation the weights of edges linking node i to level j.If Mij = 1, then node i receives input from node j ; otherwise, node i does not receive input from node j. Since the output of each node is determined solely by its present state and the states of its neighbors,."
    },
    {
        "original_text": "We present results on metal and molecular gas cooling in cosmological hydrodynamic simulations with the Enzo code, focusing on the effects of different numerical schemes for solving the energy equation (SPH vs. grid-based) as well as varying physical prescriptions for star formation feedback. We find that SPH codes tend to overestimate the amount of cold gas at high redshifts compared to grid-based methods due to artificial viscosity heating. Feedback models which include galactic winds are able to suppress this effect by removing low entropy material from galaxies. However, we also show that these wind models can lead to an underestimation of the total mass fraction of cool gas if they remove too much hot halo gas around massive halos. Overall our results suggest that current state-of-the-art galaxy formation models produce reasonable estimates for the global properties of the warm-hot intergalactic medium but may still be missing important physics related to the detailed distribution of metals within individual galaxies.",
        "watermark_text": "We present results on metal and molecule gas cooling in cosmological hydrodynamic simulations with the Enzo code, focusing on the effects of different numerical schemes for solving the energy equation ( SPH vs. grid - based ) as well as varying physical prescriptions for star formation feedback.We find that SPH codes tend to overestimate the amount of cold gas at high redshifts compared to grid - based methods due to artificial viscosity heating.Feedback models which include galactic winds are able to suppress this effect by removing low entropy matter from galaxies.However, we still show that these wind models can lead to an underestimation of the total mass fraction of cool gas if they remove too much hot halo gas around massive halos.Overall our results suggest that current state - of - the - art galaxy forming models produce sensible estimates for the global properties of the warm - hot intergalactic medium but might still be missing important physics related to the detailed distribution of metals within individual galaxies."
    },
    {
        "original_text": "We present new optical/NIR data for GRB 060206, which show that its X-ray to radio afterglow is well described by an achromatic break at tbreak = 1.3 days followed by a power-law decay with index -1.2 (Fν ∝ t-1.2). The lack of any spectral evolution across this break suggests it was caused by energy injection into the blast wave. We find no evidence for dust extinction along our line-of-sight; however we cannot rule out significant reddening due to host galaxy dust. Our results are consistent with previous claims that achromatic breaks observed in many other bursts may be explained as being due to late-time energy injections rather than jet-break effects. \n \n Keywords: Gamma-ray burst, Afterglow emission, Energy injection, Jet break, Redshift measurement \n \n INTRODUCTION \n \n In recent years there has been growing interest in understanding how gamma ray bursts (GRBs) produce their broadband electromagnetic radiation. This effort has led to several successful models describing the prompt phase of GRB emission (see e.g., Piran 2005; Zhang 2007), but less progress on explaining the origin of the afterglow component. A key feature of most afterglows is the presence of a steepening or 'jet break' in the light curve around one day postburst (Rhoads 1999) . Such breaks have traditionally been interpreted as marking the time when the relativistic ejecta becomes optically thin to synchrotron self-absorption, causing the flux density to drop rapidly. However, some authors argue that such breaks can also arise if the ejecta undergoes continued energy input following the initial explosion (e.g., Kumar & Panaitescu 2000; Granot et al. 2001; Chevalier & Li 2000) , while others suggest that they could instead result from changes in the geometry of the emitting region (e.g., Racusin et al. 2008 ). An alternative explanation for these breaks invokes interstellar scintillation (Goodman 1997; Goodman & Narayan 2006 ) - a phenomenon",
        "watermark_text": "We present new optical / NIR data for GRB 060206, which show that its X - ray to radio afterglow is well described by an achromatic break at tbreak = 1. 3 days followed by a power - law decay with index - 1. 2 ( Fν [UNK] t - 1. 2 ).The lack of any spectral evolution across this break suggests it was caused by energy injection into the blast wave.We find no proof for dust extinction along our line - of - sight ; however we cannot rule out significant reddening due to host galaxy dust.Our results are consistent with previous claims that achromatic breaks observed in much other bursts may be explained as being owing to late - time energetic injections rather than jet - break effects.Keywords : Gamma - ray burst, Afterglow emission, Energy injection, Jet break, Redshift measurement INTRODUCTION In recent years there has been growing interest in understanding how gamma ray bursts ( GRBs ) produce their broadband electromagnetic radiation.This effort has led to several successful models describing the prompt phase of GRB emission ( see e. g., Piran 2005 ; Zhang 2007 ), but less progress on explaining the origin of the afterglow component.A key feature of most afterglows is the existence of a steepening or ' jet break ' in the light curve around 1 day postburst ( Rhoads 1999 ).Such breaks have traditionally been understood as marking the period when the relativistic ejecta becomes optically thin to synchrotron self - absorbed, causing the flux density to drop rapidly.However, some authors argue that such breaks can also arise if the ejecta undergoes continued energetic input following the initial explosion ( e. g., Kumar & Panaitescu 2000 ; Granot et al. 2001 ; Chevalier & Lie 2000 ), while others suggest that they could instead result from changes in the geometry of the emitting region ( e. g., Racusin et al. 2008 ).An alternative explanation for these breaks invokes interstellar scintillation ( Goodman 1997 ; Goodman & Narayan 2006 ) - a phenomenon"
    },
    {
        "original_text": "We consider the problem of finding an optimal first-order reduced basis space in the context of model reduction using Proper Orthogonal Decomposition (POD). We show that this can be achieved by solving a sequence of generalized eigenvalue problems associated with certain polynomials, which are derived from the original POD Galerkin formulation and its adjoint. The proposed approach is illustrated on two numerical examples. In particular we demonstrate how it allows to find a better approximation than standard greedy algorithms. This work was supported by EPSRC grant EP/K034494/1. Model reduction techniques have been widely used over recent years as efficient tools for reducing computational complexity when simulating complex physical systems governed by partial differential equations (PDEs) [1] . One popular class of methods relies on Proper Orthogonal Decompostion (POD), where one seeks to approximate the solution u(x, t) ∈ R N of a PDE system by projecting onto a low-dimensional subspace spanned by a set of orthonormal functions {φi(x)}Ni=1 [2] , i.e.,",
        "watermark_text": "We consider the problem of finding an optimal first - order reduced base space in the context of model reduction utilizing Proper Orthogonal Decomposition ( POD ).We show that this can be achieved by solving a series of generalized eigenvalue problems associated with certain polynomials, which are derived from the original POD Galerkin formulation and its adjoint.The proposed approach is illustrated on 2 numerical examples.In particular we demonstrate how it allows to find a improved approximation than standard greedy algorithms.This work was supported by EPSRC grant EP / K034494 / 1.Model reduction techniques have been widely used over recent years as efficient tools for reducing computational complexity when simulating complex physical systems governed by partial differential equations ( PDEs )[ 1 ].One popular class of methods relies on Proper Orthogonal Decompostion ( POD ), where one seeks to approximate the solve u ( x, t ) ∈ R N of a PDE system by projecting onto a low - dimensional subspace spanned by a set of orthonormal functions { φi ( x ) } Ni = 1[ 2 ], i. e.,"
    },
    {
        "original_text": "We present an analysis of the temperature dependence of thermally stimulated luminescent (TSL) glow curves in terms of the nonstationary electron-phonon relaxation theory, which does not assume that the system is close to equilibrium at any time during its evolution.  We show how this approach can be used for extracting information about the phonon spectrum and the density of states of charge carriers from TSL data obtained on different types of materials. The results are compared with those obtained by other methods such as photoluminescence excitation spectroscopy or Raman scattering. In particular we demonstrate that our method allows one to determine the energy gap between the conduction band minimum and valence band maximum in semiconductors. This work was supported by Russian Science Foundation grant No. 14-50-00040. DOI: 10.1063/1.4935190 \nI. INTRODUCTORY REMARK\nThe study of luminescence phenomena has been attracting considerable attention over many years because it provides valuable information about electronic structure and optical properties of solids [1] . Thermal stimulation luminescence (TSL), also known as optically stimulated luminescence (OSL), is particularly useful since it enables us to probe the distribution function of electrons excited into the conduction band [2] .\nIn recent decades there have been numerous attempts to develop theoretical models describing various aspects of luminescence processes [3] , including thermal stimulation luminescence [4] - [8] . However, most of these works were based on the assumption that the system under consideration is always close to equilibrium [9] . As a result they cannot describe correctly some important features observed experimentally [10] . For example, the shape of the TSL glow curve depends strongly on the type of material [11] : while in insulators it usually exhibits a single peak [12] , in metals it often consists of several peaks [13] . Moreover, even within the same class of materials, e.g., semiconductor crystals [14] , the number of peaks may vary depending on the doping level [15] . These observations cannot be explained using existing theories [16] .",
        "watermark_text": "We present an analysis of the temperature dependence of thermally stimulated luminescent ( TSL ) glow curves in terms of the nonstationary electron - phonon relaxation theory, which does not assume that the system is close to equilibrium at any time during its evolution.We show how this approach can be used for extracting information about the phonon spectrum and the density of states of charge carriers from TSL data obtained on different types of materials.The results are compared with those obtained by other methods such as photoluminescence excitation spectroscopy or Raman scattering.In particular we demonstrate that our methodology allows one to determine the energy gap between the conduction band minimum and valence band maximum in semiconductors.This work was supported by Russia Science Foundation grant No. 14 - 50 - 00040.DOI : 10. 1063 / 1. 4935190 I. INTRODUCTORY REMARKThe study of luminescence phenomena has been attracting considerable attention over several years because it offers valuable information about electronic structure and optical properties of solids[ 1 ].Thermal stimulation luminescence ( TSL ), also known as optically stimulated luminescence ( OSL ), is particularly useful since it enables us to probe the distribution function of electrons excited into the conduction band[ 2 ].In recent decades there have been numerous attempts to develop theoretical models describing various aspects of luminescence processes [ 3 ], including thermal stimulation luminescence[ 4 ] - [ 8 ].However, most of these works were based on the assumption that the system under consideration is always near to equilibrium[ 9 ].As a result they cannot describe correctly some important features observed experimentally[ 10 ].For example, the shape of the TSL glow curve relies strongly on the type of material [ 11 ] : while in insulators it usually exhibits a single peak [ 12 ], in metals it commonly consists of several ones [ 13 ].Moreover, even within the same class of materials, e. g., semiconductor crystals [ 14 ], the number of tops may vary depending on the doping amount [ 15 ].These observations cannot be explained using existing theories[ 16 ]."
    },
    {
        "original_text": "The universe is expanding at an accelerating rate, which has been attributed to \"dark energy\".  This article reviews the current status of research into dark energy by examining some recent observational results in this area.   The author concludes that there are still many open questions about how best to explain these observations within general relativity theory. In particular, it remains unclear whether or not the observed acceleration can be explained as being due solely to gravitational effects associated with the presence of dark energy. It also appears likely that new physics will need to be introduced if we wish to understand why the expansion of space-time should accelerate rather than decelerate over time. The universe is expanding at an accelerated rate, which has been interpreted as evidence for the existence of \"dark energy\" (DE). This article examines some recent observational results on DE using supernovae Ia data, cosmic microwave background radiation measurements, baryon acoustic oscillations, galaxy cluster counts, weak lensing surveys, and Hubble parameter determinations.",
        "watermark_text": "The universe is expanding at an accelerating rate, which has been attributed to \" dark energy \".This article reviews the existing status of research into dark energy by evaluating some recent observational results in this area.The author concludes that there are still many open questions about how better to explain these observations within general relativity theory.In particular, it remains unclear whether or not the observed acceleration can be explained as being due solely to gravitational effects involved with the presence of dark energy.It also appears likely that new physics will require to be introduced if we want to see why the expansion of space - time should accelerate instead than decelerate over money.The universe is expanding at an accelerated rate, which has been interpreted as evidence for the existence of \" dark energy \" ( DE ).This article examines some recent observational results on DE using supernovae Ia data, cosmic microwave background radiation measurements, baryon acoustic oscillations, galaxy cluster numbers, weak lensing surveys, and Hubble parameter determinations."
    },
    {
        "original_text": "The Sun is the nearest star to Earth, and its activity has been studied for thousands of years.  The Sun's magnetic field plays an important role in solar activity.   In this talk I will discuss how we can use observations made by spacecraft such as SOHO (Solar and Heliospheric Observatory) and SDO (Solar Dynamics Observatory), together with ground-based telescopes on the Canary Islands, to study the Sun's magnetic fields and their relationship to solar activity. This research helps us understand what happens when stars like our Sun die out - they become red giants that eject huge amounts of material into space which may eventually form new planets or even life elsewhere in the Universe. Keywords: Solar Activity, Red Giant Star, Magnetic Field, Space Weather. Title: Cool Stars in Hot Places. Abstract: The Sun is the nearest star  to Earth, and its  activity has been studied for thousand of years. The Sun's magnetic field play an important role in solar activities. In this talk I will discus how we can use observation made by spacecrafts such as SOHO(Solar and Heliospherical Observatory)  and SDO(Solar Dynamics Observatory),  together with ground based telescope on the Canary Island,  to study the Sun's magentic fields and their relation to solar activity. This reseach help us understant what happen when stars like our sun dies out- they becom red giant stars that ejecta huge amount of materiel into space whic may eventually form new planet or even life elsewere in universe.",
        "watermark_text": "The Sun is the closest star to Earth, and its action has been studied for thousands of years.The Sun ' s magnetic field plays an important role in solar activity.In this talk I will talk how we can use observations made by satellites such as SOHO ( Solar and Heliospheric Observatory ) and SDO ( Solar Dynamics Observatory ), along with ground - based telescopes on the Canary Islands, to study the Sun ' s magnetic fields and their relationship to solar activity.This research helps us understand what occurs when stars like our Sun die out - they become reddish giants that eject huge amounts of material into space which might eventually form new planets or indeed life else in the Universe.Keywords : Solar Activity, Red Giant Star, Magnetic Field, Space Weather.Title : Cool Stars in Hot Places.Abstract :The Sun is the closest star to Earth, and its activity has been studied for thousand of ages.The Sun ' s magnetic field play an important role in sun activities.In this talk I will discus how we can utilize observation made by spacecrafts such as SOHO ( Solar and Heliospherical Observatory ) and SDO ( Solar Dynamics Observatory ), together with ground based telescope on the Canary Island, to study the Sun ' s magentic fields and their relation to solar activity.This reseach help us understant what happen when stars like our sun dies out - they becom red giant stars that ejecta huge amount of materiel into space whic may eventually form new planet or even life elsewere in universe."
    },
    {
        "original_text": "We present results on modeling the spectral energy distribution (SED) and variability of the blazar 3C 66A observed by the Whole Earth Blazar Telescope (WEBT). The SED is modeled with an accretion disk, synchrotron emission from relativistic electrons in jets, inverse Compton scattering off soft photons produced within the jet or external to it, and thermal radiation from dusty clouds surrounding the central engine. We find that the model can reproduce most features of the SED: the optical-UV spectrum; the X-ray spectrum; the infrared-optical flux ratio; and the radio-to-optical spectral index. However, we cannot explain why there are two peaks in the UV spectrum at ~1400 Å and ~1900 Å simultaneously. In addition, our model fails to account for the rapid flares detected in the light curve of this source. This suggests that either additional components should be included into the model and/or some physical processes have been neglected. \n \n Keywords: blazars, 3C 66A",
        "watermark_text": "We present results on modeling the spectral energy distribution ( SED ) and variability of the blazar 3C 66A observed by the Whole Earth Blazar Telescope ( WEBT ).The SED is modeled with an accretion disc, synchrotron emission from relativistic electrons in jets, inverse Compton scattering off soft photons produced within the jet or external to it, and heat radiation from dusty clouds surrounding the central engine.We find that the model can produce most features of the SED : the optical - UV spectrum ; the X - linked spectrum ; the infrared - optical flux ratio ; and the radio - to - optical spectral index.However, we cannot explain why there are 2 peaks in the UV spectrum at ~ 1400 Å and ~ 1900 Å simultaneously.In addition, our model fails to account for the rapid flares detected in the light curve of this source.This suggests that either extra components should be included into the model and / or some physical procedures have been neglected.Keywords : blazars, 3C 66A"
    },
    {
        "original_text": "We show that the observed value of the cosmological constant is systematically affected by the presence of matter around us, and we calculate this effect for different models of dark energy.  We find that the correction can be significant (up to 30%) if one assumes that the universe has an average density equal to the critical density today. The correction becomes smaller when the universe is less dense than the critical density or more negative pressure is assumed. This systematic error may explain why the current measurements are not consistent with each other within their errors. In addition, it could also affect future experiments aimed at measuring the time evolution of the cosmological constant. Introduction -The recent discovery of accelerated expansion of our Universe [1] , which implies existence of some form of \"dark energy\" [2] , leads naturally to the question about its nature [3] . One possibility is that the dark energy is simply vacuum energy [4] . Another option is that the dark energy consists of new particles such as axions [5] .\nIn order to test these ideas observationally, precise measurement of the properties of dark energy is needed [6] . However, there are several difficulties associated with this task [7, 8] . For example, even though the present-day acceleration of the universe is very small compared to the Hubble parameter H 0 = 100h km/s/Mpc [9] , where h ≈ 0.7 ± 0.1 [10] , the corresponding change in the scale factor over the age of the universe is large enough so that the effects on the distance-redshift relation cannot be neglected [11] . Moreover, since the dark energy affects both space and time [12] , it changes the rate of clocks [13] and thus introduces additional uncertainty into the determination of distances [14] . Finally, the fact that the dark energy evolves with time [15] makes the problem much harder [16] .\nOne way to overcome these problems is to measure directly the equation-of-state w(z), defined as [17] \nwhere p de and ρ de are respectively the pressure and density of the dark energy. If the dark energy behaves like a perfect fluid then w(z) ≡ −1 [18] . It was shown recently [19] that the most",
        "watermark_text": "We show that the observed value of the cosmological constant is systematically impacted by the existence of material around us, and we calculate this effect for different models of dark energy.We find that the correction can be significant ( up to 30 % ) if one assumptions that the universe has an average density equal to the critical density today.The correction becomes narrower when the universe is fewer dense than the critical dense or more negative pressure is assumed.This systematic error may explain why the present measurements are not consistent with each other within their mistakes.In addition, it could also affect future experiments aimed at measuring the time evolution of the cosmological invariant.Introduction - The recent discovery of accelerated expansion of our Universe[ 1 ], which implies existence of some form of \" dark energy \"[ 2 ], leads naturally to the question about its nature[ 3 ].One possibility is that the dark energy is simply vacuum energy [ 4 ].Another option is that the dark energy consists of new particles such as axions [ 5 ].In order to test these ideas observationally, exact measurement of the properties of dark energy is needed [ 6 ].However, there are several difficulties associated with this task[ 7, 8 ].For example, even though the present - day acceleration of the universe is very small compared to the Hubble parameter H 0 = 100h kilometres / s / Mpc[ 9 ], where h ≈ 0. 7 ± 0. 1 [ 10 ], the corresponding change in the scale factor over the age of the universe is large enough so that the effects on the distance - redshift relation cannot be neglected [ 11 ].Moreover, since the dark energy affects both space and time [ 12 ], it changes the rate of clocks [ 13 ] and thus introduces additional doubt into the determination of distances [ 14 ].Finally, the fact that the dark energy evolves with time [ 15 ] makes the challenge much harder [ 16 ].One way to overcome these problems is to measure directly the equation - of - state w ( z ), defined as [ 17 ] where p de and ρ de are respectively the pressure and density of the dark energy.If the dark energy behaves like a perfect liquid then w ( z ) ≡ −1[ 18 ].It was presented recently [ 19 ] that the most"
    },
    {
        "original_text": "We present new spectroscopic data for the galaxy cluster Abell115 (z=0.084) obtained with the VLT/FORS2 instrument in order to study its dynamics and mass distribution. We have observed 23 galaxies within an aperture radius of 1 Mpc centered on the brightest cluster member, which is also the central dominant galaxy. The velocity dispersion profile shows no significant variation across the whole region covered by our observations. This result suggests that Abell115 has not experienced any major merger event since z=1.5-2.0. Using Jeans models we find evidence for a dark matter halo extending out to at least 3 times the virial radius. From this analysis we derive a total mass of 2.1(+0.7-0.6)x10^14M_sun inside a sphere of radius R200=850kpc. Finally, using weak lensing measurements we estimate a mass-to-light ratio of about 400h/M_luminosity_Solar_Unit.",
        "watermark_text": "We present new spectroscopic data for the galaxy cluster Abell115 ( z = 0. 084 ) obtained with the VLT / FORS2 instrument in order to study its dynamics and massive distribution.We have observed 23 galaxies inside an aperture radius of 1 Mpc centered on the brightest cluster member, which is also the central dominant galaxy.The velocity dispersion profile shows no significant variation across the whole region covered by our observations.This result suggests that Abell115 has not experienced any major merger event following z = 1. 5 - 2. 0.Using Jeans models we find evidence for a black matter halo extending out to at least 3 times the virial radius.From this analysis we derive a total mass of 2. 1 ( + 0. 7 - zero. 6 ) x10 ^ 14M _ sunlight inside a sphere of radius R200 = 850kpc.Finally, using weak lensing measurements we estimate a mass - to - light ratio of about 400h / M _ luminosity _ Solar _ Unit."
    },
    {
        "original_text": "We present results on the role played by the rho meson in describing pion electroproduction data obtained with the CLAS detector at Jefferson Lab (JLab). The analysis is performed within an effective field theory approach, where we use chiral perturbation theory to describe the interaction between pions and nucleons up to next-to-leading order. We then introduce vector-meson degrees of freedom through the hidden gauge formalism. In particular, we consider contributions coming from one-loop diagrams involving rho mesons as well as tree-level processes mediated by rho mesons. Our theoretical framework allows us to study both neutral current reactions such as elastic ep scattering or charged current reactions like single-pion production off protons. Using this model, we are able to reproduce experimental data for all these observables simultaneously. Finally, we discuss how our findings can be used to extract information about the properties of the rho meson. This work was supported by the U.S. \n\n\nDepartment of Energy under Contract No. DE-SC0012704.\n\nPACS numbers: 12.38.Mh",
        "watermark_text": "We present results on the role played by the rho meson in describing pion electroproduction data obtained with the CLAS detection at Jefferson Lab ( JLab ).The analysis is performed within an effective field theory approach, where we use chiral perturbation theory to describe the interaction between pions and nucleons up to next - to - leading order.We then introduce vector - meson degrees of freedom through the hidden gauge formalism.In particular, we consider contributions coming from one - loop diagrams involving rho mesons as also as tree - level processes mediated by rho mesons.Our theoretical framework allows us to study both neutral current reactions such as elastic ep scattering or charged current reactions like single - pion production off protons.Using this model, we are able to reproduce experiment data for all these observables concurrently.Finally, we discuss how our discoveries can be used to extract information about the properties of the rho meson.This work was supported by the U. St. Department of Energy under Contract No. DE - SC0012704. PACS numbers : 12. 38. Mh"
    },
    {
        "original_text": "We prove that the Poincare duality pairs are exactly those which can be obtained by gluing together two copies of the same surface along their boundaries, and we give an explicit description for all such surfaces.  We also show how to construct these surfaces using only elementary operations on polygons with holes. The Poincare conjecture states that any closed orientable 3-manifold is homeomorphic to either S 3 , R 3 or one of the lens spaces L(p,q) where p and q are relatively prime integers greater than 1. In this note we study another class of manifolds called Poincare duality pairs: These are simply connected compact oriented 3-manifolds M whose intersection form Q satisfies Q = −Q t . It follows immediately from the definition that if M is a Poincare duality manifold then it has signature zero (i.e., its second Stiefel-Whitney class vanishes).",
        "watermark_text": "We prove that the Poincare duality pairs are exactly those which can be obtained by gluing together two copies of the same surface along their boundaries, and we give an explicitly description for all such surfaces.We also show how to construct these surfaces using only elementary operations on polygons with holes.The Poincare conjecture states that any closed orientable 3 - manifold is homeomorphic to either S 3, R 3 or either of the lens spaces L ( p, q ) where p and q are comparatively prime integers greater than one.In this note we study another class of manifolds called Poincare duality pairs : These are simple connected compact oriented 3 - manifolds M whose intersection form Q satisfies Q = −Q t.It follows immediately from the definition that if M is a Poincare duality manifold then it has signature zero ( i. e., its second Stiefel - Whitney class vanishes )."
    },
    {
        "original_text": "We present new near-infrared (NIR) and millimeter-wave observations of the starless dense core FeSt 1-457, which is located in the Taurus molecular cloud complex at a distance of 140 pc. The NIR data were obtained with the Subaru telescope using the SofI instrument on 2005 May 24-25 UT. We detected two sources within the central 0.5 arcmin region; one source was found to be associated with an infrared dark cloud (IRDC), while another source was not. Both sources are embedded deeply inside the dusty envelope surrounding the dense core. In addition, we observed this object simultaneously with the Nobeyama 45 m radio telescope at 1 mm wavelength during the same night as our NIR observation. No significant emission line features were seen in either spectrum. Using these observational results, we discuss possible scenarios for the formation of stars in such a young dense core.",
        "watermark_text": "We present new near - infrared ( NIR ) and millimeter - wave observations of the starless dense core FeSt 1 - 457, which is located in the Taurus molecules cloud complex at a distance of 140 pc.The NIR data were obtained with the Subaru telescope using the SofI instrument on 2005 May 24 - 25 UT.We detected 2 sources within the central 0. 5 arcmin region ; one source was found to be associated with an infrared dark cloud ( IRDC ), while another source was not.Both sources are embedded deeply inside the dusty envelope surrounding the dense core.In addition, we observed this object simultaneously with the Nobeyama 45 m radio telescope at one mm wavelength during the same night as our NIR observation.No significant emission line features were seen in either spectrum.Using these observational results, we discuss possible scenarios for the formation of stars in such a young dense core."
    },
    {
        "original_text": "The reaction mechanism for the ring-opening reactions of cyclic alkanes with water has been studied using density functional theory (DFT) and ab initio molecular orbital methods at the B3LYP/6-311++G(d,p), MP2/6-31+G*, QCISD/6-31+G* levels in conjunction with the CBS-QB3 method to calculate enthalpies of formation.  The results show that the activation energies are lower than those obtained previously by DFT or semiempirical methods. In addition, it is found that the transition states have one imaginary frequency along the reaction coordinate corresponding to the breaking of C-H bonds on both sides of the carbonyl group. The calculated rate constants agree well with experimental data over a wide temperature range. Finally, we propose an explanation for the observed differences between theoretical predictions and experiments based on the fact that the solvent effect was not taken into account in previous studies.",
        "watermark_text": "The reaction mechanism for the ring - opening reactions of cyclic alkanes with water has been studied utilizing density functional theory ( DFT ) and ab initio molecule orbital techniques at the B3LYP / six - 311 + + G ( d, pp ), MP2 / six - 31 + G *, QCISD / 6 - 31 + G * levels in conjunction with the CBS - QB3 method to calculate enthalpies of formation.The results show that the activation energies are lower than those obtained previously by DFT or semiempirical methods.In addition, it is found that the transition states have one imaginary frequency along the reaction coordinate corresponding to the breaking of C - H bonds on both sides of the carbonyl group.The calculated rate constants agree well with experimental data over a wide temperature range.Finally, we propose an explanation for the observed differences between theoretical predictions and experiments based on the fact that the solvent effect was not taken into account in previous studies."
    },
    {
        "original_text": "The equilibrium fluctuations in isolated systems are studied by using statistical mechanics and information theory. The entropy production rate is calculated for different types of isolated systems: (i) closed, (ii) open, and (iii) dissipative. It is shown that the entropy production rate can be expressed as a sum over all possible transitions between states weighted with their respective transition probabilities. For closed systems it is found to be equal to zero at thermal equilibrium. This result agrees well with previous results obtained within linear response theory. In contrast, for open or dissipative systems we find that the entropy production rate does not vanish even if they reach thermal equilibrium. We show how this finding leads to a new interpretation of the second law of thermodynamics. Finally, we discuss our findings in terms of fluctuation theorems. PACS: 05.45.Mt, 02.10.Yn, 03.65.Ta Keywords: Entropy Production Rate, Second Law of Thermodynamics",
        "watermark_text": "The equilibrium fluctuations in isolated systems are studied by utilizing statistical mechanics and information theory.The entropy production rate is calculated for different types of isolated systems : ( i ) closed, ( ii ) open, and ( iii ) dissipative.It is shown that the entropy production scale can be expressed as a sum over all available transitions between states weighted with their respective transition probabilities.For closed systems it is found to be equal to zero at thermal equilibrium.This result agrees well with previous results obtained within linear response theory.In contrast, for open or dissipative systems we find that the entropy production rate does not vanish even if they reach thermal balance.We show how this discovery leads to a new interpretation of the second law of thermodynamics.Finally, we discuss our findings in terms of fluctuation theorems.PACS :05. 45. Mt, 02. 10. Yn, 03. 65. Ta Keywords : Entropy Production Rate, Second Law of Thermodynamics"
    },
    {
        "original_text": "We present the discovery, photometric and spectroscopic observations of SN 2005hj (PTF10ygu), an apparently normal-bright Type Ia supernova discovered by PTF in late March 2005 at z = 0.084. The light curve shows two distinct peaks separated by about one month with no evidence for interaction between ejecta and circumstellar material. We find that this object is consistent with being a member of the class of \"normal-bright\" SNe Ia defined by Phillips et al. (1999) but has a higher peak luminosity than most members of this class. Using our own data as well as published results we estimate the distance to SN 2005hj using three different methods. All three give distances which are inconsistent with each other within their uncertainties. This may be due to systematic errors or it could indicate that there exists more than one subclass of \"normal-bright\" objects. If confirmed, these findings have important implications for cosmological studies based on SNe Ia. \n \n Keywords: Supernovae",
        "watermark_text": "We present the discovery, photometric and spectroscopic observations of SN 2005hj ( PTF10ygu ), an apparently normal - bright Type Ia supernova discovered by PTF in late March 2005 at z = 0. 084.The light curve shows 2 distinct peaks separated by about one month with no evidence for interaction between ejecta and circumstellar material.We find that this object is consistent with being a member of the class of \" ordinary - bright \" SNe Ia defined by Phillips e al. ( 1999 ) but has a upper peak luminosity than most members of this class.Using our own data as well as published results we estimate the distance to SN 2005hj using three different methods.All three give distances which are inconsistent with each other inside their uncertainties.This may be due to systematic errors or it could indicate that there exists more than single subclass of \" ordinary - bright \" objects.If confirmed, these findings have important implications for cosmological studies based on SNe Ia. Keywords : Supernovae"
    },
    {
        "original_text": "We present the results of our study on super star clusters (SSCs) in which we have found that SSCs can be divided into two categories, namely, those having a single mode and those having a double-mode solution for their density profiles. We show how these solutions are related to each other by using approximate analytic methods. The main aim is to understand why some SSCs appear as point sources while others do not. In this work, we also discuss the possibility of formation of such objects through mergers between smaller clusters or stars. Super massive star clusters (SMCs), known as young globular clusters (YGCs), open clusters (OCs), compact elliptical galaxies (CEGs), etc., are observed in many galactic systems ranging from dwarf irregular galaxies to giant ellipticals. These objects are believed to form during violent events like galaxy mergers, tidal interactions, and/or gas-rich major mergers. However, it has been shown recently that there exists another class of SMCs whose luminosity function shows a peak at intermediate masses (10^6-10^7 Msun). This type of cluster is referred to as \"Intermediate Massive Clusters\"(IMCs; Portegies Zwart et al. (2010)). It appears that IMCs may represent a transition phase between open clusters and YGCs.",
        "watermark_text": "We present the results of our study on super stellar clusters ( SSCs ) in which we have found that SSCs can be divided into two categories, namely, those having a single mode and those having a double - role solution for their dense profiles.We show how these solutions are related to each other by utilizing approximate analytic techniques.The main aim is to understand why some SSCs seem as point sources while others do not.In this work, we even discuss the potential of formation of such objects through mergers between smaller clusters or stars.Super massive star clusters ( SMCs ), known as young globular clusters ( YGCs ), open clusters ( OCs ), compact elliptical galaxies ( CEGs ), etc., are observed in many galactic systems ranging from dwarf irregular galaxies to giant ellipticals.These objects are believed to form during violent events like galaxy mergers, tidal interactions, and / or gas - rich major mergers.However, it has been shown recently that there exists another class of SMCs whose luminosity function shows a high at medium masses ( 10 ^ six - ten ^ 7 Msun ).This type of cluster is referred to as \" Intermediate Massive Clusters \" ( IMCs ; Portegies Zwart et al. ( 2010 ) ).It appears that IMCs may denote a transition phase between open clusters and YGCs."
    },
    {
        "original_text": "We have performed ab initio molecular dynamics simulations to study the in-plane structure, order parameters, and surface tension of liquid Na(l) in contact with vacuum or solid NaCl (001). We find that the density profile is strongly dependent on the presence of an underlying substrate; it exhibits a pronounced double peak for the case without substrate but becomes single-peaked when the substrate is present. The height fluctuations are found to be larger than those observed experimentally by STM measurements. This discrepancy may arise due to the fact that our simulation cell contains only one layer of liquid sodium atoms while experiments typically involve several layers. In addition, we observe that the average nearest neighbor distance decreases as the number of layers increases. Our results show that the in-plane structure of liquid sodium can be significantly influenced by its environment. Finally, we calculate the surface tensions using two different methods and compare them against each other.",
        "watermark_text": "We have performed ab initio molecular dynamics simulations to study the in - plane structure, order parameters, and surface tension of liquid Na ( l ) in contact with vacuum or solid NaCl ( 001 ).We find that the density profile is strongly dependent on the presence of an embedded substrate ; it exhibits a pronounced double peak for the case without substrate but becomes single - peaked when the substrate is present.The height fluctuations are found to be larger than those observed experimentally by STM measurements.This discrepancy may arise due to the fact that our simulation cell contains only 1 layer of fluid sodium atoms while experiments typically involve several layers.In addition, we observe that the average closest neighbor distance decreases as the number of layers increases.Our results show that the in - plane structure of liquid sodium can be significantly influenced by its environmental.Finally, we calculate the surface tensions using two different methods and compare them against each other."
    },
    {
        "original_text": "We present new results on diffuse gamma-ray emission produced by cosmic rays interacting with interstellar gas, based on data collected during the first year of operation of the Large Area Telescope (LAT) aboard Fermi satellite. We find that this component is well described by a power law spectrum with index ~2.3 extending up to 100 GeV. The total flux above 1 GeV amounts to about 10% of the observed Galactic diffuse emission at these energies. This result confirms previous estimates obtained using EGRET data. In addition we report an upper limit for the flux of unresolved point sources below 10 GeV which is consistent with predictions made within the framework of standard models of cosmic ray origin and propagation. Finally, we discuss implications of our findings for the interpretation of observations performed towards the supernova remnant RX J1713.7--3946. PACS numbers: 98.70.Sa, 95.55.Ym",
        "watermark_text": "We present new results on diffuse gamma - ray emission produced by cosmic rays interacting with interstellar gas, based on data collected during the initial year of operation of the Large Area Telescope ( LAT ) aboard Fermi satellite.We find that this component is well described by a power law spectrum with index ~ 2. 03 extending up to 100 GeV.The total flux above 1 GeV amounts to about 10 % of the observed Galactic diffuse emission at these energies.This result confirms previous estimates obtained using EGRET data.In addition we report an upper limit for the flux of unresolved point sources below 10 GeV which is consistent with predictions made within the frame of standard models of cosmic ray origin and propagation.Finally, we discuss implications of our findings for the interpretation of observations performed towards the supernova remnant RX J1713. 7 - - 3946.PACS numbers : 98. 70. Sa, 95. 55. Ym"
    },
    {
        "original_text": "We present new results on gamma-ray emission produced by cosmic rays interacting with interstellar gas, based on observations made with the HESS telescope array between 2004 and 2007. We report an improved measurement of the spectrum of the brightest source detected at TeV energies, RX J1713.7--3946 (HESS J1714-385), which is well described by a power law with index = 2.28 ± 0.04 stat ± 0.1 sys . The integral flux above 1 TeV amounts to (2.6 +/- 0.4) x 10-12 cm-2 s-1 , corresponding to about 10% of the total Galactic diffuse emission observed at these energies. This result confirms that this object is indeed a supernova remnant as suggested previously. \n \n In addition we have discovered two new sources within the field-of-view of our instrumentation. One of them has been identified with the shell-type supernova remnant G349.7+0.2 while another one remains unidentified.",
        "watermark_text": "We present fresh results on gamma - ray emission produced by cosmic rays interacting with interstellar gas, based on observations made with the HESS telescope array between 2004 and 2007.We report an improved measurement of the spectrum of the brightest source detected at TeV energies, RX J1713. 7 - - 3946 ( HESS J1714 - 385 ), which is well described by a power law with index = 2. 28 ± 0. 04 stat ± 0. 1 sys.The integral flux above 1 TeV amounts to ( 2. 6 + / - 0. 4 ) x 10 - twelve cm - 2 s - 1, corresponding to about 10 % of the total Galactic diffuse emission observed at these energies.This result confirms that this object is indeed a supernova remnant as suggested previously.In addition we have discovered two new sources inside the field - of - view of our instrumentation.One of them has been identified with the shell - type supernova remnant G349. 7 + 0. 2 while others one remains unidentified."
    },
    {
        "original_text": "We present the results of an automated search for star cluster candidates (SCCs) using deep HST/ACS images covering most of the disk and halo of M33, obtained as part of program GO-10229. The SCCs were identified by applying the DAOPHOT photometry package to detect sources with high surface brightnesses relative to their local backgrounds. We then applied several selection criteria based on color-magnitude diagrams (CMDs), luminosity functions (LFs), and radial profiles to identify bona fide SCCs among these bright objects. A total of 1,082 candidate clusters are found within our survey area; we estimate that about half of them may be real open clusters or associations. These newly discovered SCCs will provide important targets for future spectroscopic studies aimed at understanding how star formation proceeds in low-metallicity environments such as those found in dwarf galaxies like M33.",
        "watermark_text": "We present the results of an automatic search for star cluster candidates ( SCCs ) using deep HST / ACS images covering most of the disk and halo of M33, obtained as part of program GO - 10229.The SCCs were identified by applying the DAOPHOT photometry package to detect sources with high surface brightnesses relative to their local backgrounds.We then applied several selection parameters based on color - magnitude diagrams ( CMDs ), luminosity functions ( LFs ), and radiating profiles to identify bona fide SCCs among these bright objects.A total of 1, 082 candidate clusters are found within our survey region ; we estimate that about half of them may be real open ones or associations.These newly discovered SCCs will provide important targets for future spectroscopic studies targeted at understanding how star formation proceeds in low - metallicity environments such as those found in dwarf galaxies like M33."
    },
    {
        "original_text": "The measurement of ultra-low potassium contaminations in silicon is important for the development and production of semiconductor devices, especially solar cells. The detection limit of conventional methods such as flame photometry or atomic absorption spectroscopy (AAS) is not sufficient to meet the requirements set by industry standards. In this work we present an alternative method based on accelerator mass spectrometry (AMS). We show that AMS can be used to measure potassium concentrations down to 10(-12) at% K in Si samples. This corresponds to a sensitivity improvement by three orders of magnitude compared to standard techniques like flame photometry. Furthermore, our results demonstrate that AMS has no significant matrix effects when measuring low-potassium doped Si wafers. Finally, we discuss possible applications of AMS beyond its use as a highly sensitive analytical tool. Keywords: Silicon wafer, Accelerator mass spectrometry, Flame photometry",
        "watermark_text": "The measurement of ultra - low potassium contaminations in silicon is crucial for the development and production of semiconductor devices, especially solar cells.The detection limit of traditional methods such as flame photometry or atomic absorption spectroscopy ( AAS ) is not sufficient to meet the requirements set by industry standards.In this work we present an alternative method based on accelerator mass spectrometry ( AMS ).We show that AMS can be used to measure potassium concentrations down to 10 ( - 12 ) at % K in Si samples.This corresponds to a sensitivity improvement by 3 orders of magnitude compared to standard techniques like flame photometry.Furthermore, our results demonstrate that AMS has no significant matrix effects when testing low - potassium doped Si wafers.Finally, we discuss potential applications of AMS outside its use as a high sensitive analysis tool.Keywords : Silicon wafer, Accelerator mass spectrometry, Flame photometry"
    },
    {
        "original_text": "We present new evolutionary tracks for low-mass stars with initial masses between 0.8 and 8 M⊙, which include convective overshooting in both core helium burning (CHeB) and red giant branch phases as well as mass loss on the AGB phase. We compare these models to observations of Galactic open clusters and find that they reproduce the observed luminosity function very well at all ages up to 1 Gyr. The predicted number ratio of carbon-rich to oxygen-rich AGB stars is also consistent with observations. However, we show that our current set of models fails to explain the existence of extremely luminous C-stars found among old open cluster members. These objects are located above the tip of the RGB but below the theoretical limit of the TP-AGB phase. They may be explained by assuming an additional mixing process during the early stages of the TP-AGB; however, this requires further investigation. \n \n Keywords: Post-AGB evolution",
        "watermark_text": "We present new evolutionary tracks for low - mass stars with initial masses between 0. 8 and 8 [UNK], which include convective overshooting in both core helium burning ( CHeB ) and red giant branch phases as well as mass loss on the AGB phase.We compare these models to observations of Galactic open clusters and find that they reproduce the observed luminosity function very well at all ages up to 1 Gyr.The predicted number ratio of carbon - rich to oxygen - rich AGB stars is also consistent with observations.However, we show that our current set of models lacks to explanation the existence of extremely luminous C - stars found among old open cluster members.These objects are located above the tip of the RGB but below the theoretical limit of the TP - AGB phase.They may be explained by assuming an additional mixing process during the early phases of the TP - AGB ; however, this requires further investigation.Keywords : Post - AGB evolution"
    },
    {
        "original_text": "We study the dynamics of particles suspended in an idealized, two-dimensional turbulent jet using direct numerical simulations (DNS). The jet is forced by imposing random velocity fluctuations at its inflow boundary; it develops into a coherent vortex street downstream that breaks down further downstream to form small-scale turbulence. We find that the particle trajectories are strongly influenced by the presence of large-scale vortices which trap them for extended periods of time. In addition, we observe that the particles can be trapped within smaller scale eddies as well. These dynamical traps lead to enhanced concentration levels of particles along certain regions of their trajectory. Finally, we show that the trapping effect depends on the initial position of the particles with respect to the mean flow direction. Our results suggest that this mechanism may play an important role in the transport of pollutants or other tracers in geophysical flows such as atmospheric jets. Turbulence plays an important role in many natural phenomena ranging from weather prediction to oceanic mixing processes [1] . It also has significant impact on industrial applications including combustion [2] , chemical engineering [3] , and fluid mechanics [4] .\nIn recent years there have been several studies aimed at understanding how particles behave when they are suspended in a turbulent flow [5] - [8] . This problem is relevant not only because of practical reasons but also due to fundamental interest in studying the statistical properties of Lagrangian trajectories [9] . For example, one would like to know whether particles tend to cluster together [10] or disperse homogeneously [11] depending upon their size [12] and/or shape [13] .",
        "watermark_text": "We study the dynamics of particles suspension in an idealized, two - dimension turbulent jet utilizing direct numerical simulations ( DNS ).The jet is forced by imposing randomly velocity fluctuations at its inflow border ; it develops into a coherent vortex street downstream that breaks down further downstream to form small - scale turbulence.We find that the particle trajectories are strongly influenced by the presence of large - scale vortices which trap them for extended periods of time.In addition, we observe that the particles can be trapped inside smaller scale eddies as also.These dynamical traps lead to enhanced concentration concentrations of particles along certain regions of their trajectory.Finally, we show that the trapping effect depends on the early position of the particles with respect to the mean flow direction.Our results suggest that this mechanism may play an important role in the transport of pollutants or other tracers in geophysical flows such as atmospheric jets.Turbulence plays an influential role in many natural phenomena ranging from weather prediction to oceanic mixing procedures [ 1 ].It also has significant impact on industrial applications including combustion[ 2 ], chemical engineering [ 3 ], and fluid mechanics [ 4 ].In recent years there have been several studies aimed at understanding how particles behave when they are suspended in a turbulent flow[ 5 ] - [ 8 ].This problem is relevant not only because of practical causes but even due to basic interest in studying the statistical properties of Lagrangian trajectories [ 9 ].For example, one would like to know whether particles tend to cluster together [ 10 ] or disperse homogeneously [ eleven ] depending upon their size[ 12 ] and / or shape[ 13 ]."
    },
    {
        "original_text": "We present proper motions for stars with magnitudes between 8 and 16, obtained by combining data from two epochs of photographic plates taken at the Palomar Observatory (POSS-I) and one epoch of digital images taken with the Hubble Space Telescope (HST). The sample consists of about 1 million objects located within a region centered on the galactic center that is known as \"Plaut's window\".  We find that our results are consistent with previous measurements made using POSS-II plates combined with HST observations. However, we also find significant differences when compared to other recent studies based on similar datasets but different analysis techniques. These discrepancies may be due to systematic errors introduced during the reduction process or they could indicate real changes in the structure of the bulge over time. Our final catalogue will be available online through the CDS Vizier service. This work was supported by NASA grant NAG5-13523.",
        "watermark_text": "We present proper motions for stars with magnitudes between 8 and 16, obtained by combining data from two epochs of photographic plates taken at the Palomar Observatory ( POSS - I ) and one epoch of digital images taken with the Hubble Space Telescope ( HST ).The sample consists of about 1 million items located within a region centered on the galactic center that is known as \" Plaut ' s window \".We find that our results are consistent with previous measurements made using POSS - II plates combined with HST observations.However, we also find significant differences when compared to other recent studies based on similar datasets but different analysis techniques.These discrepancies may be due to systematic errors introduced during the reduction process or they could indicate real changes in the structure of the bulge over time.Our final catalog will be online online through the CDS Vizier service.This work was supported by NASA grant NAG5 - 13523."
    },
    {
        "original_text": "We present new spectroscopic observations for nine cataclysmic variable stars (CVs) obtained with the HIRES spectrograph on Keck I telescope in Hawaii, and compare them to previous results. We find that all CVs show double-peaked emission lines which are characteristic features of accretion disks around white dwarfs. The line profiles change dramatically during outburst phases when mass transfer rates increase by several orders of magnitude compared to quiescent states. In addition we detect absorption components at red-shifted velocities in some systems indicating the presence of an extended disk wind or stream overflowing into the disk. These results provide important constraints on theoretical models of CV evolution. \n \n Keywords: Accretion Disk, Double-Peaked Emission Lines, White Dwarf, Cataclysmic Variables \n \n \n \n 1 Introduction \n \n Cataclysmic variables (CVs), also known as dwarf novae, are close binary systems consisting of a white dwarf primary star and a late-type secondary star filling its Roche lobe. Mass is transferred through the inner Lagrangian point L1 onto the surface of the white dwarf where it forms an accretion disk surrounding the compact object. This process leads to periodic outbursts caused by thermal instabilities in the accretion disk resulting in dramatic changes in luminosity over time scales ranging from hours up to years [1] . During these outbursts, the accretion rate increases by several orders of magnitude leading to strong winds and high temperatures in the disk [2] , while the system becomes fainter than usual due to obscuration effects [3] .\n \nThe study of CVs provides valuable information about the physical processes involved in accretion flows [4] , magnetic fields [5] , and angular momentum transport [6] . Furthermore, they can be used as distance indicators [7, 8] and probes of galactic structure [9] . \n \n 2 Observations & Data Reduction \n \n Our sample consists of 9 CVs observed between 2004 and 2007 using the High Resolution Echelle Spectrometer (HIRES) [10] mounted on the 10 m Keck I telescope located on Mauna Kea",
        "watermark_text": "We present fresh spectroscopic observations for nine cataclysmic variable stars ( CVs ) obtained with the HIRES spectrograph on Keck I telescope in Hawaii, and compare them to previous results.We find that all CVs display double - peaked emission lines which are characteristic features of accretion discs around white dwarfs.The line profiles change dramatically during outburst phases when mass transfer rates increase by several orders of sign compared to quiescent states.In addition we detect absorption components at red - shifted velocities in some systems indicating the presence of an extended disk wind or stream overflowing into the disk.These results provide important constraints on theoretical models of CV evolution.Keywords : Accretion Disk, Double - Peaked Emission Lines, White Dwarf, Cataclysmic Variables 1 Introduction Cataclysmic variables ( CVs ), also known as dwarf novae, are close binary systems consisting of a white dwarf primary star and a late - type secondary star filling its Roche lobe.Mass is transferred through the inner Lagrangian point L1 onto the surface of the white dwarf where it forms an accretion disc surrounding the compact object.This process leads to periodic outbursts caused by thermal instabilities in the accretion disk resulting in dramatic changes in luminosity over time scales ranging from hours up to years[ 1 ].During these outbursts, the accretion rate increases by several orders of magnitude leading to strong winds and high temperatures in the disc [ 2 ], while the system becomes fainter than usual due to obscuration effects [ 3 ].The study of CVs provides valuable information about the physical processes involved in accretion flows [ 4 ], magnetic fields[ 5 ], and angular momentum transport[ 6 ].Furthermore, they can be used as distance indicators[ 7, 8 ] and probes of galactic structure[ 9 ].2 Observations & Data Reduction Our sample consists of nine CVs observed between 2004 and 2007 using the High Resolution Echelle Spectrometer ( HIRES )[ 10 ] mounted on the 10 mKeckI telescope located on Mauna Kea"
    },
    {
        "original_text": "We propose an image stabilizing method for video capturing in turbulent environments, which is based on the super-resolution technique. The proposed method can be used to improve the quality of captured videos with handheld cameras or other devices that are subject to motion blur caused by turbulence. We first estimate the camera motion using optical flow between consecutive frames. Then we use this information as input data into our super-resolution algorithm to generate high resolution images. Finally, these images are combined together to produce a stable output frame. Our experimental results show that the proposed method outperforms existing methods both visually and quantitatively. \n \n Keywords: Real time video processing; Turbulence; Motion blur; Optical flow; Super-resolution; Image stabilization. 1 Introduction \n \n In recent years there has been growing interest in developing techniques for real time video processing applications such as video surveillance systems [1] , traffic monitoring [2] , remote sensing [3] . However, most of these applications require capturing clear images under challenging conditions like low-light illumination [4] , fast moving objects [5] , blurry scenes [6] , etc.. Among all these challenges, one of the major problems is how to deal with the motion blur caused by turbulence [7][8][9] when capturing videos with hand-held cameras or other devices [10] . \n \n Figure 1: An example of a video sequence taken at nighttime (a) and its corresponding ground truth (b).",
        "watermark_text": "We propose an image stabilizing method for video capturing in turbulent environments, which is based on the super - resolution technique.The proposed method can be used to improve the quality of captured videos with handheld cameras or other devices that are subject to motion blur caused by turbulence.We first estimate the camera motion utilizing optical flow between consecutive frames.Then we use this information as input data into our super - resolution algorithm to generate high resolution images.Finally, these images are combined together to produce a stable output frame.Our experimental results show that the proposed method outperforms existing methods both visually and quantitatively.Keywords : Real time video processing ; Turbulence ; Motion blur ; Optical flow ; Super - resolution ; Image stabilization.1Introduction In recent years there has been growing interest in developing techniques for real moment video processing applications such as video surveillance systems[ 1 ], traffic monitoring [ 2 ], remote sensing [ 3 ].However, most of these applications require capturing clean images under challenging conditions like low - light illumination [ 4 ], fast moving objects[ 5 ], blurry scenes[ 6 ], etc.Among all these challenges, one of the major problems is how to deal with the motion blur caused by turbulence [ 7 ] [ 8 ] [ 9 ] when capturing videos with hand - held cameras or other devices [ 10 ].Figure 1 : An example of a video sequence taken at nighttime ( a ) and its corresponding ground truth ( b )."
    },
    {
        "original_text": "We show that the linear programming relaxation (LP) is equivalent to the max-product algorithm on general graphs, when applied to weighted matching problems with non-negative weights.  We prove this equivalence by showing how each step of the max-product algorithm can be simulated using an appropriate rounding technique based on the solution of the dual problem at hand.   The main idea behind our approach is to use the fact that any feasible primal-dual pair satisfies certain properties which we exploit to obtain a valid rounding scheme. Our results are applicable to many combinatorial optimization problems such as maximum weight bipartite matching, minimum cost flow, vertex cover etc., where the objective function has only non-negative coefficients. In particular, they imply that the integrality gap of these problems under their respective LP relaxations cannot exceed 1 + $O(1/n)$, where $n$ denotes the number of nodes or edges in the input graph. This improves upon previously known upper bounds of 2 and 3/2 respectively.",
        "watermark_text": "We show that the linear programming relaxation ( LP ) is equivalent to the max - product algorithm on general graphs, when applied to weighted matching issues with un - negative weights.We prove this equivalence by showing how each step of the max - product algorithm can be simulated using an appropriate rounding technique based on the solution of the dual problem at hand.The main idea behind our approach is to use the fact that any feasible primal - dual pair satisfies certain properties which we exploit to obtain a valid rounding system.Our results are applicable to many combinatorial optimization problems such as maximum weight bipartite matching, minimal cost stream, vertex coverage etc., where the objective function has only non - negative coefficients.In particular, they imply that the integrality gap of these problems under their respective LP relaxations cannot exceed one + $ O ( 1 / n ) $, where $ n $ denotes the number of nodes or edges in the input graph.This improves upon previously known higher bounds of 2 and 3 / two respectively."
    },
    {
        "original_text": "We study the production of magnetic fields and their subsequent evolution during the relativistic blast wave phase of gamma-ray burst (GRB) afterglow emission, using numerical simulations with high spatial resolution. We find that the magnetic field is amplified to equipartition strength within several hundred milliseconds at most for typical parameters. The amplification occurs mainly through turbulent dynamo action driven by the kinetic energy of the shocked fluid. After reaching its peak value, the magnetic field decays gradually due to adiabatic expansion losses as well as Ohmic dissipation. Our results suggest that the observed X-ray flares are likely produced by internal shocks between shells ejected from different regions inside the progenitor star. \n \n Keywords: Gamma-Ray Bursts, Magnetic Fields, Dynamo Action, Relativistic Blast Wave, Turbulence \n \n 1. Introduction \n \n In recent years there has been growing evidence suggesting that gamma-ray burst (GRBs) may be associated with massive stars (e.g., Woosley & Bloom 2006) . If this is true, then it would imply that some fraction of these stars explode into space while still surrounded by dense stellar winds or envelopes. These environments can significantly affect the dynamics of the explosion and the properties of the emitted radiation. For example, Chevalier et al. (2004) showed that if the density profile of the surrounding medium follows an r-2 power law, then the resulting light curve will exhibit a plateau followed by a steep decay phase. This behavior was later confirmed observationally (e.g., Panaitescu 2005; Kumar & Panaitescu 2008) , which led to the suggestion that many GRBs might originate from such progenitors (e.g., Zhang 2007). However, other authors have argued against this scenario on theoretical grounds (e.g., Ramirez-Ruiz et al. 2005 ) and observational ones (e.g., Lazzati et al. 2009 ). It should also be noted that even though the majority of GRBs seem to follow this general trend, there exist cases where no clear signature of interaction with a wind-like environment could",
        "watermark_text": "We study the production of magnetic fields and their subsequent evolution during the relativistic blast wave stage of gamma - ray burst ( GRB ) afterglow emission, using numerical simulations with high spatial resolution.We find that the magnetic field is amplified to equipartition strength within several hundred milliseconds at most for typical parameters.The amplification happens mainly through turbulent dynamo action driven by the kinetic energy of the shocked fluid.After reaching its peak value, the magnetic field decays progressively due to adiabatic expansion losses as also as Ohmic dissipation.Our results suggest that the observed X - ray flares are likely produced by internal shocks between shells expelled from different regions inside the progenitor star.Keywords : Gamma - Ray Bursts, Magnetic Fields, Dynamo Action, Relativistic Blast Wave, Turbulence 1.Introduction In recent years there has been growing evidence suggesting that gamma - ray burst ( GRBs ) may be associated with massive stars ( e. g., Woosley & Bloom 2006 ).If this is true, then it would imply that some fraction of these stars explode into space while still surrounded by density stellar winds or envelopes.These environments can significantly affect the dynamics of the blast and the properties of the emitted radiation.For example, Chevalier et al. ( 2004 ) showed that if the density profile of the surrounding medium follows an r - 2 power law, then the resulting light curve will manifest a plateau followed by a steep decay phase.This behavior was later verified observationally ( e. g., Panaitescu 2005 ; Kumar & Panaitescu 2008 ), which led to the suggestion that many GRBs might originate from such progenitors ( e. g., Zhang 2007 ).However, other authors have argued against this scenario on theoretical reasons ( e. big., Ramirez - Ruiz et al. 2005 ) and observational ones ( e. g., Lazzati et al. 2009 ).It should also be noted that even though the majority of GRBs seem to follow this general trend, there exist instances where no distinct signature of interaction with a wind - like environment could"
    },
    {
        "original_text": "We present an algorithm that determines whether or not there exists a quantum circuit with a given number of qubits and gates, such that the corresponding time-independent Hamiltonian is realizable by a physical system in which each energy level has at most one excited state.  We also show how to find all possible circuits if they exist. Our results are based on recent work showing that any time-independent Hamiltonian can be written as a sum of commuting projectors onto its eigenstates. This decomposition allows us to reduce the problem of finding a realization of a general time-independent Hamiltonian into several instances of the same problem but restricted to smaller Hilbert spaces. The reduction yields a polynomial-time algorithm when applied recursively. Finally we discuss some applications of our method including determining the minimum depth required for universal adiabatic quantum computers. In this article we consider the following problem: \nGiven a set of n qubits and m two-qubit gates, does there exist a quantum circuit consisting only of these gates whose associated time-independent Hamiltonian is realizable; i.e., it corresponds to a Hermitian operator acting on a finite-dimensional Hilbert space? If so, what is the smallest circuit size needed?\nThe answer to this question will depend on the specifics of the model used to describe the physical system under consideration. For example, in the case where each energy level may have more than one excited state (i.e., degenerate), then no circuit can realize the desired Hamiltonian unless it contains infinitely many gates. On the other hand, if each energy level has exactly one excited state (i..",
        "watermark_text": "We present an algorithm that determines whether or not there exists a quantum circuit with a given number of qubits and gates, such that the corresponding time - independent Hamiltonian is realizable by a physical system in which each energy level has at most one excited state.We also show how to find all possible circuits if they exist.Our results are based on recent work showing that any time - independent Hamiltonian can be written as a sum of commuting projectors upon its eigenstates.This decomposition enables us to reduce the problem of discovering a realization of a general time - independent Hamiltonian into several examples of the same problem but restricted to smaller Hilbert spaces.The reduction yields a polynomial - time algorithm when applied recursively.Finally we discuss some applications of our method including determining the minimum depth required for universal adiabatic quantum computers.In this article we consider the following problem : Given a set of n qubits and m two - qubit gates, does there exist a quantum circuit consisting only of these gates whose associated time - independent Hamiltonian is realizable ; i. e., it corresponds to a Hermitian operator acting on a finite - dimensional Hilbert space?If so, what is the smallest circuit size needed?The answer to this question will depend on the specifics of the model used to describe the physical system under consideration.For example, in the case where each energy level may have more than 1 excited state ( i. e., degenerate ), then no circuit can realise the desired Hamiltonian unless it contains infinitely many gates.On the other hand, if each energy level has exactly one excited state ( i."
    },
    {
        "original_text": "We propose an explicit construction for a string model with gauge group SU(3)xSU(2)xU(1), three generations of quarks and leptons, right-handed neutrinos, and no exotic particles beyond those in the minimal supersymmetric standard model (MSSM). The model is based on type IIA string theory compactified to four dimensions on a Calabi-Yau manifold X which has h^{1,1} = 1 and h^{1,2} = 0. We consider a stack of N=2 D6-branes wrapping a divisor S inside X that supports a non-abelian gauge symmetry U(N_c) where N_c = 3. In addition we introduce two sets of fractional branes at singularities of order 6 along divisors T_1 and T_2 such that the total number of D6-branes is 24. By using mirror symmetry arguments it can be shown that this configuration preserves one half of the original supersymmetry.",
        "watermark_text": "We propose an explicit construction for a string model with gauge group SU ( 3 ) xSU ( 2 ) xU ( 1 ), three generations of quarks and leptons, right - handed neutrinos, and no exotic particles beyond those in the minimal supersymmetric standard model ( MSSM ).The model is based on type IIA string theory compactified to 4 dimensions on a Calabi - Yau manifold X which has h ^ { 1, 1 } = one and h ^ { 1, 2 } = 0.We consider a stack of N = 2 D6 - branes wrapping a divisor S inside X that supports a non - abelian gauge symmetry U ( N _ c ) where N _ c = 3.In addition we introduce two sets of fractional branes at singularities of order six along divisors T _ 1 and T _ 2 such that the total number of D6 - branes is 24.By using mirror symmetry arguments it can be shown that this arrangement preserves one half of the original supersymmetry."
    },
    {
        "original_text": "We present field-theoretical formulations for modified Newtonian dynamics (MOND) and its relativistic generalization, TeVeS. We show that the two theories are equivalent in their weak-field limit but differ significantly at high accelerations. In particular we find that the gravitational potential generated by an isolated point mass is different between the two theories even when they predict identical rotation curves around this object. This difference can be used to test whether or not dark matter exists using observations of galaxy clusters. The equivalence principle states that all local physics should be independent of where it occurs in space-time. However, there exist many extensions to general relativity which violate this principle. One such extension is the so-called scalar-tensor-vector-symmetric theory (STV), also known as TeVeS. STV has been shown to successfully reproduce galactic rotation curves without requiring any additional dark matter component. Here we study how violations of the equivalence principle affect the growth rate of structure formation within the context of STV cosmology.",
        "watermark_text": "We present field - theoretical formulations for modified Newtonian dynamics ( MOND ) and its relativistic generalization, TeVeS.We show that the two theories are comparable in their weak - field limit but differ significantly at high accelerations.In particular we find that the gravitational potential generated by an isolated point mass is changed between the two theories even when they predict identical rotation curves around this object.This difference can be used to test whether or not dark matter exists via observations of galaxy clusters.The equivalence principle states that all local physics should be independent of where it happens in space - time.However, there exist many extensions to general relativity which violate this principle.One such extension is the so - called scalar - tensor - vector - symmetric theory ( STV ), also known as TeVeS. STV has been shown to successfully reproduce galactic rotation curves without requiring any additional dark matter component.Here we study how violations of the equivalence principle affect the growth rate of structure formation within the context of STV cosmology."
    },
    {
        "original_text": "We report on the search for a K-nuclear bound state in 4 He using the reaction $^4$He (K - , n). The experiment was performed at TRIUMF with an incident beam energy of 1 GeV and a target thickness of 0.5 cm. A total number of 2.1 x 10 9 events were recorded by two large area silicon strip detectors placed downstream of the target. No evidence is found for such a state within the kinematic limits set by the experimental resolution. Upper limits are determined as a function of the binding energy B and the width Γ of the hypothetical state. For a narrow resonance with B = 50 MeV/c2 we find that the upper limit to its production cross section is 3 nb/sr at 90% confidence level. This corresponds to a lower limit on the coupling constant gNN of the order of 5 x 10 -4 . \nThe results presented here represent one of the most stringent constraints yet obtained on this type of exotic nuclear structure. \n \n Keywords: Kaon nucleus interaction",
        "watermark_text": "We report on the search for a K - nuclear bound state in 4 He using the reaction $ ^ 4 $ He ( K -, n ).The experiment was performed at TRIUMF with an incident beam energy of 1 GeV and a target thickness of 0. 5 cm.A total number of 2. 1 x 10 9 events were recorded by two large region silicon strip detectors put downstream of the target.No evidence is found for such a state inside the kinematic constraints set by the experiment resolution.Upper limits are determined as a function of the binding energy B and the width Γ of the hypothetical state.For a narrow resonance with B = 50 MeV / c2 we find that the higher limit to its production cross section is 3 nb / sr at 90 % confidence level.This corresponds to a lower limit on the coupling constant gNN of the order of 5 × 10 - 4.The results presented here represent one of the most stringent constraints yet obtained on this type of exotic nuclear structure.Keywords : Kaon nucleus interaction"
    },
    {
        "original_text": "We report on the spin polarization and magnetoresistance properties of GaAs/(Cd,Mn)Te/GaAs quantum well structures grown by molecular beam epitaxy (MBE). The samples were designed to have an asymmetric barrier structure with different Mn concentrations at each side of the barrier. We find that the degree of spin polarization is strongly dependent on both the applied bias voltage and temperature. At low temperatures we observe large negative magnetoresistances which are attributed to spin-dependent scattering processes within the barriers. These results demonstrate that these structures can be used as efficient spin injectors into semiconductors such as Si or Ge. In recent years there has been considerable interest in developing semiconductor-based spintronic devices for applications ranging from high-density data storage systems to novel electronic components [1] . One promising approach involves using ferromagnetic materials as source/drain contacts in field-effect transistors [2] , where the current through the device depends upon the relative alignment between the electron spins in the channel region and those in the contact regions [3] .\nIn this work we present experimental studies of spin polarized transport in GaAs/Cd 0.9 Mn 0.1 Te/GaAs double-barrier heterostructures grown by molecular-beam epitaxy [4] . Our aim was to investigate how the degree of spin polarization varies under different conditions of applied bias voltage and temperature, and also to determine whether it is possible to use these structures as efficient spin injectors for other semiconductors such as silicon [5] .",
        "watermark_text": "We report on the spin polarization and magnetoresistance properties of GaAs / ( Cd, Mn ) Te / GaAs quantum well structures grown by molecular beam epitaxy ( MBE ).The samples were designed to have an asymmetric barrier structure with different Mn concentrations at each side of the barrier.We find that the degree of spin polarization is strong dependent on both the applied bias voltage and temperature.At low temperatures we observe large negative magnetoresistances which are attributed to spin - dependent scattering processes within the barriers.These results demonstrate that these structures can be used as effective spin injectors into semiconductors such as S or Ge.In recent years there has been considerable interest in developing semiconductor - based spintronic devices for applications ranging from highly - dense data storage systems to new electronic components [ 1 ].One promising approach involves using ferromagnetic substances as origin / drain contacts in field - effect transistors[ 2 ], where the current through the device depends upon the relative alignment between the electron spins in the channel region and those in the contact regions [ 3 ].In this work we present experimental studies of spin polarized transport in GaAs / Cd 0. 9 Mn 0. 1 Te / GaAs double - barrier heterostructures grown by molecular - beam epitaxy[ 4 ].Our aim was to investigate how the degree of spin polarization varies under different conditions of applied bias voltage and temperature, and also to determine whether it is possible to use these structures as efficient spin injectors for other semiconductors such as silicon[ 5 ]."
    },
    {
        "original_text": "We present the results of an analysis searching for supersymmetric particles in events with jets and missing transverse energy using data collected by the D0 experiment at Fermilab during Run II, corresponding to 1 fb-1 . We consider models where squarks decay into quarks and gluinos which then decay via intermediate sleptons or neutralinos into final states containing two light-flavored leptons (electrons and/or muons) and large E T / .\nThe search is performed over a wide range of masses for all sparticles involved in these cascade decays , including those that are not directly produced but can be exchanged in t-channel processes . No significant excess above background expectations has been observed . Limits on the production cross sections times branching fractions have been set as functions of the mass parameters of the model considered . These limits are compared to theoretical predictions obtained within the framework of minimal supergravity grand unification .",
        "watermark_text": "We present the results of an analysis searching for supersymmetric particles in events with jets and missing transverse energy using data collected by the D0 experiment at Fermilab during Run II, corresponding to one fb - 1.We consider models where squarks decay into quarks and gluinos which then decay using intermediate sleptons or neutralinos into final states containing two light - flavored leptons ( electrons and / or muons ) and large E T /.The search is performed over a wide range of masses for all sparticles involved in these cascade decays, like those that are not directly produced but can be traded in t - channel processes.No significant excess above background expectations has been observed.Limits on the production cross sections times branching fractions have been set as functions of the mass parameters of the model considered.These limits are compared to theoretical predictions obtained within the framework of minimal supergravity grand unification."
    },
    {
        "original_text": "We report on the discovery and study of J1128+592, an intraday variable (IDV) radio quasar at redshift z = 1.8. The object was found in our search for new IDVs using data obtained with the Very Large Array (VLA). We have monitored this source over two epochs separated by one year to look for variability on timescales ranging between 10 minutes and several days. Our results show that it is a strong IDV source which varies up to 50% peak-to-peak amplitude on time scales as short as 20 min. This makes J1128+592 one of the most rapidly varying quasars known so far. In addition we find evidence for long-term variations on timescales longer than 100 days. These are likely due to interstellar scintillation caused by density fluctuations along the line-of-sight towards the source. Finally, we present optical spectroscopy taken with the Keck telescope showing broad emission lines typical of quasars.",
        "watermark_text": "We report on the discovery and study of J1128 + 592, an intraday variable ( IDV ) radio quasar at redshift z = 1. 8.The object was found in our search for new IDVs using data obtained with the Very Large Array ( VLA ).We have watched this source over two epochs separated by one year to look for variability on timescales ranging between 10 minutes and several days.Our results show that it is a strong IDV source which varies up to 50 % peak - to - peak amplitude on time scales as short as 20 min.This makes J1128 + 592 one of the most rapidly varying quasars named so far.In addition we find evidence for long - term variations on timescales farther than 100 days.These are probably due to interstellar scintillation caused by density fluctuations along the line - of - sight towards the source.Finally, we present optical spectroscopy taken with the Keck telescope showing broad emission lines characteristic of quasars."
    },
    {
        "original_text": "We present new observations with the High Sensitivity Array (HSA) at 1.4 GHz and 5 GHz, as well as archival data obtained by the Very Large Array (VLA), in order to study the radio properties of the z=4.4 quasar BRI1335-0417. We detect two compact components separated by 0.3 arcsec on both sides of the optical position of this source. The total flux density is S5GHz=(1.6 ±0.2) mJy for component A and S1.4Ghz=0.7±0.1 mJy for component B. Both sources are unresolved within our beam size. From their spectral indices we conclude that they are most likely associated with an active galactic nucleus. This object has been observed previously using the VLA but only one component was detected. Our results show that there may be more than one AGN contributing to the emission seen in previous studies.",
        "watermark_text": "We present new observations with the High Sensitivity Array ( HSA ) at 1. 4 GHz and 5 GHz, as ill as archival data obtained by the Very Large Array ( VLA ), in order to study the radio properties of the z = 4. 4 quasar BRI1335 - 0417.We detect two compact components separated by zero. 3 arcsec on both sides of the optical position of this source.The total flux density is S5GHz = ( 1. 6 ±0. 2 ) mJy for constituent A and S1. 4Ghz = 0. 7±0. 1 mJy for component B.Both sources are unresolved inside our beam size.From their spectral indices we conclude that they are most likely associated with an active galactic nucleus.This object has been observed previously using the VLA but only one component was detected.Our results show that there may be more than 1 AGN contributing to the emission seen in previous studies."
    },
    {
        "original_text": "We present an approach to nonequilibrium entropy production in the lattice Boltzmann (LB) method by introducing entropy limiters into the collision operator. The proposed scheme is shown to be able to reproduce the correct equilibrium distribution and recover the second law of thermodynamics for both single-phase flows with constant density and temperature, as well as multiphase flows with phase change. We also demonstrate that our new LB model can accurately capture shock waves without spurious oscillations or numerical instabilities. \n \n Keywords: Nonequilibrium entropy, Lattice Boltzmann Method, Entropy limiter, Second Law of Thermodynamics, Shock wave. 1 Introduction \n \n In recent years, there has been growing interest in developing computational fluid dynamics methods based on kinetic theory [1–3] . Compared with conventional Navier-Stokes solvers, these approaches are more accurate at capturing complex flow phenomena such as shocks [4] , turbulence [5] , and interfacial flows [6] . Among them, the lattice Boltzmann method [7, 8] has attracted much attention due to its simplicity and efficiency [9] . \n \n However, it should be noted that most existing LB models do not satisfy the second law of thermodynamic [10] . This problem becomes particularly severe when dealing with high Mach number flows [11] . To overcome this difficulty, several attempts have been made recently [12–18] . For example, Chen et al. [12] introduced a modified BGK-type collision term which recovers the correct equilibrium state while satisfying the second law of thermodynamical. Similarly, Yu et al. [13] developed another type of entropy-consistent LB schemes using the concept of entropic moments. More recently, Shan et al. [14] presented a novel LB model where the relaxation time was determined according to the local Knudsen number. Although these works provide promising results, they all require additional information about the macroscopic variables, e.g., pressure and velocity fields. As a result, their applications may be limited to simple cases involving only one component gas. \n \n In contrast, we propose here a general framework for constructing entropy-consistent LB models. Our strategy relies on adding",
        "watermark_text": "We present an approach to nonequilibrium entropy production in the lattice Boltzmann ( LB ) method by introducing entropy limiters into the collision operator.The proposed scheme is shown to be able to reproduce the correct equilibrium distribution and recover the second law of thermodynamics for both single - phase flows with consistent density and temperature, as well as multiphase flows with phase change.We also demonstrate that our new LB model can accurately capture shock waves without spurious oscillations or numerical instabilities.Keywords : Nonequilibrium entropy, Lattice Boltzmann Method, Entropy limiter, Second Law of Thermodynamics, Shock wave.1Introduction In recent years, there has been growing interest in developing computational fluid dynamics methods based on kinetic theory [ 1 – 3 ].Compared with conventional Navier - Stokes solvers, these approaches are more accurate at capturing complex flow phenomena such as shocks [ 4 ], turbulence [ five ], and interfacial flows [ 6 ].Among them, the lattice Boltzmann method [ 7, 8 ] has drawn much attention due to its simplicity and efficiency [ 9 ].However, it should be noted that most existing LB models do not fulfill the 2nd law of thermodynamic [ 10 ].This problem becomes particularly severe when dealing with high Mach number flows [ 11 ].To overcome this difficulty, multiple attempts have been made recently [ 12 – 18 ].For example, Chen et al.[ 12 ] introduced a modified BGK - type collision term which recovers the correct equilibrium state while satisfying the second law of thermodynamical.Similarly, Yu et al.[ 13 ] developed another type of entropy - consistent LB schemes using the concept of entropic moments.More recently, Shan et al.[ 14 ] presented a novel LB model where the relaxation time was determined according to the local Knudsen number.Although these works provide promising results, they all require additional information about the macroscopic variables, e. g., pressure and velocity fields.As a result, their applications may be limited to simple cases involving only 1 component gas.In contrast, we propose here a general framework for constructing entropy - consistent LB representations.Our strategy relies on adding"
    },
    {
        "original_text": "We present new observations of the low surface brightness galaxy PGC 045080, which is known to host an active galactic nucleus (AGN). We use these data to study the properties of this AGN as well as its relationship with the surrounding gas disk.  The AGN has been detected by previous studies at radio wavelengths using Very Large Array (VLA) observations. In our work we have used VLA archival data along with new observations made with the Karl G. Jansky Very Large Array (JVLA), to detect emission lines associated with the AGN. These include H-alpha, [NII] , [SII] , [OIII] , and [CII] . Using these line fluxes we calculate the luminosity of the AGN to be 1.1 x 10^41 erg/sec. This value agrees very closely with that found for other similar galaxies. We also find evidence for outflows on both large and small scales around the AGN.",
        "watermark_text": "We present new observations of the low surface brightness galaxy PGC 045080, which is known to host an active galactic nucleus ( AGN ).We use these data to study the properties of this AGN as well as its relationship with the surrounding gas disk.The AGN has been detected by previous studies at radio wavelengths using Very Big Array ( VLA ) measurements.In our work we have utilized VLA archival data alongside with novel observations made with the Karl G. Jansky Very Large Array ( JVLA ), to detect emission lines associated with the AGN.These include H - alpha, [ NII ], [ SII ], [ OIII ], and [ CII ].Using these line fluxes we calculate the luminosity of the AGN to be 1. 1 x 10 ^ 41 erg / sec.This value agrees very closely with that found for other similar galaxies.We also find proof for outflows on both large and small scales around the AGN."
    },
    {
        "original_text": "We introduce the concept of algebraic charge liquids, which are defined as ground states of Hamiltonians with local interactions that can be written in terms of fermionic creation and annihilation operators. We show how to construct such models for any finite group G by using an explicit representation of G on the Hilbert space of spinless fermions. The resulting model is exactly solvable when G has no non-trivial subgroups. In this case we find that there exists at least one phase transition between different phases characterized by distinct topological orders. For example, if G = Z2 × Z2 then our construction yields two gapped phases distinguished by their chiral central charges c− = 0 or 1. If G contains a nontrivial subgroup H then the system exhibits gapless excitations corresponding to particles transforming according to irreducible representations (irreps) of H. These results provide new insights into the classification problem of quantum many-body systems.",
        "watermark_text": "We introduce the concept of algebraic charge liquids, which are defined as ground states of Hamiltonians with local interactions that can be written in terms of fermionic creation and annihilation operators.We show how to construct such models for any finite group G by using an explicitly representation of G on the Hilbert space of spinless fermions.The resulting model is exactly solvable when G has no non - trivial subgroups.In this case we find that there exists at minimum one phase transition between different phases characterized by distinct topological orders.For example, if G = Z2 × Z2 then our construction yields two gapped phases distinguished by their chiral central charges c− = zero or one.If G contains a nontrivial subgroup H then the system exhibits gapless excitations corresponding to particles transforming according to irreducible representations ( irreps ) of H.These results provide new insights into the classification problem of quantum many - body systems."
    },
    {
        "original_text": "We study the dynamics near transcritical bifurcation points for non integrable Hamiltonians with two degrees of freedom, using perturbation theory and numerical simulations.  We show that there is an infinite number of periodic orbits which are born at the bifurcation point as well as infinitely many families of quasi-periodic solutions. The latter have been found numerically by computing Lyapunov exponents along trajectories starting close to the equilibrium position corresponding to the unperturbed problem. \nThe results presented here can be applied to several physical systems such as Josephson junctions or pendula coupled through elastic elements. Transcritical bifurcations occur when a stable fixed point loses its stability under small perturbations. In this case, new types of attractors appear nearby, including limit cycles and chaotic sets. This phenomenon has been studied extensively both theoretically and experimentally (see e.g., [1] , [3] ). However, most studies were restricted to low dimensional dynamical systems where it was possible to obtain explicit expressions for all relevant quantities. Here we consider higher-dimensional problems where only approximate methods exist. Our main motivation comes from nonlinear physics, but our results may also apply to other fields like biology or economics.",
        "watermark_text": "We study the dynamics near transcritical bifurcation points for non integrable Hamiltonians with two degrees of free, using perturbation theory and numerical simulations.We show that there is an infinite number of periodic orbits which are born at the bifurcation point as also as infinitely much families of quasi - periodic solutions.The latter have been found numerically by computing Lyapunov exponents across trajectories starting close to the equilibrium position corresponding to the unperturbed problem.The results presented here can be applied to several physical systems such as Josephson junctions or pendula coupled through elastic elements.Transcritical bifurcations occur when a fixed fixed point loses its stability under small perturbations.In this case, new types of attractors appear nearby, including limit cycles and chaos sets.This phenomenon has been studied extensively both theoretically and experimentally ( see e. g., [ 1 ], [ 3 ] ).However, most studies were restricted to low dimension dynamical systems where it was feasible to obtain explicitly expressions for all relevant quantities.Here we consider higher - dimensional problems where only approximate methods exist.Our main motivation comes from nonlinear physics, but our outcomes may also apply to other fields like biology or economics."
    },
    {
        "original_text": "We study the dynamics of free fermions hopping between sites of an arbitrary connected graph, with no restriction to nearest-neighbor hopping. We show that this system is equivalent to a collection of independent random walks evolving in parallel and interacting via pairwise collisions at vertices. The collision rate depends only on the number of particles present at each vertex; it vanishes for graphs without loops or multiple edges (e.g., trees), but can be arbitrarily large otherwise. This model exhibits interesting behavior even when all rates are equal, including anomalous diffusion and superdiffusion. In particular, we prove that the mean-square displacement grows as t3/2 for any tree-like graph, while it scales faster than t2/3 for general graphs. Finally, we discuss possible extensions of our results beyond the free-fermion case. Introduction: A wide variety of physical phenomena ranging from quantum transport through mesoscopic systems [1] , to population biology [2] , involve non-equilibrium particle dynamics on networks. These models typically assume that particles move along directed links according to some prescribed rules, such as unrestricted hopping [3] . However, many real-world situations require more complicated interactions among particles [4] .\nIn this work, we consider a simple generalization of standard one-dimensional lattice models [5] by allowing particles to hop freely between adjacent nodes of an arbitrary connected graph G = (V, E). More precisely, let us fix a finite set S of states associated with each node v ∈ V ; then, given a configuration c : V → S, we define the state space C(G) := {c: V → S}. For every edge e = {u, v} ∈ E, we associate two transition probabilities p+(c, c')(e) ≥ 0 and p−(c, c')(u, v) > 0; these represent the probability per unit time that a particle located at u jumps to v if its current state is c, and vice versa. Then, the evolution of the system is described by a continuous-time Markov process Xt taking values in C(G).\nThe main goal of this Letter is to analyze the",
        "watermark_text": "We study the dynamics of free fermions hopping between sites of an arbitrary connected graph, with no restraint to nearest - neighbor hopping.We show that this system is equivalent to a collection of independent random walks evolving in parallel and interacting via pairwise collisions at vertices.The collision rate depends only on the number of particles presence at each vertex ; it vanishes for graphs without loops or multiple edges ( e. g., trees ), but can be arbitrarily large otherwise.This model exhibits interesting behavior even when all rates are even, including anomalous diffusion and superdiffusion.In particular, we prove that the mean - square displacement grows as t3 / 2 for any tree - like graph, while it scales faster than t2 / 3 for general ones.Finally, we discuss possible extensions of our results beyond the freedom - fermion case.Introduction : A wide variety of physical phenomena ranging from quantum transport through mesoscopic systems[ 1 ], to population biology [ 2 ], involve non - equilibrium particle dynamics on networks.These models typically assume that particles motion along directed links according to some prescribed rules, such as unrestricted hopping [ 3 ].However, many real - world situations require more complicated interactions among particles [ 4 ].In this work, we consider a simple generalization of standard one - dimension lattice models [ 5 ] by allowing particles to hop free between adjoining nodes of an arbitrary connected graph G = ( V, E ).More precisely, let us fix a finite set S of states associated with each node v ∈ V ; then, given a setup c : V → S, we define the state space C ( G ) := { c : V → S }.For every edge e = { u, v } ∈ E, we associate 2 transition probabilities p + ( c, c ' ) ( e ) ≥ 0 and p− ( c, c ' ) ( u, v ) > 0 ; these represent the probability per unit time that a particle located at u jumps to v if its current state is c, and vice versa.Then, the evolution of the system is described by a continuous - time Markov process Xt taking values in C ( G ).The main goal of this Letter is to analyze the"
    },
    {
        "original_text": "We present new near-infrared (NIR) observations of the Coma cluster using the Infrared Array Camera on board the Spitzer Space Telescope, which allow us to study the dwarf galaxy population in this rich environment for the first time at wavelengths longer than 1 micron. We identify and classify all galaxies detected within an area of 0.5 deg2 centered around the center of the Coma cluster down to a limiting magnitude of Ks = 18 mag. The majority of these sources are faint red galaxies that have been missed by previous optical surveys due to their low surface brightnesses. Using photometric redshift estimates we find that most of them lie between z=0.1 and z=1.0. By comparing our sample to existing spectroscopic data sets we show that our NIR selection is complete up to M* ~ - 17 + 5 log h70. This corresponds roughly to L*(z=0), but it should be noted that there may still exist some fainter dwarfs below our detection limit.",
        "watermark_text": "We present newly near - infrared ( NIR ) observations of the Coma cluster using the Infrared Array Camera on board the Spitzer Space Telescope, which allow us to study the dwarf galaxy population in this rich environment for the first time at wavelengths longer than 1 micron.We identify and classify all galaxies detected within an area of 0. 5 deg2 centered around the center of the Coma cluster down to a limiting magnitude of Ks = 18 mag.The majority of these sources are faint red galaxies that have been missed by previous optical surveys due to their low surface brightnesses.Using photometric redshift estimates we find that most of them lie between z = 0. 1 and z = 1. 0.By comparing our sample to existing spectroscopic data sets we show that our NIR choosing is complete up to M * ~ - 17 + 5 log h70.This corresponds roughly to L * ( z = 0 ), but it should be noted that there may still exist some fainter dwarfs below our detection limit."
    },
    {
        "original_text": "The idea that the universe underwent an inflationary phase at very early times is now widely accepted by cosmologists as one possible explanation for many observed features of our present-day universe, such as its flatness and homogeneity.  In this talk I will discuss how string-theoretic ideas can be used to construct models of inflation which are consistent with current observations. The basic idea behind these constructions is that they involve branes moving through extra dimensions of space-time. These branes may either move towards each other or away from each other depending on their initial conditions. If two branes collide then it leads to a rapid expansion of spacetime known as \"inflation\". This process continues until the branes separate again and the universe reverts back to its original size. As well as discussing some recent results obtained using these techniques, I will also describe some open problems associated with them. Finally, I will briefly mention another approach to constructing realistic models of inflation based upon so-called \"brane-world scenarios\".",
        "watermark_text": "The idea that the universe underwent an inflationary phase at very early times is now widely accepted by cosmologists as one possible explanation for many observed features of our present - day universe, such as its flatness and homogeneity.In this talk I will discuss how string - theoretic ideas can be utilized to construct models of inflation which are consistent with current observations.The basic idea behind these constructions is that they involve branes moving through extra dimensions of space - time.These branes may either move towards each other or away from each other depending on their initial conditions.If two branes collide then it leads to a rapid expansion of spacetime termed as \" inflation \".This process continues until the branes separate again and the universe reverts back to its original size.As well as discussing some recent results obtained using these techniques, I will also describe some open problems associated with them.Finally, I will briefly mention another approach to constructing realistic models of inflation based using so - called \" brane - world scenarios \"."
    },
    {
        "original_text": "In this work, we study the diversity-multiplexing tradeoff (DMT) for amplify-andforward multihop relay channels with multiple-input and multiple-output (MIMO). We first derive an upper bound on DMT by using the cut-set theorem. Then, based on the derived upper bound, we propose two schemes to achieve the optimal DMT performance in different scenarios. In particular, when all relays have full-duplex capability, our proposed scheme achieves the optimal DMT at high multiplexing gain region; while if only half-duplex relays are available, then our proposed scheme can still achieve the optimal DMT except that it is achieved at low multiplexing gain region instead. Finally, simulation results show that both proposed schemes outperform existing ones significantly. Index Terms-Diversity-Multiplexing Tradeoff, Multiple-Input MultipleOutput, Amplify-and-Forward",
        "watermark_text": "In this work, we study the diversity - multiplexing dealoff ( DMT ) for amplify - andforward multihop relay channels with multiple - input and multiple - output ( MIMO ).We first derive an higher bound on DMT by using the cut - set theorem.Then, based on the derived upper bound, we propose 2 schemes to achieve the ideal DMT performance in different scenarios.In particular, when all relays have full - duplex capability, our proposed scheme achieves the optimal DMT at high multiplexing gain region ; while if only half - duplex relays are available, then our proposed scheme can still achieve the optimal DMT except that it is achieved at low multiplexing gain region instead.Finally, simulation results show that both proposed schemes outperform existing schemes significantly.Index Terms - Diversity - Multiplexing Tradeoff, Multiple - Input MultipleOutput, Amplify - and - Forward"
    },
    {
        "original_text": "Magnetic separation is an important tool in biomedical research and clinical diagnostics, but it has been limited to macroscopic devices that are not suitable for point-of-care applications. Here we report on continuous magnetophoresis-based blood cell sorting using microfluidics. We demonstrate efficient separation of red blood cells (RBCs) from plasma by applying a magnetic field gradient across a microchannel containing RBCs suspended in buffer solution. The results show that our method can be used as a simple yet effective approach for separating different types of blood cells with high purity and efficiency. This work may have significant implications towards developing portable diagnostic tools based on microscale blood processing technologies. Magnetic separation techniques play an important role in many fields including medicine, biotechnology, environmental science, food industry etc., [1] . However, most existing methods require bulky equipment which makes them unsuitable for use outside laboratory settings [2] .\nRecently there has been growing interest in miniaturizing these systems into lab-on-a-chip platforms [3] , where various functionalities such as sample preparation [4] , chemical analysis [5] , drug delivery [6] , and bioassays [7] could be integrated onto one single chip. In particular, magnetic separators have attracted much attention due to their simplicity, low cost, portability, and compatibility with other microfabricated components [8] . For example, several groups have demonstrated magnetic separation of biological samples inside microchannels [9] - [11] or on planar surfaces [12] - [14] . Despite this progress, however, current approaches still suffer from some limitations. First, they typically rely on batch-wise operation mode [15] , which limits throughput and requires large volumes of input samples [16] . Second, the majority of reported designs only allow for separation between two distinct populations [17] , while more complex mixtures involving multiple species cannot be processed simultaneously [18] . Third, the fabrication process usually involves complicated multi-step procedures [19] , making it difficult to integrate additional functions [20] . Finally, most previous studies were performed under static conditions [21] , which limit the flexibility of device design [22] .",
        "watermark_text": "Magnetic separation is an essential tool in biomedical research and clinical diagnostics, but it has been limited to macroscopic devices that are not suitable for point - of - care applications.Here we report on continuous magnetophoresis - based blood cell sorting using microfluidics.We demonstrate efficient separation of red blood cells ( RBCs ) from plasma by applying a magnetic field gradient across a microchannel containing RBCs suspension in buffer solution.The results show that our methodology can be used as a simple yet successful approach for separating different types of blood cells with high purity and efficiency.This work may have significant implications towards developing mobile diagnostic tools based on microscale blood processor technologies.Magnetic separation techniques play an important role in numerous fields including medicine, biotechnology, environmental science, food industry etc.,[ 1 ].However, most existing methods need bulky gear which makes them unsuitable for use outside laboratory settings [ 2 ].Recently there has been growing interest in miniaturizing these systems into lab - on - a - chip platforms [ 3 ], where various functionalities such as specimen preparation[ 4 ], chemical analysis [ 5 ], drug delivery[ 6 ], and bioassays[ 7 ] could be integrated onto one individual chip.In particular, magnetic separators have attracted much attention due to their simplicity, low cost, portability, and compatibility with other microfabricated parts [ 8 ].For example, several groups have demonstrated magnetic segregation of biological samples inside microchannels[ 9 ] - [ 11 ] or on planar surfaces [ 12 ] -[ 14 ].Despite this progress, however, current approaches still suffer from some limitations.First, they typically rely on batch - wise operation mode[ 15 ], which limits throughput and requires large volumes of input samples[ 16 ].Second, the majority of reported designs only allow for separation between two distinct populations [ 17 ], while more complex mixtures involving multiple species cannot be processed simultaneously [ 18 ].Third, the fabrication process usually involves complicated multiple - stage procedures [ 19 ], making it difficult to integrate additional functions [ 20 ].Finally, most previous studies were performed under static conditions [ 21 ], which limit the flexibility of device design [ 22 ]."
    },
    {
        "original_text": "We present new observations in the mid-infrared (MIR) and near-infrared (NIR), as well as archival data, to study the physical conditions of the gas surrounding the young stellar object Re 4 IRS located at the center of the reflection nebula NGC 1333 IRAS 2. We find that the MIR spectrum is dominated by strong ro-vibrational lines of H$_2$O and CO, while the NIR spectrum shows prominent Brackett-γ line emission with an equivalent width of ~1 Å. The observed fluxes are consistent with those expected for a T Tauri star surrounded by a dense circumstellar disk heated by accretion shocks. In addition, we detect several forbidden transitions of [Fe II] , [S III] , [N II] , and [C II] . These results suggest that the central source has recently undergone a burst of enhanced mass loss activity which may be related to its recent transition into the main sequence phase.",
        "watermark_text": "We present new observations in the middle - infrared ( MIR ) and near - infrared ( NIR ), as well as archival data, to research the physical conditions of the gas surrounding the young stellar object Re 4 IRS located at the center of the reflection nebula NGC 1333 IRAS 2.We find that the MIR spectrum is dominated by strong ro - vibrational lines of H $ _ 2 $ O and CO, while the NIR spectrum shows prominent Brackett - γ line emission with an equivalent width of ~ 1 Å.The observed fluxes are consistent with those expected for a T Tauri star surrounded by a dense circumstellar disc heated by accretion shocks.In addition, we detect various forbidden transitions of [ Fe II ], [ S III ],[ N II ], and [ C II ].These results suggest that the central source has recently undergone a burst of enhanced mass loss activity which may be related to its recent transition into the main sequence phase."
    },
    {
        "original_text": "We propose that the metallic enhancement observed for some post T Tauri stars (PTTS) may be due to an accretion of planetesimals during their formation phase, which is followed by rapid planet formation and subsequent ejection of planets into space.  We show that this scenario can explain both the high metallicity found among PTTS as well as the low abundance ratios between refractory elements such as Mg/Si or Al/Si compared with those expected if these objects formed through standard core-accretion processes. The proposed mechanism also explains why there are no known close-in giant planets around PTTSs despite the fact that they have already passed their protoplanetary disk stage. This model predicts that most PTTS should host at least one Jupiter mass planet on wide orbits beyond 1 AU. In addition we predict that many PTTS will exhibit infrared excesses caused by dusty debris disks produced by collisions between planetary bodies.",
        "watermark_text": "We propose that the metallic enhancement observed for some post T Tauri stars ( PTTS ) may be due to an accretion of planetesimals during their forming phase, which is followed by rapid planet formation and subsequent ejection of planets into sky.We show that this scenario can explain both the high metallicity findings among PTTS as also as the low abundance ratios between refractory elements such as Mg / Si or Al / Si compared with those expected if these objects formed through standard core - accretion processes.The proposed mechanism also explains why there are no known close - in giant planets around PTTSs despite the reality that they have already passed their protoplanetary disc stage.This model predicts that most PTTS should host at minimum one Jupiter mass planet on wide circles beyond 1 AU.In addition we predict that many PTTS will exhibit infrared excesses caused by dusty debris discs produced by collisions between planetary bodies."
    },
    {
        "original_text": "We present an analysis of the distribution of planetary orbital parameters and masses for all known extrasolar planets with measured mass (N=73). We find that this sample can be divided into three distinct groups, which we call super-Earths, mini-Neptunes, and hot Jupiters. The first two are characterized by low eccentricities and high mutual inclinations between their orbits; in contrast, hot Jupiters have small mutual inclinations but large eccentricities. Super-Earths and mini-Neptunes also appear to form separate sequences on the radius-mass diagram. These results suggest that these three populations may represent different formation mechanisms or evolutionary histories. In particular, our findings support previous suggestions that super-Earths formed via core accretion followed by significant inward migration while mini-Neptunes were likely assembled through gravitational instability. Finally, we show how these results can be used as priors when searching for additional exoplanets using transit surveys such as Kepler.",
        "watermark_text": "We present an analysis of the distribution of planetary orbital parameters and masses for all known extrasolar planets with measured mass ( N = 73 ).We find that this sample can be divided into 3 distinct groups, which we call super - Earths, mini - Neptunes, and hot Jupiters.The first two are characterized by low eccentricities and high mutual inclinations between their orbits ; in contrast, warm Jupiters have small mutual inclinations but large eccentricities.Super - Earths and mini - Neptunes also appear to form separate sequences on the radius - mass diagram.These results suggest that these three populations may indicate different formation mechanisms or evolutionary histories.In particular, our findings support previous suggestions that super - Earths formed via core accretion followed by significant inward migration while mini - Neptunes were likely assembled through gravitational instability.Finally, we show how these results can be used as priors when searching for additional exoplanets via transit surveys such as Kepler."
    },
    {
        "original_text": "We study patterns of global economic activity by analyzing the World Trade Web (WTW), which is an interconnected network that represents international transactions between countries. We find that the WTW exhibits scale-free and small-world properties, as well as community structure. The communities are characterized by their high density of links within themselves but low density with other communities. In addition to these structural features, we also examine how the flow of goods changes over time across different parts of the network. Our results show that there exist several distinct phases during which the flow of goods increases or decreases significantly at certain locations on the network. These findings suggest that the current state of the economy can be inferred from the topological characteristics of the WTW. This work provides new insights into the dynamics of the global economy and may help us better understand its evolution. The World Trade Web (WTW: www.wtwdata.com) is a large database containing information about international transactions between countries [1] . It contains data for more than 180 countries spanning almost 50 years , including bilateral trade volumes and values, imports and exports, and country-specific product codes [2] .\nThe WTW has been used extensively to analyze various aspects of the global economy [3] - [8] . For example, it was shown recently that the WTW displays scale-free [9] and small-world [10] properties similar to those observed in many real-world networks [11] . Moreover, the WTW shows significant clustering [12] , indicating that countries tend to have strong ties among each other when they share common trading partners [13] . Finally, the WTW reveals important differences in the way countries interact with one another [14] : some countries act primarily as exporters while others serve mainly as importers; some countries are highly specialized whereas others are diversified; and so forth [15] .",
        "watermark_text": "We study patterns of global economy activity by analyzing the World Trade Web ( WTW ), which is an interconnected network that represents international transactions between nations.We find that the WTW exhibits scale - free and small - world properties, as also as community structure.The communities are characterized by their high density of links within themselves but low density with other communities.In addition to these structural features, we also examine how the circulation of goods changes over time across different parts of the network.Our results show that there exist several distinct phases during which the flow of goods increases or decreases significantly at certain locations on the network.These findings suggest that the present state of the economy can be inferred from the topological features of the WTW.This work provides new insights into the dynamics of the global economy and may help us best understand its evolution.The World Trade Web ( WTW : www. wtwdata. com ) is a large database containing information about international dealings between nations [ 1 ].It contains data for more than 180 countries spanning almost 50 years, including bilateral trade volumes and values, imports and exports, and nation - specific goods codes [ 2 ].The WTW has been utilized extensively to analyze various areas of the global economic [ 3 ] - [ 8 ].For example, it was shown recently that the WTW displays scale - free [ 9 ] and little - world[ 10 ] properties similar to those observed in many real - world networks [ 11 ].Moreover, the WTW shows significant clustering [ 12 ], indicating that nations tend to have strong ties amongst each other when they share common trading partners [ 13 ].Finally, the WTW reveals important differences in the way nations interact with one another [ 14 ] : some countries act primarily as exporters while others serve mainly as importers ; some countries are highly specialized whereas others are diversified ; and so forth [ 15 ]."
    },
    {
        "original_text": "We present new observations at millimeter wavelengths (1.2 mm and 3mm) toward the W3 Giant Molecular Cloud, which is one of the most active sites of star formation in our Galaxy. We have detected several hundred compact sources with masses ranging between 0.01 to 10 solar masses. The majority of these objects are associated with infrared dark clouds that contain young stellar objects surrounded by dense envelopes. These results show that massive stars form out of gravitationally bound cores within GMCs. This process may be regulated by turbulence and/or magnetic fields. \n \n Keywords: Star Formation, Infrared Dark Clouds, Millimeter Astronomy, Giant Molecular Clouds \n \n 1 Introduction \n \n Massive stars play an important role in shaping their environments through feedback processes such as radiation pressure, winds, and supernova explosions. However, it remains unclear how they form. One possibility is that massive stars form like low-mass stars via gravitational collapse of dense cores inside Giant Molecular Clouds (GMCs; e.g., McKee & Ostriker 2007). Alternatively, massive stars could form directly from turbulent flows without any intermediate core phase (e.g., Banerjee et al. 2006) . \n \n To investigate this issue we observed the W3 region using the Submillimeter Array (SMA; Ho et al. 2004 ) on Mauna Kea Observatory during two nights in November 2005. The SMA consists of eight 6 m antennas operating simultaneously at three different frequencies centered around 230 GHz, 345 GHz, and 690 GHz. At each frequency there were four basebands covering a bandwidth of 2 GHz for continuum emission and 4 GHz for spectral line studies. The primary beam size ranges from ~5′′ to ~20′′ depending on the observing frequency. The total integration time was about 12 hours per night spread over six tracks. Details of the observational setup can be found in Wu et al. (2007a) , where we presented initial results based on data taken only at 345 GHz. Here we report results obtained at all three bands.",
        "watermark_text": "We present fresh observations at millimeter wavelengths ( 1. 2 mm and 3mm ) toward the W3 Giant Molecular Cloud, which is one of the most active sites of star formation in our Galaxy.We have detected several hundred compact sources with masses ranging between 0. 01 to 10 solar masses.The majority of these items are associated with infrared dark clouds that contain young star objects surrounded by density envelopes.These results show that massive stars form out of gravitationally bound cores inside GMCs.This process may be regulated by turbulence and / or magnetic fields.Keywords : Star Formation, Infrared Dark Clouds, Millimeter Astronomy, Giant Molecular Clouds 1 Introduction Massive stars play an important role in transforming their environments through feedback processes such as radiation pressure, winds, and supernova explosions.However, it remains unclear how they form.One possibility is that massive stars form like low - mass stars via gravitational fall of dense cores inside Giant Molecular Clouds ( GMCs ; e. g., McKee & Ostriker 2007 ).Alternatively, massive stars could form directly from turbulent flows without any intermediate core phase ( e. g., Banerjee et al. 2006 ).To investigate this issue we observed the W3 region using the Submillimeter Array ( SMA ; Ho et al. 2004 ) on Mauna Kea Observatory during 2 nights in November 2005.The SMA consists of eight 6 m antennas operating simultaneously at three different bands centered around 230 GHz, 345 GHz, and 690 GHz.At each frequency there were 4 basebands covering a bandwidth of 2 GHz for continuum emission and four GHz for spectrum line studies.The primary beam size ranges from ~ 5 ″ ′ to ~ 20 ′ ′ based on the observing frequency.The total integration time was about 12 hours per night spread over 6 tracks.Details of the observational setup can be found in Wu et al. ( 2007a ), where we presented preliminary results based on data taken only at 345 GHz.Here we report results obtained at all 3 bands."
    },
    {
        "original_text": "We study the correlations and sum rules in a semi-infinite system with impurities at its surface, which is described by the quantum two-dimensional (2D) one component plasma model. We use the exact diagonalization method to calculate the density-density correlation function and static structure factor as well as their corresponding sum rules. The results show that there are two different regimes depending on whether the temperature T is larger or smaller than the Fermi energy EF . In particular, we find that when T < EF , the behavior of these quantities can be understood within the framework of Landau's Fermi liquid theory. However, if T > EF , our numerical data deviate significantly from this picture. Finally, we also investigate how the presence of impurities affects the above mentioned physical properties. Our findings suggest that the effect of impurities depends strongly on the distance between them. If they are close enough, then the impurity-impurity interaction dominates over other interactions leading to an increase of the effective mass of particles near the surface.",
        "watermark_text": "We study the correlations and sum rules in a semi - endless system with impurities at its surface, which is described by the quantum 2 - dimension ( 2D ) 1 component plasma model.We use the exact diagonalization method to calculate the density - density correlation function and static structure factor as also as their respective sum rules.The results show that there are 2 different regimes depending on whether the climate T is bigger or smaller than the Fermi energy EF.In particular, we find that when T EF, our number data deviate significantly from this picture.Finally, we also investigate how the presence of impurities affects the above mentioned physical properties.Our findings suggest that the effect of impurities depends strongly on the distance between them.If they are close enough, then the impurity - impurity interaction dominates over other interactions leading to an rise of the effective mass of particles nearby the surface."
    },
    {
        "original_text": "We present the results of our CCD photometric study of 42 open clusters in the southern hemisphere, carried out at the 1-meter telescope of the South African Astronomical Observatory (SAAO). The observations were made with an SBIG STL-1001E camera equipped with a Kodak KAF-0400 chip and Johnson V filter during three observing runs between September 1998 and February 1999. We have used DAOPHOT II to perform aperture photometry on all stars detected within each cluster field-of-view. A total number of about 15000 stars was measured for each cluster. In addition we obtained UBVRI photometry for some of these clusters using the same instrumentation as described above.  From this data set we derived the following parameters: reddening E(B-V), distance modulus DM, age t, metallicity [Fe/H] , mass function slope x, core radius rc, central surface brightness µ0, concentration index c, and integrated absolute magnitude M.",
        "watermark_text": "We present the results of our CCD photometric study of 42 open clusters in the south hemisphere, carried out at the 1 - metre telescope of the South Africa Astronomical Observatory ( SAAO ).The observations were made with an SBIG STL - 1001E camera fitted with a Kodak KAF - 0400 chip and Johnson V filter during three observing runs between September 1998 and February 1999.We have used DAOPHOT II to perform aperture photometry on all stars detected within each cluster field - of - view.A total number of about 15000 stars was measured for each cluster.In addition we obtained UBVRI photometry for some of these clusters using the same equipment as described above.From this data set we derived the following parameters : reddening E ( B - V ), distance modulus DM, age t, metallicity[ Fe / H ], mass function slope x, core radius rc, central surface brightness µ0, concentration index c, and integrated absolute magnitude M."
    },
    {
        "original_text": "We present the analysis of the magnetic field configuration in active region NOAA 11158, which produced several large solar flares during its passage across the central meridian on February 15-16, 2011 . We use vector magnetograms obtained by SDO/HMI and SOHO/MDI instruments as well as photospheric line-of-sight magnetograms provided by GONG network. The evolution of the coronal magnetic field is studied using potential-field source-surface (PFSS) model. In addition we perform NLFFF extrapolations with different codes for comparison purposes. Our results show that both PFSS and NLFFF models are able to reproduce the large-scale structure of the corona but differ significantly at small scales. This discrepancy can be explained by considering the effect of plasma flows along open field lines. Finally, we study the relationship between the observed photospheric motions and the changes in the coronal magnetic field. Active Region NOAA 11158 was one of the most energetic regions ever recorded. It produced several X-class flares including an X2.2 event on February 16, 2011 , when it crossed the central meridian. Several authors have analyzed this active region before and after the flare occurrence. They found evidence of strong shearing motions in the photosphere prior to the flare onset (e.g., Liu et al. , 2012; Petrie & Sudol 2010; Schrijver 2009 ). These observations suggest that the energy release may be triggered by reconnection processes involving twisted flux tubes (Petrie 2013) . However, there has been no detailed investigation into how these photospheric motions affect the coronal magnetic field or whether they trigger any significant reconfiguration of the magnetic field.",
        "watermark_text": "We present the analysis of the magnetic field configuration in active region NOAA 11158, which produced several large solar flares during its passage across the central meridian on February 15 - 16, 2011.We use vector magnetograms obtained by SDO / HMI and SOHO / MDI instruments as ill as photospheric line - of - sight magnetograms provided by GONG network.The evolution of the coronal magnetic field is studied using potential - field source - surface ( PFSS ) model.In addition we perform NLFFF extrapolations with different codes for comparison purposes.Our results show that both PFSS and NLFFF models are able to reproduce the big - scale structure of the corona but differ significantly at low scales.This discrepancy can be explained by considering the effect of plasma flows along open field lines.Finally, we study the relationship between the observed photospheric motions and the alterations in the coronal magnetic field.Active Region NOAA 11158 was one of the most energetic areas ever recorded.It produced various X - class flares including an X2. 2 event on February 16, 2011, when it crossed the central meridian.Several authors have analyzed this active region before and after the flare occurrence.They found proof of strength shearing motions in the photosphere prior to the flare onset ( e. g., Liu et al., 2012 ; Petrie & Sudol 2010 ; Schrijver 2009 ).These observations suggest that the energy release may be triggered by reconnection processes involving twisted flux tubes ( Petrie 2013 ).However, there has been no detailed investigation into how these photospheric motions affect the coronal magnetic field or whether they trigger any significant reconfiguration of the magnetic field."
    },
    {
        "original_text": "We present the relativistic second order perturbation theory for fluids in curved space-time with arbitrary number of components. We derive the general expression for the energy-momentum tensor at first order in perturbations as well as its trace-free part which is responsible for gravitational waves generation. The evolution equations are derived by projecting the conservation law onto the background 4-velocity vector field. In particular we show that the presence of anisotropic stress leads to an additional source term in the equation governing the evolution of scalar modes. Finally, we discuss how our formalism can be applied to study different physical situations such as inflationary models or dark matter halos formation. Cosmology has been revolutionized over the past decade thanks to precision measurements of temperature fluctuations in the cosmic microwave background (CMB) radiation [1] . These observations have provided us with detailed information about the early universe and allowed to test fundamental physics on very large scales [2] .\nThe standard model of cosmology assumes that the universe consists of several interacting components including cold dark matter (CDM), baryons, photons, neutrinos etc.. Each component evolves according to some set of hydrodynamical equations describing their dynamics [3] . However, these equations cannot be solved analytically even if one neglects all interactions between particles [4] , so numerical simulations are required [5] . On the other hand, analytical solutions exist only under certain approximations [6] . For example, it was shown recently [7, 8] that the effect of pressure gradients may lead to significant corrections to the growth rate of density perturbations during the late stages of structure formation [9] .",
        "watermark_text": "We present the relativistic 2nd order perturbation theory for fluids in curved space - time with arbitrary number of components.We derive the general expression for the energy - momentum tensor at initial order in perturbations as also as its trace - freedom part which is responsible for gravitational waves generation.The evolution equations are derived by projecting the conservation law upon the background 4 - velocity vector field.In particular we show that the presence of anisotropic stress leads to an extra source term in the equation governing the evolution of scalar modes.Finally, we discuss how our formalism can be applied to study different physical scenarios such as inflationary models or dark material halos formation.Cosmology has been revolutionized over the past decade thanks to precision measurements of temperature fluctuations in the cosmic microwave background ( CMB ) radiation[ 1 ].These observations have provided us with detailed information about the early universe and allowed to test fundamental physics on very large scales [ 2 ].The standard model of cosmology assumes that the universe consists of several interacting components including cold dark matter ( CDM ), baryons, photons, neutrinos etc.Each component evolves according to some set of hydrodynamical equations describing their dynamics[ 3 ].However, these equations cannot be solved analytically even if one neglects all interactions between particles [ 4 ], so numerical simulations are required [ 5 ].On the other hand, analytical solutions exist only under certain approximations[ 6 ].For example, it was shown recently [ 7, 8 ] that the effect of pressure gradients may lead to significant adjustments to the growth rate of density perturbations during the late stages of structure formation [ 9 ]."
    },
    {
        "original_text": "Superhumps are periodic modulations in the light curves of some cataclysmic variables (CVs). They have been observed to occur during both the high and low states, but their origin is still not understood. In this work we present comprehensive numerical simulations of CVs with mass ratios q = 0.7-0.9 that include tidal dissipation effects as well as magnetic braking. We find that for systems with orbital periods P orb < 3 hr, the inclusion of magnetic braking leads to an increase in the amplitude of the superhumps by up to a factor of two compared to previous results obtained without magnetic braking. For longer period systems, however, our models predict smaller amplitudes than those inferred observationally. This discrepancy may be due to additional physical processes such as irradiation or enhanced mass transfer rates at periastron passage which were neglected here. \n \n Keywords: Cataclysmic Variables",
        "watermark_text": "Superhumps are periodic modulations in the light curves of some cataclysmic variables ( CVs ).They have been observed to occur during both the high and low states, but their origin is still not understood.In this work we present comprehensive numerical simulations of CVs with mass ratios q = zero. 7 - 0. 9 that include tidal dissipation effects as well as magnetic braking.We find that for systems with orbital periods P orb < 3 hr, the inclusion of magnetic braking leads to an increase in the amplitude of the superhumps by up to a factor of 2 compared to previous results obtained without magnetic braking.For longer period systems, however, our models predict lesser amplitudes than those inferred observationally.This discrepancy may be due to additional physical processes such as irradiation or enhanced mass transport rates at periastron passage which were neglected here.Keywords : Cataclysmic Variables"
    },
    {
        "original_text": "We study double solid twistor spaces in general dimension and signature, extending previous results on self-dual manifolds to all signatures. We show that these spaces are always smooth, but may have singularities along certain subvarieties. In particular we prove that if $(M^{2n},g)$ is an oriented Riemannian manifold with holonomy group contained in Spin($n$), then its double solid twistor space has no singularities at all. This result can be seen as a generalization of the well-known fact that the twistor space of a self-dual 4-manifold does not have any singularities. The main tool used here is the spinor representation of the complexified Clifford algebra bundle over $M$. As another application of this technique, we give a new proof for the existence of a canonical connection on the normal bundle of a totally geodesic submanifold of a Riemannian manifold.",
        "watermark_text": "We study double solid twistor spaces in general dimension and signature, extending previous results on self - dual manifolds to all signs.We show that these spaces are always smooth, but might have singularities across certain subvarieties.In particular we prove that if $ ( M ^ { 2n }, g ) $ is an oriented Riemannian manifold with holonomy group contained in Spin ( $ n $ ), then its double solid twistor space has no singularities at all.This result can be seen as a generalization of the well - known fact that the twistor space of a self - dual four - manifold does not have any singularities.The main tool used here is the spinor representation of the complexified Clifford algebra bundle over $ M $. As another application of this technique, we give a new proof for the existence of a canonical connection on the ordinary bundle of a totally geodesic submanifold of a Riemannian manifold."
    },
    {
        "original_text": "The extraction of fresh water and energy from the atmosphere is proposed as an alternative to conventional sources, which are limited in supply or environmentally damaging.  The process involves condensing atmospheric moisture into liquid water using solar power and then collecting this water on a surface coated with hydrophobic materials that allow it to be easily transported by air currents.   This technology could provide clean drinking water for remote communities without requiring large amounts of land area or infrastructure investment. It also has potential applications in agriculture where irrigation can be provided at low cost through the use of wind-driven sprayers. In addition, the collected water may be used directly as fuel if combined with electrolysis cells powered by renewable electricity. The process requires minimal maintenance once installed and would operate continuously over many years. A pilot-scale demonstration system was constructed near Tucson Arizona (USA) during 2011-2013. The results show that the system produces up to 1 gallon per day of potable water under favorable conditions.",
        "watermark_text": "The extraction of freshwater water and energy from the atmosphere is proposed as an alternative to traditional sources, which are limited in supply or environmentally damaging.The process involves condensing atmospheric moisture into liquid water using solar power and then gathering this water on a substrate coated with hydrophobic materials that allow it to be easily transported by atmospheric currents.This technology could provide clear drinking water for isolated communities without requiring large amounts of land area or infrastructure investment.It also has possible applications in agriculture where irrigation can be provided at low cost through the use of wind - driven sprayers.In addition, the collected water may be used directly as energy if combined with electrolysis cells driven by renewable electricity.The process requires minimal maintenance once implemented and would operate continuously over many years.A pilot - scale demonstration system was constructed near Tucson Arizona ( US ) during 2011 - 2013.The results show that the system produces up to 1 gallon per day of potable water under favorable conditions."
    },
    {
        "original_text": "We present the first exact solution for the axisymmetric, stationary and force-free magnetic field structure around a rapidly-rotating neutron star with arbitrary inclination angle between its rotation and magnetic axes. The model is based on the assumption that the stellar surface is covered by a thin layer of plasma which corotates with the star at all latitudes. We show how this solution can be used to calculate the X-ray light curves produced by hot spots located at different latitudes above the stellar surface. In particular we demonstrate that the observed phase shifts between the peaks of soft X-rays (0.5-2 keV) and hard X-rays (2-10 keV), as well as their relative amplitudes are reproduced very accurately if one assumes that both emission components originate from two antipodal hot spots located near the magnetic poles. This result suggests that the observed X-ray pulsations may be caused by the rotational modulation of the local emissivity rather than by the Doppler effect due to bulk motion of matter within the emitting regions. \n \n Keywords: Force-free fields, Pulsar wind nebulae",
        "watermark_text": "We present the first precise solution for the axisymmetric, stationary and force - liberated magnetic field structure around a rapidly - rotating neutron star with arbitrary orientation angle between its rotation and magnetic axes.The model is based on the assumption that the stellar surface is covered by a thin layer of plasma which corotates with the star at all latitudes.We show how this solution can be used to calculate the X - ray light curves produced by hot spots located at different latitudes above the star surface.In particular we demonstrate that the observed phase shifts between the peaks of soft X - rays ( zero. 5 - 2 keV ) and hard X - rays ( 2 - 10 keV ), as well as their relative amplitudes are reproduced very accurately if one assumes that both emission components originate from two antipodal hot spots located near the magnetic poles.This result suggests that the observed X - ray pulsations may be caused by the rotational modulation of the local emissivity rather than by the Doppler effect due to bulk movement of material within the emitting regions.Keywords : Force - free fields, Pulsar wind nebulae"
    },
    {
        "original_text": "The rapidity and transverse momentum (pT) dependences of the electric charge correlation functions are studied for central Au+Au, d+Au and p+p collisions at RHIC and LHC energies using the AMPT model with string melting mechanism. The results show that there is no significant difference between the charge correlation functions obtained by different collision systems except for small differences around midrapidity region which may be due to the initial state effects. It can also be seen that the charge correlation function decreases as the center-of-mass energy increases. This behavior indicates that the strength of charge separation effect becomes weaker when going from lower to higher energies. Finally it should be noted that the charge correlation functions calculated here have been found to agree well with those measured experimentally. PACS numbers: 25.75.-q, 11.15.-x, 12.38.Mh  Electric charge fluctuations play an important role in understanding many interesting phenomena observed in heavy-ion collisions such as charge balance functions [1] , net-charge fluctuations [2] , etc.. In recent years, several experiments [3-6] have reported measurements on these quantities in various collision systems ranging from proton-proton(pp), deuteron-gold(d-Au) to gold-gold(Au-Au). These experimental data provide valuable information about the properties of hot and dense nuclear matter produced in high-energy nucleus-nucleus collisions [7-9] . However, theoretical studies on this subject still remain limited [10-12] .\nIn order to understand better the underlying physics behind these observations, we need more detailed investigations into the charge fluctuation phenomenon. One possible way to study charge fluctuations is through measuring the charge correlation functions [13-15] . Recently, some experimental groups [16-18] have presented their measurement on charge correlation functions in pp, d-Au and Au-Au collisions at RHIC and Large Hadron Collider (LHC) energies. On the other hand, the relativistic quantum molecular dynamics (RQMD) [19] and the parton-hadron-string dynamics (PHSD) [20] models predict that the charge correlation functions decrease rapidly towards zero",
        "watermark_text": "The rapidity and transverse momentum ( pT ) dependences of the electric charge correlation functions are investigated for central Au + Au, d + Au and p + p collisions at RHIC and LHC energies using the AMPT model with string melting mechanism.The results show that there is no significant difference between the charge correlation functions obtained by different collision systems besides for small differences around midrapidity area which may be due to the initial state effects.It can also be seen that the charge correlation function decreases as the centre - of - mass energy increases.This behavior indicates that the strength of charge segregation effect becomes weaker when going from lower to higher energies.Finally it should be noted that the charge correlation functions calculated here have been found to agreement well with those measured experimentally.PACS numbers : 25. 75. - q, 11. 15. - x, 12. 38. Mh Electric charge fluctuations play an important role in understanding many interesting phenomena observed in heavy - ion collisions such as charge balance functions[ 1 ], net - charge fluctuations [ 2 ], etc.In recent years, several experiments [ 3 - 6 ] have reported readings on these amounts in various collision systems ranging from proton - proton ( pp ), deuteron - golden ( d - Au ) to gold - gold ( Au - Au ).These experimental data provide valuable information about the properties of hot and density nuclear matter produced in high - energy nucleus - nuclear collisions[ 7 - 9 ].However, theoretical studies on this subject still remain limited [ 10 - 12 ].In order to understand better the underlying physics underlying these observations, we need more detailed investigations into the charge fluctuation process.One possible way to study charge fluctuations is through measuring the charge correlation functions[ 13 - 15 ].Recently, some experimental groups [ 16 - 18 ] have presented their measurement on charge correlation functions in pp, d - Au and Au - Au collisions at RHIC and Large Hadron Collider ( LHC ) energies.On the other hand, the relativistic quantum molecular dynamics ( RQMD )[ 19 ] and the parton - hadron - string dynamics ( PHSD )[ 20 ] models predict that the charge correlation functions decrease rapidly towards zero"
    },
    {
        "original_text": "We present an analysis of the kinematic properties of the ultra-faint satellites (UFS) of the Milky Way, using data from the Sloan Digital Sky Survey and the Dark Energy Survey. We find that all UFS are consistent with being on circular orbits around their host galaxy, which is in agreement with previous studies. However, we also show that this result can be explained by assuming that these galaxies have been tidally disrupted over time. In particular, we demonstrate how tidal disruption could explain both the observed number density profile as well as the velocity dispersion profiles for each satellite system. Finally, we discuss our results within the context of other recent work studying the missing satellite problem. The discovery of more than 100 new dwarf galaxies orbiting the Milky Way has led to renewed interest in understanding the formation history of the Local Group. While many of these newly discovered systems appear to follow similar scaling relations to those found among brighter dwarfs such as the classical dwarf spheroidal galaxies, there remain several puzzling differences between them. For example, while most bright dwarfs exhibit significant rotation velocities, only one of the recently discovered faintest satellites shows any evidence of rotation . Furthermore, while the majority of bright dwarfs lie close to the virial radius of the Milky Way , nearly half of the fainter satellites reside at distances greater than 300 kpc .\nIn addition to these observational challenges, theoretical models predict that dark matter halos should contain far fewer subhalos than are currently known to exist . This discrepancy -known as the \"missing satellite problem\"-has motivated numerous investigations into possible solutions ranging from modifications to standard cold dark matter theory to alternative theories of gravity .",
        "watermark_text": "We present an analysis of the kinematic properties of the ultra - faint satellites ( UFS ) of the Milky Way, utilizing data from the Sloan Digital Sky Survey and the Deep Energy Survey.We find that all UFS are consistent with being on circle orbits around their host galaxy, which is in agreement with previous studies.However, we still show that this outcome can be explained by assuming that these galaxies have been tidally disrupted over time.In particular, we demonstrate how tidal disturbance could explain both the observed numerical density profile as also as the velocity dispersion profiles for each satellite system.Finally, we discuss our results within the context of other latest work studying the lost satellite problem.The discovery of more than 100 new dwarf galaxies orbiting the Milky Way has led to renewed interest in understanding the forming history of the Local Group.While many of these newly discovered systems appear to follow similar scaling relationships to those discovered among brighter dwarfs such as the classical dwarf spheroidal galaxies, there remain several puzzling differences between them.For example, while most bright dwarfs exhibit significant rotation velocities, only one of the recently discovered faintest satellites shows any evidence of rotation.Furthermore, while the majority of bright dwarfs lie close to the virial radius of the Milky Association, nearly half of the fainter satellites reside at distances greater than 300 kpc.In addition to these observational challenges, theoretical models predict that dark matter halos should contain far fewer subhalos than are currently known to exist.This discrepancy - known as the \" missing satellite problem \" - has motivated numerous investigations into possible solutions ranging from modifications to standard cold dark matter theoretical to alternative theories of gravity."
    },
    {
        "original_text": "We study the profinite complex associated to a family of smooth projective curves over a field k with fixed genus g>0. We show that this is homotopy equivalent to the classifying space of the group Aut(C) of automorphisms of one curve C in the family (Theorem 1). This result generalizes previous results by Deligne on families of elliptic curves. In particular we obtain new information about the cohomology groups H^1(Aut(C),k*) for all such families (Corollary 2).\nIn section 3 we use our results to prove some basic facts about the anabelian geometry of the moduli stack M_g of stable curves of genus g. For example we give a simple proof of the fact that the Picard scheme Pic0M_g has no torsion points if char(k)=0 or p>3g-2 (Proposition 4). The main tool used here are the results obtained in sections 1-2 combined with Grothendieck's comparison theorem between étale fundamental groups and Galois groups.",
        "watermark_text": "We study the profinite complex associated to a family of smooth projective curves over a field k with fixed genus g > zero.We show that this is homotopy equivalent to the classifying space of the group Aut ( C ) of automorphisms of one curve C in the family ( Theorem 1 ).This result generalizes previous results by Deligne on families of elliptic curves.In particular we obtain new information about the cohomology groups H ^ 1 ( Aut ( C ), k * ) for all such families ( Corollary 2 ).In section 3 we use our results to prove some basic facts about the anabelian geometry of the moduli stack M _ g of stability curves of category g.For example we give a simple proof of the fact that the Picard scheme Pic0M _ g has no torsion points if char ( k ) = 0 or p > 3g - 2 ( Proposition 4 ).The main tool used here are the results obtained in sections 1 - 2 combined with Grothendieck ' s compared theorem between étale fundamental groups and Galois groups."
    },
    {
        "original_text": "We present results on the production and evolution of Langmuir waves (LWs) excited by an intense laser pulse interacting with a supersonic plasma flow, which is generated by a pulsed gas jet. The LWs are detected using Thomson scattering at different angles to the direction of propagation of the laser beam. We show that the LW spectrum has two distinct components: one component corresponds to the excitation of LWs by the ponderomotive force of the laser field; another component arises due to nonlinear wave-wave interactions between counter-propagating LWs. In addition, we find that the LWs can be efficiently converted into electromagnetic waves via Landau damping. Finally, we demonstrate that the LWs decay into ion acoustic waves through modulational instability. These findings provide new insights into the physics of diffusive radiation in plasmas driven by strong shocks. \n \n Introduction \n \n Diffuse radiative emission plays an important role in many astrophysical phenomena such as solar flares [1] , supernovae [2] , gamma-ray bursts [3] . It also occurs in laboratory experiments [4] where it may limit the efficiency of inertial confinement fusion schemes [5] . However, despite its importance there remain significant uncertainties about how diffuse radiation is generated [6] .\n \nIn this Letter, we report experimental measurements of the generation and evolution of Langmuintype waves (LWs), which play a key role in the process of diffusive radiation [7–9] . Our experiment uses a high-power short-pulse laser system operating at 1054 nm wavelength [10] to drive a supersonic plasma expansion [11] . This produces a strongly magnetized plasma [12] containing both electrons and ions [13] . The electron density profile along the axis of the expanding plasma column was measured using interferometry [14] . The temporal evolution of the electron temperature T e was inferred from the line-integrated intensity of the scattered light [15] . The LWs were probed using Thomson scattering [16] at various angles θ to the direction of propagation k 0 of the incident laser beam [17] . \n \n Figure 1 shows typical examples of the time-averaged scattered spectra S(k x ) obtained for",
        "watermark_text": "We present results on the production and evolution of Langmuir waves ( LWs ) excited by an intense laser pulse interacting with a supersonic plasma flow, which is generated by a pulsed gas jet.The LWs are detected utilizing Thomson scattering at different angles to the direction of propagation of the laser beam.We show that the LW spectrum has two distinct components : one component corresponds to the excitation of LWs by the ponderomotive force of the laser field ; another constituent arises due to nonlinear wave - wave interactions between counter - propagating LWs.In addition, we find that the LWs can be efficiently converted into electromagnetic waves via Landau damping.Finally, we demonstrate that the LWs decay into ion acoustic waves through modulational instability.These findings provide new insights into the physics of diffusive radiation in plasmas driven by strong shocks.Introduction Diffuse radiative emission plays an important role in many astrophysical phenomena such as solar flares[ 1 ], supernovae [ 2 ], gamma - ray bursts [ 3 ].It also occurs in lab experiments [ 4 ] where it might limit the efficacy of inertial confinement fusion schemes [ five ].However, despite its importance there remain significant uncertainties about how diffuse radiation is generated [ 6 ].In this Letter, we report experimental measurements of the generation and evolution of Langmuintype waves ( LWs ), which play a key role in the process of diffusive radiation [ 7 – 9 ].Our experiment uses a high - power short - pulse laser system operating at 1054 nm wavelength[ 10 ] to drive a supersonic plasma expansion[ 11 ].This produces a strongly magnetized plasma[ 12 ] containing both electrons and ions [ 13 ].The electron density profile along the axis of the expanding plasma column was measured using interferometry [ 14 ].The temporal evolution of the electron temperature T e was inferred from the line - integrated intensity of the scattered light [ 15 ].The LWs were probed utilizing Thomson scattering [ 16 ] at various angles θ to the direction of propagation k 0 of the incident laser beam[ 17 ].Figure 1 shows typical examples of the time - averaged scattered spectra S ( k x ) obtained for"
    },
    {
        "original_text": "We study the generation of large-scale magnetic fields in astrophysical plasmas with very small values of the magnetic Prandtl number, Pm = ν/η ≪ 1 (ν is viscosity, η is resistivity). We consider two different types of flows that are relevant for this problem -helically driven turbulence and convection-driven turbulence. In both cases we find that the mean electromotive force has contributions from several terms which scale differently as functions of the Reynolds number Re = UL/ν and the magnetic Reynolds number Rm = URm/η. Here U , L, and Rm are characteristic velocity, length, and magnetic field scales respectively.  For helically driven turbulence these contributions can be grouped into three categories:  The first category includes all terms proportional to Re(Rm)−1/2 . These terms have been studied previously by many authors using various approaches including direct numerical simulations. They represent the contribution of the so-called α-effect due to helical motions. The second category contains all terms proportional to Re1/2 (Rm)−1/4 . This term represents the effect of helicity on the nonlinear evolution of the magnetic fluctuations. Finally, there exists also an additional third category containing all terms proportional to Re3/4 (Rm)−3/8 . It describes the influence of helicity on the linear growth rate of the magnetic fluctuations.",
        "watermark_text": "We study the generation of large - scale magnetic fields in astrophysical plasmas with very small values of the magnetic Prandtl number, Pm = ν / η [UNK] 1 ( ν is viscosity, η is resistivity ).We consider two different types of flows that are relevant for this problem - helically driven turbulence and convection - driven turbulence.In both cases we find that the mean electromotive force has contributions from several terms which scale differently as functions of the Reynolds number Re = UL / ν and the magnetic de number Rm = URm / η.Here U, L, and Rm are characteristic velocity, length, and magnetic field scales respectively.For helically driven turbulence these contributions can be grouped into three categories : The first category includes all terms proportional to Re ( Rm ) −1 / 2.These terms have been studied previously by many authors using various approaches including direct numerical simulations.They represent the contribution of the so - called alpha - effect due to helical motions.The second category contains all terms proportional to Re1 / 2 ( Rm ) −1 / 4.This term represents the effect of helicity on the nonlinear evolution of the magnetic fluctuations.Finally, there exists also an additional third category containing all words proportional to Re3 / 4 ( Rm ) minus3 / eight.It describes the influence of helicity on the linear growth rate of the magnetic fluctuations."
    },
    {
        "original_text": "We present new space velocities for the nearest late-M, L-, and T-dwarf stars based on high-precision radial velocity measurements obtained with the HARPS spectrograph at La Silla Observatory in Chile over an 8-year period (2003-2009). We find that all but one of these objects are members of young nearby open clusters or associations. The only exception is LP 944-20 which has been shown to be a member of the Hyades supercluster by its proper motion.  These results confirm previous suggestions that most brown dwarfs have ages less than 100 Myr. They also show that there may exist two populations among the very low-mass stars and brown dwarfs: those associated with open clusters/associations and those apparently not gravitationally bound to any cluster. This suggests that either some brown dwarfs form outside open clusters and/or they evaporate rapidly after formation. Finally we discuss possible explanations for the observed kinematics of the lowest mass stars and brown dwarfs.",
        "watermark_text": "We present fresh space velocities for the nearest late - M, L -, and T - dwarf stars based on high - precision radial velocity measurements obtained with the HARPS spectrograph at La Silla Observatory in Chile over an 8 - year period ( 2003 - 2009 ).We find that all but one of these objects are members of young nearby open clusters or associations.The only exception is LP 944 - 20 which has been shown to be a member of the Hyades supercluster by its correct motion.These results confirm previous suggestions that most brown dwarfs have ages less than 100 Myr.They also show that there may exist two populations among the very poor - mass stars and brown dwarfs : those associated with open clusters / associations and those apparently not gravitationally bound to any cluster.This suggests that either some brown dwarfs form outside open clusters and / or they evaporate rapidly after formation.Finally we discuss potential explanations for the observed kinematics of the lowest mass stars and brown dwarfs."
    },
    {
        "original_text": "We present an algorithm for computing trajectories in the Bohmian interpretation of quantum mechanics, based on wavefunction entanglement and locality constraints. The method is applied to two examples with one or more particles in 1D space. We show that our results are consistent with those obtained by other methods when they exist; otherwise we obtain new insights into the dynamics of these systems. Our approach can be used as a tool for studying the foundations of quantum mechanics, and may also have practical applications such as guiding the design of novel quantum algorithms. Quantum mechanics has been successful at predicting experimental outcomes across many different physical phenomena [1] . However, it remains unclear how this theory should be interpreted physically [2] , especially since its predictions cannot always be reproduced experimentally [3] .\nOne possible way forward is to consider alternative interpretations of quantum mechanics [4] . In particular, there exists a class of theories known as hidden-variable theories [5] which attempt to explain quantum mechanical measurements using additional degrees of freedom not included within standard quantum mechanics [6] . One popular example of such a theory is Bohm's formulation [7, 8] where each particle follows a trajectory through configuration space [9] . This theory reproduces all of the statistical predictions made by standard quantum mechanics [10] but provides a deterministic description of individual measurement events [11] .",
        "watermark_text": "We present an algorithm for computing trajectories in the Bohmian interpretation of quantum mechanics, based on wavefunction entanglement and locality constraints.The method is applied to 2 examples with one or more particles in 1D space.We show that our results are consistent with those received by other methods when they exist ; otherwise we obtain new insights into the dynamics of these systems.Our approach can be used as a tool for studying the foundations of quantum mechanics, and may also have practical applications such as guiding the design of novel quantum algorithms.Quantum mechanics has been successful at predicting experimental outcomes across many different physical phenomena[ 1 ].However, it remains unclear how this theory should be interpreted physically [ 2 ], especially since its predictions cannot always be reproduced experimentally [ 3 ].One possible way forward is to consider alternative interpretations of quantum mechanics [ 4 ].In particular, there exists a class of theories known as hidden - variable theories [ 5 ] which attempt to explain quantum mechanical measurements using additional degrees of freedom not included within standard quantum mechanics [ 6 ].One popular example of such a theory is Bohm ' s formulation[ 7, 8 ] where each particle follows a trajectory through configuration space[ 9 ].This theory reproduces all of the statistical predictions made by standard quantum mechanics [ 10 ] but provides a deterministic description of individual measurement events[ 11 ]."
    },
    {
        "original_text": "We consider the probability distribution of the number of times that a simple random walk on an infinite graph visits some fixed vertex in finite time, and show how this can be approximated by a Poisson distribution with mean equal to the expected value of the number of visits.  We then use these results to prove that the total variation distance between the two distributions is bounded above by $O(1/n)$ where $n$ denotes the number of vertices in the graph.   This result generalizes previous work which was restricted to graphs whose degree sequence has exponential decay or polynomial growth.    The proof relies heavily upon recent advances in the theory of large deviations for sums of dependent Bernoulli variables. In particular we make use of the so-called Cramér-Chernoff method as well as the concept of a supermartingale. Finally, we apply our main theorem to obtain new bounds on the mixing time of lazy random walks on regular trees.",
        "watermark_text": "We consider the likelihood distribution of the number of times that a simple random walk on an infinite graph visits some fixed vertex in finite time, and show how this can be approximated by a Poisson distribution with mean equal to the expected value of the number of visits.We then utilize these results to prove that the total variation distance between the two distributions is bounded above by $ O ( 1 / n ) $ where $ n $ denotes the number of vertices in the graph.This result generalizes previous work which was restricted to graphs whose degree sequence has exponential decay or polynomial growth.The proof relies heavily upon recent advances in the theory of big deviations for sums of dependent Bernoulli variables.In particular we make use of the so - called Cramér - Chernoff method as also as the notion of a supermartingale.Finally, we apply our main theorem to obtain new bounds on the mixing time of lazy randomly walks on regular trees."
    },
    {
        "original_text": "The low-energy parameters of neutron-proton scattering are determined by using modern experimental data obtained in partial-wave analyses (PWAs). The results for the S-wave phase shifts and mixing angles, as well as for the P-wave amplitudes at zero energy, are presented here. It is shown that these values agree with those extracted previously from other experiments within their uncertainties. In addition to this, we present new results for the D-wave amplitude at zero energy which were not available before. \nI. INTRODUCTIO N\nNeutron-proton elastic scattering has been studied extensively over many decades [1] . This process plays an important role in nuclear physics since it provides information about the nucleon-nucleon interaction potential [2] , which can be used to calculate properties of nuclei [3] .\nIn recent years there have been significant advances in our understanding of the structure of the nucleon-nucleus system [4] . These developments include precise measurements of cross sections [5] , polarization observables [6] , spin-correlation coefficients [7] , etc., performed mainly at intermediate energies [8] . However, despite all efforts made so far, some questions remain open [9] . For example, one still needs more accurate determinations of the lowenergy parameters of the nucleonnucleon interaction [10] .",
        "watermark_text": "The low - energy parameters of neutron - proton scattering are determined by using modern experimental data derived in partial - wave analyses ( PWAs ).The results for the S - wave phase shifts and mixing angles, as well as for the P - phase amplitudes at zero energy, are presented here.It is shown that these values agree with those extracted previously from other experiments inside their uncertainties.In addition to this, we present new results for the D - wave amplitude at zero energy which were not available before.I. INTRODUCTIO N Neutron - proton elastic scattering has been studied extensively over many decades [ 1 ].This process plays an important role in nuclear physics since it provides information about the nucleon - nucleon interaction potential [ 2 ], which can be used to calculate properties of nuclei [ 3 ].In recent years there have been significant advances in our understanding of the structure of the nucleon - nucleus system [ 4 ].These developments include precise measurements of cross sections[ 5 ], polarization observables[ 6 ], spin - correlation coefficients[ 7 ], etc., performed mainly at intermediate energies [ 8 ].However, despite all efforts made so far, some questions remain open [ 9 ].For example, one still needs more accurate determinations of the lowenergy parameters of the nucleonnucleon interaction[ 10 ]."
    },
    {
        "original_text": "We present new results on the asteroseismic analysis of the primary component in the binary system Alpha Centari, based on data obtained with the HARPS spectrograph at La Silla Observatory (Chile). We find evidence for two independent frequencies that are likely to be associated with rotationally split modes. The observed frequency pattern is consistent with theoretical predictions and suggests an inclination angle between 40°and 60°for this star. \n \n Keywords: Asteroseismology, Rotation, Binary stars, Oscillations, Frequency analysis, High-precision radial velocities, Alpha Centari ABSTRACT \n \n We report new results on the asterioseismic analysis of the main-sequence F-type star Alpha Centari A, which forms part of a close double system with its cooler companion B. Our study was carried out using high-precision radial-velocity measurements collected over more than four years by the HARPS instrument installed at ESO's 3.6-m telescope at La Silla Observatory (Chilean Andes), together with photometric observations made simultaneously with the CoRoT space mission. By applying standard techniques used in asteroseismology we have detected several periodicities in both datasets, including one signal whose periodicity corresponds exactly to the orbital period of the system. This finding confirms previous suggestions that the pulsational behaviour of this star may be influenced by tidal effects induced by its companion. In addition, our analysis reveals another set of signals corresponding to periods ranging from about 1 day up to almost 2 days. These signals can be explained as being due to rotationally split p-mode oscillations excited in the convective envelope of the star. Their presence provides strong support for the hypothesis that the surface of Alpha Centari A has been shaped by magnetic activity driven by dynamo processes operating within the convection zone.",
        "watermark_text": "We present fresh results on the asteroseismic analysis of the primary constituent in the binary system Alpha Centari, based on data obtained with the HARPS spectrograph at La Silla Observatory ( Chile ).We find evidence for 2 independent frequencies that are probable to be associated with rotationally split modes.The observed frequency pattern is consistent with theoretical predictions and suggests an orientation angle between 40°and 60°for this star.Keywords : Asteroseismology, Rotation, Binary stars, Oscillations, Frequency analysis, High - precision radial velocities, Alpha Centari ABSTRACT We report new results on the asterioseismic analysis of the main - sequence F - type star Alpha Centari A, which forms part of a close double system with its cooler companion B.Our study was carried out via high - precision radial - velocity measurements collected over more than 4 years by the HARPS equipment installed at ESO ' s 3. 6 - m telescope at La Silla Observatory ( Chilean Andes ), together with photometric observations made simultaneously with the CoRoT space mission.By applying standard techniques used in asteroseismology we have detected several periodicities in both datasets, including single signal whose periodicity matches exactly to the orbital period of the system.This finding confirms previous suggestions that the pulsational behavior of this star may be influenced by tidal influences induced by its companion.In addition, our analysis reveals additional set of signals corresponding to periods ranging from about one day up to almost two days.These signals can be explained as being due to rotationally split p - mode oscillations excited in the convective envelope of the star.Their presence provides strong support for the hypothesis that the surface of Alpha Centari A has been shaped by magnetic action driven by dynamo processes operating within the convection zone."
    },
    {
        "original_text": "We present the results of an analysis of galaxy clustering in the Sloan Digital Sky Survey (SDSS) Data Release 7, using scale-independent and -dependent bias models to describe the observed correlation function on scales ranging from 0.1 h-1 Mpc to 20 h-1 Mpc.  We find that both models provide good fits to the data at large separations but only the scale-independent model provides a reasonable fit over all scales considered here. The best-fit values for the linear bias parameter are b1 = 1.7 +/- 0.2 for the scale-independent case and b2 = 2.3 +/- 0.4 for the scale-dependent case. These results suggest that galaxies may be biased tracers of dark matter fluctuations with different bias parameters depending upon their mass or luminosity. This is consistent with previous studies which have found evidence for scale dependence in the galaxy-matter cross-correlation function. However, we note that our conclusions depend strongly on the assumed functional form for the scale dependent bias factor.",
        "watermark_text": "We present the results of an analysis of galaxy clustering in the Sloan Digital Sky Survey ( SDSS ) Data Release 7, using scale - independent and - dependent bias models to describe the observed correlation function on scales ranging from 0. 1 h - 1Mpc to 20 h - 1 Mpc.We find that both models offer good fits to the data at large separations but only the scale - independent model provides a reasonable fit over all sizes considered here.The best - fit values for the linear bias parameter are b1 = 1. 7 + / - zero. 2 for the scale - independent case and bi2 = 2. 3 + / - zero. 4 for the scale - dependent case.These results suggest that galaxies may be biased tracers of dark matter fluctuations with different bias parameters depending upon their mass or luminosity.This is consistent with previous studies which have found proof for scale dependence in the galaxy - matter cross - correlation function.However, we note that our conclusions rely strongly on the assumed functional form for the scale dependent bias factor."
    },
    {
        "original_text": "We report on observations made with the Submillimeter Array and the Atacama Large Millimeter/submillimeter Array in order to study the kinematics of an outflow driven by the high-mass protostellar object, IRAS 18566+0408; this source is associated with a cluster of young stellar objects located at a distance of 3 kpc. The data reveal that there are two components along the line-of-sight; one component has a systemic velocity of ~10 km s-1 , while another component shows blueshifted emission up to -60 km s-1 . We find evidence for a collimated jet-like structure extending over ~0.5 pc. This suggests that the driving source may be deeply embedded within its natal cloud core. In addition, we detect several compact knots distributed along the flow axis which show blue-shifted velocities ranging between 10-60 km s-1 .\nThe mass-loss rate estimated from our observations ranges between 1×10-3 -1×10-2 M⊙ yr-1 .",
        "watermark_text": "We report on observations made with the Submillimeter Array and the Atacama Large Millimeter / submillimeter Array in order to study the kinematics of an outflow fueled by the high - mass protostellar body, IRAS 18566 + 0408 ; this source is associated with a cluster of young stellar objects located at a distance of 3 kpc.The data reveal that there are two components along the line - of - view ; one component has a systemic velocity of ~ 10 km s - one, while another component shows blueshifted emitted up to - 60 kilometers s - 1.We find evidence for a collimated jet - like structure extending over ~ 0. 5 pc.This suggests that the driving source may be deep embedded inside its natal cloud core.In addition, we detect several compact knots distributed along the flow axes which show blue - shifted velocities ranging between 10 - 60 km s - 1.The mass - loss rate estimated from our observations ranges between 1×10 - 3 - 1×10 - 2 [UNK] yr - 1."
    },
    {
        "original_text": "We present an algorithm to compute the Jones polynomial using three quantum wires and one ancilla qubit, which is based on the idea that the Jones polynomial can be computed by evaluating the Tutte polynomial at 1. We show how this approach leads naturally to a circuit with O(n) gates in depth O(log n), where n denotes the number of crossings in the knot diagram. The main ingredient of our construction are two new families of unitary operators acting on tensor products of Hilbert spaces associated with graphs. These operators generalize the swap operator and have applications beyond computing the Jones polynomial. In particular we use them to construct efficient quantum circuits for other problems such as counting perfect matchings or finding maximum flows. \nIntroduction\n\nThe Jones polynomial J K (t) ∈ Z[t ±1/2 ] of a knot K is a Laurent polynomial invariant of knots and links defined by V. Jones [Jon87] . It has been shown that it distinguishes all prime knots up to 10 crossings [Kaw96] , but its complexity makes it hard to evaluate even for small values of t. For example, if K is the trefoil knot then J K (1) = −1/4 while J K (−1/2) = 1/2. This raises the question whether there exists a quantum algorithm to efficiently calculate the Jones polynomial.",
        "watermark_text": "We present an algorithm to compute the Jones polynomial using 3 quantum wires and one ancilla qubit, which is based on the idea that the Jones polynomial can be computed by evaluating the Tutte polynomial at 1.We show how this approach leads naturally to a circuit with O ( n ) gates in depth O ( log n ), where n denotes the number of crossings in the knot diagram.The main ingredient of our construction are 2 new families of unitary operators acting on tensor products of Hilbert spaces associated with graphs.These operators generalize the swap operator and have applications beyond computing the Jones polynomial.In particular we use them to construct efficient quantum circuits for other issues such as counting perfect matchings or finding maximum flows.Introduction The Jones polynomial J K ( t ) ∈ Z [ t ±1 / 2 ] of a knot K is a Laurent polynomial invariant of knots and links defined by V. Jones[ Jon87 ].It has been shown that it distinguishes all prime knots up to 10 crossings [ Kaw96 ], but its complexity makes it hard to evaluate even for small values of t. For example, if K is the trefoil knot then J K ( 1 ) = −1 / 4 while J K ( −1 / 2 ) = 1 / 2.This raises the question whether there exists a quantum algorithm to efficiently calculate the Jones polynomial."
    },
    {
        "original_text": "We present an algorithm to solve the half-space depth problem, which is one of the most fundamental problems in computational geometry. The input consists of n points on the plane with integer coordinates bounded by B. We want to find a point that minimizes its distance to all other points. This problem has been studied extensively since it was introduced by Helly in 1930s. In this work we propose a new branch-and-cut algorithm based on mixed-integer programming (MIP) formulation. Our MIP model uses O(nB) variables and constraints. Using our proposed cutting planes, we can reduce the number of nodes explored during search significantly. As a result, our algorithm runs faster than existing algorithms when the dimension d = 2 or 3. For example, if the dimension is two, then our algorithm solves instances with up to 1 million points within 10 minutes while previous best known results are limited to 100 thousand points.",
        "watermark_text": "We present an algorithm to solve the half - space deep problem, which is 1 of the most fundamental problems in computational geometry.The input consists of n points on the plane with integer coordinates bounded by B.We want to find a point that minimizes its distance to all other points.This problem has been considered extensively since it was introduced by Helly in 1930s.In this work we propose a fresh branch - and - cut algorithm based on mixed - integer programming ( MIP ) formulation.Our MIP model utilizes O ( nB ) variables and limitations.Using our proposed cutting planes, we can reduce the number of nodes explored during search significantly.As a result, our algorithm runs faster than existing algorithms when the dimension d = 2 or three.For example, if the dimension is two, then our algorithm solves instances with up to one million points within 10 min while previous best known results are limited to 100 thousand points."
    },
    {
        "original_text": "We study the structure of the stationary distribution for an asymmetric version of the Target Process (TP). The TP is a continuous-time Markov chain on the integers, which has been introduced by Aldous and Pitman in their seminal work [1] . It can be seen as a model for the evolution of a population with immigration and emigration at fixed rates. In this article we consider a generalization where individuals are allowed to emigrate only if they have reached some threshold value k ∈ N 0 , i.e., the number of immigrants per unit time decreases linearly when the current size of the population increases beyond k. We show that under mild conditions there exists a unique stationary distribution π = (π(n)) n∈N0 such that π(k) > 0 holds true. Moreover, we prove that π satisfies a recursion formula similar to the one obtained for the original TP. Finally, we provide explicit expressions for π(1), ..., π(k+1).\nKeywords: Asymmetric target process, Stationary distribution",
        "watermark_text": "We study the structure of the stationary distribution for an asymmetric form of the Target Process ( TP ).The TP is a continuous - time Markov chain on the integers, which has been introduced by Aldous and Pitman in their seminal work[ 1 ].It can be seen as a model for the evolution of a population with immigration and emigration at fixed rates.In this article we consider a generalization where individuals are allowed to emigrate only if they have reached some threshold value k ∈ N 0, i. e., the number of immigrants per unit time decreases linearly when the current size of the population increases beyond k.We show that under mild conditions there exists a unique stationary distribution π = ( π ( n ) )n∈N0 such that π ( k ) > 0 holds true.Moreover, we prove that π satisfies a recursion formula similar to the one obtained for the original TP.Finally, we offer explicit expressions for π ( 1 ),., π ( k + 1 ).Keywords : Asymmetric target process, Stationary distribution"
    },
    {
        "original_text": "We present the results of searches for Pevatron candidates in the northern hemisphere using data collected by the High Energy Stereoscopic System (HESS) between 2004 and 2007, as well as IceCube data taken during 2005-2007. We find no significant excesses above background expectations at any point on the sky. Upper limits are set on the flux density of TeV photons and neutrinos associated with hypothetical sources within our field-of-view. These upper limits are used to constrain theoretical models describing the production mechanisms responsible for accelerating particles up to energies approaching 10^14 eV. The HESS collaboration has recently reported an observation of a new source of very-high-energy (VHE; >100 GeV) gamma-rays located near the Galactic Center [1] . This source is spatially coincident with the supernova remnant Sgr A East [2] , which was previously detected in radio waves [3] .\nThe discovery of this VHE source raises several questions about its origin. In particular, it remains unclear whether or not the observed emission arises directly from accelerated protons interacting with ambient gas [4] , or if other processes such as inverse Compton scattering off electrons [5] and/or bremsstrahlung [6] play a dominant role. It also remains unknown how these energetic particles were accelerated to their high energy levels [7, 8] .",
        "watermark_text": "We present the results of searches for Pevatron candidates in the north hemisphere using data collected by the High Energy Stereoscopic System ( HESS ) between 2004 and 2007, as well as IceCube data taken during 2005 - 2007.We find no significant excesses above background expectations at any point on the sky.Upper limits are set on the flux density of TeV photons and neutrinos associated with hypothetical sources within our field - of - view.These upper limits are used to constrain theoretical models describing the produced mechanisms responsible for accelerating particles up to energies approaching 10 ^ 14 eV.The HESS collaboration has recently reported an observation of a new source of very - high - energy ( VHE ; > 100 GeV ) gamma - rays located near the Galactic Center[ 1 ].This source is spatially coincident with the supernova remnant Sgr A East[ 2 ], which was previously detected in radio waves[ 3 ].The discovery of this VHE source raises several questions about its origin.In particular, it remains unclear whether or not the observed emission arises straight from accelerated protons engaging with ambient gas [ 4 ], or if other processes such as reverse Compton scattering off electrons [ 5 ] and / or bremsstrahlung[ 6 ] play a dominant role.It also remains unknown how these energetic particles were accelerated to their high energy levels[ 7, 8 ]."
    },
    {
        "original_text": "Gravastars are hypothetical objects that may be the final state of stellar evolution, and which have been proposed as alternatives to black holes.  Gravastars can be distinguished from black holes by their gravitational lensing effects on background stars.   In this work we show how these differences in lensing behavior could be used to distinguish between gravastars and black holes using observations made with current or future space-based telescopes such as LSST (Large Synoptic Survey Telescope) and WFIRST-AFTA (Wide Field Infrared Space Telescope - Astro-Physics). Gravitational lenses are powerful tools for studying distant galaxies because they magnify images of background sources.  The most famous example is the Einstein ring produced when light passes close to the Sun's mass.  However, there are many other types of gravitational lenses including those formed by galaxy clusters, individual galaxies, and even dark matter halos around single galaxies.  Gravitational lenses also provide information about the masses of both foreground and background objects.  For instance, if one knows the distance to an object producing a gravitational lens effect then its mass can be determined directly from the observed angular diameter of the lensed image.  This technique has been used successfully to measure the masses of supermassive black holes at the centers of nearby galaxies.  Gravitational lensing occurs whenever light travels through regions where gravity varies spatially.  Thus it should occur wherever gravity deviates significantly from Newtonian predictions.  Black holes violate general relativity near their event horizons so they produce strong deviations from Newtonian gravity.  On the other hand, gravastars do not violate general relativity outside their surfaces...",
        "watermark_text": "Gravastars are hypothetical objects that may be the final state of stellar evolution, and which have been proposed as alternatives to black holes.Gravastars can be distinguished from dark holes by their gravitational lensing effects on background stars.In this work we show how these differences in lensing behavior could be used to distinguish between gravastars and black holes using observations made with current or future space - based telescopes such as LSST ( Large Synoptic Survey Telescope ) and WFIRST - AFTA ( Wide Field Infrared Space Telescope - Astro - Physics ).Gravitational lenses are strong tools for studying distant galaxies because they magnify images of background sources.The most famous example is the Einstein ring production when light passes close to the Sun ' s mass.However, there are many other types of gravitational lenses like those formed by galaxy clusters, single galaxies, and even dark matter halos around single galaxies.Gravitational lenses also provide information about the masses of both foreground and background objects.For instance, if one knows the distance to an object producing a gravitational lens effect then its mass can be determined directly from the observed angular diameter of the lensed image.This technique has been used successfully to measure the masses of supermassive dark holes at the centers of near galaxies.Gravitational lensing occurs anytime light travels through regions where gravitational varies spatially.Thus it should occur wherever gravity deviates significantly from Newtonian predictions.Black holes violate general relativity near their event horizons so they produce strong deviations from Newtonian gravity.On the other hand, gravastars do not violate general relativity outside their surfaces."
    },
    {
        "original_text": "The search is performed using data collected by the BABAR experiment at SLAC in 1999-2000, corresponding to an integrated luminosity of about 40 fb-1 . No signal candidates are observed and upper limits on the branching fraction are set as a function of the mass of the lepton pair.  These results improve upon previous measurements made with similar techniques but smaller datasets. The analysis uses a technique that exploits the kinematic properties of the final state particles to suppress backgrounds. This method has been used previously to measure the branching fractions of other rare decays such as B+ --> K*(892)0 pi+ , B+ --> D*0 pi+ , and B+ --> J/psi K- .\nPACS numbers: 11.30.Er, 12.15.Hh, 13.20.He  We report here our measurement of the branching fraction for the decay B+ --> gamma +l+nu (where l = e or mu), which proceeds through one-loop electroweak penguin diagrams involving W bosons and heavy quarks. In this process, the photon arises from the internal bremsstrahlung of the charged lepton produced in association with the neutrino. The Standard Model predicts a branching fraction of 1.1 x 10-6 [1] . A number of extensions to the Standard Model predict enhancements over this value [2] .  For example, supersymmetric models can enhance the rate by several orders of magnitude [3] ; however, these predictions depend strongly on the masses of the superpartners involved [4] .",
        "watermark_text": "The search is performed utilizing data collected by the BABAR experiment at SLAC in 1999 - 2000, corresponding to an integrated luminosity of about 40 fb - one.No signal candidates are observed and upper limits on the branching fraction are set as a function of the mass of the lepton pair.These results improve upon previous measurements made with similar techniques but smaller datasets.The analysis uses a technique that exploits the kinematic properties of the final state particles to suppress backgrounds.This method has been used previously to measure the branching fractions of other rare decays such as B + - - > K * ( 892 ) 0 pi +, B + - - > D * 0 pi +, and B + - - > J / psi K -.PACS numbers : 11. 30. Er, 12. 15. Hh, 13. 20. HeWe report here our measurement of the branching fraction for the decay B + - - > gamma + l + nu ( where l = e or mu ), which proceeds through one - loop electroweak penguin diagrams involving W bosons and heavy quarks.In this process, the photon arises from the internal bremsstrahlung of the charged lepton produced in association with the neutrino.The Standard Model predicts a branching fraction of 1. 1 × 10 - six [ 1 ].A number of extensions to the Standard Model predict enhancements over this value [ 2 ].For example, supersymmetric models can enhance the rate by several orders of magnitude [ 3 ] ; nevertheless, these predictions depend strongly on the masses of the superpartners involved [ 4 ]."
    },
    {
        "original_text": "The electronic properties of carbon nanotubes are calculated using density functional theory (DFT) with the local-density approximation (LDA). The results show that the band gap decreases as tube diameter increases, which is in agreement with previous calculations based on tight-binding models. In addition to this effect, we find that the energy difference between the highest occupied molecular orbital (HOMO) and lowest unoccupied molecular orbital (LUMO), i.e., the HOMO-LUMO gap also depends strongly on tube diameter. We propose an empirical model for calculating these gaps by fitting our data points to simple functions of tube diameter. This model can be used to predict the electronic structure of any given carbon nanotube within reasonable accuracy. Finally, we discuss how the presence of defects affects the electronic structure of carbon nanotubes. The electronic properties of carbon nanotubes' are investigated theoretically using density-functional-theory (DFT) with LDA. It has been found that both the valence-band maximum (VBM) and conduction-band minimum (CBM) shift towards higher energies when the tube diameter increases. Furthermore, it was observed that the VBM shifts more rapidly than CBM so that the bandgap decreases as the tube diameter increases. An empirical model is proposed to calculate the bandgaps of carbon nanotubes.",
        "watermark_text": "The electronic properties of carbon nanotubes are calculated utilizing density functional theory ( DFT ) with the local - density approximation ( LDA ).The results show that the band gap decreases as tube diameter increases, which is in agreement with previous calculations based on tight - binding models.In addition to this effect, we find that the energy differential between the highest occupied molecular orbital ( HOMO ) and lowest unoccupied molecular orbital ( LUMO ), i. e., the HOMO - LUMO gap also depends strongly on tube diameter.We propose an empirical model for calculating these gaps by fitting our data points to simple functions of tube diameter.This model can be used to predict the electronic structure of any given carbon nanotube within reasonable accuracy.Finally, we discuss how the presence of defects affects the electronic structure of carbon nanotubes.The electronic properties of carbon nanotubes ' are investigated theoretically utilizing density - functional - theory ( DFT ) with LDA.It has been found that both the valence - band maximum ( VBM ) and conduction - band minimal ( CBM ) shift towards higher energies when the tube diameter increases.Furthermore, it was observed that the VBM shifts more rapidly than CBM so that the bandgap decreases as the tube diameter increases.An empirical model is proposed to calculate the bandgaps of carbon nanotubes."
    },
    {
        "original_text": "We present new theoretical evolutionary tracks for the mass range 1.8 to 2.5 M⊙, which are based on an improved treatment of convection in stellar interiors. We use these tracks as input into our seismic modelling code CESAM2k to compute synthetic seismograms for two different sets of observed frequencies (from COROT) corresponding to two possible values of the inclination angle i = 90° or 60° . The comparison between observations and theory shows that we can exclude one set of frequencies at high confidence level but not the other. This is due to the fact that the frequency differences between ℓ=0 and ℓ=2 modes depend strongly on the inclination angle. In addition, we find that the best fit model has a radius R=1.95R⊙ , which agrees well with the value inferred by asteroseismology using only ℓ=0 modes. Finally, we show how this result could be used to determine the age of the star.  Keywords: Seismic modelling",
        "watermark_text": "We present newly theoretical evolutionary tracks for the mass range 1. 8 to two. 5 [UNK], which are based on an improved treatment of convection in stellar interiors.We use these tracks as input into our seismic modelling code CESAM2k to compute synthetic seismograms for 2 different sets of observed frequencies ( from COROT ) corresponding to two possible values of the inclination angle i = 90° or 59°.The comparison between observations and theory shows that we can exclude one group of frequencies at high confidence value but not the other.This is due to the fact that the frequency differences between ℓ = 0 and ℓ = 2 modes depend strongly on the inclination angle.In addition, we find that the greatest fit model has a radius R = 1. [UNK], which agrees good with the value inferred by asteroseismology using only ℓ = zero modes.Finally, we show how this outcome could be used to decide the era of the star.Keywords : Seismic modelling"
    },
    {
        "original_text": "We present the first detailed analysis of the early photospheric evolution of Nova Scorpii 2004 # 1, based on high-resolution optical spectroscopy obtained with the Ultraviolet and Visual Echelle Spectrograph mounted at the Very Large Telescope in Chile.  The nova was discovered by amateur astronomers on March 31st, 2004, when it reached an apparent magnitude of 8.7. We find that the ejecta are expanding at velocities between 1000 km/s to 3000 km/s. From our observations we derive a distance estimate for this object of about 3 kpc. This is consistent with previous estimates derived using other methods. Using these results as input parameters into theoretical models, we determine the chemical composition of the ejecta. Our best fit model suggests that the ejecta consist mainly of O-rich material mixed with some CNO-processed material. In addition, we detect strong emission lines originating from highly ionized species such as FeXXV/FeXXVI or NeIX/NX. These lines indicate that the ejecta were heated up to temperatures above 10 million K during their expansion.",
        "watermark_text": "We present the first detailed analysis of the initial photospheric evolution of Nova Scorpii 04 # 1, based on high - resolution optical spectroscopy obtained with the Ultraviolet and Visual Echelle Spectrograph mounted at the Very Large Telescope in Chile.The nova was discovered by amateur astronomers on March 31st, 2004, when it reached an apparent magnitude of eight. 7.We find that the ejecta are expanding at velocities between 1000 kilometres / s to 3000 km / s.From our observations we derive a distance estimate for this object of about 3 kpc.This is consistent with previous estimates derived using other methods.Using these results as input parameters into theoretical models, we determine the chemical makeup of the ejecta.Our best fit model suggests that the ejecta consist mainly of O - rich material mixed with some CNO - processed material.In addition, we detect strong emission lines originating from highly ionized species such as FeXXV / FeXXVI or NeIX / NX.These lines indicate that the ejecta were heated up to temperatures above 10 million K during their expansion."
    },
    {
        "original_text": "We study pair production of doubly-charged scalars in association with two jets, which can be induced by both weak gauge bosons (W or Z) and photons via loops involving heavy fermions such as top quarks. We derive constraints on the masses of these particles using current experimental data for W+jets and Z+jets processes collected by ATLAS and CMS experiments at the Large Hadron Collider (LHC). In addition to the standard model backgrounds, we also consider contributions from other new physics models that may have similar signatures. The results are presented in terms of exclusion limits on the mass parameters of various new physics scenarios. Finally, we discuss possible signals of this process at future runs of the LHC. PACS numbers: 12.60.Jv, 13 .85.Rm, 14.80.Ly \nI. INTRODUCTIO N\nThe discovery of neutrinos has opened up an exciting possibility of probing beyond Standard Model (SM), especially its Majorana nature [1] , through their lepton number violating interactions [2] . One interesting scenario is the seesaw mechanism [3] where SM singlet right-handed neutrinos acquire large Majorana masses after electroweak symmetry breaking [4] .\nIn order to test whether the observed light neutrinos are indeed Majorana particles, one needs to look for lepton-number-violating processes mediated by virtual heavy neutrinos [5] . These include neutrinoless double beta decay [6] , tritium beta decay [7] , and charged-current quasielastic scattering [8] . However, it turns out that all these processes suffer from severe astrophysical and/or nuclear matrix element uncertainties [9] . On the other hand, colliders provide clean environments to probe lepton number violation directly [10] . For example, searches for same-sign dileptons [11] and trileptons [12] at hadronic colliders could lead to important information about Majorana neutrinos [13] . Another promising channel is the production of doubly-charge scalar particles [14] , which can occur either through s-channel exchange of neutral gauge bosons [15] or t-channel exchange of heavy ferm",
        "watermark_text": "We study pair production of doubly - charged scalars in association with 2 jets, which can be induced by both weak gauge bosons ( W or Z ) and photons via loops involving heavy fermions such as top quarks.We derive constraints on the masses of these particles using current experimental data for W + jets and Z + jets processes collected by ATLAS and CMS experiments at the larger Hadron Collider ( LHC ).In addition to the standard model backgrounds, we also consider contributions from other new physics models that may have similarly signatures.The results are presented in terms of exclusion limits on the mass parameters of various new physics scenarios.Finally, we discuss potential signals of this process at future runs of the LHC.PACS numbers : 12. 60. Jv, 13. 85. Rm, 14. 80. Ly I. INTRODUCTIO NThe discovery of neutrinos has opened up an exciting chance of probing beyond Standard Model ( SM ), especially its Majorana nature[ 1 ], through their lepton number violating interactions [ 2 ].One interesting scenario is the seesaw mechanism [ 3 ] where SM singlet right - handed neutrinos acquire large Majorana masses after electroweak symmetry breaking [ 4 ].In order to test whether the observed light neutrinos are indeed Majorana particles, one needs to seek for lepton - number - violating processes mediated by virtual heavy neutrinos [ 5 ].These include neutrinoless double beta decay[ 6 ], tritium beta decay[ 7 ], and charged - current quasielastic scattering [ 8 ].However, it turns out that all these processes suffer from severe astrophysical and / or atomic matrix element uncertainties [ 9 ].On the other hand, colliders supply clean environments to probe lepton number violation directly [ 10 ].For example, searches for same - sign dileptons [ 11 ] and trileptons[ 12 ] at hadronic colliders could lead to important information about Majorana neutrinos [ 13 ].Another promising channel is the production of doubly - charge scalar particles [ 14 ], which can occur either through s - channel exchange of neutral gauge bosons[ 15 ] or t - channel exchange of heavy ferm"
    },
    {
        "original_text": "We study the decoherence dynamics of an open quantum system consisting of two-level atoms coupled to a single-mode cavity field in presence of dissipation and driving fields. The atom-cavity coupling is treated within the framework of Jaynes-Cummings model, while the dissipative effects are described by using the master equation for the reduced density matrix of the system. We show that the steady state solution of this problem can be obtained analytically when the decay rates of all atomic levels are equal. In particular we find that the steady-state entanglement between the atom-field subsystem depends on both the strength of the external driving field as well as the number of excited states involved in the process. Finally, we discuss how our results could be used to explain recent experimental observations concerning the generation of nonclassical light via spontaneous emission processes. PACS numbers: 03.67.Mn, 42.50.Vk",
        "watermark_text": "We study the decoherence dynamics of an open quantum system consisting of two - level atoms coupled to a single - level cavity field in presence of dissipation and driving Forces.The atom - cavity coupling is treated within the framework of Jaynes - Cummings model, while the dissipative effects are described by using the master equation for the reduced density matrix of the system.We show that the steady state solution of this problem can be obtained analytically when the decay rates of all atomic levels are even.In particular we find that the steady - state entanglement between the atom - field subsystem depends on both the strength of the outside driving field as well as the number of excited states involved in the process.Finally, we discuss how our results could be used to explain recent experimental observations concerning the generation of nonclassical light using spontaneous emitted processes.PACS numbers : 03. 67. Mn, 42. 50. Vk"
    },
    {
        "original_text": "We present an analysis of the most massive cluster known to be part of the Great Attractor, based on new spectroscopic data obtained with VLT/VIMOS and archival Chandra X-ray Observatory observations. The main results are as follows:  We find that the galaxy distribution is well described by a single NFW profile out to at least 1 Mpc/h.  Using this mass model we derive a virial mass for the cluster of Mvir = 2.1 x 1015M⊙/h70 within R200 = 0.9 h-1 70 Mpc/h. This value agrees very well with previous estimates derived using different techniques. We also show that the velocity dispersion profile can be fitted with a simple β-model up to r ~ 0.7R200. Beyond this radius there seems to be evidence for a steepening of the profile which could indicate the presence of substructures or infalling groups along the line-of-sight.",
        "watermark_text": "We present an analysis of the most massive cluster known to be member of the Great Attractor, based on new spectroscopic data obtained with VLT / VIMOS and archival Chandra X - ray Observatory observations.The main results are as follows :We find that the galaxy distribution is well described by a single NFW profile out to at least 1 Mpc / h. Using this mass model we derive a virial mass for the cluster of Mvir = 2. 1 x [UNK] / h70 within R200 = 0. 9 h - 1 70 Mpc / h.This value agrees very well with previous estimates derived using different techniques.We also show that the velocity dispersion profile can be fitted with a simple β - model up to r ~ 0. 7R200.Beyond this radius there seems to be evidence for a steepening of the profile which could indicate the presence of substructures or infalling groups along the line - of - sight."
    },
    {
        "original_text": "The article is devoted to the problem of possible existence of dark matter particles in our Galaxy, which are not detected by other methods than their gravitational effects on visible objects (stars). The author considers the possibility that these hypothetical particles can be described as celestial mechanics daemons with certain properties. In particular, it is shown how such daemons could explain some features observed recently for the DAMA experiment at Gran Sasso National Laboratory. It should be noted that this explanation does not contradict any known experimental data. However, there are also serious difficulties associated with the proposed model. These problems will require further study. This work was supported by Russian Science Foundation grant No 14-50-00040. URL: http://arxiv.org/abs/1409.5189 . \nI. INTRODUCTORY REMARK .\nDark Matter (DM) is one of the most important mysteries of modern physics [1] - [4] . Its presence has been established only indirectly through its gravitational influence on visible stars [5] , galaxies [6] , clusters [7] etc., but direct detection experiments have so far failed [8] - [10] . There exist many theoretical models describing DM [11] - [13] ; however, none of them has yet been confirmed experimentally [14] . One of the possibilities is that DM consists of new elementary particles [15] - [17] . If they interact weakly or electromagnetically with ordinary matter then they would escape detection even if they were produced in large quantities [18] . On the other hand, if they interact strongly enough with normal matter, then they may be detectable directly [19] - [21] . A number of experiments searching for DM particles have been carried out [22] - [26] . Recently, the results obtained by the DAMA collaboration [27] attracted considerable attention [28] - [30] . According to these results, the annual modulation effect [31] - [33] caused by the motion of Earth around Sun [34] - [36] leads to an increase in the rate of nuclear recoils registered by detectors during June-October period [37] compared to December-February period. Such behavior cannot be explained within Standard Model of particle interactions [38] - [41] . Several authors suggested different explanations based on",
        "watermark_text": "The article is devoted to the problem of potential existence of dark matter particles in our Galaxy, which are not detected by other methods than their gravity effects on visible objects ( stars ).The author considers the possibility that these hypothetical particles can be described as celestial mechanics daemons with certain properties.In particular, it is shown how such daemons could explain some features seen recently for the DAMA experiment at Gran Sasso National Laboratory.It should be noted that this explanation does not contradict any known experiments data.However, there are also serious difficulties involved with the proposed model.These problems will require further study.This work was supported by Russian Science Foundation grant No 14 - 50 - 00040.URL : http : / / arxiv. org / abs / 1409. 5189.I. INTRODUCTORY REMARK.Dark Matter ( DM ) is one of the most significant mysteries of modern physics[ 1 ] - [ 4 ].Its presence has been established only indirect through its gravitational effect on visible stars [ 5 ], galaxies[ 6 ], clusters [ 7 ] etc., but direct detection experiments have so far unsuccessful [ 8 ] - [ 10 ].There exist many theoretical models describing DM[ 11 ] -[ 13 ] ; however, none of them has yet been verified experimentally[ 14 ].One of the possibilities is that DM consists of new elementary particles [ 15 ] - [ 17 ].If they interact weakly or electromagnetically with ordinary matter then they could escape detector even if they were produced in large quantities [ 18 ].On the other hand, if they interact strongly enough with normal matter, then they might be detectable directly[ 19 ] -[ 21 ].A number of experiments searching for DM particles have been carried out [ 22 ] - [ 26 ].Recently, the results obtained by the DAMA collaboration [ 27 ] attracted considerable attention[ 28 ] - [ 30 ].According to these results, the annual modulation effect [ 31 ] - [ 33 ] caused by the motion of Earth around Sun[ 34 ] - [ 36 ] leads to an increase in the rate of nuclear recoils registered by detections during June - October period[ 37 ] compared to December - February period.Such behaviour cannot be explained within Standard Model of particle interactions[ 38 ] - [ 41 ].Several authors suggested different explanations based on"
    },
    {
        "original_text": "We study the orbital evolution of planets in binaries under the effect of gravitational perturbations due to third bodies, which can lead to large eccentricities and inclinations for both components of the system. We show that this mechanism is able to explain some observed properties of extrasolar systems such as HD 169830 or Kepler-16. In particular we find that it may be responsible for the formation of hot Jupiters through planet-planet scattering processes. The main results are summarized below: \n1) We present an analytical model describing the long-term evolution of the semi-major axes (a), eccentricities (e), and mutual inclination angles (i) of two orbiting objects under the combined effects of general relativity, tides, and secular interactions between all three bodies. \n2) Using our model, we perform numerical integrations of several representative cases showing how the presence of additional perturbative forces can significantly modify the orbital parameters of the innermost body over time-scales ranging from millions up to billions of years. \n\n3) We apply our model to the case of the exoplanetary system around HD 169830 composed of four giant planets on highly inclined orbits. Our calculations suggest that the current architecture of this system could have been produced by successive scatterings among its planets triggered by strong gravitational encounters with other massive bodies located at distances larger than 100 AU. \n \n 4) Finally, we explore the possibility that the recently discovered transiting super-Earths in the Kepler-16 system might also have formed via similar mechanisms.",
        "watermark_text": "We study the orbital evolution of planets in binaries under the effect of gravitational perturbations due to third bodies, which can lead to large eccentricities and orientations for both components of the system.We show that this mechanism is able to explain some observed properties of extrasolar systems such as HD 169830 or Kepler - 16.In particular we find that it may be responsible for the formation of hot Jupiters through planet - planetary scattering processes.The main results are summarized below : 1 )We present an analytical model describing the long - run evolution of the semi - major axes ( a ), eccentricities ( e ), and mutual orientation angles ( i ) of two orbiting objects under the combined effects of general relativity, tides, and secular interactions between all three bodies.2 ) Using our model, we perform numerical integrations of several representative cases showing how the presence of additional perturbative forces can significantly modify the orbital parameters of the innermost body over time - scales ranging from millions up to billions of years.3 ) We apply our model to the case of the exoplanetary system surrounding HD 169830 composed of four giant worlds on extremely inclined orbits.Our calculations suggest that the present architecture of this system could have been produced by successive scatterings among its planets triggered by strongly gravitational encounters with other massive bodies located at distances bigger than 100 AU.4 )Finally, we explore the possibility that the recently discovered transiting super - Earths in the Kepler - 16 system might also have formed via similarly mechanisms."
    },
    {
        "original_text": "We study the possibility that nonstandard interactions (NSI) between neutrinos and matter can be probed by using solar and reactor neutrino data simultaneously, in particular through their combined effect on the survival probability P(νe→νe). We find that NSI parameters are constrained to values below 0.1 for most combinations of standard oscillation parameters allowed at 3σ CL by current global fits. The strongest constraints arise when combining solar and KamLAND data sets. In this case we obtain upper bounds on |εee|, |εµτ | < 0.06 − 0.07 depending on the value of θ13. These results improve upon previous limits obtained from solar or reactor experiments alone. \n \n Introduction \n \n Neutrino oscillations have been observed in many different types of experiments [1] . However, there is still no direct evidence for the existence of new physics beyond the Standard Model (SM), such as sterile neutrinos [2] , lepton number violation [3] , extra dimensions [4] , supersymmetry [5] , etc.. Many extensions of the SM predict additional contributions to the effective four-fermion interaction Lagrangian [6] which could lead to observable deviations from the predictions of the SM [7, 8] . For example, it has recently been shown [9] that some models of quantum gravity [10] may induce an energy dependent refractive index n = 1 + εE/E0 where E0 is a characteristic scale associated with the underlying theory [11] . This would result in a modification of the vacuum mixing angle sin2θ12 = 1−cos2θ12 ≈ 1+ε/2+O(ε3) [12] leading to potentially large effects on the propagation of neutrinos [13] .\n \nIn addition to these theoretical motivations, there exist several experimental indications pointing towards possible new physics beyond the SM [14] : i) Large atmospheric [15] and solar [16] neutrino flux deficits; ii) LSND [17] and MiniBooNE [18] anomalies indicating short-baseline νμ → νe appearance transitions not predicted within three-flavor neutrino oscillations [19] ; iii) Anomalies in the measurement of the muon anomalous magnetic moment",
        "watermark_text": "We study the possibility that nonstandard interactions ( NSI ) between neutrinos and material can be probed by using solar and reactor neutrino data concurrently, in particular through their together effect on the survival probability P ( νe→νe ).We find that NSI parameters are constrained to values below 0. 1 for most combinations of standard oscillation parameters permitted at 3σ CL by current global fits.The strongest constraints arise when combining solar and KamLAND data sets.In this case we obtain higher bounds on | εee |, | εµτ | < zero. 06− 0. 07 depending on the value of θ13.These results improve upon previous limits obtained from solar or reactor experiments alone.Introduction Neutrino oscillations have been observed in many different types of experiments [ 1 ].However, there is still no direct evidence for the existence of new physics past the Standard Model ( SM ), such as sterile neutrinos [ 2 ], lepton number violation[ 3 ], extra dimensions [ 4 ], supersymmetry[ 5 ], etc.Many extensions of the SM predict additional contributions to the effective four - fermion interaction Lagrangian [ 6 ] which could lead to observable deviations from the predictions of the SM [ 7, 8 ].For example, it has recently been shown [ 9 ] that some models of quantum gravity [ 10 ] may induce an energy dependent refractive index n = 1 + εE / E0 where E0 is a characteristic scale associated with the underlying theory [ eleven ].This would result in a modification of the vacuum mixing angle sin2θ12 = 1−cos2θ12 ≈ 1 + η / 2 + O ( ε3 )[ 12 ] leading to potentially large effects on the propagation of neutrinos [ 13 ].In addition to these theoretical motivations, there exist several experimental indications pointing towards possible new physics past the SM[ 14 ] : i )Large atmospheric[ 15 ] and solar [ 16 ] neutrino flux deficits ; ii ) LSND[ 17 ] and MiniBooNE [ 18 ] anomalies indicating short - baseline νμ → νe appearance transitions not predicted within three - flavor neutrino oscillations[ 19 ] ; iii ) Anomalies in the measurement of the muon anomalous magnetic moment"
    },
    {
        "original_text": "The author presents an alternative approach to teaching special relativity by using the concept of transformation groups and their generators, which are used in physics for describing symmetry properties of physical systems.  The main idea is that students can learn about the foundations of special relativity without having to deal with complicated mathematical concepts such as tensors or spinor fields. This article describes how this method works on examples related to the Lorentz transformations. It also discusses some possible applications of these ideas in other areas of physics. In particular, it shows how one can use them to explain the origin of gauge symmetries in quantum field theory. Special relativity (SR) has been taught at many universities since its discovery in 1905 [1] . However, despite numerous attempts [2] , there still exists no generally accepted way of introducing SR into undergraduate courses [3] .\nIn recent years, several authors have proposed new approaches to teaching SR [4] - [8] . These methods usually involve presenting the basic principles of SR through simple experiments performed in different reference frames [9] - [11] . They often require only minimal knowledge of mathematics [12] - [14] . Some of these proposals were inspired by Feynman's lectures [15] . Other authors tried to develop similar techniques based on modern computer technology [16] - [18] .",
        "watermark_text": "The author presents an alternative approach to teaching special relativity by using the concept of transformation groups and their generators, which are utilized in physics for describing symmetry properties of physical systems.The main idea is that students can learn about the foundations of special relativity without having to deal with complicated mathematical concepts such as tensors or spinor fields.This article describes how this method works on examples related to the Lorentz transformations.It also discusses some possible applications of these ideas in other areas of physics.In particular, it shows how one can use them to justify the source of gauge symmetries in quantum field theory.Special relativity ( SR ) has been taught at many universities since its discovery in 1905 [ 1 ].However, despite numerous attempts [ 2 ], there still remains no generally accepted method of introducing SR into undergraduate courses [ 3 ].In recent years, several authors have proposed novel approaches to teaching SR[ 4 ] - [ 8 ].These methods usually involve presenting the basic principles of SR through simple experimentation performed in different reference frames [ 9 ] - [ 11 ].They often require only minimal learning of mathematics[ 12 ] -[ 14 ].Some of these proposals were inspired by Feynman ' s lectures [ 15 ].Other authors tried to develop similar techniques based on modern computer technology[ 16 ] - [ 18 ]."
    },
    {
        "original_text": "We propose the Gaussian-basis Monte Carlo method to study ground states of itinerant electron systems with strong correlations, which is based on the variational principle in terms of the trial wave function expressed by the product of Gutzwiller-Jastrow factors. The proposed method can be applied to any kind of electronic structure calculation methods such as density functional theory (DFT) or quantum Monte Carlo (QMC). We demonstrate that our method works well even when we use DFT results as input data instead of QMC ones. In addition, it enables us to calculate physical quantities directly related to the correlation effects without using complicated numerical procedures. As an example application, we show how this method can be used to investigate magnetic properties of strongly correlated materials. Our method will provide useful information about the nature of magnetism in these materials. This work was supported by JSPS KAKENHI Grant Number JP16K05481",
        "watermark_text": "We propose the Gaussian - basis Monte Carlo method to study ground states of itinerant electron systems with strong correlations, which is based on the variational principle in terms of the trial wave function expressed by the product of Gutzwiller - Jastrow factors.The proposed method can be applied to any kind of electronic structure calculation calculations such as dense functional theory ( DFT ) or quantum Monte Carlo ( QMC ).We demonstrate that our method works well even when we utilize DFT outcomes as input data instead of QMC ones.In addition, it enables us to calculate physical quantities directly related to the correlation effects without using complicated numerical procedures.As an example application, we demonstrate how this methodology can be used to investigate magnetic properties of strong correlated materials.Our method will provide useful information about the nature of magnetism in these materials.This work was supported by JSPS KAKENHI Grant No JP16K05481"
    },
    {
        "original_text": "In this work, we propose cooperative transmission protocols for wireless networks using multiuser detection (MUD) at the relay node to improve spectral efficiency as well as diversity order. The proposed schemes are based on network coding techniques that allow multiple users in the system to share the same time-frequency resources by exploiting spatial multiplexing gain. We first consider an amplify-and-forward protocol where each user transmits its signal simultaneously over different antennas while the relay performs MUD before forwarding it to all other users. Then, we extend our analysis to decode-and forward scheme which allows us to achieve higher data rates than those achieved by amplify-and-forward scheme. Finally, we derive closed-form expressions for outage probability and ergodic capacity under Rayleigh fading channels. Our results show that the proposed schemes can significantly enhance both spectral efficiency and diversity order compared to conventional non-cooperative systems. In addition, they also demonstrate that the performance gap between the two considered cooperative schemes is negligible when the number of transmit antennas increases. \n \n Keywords: Cooperative communication; Amplify-and-Forward Protocol; Decode-and-Forward Scheme",
        "watermark_text": "In this work, we propose cooperative transmission protocols for wireless networks using multiuser detector ( MUD ) at the relay node to improve spectral efficiency as well as diversity order.The proposed schemes are based on network coding techniques that allow multiple users in the system to share the same moment - frequency resources by exploiting spatial multiplexing gain.We first consider an amplify - and - forward protocol where each user transmits its signal simultaneously over different antennas while the relay performs MUD before forwarding it to all other users.Then, we extend our analysis to decode - and forward scheme which allows us to achieve higher data rates than those achieved by amplify - and - advance scheme.Finally, we derive closed - form expressions for outage probability and ergodic capacity under Rayleigh fading channels.Our results show that the proposed schemes can significantly enhance both spectral efficiency and diversity order comparison to conventional non - cooperative systems.In addition, they also demonstrate that the performance gap between the two considered cooperative schemes is negligible when the number of transmit antennas increases.Keywords : Cooperative communication ; Amplify - and - Forward Protocol ; Decode - and - Forward Scheme"
    },
    {
        "original_text": "We study the phenomenology of non-zero trilinear soft supersymmetry breaking (SSB) term A 0 in minimal supergravity (mSUGRA). We find that for large values of tan β, there is an upper bound on |A 0 | which can be obtained by requiring correct electroweak symmetry breaking. For small values of tan β, we show that the allowed range of |A 0 | increases with decreasing value of M 1/2 . In both cases, the lower limit on |A 0 | comes from the requirement of not having charge and/or color breaking minima deeper than the electroweak vacuum. The effect of varying |A 0 | on sparticle masses are studied numerically using ISAJET 7.64. It is found that increasing |A 0 | leads to decrease in mass difference between lightest neutralino and lighter charginos as well as increase in mass splitting among squarks and sleptons. This results into enhancement of production cross sections of these particles at hadronic colliders like Tevatron and LHC.",
        "watermark_text": "We study the phenomenology of non - zero trilinear soft supersymmetry breaking ( SSB ) term A 0 in minimal supergravity ( mSUGRA ).We find that for large values of tan β, there is an higher bound on | A 0 | which can be obtained by needing correct electroweak symmetry breaking.For small values of tan β, we show that the allowed range of | A 0 | increases with decreasing sign of M1 1 / 2.In both cases, the lower limit on | A 0 | comes from the requirement of not having charge and / or color breaking minima deeper than the electroweak vacuum.The effect of varying | A 0 | on sparticle masses are studied numerically using ISAJET 7. 64.It is found that increasing | A 0 | leads to decrease in mass difference between lightest neutralino and lighter charginos as well as increase in mass splitting among squarks and sleptons.This results into enhancement of production cross sections of these particles at hadronic colliders like Tevatron and LHC."
    },
    {
        "original_text": "We study thermodynamics and transport properties of the Kondo necklacemodel (KNM) in the vicinity of its quantum phase transition to an ordered state, which is driven by spin fluctuations. We show that this transition can be described within the framework of Landau-Ginzburg-Wilson theory with a nontrivial scaling dimension of the order parameter field. The latter determines the universality class of the transition as well as the temperature dependence of various physical quantities such as specific heat or resistivity. In particular we find that at low temperatures the system exhibits non-Fermi liquid behavior characterized by power-law dependences of these quantities on T . \nI. INTRODUCTORY REMARkS\nThe Kondo necklace model 1 ,2 describes a chain of magnetic impurities coupled via antiferromagnetic exchange interactions J. It has been introduced originally for describing the physics of heavy fermion compounds 3 but it also appears naturally in other contexts 4-7 .\nIn the present work we consider the case when the coupling constant J exceeds some critical value Jc = 2t / U where t denotes hopping amplitude between neighboring sites and U stands for local Coulomb repulsion energy 8-10 . At zero temperature the ground state of the system corresponds then to a ferromagnetically ordered state 11-13 while at finite temperatures one expects a continuous quantum phase transition into a paramagnetic state 14-17 . This transition occurs due to strong spin fluctuations 18-20 and belongs therefore to the same universality class as the Heisenberg chain 21-23 . However there are important differences between both models 24-26 : First, the Kondo necklace contains two types of excitations -spinons and holons 27-29 -while the Heisenberg chain only consists of spin-1/2 particles. Second, the Kondo necklaces contain additional degrees of freedom associated with charge carriers 30-32 . These features lead to new phenomena not observed in the Heisenberg chain 33-36 . For example, the Kondo necklacelike systems may exhibit unconventional superconducting states 37-39 .",
        "watermark_text": "We study thermodynamics and transport properties of the Kondo necklacemodel ( KNM ) in the vicinity of its quantum phase transition to an ordered state, which is driven by spin fluctuations.We show that this transition can be described within the frame of Landau - Ginzburg - Wilson theory with a nontrivial scaling dimensional of the order parameter field.The latter determines the universality class of the transition as well as the temperature dependence of various physical quantities such as specific heat or resistivity.In particular we find that at low temperatures the system exhibits non - Fermi liquid behavior characterized by power - law dependences of these amounts on T.I. INTRODUCTORY REMARkSThe Kondo necklace model 1, 2 describes a chain of magnetic impurities coupled using antiferromagnetic exchange interactions J.It has been introduced originally for describing the physics of heavy fermion compounds 3 but it also appears naturally in other contexts 4 - 7.In the present work we consider the case when the coupling constant J exceeds some critical valueJc = 2t / U where t denotes hopping amplitude between neighboring sites and U stands for local Coulomb repulsion energy 8 - 10.At zero temperature the ground state of the complex corresponds then to a ferromagnetically ordered state 11 - 13 while at finite temperatures one expects a continuous quantum phase transition into a paramagnetic state 14 - 17.This transition occurs due to strong spin fluctuations 18 - 20 and belongs therefore to the same universality class as the Heisenberg chain 21 - 23.However there are important disagreements between both models 24 - 26 : First, the Kondo necklace includes two types of excitations - spinons and holons 27 - 29 - while the Heisenberg chain only consists of spin - one / 2 particles.Second, the Kondo necklaces contain additional degrees of liberty associated with charge carriers 30 - 32.These features lead to new phenomena not observed in the Heisenberg chain 33 - 36.For example, the Kondo necklacelike systems may exhibit unconventional superconducting states 37 - 39."
    },
    {
        "original_text": "The discovery that the universe is expanding at an accelerating rate has led to intense interest in dark energy as well as new ideas about fundamental physics. This talk will review some recent results on these topics including constraints on models for cosmic acceleration using supernovae data, measurements of the Hubble constant with Type Ia supernovae, and tests of general relativity using gravitational lensing statistics. The talk will also discuss how future surveys such as LSST can be used to further our understanding of dark energy and fundamental physics. I will conclude by discussing my own work on testing gravity theories beyond Einstein's theory using weak lensing observations. Keywords: Cosmology, Dark Energy, General Relativity, Weak Lensing, Supernovae, Gravitational Waves, Cosmic Microwave Background. Speaker: Adam Riess (Princeton University) Date: February 18, 2007 Time: 4:30pm - 5:15pm Location: Room B",
        "watermark_text": "The discovery that the universe is expanding at an accelerating rate has led to intense interest in dark energy as well as new ideas about fundamental physics.This talk will review some recent results on these topics including constraints on models for cosmic acceleration using supernovae data, measurements of the Hubble constant with Type Ia supernovae, and tests of general relativity using gravitational lensing statistics.The talk will also discuss how upcoming surveys such as LSST can be used to further our understanding of dark energy and fundamental physics.I will conclude by discussing my own work on testing gravity theories beyond Einstein ' s work using weak lensing observations.Keywords : Cosmology, Dark Energy, General Relativity, Weak Lensing, Supernovae, Gravitational Waves, Cosmic Microwave Background.Speaker : Adam Riess ( Princeton University )Date : February 18, 2007 Time : 4 : 30pm - 5 : 15pm Location : Room B"
    },
    {
        "original_text": "We present new observations and analysis of the neutral hydrogen (HI) disks surrounding isolated galaxies, using data obtained with the Very Large Array (VLA). We have observed 12 nearby galaxies at 21 cm wavelength to determine their total HI mass and distribution within the optical disk. The sample includes both late-type spirals and dwarf irregulars. Our results show that all but one galaxy has an extended HI halo beyond its optical radius; this is true even for the most gas-rich systems such as NGC 4254 and NGC 5253. In addition, we find evidence for significant amounts of atomic gas outside our detection limits which may be associated with tidal features or other interactions between these galaxies and neighboring companions. These findings are consistent with previous studies showing that many isolated spiral galaxies contain large quantities of cold interstellar medium distributed over several kiloparsecs. \n \n Keywords: Atomic Hydrogen, Galaxy Evolution, Spiral Structure",
        "watermark_text": "We present fresh observations and analysis of the neutral hydrogen ( HI ) disks surrounding isolated galaxies, using data obtained with the Very Large Array ( VLA ).We have observed 12 nearby galaxies at 21 centimeters wavelength to decide their total HI mass and distribution within the optical disc.The sample includes both late - type spirals and dwarf irregulars.Our results show that all but one galaxy has an extended HI halo beyond its optical radius ; this is true even for the most gas - rich systems such as NGC 4254 and NGC 5253.In addition, we discover evidence for significant amounts of atomic gas beyond our detector limits which may be associated with tidal features or other interactions between these galaxies and neighboring companions.These findings are consistent with previous studies showing that many isolated spiral galaxies contain large quantities of cold interstellar medium distributed over many kiloparsecs.Keywords : Atomic Hydrogen, Galaxy Evolution, Spiral Structure"
    },
    {
        "original_text": "The author describes how he has used the concept of \"errors in thinking\" to help students understand and learn about science, particularly physics.  He explains that this approach is based on his own experience as an undergraduate student at Harvard University where he was taught by Professor Richard Feynman.   The author suggests that it may be useful for teachers to use similar approaches when teaching other subjects such as mathematics or chemistry. The author also discusses some of the difficulties associated with using this method. This article appeared originally in Physics Today (Vol. 51 No. 1 January 1997). It can be downloaded from: http://arxiv.org/abs/physics/9701001v1.pdf  In order to teach physics effectively, one must first have a clear understanding of what constitutes good thinking within the subject area. Unfortunately, many people who are not trained scientists do not think like physicists; they tend to make mistakes which often lead them astray. For example, if asked whether two objects will fall together towards earth's center of mass, most people would say no because they believe that gravity acts only between bodies that touch each other. However, according to Newtonian mechanics, gravitational attraction does act upon all matter regardless of its position relative to another body. If you were to ask someone else why two objects don't fall together, she might answer that they are connected by a string so their weight cancels out. Although this explanation seems reasonable, it fails to take into account the fact that the force exerted by the string is negligible compared to the forces acting upon both objects individually. As a result, her reasoning is flawed.",
        "watermark_text": "The author describes how he has utilized the concept of \" errors in thoughts \" to help students comprehend and study about science, particularly physics.He explains that this approach is based on his own experience as an undergraduate student at Harvard University where he was taught by Prof Richard Feynman.The author suggests that it may be useful for teachers to use similar approaches when teaching other topics such as math or chemistry.The author also discusses some of the difficulties associated with utilizing this technique.This article appeared originally in Physics Today ( Vol. 51No. 1 January 1997 ).It can be downloaded from : http : / / arxiv. org / abs / physics / 9701001v1. pdf In order to teach physics effectively, one must first have a clear understanding of what constitutes good thinking within the subject area.Unfortunately, many people who are not trained science do not think like physicists ; they tend to make mistakes which often lead them astray.For example, if asked whether two objects will fall together towards earth ' s centre of mass, most people would say no because they believe that gravity acts only between bodies that touch each other.However, according to Newtonian mechanics, gravitational attraction does act upon all matter regardless of its location relative to another body.If you were to ask someone else why two objects don ' t fall together, she might answer that they are connected by a string so their weight cancels out.Although this explanation seems reasonable, it fails to take into account the fact that the force exerted by the string is negligible compared to the forces acting upon both objects individually.As a result, her reasoning is flawed."
    },
    {
        "original_text": "The distance geometry problem is the following: given n points in space, find their coordinates such that they are as close to each other as possible while respecting some constraints on distances between pairs of points.  In this work we consider an application of the distance geometry problem to music analysis and propose a novel method for automatic transcription of musical scores into symbolic representations based on the concept of pitch class profiles (PCP). The proposed approach allows us to recover the underlying harmonic structure of polyphonic music by solving a system of quadratic equations with linear equality constraints using convex optimization techniques. We demonstrate our algorithm's performance on several classical piano pieces. 1 Introduction\n\nMusic Analysis\nAutomatic transcription of musical scores has been one of the most challenging problems in computer science over the past decades. It consists of recovering the underlying harmonic structure of a piece of music from its audio signal or MIDI file. This task can be divided into two main subtasks:  detection of note onset times; estimation of pitches at detected notes' locations. Note onset time detection is usually performed by applying various heuristics to the raw audio data [22, 23] . Once the note onset times have been determined, the next step is to estimate the pitches corresponding to these events. There exist many different approaches to solve this problem ranging from simple template matching methods to more sophisticated statistical models [7, 8, 10, 11, 13, 14, 16, 17, 19-21, 24-26] .\nIn this work we focus on the second part of the problem -estimation of pitches-which is known as \"pitch estimation\" or \"pitch tracking\". Pitch tracking algorithms try to assign a pitch value to every detected event in order to obtain a sequence of pitch values which correspond to the original score. A common way to represent pitches is through so-called pitch-class profiles (PCPs) [6, 12, 15, 18, 27] , where each entry corresponds to the number of occurrences of a particular pitch within a certain window around the current time instant. For example, Figure 1 shows a typical PCP obtained from a single-note mel",
        "watermark_text": "The distance geometry problem is the following : given n points in space, find their coordinates such that they are as close to each other as able while respecting some constraints on distances between pairs of points.In this work we consider an application of the distance geometry problem to music analysis and propose a new method for automatic transcription of musical scores into symbolic representations based on the concept of pitch class profiles ( PCP ).The proposed approach permits us to retrieve the embedded harmonic structure of polyphonic music by solving a system of quadratic equations with linear equality constraints using convex optimization techniques.We demonstrate our algorithm ' s performance on several classical piano works.1 Introduction Music Analysis Automatic transcription of musical scores has been one of the most difficult problems in computer scientist over the past decades.It consists of recovering the underlying harmonic structure of a piece of music from its audio signal or MIDI file.This task can be divided into 2 main subtasks : detection of note onset times ; estimation of pitches at detected notes ' localities.Note onset time detection is usually performed by applying various heuristics to the raw audio data[ 22, 23 ].Once the note onset times have been determined, the next step is to estimate the pitches associated to these events.There exist many different approaches to solve this problem ranging from simple template matching methods to more sophisticated statistical models[ 7, 8, 10, 11, 13, 14, 16, 17, 19 - 21, 24 - 26 ].In this work we focus on the second portion of the issue - estimation of pitches - which is known as \" pitch estimation \" or \" pitch tracking \".Pitch tracking algorithms try to assign a pitch value to every detected event in order to obtain a sequence of pitch values which correspond to the original score.A common way to represent pitches is through so - called pitch - class profiles ( PCPs )[ 6, 12, 15, 18, 27 ], where each entry corresponds to the number of occurrences of a particular pitch inside a certain window around the present time instant.For example, Figure 1 shows a common PCP obtained from a single - note mel"
    },
    {
        "original_text": "The effect of intermolecular interactions on the elastic properties of bottlebrush polymer networks is investigated using molecular dynamics simulations and experimental measurements. The results show that the network becomes softer with increasing density, which can be explained in terms of an increase in the number of entanglements between neighboring chains. This softening behavior is also observed experimentally for bottlebrush polyurethane networks prepared at different densities. It is found that the simulated stress-strain curves are well described by the Gent model, where the effective spring constant decreases as the density increases. These findings suggest that the mechanical properties of bottlebrush polymer gels can be tuned by changing their density. \n \n Soft materials such as rubbers have been widely used in many applications including tires, seals, adhesives, and biomaterials because they exhibit unique physical characteristics such as high extensibility and low modulus [1–3]. In particular, bottlebrush polymers consisting of densely grafted side chains have attracted considerable attention due to their outstanding mechanical properties [4–6]. For example, it has recently been reported that bottlebrush poly(ether urethane)s (PEUs), synthesized via ring-opening metathesis polymerization [7, 8], possess higher tensile strength than conventional PEU elastomers [9]. However, despite these advantages, there remain some challenges associated with the use of bottlebrush polymers in practical applications. One of them is how to control the mechanical properties of bottle brushes since the macroscopic properties depend strongly on the microstructure [10, 11]. Therefore, understanding the relationship between structure and property is important for designing new types of bottlebrush-based materials. \nIn this study, we investigate the influence of chain density on the mechanical properties of bottle-brush polyurethanes (BPUs). We find that BPUs become softer when the density increases. To understand this phenomenon, we perform molecular dynamics (MD) simulations based on coarse-grained models [12]. Our simulation results reveal that the network becomes sof...",
        "watermark_text": "The effect of intermolecular interactions on the elastic properties of bottlebrush polymer networks is investigated utilizing molecular dynamics simulations and experimental measurements.The results show that the network gets softer with increasing density, which can be explained in terms of an increase in the number of entanglements between neighboring chains.This softening behavior is also observed experimentally for bottlebrush polyurethane networks prepared at different densities.It is found that the simulated stress - strain curves are well described by the Gent model, where the effective spring constant drops as the density increases.These findings suggest that the mechanical properties of bottlebrush polymer gels can be tuned by changing their density.Soft materials such as rubbers have been widely utilized in many applications including tires, seals, adhesives, and biologicalmaterials because they exhibit unique physical characteristics such as high extensibility and low modulus [ 1 – 3 ].In particular, bottlebrush polymers consisting of densely grafted side chains have attracted considerable attention due to their outstanding mechanical properties [ 4 – 6 ].For example, it has recently been reported that bottlebrush poly ( ether urethane ) s ( PEUs ), synthesis via ring - opening metathesis polymerization [ 7, 8 ], possess higher tensile strength than conventional PEU elastomers [ 9 ].However, despite these advantages, there remain some difficulties associated with the use of bottlebrush polymers in practical applications.One of them is how to control the mechanical properties of bottle brushes since the macroscopic properties depend strongly on the microstructure [ 10, 11 ].Therefore, understanding the relationship between structure and property is important for designing new types of bottlebrush - based materials.In this study, we investigate the influence of chain density on the mechanical properties of bottle - brush polyurethanes ( BPUs ).We find that BPUs become softer when the density increases.To understand this phenomenon, we perform molecule dynamics ( MD ) simulations based on coarse - grained models [ 12 ].Our simulation results reveal that the network becomes sof."
    },
    {
        "original_text": "BaFeO3 is one of the most promising cathode materials for solid oxide fuel cells (SOFCs). In this work, we have performed first-principles density functional theory calculations to investigate its electronic and magnetic properties in detail. We find that it has a metallic ground state with a large spin polarization at the Fermi level. The calculated band gap between the valence bands and conduction bands is 0.2 eV which agrees well with previous experimental results. Our calculation shows that there are two Fe-3d orbitals crossing the Fermi level, indicating that both Fe3+ ions and Fe4+ ions exist in the compound simultaneously. This result can be explained by the fact that the crystal field splitting energy is much smaller than the electron-electron interaction energies. Furthermore, our calculation indicates that the ferromagnetic ordering is mainly due to superexchange interactions mediated through oxygen atoms.  Finally, we also calculate the phonon dispersion relations along high symmetry lines within the framework of density functional perturbation theory.",
        "watermark_text": "BaFeO3 is one of the most promising cathode materials for solid oxide fuel cells ( SOFCs ).In this work, we have performed first - principles density functional theoretical calculations to probe its electronic and magnetic properties in detail.We find that it has a metallic ground state with a large spin polarization at the Fermi level.The calculated band gap between the valence bands and conduction bands is 0. 2 eV which agrees well with previous experimental findings.Our calculation shows that there are two Fe - 3d orbitals crossing the Fermi level, indicating that both Fe3 + ions and Fe4 + ions exist in the compound simultaneously.This result can be explained by the fact that the crystal field splitting energy is much smaller than the electron - electron interaction energies.Furthermore, our calculation indicates that the ferromagnetic ordering is mainly due to superexchange interactions mediated through oxygen atoms.Finally, we also calculate the phonon dispersion relations along high symmetrical lines within the framework of density functional perturbation theory."
    },
    {
        "original_text": "The Gamma Ray Burst (GRB) 031203 was detected by several satellites on December 3rd, 2003 at 07:47 UT and lasted about 20 s. The burst had an extremely bright optical counterpart with R ~ 12 mag., which faded rapidly to V ~ 21 mag. within one day after the burst. This is among the most energetic events ever observed in the universe. We present here our analysis of this event based on data obtained mainly by Swift satellite. Our results show that the prompt emission can be well described as a single-peaked pulse lasting for about 10 seconds followed by a power-law decaying tail extending up to 100 seconds. The X-ray light curve shows two flares peaking around 5 and 15 seconds respectively following the main peak. These features are similar to those seen in other GRBs but their relative strength is much stronger than usual. In addition we find evidence for spectral evolution during the prompt phase.",
        "watermark_text": "The Gamma Ray Burst ( GRB ) 031203 was detected by several satellites on December 3rd, 2003 at 07 : 47 UT and lasted about 20 s.The burst had an incredibly bright optical counterpart with R ~ 12 mag., which faded rapidly to V ~ 21 mag.within one day after the burst.This is among the most energetic events ever observed in the universe.We present here our analysis of this event based on data obtained mainly by Swift satellite.Our results show that the prompt emission can be well described as a one - peaked pulse lasting for about ten seconds followed by a power - law decaying tail extending up to 100 seconds.The X - ray light curve shows two flares peaking near 5 and 15 seconds respectively following the main peak.These features are similar to those seen in other GRBs but their compared strength is much stronger than usual.In addition we find evidence for spectral evolution during the prompt stage."
    },
    {
        "original_text": "In this work, we study the throughput capacity region for multi-hop wireless networks with multiple transmitters and one receiver (MISO-MHWN). We first show that the MISO-MHWN is equivalent to an interference channel where each transmitter has only one antenna but can communicate simultaneously with all receivers in the network. Then, by using the concept of degrees-of-freedom (DoF), which characterizes how many parallel data streams are supported at high signal-to-noise ratio (SNR) regime, we derive outer bounds on the DoF region of the MISO-MHWNS. Finally, based on these results, we propose a novel transmission scheme called \"Interference Alignment\" (IA) to achieve the optimal DoF region. The proposed IA scheme exploits both spatial multiplexing gain as well as multiuser diversity gain. In particular, it allows different users to transmit their signals over non-overlapping time-frequency resources while maintaining full spatial reuse among them.",
        "watermark_text": "In this work, we study the throughput capacity region for multi - hop wireless networks with multiple transmitters and one receiver ( MISO - MHWN ).We first show that the MISO - MHWN is equivalent to an interfering channel where each transmit has only 1 antenna but can communicate simultaneously with all receivers in the network.Then, by using the concept of degrees - of - freedom ( DoF ), which characterizes how many parallel data streams are supported at high signal - to - noise ratio ( SNR ) regime, we derive outer bounds on the DoF region of the MISO - MHWNS.Finally, based on these results, we propose a novel transmission scheme called \" Interference Alignment \" ( IA ) to attain the optimal DoF area.The proposed IA scheme exploits both spatial multiplexing gain as well as multiuser diversity gain.In particular, it permits different users to transmit their signals over non - overlapping time - frequency facilities while maintaining full spatial reuse among them."
    },
    {
        "original_text": "Parametric Perturbation Theory (PPT) is an extension to the standard perturbative approach in quantum field theories, which allows for systematically including higher-order corrections into Feynman diagrams and thus improving their accuracy.  In this talk I will present PPT as well as its application to QCD processes at hadron colliders such as Drell-Yan production or Higgs boson decay into bottom quarks. The results are obtained within the framework of Soft-Collinear Effective Field Theory (SCET). This talk was given by Jens Wackeroth on behalf of the CMS collaboration during the LHCP2018 conference held in Paris between June 24th - 28th 2018. It has been recorded with permission. For more information about the speaker please see his profile page here . \nJens Wackeroth is a postdoctoral researcher working on soft-collinear effective theory and parametric perturbation theory at CERN.",
        "watermark_text": "Parametric Perturbation Theory ( PPT ) is an extension to the standard perturbative approach in quantum field theories, which allows for systematically including higher - order corrections into Feynman diagrams and thus improving their accuracy.In this talk I will present PPT as well as its application to QCD processes at hadron colliders such as Drell - Yan production or Higgs boson decomposition into bottom quarks.The results are obtained within the framework of Soft - Collinear Effective Field Theory ( SCET ).This talk was given by Jens Wackeroth on behalf of the CMS cooperation during the LHCP2018 conference held in Paris between June 24th - 28 2018.It has been recorded with permission.For more information about the speaker please see his profile page here.Jens Wackeroth is a postdoctoral researcher working on soft - collinear effective theory and parametric perturbation theoretical at CERN."
    },
    {
        "original_text": "We consider the problem of estimating an unknown function f from noisy measurements y = Af + w, where A is a linear operator and w is white noise with known covariance matrix Cw.  We assume that the operator A has been discretized on some grid (e.g., by using finite differences or spectral methods) so that it can be represented as a large matrix.  The goal is to find an estimatef such that Ef − f  2 is minimized subject to certain constraints on the smoothness off . \nIn this work we propose new numerical techniques based on needlets which are able to efficiently solve these constrained optimization problems.  In particular, our approach allows us to obtain accurate estimates even when the number N of available observations is much smaller than the dimension M of the space spanned by the columns of A. \nThe proposed method relies on two main ingredients:  First, we use a sparse representation of functions in terms of needlets.  Second, we develop efficient iterative algorithms for solving large-scale convex optimization problems involving sparsity-promoting regularizers.  These algorithms combine ideas from compressed sensing theory and recent results about the convergence rate of alternating direction method of multipliers (ADMM).",
        "watermark_text": "We consider the problem of estimating an unknown function f from noisy measurements y = Af + w, where A is a linear operator and w is white noise with known covariance matrix Cw.We assume that the operator A has been discretized on some grid ( e. g., by utilizing finite differences or spectral methods ) so that it can be represented as a large matrix.The goal is to find an estimatef such that Ef − f 2 is minimized subject to certain constraints on the smoothness off.In this work we propose new numerical techniques based on needlets which are able to efficiently solve these constrained optimization problems.In particular, our approach allows us to get accurate estimates also when the number N of available observations is much smaller than the dimension M of the space spanned by the columns of A. The proposed method relies on two main ingredients :First, we use a sparse representation of functions in terms of needlets.Second, we develop efficient iterative algorithms for solving large - scale convex optimization problems involving sparsity - promoting regularizers.These algorithms combine ideas from compressed sensing theory and recent results about the convergence rate of alternating direction methodology of multipliers ( ADMM )."
    },
    {
        "original_text": "In this note, we present an elementary proof for the following theorem due to Pappus:\nTheorem 1 (Pappus' theorem). Let $ABC$ be any triangle and let $D$ be its incenter. Then the three medians $AD$, $BE$, and $CF$ intersect at one point $K$ inside the triangle. \nProof. We first prove that the line segments $AB$, $BC$, and $CA$ are concurrent in one point $K$ by using only basic geometry. The idea is as follows. Consider the circle $C_1$ centered at $A$ with radius $AC$. Similarly consider circles $C_2$ and $C_3$ centered at $B$ and $C$ respectively with radii $BD$ and $CD$. Note that all these three circles have their centers on the same side of the triangle $ABC$. Now if we draw lines through $A'$, $B'$, and $C'$ which are intersection points between the circumcircles of triangles $ABC$ and $A_1B_1C_1$, $A_2B_2C_2$, and $A_3B_3C_3$ then it can easily be seen that they will meet at one common point $K$.",
        "watermark_text": "In this note, we present an elementary proof for the following theorem due to Pappus :Theorem 1 ( Pappus ' theorem ).Let $ ABC $ be any triangle and let $ D $ be its incenter.Then the three medians $ AD $, $ BE $, and $ CF $ intersect at one point $ K $ inside the triangular.Proof.We first prove that the line segments $ AB $, $ BC $, and $ CA $ are concurrent in 1 point $ K $ by using only basic geometry.The idea is as follows.Consider the circle $ C _ 1 $ centered at $ A $ with radius $ AC $. Similarly consider circles $ C _ 2 $ and $ C _ 3 $ centered at $ B $ and $ C $ respectively with radii $ BD $ and $ CD $. Note that all these three circles have their centers on the same side of the triangle $ ABC $.Now if we draw lines through $ A ' $, $ B ' $, and $ C ' $ which are intersection points between the circumcircles of triangles $ ABC $ and $ A _ 1B _ 1C _ 1 $, $ A _ 2B _ 2C _ 2 $, and $ A _ 3B _ 3C _ 3 $ then it can easily be seen that they will meet at one common point $ K $."
    },
    {
        "original_text": "We propose an approach to causal inference for longitudinal data based on the use of marginal structural models (MSMs) that are restricted by past treatment and covariate histories, which we refer to as \"history-restricted\" MSMs.  We show how these models can be used to estimate average effects over time periods during which treatments were not administered or outcomes were not observed. Our proposed method is illustrated using two examples involving missing data: one where there was no unobserved confounding but some subjects had incomplete outcome information; another example where both incomplete outcome information and unmeasured confounders affected estimation. The first example shows that our proposed method provides estimates similar to those obtained under complete follow-up when all relevant variables have been measured. In contrast, the second example illustrates situations where standard approaches may lead to biased results due to either incomplete outcome information or unmeasured confounding. Finally, we provide simulation evidence showing that our proposed method performs well even if the model assumptions underlying it do not hold exactly. \nKeywords: Marginal Structural Models, Longitudinal Data Analysis",
        "watermark_text": "We propose an approach to causal inference for longitudinal data based on the use of marginal structural models ( MSMs ) that are restricted by past treatment and covariate histories, which we refer to as \" history - restricted \" MSMs.We show how these models can be utilized to estimate average effects over time periods during which treatments were not administered or results were not observed.Our proposed method is illustrated utilizing two examples involving missing data : one where there was no unobserved confounding but some subjects had incomplete outcome information ; another example where both incomplete outcome information and unmeasured confounders affected estimation.The first example shows that our proposed methodology provides estimates similarly to those obtained under complete follow - up when all relevant variables have been measured.In contrast, the second example illustrates situations where standard approaches may lead to biased effects due to either incomplete outcome information or unmeasured confounding.Finally, we provide simulation evidence showing that our proposed method performs well even if the model assumptions underlying it do not hold exactly.Keywords : Marginal Structural Models, Longitudinal Data Analysis"
    },
    {
        "original_text": "We study the quantum Hall effect (QHE) and its interplay with magnetism in monolayer graphene by using an effective low-energy model that takes into account both electron-electron interactions and disorder effects. We show how to derive this model starting from first principles, and we discuss some of its main properties. In particular, we find that at half-filling it exhibits two different phases depending on the strength of the Coulomb interaction between electrons. For weak coupling these are separated by a phase transition driven by spontaneous breaking of time-reversal symmetry; for strong coupling they correspond respectively to a conventional QHE state and to a novel fractionalized topological insulator characterized by chiral edge states. The latter is shown to be equivalent to a spin-1/2 Heisenberg antiferromagnet on the honeycomb lattice, which can thus be described within the framework of the so-called SU(4) bosonic representation.",
        "watermark_text": "We study the quantum Hall effect ( QHE ) and its interplay with magnetism in monolayer graphene by using an effective low - energy model that takes into account both electron - electron interactions and disorder effects.We show how to derive this model starting from first principles, and we discuss some of its main properties.In particular, we find that at half - filling it exhibits two different phases depending on the strength of the Coulomb interface between electrons.For weak coupling these are separated by a phase transition driven by spontaneous breakdown of time - reversal symmetry ; for strong coupling they correspond respectively to a conventional QHE state and to a novel fractionalized topological insulator characterized by chiral edge states.The latter is shown to be equivalent to a spin - 1 / 2 Heisenberg antiferromagnet on the honeycomb lattice, which can thus be described within the framework of the so - called SU ( four ) bosonic representation."
    },
    {
        "original_text": "We study the vibrational density of states (VDOS) of glassy materials using molecular dynamics simulations with anharmonic interactions between particles. We show that the VDOS can be decomposed into three main contributions: one at low frequencies corresponding to acoustic phonons; another contribution centered around the Debye frequency which is associated with optical phonons; and finally a third contribution located at high frequencies whose origin lies on the presence of unstable modes. The latter are responsible for the appearance of the so-called boson peak in the VDOS. In addition we find that these unstable modes have a strong tendency to form clusters or groups of correlated particles. Finally, by analyzing the spatial distribution of the unstable modes it becomes evident that they tend to localize near regions where there exist structural defects such as icosahedral-like motifs. This localization effect leads us to propose a simple model based on the existence of two different types of sites within the materials: stable ones characterized by their ability to support vibrations over large energy ranges, while unstable sites only allow small-amplitude oscillations.",
        "watermark_text": "We study the vibrational density of states ( VDOS ) of glassy materials using molecular dynamics simulations with anharmonic interactions between particles.We show that the VDOS can be decomposed into three main contributors : one at low frequencies corresponding to acoustic phonons ; another contribution centered around the Debye resolution which is associated with optical phonons ; and finally a third contribution located at high frequencies whose origin lies on the presence of unstable modes.The latter are responsible for the appearance of the so - called boson peak in the VDOS.In addition we find that these unstable modes have a strong tendency to form clusters or groups of correlated particles.Finally, by analyzing the spatial distribution of the unstable modes it becomes evident that they tend to localize near regions where there occur structural defects such as icosahedral - like motifs.This localization effect leads us to propose a simple model based on the existence of 2 different types of websites within the materials : stable ones characterized by their ability to support vibrations over large energy ranges, while unstable sites only allow small - amplitude oscillations."
    },
    {
        "original_text": "We report on the magnetic properties of Fe nanodots with diameters ranging between 10 and 100 nm, prepared by pulsed laser deposition (PLD) onto Si(100). The dots are characterized by X-ray photoelectron spectroscopy (XPS), transmission electron microscopy (TEM), scanning tunneling microscopy/spectroscopy (STM/STS), and vibrating sample magnetometry (VSM).\nThe XPS data show that the dots have an oxidized surface layer consisting mainly of iron oxide species such as FeO x , Fe 3 O 4 , or Fe 2 O 3 . This is confirmed by STM measurements which reveal a corrugated structure for all sizes investigated here. In addition to this common feature we find two different types of structures depending on dot size. For small dots (10-20 nm in diameter) we observe a dome-like shape while larger dots (40-60 nm in diameter) exhibit a flat topography. Both shapes can be explained by assuming either a core-shell model or a porous structure. We also found that the magnetic behavior depends strongly on the dot size. While large dots behave like bulk material they show superparamagnetism at room temperature when their diameter decreases below 40 nm.",
        "watermark_text": "We report on the magnetic properties of Fe nanodots with diameters ranging between 10 and 100 nm, prepared by pulsed laser deposition ( PLD ) upon Si ( 100 ).The dots are characterized by X - ray photoelectron spectroscopy ( XPS ), transmitted electron microscopy ( TEM ), scanning tunneling microscopy / spectroscopy ( STM / STS ), and vibrating sample magnetometry ( VSM ).The XPS data show that the dots have an oxidized surface layer consisting mainly of iron oxide species such as FeO x, Fe 3 O 4, or Fe 2 O 3.This is confirmed by STM measurements which reveal a corrugated structure for all sizes investigated here.In addition to this common feature we discover two different types of structures depending on dot size.For small dots ( 10 - 20 nm in diameter ) we observe a dome - shaped shape while larger dots ( 40 - 60 nm in diameter ) exhibit a flat topography.Both shapes can be explained by assuming either a core - shell model or a porous structure.We also found that the magnetic behavior depends strongly on the dot size.While large dots behave like bulk material they show superparamagnetism at room temperature when their diameter decreases below 40 nm."
    },
    {
        "original_text": "In this work, we study the distribution of the size of largest planar matching (LPM) and largest planar subgraph (LPS) in random bipartite graphs with n vertices on each side. We show that for any fixed integer k > 0, there exists an absolute constant ck such that if G is a random bipartite graph with n vertices on each part satisfying cn < p = e(G)/n < 1 − cn then LPM(G) has at least k components w.h.p.. Moreover, when p = 1/2 + o(1), we prove that LPS(G) contains a cycle of length Ω(log log n). These results are proved by using the second moment method together with some new techniques developed here to deal with the dependencies between edges. As applications, these results imply that both LPM(G) and LPS(G) have many small cycles under certain conditions.",
        "watermark_text": "In this work, we study the distribution of the size of biggest planar matching ( LPM ) and largest planar subgraph ( LPS ) in random bipartite graphs with n vertices on each side.We show that for any fixed integer k > 0, there exists an absolute constant ck such that if G is a random bipartite graph with n vertices on each part satisfying cn < p= e ( G ) / n < 1− cn then LPM ( G ) has at least k components w. h. p.Moreover, when p = 1 / 2 + o ( 1 ), we prove that LPS ( G ) possesses a cycle of length [UNK] ( log log n ).These results are proved by using the second moment method together with some new techniques developed here to cope with the dependencies between edges.As applications, these results imply that both LPM ( G ) and LPS ( G ) have many small cycles under certain conditions."
    },
    {
        "original_text": "We report the detection of periodic radial velocity variations in the spectrum of the K2V dwarf GJ 436, which are consistent with those expected for an orbiting planet. The period is 3.2 days and the semi-amplitude is about 30 m/sec. We also find evidence that this signal may be modulated on timescales longer than one year by another component whose mass we estimate to be at least 0.1 M⊕. This system has been extensively studied over many years as it lies close (5 pc) to our Sun but was not previously known to host any planets. It is therefore particularly interesting because its properties can now be compared directly with theoretical models of formation and evolution. \n \n Keywords: Planetary systems - Formation, Solar System\n\nIntroduction\n\nThe discovery of extrasolar planets has led to new insights into how planetary systems form and evolve. However, most exoplanets have been found using indirect techniques such as transit photometry or Doppler spectroscopy. These methods provide information only about the orbital parameters of the planet(s), while direct imaging provides additional constraints on their physical characteristics. In particular, high contrast imaging allows us to measure the masses of companions down to very low levels of flux ratio relative to their parent stars.\n\nIn recent years there has been significant progress towards achieving high-contrast imaging capabilities required to detect Earth-like planets around nearby stars. For example, the Gemini Planet Imager (GPI; Macintosh et al., 2014) , SPHERE (Beuzit et al., 2008) and SCExAO (Jovanovic et al., 2015) instruments will soon begin operation on 8-10 m class telescopes. These facilities offer unprecedented sensitivity and angular resolution, allowing them to probe regions closer to the central star where terrestrial planets are more likely to exist. \nHowever, these observatories operate under different conditions and use different technologies so it remains unclear what performance they will achieve once commissioned.",
        "watermark_text": "We report the detection of periodic radial velocity variations in the spectrum of the K2V dwarf GJ 436, which are consistent with those expected for an orbiting planet.The period is 3. 2 days and the semi - amplitude is about 30 m / sec.We also find evidence that this signal may be modulated on timescales longer than 1 year by others component whose mass we estimate to be at least 0. 1 M⊕.This system has been extensively studied over many years as it lay close ( 5 pc ) to our Sun but was not previously known to host any planets.It is therefore particularly interesting because its properties can now be compared directly with theory models of formation and evolution.Keywords : Planetary systems - Formation, Solar System Introduction The discovery of extrasolar planets has led to new insights into how planet systems form and evolve.However, most exoplanets have been found using indirect techniques such as transit photometry or Doppler spectroscopy.These methods provide information only about the orbital parameters of the planetary ( s ), while direct imaging provides additional constraints on their physical characteristics.In particular, high contrast imaging allows us to measure the masses of companions down to very little levels of flux ratio relative to their parent stars.In recent years there has been significant progress towards achieving highly - contrast imaging capabilities required to detect Earth - like planets around nearby stars.For example, the Gemini Planet Imager ( GPI ; Macintosh et al., 2014 ), SPHERE ( Beuzit et al., 2008 ) and SCExAO ( Jovanovic et al., 2015 ) instruments will soon begin operation on 8 - ten m class telescopes.These facilities offer unprecedented sensitivity and angular resolution, allowing them to probe regions closer to the central star where terrestrial planets are more likely to exist.However, these observatories operate under different circumstances and use different technologies so it remains unclear what performance they will achieve once commissioned."
    },
    {
        "original_text": "We present an analysis of the ages derived by applying the gyrochronological method to a sample of open clusters with known ages (from literature) in order to assess its reliability as well as possible systematics associated with it. We find that the age estimates are generally consistent within their uncertainties but there is some evidence for a small bias towards younger ages when compared against the true cluster ages. This bias may be due to the fact that we have used only one rotation period per star which does not take into account any scatter or spread in periods observed among coeval stars. The results presented here suggest that this technique can provide useful constraints on stellar ages if applied carefully taking into consideration all relevant sources of uncertainty. Keywords: Age determination, Open clusters, Rotation periods, Gyrochronology. 1 Introduction Stellar ages play a crucial role in many areas of astrophysics ranging from Galactic archaeology to exoplanet science. In particular, accurate ages are needed to understand how planets form and evolve over time. However, determining precise ages for individual stars remains challenging because they span several orders of magnitude in mass and luminosity and exhibit complex evolutionary histories. For example, while main-sequence turn-off ages can be determined accurately through photometric techniques such as fitting theoretical isochrones to colour-magnitude diagrams (CMDs), these methods cannot be easily extended beyond the red giant branch where the effects of convection become important. Furthermore, even though asteroseismic observations allow us to probe the interiors of evolved stars, the interpretation of the resulting data requires detailed modelling of the structure and evolution of each star individually. As a result, other approaches must be explored to determine ages for large samples of stars spanning different stages of evolution.\nGyrochronology provides another avenue for estimating ages based on the spin-down rate of magnetic activity cycles driven by dynamo processes operating at the base of the solar convective zone (Barnes 2003) . It has been shown that the Rossby number R o , defined as the ratio between the rotation period P rot and the convective overturning timescale",
        "watermark_text": "We present an analysis of the years derived by applying the gyrochronological method to a sample of open clusters with established ages ( from literature ) in order to assess its reliability as well as possible systematics associated with it.We find that the age estimates are generally constant within their uncertainties but there is some evidence for a small bias towards younger ages when compared against the truth cluster ages.This bias may be due to the fact that we have used only 1 rotation period per star which does not take into consider any scatter or spread in times observed among coeval stars.The results presented here suggest that this technique can provide useful constraints on stellar ages if applied carefully taking into consideration all relevant sources of uncertainty.Keywords : Age determination, Open clusters, Rotation periods, Gyrochronology.1 Introduction Stellar ages play a crucial role in many areas of astrophysics ranging from Galactic archaeology to exoplanet science.In particular, accurate ages are needed to comprehend how planets form and evolve over time.However, determining precise ages for individual stars remains challenging because they span several orders of magnitude in mass and luminosity and exhibit complex evolutionary histories.For example, while main - sequence turn - off ages can be determined accurately through photometric techniques such as fitting theoretical isochrones to color - magnitude diagrams ( CMDs ), these methods cannot be easily extended beyond the red giant branch where the effects of convection become important.Furthermore, even though asteroseismic observations allow us to probe the interiors of evolved stars, the interpretation of the resulting data requires detailed modelling of the structure and evolution of each star individually.As a result, other approaches must be explored to determine ages for large samples of stars spanning different phases of evolution.Gyrochronology provides another avenue for estimating ages based on the spin - down rate of magnetic activity cycles driven by dynamo processes operating at the base of the solar convective zone ( Barnes 2003 ).It has been shown that the Rossby number R o, defined as the ratio between the rotation period P rot and the convective overturning timescale"
    },
    {
        "original_text": "The mass spectrum and decay properties of the scalar mesons are studied by using the QCD sum rule method with the light-cone distribution amplitudes (LCDAs). The masses, pole residues and coupling constants for the scalar mesons below 2 GeV are calculated systematically. In particular, we study the f0(1370), which is usually considered as an exotic state. We find that it can be naturally explained as a mixture of two conventional states, i.e., the lowest lying scalar glueball and the scalar quarkonium. Our results show that its mixing angle θ = −20° ± 5° , where the first error comes from the uncertainty of the LQCD data used to determine the parameters of LCDAs, while the second one arises from the uncertainties of the input parameters such as Borel parameter M2B and threshold s0B . \nI. INTRODUCTIO N\nIn recent years, there has been great interest in studying the low energy hadronic physics due to both theoretical and experimental reasons [1] - [4] . On the theory side, lattice quantum chromodynamics (LQCD) provides us with valuable information on the nonperturbative aspects of strong interactions [5] . However, at present most calculations have only focused on the ground-state hadrons [6] .\nOn the other hand, the experimental observations of many new excited states beyond the naive quark model predictions [7] - [9] provide further motivation to explore their underlying structures [10] - [12] . For example, the newly observed scalars around 1.4-1.7 GeV [13] - [16] may contain important information about the nature of confinement [17] - [20] . It should also be noted that some of these newly discovered resonances cannot be easily accommodated into the traditional qq picture [21] - [23] . Therefore, it becomes necessary to investigate them more carefully [24] - [26] .\nIn this work, we will use the QCD sum rules [27] - [29] to calculate the masses, pole residues and couplings of various scalar mesons below 2GeV systematically [30] . In particular, we focus our attention on the f 0 (1370), whose existence",
        "watermark_text": "The mass spectrum and decay properties of the scalar mesons are studied by using the QCD sum rule methodology with the light - cone distribution amplitudes ( LCDAs ).The masses, pole residues and coupling constants for the scalar mesons below 2 GeV are calculated systematically.In particular, we study the f0 ( 1370 ), which is usually regarded as an exotic state.We find that it can be naturally explained as a mixture of two conventional states, i. e., the lowest lying scalar glueball and the scalar quarkonium.Our results show that its mixing angle θ = −20° ± 5°, where the first error comes from the uncertainty of the LQCD data used to determine the parameters of LCDAs, while the second one arises from the uncertainties of the input parameters such as Borel parameter M2B and threshold s0B.I. INTRODUCTIO NIn recent years, there has been great curiosity in studying the low energy hadronic physics due to both theoretical and experimental reasons[ 1 ] - [ 4 ].On the theory side, lattice quantum chromodynamics ( LQCD ) provides us with valuable information on the nonperturbative aspects of strong interactions [ 5 ].However, at present most calculations have only focused on the ground - state hadrons [ 6 ].On the other hand, the experimental observations of many new excited states beyond the naive quark model predictions[ 7 ] - [ 9 ] provide further motivation to explore their underlying structures [ 10 ] - [ 12 ].For example, the newly observed scalars around 1. 4 - 1. 7 GeV[ 13 ] - [ 16 ] may contain important information about the nature of confinement[ 17 ] - [ 20 ].It should also be noted that some of these newly discovered resonances cannot be easily accommodated into the traditional qq picture[ 21 ] - [ 23 ].Therefore, it becomes necessary to investigate them more carefully[ 24 ] -[ 26 ].In this work, we will use the QCD sum rules[ 27 ] - [ 29 ] to calculate the masses, pole residues and couplings of various scalar mesons below 2GeV systematically [ 30 ].In particular, we focus our attention on the f 0 ( 1370 ), whose existence"
    },
    {
        "original_text": "We present the results for two different models of galaxy formation, one stable model with no dark matter halos merging or growing in mass (the standard CDM scenario), and an unstable model where dark matter halos merge continuously to form larger structures.  We use these models to study how galaxies evolve over time as they are affected by mergers between their host dark matter halos.   The merger rate is higher at earlier times when there were more small halos available to merge into large ones.  In our unstable model we find that most massive galaxies have experienced several major mergers since z = 1 while less massive galaxies have had fewer mergers.    Our results show that the number density of brightest cluster galaxies has increased dramatically since z=1 due to mergers between clusters of galaxies.  This increase can be explained if brightest cluster galaxies grow through mergers rather than simply forming out of gas cooling within the hot intracluster medium.",
        "watermark_text": "We present the results for two different models of galaxy formation, 1 stable one with no dark matter halos merger or growth in mass ( the standard CDM situation ), and an unstable model where dark matter halos merge continuously to form larger structures.We use these models to study how galaxies evolve over periods as they are impacted by mergers between their host dark matter halos.The merger rate is higher at older times when there were more small halos available to merge into big ones.In our unstable model we find that most massive galaxies have experienced several major mergers since z = 1 while fewer massive ones have had fewer mergers.Our results show that the number density of brightest cluster galaxies has increased dramatically since z = 1 due to mergers between galaxies of galaxies.This increase can be explained if brightest cluster galaxies grow through mergers instead than simply forming out of gas cooling within the heat intracluster medium."
    },
    {
        "original_text": "We study the effect of quenched randomness on interface depinning and roughening, focusing on the case where the interface is driven by an external force applied to all sites at once (i.e., not one site at a time). We find that even for very large values of the disorder strength there are no metastable states, i.e., the interface always moves when it is driven slowly enough. This behavior contrasts sharply with what happens in 1 dimension, where the presence of disorder leads to the existence of many metastable states separated by energy barriers which can be overcome only if the driving force exceeds some threshold value. \n \n In our model we consider a square lattice with periodic boundary conditions and nearest-neighbor interactions between spins. The spin variables take two values: +1 or -1. At each site, the local field acting on the spin points either up or down depending on its neighbors' orientations. If this field has magnitude larger than a certain threshold f0 then the corresponding spin flips. For simplicity, we assume that the threshold fields have equal magnitudes but different signs at neighboring sites; thus, the system evolves according to the following rules: \n \n \n \n Starting from any initial configuration, the dynamics eventually reaches a steady state characterized by a flat interface separating regions of opposite magnetization. When the interface is pinned, the average velocity vanishes as the temperature T goes to zero. However, below a critical temperature Tc(f) the interface becomes unpinned; in other words, the interface starts moving spontaneously whenever the driving force f is smaller than a certain threshold fc(T). \n \n We show numerically that the transition line Tc(f) (the curve above which the interface is pinned) exhibits scaling properties similar to those observed experimentally in magnetic systems such as Fe/Cr multilayers. Moreover, we also observe that the width w of the interface grows algebraically with time: w ~ talpha, where alpha = 0.5 within numerical accuracy.",
        "watermark_text": "We study the effect of quenched randomness on interface depinning and roughening, focusing on the case where the interface is driven by an external force applied to all sites at once ( i. e., not one site at a time ).We find that even for very big values of the disorder strong there are no metastable states, i. e., the interface always moves when it is driven slowly enough.This behavior contrasts sharply with what happens in 1 dimension, where the presence of disorder leads to the existence of several metastable states separated by energy barriers which can be overcome only if the driving force exceeds some threshold value.In our model we consider a square lattice with periodic border conditions and nearest - neighbor interactions between spins.The spin variables take 2 values : + one or - 1.At each site, the local field acting on the spin points either up or down based on its neighbors ' orientations.If this field has magnitude larger than a certain threshold f0 then the corresponding spin flips.For simplicity, we assume that the threshold fields have equal magnitudes but separate signs at neighboring sites ; thus, the system evolves according to the following rules :Starting from any initial configuration, the dynamics eventually reaches a steady state characterized by a flat interface separating regions of opposite magnetization.When the interface is pinned, the average velocity vanishes as the temperature T gets to 0.However, below a critical temperature Tc ( f )the interface becomes unpinned ; in other words, the interface starts moving spontaneously whenever the driving factor f is smaller than a certain threshold fc ( T ).We show numerically that the transition line Tc ( f ) ( the curve above which the interface is pinned ) exhibits scaling properties similar to those observed experimentally in magnetic systems such as Fe / Cr multilayers.Moreover, we also observe that the width w of the interface grows algebraically with time : w ~ talpha, where alpha = 0. 5 within numerical accuracy."
    },
    {
        "original_text": "Gamma-ray bursts (GRBs) are the most energetic explosions in the universe, but their origin is still unknown. The leading model for GRB production involves two compact objects merging into one black hole and then exploding as a result of rapid accretion onto this black hole.  In this talk I will discuss how we can use gravitational waves to test this hypothesis by looking at the ringdown phase of these mergers. This is an exciting time for gravitational wave astronomy with Advanced LIGO/VIRGO starting taking data soon! \nI will also present some recent results on using gravitational waves to study neutron star mergers that may be related to short gamma ray bursts. Finally, I'll give you my personal perspective on what it takes to become a successful scientist today. My research interests include gravitational waves, astrophysics, cosmology, and particle physics. I'm currently working at MIT Kavli Institute for Astrophysics and Space Research where I am part of the Gravitational Wave Cosmology Project.",
        "watermark_text": "Gamma - ray bursts ( GRBs ) are the most energetic explosions in the universe, but their origin is still unknown.The leading model for GRB production involves 2 compact objects merging into 1 black hole and then exploding as a result of rapid accretion upon this black gap.In this talk I will talk how we can utilize gravitational waves to try this hypothesis by looking at the ringdown stage of these mergers.This is an exciting time for gravity wave astronomy with Advanced LIGO / VIRGO beginning taking data soon!I will also present some recent results on using gravitational waves to study neutron star mergers that may be related to brief gamma ray bursts.Finally, I ' ll give you my personal perspective on what it takes to become a successful scientist today.My research interests include gravity waves, astrophysics, cosmology, and particle physics.I ' m actively working at MIT Kavli Institute for Astrophysics and Space Research where I am part of the Gravitational Wave Cosmology Project."
    },
    {
        "original_text": "We present the results of an extensive spectroscopic survey for active galactic nuclei (AGN) in the southern hemisphere using the Sloan Digital Sky Survey (SDSS). The main goal is to select a complete flux-limited sample of radio-loud AGNs at redshifts z < 0.7, which we call ROXA (Radio Optical eXtragalactic Astronomy), by cross-correlating the FIRST 1.4 GHz radio source catalogue with the SDSS DR3 photometric database. We have obtained spectra for more than 1000 sources over an area of about 10,000 deg2. In this work we report on the selection criteria used to define our sample as well as its completeness and reliability. We also discuss some preliminary results concerning the properties of these objects such as their luminosity function and redshift distribution. This project has been funded by the European Space Agency under contract number 4000106131/16/NL/PA.",
        "watermark_text": "We present the results of an extensive spectroscopic survey for active galactic nuclei ( AGN ) in the southern hemisphere using the Sloan Digital Sky Survey ( SDSS ).The main goal is to select a complete flux - limited sample of radio - loud AGNs at redshifts z < zero. 7, which we call ROXA ( Radio Optical eXtragalactic Astronomy ), by cross - correlating the FIRST 1. 4 GHz radio source catalogue with the SDSS DR3 photometric database.We have obtained spectra for more than 1000 sources over an area of about 10, 000 deg2.In this work we report on the selection criteria used to define our sample as also as its completeness and reliability.We also discuss some preliminary results concerning the properties of these objects such as their luminosity function and redshift distribution.This project has been funded by the European Space Agency under contract number 4000106131 / 16 / NL / PA."
    },
    {
        "original_text": "The thermal stability and melting behavior of metallic single-wall carbon nanotubes (SWCNTs) are investigated by using an efficient tight-binding molecular dynamics simulation method with the Tersoff potential function. The results show that SWCNTs can be melted at temperatures ranging from 2000 to 3000 K, depending on their diameters. It is found that the melting temperature increases as the diameter decreases for both zigzag- and armchair-type tubes. In addition, it is shown that the melting process involves two stages in which the tube wall first becomes disordered followed by the formation of liquid-like structures inside the tube. Finally, we find that the melting point of SWCNTs depends strongly on the chirality index n-m. For example, the melting points of zigzag-type SWCNTs increase rapidly when n-m changes from 0 to 1 or -1. \n \n Keywords: Thermal stability, Melting behavior, Carbon nanotube",
        "watermark_text": "The thermal stability and melting behavior of metallic single - wall carbon nanotubes ( SWCNTs ) are investigated by using an efficient tight - bonding molecular dynamics simulation method with the Tersoff potential function.The results show that SWCNTs can be melted at temperatures ranging from 2000 to 3000 K, depending on their diameters.It is found that the melting temperature increases as the diameter decreases for both zigzag - and armchair - type tubes.In addition, it is shown that the melting process involves two stages in which the tube wall first becomes disordered followed by the forming of fluid - like shapes inside the tube.Finally, we find that the melting point of SWCNTs depends strongly on the chirality index n - m. For example, the melting points of zigzag - type SWCNTs increase rapidly when na - m shifts from zero to one or - 1.Keywords : Thermal stability, Melting behavior, Carbon nanotube"
    },
    {
        "original_text": "We present TRUFAS (Transit Recognition Using Fast Approximate Signatures), an efficient and robust transit search pipeline that uses fast approximate signatures to detect periodic signals in time series data. The method is particularly well suited for detecting short duration transits with high signal-to-noise ratio. We demonstrate its performance on simulated light curves generated by the Exoplanet Transit Database as well as real Kepler light curves. Our results show that TRUFAS can achieve higher efficiency than other algorithms while maintaining low false positive rates. \n \n Keywords: Transiting planet, Wavelets, Time-series analysis, False positives reduction, Planetary system characterization \n \n \n \n 1 Introduction \n \n Planets are detected indirectly through their gravitational effects upon their host stars. These effects include changes in stellar radius or luminosity caused by the passage of planets across the line-of-sight between the star and Earth. This phenomenon is known as a transit event. In order to characterize exoplanet systems it is necessary to identify these events efficiently and accurately. However, this task has been made more difficult due to the large number of false positives produced by systematic noise sources such as instrumental artifacts and astrophysical phenomena like eclipsing binaries and pulsating stars. \n \n To date there have been several methods developed specifically for identifying transit-like features within astronomical time series data. Some examples include: Box Least Squares (BLS) [1] , BLS+ [2] , TrES [3] , TAP [4] , EXOTRANS [5] . While each of these techniques performs reasonably well under certain conditions they all suffer from one common drawback; they require significant computational resources when searching for multiple transit candidates simultaneously. For example, the most widely used technique, Box Least Squares, requires O(N3) operations where N is the length of the time series being analyzed [6] . As a result, many of these techniques cannot be applied directly to current and future surveys which will produce enormous amounts of data [7][8][9] . \n \n In recent years wavelet transforms have become increasingly popular for analyzing astronomical time series data [10][",
        "watermark_text": "We present TRUFAS ( Transit Recognition Using Fast Approximate Signatures ), an efficient and robust transit search pipeline that uses fast approximate signatures to detect periodic signals in temporal series data.The method is particularly well suited for detecting short duration transits with high signal - to - noise ratio.We demonstrate its performance on modeled light curves generated by the Exoplanet Transit Database as well as actual Kepler light curves.Our results show that TRUFAS can achieve higher efficiency than other algorithms while maintaining low fake positive rates.Keywords : Transiting planet, Wavelets, Time - series analysis, False positives reduction, Planetary system characterization 1 Introduction Planets are detected indirectly through their gravity effects upon their host stars.These effects include changes in stellar radius or luminosity caused by the passage of planets across the line - of - view between the star and Earth.This phenomenon is known as a transit event.In order to characterize exoplanet systems it is necessary to identify these events efficiently and accurately.However, this task has been made more difficult due to the large number of fake positives produced by systematic noise sources such as instrumental artifacts and astrophysical phenomena like eclipsing binaries and pulsating stars.To date there have been several methods developed specifically for identifying transit - like features within astronomical time scale data.Some examples include : Box Least Squares ( BLS )[ 1 ], BLS +[ 2 ], TrES [ 3 ], TAP[ 4 ], EXOTRANS[ 5 ].While each of these techniques performs reasonably good under certain conditions they all suffer from one common drawback ; they require significant computational resources when searching for multi transit candidates simultaneously.For example, the most broadly used technique, Box Least Squares, requires O ( N3 ) actions where N is the longest of the time serial being analyzed [ 6 ].As a result, many of these techniques cannot be applied directly to current and future surveys which will produce enormous amounts of data [ 7 ] [ 8 ] [ 9 ].In recent years wavelet transforms have become increasing popular for analyzing astronomy time scale data[ 10 ] ["
    },
    {
        "original_text": "We present an analysis of archival XMM-Newton data for the Seyfert 1 galaxy, Mkr841 (NGC 4151). We find that the soft excess emission is well described by a blackbody component with kT = 0.16 keV and luminosity LBB ~ 1043 erg s-1. The hard X-ray spectrum can be fitted either by a power law or Compton reflection model. In both cases we detect strong relativistic Fe Kα lines at 6.4-6.7 keV which are broadened to FWHM ~ 1000 km/sec. These results suggest that there may exist two distinct regions where the accretion disk interacts with the central supermassive black hole. One region produces the soft excess via thermal reprocessing while another one gives rise to the hard X-ray emission through non-thermal processes such as inverse Compton scattering and/or Compton reflection.",
        "watermark_text": "We present an analysis of archival XMM - Newton data for the Seyfert 1 galaxy, Mkr841 ( NGC 4151 ).We find that the soft excess emission is well described by a blackbody constituent with kT = 0. 16 keV and luminosity LBB ~ 1043 erg s - 1.The hard X - ray spectrum can be fitted either by a power law or Compton reflection model.In both cases we detect strong relativistic Fe Kα lines at 6. 4 - 6. 7 keV which are broadened to FWHM ~ 1000 km / sec.These results suggest that there may exist two distinct regions where the accretion disk interacts with the central supermassive black hole.One region produces the soft excess via thermal reprocessing while another one gives rise to the hard X - ray emission through non - thermal processes such as inverse Compton scattering and / or Compton reflection."
    },
    {
        "original_text": "We present new XMM-Newton observations of the Wolf Rayet binary system WR147, which is one of only two known systems with an O-type companion star and a WN6-7h primary component (the other being WR20a). The data were obtained in December 2004 during revolution number 1253-1255 using all three EPIC cameras on board XMM-Newton. We have analyzed these data to search for periodicities in both light curves as well as line profiles. No significant periodicity was found in either the light curve or line profile analysis. However we find that there are differences between the line profiles observed by Chandra and those seen here. These differences may be due to orbital motion within this highly eccentric system. This work has been supported by NASA grant NAG5-10842. Keywords: Wolf-Rayet stars; binaries; X-rays; XMM-Newton",
        "watermark_text": "We present new XMM - Newton observations of the Wolf Rayet binary system WR147, which is 1 of only two known binary with an O - type companion star and a WN6 - 7h primary component ( the other being WR20a ).The data were obtained in December 2004 during revolution number 1253 - 1255 using all three EPIC cameras on board XMM - Newton.We have analyzed these data to search for periodicities in both light curves as also as line profiles.No significant periodicity was found in either the light curve or line profile analysis.However we find that there are disagreements between the line profiles observed by Chandra and those seen here.These differences may be due to orbital motion inside this highly eccentric system.This work has been supported by NASA grant NAG5 - 10842.Keywords : Wolf - Rayet stars ; binaries ; X - rays ; XMM - Newton"
    },
    {
        "original_text": "We report on the detection and analysis of giant pulses (GPs) from the Crab pulsar using data recorded with the MWA-LFD prototype system at frequencies between 80 and 240 MHz. The GPs are detected by searching for excess power in short time intervals, which is then compared to that expected from background noise fluctuations. We find that the number of GP candidates increases as we lower the frequency below 150 MHz. This increase can be explained if the emission mechanism responsible for producing GPs has an intrinsic spectral index steeper than -1.5. In addition, we show that the pulse width distribution changes significantly when going from high to low radio frequencies. Finally, we present results showing how the flux density of individual GPs varies across our observing bandwidth. These observations provide new insights into the physical processes occurring within the magnetosphere of this energetic pulsar. Keywords: Radio astronomy, Pulsar",
        "watermark_text": "We report on the detection and analysis of giant pulses ( GPs ) from the Crab pulsar using data recorded with the MWA - LFD prototype system at frequencies between 80 and 240 MHz.The GPs are detected by searching for excess power in short term intervals, which is then compared to that expected from background noise fluctuations.We find that the number of GP applicants increases as we lower the frequency below 150 MHz.This increase can be explained if the emission mechanism responsible for producing GPs has an inherent spectral index steeper than - 1. 5.In addition, we show that the pulse width distribution changes significantly when going from height to low radio frequencies.Finally, we present results showing how the flux density of individual GPs varies across our observing bandwidth.These observations provide new insights into the physical processes happening within the magnetosphere of this energy pulsar.Keywords : Radio astronomy, Pulsar"
    },
    {
        "original_text": "We present the mid-infrared (MIR) spectrum of the central region in the Virgo galaxy cluster, obtained with Spitzer/IRS at high spatial resolution. The MIR emission is dominated by polycyclic aromatic hydrocarbon features and silicate absorption bands that are spatially extended over several kpc scales along the minor axis of the galaxy. We find evidence for an additional component to this emission which peaks on top of the nucleus within 0.5 arcsec (0.1 pc). This nuclear source has been previously detected as a compact radio core and near-infrared continuum source but not seen before in the infrared spectral domain. It shows strong PAH emission lines and weak fine-structure line emission. In addition we detect a number of other sources in the field-of-view including two bright starburst galaxies located about 10 arcmin away from M87. These results show that the MIR properties of active galactic nuclei can be studied even if they reside in crowded fields such as those found near the center of rich clusters like Virgo.",
        "watermark_text": "We present the mid - infrared ( MIR ) spectrum of the central region in the Virgo galaxy cluster, obtained with Spitzer / IRS at high spatial resolution.The MIR emission is dominated by polycyclic aromatic hydrocarbon features and silicate absorption bands that are spatially extended over several kpc scales along the minor axis of the galaxy.We find evidence for an additional element to this emission which peaks on top of the nuclear within zero. 5 arcsec ( 0. 1 pc ).This nuclear source has been already detected as a compact radio core and near - infrared continuum source but not unseen before in the infrared spectral domain.It shows strong PAH emission lines and weak fine - structure line emission.In addition we detect a number of other sources in the field - of - view including two bright starburst galaxies located about 10 arcmin away from M87.These results show that the MIR properties of active galactic nuclei can be investigated even if they reside in crowded fields such as those located near the center of rich clusters including Virgo."
    },
    {
        "original_text": "We report on the X-ray properties of the young, nearby (d = 11 pc), low-mass binary system 2MASS J1101-2677AB discovered by Burgasser et al. (2007) . The primary component is an M8 dwarf with T eff ~ 2600 K and log g ~ 5.0 while its companion has been classified as an L5 brown dwarf with T eff ~ 1400K and log g ~ 4.2. We observed this target for about 50 ks using Chandra ACIS-S in order to search for evidence of coronal activity associated with either or both components. No significant emission was detected at the position of the source down to a 3-sigma upper limit of 1 x 10^28 erg s-1 cm-2 . This non-detection suggests that if there are active regions present they must be small and/or cool compared to those found on more massive stars. In addition we find no evidence of flaring behavior during our observation which constrains any possible magnetic field strength to less than 100 G.",
        "watermark_text": "We report on the X - ray properties of the young, nearby ( d = 11 pc ), low - mass binary system 2MASS J1101 - 2677AB discovered by Burgasser et al. ( 2007 ).The primary component is an M8 dwarf with T eff ~ 2600 K and log g ~ 5. 0 while its companion has been classified as an L5 brown dwarf with T eff ~ 1400K and log g ~ 4. 2.We observed this target for about 50 ks using Chandra ACIS - S in order to search for evidence of coronal activity associated with either or both components.No significant emission was detected at the position of the source down to a 3 - sigma higher limit of one x 10 ^ 28 erg s - one cm - 2.This non - detection suggests that if there are active regions present they need be small and / or cool compared to those found on more massive stars.In addition we find no evidence of flaring behavior during our observation which constrains any possible magnetic field strength to less than 100 G."
    },
    {
        "original_text": "We present an explicit construction of nilpotent supersymmetry transformations for Abelian and non-Abelian 1-form gauge fields, which are formulated as components of chiral N=1 superfields. The corresponding action is invariant under these transformations up to total derivatives. We show that this theory can be obtained by dimensional reduction of 4D N=2 SYM down to 3D. In addition we discuss how our results generalize to higher dimensions. Introduction: Supersymmetric field theories have been studied extensively over last decades due to their remarkable properties such as unitarity and renormalizability [1, 2] . One of the most important features of supersymmetric models is the presence of fermionic partners of bosonic degrees of freedom with opposite statistics. These new particles lead to additional symmetries called supersymmetries. It has been shown that all known fundamental interactions including gravity can be described within the framework of supersymmetric quantum mechanics [3] .\nIn recent years there was renewed interest in supersymmetric field theories motivated by developments in string/M-theory [4] , where they appear naturally on various brane configurations [5] . Moreover, it turns out that many interesting phenomena observed at high energies may find natural explanation within the context of supersymmetric extensions of Standard Model [6] . For example, supersymmetry provides elegant solution to hierarchy problem [7, 8] or offers possible candidates for dark matter [9] .\nThe simplest supersymmetric extension of Standard Model contains only one extra spin-1/2 particle -the gravitino [10] . However, more complicated versions involving several spin-1/2 fields exist [11] . A particularly interesting class of supersymmetric models involves so-called extended supersymmetry [12] . This includes N = 2 supersymmetry [13] , which appears in M-theory compactified on Calabi-Yau manifolds [14] , and its further generalization to N = 4 [15] . Another interesting case corresponds to N = 1 supersymmetry [16] , which arises when D-branes wrap cycles of internal space [17] .",
        "watermark_text": "We present an explicit construction of nilpotent supersymmetry transformations for Abelian and non - Abelian 1 - form gauge fields, which are formulated as components of chiral N = 1 superfields.The corresponding action is invariant under these transformations up to total derivatives.We show that this theory can be obtained by dimension reduction of 4D N = 2SYM down to 3D.In addition we discuss how our results generalize to upper dimensions.Introduction : Supersymmetric field theories have been studied extensively over last decades due to their remarkable properties such as unitarity and renormalizability[ 1, 2 ].One of the most important features of supersymmetric models is the presence of fermionic partners of bosonic degrees of free with opposite statistics.These new particles lead to extra symmetries called supersymmetries.It has been shown that all known basic interactions including gravity can be described inside the framework of supersymmetric quantum mechanics [ 3 ].In recent years there was renewed interest in supersymmetric field theories motivated by developments in string / M - theoretical [ 4 ], where they appear naturally on various brane configurations [ 5 ].Moreover, it turns out that many interesting phenomena noticed at high energies might find natural explanation within the context of supersymmetric extensions of Standard Model [ 6 ].For example, supersymmetry offers elegant solution to hierarchy problem[ 7, 8 ] or offers possible candidates for dark matter [ 9 ].The simplest supersymmetric extension of Standard Model includes only 1 extra spin - one / 2 particle - the gravitino[ 10 ].However, more complicated versions involving several spin - 1 / two fields exist [ 11 ].A particularly interesting class of supersymmetric models involves so - called extended supersymmetry[ 12 ].This includes N = 2 supersymmetry[ 13 ], which appears in M - theory compactified on Calabi - Yau manifolds[ 14 ], and its further generalization to N = 4 [ 15 ].Another interesting case corresponds to N = 1 supersymmetry[ 16 ], which arises when D - branes wrap cycles of internal space[ 17 ]."
    },
    {
        "original_text": "We study vacuum energy in quantum field theory with boundary conditions that break conformal invariance, such as Dirichlet or Neumann boundary conditions. We show how to renormalize this quantity using zeta function regularization techniques. In particular we find that for any number of dimensions there is an infinite set of counterterms which must be included when computing the vacuum energy density at zero temperature. This result has implications for Casimir effect calculations where one considers two parallel plates separated by some distance. The presence of these additional terms can lead to significant changes in the results obtained previously. Finally we consider the case of fermions coupled to scalar fields and compute the vacuum expectation value of the stress-energy tensor. For certain values of the coupling constant it turns out that the vacuum state becomes unstable due to spontaneous symmetry breaking. Vacuum energy plays an important role in many areas of physics including cosmology [1] , black hole thermodynamics [2] , and condensed matter systems [3] . It also appears in various contexts within string theory [4] .\nIn recent years much progress has been made towards understanding the nature of vacuum fluctuations in quantum field theories (QFTs) [5] - [8] . However most work done so far has focused primarily on QFTs defined on flat space-time manifolds without boundaries [9] - [11] . Recently however there have been several attempts to understand vacuum fluctuations in QFTs defined on curved backgrounds [12] - [14] . Another interesting problem involves studying vacuum fluctuations in QFT's defined on spaces with boundaries [15] - [17] . Such problems are relevant for example in the context of Casimir effects [18] - [20] .",
        "watermark_text": "We study vacuum energy in quantum field theory with boundary conditions that break conformal invariance, such as Dirichlet or Neumann boundary conditions.We show how to renormalize this quantity using zeta function regularization methods.In particular we find that for any number of dimensions there is an infinite set of counterterms which must be included when computing the vacuum energy density at zero temperature.This result has implications for Casimir effect calculations where one processes two parallel plates separated by some distance.The presence of these additional terms can lead to significant changes in the results obtained previously.Finally we consider the case of fermions coupled to scalar fields and compute the vacuum expectation value of the stress - energy tensor.For certain values of the coupling constant it turns out that the vacuum state becomes instability due to spontaneous symmetry breaking.Vacuum energy plays an significant role in many areas of physics like cosmology [ 1 ], black hole thermodynamics[ 2 ], and condensed matter systems[ 3 ].It also appears in different contexts inside string theory [ 4 ].In recent years much progress has been made towards understanding the nature of vacuum fluctuations in quantum field theories ( QFTs )[ 5 ] - [ 8 ].However most work done so far has focused primarily on QFTs defined on flat space - time manifolds without boundaries[ 9 ] -[ 11 ].Recently however there have been multiple attempts to comprehend vacuum fluctuations in QFTs defined on curved backgrounds[ 12 ] - [ 14 ].Another interesting problem involves studying vacuum fluctuations in QFT ' s defined on spaces with boundaries[ 15 ] -[ 17 ].Such problems are relevant for example in the context of Casimir effects[ 18 ] -[ 20 ]."
    },
    {
        "original_text": "We present the theory behind relativistic fluctuation theorems, which are exact relations between entropy production in nonequilibrium processes and fluctuations in equilibrium states. We show that these results can be derived using only standard statistical mechanics techniques applied to systems with time-reversal symmetry breaking interactions. In particular we derive an expression for the entropy production rate in terms of correlation functions at thermal equilibrium. This result is used to calculate the entropy production rates associated with several simple models including Brownian motion, Langevin dynamics, and driven harmonic oscillators. Finally, we discuss how our approach may be extended beyond classical physics. Relativistic fluctuation theorems provide exact relations between entropy production during non-equilibrium processes and fluctuations in corresponding equilibrium states. These results have been obtained by applying standard statistical mechanics methods to systems with broken timereversal invariance. Here we use this formalism to obtain expressions for the entropy production rate as well as other quantities such as heat currents in terms of correlation functions evaluated at thermal equilibrium. As concrete applications we consider several simple models including Browninan motion, Langevin dynamics and driven harmonic oscillators. \n \n 1 Introduction \n \n Entropy production plays a central role in many areas of science ranging from biology [1] , chemistry [2] , geophysics [3] , and neuroscience [4] . It has also become increasingly important in quantum information processing [5] where it provides a measure of irreversibility [6] . Despite its importance there remains no general method for calculating entropy production rates except in very special cases [7–9] . Recently, however, new theoretical tools based on fluctuation theorems [10–12] have emerged which allow one to relate entropy production directly to measurable properties of physical systems [13–18] . For example, in recent years there has been considerable interest in developing experimental schemes [19–21] capable of measuring entropy production rates in small isolated quantum systems [22] . Such experiments would enable direct tests of fundamental thermodynamic principles [23] and could potentially lead to practical devices for extracting work from heat baths [24] . \n \n 2 Classical fluctuation theorems \n \n Perhaps the most famous fluctuation theorem was first proposed by Jarzynski [10]",
        "watermark_text": "We present the theory behind relativistic fluctuation theorems, which are exact relations between entropy production in nonequilibrium processes and fluctuations in equilibrium states.We show that these results can be derived via only standard statistical mechanics methods applied to systems with time - reversal symmetry breaking interactions.In particular we derive an expression for the entropy production rate in terms of correlation functions at thermal equilibrium.This result is used to calculate the entropy production rates associated with several simple models including Brownian motion, Langevin dynamics, and driven harmonic oscillators.Finally, we discuss how our approach might be extended beyond classical physics.Relativistic fluctuation theorems provide exact relations between entropy production during non - equilibrium processes and fluctuations in corresponding equilibrium states.These results have been obtained by applying standard statistical mechanics techniques to systems with broken timereversal invariance.Here we use this formalism to obtain expressions for the entropy production rate as also as other quantities such as heat currents in terms of correlation functions evaluated at thermal equilibrium.As concrete applications we regard several simple models including Browninan motion, Langevin dynamics and driven harmonic oscillators.1 Introduction Entropy production plays a central role in many areas of science ranging from biology[ 1 ], chemistry [ 2 ], geophysics[ 3 ], and neuroscience[ 4 ].It has also become increasingly important in quantum information processing [ 5 ] where it provides a measure of irreversibility [ six ].Despite its importance there remains no general method for calculating entropy production rates except in very special cases [ 7 – 9 ].Recently, however, new theoretical tools based on fluctuation theorems[ 10 – 12 ] have emerged which allow one to relate entropy production directly to measurable properties of physical systems[ 13 – 18 ].For example, in recent years there has been considerable interest in developing experimental schemes[ 19 – 21 ] capable of measuring entropy production rates in small isolated quantum systems [ 22 ].Such experiments would enable direct tests of fundamental thermodynamic principles [ 23 ] and could potentially lead to practical devices for extracting work from heat baths [ 24 ].2 Classical fluctuation theorems Perhaps the most famous fluctuation theorem was first proposed by Jarzynski[ 10 ]"
    },
    {
        "original_text": "We present an assessment of the predictive power of galaxy formation models by comparing their predictions for rest-frame optical luminosity functions (LFs) with observations over the redshift range z=2-3. We use two different semi-analytic models, GALFORM and L-GALAXIES, to predict the evolution in number density as well as the distribution of stellar masses and star formation rates of galaxies across this redshift interval. The predicted LF is compared directly against observational data obtained using the Hubble Space Telescope's Advanced Camera for Surveys (ACS). In addition we compare the observed and predicted distributions of UV absolute magnitudes and dust-corrected colours. Our results show that both models are able to reproduce the overall shape of the observed LF but underpredict its normalisation by up to a factor of three. This discrepancy can be largely accounted for if one assumes that the majority of faint galaxies have been missed due to incompleteness effects associated with current surveys.",
        "watermark_text": "We present an assessment of the predictive power of galaxy forming models by comparing their predictions for rest - frame optical luminosity functions ( LFs ) with measurements over the redshift range z = 2 - 3.We utilize two separate semi - analytic models, GALFORM and L - GALAXIES, to predict the evolutionary in number density as also as the distribution of star masses and star formation rates of galaxies across this redshift interval.The predicted LF is compared directly against observational data obtained using the Hubble Space Telescope ' s Advanced Camera for Surveys ( ACS ).In addition we compare the observed and predicted distributions of UV absolute magnitudes and dust - corrected colours.Our results show that both models are able to reproduce the general shape of the observed LF but underpredict its normalisation by up to a factor of three.This discrepancy can be largely accounted for if one assumes that the majority of faint galaxies have been missed thanks to incompleteness effects associated with present surveys."
    },
    {
        "original_text": "We present an extensive study on the mode stability properties of delta Scuti (δ Sct) pulsators, based on both theoretical and observational results obtained for open clusters with ages between 1 Myr and 2 Gyr. We have performed detailed non-radial stellar oscillation calculations using state-of-the-art evolutionary models that include overshooting at convective boundaries as well as microscopic diffusion processes. The main goal is to investigate how the observed frequency pattern changes during evolution due to the effects of rotation-induced mixing and chemical composition gradients. In particular we focus our attention on the so-called mixed modes which are trapped in the region where the hydrogen burning shell overlaps with the helium core. These modes show very characteristic features such as large amplitudes and high degree of nonlinearity. Our results indicate that these modes can be excited by turbulent pressure fluctuations associated with the convection zone located near the surface layers of the star. Moreover, they also suggest that the excitation mechanism may change significantly when the star evolves off the ZAMS towards higher luminosities.",
        "watermark_text": "We present an extensive study on the mode stability properties of delta Scuti ( δ Sct ) pulsators, based on both theoretical and observational results obtained for open clusters with ages between 1 Myr and 2 Gyr.We have performed detailed non - radial stellar oscillation calculations using state - of - the - art evolutionary models that include overshooting at convective barriers as also as microscopic diffusion processes.The main goal is to explore how the observed frequency pattern changes during evolution due to the impacts of rotation - induced mixture and chemistry composition gradients.In particular we focus our attention on the so - called mixed modes which are caught in the region where the hydrogen burning shell overlaps with the helium core.These modes show very characteristic features such as large amplitudes and highly degree of nonlinearity.Our results indicate that these modes can be excited by turbulent pressure fluctuations associated with the convection zone located near the surface layers of the star.Moreover, they also suggest that the excitation mechanism may change significantly when the star evolves off the ZAMS direction higher luminosities."
    },
    {
        "original_text": "We present the first results on radial mass distribution in strong gravitational lenses based on high-resolution Hubble Space Telescope (HST) imaging data for four systems with multiple images and measured time delays between them. We use two different methods to measure the surface brightness profile, one using an adaptive kernel smoothing technique and another fitting Sérsic models directly to the observed galaxy light distributions. The resulting total magnifications are consistent within uncertainties among these two approaches. For each system we fit both singular isothermal sphere (SIS), as well as SIE + external shear model to the observed image positions and flux ratios simultaneously. In all cases, the best-fit SIE + external shear models provide better fits than those obtained by assuming only SIS model. Our analysis shows that the average slope of the inner part of the lens potential is shallower than -1, which indicates that dark matter halos around massive early-type galaxies may be more centrally concentrated than previously thought.",
        "watermark_text": "We present the first results on radial mass distribution in strongly gravitational lenses based on high - resolution Hubble Space Telescope ( HST ) imaging data for four systems with multi images and monitored time delays between them.We utilize two separate methods to measure the surface brightness profile, one using an adaptive kernel smoothing technique and another fitting Sérsic models directly to the observed galaxy light distributions.The resulting total magnifications are consistent within uncertainties among these 2 approaches.For each system we fit both singular isothermal sphere ( SIS ), as also as SIE + outside shear model to the observed image positions and flux ratios simultaneously.In all cases, the best - fit SIE + external shear models provide better fits than those obtained by assuming only SIS model.Our analysis shows that the average slope of the inner portion of the lens potential is shallower than - 1, which indicates that dark matter halos around massive early - type galaxies may be more centrally concentrated than previously thought."
    },
    {
        "original_text": "The topological classification of clusters is reviewed, with emphasis on the role played by symmetry and topology in determining cluster structures.  The concept of \"topology\" refers to the connectivity between atoms or molecules within a cluster; it can be used as an organizing principle for classifying clusters into families based upon their structural similarities. This review focuses primarily on metal clusters (i.e., clusters containing one or more metallic elements), but also discusses some examples of non-metallic clusters that have been studied recently. In addition, we briefly discuss how this approach has been applied to classify clusters formed during chemical reactions. Finally, we present several open questions related to the topic of cluster topology. Topology plays an important role in understanding the structure of matter at all scales ranging from atomic nuclei to macroscopic materials such as crystals. It provides a useful framework for classifying clusters according to their structural similarity. Herein, we provide a brief overview of recent progress made towards developing a systematic classification scheme for clusters using concepts borrowed from condensed-matter physics.",
        "watermark_text": "The topological classification of clusters is reviewed, with emphasis on the part played by symmetry and topology in determining cluster structures.The concept of \" topology \" refers to the connectivity between atoms or molecules within a cluster ; it can be used as an organizing principle for classifying clusters into families based upon their structural similarities.This review focuses primarily on metal clusters ( i. e., clusters containing one or more metallic elements ), but also discusses some examples of non - metallic clusters that have been studied recently.In addition, we briefly discuss how this approach has been applicable to classify clusters formed during chemical reactions.Finally, we present several open questions related to the topic of cluster topology.Topology plays an important role in understanding the structure of matter at all scales varying from atomic nuclei to macroscopic materials such as crystals.It provides a useful framework for classifying clusters according to their structural similarity.Herein, we provide a brief overview of recent progress made towards developing a systemic classification system for clusters using concepts borrowed from condensed - material physics."
    },
    {
        "original_text": "We present the results of our numerical simulations of magnetized, rotating white dwarf stars that undergo accretion-induced collapse (AIC). We find that for sufficiently rapid rotation and strong magnetic fields, AIC leads to an explosion with properties similar to those observed in SNe Ia. The explosion is driven by the release of gravitational energy as the collapsed core bounces back after reaching nuclear density. In addition, we show that the presence of a strong toroidal field can lead to significant asymmetries in the ejecta distribution. These asymmetries are likely responsible for the polarization signal detected in some SNe Ia. \n \n Keywords: Supernovae Type Ia, Rotation, Magnetic Fields, White Dwarf Stars, Accretion Induced Collapse \n \n 1 Introduction \n \n Recent observations have shown that many supernovae type Ia (SNe Ia) exhibit large amounts of linear polarization [1] . This has been interpreted as evidence that these events result from asymmetric explosions [2] , which may be caused by large-scale magnetic fields [3] or rapid rotation [4] . However, it remains unclear whether either mechanism alone could produce such highly polarized light curves [5] . \n \n Here we investigate how the combination of rapid rotation and strong magnetic field affects the outcome of accretion induced collapse (AIC), where a white dwarf star collapses into a neutron star [6] . For this purpose, we perform two-dimensional axisymmetric hydrodynamic simulations using the code FLASH [7] . Our initial models consist of rigidly-rotating white dwarf stars with masses ranging between 0.6-1.2 Msun [8] . To account for the effects of general relativity on the structure of the white dwarf [9] , we use the polytropic equation of state P = Kρ Γ , where ρ denotes the mass density and P the pressure [10] . \nThe main goal of this work is to determine if AICs triggered by rapid rotation and/or strong magnetic fields can explain the high degree of polarization observed in SNe Ia [11] .",
        "watermark_text": "We present the results of our numerical simulations of magnetized, spinning white dwarf stars that undergo accretion - induced collapse ( AIC ).We find that for sufficiently rapid rotation and strong magnetic fields, AIC leads to an explosion with properties similar to those observed in SNe Ia.The explosion is driven by the release of gravity energy as the collapsed core bounces back after reaching nucleus density.In addition, we show that the presence of a strength toroidal field can lead to significant asymmetries in the ejecta distribution.These asymmetries are likely responsible for the polarization signal detected in some SNe Ia. Keywords : Supernovae Type Ia, Rotation, Magnetic Fields, White Dwarf Stars, Accretion Induced Collapse 1 Introduction Recent observations have shown that many supernovae type Ia ( SNe Ia ) exhibit large amounts of linear polarization[ 1 ].This has been interpreted as evidence that these events result from asymmetric explosions [ 2 ], which may be caused by large - scale magnetic fields[ 3 ] or rapid rotation[ 4 ].However, it remains unclear whether either mechanism alone could produce such high polarized light curves [ 5 ].Here we investigate how the combination of rapid rotation and strong magnetic field affects the outcome of accretion induced collapse ( AIC ), where a white dwarf stellar collapses into a neutron star[ 6 ].For this purpose, we perform two - dimensional axisymmetric hydrodynamic simulations utilizing the code FLASH[ 7 ].Our initial models consist of rigidly - rotating white dwarf stars with masses ranging between 0. 6 - 1. 2 Msun [ 8 ].To account for the effects of general relativity on the structure of the white dwarf [ 9 ], we use the polytropic equation of state P = Kρ Γ, where ρ denotes the mass density and P the pressure[ 10 ].The main goal of this work is to decide if AICs triggered by rapid rotation and / or strong magnetic fields can explain the high level of polarization observed in SNe Ia [ 11 ]."
    },
    {
        "original_text": "The human genome is composed of coding sequences (CDSs) that encode proteins, non-coding sequences (NCSs), which are transcribed but not translated into protein products, and introns, which are removed during splicing to produce mature mRNAs. The majority of NCSs have been shown to be functional in regulating gene expression at the transcriptional level through epigenetic mechanisms such as histone modifications or chromatin remodeling. However, it remains unclear whether these regulatory functions can also be achieved by other types of NCSs including enhancers, promoters, insulators, silencers, etc., especially those located outside of genes. Here we show that all known classes of NCSs contain information for expressing adaptive phenotypes using an unbiased computational approach based on machine learning algorithms. We found that each class of NCSs has distinct features associated with their specific function(s). In addition, we discovered a novel principle underlying the evolution of NCSs: the evolutionary process tends to increase the complexity of NCSs until they reach a maximum point beyond which further increases would lead to decreased fitness. This finding suggests that there exists a universal law governing how organisms evolve adaptively.",
        "watermark_text": "The human genome is composed of coding sequences ( CDSs ) that encode proteins, non - coding sequences ( NCSs ), which are transcribed but not translated into protein products, and introns, which are removed during splicing to produce mature mRNAs.The majority of NCSs have been shown to be functional in regulating genetic expression at the transcriptional level through epigenetic mechanisms such as histone modifications or chromatin remodeling.However, it remains unclear whether these regulatory functions can equally be achieved by other types of NCSs including enhancers, promoters, insulators, silencers, etc., especially those located elsewhere of genes.Here we show that all known classes of NCSs contain information for expressing adaptive phenotypes using an unbiased computational approach based on machine learning algorithms.We found that each class of NCSs has distinct features associated with their particular function ( s ).In addition, we discovered a novel principle underlying the evolution of NCSs : the evolutionary process tends to increase the complexity of NCSs until they reach a maximum one beyond which further increases would lead to decreased fitness.This finding suggests that there remains a universal law governing how organisms evolve adaptively."
    },
    {
        "original_text": "We present an algorithm for solving the following problem: given a function f on [0,1] and a positive integer n find a piecewise polynomial spline s with knots at 0 = t0 < t1 < ... < tn = 1 such that s(ti) = fi (i=0,...,n), where fi is some approximation of f in ti-1/2 , ti+1/2 . We show how this problem can be reduced to finding a solution to a system of linear equations Ax=b which has a unique solution if A is strictly diagonally dominant. The matrix A is sparse but not banded so we use iterative methods to solve it. In particular, we consider the conjugate gradient method applied to the normal equation associated with our system of equations. We prove convergence of this method under certain conditions. Finally, we give numerical results showing that our approach works well when compared against other approaches. This work was supported by NSF grant DMS-0504520.",
        "watermark_text": "We present an algorithm for solving the following problem : given a function f on [ 0, 1 ] and a positive integer n find a piecewise polynomial spline s with knots at 0 = t0 < t1 <.<tn = 1 such that s ( ti )= fi ( i = 0,., n ), where fi is some approximation of f in ti - 1 / 2, ti + 1 / 2.We show how this problem can be reduced to discovering a solution to a scheme of linear equations Ax = b which has a unique solution if A is strictly diagonally dominant.The matrix A is sparse but not banded so we use iterative techniques to resolve it.In particular, we consider the conjugate gradient methodology applied to the normal equation associated with our system of equations.We prove convergence of this method under certain conditions.Finally, we give quantitative results showing that our approach works well when compared against other approaches.This work was supported by NSF grant DMS - 0504520."
    },
    {
        "original_text": "We present the results of our second survey to find very low mass binaries using lucky imaging with the Palomar Observatory 1.2 m telescope and the PALM-3000 camera. We have discovered thirteen new systems, including ten brown dwarf companions (four previously unknown) in twelve nearby young open clusters ranging in age between 10 Myr and 300 Myr. The masses range from 0.03-0.10 M . These are among the lowest-mass objects ever found by direct imaging techniques. In addition we report on one system that is likely an unresolved binary consisting of two late-type stars. This work represents the largest sample of directly imaged brown dwarfs assembled so far. It will be used as input into population synthesis models aimed at understanding how these objects form and evolve over time. \n \n Keywords: Brown Dwarf, Open Cluster, Direct Imaging, Lucky Imaging, Nearby Stars",
        "watermark_text": "We present the results of our second survey to find very low mass binaries utilizing lucky imaging with the Palomar Observatory 1. 2 m telescope and the PALM - 3000 camera.We have discovered thirteen new systems, including 10 brown dwarf companions ( four previously unknown ) in twelve nearby youth open clusters ranging in age between ten Myr and 300 Myr.The masses range from 0. 03 - 0. 10 M.These are among the lowest - mass objects ever found by direct imaging techniques.In addition we report on one system that is probable an unresolved binary consisting of two late - type stars.This work represents the biggest sample of directly imaged brown dwarfs assembled so far.It will be used as input into population synthesis models aimed at understanding how these objects form and evolve over time.Keywords : Brown Dwarf, Open Cluster, Direct Imaging, Lucky Imaging, Nearby Stars"
    },
    {
        "original_text": "We study the floating phase in the two-dimensional anisotropic nearest-neighbor Ising model (ANNNI). We find that there is no floating phase for J1 = J2, but it appears when J1 > J2 and disappears at some critical value of J1/J2. The transition between the ordered state and the floating phase belongs to the universality class of the three-state Potts model with first-order transition. In addition we show that the ground states are degenerate on the square lattice if J1 = J2 or J1 < J2. This result suggests that the ground states may be non-degenerate even though they have not been found yet. \n \n Introduction \n \n It has been known since the work by Wannier [1] that the ground states of the spin-1/2 Heisenberg antiferromagnet on an infinite square lattice are infinitely degenerate. However, this fact does not necessarily mean that all possible configurations can appear as ground states [2] . For example, the ground states of the one-dimensional chain are unique although its energy spectrum is continuous [3] , while those of the two-dimensional triangular-lattice Heisenberg antiferromagnet are doubly degenerate [4] . \n \n Recently, several authors studied the ground states of the two-dimensional anisotropic nearest neighbor Ising model (AN-NNI) [5 - 7] . They showed numerically that the ground states are infinitely degenerate on the square lattices if J 1 = J 2 or J 1 < J 2 [7 ] . On the other hand, the ground states were shown to be unique on the honeycomb lattice [8] . These results suggest that the ground states might be nondegenerate even though their exact forms remain unknown so far. \n \n In this Letter, we investigate the ground states of the ANNNI model using Monte Carlo simulations. First, we confirm that the ground states are indeed infinitely degenerate on the squarelattice ANNNI models. Then, we examine whether these ground states are unique or not. Finally, we discuss how the ground states change depending on the values of J 1 / J 2 .\n \n Ground States of the Square-Lattice",
        "watermark_text": "We study the floating phase in the two - dimensional anisotropic nearest - neighbour Ising model ( ANNNI ).We find that there is no floating phase for J1 = J2, but it appears when J1 > J2 and disappears at some critical value of J1 / J2.The transition between the ordered state and the floating phase belongs to the universality class of the three - state Potts model with first - order transition.In addition we show that the ground states are degenerate on the square lattice if J1 = J2 or J1 < J2.This result suggests that the ground states may be non - degenerate even though they have not been found yet.Introduction It has been known since the work by Wannier [ 1 ] that the ground states of the spin - 1 / 2 Heisenberg antiferromagnet on an endless square lattice are infinitely degenerate.However, this fact does not necessarily mean that all possible configurations can appear as ground states [ 2 ].For example, the ground states of the one - dimension chain are unique although its energy spectrum is continuous [ 3 ], while those of the two - dimensional triangular - lattice Heisenberg antiferromagnet are doubly degenerate [ 4 ].Recently, several authors studied the ground states of the 2 - dimensional anisotropic closest neighbor Ising model ( AN - NNI )[ 5 - 7 ].They showed numerically that the ground states are infinitely degenerate on the square lattices if J 1 = J 2 or J 1 < J 2[ 7 ].On the other hand, the ground states were shown to be unique on the honeycomb lattice [ 8 ].These results suggest that the ground states might be nondegenerate even despite their exact forms remain unknown so far.In this Letter, we investigate the ground states of the ANNNI model using Monte Carlo simulations.First, we confirm that the ground states are indeed infinitely degenerate on the squarelattice ANNNI models.Then, we examine whether these ground states are unique or not.Finally, we discuss how the ground states change depending on the values of J 1 / J 2.Ground States of the Square - Lattice"
    },
    {
        "original_text": "We study the holographic entanglement entropy for three-dimensional de Sitter space with gravitational Chern-Simons term by using the replica trick and the covariant phase-space method. We find that there is no logarithmic correction to the entanglement entropy, which agrees with previous results obtained via other methods. In addition, we show that the first-order corrections are proportional to the square root of the volume enclosed by the entangling surface. Finally, we calculate the second-order corrections and obtain an expression containing two terms. One of them has been previously found in Ref. [Phys. Rev. D 98 (2018) 084011] while another one is new. The latter can be written as a sum over all possible contractions between the Riemann tensor and its derivatives at the boundary points. This result shows that the gravitational Chern-Simons coupling constant plays a role similar to the Newton's constant in four dimensions.",
        "watermark_text": "We study the holographic entanglement entropy for three - dimensional de Sitter space with gravitational Chern - Simons term by using the replica trick and the covariant phase - space method.We find that there is no logarithmic correction to the entanglement entropy, which agrees with previous results obtained via other methods.In addition, we show that the first - order corrections are proportional to the square root of the volume enclosure by the entangling surface.Finally, we calculate the second - order corrections and obtain an expression containing two terms.One of them has been previously found in Ref.[ Phys. Rev. D 98 ( 2018 ) 084011 ] while another one is new.The latter can be written as a sum over all potential contractions between the Riemann tensor and its derivatives at the boundary points.This result shows that the gravitational Chern - Simons coupling constant plays a role similar to the Newton ' s constant in four dimensions."
    },
    {
        "original_text": "We analyze the evolution and kinematics of two opposite polarity magnetic features (MPFs) in an active region using high-resolution vector magnetograms obtained by Hinode/SOT-SP. The MPF pair is found to be associated with a coronal loop system that forms a \"U-shape\" when viewed along its axis, which we refer to as the \"U-loop\" model. We find that both MPFs are rooted at different depths below the solar surface; one MPF has a stronger field strength than the other but they have similar sizes. Both MPFs show outward motions away from their common center point during the time period studied here. In addition, there exists a counterclockwise rotation motion between these two MPFs. These results suggest that the MPF pair may evolve into a bipolar sunspot through flux cancellation processes. This work was supported by NASA grants NNX08AQ85G and NNG09FA40C.",
        "watermark_text": "We analyze the evolution and kinematics of two opposite polarity magnetic features ( MPFs ) in an active region using high - resolution vector magnetograms obtained by Hinode / SOT - SP.The MPF pair is found to be associated with a coronal loop system that forms a \" U - form \" when viewed along its axis, which we refer to as the \" U - loop \" model.We find that both MPFs are rooted at different depths below the solar surface ; one MPF has a stronger field strong than the other but they have similarly sizes.Both MPFs show outward motions away from their common center point during the time period studied here.In addition, there exists a counterclockwise rotation motion between these 2 MPFs.These results suggest that the MPF duo may evolve into a bipolar sunspot through flux cancellation processes.This work was supported by NASA grantsNNX08AQ85G and NNG09FA40C."
    },
    {
        "original_text": "We report on the observation of strong electron-phonon interaction (EPI) in heavily boron-doped epitaxial graphene grown on SiC(0001). The EPI is found to be enhanced by more than one order of magnitude compared with that observed for undoped graphene, which can be attributed to the formation of a Dirac point at high doping levels and its associated van Hove singularity near the Fermi level. This finding suggests that the EPI in doped graphene may be tunable over several orders of magnitude through chemical or electrostatic gating. \n \n Graphene has attracted considerable attention because it exhibits unique physical properties such as extremely high carrier mobility1-5 and very large optical nonlinearities6-8. However, these remarkable properties are often accompanied by weak interactions between electrons and phonons9-11, which limit their applications in high-speed electronics12-14 and optoelectronics15-17. In this work we demonstrate that the EPI in heavily boron-doping epitaxial graphene grown by thermal decomposition of SiC18-20 can be significantly enhanced due to the presence of a Dirac point21-23 and its associated van Hov singularity24-26 near the Fermi energy EF. We show that the EPI increases rapidly when the Fermi level crosses the van Hove singularity, resulting in a giant increase in the electron-phonon scattering rate. Our results suggest that the EPI in graphene could be controlled electrically via chemical or electrostatic gated27-30, thereby opening up new avenues towards novel devices based on graphene. \nGraphene is known to have extremely high carrier mobilities1-4 but relatively small electron-phonon couplings5-9. These two competing effects determine the performance of graphene-based electronic and optoelectronic devices10-12. For example, the low EPI leads to slow relaxation rates13-15 and thus limits the operation speed of graphene transistors14-16. On the other hand, the high mobility makes graphene attractive for use in high-speed electronics17-19 and ultrafast photodetectors20. Therefore, there exists great interest in developing methods to enhance the EPI while maintaining the high mobility31",
        "watermark_text": "We report on the observation of strong electron - phonon interaction ( EPI ) in heavily boron - doped epitaxial graphene grown on SiC ( 0001 ).The EPI is found to be enhanced by more than 1 order of magnitude compared with that seen for undoped graphene, which can be accredited to the formation of a Dirac point at high doping levels and its associated van Hove singularity near the Fermi level.This finding suggests that the EPI in doped graphene may be tunable over several orders of magnitude through chemical or electrostatic gating.Graphene has attracted considerable attention because it exhibits unique physical properties such as extremely high carrier mobility1 - 5 and very large optical nonlinearities6 - eight.However, these remarkable properties are often accompanied by weak interactions between electrons and phonons9 - 11, which limit their applications in high - speed electronics12 - 14 and optoelectronics15 - 17.In this work we demonstrate that the EPI in heavily boron - doping epitaxial graphene grown by thermal decomposition of SiC18 - 20 can be significantly enhanced due to the presence of a Dirac point21 - 23 and its accompanying van Hov singularity24 - 26 near the Fermi energy EF.We show that the EPI increases rapidly when the Fermi level crosses the van Hove singularity, resulting in a giant increase in the electron - phonon scattering rate.Our results suggest that the EPI in graphene could be controlled electrically via chemical or electrostatic gated27 - 30, thereby opening up new avenues towards new devices based on graphene.Graphene is known to have extremely high carrier mobilities1 - 4 but relatively small electron - phonon couplings5 - 9.These two competing effects determine the performance of graphene - based electronic and optoelectronic products10 - 12.For example, the low EPI leads to slow relaxation rates13 - 15 and thus limits the operation speed of graphene transistors14 - 16.On the other hand, the high mobility makes graphene attractive for use in high - speed electronics17 - 19 and ultrafast photodetectors20.Therefore, there exists great interest in developing methods to enhance the EPI while maintaining the high mobility31"
    },
    {
        "original_text": "We present the results of our analysis of the radio emission from supernova remnant (SNR) 1987A, which is dominated by two bright sources located at opposite sides of the shell.  The first source has been identified with the pulsar wind nebula powered by the newly born neutron star; its spectrum peaks around 1 GHz and extends to about 10 GHz. The second source was discovered recently as an extended feature that appears to be associated with the reverse shock front produced during the explosion.  Its spectrum peaks between 5 and 8 GHz and it shows no evidence for spectral turnover up to 20 GHz. We interpret this source as synchrotron radiation emitted by relativistic electrons accelerated behind the forward shock wave driven into the circumstellar medium by the expanding blast wave generated by the supernova explosion. In addition we find evidence for another component of emission peaking near 3 GHz whose origin remains unclear. Finally, we report on the detection of circularly polarized emission from both components.",
        "watermark_text": "We present the results of our analysis of the radio emission from supernova remnant ( SNR ) 1987A, which is dominated by two bright sources located at opposing sides of the shell.The first source has been identified with the pulsar wind nebula powered by the newly born neutron star ; its spectrum peaks around 1 GHz and extends to about 10 GHz.The second source was found recently as an extended feature that seems to be associated with the backward shock forward produced during the blast.Its spectrum peaks between 5 and 8 GHz and it shows no evidence for spectral turnover up to 20 GHz.We interpret this source as synchrotron radiation emitted by relativistic electrons accelerated behind the forward shock wave driven into the circumstellar medium by the expanding blast shock generated by the supernova explosion.In addition we find evidence for another constituent of emission peaking near 3 GHz whose source remains unclear.Finally, we report on the detection of circularly polarized emission from both components."
    },
    {
        "original_text": "We present the results of an analysis aimed at identifying correlations between supermassive black hole (SMBH) mass and host galaxy properties, using data for a sample of galaxies with SMBH masses determined by reverberation mapping techniques. We find that bulge luminosity is strongly correlated to SMBH mass in both early- and late-type hosts. The correlation strengthens when we consider only those objects whose central regions are dominated by old stellar populations. In addition, we show that there exists a strong correlation between SMBH mass and the velocity dispersion of stars within the bulges of their host galaxies. These relationships can be used as predictors of SMBH mass based on observations of the host galaxy alone. This work was supported by NASA grant NAG5-10842. We thank J. Krolik for providing us with his model predictions prior to publication. \n \n Key words: black holes - galaxies: active",
        "watermark_text": "We present the results of an analysis aimed at identifying correlations between supermassive black hole ( SMBH ) mass and home galaxy properties, using data for a sample of galaxies with SMBH masses determined by reverberation mapping techniques.We find that bulge luminosity is heavily correlated to SMBH mass in both early - and late - type hosts.The correlation strengthens when we think only those objects whose central regions are dominated by old stellar populations.In addition, we show that there exists a strong correlation between SMBH mass and the velocity dispersion of stars within the bulges of their home galaxies.These relationships can be used as predictors of SMBH mass based on observations of the host galaxy alone.This work was supported by NASA grant NAG5 - 10842.We thank J. Krolik for supplying us with his model predictions previous to publication.Key words : black holes - galaxies : active"
    },
    {
        "original_text": "Image registration is an important problem in medical imaging and computer vision, where the goal is to find a transformation that aligns two or more images taken at different times and/or by different sensors. In this work we present evolutionary optimisation methods for template based image registration problems. We consider both rigid and non-rigid transformations between images. The proposed algorithms are tested on synthetic data as well as real world datasets including brain MRI scans and CT angiography (CTA) volumes. Our results show that our approach outperforms state-of-the-art techniques in terms of accuracy while being computationally efficient. This research was supported by EPSRC grant EP/N014560/1. Keywords: Evolutionary Computation, Registration, Non-Rigid Transformation, Rigid Transformation, Brain Imaging, Computer Vision. 1 Introduction Image registration is one of the most fundamental tasks in many areas such as medical imaging [1] , remote sensing [2] , video processing [3] , etc., which aims to find a spatial transformation T that maps each point x ∈ Ω1 = [0, 1]d into its corresponding location y = Tx ∈ Ω2 = [0, 1]d in another image I(y). Here d denotes the dimension of the space. For example, if T1 and T2 denote two consecutive time points in a dynamic sequence of images then finding the optimal transformation T would allow us to track the movement of objects over time [4] . Similarly, if S1 and S2 represent two views of the same scene captured using cameras with slightly differing orientations then registering these images will help us fuse information across multiple viewpoints [5] .\nIn recent years there has been significant interest in developing fast and accurate registration algorithms [6] - [8] . However, despite considerable progress made towards solving this challenging problem [9] - [11] , it remains unsolved due to several factors including large number of degrees of freedom involved [12] , presence of noise [13] , partial occlusions [14] , lack of feature correspondence [15] , etc..",
        "watermark_text": "Image registration is an essential problem in medical imaging and computer vision, where the goal is to locate a transformation that aligns two or more images taken at different times and / or by different sensors.In this work we present evolutionary optimisation methods for template based image register problems.We consider both rigid and non - rigid transformations between pictures.The proposed algorithms are tested on synthetic data as well as reality world datasets like brain MRI scans and CT angiography ( CTA ) volumes.Our results show that our approach outperforms state - of - the - world techniques in terms of accuracy while being computationally efficient.This research was supported by EPSRC grant EP / NO014560 / 1.Keywords : Evolutionary Computation, Registration, Non - Rigid Transformation, Rigid Transformation, Brain Imaging, Computer Vision.1 Introduction Image registration is one of the most fundamental tasks in many areas such as medical imaging[ 1 ], remote sensing [ 2 ], video processing [ 3 ], etc., which aims to find a spatial transformation T that maps each point x ∈ [UNK] = [ 0, 1 ] d into its corresponding place y = Tx ∈ [UNK] = [ 0, 1 ] d in others image I ( y ).Here d denotes the dimension of the space.For example, if T1 and T2 denote two consecutive time points in a dynamic sequence of imagery then finding the ideal transformation T could allow We to track the movement of objects over time [ 4 ].Similarly, if S1 and S2 represent 2 views of the same scene captured using cameras with slightly differing orientations then registering these images will help We fuse info across multi viewpoints [ 5 ].In recent years there has been significant attention in developing fast and accurate registration algorithms[ 6 ] -[ 8 ].However, despite considerable progress made towards solving this challenging problem [ 9 ] - [ 11 ], it remains unsolved due to several factors including large number of degrees of free involved[ 12 ], presence of noise[ 13 ], partial occlusions[ 14 ], lack of feature correspondence[ 15 ], etc."
    },
    {
        "original_text": "We study the dynamics of a population density u(x, t) governed by a nonlinear diffusion equation coupled to an ordinary differential equation for the concentration c(t). The latter describes the evolution of a chemical substance produced and consumed by bacteria at rates proportional respectively to u and cu. We show that if the initial data is sufficiently concentrated then there exists a unique global solution which converges exponentially fast as time goes to infinity towards a stationary state consisting of two Dirac masses located on opposite sides of the origin. This result can be seen as a generalization of the classical theorem due to J. L. Lions concerning the existence of solutions to the steady-state problem associated with the celebrated Keller-Segel system describing chemotaxis phenomena. In addition we prove that this convergence takes place even when the total number of bacteria initially present is less than the critical value predicted by the theory developed by S. Chandrasekhar in order to explain the stability of white dwarfs against gravitational collapse.",
        "watermark_text": "We study the dynamics of a population density u ( x, t ) governed by a nonlinear diffusion equation coupled to an ordinary differential one for the concentration c ( t ).The latter describes the evolution of a chemical substance produced and consumed by bacteria at rates proportional respectively to u and cu.We show that if the initial data is adequately concentrated then there exists a unique worldwide solution which converges exponentially fast as place goes to infinity towards a stationary state consisting of two Dirac masses situated on opposite sides of the origin.This result can be seen as a generalization of the classical theorem due to J. L. Lions concerning the existence of solutions to the steady - state issue associated with the celebrated Keller - Segel system describing chemotaxis phenomena.In addition we prove that this convergence takes place even when the total number of bacteria originally present is less than the critical value anticipated by the theory developed by S. Chandrasekhar in order to explain the stability of white dwarfs against gravitational collapse."
    },
    {
        "original_text": "We report the detection of cosmic far-infrared background (CFIRB) fluctuations using deep observations made by the Far Infrared Surveyor (FIS) onboard Akari satellite at 65 and 90 micron bands in the Lockman Hole field, which is one of the most sensitive fields for detecting extragalactic sources. The FIS has two photometric channels; N60 band covers 60 to 120 microns while WIDE-S channel covers 50 to 100 microns. We used data taken during the period between February 2005 and March 2007. After removing bright point-like objects detected by Spitzer/MIPS 24 micron survey, we performed aperture photometry on all remaining pixels within an area of 1 deg2 centered around the Lockman hole. To estimate the contribution from Galactic cirrus emission, we subtracted the median value of each pixel after applying a 3 sigma clipping method. Then we calculated power spectrum density (PSD) of the residual map. By fitting the PSD with a single power law model, we obtained the best-fit slope as -2.1 ± 0.3 at 65 micron and -1.9 ± 0.4 at 90 micron. These slopes are consistent with those expected from clustering properties of infrared galaxies.",
        "watermark_text": "We report the detection of cosmic far - infrared background ( CFIRB ) fluctuations using deep observations made by the Far Infrared Surveyor ( FIS ) onboard Akari satellite at 65 and 90 micron frequencies in the Lockman Hole field, which is one of the most sensitive fields for detecting extragalactic sources.The FIS has two photometric channels ; N60 band covers 60 to 120 microns while WIDE - S channel covers 50 to 100 microns.We utilized data taken during the time between Feb 2005 and Mar 2007.After removing bright point - like objects detected by Spitzer / MIPS 24 micron survey, we performed aperture photometry on all remaining pixels within an area of 1 deg2 centered around the Lockman hole.To estimate the contribution from Galactic cirrus emission, we subtracted the median value of each pixel after applying a 3 sigma clipping technique.Then we calculated power spectrum density ( PSD ) of the residual map.By fitting the PSD with a single power legal model, we obtained the best - fit slope as - 2. 1 ± zero. 3 at 65 micron and - 1. 9 ± zero. 4 at 90 micron.These slopes are consistent with those expected from clustering properties of infrared galaxies."
    },
    {
        "original_text": "We present the results of an all-sky survey for galaxy clusters using data obtained with the Sunyaev-Zel'dovich effect (SZE) by the Planck satellite, complemented at low redshifts by X-ray observations made with XMM-Newton and Chandra satellites. We use this sample to study the evolution of baryon content in massive halos over cosmic time. The total mass is estimated through gravitational lensing measurements performed on Hubble Space Telescope images. Our main findings are as follows:  1. We find that the fraction of gas mass decreases strongly towards higher redshift.  2. At z < 0.5 we measure fgas = Mgas/Mtot = 0.11 ± 0.01(stat.) ±0.02(sys.), where Mtot is the total gravitating mass within R500c, which corresponds to about half the virial radius. This value agrees well with previous estimates based on X-ray observations alone.  3. For our full cluster sample spanning the range 0.1 < z < 1.3, we obtain fgas = 0.09 ± 0.01(±stat.).",
        "watermark_text": "We present the results of an all - sky survey for galaxy clusters utilizing data obtained with the Sunyaev - Zel ' dovich effect ( SZE ) by the Planck satellite, complemented at low redshifts by X - ray observations made with XMM - Newton and Chandra satellites.We use this sample to study the evolution of baryon concentration in massive halos over cosmic time.The total mass is estimated through gravity lensing measurements conducted on Hubble Satellite Telescope imagery.Our main findings are as follows :1.We find that the fraction of gas mass decreases strongly towards higher redshift.2.At z < 0. 5 we measure fgas = Mgas / Mtot = zero. 11 ± zero. 01 ( stat. )±0. 02 ( sys. ), where Mtot is the total gravitating mass inside R500c, which corresponds to about half the virial radius.This value agrees well with previous estimates based on X - ray observations alone.3.For our full cluster sample spanning the range 0. 1 < z < 1. 3, we obtain fgas = zero. 09 ± 0. 01 ( ±stat. )."
    },
    {
        "original_text": "We present the first results on infrared high-resolution spectroscopy (HRS) of post-AGB disks, obtained with CRIRES/VLT and NIRSPEC/Keck II. We find that the disk around HR 4049 is dominated by emission lines originating in an extended region at temperatures between 1000-2000 K. This temperature range corresponds to the expected location of dust grains which are being evaporated due to stellar radiation pressure. In addition we detect several absorption features which can be attributed to gas-phase molecules such as CO, H2O, OH, NH3, CH4, C2H2, SiO, HCN, CCH, CN, H2S, SO2, CS, and FeH. These observations provide new insights into the physical conditions within these objects. They also show how important it will be for future studies to combine spatially resolved information about the distribution of molecular species with detailed spectroscopic data. \n \n Keywords: circumstellar disk",
        "watermark_text": "We present the first results on infrared high - resolution spectroscopy ( HRS ) of post - AGB discs, obtained with CRIRES / VLT and NIRSPEC / Keck II.We find that the disc around HR 4049 is dominated by discharge lines originating in an extended region at temperatures between 1000 - 2000 K.This temperature range corresponds to the expected location of dust grains which are being evaporated due to star radiation pressure.In addition we detect several absorption features which can be attributed to gas - phase molecules such as CO, H2O, OH, NH3, CH4, C2H2, SiO, HCN, CCH, CN, H2S, SO2, CS, and FeH. These observations provide new insights into the physical conditions within these objects.They also show how significant it will be for future studies to combine spatially resolution information about the distribution of molecular species with detailed spectroscopic data.Keywords : circumstellar disk"
    },
    {
        "original_text": "The present work is devoted to the investigation of new possible nuclear properties using nonlinear methods, namely fractal dimension (FD) and recurrence quantification analysis (RQA). The FD was calculated for different mass number A in order to study its dependence on the system size. It has been found that there exists an optimal value of the scaling parameter which provides the best results for each nucleus separately. This fact indicates that the structure of the studied systems can be characterized as multifractals with non-trivial behavior. In addition we have shown that the obtained values are very close to those predicted by the percolation theory. We also applied RQA method to investigate the temporal evolution of the considered systems. Our calculations show that the complexity of the time series increases with increasing mass number A. Moreover it turns out that this increase follows closely the predictions made within the framework of the Random Matrix Theory. Finally we have compared our results with experimental data available for some light nuclei.",
        "watermark_text": "The present work is devoted to the investigation of new possible nuclear properties utilizing nonlinear techniques, namely fractal dimension ( FD ) and recurrence quantification analytical ( RQA ).The FD was calculated for various mass number A in order to study its dependence on the system size.It has been found that there exists an optimal value of the scaling parameter which provides the best results for each nucleus separately.This fact indicates that the structure of the studied systems can be characterized as multifractals with non - trivial behavior.In addition we have shown that the obtained values are very close to those predicted by the percolation theorist.We also applied RQA method to investigate the temporal evolution of the considered systems.Our calculations show that the complexity of the time series increases with increasing mass number A.Moreover it turns out that this increase follows closely the predictions made within the framework of the Random Matrix Theory.Finally we have compared our results with experiment data available for some light nuclei."
    },
    {
        "original_text": "We present deep spectroscopic observations for a sample of extended Lyα sources (ELAS) selected in the redshift range 3<z<5 using narrowband imaging data obtained with Subaru/Suprime-Cam and VLT/VIMOS. The ELAS are characterized by their large angular sizes, which correspond to physical scales ranging between 1 kpc and 10 Mpc. We find that most of them show spatially resolved emission line profiles consisting of multiple components separated by several hundred km s-1. These results suggest that they may be powered by AGNs or starburst galaxies surrounded by dense gas clouds. In addition, we detect strong absorption lines associated with intervening systems along some sightlines toward these objects. This suggests that our targets are located behind massive halos of neutral hydrogen. Finally, we report on an interesting object showing both spatially unresolved and resolved emission line features. Our study provides new insights into the nature of high-redshift star-forming regions.",
        "watermark_text": "We present deep spectroscopic observations for a sample of extended Lyα sources ( ELAS ) selected in the redshift range 3 < z < 5 using narrowband imaging data obtained with Subaru / Suprime - Cam and VLT / VIMOS.The ELAS are characterized by their big angular sizes, which correspond to physical scales ranging between 1 kpc and 10 Mpc.We find that most of them show spatially resolved emission line profiles consisting of multiple components segregated by several hundred kilometre s - one.These results suggest that they may be powered by AGNs or starburst galaxies surrounded by dense gas clouds.In addition, we detect strong absorption lines associated with intervening systems along some sightlines toward these objects.This suggests that our targets are situated behind massive halos of neutral hydrogen.Finally, we report on an interesting object showing both spatially unresolved and resolved emission line features.Our study provides new insights into the nature of high - redshift star - formation regions."
    },
    {
        "original_text": "We present an open-source, free software package that computes the one-loop Feynman diagrams contributing to the hadronic weak decay amplitudes of heavy quarks into light leptons and pions.  The code is written entirely within the Wolfram Language using only built-in functions.   It can be downloaded at https://github.com/mharrison/harmonic-oscillator-matrix-elements/tree/master/Mathematica_code. We have tested our results against those obtained with FeynArts 3.9 [1] , FormCalc 8 [2] , LoopTools 2 [3] , and QCDLoop [4] . \nThe program has been used to compute the leading-order (LO) contributions to the helicity amplitudes for B meson decays into muons or electrons plus pions [5] .  These are required inputs for the calculation of the branching fractions [6] and CP asymmetries [7, 8] of these processes.  In addition, we provide the LO contribution to the pion form factor [9] .\nOur approach uses the method developed by M. Neubert [10]  which exploits the fact that the relevant loop integrals can all be expressed as linear combinations of products of two-point scalar functions.  This allows us to reduce the number of independent integrations needed to evaluate each diagram to three.  Our implementation also includes several improvements over previous calculations [11, 12] :   1)  We use the exact expression for the propagators of massive fermions instead...",
        "watermark_text": "We present an open - source, free software package that computes the one - loop Feynman diagrams contributing to the hadronic weak decay amplitudes of heavy quarks into light leptons and pions.The code is written entirely within the Wolfram Language using only built - in functions.It can be downloaded at https : / / github. com / mharrison / harmonic - oscillator - matrix - elements / tree / master / Mathematica _ code.We have tested our results against those obtained with FeynArts 3. 9[ 1 ], FormCalc 8 [ 2 ], LoopTools 2[ 3 ], and QCDLoop[ 4 ].The program has been used to compute the leading - order ( LO ) contributors to the helicity amplitudes for B meson decays into muons or electrons plus pions [ 5 ].These are required inputs for the calculation of the branching fractions [ 6 ] and CP asymmetries[ 7, 8 ] of these processes.In addition, we provide the LO contribution to the pion form factor [ 9 ].Our approach uses the method developed by M. Neubert[ 10 ] which exploits the fact that the relevant loop integrals can all be expressed as linear combinations of products of two - point scalar functions.This allows us to reduce the number of independent integrations needed to evaluate each diagram to 3.Our implementation also includes several improvements over previous calculations[ 11, 12 ] : 1 )We use the exact expression for the propagators of massive fermions instead."
    },
    {
        "original_text": "We present an analysis of the X-ray spectra of accreting pulsar systems using a model for Comptonization in hot plasma that includes relativistic effects, such as Doppler boosting and gravitational redshift.  We find that this model provides good fits to the observed pulse profiles and energy-dependent pulse fractions of several sources with luminosities ranging over four orders of magnitude (from 1033 erg s-1 to 1029 erg s-1). The inferred values of the electron temperature are consistent with those expected if these objects radiate at their Eddington limits. In addition, we show how our results can be used to estimate the mass of neutron stars in these systems by comparing the measured fluxes with theoretical predictions based on models of the emission mechanisms. Finally, we discuss possible applications of our method to other types of compact objects. Subject headings: Black holes -accretion disks -X-rays: Sources -Pulsar",
        "watermark_text": "We present an analysis of the X - ray spectra of accreting pulsar systems using a model for Comptonization in heat plasma that contains relativistic effects, such as Doppler boosting and gravitational redshift.We find that this model offers good fits to the observed pulse profiles and energy - dependent pulse fractions of several sources with luminosities ranging over four orders of magnitude ( from 1033 erg s - 1 to 1029 erg s - one ).The inferred values of the electron temperature are consistent with those predicted if these objects radiate at their Eddington limits.In addition, we show how our results can be used to estimate the mass of neutron stars in these systems by comparing the measured fluxes with theory predictions based on models of the emitted mechanisms.Finally, we discuss possible applications of our method to other kinds of compact objects.Subject headings : Black holes - accretion disks - X - rays : Sources - Pulsar"
    },
    {
        "original_text": "We present new spectroscopic observations of galaxies at z ~ 1.5-2.0 selected by their UVJ colors and optical morphologies, obtained with VLT/VIMOS on the Very Large Telescope (VLT). We find that these objects are mostly early-type galaxies showing signs of recent star formation activity. The observed properties suggest that they may be progenitors of local massive elliptical galaxies. These results provide further evidence supporting the scenario where most massive galaxies grow through mergers between gas-rich disk systems during the first half of cosmic time. This is an Open Access article distributed under the terms of the Creative Commons Attribution License 2.0, which permits unrestricted use, distribution, and reproduction in any medium provided the original work is properly cited. \n \n Keywords: galaxy evolution; merger remnants; young ellipticals; CDF-S field \n \n Massive galaxies evolve rapidly over cosmic time as a result of merging processes involving smaller companions. In particular, it has been suggested that many of today's brightest cluster galaxies were formed via major mergers of two or more gas-rich disks at redshifts around one to three [1] . However, direct observational evidence for this process remains elusive because of the difficulty in identifying such events at high redshift [2] .\n \nIn order to study the physical mechanisms driving galaxy growth we have carried out deep spectroscopy of galaxies at intermediate redshifts using the VLT-VIMOS spectrograph [3] . Our sample consists of about 100 galaxies selected based on their ultraviolet J (UVJ) color [4] , morphological type [5] , and apparent magnitude [6] . Most of them show strong emission lines characteristic of active star-forming regions [7, 8] . Their stellar masses range from 10^10 M_sol to 10^11 M_sol [9] . \n\n\nThe main goal of our project was to identify possible candidates for progenitor populations of local massive elliptical/S0 galaxies [10] . To do so, we used several selection criteria designed to select galaxies with similar characteristics to those found among nearby massive spheroids [11] : \n\n\n1. Morphological type: all targets must",
        "watermark_text": "We present fresh spectroscopic observations of galaxies at z ~ 1. 5 - 2. 0 selected by their UVJ colors and optical morphologies, obtained with VLT / VIMOS on the Very Large Telescope ( VLT ).We find that these objects are mostly early - like galaxies showing signs of recent star formation activity.The observed properties suggest that they may be progenitors of local massive elliptical galaxies.These results provide further evidence supporting the scenario where most massive galaxies grow through mergers between gas - rich disc systems during the first half of cosmic time.This is an Open Access article distributed under the terms of the Creative Commons Attribution License 2. 0, which permits unrestricted use, distribution, and reproduction in any medium provided the original work is properly cited.Keywords : galaxy evolution ; merger remnants ; young ellipticals ; CDF - S field Massive galaxies evolve rapidly over cosmic time as a result of merging processes involving smaller companions.In particular, it has been suggested that many of today ' s brightest cluster galaxies were formed via major merges of two or more gas - rich disks at redshifts around one to three [ 1 ].However, direct observational evidence for this process remains elusive because of the difficulty in identification such events at high redshift [ 2 ].In order to study the physical mechanisms driving galaxy growth we have carried out deep spectroscopy of galaxies at intermediate redshifts using the VLT - VIMOS spectrograph [ 3 ].Our sample consists of about 100 galaxies selected based on their ultraviolet J ( UVJ ) color [ 4 ], morphological type [ 5 ], and apparent magnitude[ 6 ].Most of them show strong emission lines characteristic of active star - formation regions [ 7, 8 ].Their stellar masses range from 10 ^ 10 M _ sol to 10 ^ 11 M _ sol[ 9 ].The main goal of our project was to identify possible candidates for progenitor populations of local massive elliptical / S0 galaxies [ 10 ].To do so, we used several selection criteria designed to select galaxies with similar characteristics to those found amongst nearby massive spheroids [ 11 ] : 1.Morphological type : all targets must"
    },
    {
        "original_text": "We report on the controlled collision between an individual trapped atom and a singly charged ion in a Paul trap, where both particles are confined to different regions of space separated by several micrometers. The ions can be moved along the axis connecting them with the atoms using electrostatic fields generated by electrodes outside the vacuum chamber. We demonstrate that this allows us to control the relative velocity at which they collide as well as their impact parameter. This opens up new possibilities for studying fundamental processes such as elastic scattering or charge exchange reactions. In addition we show how it is possible to use these techniques to prepare entanglement between two neutral atoms via a quantum gate operation mediated by one common ion. Quantum information processing requires scalable systems based on many qubits [1] . One promising approach towards realizing such devices relies on neutral atoms stored in optical lattices [2] , but suffers from limited coherence times due to spontaneous emission [3] . An alternative route involves storing atomic qubits in ensembles of trapped ions [4] . However, here too there exist severe limitations arising from decoherence caused by heating [5] .\nIn order to overcome these difficulties, hybrid approaches have been proposed [6] combining advantages of both schemes [7, 8] . Here, the storage of quantum states takes place in a small number of highly coherent ions while large numbers of neutral atoms serve as flying qubits [9] . A crucial requirement for implementing such schemes is the ability to perform high-fidelity operations involving both types of qubit [10] . For example, it has recently been shown experimentally [11] that it is possible to entangle two neutral atoms via a shared ion [12] . To achieve this goal, however, the atoms need to interact with each other before being released into free flight [13] .",
        "watermark_text": "We report on the controlled collision between an individual trapped atom and a singly charged ion in a Paul capture, where both particles are confined to different areas of space separated by several micrometers.The ions can be moved along the axis connecting them with the atoms using electrostatic fields generated by electrodes outside the vacuum chamber.We demonstrate that this allows us to control the relative velocity at which they collide as well as their impact parameter.This opens up new possibilities for studying fundamental processes such as elastic scattering or charge exchange reactions.In addition we show how it is possible to use these techniques to prepare entanglement between two neutral atoms via a quantum gateway operation mediated by 1 common ion.Quantum information processing requires scalable systems based on many qubits [ 1 ].One promising approach towards realizing such devices relies on neutral atoms storage in optical lattices[ 2 ], but suffers from limited coherence times due to spontaneous emission[ 3 ].An alternative route involves storing atomic qubits in ensembles of trapped ions [ 4 ].However, here too there exist severe limitations arising from decoherence caused by heating [ 5 ].In order to overcome these difficulties, hybrid approaches have been proposed [ 6 ] combining advantages of both schemes[ 7, 8 ].Here, the storage of quantum states performs place in a small number of highly coherent ions while large numbers of neutral atoms serve as flying qubits [ 9 ].A crucial requirement for executing such schemes is the ability to perform high - fidelity operations involving both types of qubit [ 10 ].For example, it has recently been shown experimentally [ 11 ] that it is possible to entangle two neutral atoms via a common ion[ 12 ].To achieve this goal, however, the atoms need to interact with each other before being released into freedom flight[ 13 ]."
    },
    {
        "original_text": "We propose that the energy release process in coronal mass ejections (CMEs) is due to two different physical mechanisms, magnetic reconnection and catastrophic loss of equilibrium driven by ideal magnetohydrodynamic (MHD) instabilities.  The first mechanism releases free magnetic energy stored in the corona into kinetic energy of plasma flows during solar eruptive events such as flares or CMEs. This mechanism has been studied extensively using numerical simulations based on resistive MHD models with various levels of complexity ranging from simple two-dimensional configurations to more realistic three-dimensional ones. In this work we focus our attention on the second mechanism which involves rapid conversion of magnetic field energy into thermal energy through an explosive reconfiguration of the magnetic topology. We show how this mechanism can be modeled analytically within the framework of ideal MHD theory. Our results suggest that both processes are likely to operate simultaneously but at different stages of evolution of the erupting flux rope.",
        "watermark_text": "We propose that the energy release process in coronal mass ejections ( CMEs ) is due to two different physical mechanisms, magnetic reconnection and catastrophic loss of equilibrium driven by ideal magnetohydrodynamic ( MHD ) instabilities.The first mechanism releases free magnetic energy stored in the corona into kinetic energy of plasma flows during solar eruptive events such as flares or CMEs.This mechanism has been studied extensively using numerical simulations based on resistive MHD models with various levels of complexity ranging from simple two - dimensional configurations to more real three - dimensional ones.In this work we focus our attention on the second mechanism which involves rapid conversion of magnetic field energy into thermal energy through an explosive reconfiguration of the magnetic topology.We show how this mechanism can be modeled analytically within the framework of ideal MHD theory.Our results suggest that both processes are probable to operate simultaneously but at different stages of evolution of the erupting flux rope."
    },
    {
        "original_text": "The Astrodynamics Space Test of Relativity using Optical Devices (ASTROD) mission is proposed as an experiment for testing the gravitational theory in space, and it will be launched into orbit around L2 point by 2020.  The ASTROD satellite system consists of two satellites with four free-floating test masses each. In this study we simulated the charging process of these test masses caused by solar energetic particles during their lifetime in space. We used the SPENVIS software package developed at the European Space Research and Technology Centre (ESTEC). Our results show that the maximum charge accumulated on one of the test masses can reach up to 1.5 nC after 10 years' exposure time. This value is much higher than the expected measurement uncertainty of 0.1 nC. Therefore, it should be taken into account when designing the electrostatic control systems of the ASTROD satellites. Keywords: Charging, Solar Energetic Particles, ASTROD",
        "watermark_text": "The Astrodynamics Space Test of Relativity using Optical Devices ( ASTROD ) mission is proposed as an experiment for testing the gravitational theory in space, and it will be launched into orbit around L2 point by 2020.The ASTROD satellite system consists of 2 satellites with 4 free - floating test masses each.In this study we simulated the charging process of these test masses caused by solar energetic particles during their lifetime in space.We used the SPENVIS software package developed at the European Space Research and Technology Center ( ESTEC ).Our results show that the maximum charge accumulated on one of the trial masses can reach up to 1. 5 nC after 10 years ' exposure time.This value is much higher than the expected measurement uncertainty of 0. 1 nC.Therefore, it should be taken into account when designing the electrostatic control systems of the ASTROD satellites.Keywords : Charging, Solar Energetic Particles, ASTROD"
    },
    {
        "original_text": "We present new observations of the nuclear region in the nearby radio galaxy NGC315, made using the Chandra X-ray Observatory (CXO) and the Very Large Array (VLA). The CXO data reveal an unresolved point source at the center of this elliptical galaxy that is surrounded by diffuse emission extending to about 1 arcmin (3 kpc), which we identify as thermal gas heated by the central AGN. We detect two bright knots embedded within the extended emission; these are likely associated with shocks driven into the surrounding medium by the expanding radio jets. Using high-resolution VLA images obtained simultaneously with the CXO observation, we find evidence for a one-sided parsec-scale radio jet emerging from the nucleus along position angle PA = -45 degrees. This jet has been previously detected on larger scales out to several kiloparsecs. In addition, there appears to be another fainter component of the radio jet located further south-west than the main knot.",
        "watermark_text": "We present new observations of the nuclear region in the nearby radio galaxy NGC315, made utilizing the Chandra X - ray Observatory ( CXO ) and the Very Large Array ( VLA ).The CXO data reveal an unresolved point source at the centre of this elliptical galaxy that is surrounded by diffuse emission extending to about 1 arcmin ( 3 kpc ), which we identify as thermal gas heated by the central AGN.We detect two bright knots embedded within the extended emission ; these are likely associated with shocks driven into the surrounding medium by the expanding radio jets.Using high - resolution VLA images obtained simultaneously with the CXO observation, we find evidence for a one - way parsec - scale radio jet emerging from the nucleus along position angle PA = - 45 degrees.This jet has been previously detected on bigger scales out to many kiloparsecs.In addition, there appears to be another fainter component of the radio jet located further south - west than the main knot."
    },
    {
        "original_text": "We study the dynamics of Lorentzian brane-worlds with time dependent bulk cosmological constant in the context of Randall-Sundrum type II models, where we allow for both positive and negative values of the bulk cosmological constant. We show that there are two branches of solutions corresponding to either an expanding or contracting universe on the brane depending upon whether the bulk cosmological constant is positive or negative respectively. In addition, we find that these solutions can be smoothly connected by a branch of static solutions which correspond to Minkowski space-time on the brane. Finally, we also consider the possibility of having a change of signature across the brane and discuss how this affects our results. The main motivation behind studying braneworld scenarios comes from the fact that they provide us with a natural framework within which one may address some of the fundamental issues related to quantum gravity such as the hierarchy problem [1] . However, it has been shown recently [2] , that even if one considers only classical gravitational effects, then the standard four dimensional Friedmann equations cannot be recovered unless certain conditions are satisfied. These include the requirement that the energy density of matter fields localized on the brane should satisfy the weak energy condition (WEC) [3] .\nIn order to overcome this difficulty, several authors have considered different approaches [4] - [8] . For example, in ref. [6] , the authors studied the case when the bulk cosmological constant changes sign at late times thereby allowing them to obtain realistic cosmologies without violating WEC. On the other hand, in ref. [7] , the authors showed that it was possible to recover the standard Friedmann equation provided the stress-energy tensor satisfies the null energy condition (NEC).",
        "watermark_text": "We study the dynamics of Lorentzian brane - worlds with time based bulk cosmological constant in the context of Randall - Sundrum type II models, where we allow for both positive and negative values of the bulk cosmological constant.We show that there are two branches of solutions corresponding to either an expanding or contracting universe on the brane depending atop whether the bulk cosmological constant is positive or negative respectively.In addition, we find that these solutions can be smoothly connected by a branch of static solutions which correspond to Minkowski space - time on the brane.Finally, we also consider the possibility of having a change of signature across the brane and discuss how this affects our findings.The main motivation towards studying braneworld situations comes from the fact that they provide us with a natural framework within which one may address some of the fundamental issues related to quantum gravity such as the hierarchy problem [ 1 ].However, it has been shown recently [ 2 ], that even if one considers only classical gravitational effects, then the standard 4 dimensional Friedmann equations never be recovered except certain conditions are satisfied.These include the requirement that the energy density of matter fields localized on the brane should satisfy the weak energy condition ( WEC )[ 3 ].In order to overcome this difficulty, several writers have considered different approaches[ 4 ] -[ 8 ].For example, in ref.[ 6 ], the authors studied the case when the bulk cosmological constant changes sign at late times thereby permitting them to obtain realistic cosmologies without violating WEC.On the other hand, in ref.[ 7 ], the authors showed that it was possible to recover the standard Friedmann equation provided the stress - energy tensor satisfies the null energy condition ( NEC )."
    },
    {
        "original_text": "Transcription factors (TFs) are proteins that bind specific sequences in the genome and regulate gene expression by recruiting other regulatory molecules or directly modulating RNA polymerase activity. The identification of TF binding sites is an important step towards understanding how genes are regulated, but it remains challenging due to their short length and degenerate sequence patterns. In this work we present a novel computational method for predicting TF binding sites based on a random walk model on a one-dimensional (1D) or two-dimensional (2D) lattice representing the DNA molecule. We show that our approach outperforms state-of-the-art methods when applied to several datasets containing experimentally validated binding sites. Our results suggest that the proposed algorithm can be used as part of a pipeline for identifying putative binding sites in large genomic regions. Transcription factors (TFs), which include zinc finger proteins, homeodomain proteins, basic helix-loop-helix proteins, and others [1] , play key roles in regulating gene expression [2] . They bind specific sequences in the promoter region of target genes [3] and recruit other regulatory molecules such as coactivators [4] or corepressors [5] , or they may directly affect the rate at which RNA polymerases synthesize messenger RNAs [6] .\nThe identification of TF binding sites has been shown to be useful for studying gene regulation [7, 8] . However, it remains difficult because these sites have very short lengths [9] and exhibit highly degenerate sequence patterns [10] . Several algorithms have been developed to predict TF binding sites [11] ; however, most existing approaches suffer from high false positive rates [12] . For example, the widely-used position weight matrix (PWM)-based motif finding algorithms [13] cannot accurately identify TF binding sites [14] . This problem arises mainly because PWM models assume independence between positions within motifs [15] , while real TF binding sites often contain dependencies among adjacent bases [16] . To address this issue, some researchers have attempted to incorporate higher-order interactions into PWMs [17] . Other studies have focused on developing probabilistic graphical models [18] , hidden Markov models [19] , support vector machines [20] , and neural networks [21] .",
        "watermark_text": "Transcription factors ( TFs ) are proteins that bind particular sequences in the genome and regulate gene expression by recruiting other regulation molecules or directly modulating RNA polymerase activity.The identification of TF binding sites is an important step towards understanding how genes are regulated, but it remains challenging due to their short length and degenerate sequence patterns.In this work we present a novel computational methodology for predicting TF binding sites based on a randomly walk model on a single - dimensional ( 1D ) or two - dimensions ( 2D ) lattice representing the DNA molecule.We show that our approach outperforms state - of - the - art methods when applied to several datasets holding experimentally validated binding sites.Our results suggest that the proposed algorithm can be used as part of a pipeline for identification putative binding locations in large genomic regions.Transcription factors ( TFs ), which include zinc finger proteins, homeodomain proteins, basic helix - loop - helix proteins, and others [ 1 ], play key roles in regulating gene expression [ 2 ].They bind specific sequences in the promoter area of target genes [ 3 ] and recruit other regulator molecules such as coactivators [ 4 ] or corepressors [ 5 ], or they may directly affect the rate at which RNA polymerases synthesize messenger RNAs [ 6 ].The identification of TF binding sites has been shown to be useful for studying genetic regulation [ 7, 8 ].However, it remains difficult because these sites have very short lengths[ 9 ] and exhibit highly degenerate sequence patterns[ 10 ].Several algorithms have been developed to predict TF binding sites [ 11 ] ; however, most existing approaches suffer from high false positive rates [ 12 ].For example, the widely - utilized position weight matrix ( PWM ) - basis motif discovery algorithms[ 13 ] cannot accurately identify TF binding sites[ 14 ].This problem arises mainly because PWM models assume independence between roles within motifs[ 15 ], while real TF binding sites often contain dependencies amongst adjacent bases [ 16 ].To address this issue, some researchers have tried to incorporate higher - order interactions into PWMs [ 17 ].Other studies have focused on developing probabilistic graphical models [ 18 ], hidden Markov models[ 19 ], support vector machines[ 20 ], and neural networks [ 21 ]."
    },
    {
        "original_text": "The development of large space telescopes requires the use of lightweight materials to reduce launch costs and increase telescope performance in orbit. Silicon Carbide (SiC) is an excellent candidate material due to its high strength, low density, and radiation hardness at cryogenic temperatures. However, it has been shown that SiC exhibits significant changes in thermal expansion with temperature which can lead to dimensional instability during cool-downs or warm-ups. This work presents results on the measurement of the coefficient of thermal expansion (CTE) of SiC-100 over a wide range of temperatures using a novel technique based on laser interferometry. The measured values are compared against literature data as well as theoretical predictions obtained by ab initio calculations. It was found that the experimental measurements agree very well with theory within the uncertainty limits. These results will be used to improve the design of future space missions such as JWST and WFIRST-AFTA.",
        "watermark_text": "The development of big space telescopes requires the use of lightweight materials to reduce rocket costs and raise telescope performance in space.Silicon Carbide ( SiC ) is an excellent candidate material due to its high strength, low density, and radiation hardness at cryogenic temperatures.However, it has been shown that SiC exhibits significant changes in thermal expansion with heat which can lead to dimensional instability during cool - downs or warmth - ups.This work presents results on the measurement of the coefficient of thermal expansion ( CTE ) of SiC - 100 over a wide range of temperatures using a novel technique based on laser interferometry.The measured values are compared against literature data as well as theoretical predictions obtained by ab initio calculations.It was found that the experimental measurements agree very well with theory inside the uncertainty limits.These results will be used to enhance the design of next space missions such as JWST and WFIRST - AFTA."
    },
    {
        "original_text": "We report the discovery and analysis of an X-ray transient source IGR J17254-3257 in outburst during June 2009 with INTEGRAL/Swift/BAT. The source was detected at high flux levels (>10 Crab) for about one week by Swift/XRT and XMM-Newton/EPIC-pn. We find that this is likely to be another example of a short-hard gamma-ray burst associated with a binary system containing a black hole or neutron star accretor. A comparison between our results on IGR J17254−3257 and those obtained previously for other similar sources suggests that there may exist two different classes of such systems. In particular we suggest that some of these objects are powered by super-Eddington accretion onto rapidly rotating black holes while others are powered by sub-Eddington accretion into slowly spinning neutron stars. This work has been supported by NASA under contract NAS8-03060.",
        "watermark_text": "We report the discovery and analysis of an X - ray transient source IGR J17254 - 3257 in outburst during June 2009 with INTEGRAL / Swift / BAT.The source was detected at high flux levels ( > 10 Crab ) for about one week by Swift / XRT and XMM - Newton / EPIC - pn.We find that this is probable to be another example of a short - hard gamma - ray burst associated with a binary system containing a black hole or neutron star accretor.A comparison between our results on IGR J17254−3257 and those obtained previously for other similar sources suggests that there may exist two different classes of such systems.In particular we suggest that some of these objects are powered by super - Eddington accretion onto rapidly rotating black holes while another are powered by sub - Eddington accretion into slow spinning neutron stars.This work has been supported by NASA under contractor NAS8 - 03060."
    },
    {
        "original_text": "We study the fractional charge and statistics of elementary excitations in quantum spin systems with frustration, using exact diagonalization techniques for small clusters up to 12 sites. We find that the ground state is always gapped and has no degeneracy. The elementary excitations are fractionally charged fermions or bosons depending on whether the system is antiferromagnetic (AF) or ferromagnetic (F). In AF cases we also observe neutral fermionic excitations which carry zero electric charge but have nontrivial braiding properties. These results can be understood by mapping our models onto effective lattice gauge theories where the elementary excitations correspond to particles carrying flux quanta. Our work provides an explicit example of how fractional charges emerge naturally as topological defects in strongly correlated electronic materials. Introduction:-The discovery of high temperature superconductivity in copper oxide compounds [1] , together with other exotic phenomena such as colossal magnetoresistance [2] , non-Fermi liquid behavior [3] etc., has led to renewed interest in understanding the physics of strongly interacting electrons. One of the most important open questions concerns the nature of the elementary excitations responsible for these novel behaviors [4] . It was suggested early on [5] that the elementary excitations may be described by some kind of collective modes known as spin waves [6] . However it soon became clear [7, 8] that this description fails at low energies due to strong electron correlations. More recently there has been considerable progress towards developing theoretical descriptions based on new concepts like fractionalized quasiparticles [9] , emergent gauge fields [10] , and topological order [11] .\nIn particular, recent experiments [12] suggest that the elementary excitations in the cuprates might indeed be described by some form of fractionalized quasiparticle [13] . This raises many interesting questions about their physical properties including their charge [14] , statistics [15] , and interactions [16] . Unfortunately, despite enormous efforts [17] , a complete microscopic theory describing all these aspects remains elusive [18] . A promising approach involves studying simplified model Hamiltonians [19, 20] whose low-energy limit captures essential features of the original problem [21] .",
        "watermark_text": "We study the fractional charge and statistics of elementary excitations in quantum spin systems with frustration, using exact diagonalization methods for small clusters up to 12 sites.We find that the ground state is always gapped and has no degeneracy.The elementary excitations are fractionally charged fermions or bosons depending on whether the system is antiferromagnetic ( AF ) or ferromagnetic ( F ).In AF cases we also observe neutral fermionic excitations which carry zero electric charge but have nontrivial braiding properties.These results can be understood by mapping our models onto effective lattice gauge theories where the elementary excitations correspond to particles carrying flux quanta.Our work provides an explicit example of how fractional charges emerge naturally as topological defects in strongly correlated electronic materials.Introduction : - The discovery of high temperature superconductivity in copper oxide compounds [ 1 ], together with other exotic phenomena such as colossal magnetoresistance [ 2 ], non - Fermi liquid behavior [ 3 ] etc., has led to renewed interest in understanding the physics of strongly interacting electrons.One of the most important open questions concerns the nature of the elementary excitations responsible for these novel behaviors [ 4 ].It was suggested early on [ 5 ] that the elementary excitations may be described by some sort of group modes known as spin waves [ 6 ].However it soon became clear [ 7, 8 ] that this description fails at low energies due to strongly electron correlations.More recently there has been considerable improvement towards developing theoretical descriptions based on novel concepts like fractionalized quasiparticles [ 9 ], emergent gauge fields[ 10 ], and topological order [ 11 ].In particular, recent experiments [ 12 ] suggest that the basic excitations in the cuprates might indeed be described by some form of fractionalized quasiparticle[ 13 ].This raises many interesting questions about their physical properties including their charge [ 14 ], statistics[ 15 ], and interactions [ 16 ].Unfortunately, despite enormous efforts [ 17 ], a complete microscopic theory describing all these aspects remains elusive [ 18 ].A promising approach involves studying simpler model Hamiltonians[ 19, 20 ] whose low - energy limit captures essential features of the original problem[ 21 ]."
    },
    {
        "original_text": "The aim of this work is to study the effect of different assembly procedures, as well as different contact laws between particles in powder compaction processes using computer simulations. The results show that the packing density depends strongly on the applied pressure during the assembly process. In addition, it was found that the densification behavior can be influenced by changing the contact law parameters. Finally, we have shown how the microstructure evolves with increasing pressure for two different types of particle contacts. Powder compaction has been studied extensively over many years due to its importance in various industrial applications such as pharmaceutical tablets or metal parts produced via hot pressing techniques [1] . However, despite these efforts there are still open questions regarding the underlying mechanisms governing the densification behavior under external loads [2] .\nIn order to understand the complex phenomena occurring inside compacted materials, several experimental studies were performed [3] , which revealed important information about the evolution of the microstructure [4] . Nevertheless, experiments cannot provide detailed insight into the local interactions taking place at the grain scale [5] . Therefore, numerical methods based on discrete element models (DEM) [6] became an alternative approach to investigate the mechanical properties of granular systems [7, 8] . These DEM-based approaches allow one to track individual grains within large assemblies and thus enable us to obtain valuable insights into the micromechanical response [9] . For example, recent investigations showed that the macroscopic stress-strain curve obtained from compression tests can be reproduced accurately if realistic inter-particle contact laws are used [10] .",
        "watermark_text": "The aim of this work is to study the effect of various assembly procedures, as well as different contact laws between particles in powder compaction processes utilizing computer simulations.The results show that the packing density depends strongly on the applied pressure during the assembly procedure.In addition, it was found that the densification behaviour can be influenced by changing the contact law parameters.Finally, we have shown how the microstructure evolves with increasing force for two different types of particle contacts.Powder compaction has been studied extensively over many years due to its significance in different industrial applications such as pharmaceutical tablets or metal parts produced via heat pressing techniques [ 1 ].However, despite these efforts there are still open questions regarding the underlying mechanisms regulating the densification behavior under external loads [ 2 ].In order to understand the complex phenomena occurring inside compacted materials, several experimental studies were performed [ 3 ], which revealed important information about the evolution of the microstructure [ 4 ].Nevertheless, experiments cannot provide detailed input into the local interactions taking place at the grain scale [ 5 ].Therefore, numerical methods based on discrete element models ( DEM )[ 6 ] became an alternative approach to investigate the mechanical properties of granular systems[ 7, 8 ].These DEM - based approaches allow one to track single grains inside large assemblies and thus enable us to obtain valuable insights into the micromechanical response [ 9 ].For example, recent investigations showed that the macroscopic stress - strain curve obtained from compression tests can be reproduced accurately if real inter - particle contact laws are used [ 10 ]."
    },
    {
        "original_text": "We study the gravitational field equations for static spherically symmetric configurations on Randall-Sundrum type II brane-worlds with bulk cosmological constant and matter fields localized on the branes. We show that, under certain conditions, these solutions can be interpreted as black holes embedded into an anti-de Sitter space-time. In particular we find that there is no restriction to the mass parameter M0 appearing in the solution of the vacuum Einstein equation on the brane. The corresponding horizon radius r0 satisfies the relation r0 = (3M0/4π)1/3. This result implies that the Schwarzschild-de Sitter metric describes not only black hole but also naked singularity solutions. Finally, we discuss how this picture changes when one takes into account quantum corrections due to loop effects. PACS numbers: 04.20.-q; 11.10.Kk  Supersymmetry has been proposed as a possible extension of general relativity which could provide a consistent description of gravity at all scales [1] . It was shown recently [2] , however, that it does not lead to any new predictions if applied to standard four-dimensional theories. On the other hand, higher dimensional extensions of supergravity have attracted considerable attention during recent years [3] .\nIn this letter we consider five-dimensional supergravities [4] where the extra dimension is compactified on a circle [5] or orbifold [6] . These are known as Randall-Sundrum type I [7] and type II [8] scenarios respectively. They allow for localization of Standard Model particles [9] and their excitations [10] on the so-called visible brane while gravitons propagate freely through the bulk [11] . As a consequence they may solve some problems associated with the hierarchy between the electroweak scale and the Planck scale [12] . Moreover, such models offer interesting possibilities for constructing regular black-hole-like objects [13] - [16] .",
        "watermark_text": "We study the gravitational field equations for static spherically symmetric arrangements on Randall - Sundrum type II brane - worlds with bulk cosmological constant and matter fields localized on the branes.We show that, under certain conditions, these solutions can be interpreted as dark holes embedded into an anti - de Sitter space - time.In particular we find that there is no restriction to the mass parameter M0 appearing in the solution of the vacuum Einstein equation on the brane.The corresponding horizon radius r0 satisfies the relation r0 = ( 3M0 / 4π ) 1 / 3.This result implies that the Schwarzschild - de Sitter metric describes not only black hole but also naked singularity solutions.Finally, we discuss how this picture changes when one takes into consideration quantum corrections due to loop effects.PACS numbers : 04. 20. - q ; 11. 10. Kk Supersymmetry has been proposed as a possible extend of general relativity which could provide a consistent description of gravity at all scales [ 1 ].It was presented recently [ 2 ], however, that it does not lead to any new predictions if applied to standard four - dimensional theories.On the other hand, upper dimensional extensions of supergravity have attracted considerable attention during modern years [ 3 ].In this letter we consider five - dimensions supergravities [ 4 ] where the extra dimensional is compactified on a circle [ five ] or orbifold [ 6 ].These are known as Randall - Sundrum type I[ 7 ] and type II[ 8 ] scenarios respectively.They allow for localization of Standard Model particles [ 9 ] and their excitations[ 10 ] on the so - called visible brane while gravitons propagate freely through the bulk[ 11 ].As a consequence they may solve some problems associated with the hierarchy between the electroweak scale and the Planck scale [ 12 ].Moreover, such models provide interesting possibilities for constructing regular black - hole - like objects[ 13 ] -[ 16 ]."
    },
    {
        "original_text": "The statistical mechanics of time-independent non-dissipative nonequilibrium states is studied in the framework of generalized entropy production and fluctuation theorem. The main results are formulated for systems with discrete energy levels, but they can be extended to continuous spectrum as well. It is shown that the probability distribution function (PDF) of the total entropy production has an exponential tail at large values of entropy production. This result agrees with recent experimental data on PDFs of heat fluxes between two reservoirs connected by a single molecule junction. In addition it is demonstrated how this approach allows one to calculate the average value of the total entropy production and its fluctuations. Finally we discuss possible applications of these results to transport phenomena in molecular junctions. We show that our theory predicts correctly the dependence of the current-voltage characteristics on temperature difference between the leads. Statistical mechanics of time independent non-dissipative non-equilibrium states is studied within the framework of generalized entropy-production and fluctuation theorem. Main results are formulated for systems having discrete energy-levels, however extension to continuum spectra is also discussed. It is shown that probability-distribution-function (PDF) of total entropy-production has exponential tails at large values of entropy-production. This result agrees with recently obtained experimental data on PDF's of heat-fluxes between two reservoirs coupled via a single-molecule-junction. In addition it is shown how this approach allows us to calculate the average-value of total entropy-production and it's fluctuations. Finally we discuss possibilities of applying these results to transport phenomena occurring in molecular junctions.",
        "watermark_text": "The statistical mechanics of time - independent non - dissipative nonequilibrium states is studied in the framework of generalized entropy production and fluctuation theorem.The main results are formulated for systems with discrete energetic levels, but they can be extended to continuous spectrum as well.It is shown that the probability distribution function ( PDF ) of the total entropy production has an exponential tail at large values of entropy production.This result agrees with recent experimental data on PDFs of heat fluxes between 2 reservoirs linked by a one molecule junction.In addition it is demonstrated how this approach allows one to calculate the average value of the total entropy production and its fluctuations.Finally we discuss possible applications of these results to transport phenomena in molecule junctions.We show that our theory predicts correctly the dependence of the current - voltage properties on temperature difference between the leads.Statistical mechanics of time independent non - dissipative non - equilibrium states is studied within the framework of generalized entropy - production and fluctuation theorem.Main results are formulated for systems having discrete energy - levels, however extension to continuum spectra is also discussed.It is shown that probability - distribution - function ( PDF ) of total entropy - production has exponential tails at big values of entropy - produced.This result agrees with recently obtained experimental data on PDF ' s of hot - fluxes between two reservoirs coupled via a single - molecule - junction.In addition it is shown how this approach allows us to calculate the average - value of total entropy - produced and it ' s fluctuations.Finally we discuss possibilities of applying these results to transport phenomena occurring in molecular junctions."
    },
    {
        "original_text": "We present new exact solutions to the Einstein field equations for stationary axisymmetric spacetimes with two commuting Killing vectors, which are generated by applying nonholonomic frame transforms (NFT) to known vacuum solutions. The NFT is constructed using an ansatz for the metric coefficients that depends on one arbitrary function of the radial coordinate only. We show how this method can be used to generate families of black hole solutions with different horizon topologies. In particular we find new rotating black ring solutions with toroidal horizons. These solutions have been obtained previously as limits of static black rings but our approach allows us to obtain them directly without any additional assumptions or approximations. Finally, we discuss some open problems related to these results. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq \nI. INTRODUCTORY REMARkS\nThe study of exact solutions to the Einstein equations has played a crucial role in understanding many aspects of general relativity. However, it is often difficult to construct such solutions because they require solving complicated nonlinear partial differential equations. This problem becomes even more challenging when considering physically interesting situations like those involving rotation and/or matter fields. Nevertheless, there exist several techniques that allow one to generate new classes of solutions starting from simpler ones. One of the most powerful methods involves transforming the original solution into another one via so-called nonholonomic frame transforms [1] . Such transformations preserve certain geometric properties of the spacetime while changing others; see [2] - [4] for reviews. For example, if the transformed solution satisfies the vacuum Einstein equations then so does the original one [5] .\nIn this work we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations in order to generate new exact solutions describing stationary axisymmetric spacetimes: i.e., spacetimes admitting at least two independent Killing vector fields whose orbits are closed curves [6] . Stationary axisymmetric spacetimes play an important role in astrophysics since they describe the exterior gravitational field of spinning objects like stars, planets, and black holes [7, 8]",
        "watermark_text": "We present new precise solutions to the Einstein field equations for stationary axisymmetric spacetimes with two commuting Killing vectors, which are generated by applying nonholonomic frame transforms ( NFT ) to known vacuum solutions.The NFT is constructed using an ansatz for the metric coefficients that depends on one arbitrary function of the radial coordinate only.We show how this methodology can be used to generate families of black hole solutions with different horizon topologies.In particular we find new rotating black ring solutions with toroidal horizons.These solutions have been obtained previously as limits of static black rings but our approach permits us to obtain them directly without any additional assumptions or approximations.Finally, we discuss some open problems related to these results.PACS numbers : 04. 20. - q, 11. 10. - z, 98. 80. Cq I. INTRODUCTORY REMARkSThe study of exact solutions to the Einstein equations has played a vital role in studying many aspects of general relativity.However, it is often difficult to construct such solutions because they require solving complex nonlinear partial differential equations.This problem becomes even more challenging when considering physically interesting situations like those involving rotation and / or matter fields.Nevertheless, there exist several techniques that allow one to generate new classes of solutions starting from simplified ones.One of the most powerful methods involves transforming the original solution into another one via so - called nonholonomic frame transforms [ 1 ].Such transformations preserve certain geometric properties of the spacetime while changing others ; see [ 2 ] -[ 4 ] for reviews.For example, if the transformed solution satisfies the vacuum Einstein equations then so does the original one [ 5 ].In this work we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations in order to generate newly exact solutions describing stationary axisymmetric spacetimes : i. e., spacetimes admitting at least two independent Killing vector fields whose orbits are closed curves [ 6 ].Stationary axisymmetric spacetimes play an important role in astrophysics since they describe the exterior gravitational field of spinning objects like stars, planets, and black holes[ 7, 8 ]"
    },
    {
        "original_text": "We propose to cool fermionic atoms in optical lattices by using the pairing mechanism between two different hyperfine states, which is analogous to Cooper pair formation in superconductors. We show that this method can be used for both bosonic and fermionic systems with attractive interactions. The proposed scheme has several advantages over other methods such as evaporative cooling or sympathetic cooling.  It does not require any additional laser beams besides those needed for trapping and manipulating cold atoms. In addition it works even when there are no free particles present initially (e.g., at zero temperature). Finally we discuss how our proposal could be realized experimentally. Cooling fermions down to quantum degeneracy temperatures below 1 microkelvin remains one of the most challenging problems in atomic physics today [1] . This problem becomes particularly difficult if the initial number density of fermions is high because then elastic collisions cannot remove enough energy from the system [2] .\nIn recent years, however, new experimental techniques have been developed [3, 4] , allowing us to trap and manipulate cold atoms on an unprecedented level [5] . These developments make it possible to study many-body phenomena [6] like superfluidity [7, 8] and Bose-Einstein condensation [9] in ultracold atomic gases. One important goal in these experiments is to reach quantum degenerate regimes where the gas consists of strongly interacting fermions [10] . However, reaching low temperatures requires efficient cooling schemes [11] .\nOne promising approach towards achieving this goal is to use the pairing mechanism [12] . Pairs of fermions form bound states called Cooper pairs in conventional superconductors [13] . Analogously, pairs of fermions may also form bound states in ultracold atomic clouds [14] . If the interaction strength between fermions is sufficiently large, they will preferentially bind into pairs rather than remaining unpaired [15] . Therefore, cooling fermions via pairing should work well even",
        "watermark_text": "We propose to cool fermionic atoms in optical lattices by using the pairing mechanism between 2 different hyperfine states, which is analogous to Cooper pair formation in superconductors.We show that this methodology can be used for both bosonic and fermionic systems with attractive interfaces.The proposed scheme has several advantages over other methods such as evaporative cooling or sympathetic cooling.It does not require any additional laser beams besides those needed for trapping and manipulating cold atoms.In addition it works even when there are no free particles presence initially ( e. g., at zero temperature ).Finally we discuss how our proposal could be realized experimentally.Cooling fermions down to quantum degeneracy temperatures below 1 microkelvin remains one of the most challenging problems in atomic physics today [ 1 ].This problem gets particularly difficult if the first number density of fermions is high because then elastic collisions cannot remove enough energy from the system [ 2 ].In recent years, however, new experimental methods have been developed [ 3, 4 ], allowing us to trap and influence cold atoms on an unprecedented level [ 5 ].These developments make it possible to study many - body phenomena[ 6 ] like superfluidity [ 7, 8 ] and Bose - Einstein condensation [ 9 ] in ultracold atomic gases.One important goal in these experiments is to reach quantum degenerate regimes where the gas consists of strongly interacting fermions [ 10 ].However, reaching low temperatures needs efficient cooling schemes [ 11 ].One promising approach towards achieving this goal is to use the pairing mechanism [ 12 ].Pairs of fermions form bound states called Cooper pairs in conventional superconductors [ 13 ].Analogously, pairs of fermions may also become bound states in ultracold atomic clouds [ 14 ].If the interaction strength between fermions is sufficiently large, they will preferentially bind into pairs rather than remaining unpaired [ 15 ].Therefore, cooling fermions via pairing should work well even"
    },
    {
        "original_text": "We report on the detection and analysis of radio emission associated with an impulsive solar flare that occurred in active region NOAA 10486 (SOL2010-07-20T17:48) at 17:48 UT on July 20, 2010 using the Nançay Decameter Array (NDA). The event was accompanied by a fast halo coronal mass ejection (CME), which reached Earth at 18:20 UT on July 21. We find that the radio source is located near the center of the CME front as seen in white light images taken by STEREO-Ahead/EUVI 195 Å . The radio flux density shows rapid evolution during the first hour after the onset of the flare, followed by gradual decay over several hours. The radio spectrum has a power-law shape between 1 MHz to 5 GHz. The spectral index decreases rapidly below 100 MHz but remains nearly constant above this frequency.",
        "watermark_text": "We report on the detection and analysis of radio emission associated with an impulsive solar flare that occurred in active region NOAA 10486 ( SOL2010 - 07 - 20T17 : 48 ) at 17 : 48 UT on July 20, 2010 using the Nançay Decameter Array ( NDA ).The event was accompanied by a fast halo coronal mass ejection ( CME ), which reached Earth at 18 : 20 UT on July 21.We find that the radio source is located near the center of the CME forward as saw in white light imagery taken by STEREO - Ahead / EUVI 195 Å.The radio flux density shows rapid evolution during the initial hour after the onset of the flare, followed by gradual decay over several hours.The radio spectrum has a power - law shape between 1 MHz to 5 GHz.The spectral index decreases rapidly below 100 MHz but remains almost constant above this frequency."
    },
    {
        "original_text": "We present the results of an analysis of gravitational wave data collected by the LIGO and Virgo detectors during the first observing run (O1) in 2015, which includes two candidate events for binary neutron star mergers. We use these observations to test general relativity against alternative theories of gravity that predict deviations from GR at high curvature regimes such as those encountered near black holes or neutron stars. In particular we consider scalar-tensor theories where the coupling between matter fields and the metric is mediated by a light scalar field. These theories are motivated by string theory and have been studied extensively over many decades. \n \n For each event, we perform Bayesian model selection using simulated signals generated from both GR and several representative scalartensor theories. Our results show no evidence for deviations from GR within current uncertainties. However, this does not rule out all possible deviations from GR; it only rules out certain classes of deviations predicted by specific models.",
        "watermark_text": "We present the results of an analysis of gravity wave data collected by the LIGO and Virgo detectors during the first observing run ( O1 ) in 2015, which includes two candidate events for binary neutron star mergers.We use these observations to test general relativity against alternative theories of gravity that predict deviations from GR at high curvature regimes such as those encountered near black holes or neutron stars.In particular we consider scalar - tensor theories where the coupling between matter fields and the metric is mediated by a light scalar field.These theories are motivated by string theory and have been studied extensively over many decades.For each event, we perform Bayesian model choice using simulated signals generated from both GR and several representative scalartensor theories.Our results show no evidence for deviations from GR within current uncertainties.However, this does not rule out all possible deviations from GR ; it only rules out certain classes of deviations predicted by particular models."
    },
    {
        "original_text": "We investigate the evolution of an eruptive coronal mass ejection (CME) by using three-dimensional magnetohydrodynamic simulations, which include both ideal MHD effects and resistivity. The initial condition is constructed as follows. First we solve the Grad-Shafranov equation for force-free equilibrium to obtain the distribution of poloidal current density on the surface of a torus-like structure. Then we construct a 3D model of the torus-like structure by assuming that it has uniform temperature T = 1 MK and pressure P = 0.1 dyn cm-2 inside its volume. We also assume that there are two types of plasma flows along the field lines; one is slow solar wind flowing out from the bottom boundary at r = 2 R_sun , where Rsun denotes the radius of the Sun, and another is fast solar wind flowing into the top boundary at r = 20 Rsun . Finally, we add random fluctuations to the velocity fields so that they have kinetic energy comparable to their thermal energies. \n \n In our simulation runs, we find three different phases during the CME evolution. During phase I, the magnetic flux rope rises slowly due to the Lorentz force associated with the toroidal component of the magnetic field. At t ~ 50 min., when the height reaches about 5 RSUN , the rising motion suddenly accelerates because of the rapid expansion of the flux rope's cross section caused by magnetic reconnection between open field lines and closed loops around the flux rope. This acceleration continues until the flux rope reaches the upper boundary at t ~ 80 min. . \n \n During phase II, the flux rope expands rapidly outward while maintaining its shape. After reaching the maximum size at t ~ 90 min. , however, the flux rope starts contracting inward again. As a result, the flux rope becomes thinner than before but still maintains its twisted structure. Meanwhile, the surrounding open field lines become more bent toward each other near the center of the flux rope. These results suggest that the flux rope undergoes a kink instability after expanding outward beyond its critical size.",
        "watermark_text": "We investigate the evolution of an eruptive coronal mass ejection ( CME ) by using three - dimensional magnetohydrodynamic simulations, which include both ideal MHD effects and resistivity.The initial condition is constructed as follows.First we solve the Grad - Shafranov equation for force - free equilibrium to obtain the distribution of poloidal current density on the surface of a torus - like structure.Then we construct a 3D model of the torus - resembling structure by assuming that it has uniform temperature T = 1 MK and pressure P = zero. 1 dyn centimeters - 2 inside its volume.We also assume that there are 2 types of plasma flows along the field lines ; one is slow sun wind flowing out from the bottom boundary at r = 2 R _ sunlight, where Rsun denotes the radius of the Sun, and another is fast solar flow flowing into the top boundary at r = 20 Rsun.Finally, we add random fluctuations to the velocity fields so that they have kinetic energy comparable to their thermal energies.In our simulation runs, we find three different stages during the CME evolution.During phase I, the magnetic flux rope rises slowly due to the Lorentz force involved with the toroidal constituent of the field field.At t ~ 50 min., when the height reaches about 5 RSUN, the raising motion suddenly accelerates because of the rapid expand of the flux rope ' s cross section caused by magnetic reconnection between open field lines and closure loops around the magnetic rope.This acceleration continues until the flux rope reaches the higher boundary at t ~ 80 min..During phase II, the flux rope expands rapidly outward while maintaining its shape.After reaching the maximum size at t ~ 90 min., however, the flux rope starts contracting inward again.As a result, the flux rope becomes thinner than before but still maintains its tangled structure.Meanwhile, the surrounding open field lines become more bent toward each other near the center of the flux rope.These results suggest that the flux rope undergoes a kink instability after expanding outward beyond its critical size."
    },
    {
        "original_text": "We present an experimental study on securely exchanging random bits between two parties connected to the Internet via public channels, using quantum key distribution (QKD). We show that QKD can be used for this purpose with high efficiency and security in practice by implementing it experimentally. The results demonstrate that our scheme is practical enough to be deployed as part of existing communication networks. Quantum Key Distribution (QKD) enables two remote users Alice and Bob to establish a secret key which they use to encrypt messages transmitted over insecure public channels such as the internet or telephone lines [1] . In order to achieve unconditional security against eavesdropping attacks [2] , QKD requires both users to perform measurements on single photons generated at distant locations [3] .\nIn recent years there has been significant progress towards commercialization of QKD systems [4] . However, despite these advances, deployment of QKD remains limited due to its relatively low transmission rates compared to classical cryptography [5] . This problem becomes more severe when one considers applications where multiple users need to share secrets simultaneously [6] . For example, consider a scenario where several banks want to exchange encrypted messages with each other while keeping their communications private [7, 8] .",
        "watermark_text": "We present an experiment study on securely exchanging randomly bits between two parties connected to the Internet via public channels, using quantum key distribution ( QKD ).We show that QKD can be used for this purpose with high efficiency and safety in practice by implementing it experimentally.The results demonstrate that our scheme is practical enough to be deployed as part of existing communication networks.Quantum Key Distribution ( QKD ) enables 2 remote users Alice and Bob to establish a confidential key which they use to encrypt messages transmitted over insecure public channels such as the internet or telephone lines [ 1 ].In order to achieve unconditional security against eavesdropping attacks [ 2 ], QKD requires both users to conduct measurements on single photons generated at distance locations [ three ].In recent years there has been significant progress towards commercialization of QKD systems [ 4 ].However, despite these advances, deployment of QKD remains limited due to its relatively low transmission rates compared to classical cryptography [ 5 ].This problem becomes more severe when one considers applications where multi users require to share secrets concurrently [ 6 ].For example, consider a scenario where multiple banks want to exchange encrypted messages with each other while keeping their communications private[ 7, 8 ]."
    },
    {
        "original_text": "We present the results of an optical spectroscopic follow-up campaign for a sample of X-ray selected AGN with extreme properties, observed in the first year (2000) of the XMM-Newton Serendipitous Source Catalogue (XMM-SSC). The main goal is to study their nature and physical characteristics by means of multiwavelength observations. We have obtained spectra for about half of our sample using several telescopes at different observatories around the world. Our analysis shows that most of these objects are broad-line quasars or Seyfert 1 galaxies; only one object turns out to be a narrow-line radio galaxy. In addition we find two new BL Lac candidates among this sample. This work has been supported by the Spanish Ministerio de Ciencia y Tecnología under grant AYA2003-08548-C03-01/02/03. -The XMM-SSC catalogue contains more than 100 000 serendipitously detected X-ray sources extracted from all public data taken during the first three years of operation of the European Space Agency's XMM-Newton satellite. It covers almost the entire sky visible from Europe above |b| > 10 degrees. -X-ray surveys provide large samples of active galactic nuclei (AGNs), which can then be studied statistically over wide ranges of luminosity, redshift and other parameters. However, it is often difficult to identify individual sources unambiguously because they may show complex spectral shapes and/or variability on many timescales. -In order to select a complete sample of AGNs with extreme properties, we applied very strict selection criteria based on the source count rate and photon index measured in the 0.5-2 keV band. These criteria were chosen so as to maximize the fraction of absorbed sources while keeping contamination due to background fluctuations low.  -Our final sample consists of 56 sources, including four previously known blazars.",
        "watermark_text": "We present the results of an optical spectroscopic follow - up campaign for a sample of X - ray selected AGN with extreme properties, observed in the first year ( 2000 ) of the XMM - Newton Serendipitous Source Catalogue ( XMM - SSC ).The main goal is to study their nature and physiological characteristics by way of multiwavelength observations.We have obtained spectra for about half of our sample using several telescopes at various observatories around the world.Our analysis shows that most of these objects are broad - line quasars or Seyfert 1 galaxies ; only single object turns out to be a narrow - chord radio galaxy.In addition we find two new BL Lac candidates among this sample.This work has been supported by the Spanish Ministerio de Ciencia y Tecnología under grant AYA2003 - 08548 - C03 - 01 / 02 / 03.- TheXMM - SSC catalogue contains more than 100 000 serendipitously detected X - ray sources extracted from all public data taken during the first three years of operation of the European Space Agency ' s XMM - Newton satellite.It covers nearly the entire sky visible from Europe above | b | > 10 °.- X - ray surveys provide large samples of active galactic nuclei ( AGNs ), which can then be examined statistically over wide ranges of luminosity, redshift and other parameters.However, it is often difficult to identify individual sources unambiguously because they might show complex spectral shapes and / or variability on many timescales.- In order to select a complete sample of AGNs with extreme properties, we applied very rigorous selection criteria based on the source count rate and photon index measured in the zero. 5 - 2 keV band.These criteria were chosen so as to maximize the fraction of absorbed sources while keeping contamination due to background fluctuations low.- Our final sample consists of 56 sources, including 4 previously known blazars."
    },
    {
        "original_text": "We study the problem of finding an optimal schedule for data transmission over multiple channels with interference constraints, where each channel is assigned to one transmitter-receiver pair and transmissions on different pairs are subject to mutual interference. We consider two models: (i) The first model assumes that all transmitters have fixed power levels. (ii) In the second model we assume that transmitters can adjust their powers dynamically. For both cases, we show how to find an optimal schedule by solving a sequence of linear programs. Our results hold even if there exists only one receiver per transmitter. This work was supported by NSF grant CCF-0430018. 1 Introduction Wireless networks consist of many nodes communicating via radio signals. Each node has limited range and thus cannot communicate directly with every other node. Instead, it communicates indirectly through intermediate nodes called relays or routers. A fundamental question in this context is: How should these relays be placed?",
        "watermark_text": "We study the problem of finding an ideal schedule for data transmission over multiple channels with interfering constraints, where each channel is assigned to 1 transmitter - receiver pair and transmissions on separate pairs are subject to mutual interference.We consider two models : ( i )The first model expects that all transmitters have fixed power limits.( ii ) In the second model we assume that transmitters can adjust their powers dynamically.For both cases, we show how to find an ideal schedule by solving a sequence of linear programs.Our results hold even if there remains only one receiver per transmitter.This work was supported by NSF grant CCF - 0430018.1 Introduction Wireless networks consist of many nodes communicating via radio signals.Each node has limited range and thus cannot communicate directly with every other node.Instead, it communicates indirectly through intermediate nodes called relays or routers.A fundamental question in this context is : How should these relays be placed?"
    },
    {
        "original_text": "We report on the detection by Swift/BAT and Konus-Wind of gamma-ray burst (GRB) 060927, which is one of only two events detected with redshifts greater than five to date.  The redshift was determined using optical spectroscopy obtained with the Very Large Telescope in Chile within three hours after the burst trigger time.  We find that this event has an extremely hard spectrum, similar to other high-redshift bursts observed previously.  Using our current understanding of the physics behind these phenomena we can estimate the total energy released during the prompt emission phase of the burst to be ~10^53 erg.  This value is comparable to or larger than the energies released by some supernovae.  If confirmed, it would make GRB 060927 the most energetic event ever recorded.  In addition, if the host galaxy mass function evolves similarly to what is seen locally, then the progenitor system responsible for producing such an energetic explosion must have been hosted by a very massive galaxy.  These results are consistent with theoretical predictions made about the progenitors of high-z GRBs.  Finally, we discuss how future observations of this object may help us understand the end of cosmic reionization.",
        "watermark_text": "We report on the detection by Swift / BAT and Konus - Wind of gamma - ray burst ( GRB ) 060927, which is one of only two events detected with redshifts greater than five to date.The redshift was determined using optical spectroscopy obtained with the Very Big Telescope in Chile inside three hours after the burst trigger time.We find that this event has an extremely hard spectrum, similar to other high - redshift bursts observed previously.Using our current understanding of the physics behind these phenomena we can estimate the overall energy released during the prompt emission stage of the burst to be ~ 10 ^ 53 erg.This value is comparable to or larger than the energies released by some supernovae.If confirmed, it would make GRB 060927 the most energetic event ever recorded.In addition, if the host galaxy mass function evolves similarly to what is observed locally, then the progenitor system responsible for producing such an energetic explosion must have been hosted by a very massive galaxy.These results are consistent with theoretical predictions made about the progenitors of high - z GRBs.Finally, we discuss how future observations of this object may help us understand the end of cosmic reionization."
    },
    {
        "original_text": "We present the first detection of secondary CMB polarization induced by Faraday rotation (FR) in galaxy clusters, using data taken with the Atacama Cosmology Telescope Polarimeter (ACTPol). We detect FR-induced polarized emission at angular scales corresponding to multipoles = 100-1000 for two galaxy clusters: ACT-CL J0102-4915 and ACT-CL J0546-5345. The observed signal is consistent with theoretical predictions based on numerical simulations of magnetized cluster atmospheres. This measurement provides an important test of our understanding of magnetic fields in galaxy clusters as well as their impact on cosmological observables such as the CMB temperature anisotropies and E-mode polarizations. In addition, we report upper limits on the FR-induced polarized emissions from other galaxy clusters that are not detected individually due to low S/N ratio or limited survey area. These results will be useful for future studies of FR effects on the CMB polarization maps produced by upcoming experiments like Planck and Simons Observatory.",
        "watermark_text": "We present the initial detection of secondary CMB polarization induced by Faraday rotation ( FR ) in galaxy clusters, using data taken with the Atacama Cosmology Telescope Polarimeter ( ACTPol ).We detect FR - induced polarized emission at angular scales corresponding to multipoles = 100 - 1000 for 2 galaxy clusters : ACT - CL J0102 - 4915 and ACT - CL J0546 - 5345.The observed signal is consistent with theoretical expectations based on numerical simulations of magnetized cluster atmospheres.This measurement provides an important test of our understanding of magnetic fields in galaxy clusters as also as their impact on cosmological observables such as the CMB temperature anisotropies and E - mode polarizations.In addition, we report upper limits on the FR - induced polarized emissions from other galaxy clusters that are not detected separately due to low S / N ratio or limited survey area.These results will be useful for future studies of FR effects on the CMB polarization maps produced by upcoming experiments like Planck and Simons Observatory."
    },
    {
        "original_text": "We study particle motion in rapidly oscillating potentials with arbitrary initial phases and show that, for certain values of this phase, particles can be trapped by the potential even if it is not periodic.  We find exact solutions to the Schrödinger equation describing such systems using Floquet theory and discuss their physical implications. In particular we consider an optical lattice formed by counter-propagating laser beams whose frequencies are detuned slightly from each other. This system has been studied extensively both theoretically and experimentally but our results provide new insights into its dynamics. Introduction:-In recent years there have been many studies on the physics of ultracold atoms confined in optical lattices [1] . These experiments typically involve trapping cold neutral atoms in a standing wave pattern created by two counterpropagating laser fields which are tuned close together so as to form a deep periodic potential [2] .\nThe resulting atomic gas forms a Bose-Einstein condensate (BEC) [3] , where all the atoms occupy the same quantum state [4] . Such systems have attracted considerable interest because they allow one to explore fundamental questions about quantum mechanics [5] - [8] while also providing a platform for studying novel phenomena [9] - [11] . For example, these systems have recently been used to demonstrate superfluidity [12] , Josephson effects [13] , Bloch oscillations [14] , Landau-Zener tunneling [15] , and Anderson localization [16] . However, despite much theoretical work [17] - [20] , the full range of possible behaviors exhibited by these systems remains poorly understood [21] .\nOne reason why the behavior of these systems is difficult to predict is that the underlying potential is time-dependent [22] . Indeed, since the lasers forming the lattice are usually far off-resonant [23] , the amplitude of the potential varies periodically over timescales comparable to those associated with typical experimental parameters [24] . As a result, the energy spectrum of the system becomes quasi-periodic [25] and the usual methods of solving the Schrödinger equation break down [26] .",
        "watermark_text": "We study particle motion in rapidly oscillating potentials with arbitrary initial phases and show that, for particular values of this phase, particles can be trapped by the particle even if it is not periodic.We find exact solutions to the Schrödinger equation describing such systems using Floquet theory and discuss their physical implications.In particular we consider an optical lattice formed by counter - propagating laser beams whose frequencies are detuned somewhat from each other.This system has been studied extensively both theoretically and experimentally but our results provide new insights into its dynamics.Introduction : - In recent years there have been numerous studies on the physics of ultracold atoms confined in optical lattices [ 1 ].These experiments typically involve trapping cold neutral atoms in a standing wave pattern created by two counterpropagating laser fields which are tuned near together so as to become a deeply periodic potential [ 2 ].The resulting atomic gas forms a Bose - Einstein condensate ( BEC )[ 3 ], where all the atoms occupy the same quantum state [ 4 ].Such systems have attracted considerable interest because they allow one to explore fundamental questions about quantum mechanics[ 5 ] -[ 8 ] while also providing a platform for studying novel phenomena [ 9 ] - [ 11 ].For example, these systems have recently been used to demonstrate superfluidity[ 12 ], Josephson effects[ 13 ], Bloch oscillations[ 14 ], Landau - Zener tunneling [ 15 ], and Anderson localization[ 16 ].However, despite much theoretical work [ 17 ] - [ 20 ], the full range of potential behaviors exhibited by these systems remains poorly understood [ 21 ].One reason why the behavior of these systems is difficult to predict is that the underlying potential is time - dependent [ 22 ].Indeed, since the lasers forming the lattice are usually far off - resonant[ 23 ], the amplitude of the potential varies periodically over timescales comparable to those associated with typical experiment parameters[ 24 ].As a result, the energy spectrum of the system becomes quasi - periodic [ 25 ] and the normal methods of solving the Schrödinger equation break down [ 26 ]."
    },
    {
        "original_text": "We present new measurements of the helium mass fraction YHe = 0.24 ± 0.01 (statistical) ±0.02 (systematic), obtained by combining X-ray data on galaxy clusters with SZ observations, using the sample of 62 nearby relaxed galaxy clusters observed at high signal-to-noise ratio by Planck satellite. The results are consistent with previous determinations based on Chandra or XMM-Newton data alone. \n \n We also report an improved measurement of the Hubble constant H0 = 67.4±1.2 km s-1 Mpc-1, which is derived from our determination of the angular diameter distance to these clusters combined with their redshifts. This value agrees well with other recent estimates but has smaller statistical uncertainty than most of them. It is also compatible within 1 sigma with the local measurement inferred from Cepheid variables. \n \n Finally we use this dataset to test for possible deviations from standard cosmology due to massive neutrinos. Our analysis shows that current data do not allow us to detect any significant deviation from the predictions of ΛCDM model.",
        "watermark_text": "We present new measurements of the helium mass fraction YHe = zero. 24 ± 0. 01 ( statistical ) ±0. 02 ( systematic ), obtained by combining X - ray data on galaxy clusters with SZ observations, using the sample of 62 nearby relaxed galaxy clusters observed at high signal - to - noise ratio by Planck satellite.The results are consistent with previous determinations based on Chandra or XMM - Newton data solely.We also report an improved measurement of the Hubble constant H0 = 67. 4±1. 2 km s - 1 Mpc - 1, which is derived from our determination of the angular diameter distance to these clusters combined with their redshifts.This value agrees well with other latest estimates but has smaller statistical uncertainty than most of them.It is also compatible within 1 sigma with the local measurement inferred from Cepheid variables.Finally we use this dataset to test for possible deviations from standard cosmology due to massive neutrinos.Our analysis shows that contemporary data do not allow us to detect any significant deviation from the predictions of ΛCDM model."
    },
    {
        "original_text": "We present new results on the distribution of the electron index, p, in GRB afterglow models using data from Swift/BATSE bursts with known redshifts (z < 5). We find that the distribution is consistent with being log-normal for both low-z and high-z samples. The mean value of p decreases slightly with increasing redshift but there are no significant differences between the two distributions at fixed z. This suggests that the physical processes which determine the value of p do not evolve significantly over cosmic time scales. Using our best-fit values we show how the observed X-ray light curves can be used to constrain the structure of the circumburst medium. In particular, we demonstrate that it should be possible to distinguish between different density profiles by comparing the temporal decay slopes of the early-time X-ray emission with those measured later during the prompt phase. \n \n Keywords: Gamma-ray bursts, Electron index",
        "watermark_text": "We present new results on the distribution of the electron index, p, in GRB afterglow models utilizing data from Swift / BATSE bursts with known redshifts ( z < 5 ).We find that the distribution is consistent with being log - normal for both low - z and highly - z samples.The mean value of p decreases somewhat with rising redshift but there are no significant differences between the two distributions at stationary z.This suggests that the physical processes which determine the worth of p do not evolution significantly over cosmic time scales.Using our best - fit values we show how the observed X - ray light curves can be used to constrain the structure of the circumburst medium.In particular, we demonstrate that it should be possible to distinguish between different density profiles by comparing the temporal degradation slopes of the early - time X - ray emitted with those measured later during the prompt stage.Keywords : Gamma - ray bursts, Electron index"
    },
    {
        "original_text": "The detection of exoplanets has been one of the most exciting recent developments in astronomy, but their characterization is still incomplete. The goal of this thesis was to develop new techniques for characterizing exoplanetary systems using dynamical methods. In particular, I studied how planets can be used as probes into the formation history of planetary systems by measuring the mass distribution of small bodies (planetesimals) that are trapped in mean motion resonances with them.  My first project investigated the effect of planetesimal size on the stability of planetary orbits. Using numerical simulations, we found that smaller planetesimals tend to destabilize planetary orbits more quickly than larger ones because they have higher orbital eccentricities. This result suggests that there may exist an upper limit to the size of planetesimals that form during planet migration. My second project examined the effects of mutual inclinations between planets on the stability of planetary systems. We showed that mutual inclination increases the likelihood of instability when two planets are locked in a 2:1 resonance. Finally, my third project explored the possibility of detecting terrestrial planets around white dwarfs through gravitational microlensing events.",
        "watermark_text": "The detection of exoplanets has been something of the most exciting recent developments in astronomy, but their characterization is still incomplete.The goal of this thesis was to develop new techniques for characterizing exoplanetary systems utilizing dynamical methods.In particular, I studied how planets can be used as probes into the formation history of planetary systems by measuring the mass spread of little bodies ( planetesimals ) that are trapped in mean motion resonances with them.My first project investigated the effect of planetesimal size on the stability of planet orbits.Using numerical simulations, we found that smaller planetesimals tend to destabilize planetary orbits more quickly than larger orbits because they have higher orbital eccentricities.This result suggests that there may exist an upper limit to the size of planetesimals that form during planet migration.My second project examined the effects of mutual inclinations between planets on the stability of planetary systems.We showed that mutual inclination increases the likelihood of instability when 2 planets are locked in a two : one resonance.Finally, my third project explored the possibility of detecting terrestrial planets around white dwarfs through gravitational microlensing events."
    },
    {
        "original_text": "The present work is devoted to the study of photon wave mechanics in terms of position eigenvectors, which are introduced as solutions of the Schrödinger equation for photons with an arbitrary energy spectrum. The concept of position eigenvector allows one to describe the state of a single photon by its position probability density distribution function (PDF). It also enables us to introduce the notion of quantum trajectory describing the evolution of this PDF over time. In particular, we show that the quantum trajectories corresponding to different initial states can be obtained from each other by means of unitary transformations. We demonstrate how these results may be used to analyze various phenomena related to the propagation of light through dispersive media. Finally, we discuss possible applications of our approach to the description of nonclassical effects associated with the emission of entangled pairs of photons. DOI: 10.1088/1742-6596/aa5e20\nI. INTRODUCTORY REMARkS\n\nIn recent years there has been considerable interest in developing new approaches to studying the properties of light fields based on the concepts of quantum optics [1–3] . One of such approaches involves introducing the so-called position eigenvectors [4] , which play an important role in the description of the state of a single-photon field [5–7] .\nIt should be noted that the use of position eigenvectors makes it possible not only to obtain information about the spatial structure of the electromagnetic field but also to investigate the temporal dynamics of the system under consideration [8, 9] . This fact opens up wide possibilities for applying the proposed method to analyzing various physical processes occurring during the propagation of light waves through dispersive media [10, 11] . \n \n In addition, the introduction of position eigenvectors into the theory of light fields leads to the possibility of using them to describe certain nonclassical effects associated",
        "watermark_text": "The present work is devoted to the study of photon wave mechanics in terms of position eigenvectors, which are introduced as solutions of the Schrödinger equation for photons with an arbitrary energy spectrum.The concept of position eigenvector permits one to describe the state of a single photon by its position probability density distribution function ( PDF ).It also allows us to introduce the notion of quantum trajectory describing the evolution of this PDF over time.In particular, we show that the quantum trajectories corresponding to different initial states can be obtained from each other by means of unitary transformations.We demonstrate how these outcomes may be used to analyze various phenomena related to the propagation of light through dispersive media.Finally, we discuss possible applications of our approach to the description of nonclassical effects associated with the emission of entangled couples of photons.DOI : 10. 1088 / 1742 - 6596 / aa5e20 I. INTRODUCTORY REMARkSIn recent years there has been considerable interest in developing novel approaches to studying the properties of light fields based on the concepts of quantum optics [ 1 – 3 ].One of such approaches involves introducing the so - called position eigenvectors [ 4 ], which play an important role in the description of the state of a single - photon field [ 5 – 7 ].It should be noted that the use of position eigenvectors makes it feasible not only to obtain info about the spatial structure of the electromagnetic field but also to probe the temporal dynamics of the system under consider [ 8, 9 ].This fact opens up wide possibilities for applying the proposed method to analyzing various physical processes happening during the spread of light waves through dispersive media[ 10, 11 ].In addition, the introduction of position eigenvectors into the theory of light fields leads to the possibility of using them to describe certain nonclassical effects associated"
    },
    {
        "original_text": "We study the relic density of dark matter (DM) produced by thermal freeze-out and freezein processes in Universal Extra Dimension (UED) model, where we include effects due to Majorana mass terms for the right handed neutrino fields. We find that the DM can be either fermionic or bosonic depending on the values of the parameters involved. In particular, if the UED scale is close to 1 TeV then the DM candidate could be a scalar particle which has been recently proposed as a possible explanation for the PAMELA positron excess observed at high energies. The results are presented in the context of LHC searches for new physics beyond Standard Model. Introduction:-The discovery of the Higgs-like resonance [1-3] at Large Hadron Collider (LHC), alongwith other experimental evidences [4] , have established the existence of a fundamental scalar field responsible for breaking electroweak symmetry. However, there still remain many open questions about the nature of this scalar sector such as: What is its spin? Is it CP-even or odd? Does it couple only to gauge bosons or also to fermions? Are there any additional scalars present in Nature ? These issues will be addressed once more data becomes available from ongoing experiments like ATLAS [5] and CMS [6] . On the theoretical front, one of the most interesting possibilities is to consider extensions of the Standard Model (SM). One possibility is to extend SM into higher dimensions [7-9], thereby introducing Kaluza-Klein excitations of all particles [10] .\nIn recent years, several authors [11-13] studied the phenomenology of these theories in detail. It was shown that the lightest KaluzaKlein excitation of the graviton may act as cold Dark Matter (CDM) [14-16]. This scenario is particularly appealing since CDM constitutes around 23% [17] of the energy content of our universe [18] . Moreover, the presence of an extra spatial dimension opens up the possibility of producing Kaluza-Klein states through various production mechanisms [19-21] including decay [22] and annihilation [23] . Recently, it has been pointed out [24]",
        "watermark_text": "We study the relic density of dark matter ( DM ) produced by thermal freeze - out and freezein processes in Universal Extra Dimension ( UED ) model, where we include effects due to Majorana mass terms for the right handed neutrino fields.We find that the DM can be either fermionic or bosonic depending on the values of the parameters involved.In particular, if the UED scale is close to 1 TeV then the DM candidate could be a scalar particle which has been lately proposed as a possible explanation for the PAMELA positron excess observed at high energies.The results are presented in the context of LHC searches for novel physics outside Standard Model.Introduction : - The discovery of the Higgs - like resonance [ 1 - 3 ] at Large Hadron Collider ( LHC ), alongwith other experimental evidences[ 4 ], have established the existence of a fundamental scalar field responsible for breaking electroweak symmetry.However, there still remain much open questions about the nature of this scalar sector such as : What is its spin?Is it CP - even or odd?Does it couple only to gauge bosons or also to fermions?Are there any additional scalars present in Nature?These issues will be addressed once more data gets available from continuing experiments like ATLAS[ 5 ] and CMS [ 6 ].On the theoretical front, one of the most interesting possibilities is to consider extensions of the Standard Model ( SM ).One possibility is to extend SM into upper dimensions [ 7 - nine ], thereby introducing Kaluza - Klein excitations of all particles [ 10 ].In recent years, several authors [ 11 - 13 ] studied the phenomenology of these theories in detail.It was shown that the lightest KaluzaKlein excitation of the graviton may act as cold Dark Matter ( CDM )[ 14 - 16 ].This scenario is particularly appealing since CDM constitutes around 23 % [ 17 ] of the energetic content of our universe [ 18 ].Moreover, the presence of an extra spatial dimensional opens up the possibility of producing Kaluza - Klein states through various production mechanisms[ 19 - 21 ] including decay [ 22 ] and annihilation [ 23 ].Recently, it has been pointed out [ 24 ]"
    },
    {
        "original_text": "We present the results of an analysis of rise times for a sample of type Ia supernovae (SNeIa) with well-measured light curves and redshifts in order to determine whether there is one mode of SNeIa rise time, as suggested by Phillips et al. (1999), or two modes, as suggested by Riess et al. (1999). We find that our data are consistent with either model at the 2-sigma level; however, we cannot rule out the possibility of only one mode being present. The best-fit values for the parameters describing each distribution differ significantly between these models. If future observations confirm this result, it will have important implications on cosmological studies using SNeIa as distance indicators. In particular, if there really are two populations of SNeIa, then the use of a single value for the stretch parameter may lead to systematic errors in determining distances. \n \n Keywords: Supernova, Light curve",
        "watermark_text": "We present the results of an analysis of rise times for a sample of type Ia supernovae ( SNeIa ) with well - measured light curves and redshifts in order to determine whether there is one mode of SNeIa rise time, as suggested by Phillips et al. ( 1999 ), or two modes, as suggested by Riess et al. ( 1999 ).We find that our data are consistent with either model at the 2 - sigma level ; however, we cannot rule out the possibility of only one mode being present.The best - fit values for the parameters describing each distribution differ significantly between these models.If future observations confirm this result, it will have important implications on cosmological studies using SNeIa as distance indicators.In particular, if there really are two populations of SNeIa, then the use of a single value for the stretch parameter may lead to systematic errors in determining distances.Keywords : Supernova, Light curve"
    },
    {
        "original_text": "We present new mid-IR photometry and spectroscopy of the HUDF-JD2 galaxy at redshift 2.081, which is one of the most luminous infrared galaxies known to date. The SED shows that it has an extremely red continuum with strong PAH emission features in its rest frame optical spectrum. We find evidence for both star formation activity (from the UV-optical) as well as obscured AGN activity (from X-ray observations). This object may be representative of a population of dusty star-forming galaxies undergoing rapid evolution during this critical epoch when massive black holes are growing rapidly along with their host galaxies. Keywords: Infrared, Redshift, Spectroscopy, Photometry, Black Hole Growth, Star Formation Rate Density, Ultraviolet Background Radiation, Cosmic Evolution, Cosmology, Extragalactic Astronomy, High Energy Astrophysics, Space Science, Nearby Galaxies",
        "watermark_text": "We present new mid - IR photometry and spectroscopy of the HUDF - JD2 galaxy at redshift II. 081, which is one of the most luminous infrared galaxies known to date.The SED shows that it has an extremely red continuum with powerful PAH emission features in its rest frame optical spectrum.We find evidence for both star formation activity ( from the UV - optical ) as well as obscured AGN formation ( from X - ray observations ).This object may be representative of a population of dusty star - forming galaxies undergoing rapid evolution during this critical epoch when massive pale holes are growing rapidly along with their home galaxies.Keywords : Infrared, Redshift, Spectroscopy, Photometry, Black Hole Growth, Star Formation Rate Density, Ultraviolet Background Radiation, Cosmic Evolution, Cosmology, Extragalactic Astronomy, High Energy Astrophysics, Space Science, Nearby Galaxies"
    },
    {
        "original_text": "We propose an integrative computational framework for the study of behavioral responses to strong aversive stimuli, such as pain and fearful events. The proposed approach is based on a novel combination of two complementary theoretical frameworks that have been developed in recent years within neuroscience research: (i) dynamical systems theory; and (ii) reinforcement learning theory. We show how these theories can be combined into one coherent mathematical formalism by introducing a new concept called \"state-action value function\". This concept allows us to define a single objective function which describes both the dynamics of the internal states of the brain during emotional experiences and the way in which external actions are selected depending on those internal states. Finally, we illustrate our proposal with some examples taken from experimental data obtained using functional magnetic resonance imaging techniques. In particular, we focus on the analysis of neural activity recorded while subjects were exposed to painful thermal stimulations or when they observed images depicting threatening scenes.",
        "watermark_text": "We propose an integrative computational framework for the study of behavioral responses to strong aversive stimuli, such as pain and fearful events.The proposed approach is based on a novel combination of two complementary theory frameworks that have been developed in recent years within neuroscience research : ( i ) dynamical systems theoretical ; and ( ii ) reinforcement learning theoretical.We show how these theories can be combined into one coherent math formalism by introduction a new concept called \" state - action value function \".This concept enables us to define a single objective function which describes both the dynamics of the internal states of the brain during emotional experiences and the way in which external actions are selected depending on those internal states.Finally, we illustrate our proposal with some examples taken from experiment data obtained using functional magnetic resonance imaging techniques.In particular, we focus on the analysis of neural activity recorded while subjects were exposed to painful thermal stimulations or when they observed pictures depicting threatening scenes."
    },
    {
        "original_text": "We present the first measurement of the ionization fraction in an isolated dark cloud, using observations with Herschel Space Observatory's Heterodyne Instrument for the Far Infrared (HIFI). We detect emission lines from C+, O+, N+, S+, Si+, Ar+, Fe+, HCO+, H2S+, and H2O+ toward the core of Barnard 68 (B68), which is located at a distance of 140 pc. The observed line intensities are used to derive the fractional ionizations of carbon, oxygen, nitrogen, sulfur, silicon, argon, iron, hydrogen cyanide, hydrosulfide, and water molecules relative to molecular hydrogen. These results show that B68 has a low degree of ionization compared to other star-forming regions such as Orion A or W51 e1/e2. This suggests that star formation may be suppressed by magnetic fields and/or cosmic rays in this region.",
        "watermark_text": "We present the initial measurement of the ionization fraction in an isolated dark cloud, utilizing observations with Herschel Space Observatory ' s Heterodyne Instrument for the Far Infrared ( HIFI ).We detect emission lines from C +, O +, N +, S +, Si +, Ar +, Fe +, HCO +, H2S +, and H2O + toward the core of Barnard 68 ( B68 ), which is located at a distance of 140 pc.The observed line intensities are used to derive the fractional ionizations of carbon, oxygen, nitrogen, sulfur, silicon, argon, iron, hydrogen cyanide, hydrosulfide, and water molecules relative to molecular hydrogen.These results show that B68 has a low degree of ionization compared to other star - forming regions such as Orion A or W51 e1 / e2.This suggests that stellar formation might be suppressed by magnetic fields and / or cosmic rays in this region."
    },
    {
        "original_text": "We present an algorithm for counting the number of supersymmetric states with given charge and spin in four-dimensional super Yang-Mills theory (N=4 SYM). The method is based on the use of integrability techniques to compute the spectrum of anomalous dimensions, which are then used as input into a recursion relation that counts the number of states at each level of the Bethe ansatz. We test our results against known exact answers for small values of the charges and find agreement up to numerical precision. Finally we discuss how this approach can be extended beyond the leading order approximation by including corrections due to wrapping interactions between magnons. In recent years there has been considerable interest in understanding the structure of quantum field theories using integrable systems methods [1] . One particularly interesting application of these ideas concerns the study of gauge/string dualities [2] , where it was shown that certain quantities computed in one description could be related to those obtained in another via the so-called AdS/CFT correspondence [3] .\nIn particular, the spectrum of anomalous dimension of local gauge-invariant composite operators plays a crucial role in determining physical observables such as correlation functions [4] or Wilson loops [5] . It turns out that many properties of the spectrum of anomalous dimen-sions can be determined exactly [6] - [8] , making it possible to obtain precise predictions about the behaviour of various physical quantities [9] - [11] . However, despite significant progress [12] - [16] , the problem of computing the full spectrum remains open [17] .\nThe aim of this work is to develop new computational tools for studying the spectrum of anomalous dimensionality of composite operators in N = 4 Super-Yang Mills Theory (SYMT) [18] . This will allow us to make further tests of the AdS/CFT conjecture and also provide insight into the nature of non-perturbative effects in strongly-coupled gauge theories [19] . Our main motivation comes from the fact that the spectrum of anomalous-dimension matrices in SYMT is described by the celebrated Bethe Ansatz [20] . As a result, the computation of the spectrum reduces to solving a set of coupled integral equations [21] whose solution requires sophisticated numerical",
        "watermark_text": "We present an algorithm for counting the number of supersymmetric states with given charge and spin in 4 - dimensional super Yang - Mills theory ( N = 4 SYM ).The method is based on the use of integrability techniques to compute the spectrum of anomalous dimensions, which are then used as input into a recursion relation that counts the number of states at each level of the Bethe ansatz.We test our results against known precise answers for tiny values of the charges and find agreement up to numerical precision.Finally we discuss how this approach can be extended beyond the leading order approximation by including corrections due to wrapping interactions between magnons.In recent years there has been considerable interest in understanding the structure of quantum field theories using integrable structures methods [ 1 ].One particularly interesting application of these ideas concerns the study of gauge / string dualities [ 2 ], where it was shown that certain quantities computed in single description could be related to those obtained in another via the so - called AdS / CFT correspondence[ 3 ].In particular, the spectrum of anomalous dimension of local gauge - invariant composite operators plays a crucial role in determining physical observables such as correlation functions [ 4 ] or Wilson loops [ five ].It turns out that many properties of the spectrum of anomalous dimen - sions can be decided exactly [ 6 ] - [ 8 ], making it possible to obtain precise predictions about the behaviour of various physical quantities[ 9 ] -[ 11 ].However, despite significant progress [ 12 ] - [ 16 ], the problem of computing the full spectrum remains open [ 17 ].The aim of this work is to develop novel computational tools for studying the spectrum of anomalous dimensionality of composite operators in N = 4 Super - Yang Mills Theory ( SYMT )[ 18 ].This will allow us to make further tests of the AdS / CFT conjecture and also provide insight into the nature of non - perturbative effects in strongly - coupled gauge theories [ 19 ].Our main motivation comes from the fact that the spectrum of anomalous - dimension matrices in SYMT is described by the celebrated Bethe Ansatz [ 20 ].As a result, the computation of the spectrum decreases to solving a set of coupled integral equations [ 21 ] whose solution requires sophisticated numerical"
    },
    {
        "original_text": "We present new near-infrared (NIR) polarimetric observations of the Herbig Ae star HD 142527, which reveal that its circumstellar dust is composed of two distinct populations with different grain sizes. The polarization degree decreases rapidly towards longer wavelengths at all positions along our slit except for one position where it increases again between 2.2 and 3.8 microns. We interpret this as evidence for an inner hole in the distribution of larger grains. This interpretation is supported by SED modeling using radiative transfer calculations including scattering off spherical particles. Our results suggest that the outer edge of the gap lies within 0.1 AU of the central star. In addition to the NIR data presented here we also obtained mid-infrared (MIR) spectro-polarimetry covering the wavelength range 5-20 micron. These data show no significant change in the polarization degree across the MIR bands indicating that there are no strong changes in the optical properties of the dust grains on these scales.",
        "watermark_text": "We present new near - infrared ( NIR ) polarimetric observations of the Herbig Ae star HD 142527, which reveal that its circumstellar dust is composed of two distinct populations with different grain sizes.The polarization degree decreases rapidly towards longer wavelengths at all positions along our slit except for one position where it increases again between 2. 2 and 3. 8 microns.We interpret this as evidence for an inner hole in the distribution of bigger grains.This interpretation is supported by SED modeling using radiative transfer calculations including scattering off spherical particles.Our results suggest that the outside edge of the gap lies within 0. 1 AU of the central star.In addition to the NIR data presented here we additionally obtained middle - infrared ( MIR ) spectro - polarimetry encompassing the wavelength range 5 - 20 micron.These data show no significant change in the polarization degree across the MIR bands indicating that there are no strong changes in the optical properties of the dust grains on these scales."
    },
    {
        "original_text": "We study the dynamics of quantum quenches in extended systems, focusing on the case where the initial state is an eigenstate of some local operator and the final Hamiltonian has no such symmetry. We show that for generic states this leads to relaxation towards equilibrium with a characteristic time scale which grows exponentially with system size. This behavior can be understood by considering the effect of rare regions whose energy gap scales as $1/N$, leading to exponential decay of correlations at late times. In contrast, we find that if the initial state is chosen to have maximal overlap with the ground state of the final Hamiltonian then there are no relaxation effects whatsoever. Finally, we discuss how these results may be relevant to experiments studying cold atoms in optical lattices. \nI. INTRODUCTORY REMARK\nThe problem of understanding the nonequilibrium dynamics following a sudden change in parameters (the so-called quench) continues to attract considerable interest both theoretically [1] and experimentally [2] . The main focus so far has been on closed quantum many-body systems described by Hamiltonians with short-range interactions [3] , but recently attention has shifted to open quantum systems [4] .\nIn particular, it was shown [5] that even when the initial state is highly excited, the evolution after a global quench will eventually relax into thermal equilibrium [6] . However, recent studies [7, 8] suggest that relaxation does not occur generically in open quantum systems, i.e., when the initial state is prepared by coupling the system to another reservoir or bath [9] . Instead, one expects equilibration only under certain conditions [10] : For example, if the initial state is close enough to the ground state of the new Hamiltonian [11] , or if the spectrum of the post-quench Hamiltonian contains a sufficiently large number of low-lying excitations [12] .",
        "watermark_text": "We study the dynamics of quantum quenches in expanded systems, focusing on the case where the early state is an eigenstate of some local operator and the final Hamiltonian has no such symmetry.We show that for generic states this leads to relaxation near equilibrium with a characteristic temporal scale which growth exponentially with system size.This behavior can be understood by considering the impact of rare regions whose energy gap scales as $ 1 / N $, leading to exponential decay of correlations at late times.In contrast, we find that if the initial state is chosen to have maximal overlap with the ground state of the final Hamiltonian then there are no relaxation affects whatsoever.Finally, we discuss how these outcomes may be relevant to experiments investigating cold atoms in optical lattices.I. INTRODUCTORY REMARK The problem of understanding the nonequilibrium dynamics following a sudden change in parameters ( the so - called quench ) continues to attract considerable interest both theoretically [ 1 ] and experimentally[ 2 ].The main focus so far has been on closed quantum many - body systems described by Hamiltonians with short - range interactions [ 3 ], but recently attention has shifted to open quantum systems [ 4 ].In particular, it was shown [ 5 ] that even when the beginning state is highly excited, the evolution after a universal quench will eventually relax into thermal balance [ 6 ].However, recent studies [ 7, 8 ] suggest that relaxation does not happen generically in open quantum systems, i. e., when the initial state is prepared by coupling the system to another reservoir or bath [ 9 ].Instead, one expects equilibration only under certain conditions[ 10 ] : For example, if the initial state is close enough to the ground condition of the new Hamiltonian [ 11 ], or if the spectrum of the post - quench Hamiltonian contains a sufficiently large number of low - lying excitations [ 12 ]."
    },
    {
        "original_text": "We present an algorithm for the evaluation of Hankel determinants that is almost as efficient as the product formula, but avoids numerical instability problems associated with it.  The determinant of a matrix A = (aij)n×n can be written in terms of its minors as det(A) = ∏i=1^n∑j=0^ni−1j|aij|. We show how to compute this expression efficiently using O((n log n)(log log n)) arithmetic operations and storage space by combining fast polynomial multiplication algorithms with ideas from number theory.   Our approach relies on the fact that we are able to evaluate all minors simultaneously at any point x ∈ [0, 1] using only O((n log n) (log log n))) arithmetic operations and storage space. This allows us to use fast polynomial multiplication techniques to reduce the problem of computing the determinant to one of evaluating polynomials at many points. Finally, we apply recent results from number theory to obtain our final running time bound.",
        "watermark_text": "We present an algorithm for the evaluation of Hankel determinants that is almost as efficient as the product formula, but avoids numerical instability problems associated with it.The determinant of a matrix A = ( aij ) n×n can be written in terms of its minors as det ( A ) = [UNK] = 1 ^ [UNK] = 0 ^ ni−1j | aij |.We show how to compute this expression effectively using O ( ( n log n ) ( log log n ) ) arithmetic operations and storage space by combining speed polynomial multiplication algorithms with ideas from numerical theory.Our approach relies on the fact that we are capable to assess all minors simultaneously at any point x ∈[ 0, 1 ] using only O ( ( n log n ) ( log log n ) ) ) arithmetic operations and storage space.This allows us to use fast polynomial multiplication methods to decrease the issue of computing the determinant to 1 of evaluating polynomials at many points.Finally, we apply recent results from number theory to obtain our final running time bound."
    },
    {
        "original_text": "We have studied the origin of the 60 K plateau in YBa2Cu3Ox by measuring the specific heat and magnetic susceptibility as functions of temperature, field strength, oxygen content x, and doping level p. The results show that the 60 K anomaly is due to an antiferromagnetic transition at TAF = 56 K for x= 0.6 but disappears with increasing x or decreasing p. We also find that the low-temperature upturns observed in both C/T and χ(T) are caused by impurity phases which appear when x > 0.65.  These results suggest that the 60 K anomality may be related to the appearance of these impurities. In addition we found that the high-field magnetization shows a sharp increase below 50 K indicating that there exists another phase transition near this temperature. This new phase has been identified as a charge density wave state (CDW). Finally, our data indicate that the CDW state appears only if the sample contains some amount of impurities.",
        "watermark_text": "We have studied the source of the 60 K plateau in YBa2Cu3Ox by measuring the specific heat and magnetic susceptibility as functions of temperature, field strength, oxygen content x, and doping level p.The results show that the 60 K anomaly is due to an antiferromagnetic transition at TAF = 56 K for x = 0. 6 but disappears with increasing x or decreasing p.We also find that the low - temperature upturns observed in both C / T and χ ( T ) are caused by impurity phases which appear when x > 0. 65.These results suggest that the 60 K anomality may be related to the appearance of these impurities.In addition we found that the high - field magnetization shows a sharp rise below 50 K indicating that there exists another phase change near this temperature.This new phase has been identified as a charge density wave state ( CDW ).Finally, our data indicate that the CDW state appears only if the sample contains some amount of impurities."
    },
    {
        "original_text": "The use of agents in the real world is becoming more widespread, especially for applications that require autonomous decision making or learning. However, there are many challenges associated with developing such systems including scalability issues when dealing with large numbers of agents. In this work we present an approach to optimising the performance of a committee of agents using genetic algorithms (GAs). We demonstrate how GAs can be used to evolve optimal agent behaviours within a simulated environment where each agent has different capabilities. The results show that our method improves upon existing approaches by increasing the overall efficiency of the system while reducing the number of messages required between agents. This research was funded by EPSRC grant EP/G066058/1. Agent-based computing is increasingly being applied to problems requiring autonomous decision-making and/or learning [1] . Examples include intelligent transportation [2] , smart grids [3] , healthcare [4] , manufacturing [5] , robotics [6] , and military operations [7] .\nHowever, there are several challenges associated with developing these types of systems [8] . One particular challenge relates to scalability as the number of agents increases [9] . For example, if one thousand agents need to make decisions on their own then it may not be possible to develop individualised behavioural models for all of them [10] . Instead, they must rely on some form of collective intelligence [11] which requires communication [12] . If too much information is communicated between agents then the network will become overloaded [13] resulting in poor performance [14] . Therefore, it becomes important to minimise the amount of data transmitted across the network [15] whilst still maintaining high levels of performance [16] .\nIn order to address these issues, researchers have proposed various techniques [17] ranging from simple heuristics [18] to sophisticated machine-learning methods [19] . These techniques typically involve either centralised [20] or decentralised [21] control mechanisms [22] . Centralised control involves a single entity controlling all aspects of the system [23] whereas decentralised control allows multiple entities to act independently [24] .",
        "watermark_text": "The use of agents in the real world is becoming more widespread, especially for applications that use autonomous decision making or learning.However, there are many challenges involved with developing such systems like scalability issues when dealing with big numbers of agents.In this work we present an approach to optimising the performance of a committee of agents using genetic algorithms ( GAs ).We demonstrate how GAs can be used to evolve optimal agent behaviors within a simulated environment where each agent has different capabilities.The results show that our methodology improves upon existing approaches by increasing the overall efficiency of the system while reducing the number of messages needed between agents.This research was funded by EPSRC grant EP / G066058 / 1.Agent - based computing is increasingly being applied to issues requiring autonomous decision - making and / or learning [ 1 ].Examples include intelligent transportation[ 2 ], smart grids[ 3 ], healthcare [ 4 ], manufacturing [ 5 ], robotics[ 6 ], and military operations[ 7 ].However, there are several challenges involved with developing these types of systems [ 8 ].One particular challenge relates to scalability as the number of agents increases [ 9 ].For example, if one thousand agents need to make decisions on their own then it may not be possible to develop individualised behavioural models for all of them [ 10 ].Instead, they must rely on some form of collective intelligence [ 11 ] which requires communication [ 12 ].If too much information is communicated between agents then the net will become overloaded [ 13 ] resulting in poor performance [ 14 ].Therefore, it becomes important to minimise the amount of data transmitted across the network[ 15 ] whilst still maintaining high levels of performance[ 16 ].In order to address these issues, researchers have proposed various techniques[ 17 ] ranging from simple heuristics [ 18 ] to sophisticated machine - learning methods [ 19 ].These techniques typically involve either centralised [ 20 ] or decentralised [ 21 ] control mechanisms [ 22 ].Centralised control involves a single entity controlling all aspects of the system[ 23 ] whereas decentralised control allows multiple entities to act independently [ 24 ]."
    },
    {
        "original_text": "We present the results of an analysis of the shapes, orientations, and alignments of dark matter subhalos in cosmological N-body simulations with different levels of baryonic physics included.  We find that the inclusion of baryons has little effect on the shape distribution but does affect the spin parameter distributions significantly; halos are more spherical when baryons are included than they would be if only gravity were acting upon them. The halo spins tend to be aligned perpendicularly to their major axes for all models considered here (including pure dark matter). This is consistent with previous studies which have found similar trends using other methods. However we also find evidence that this trend may not hold at very small scales where there appears to be some correlation between the direction of the angular momentum vector and the minor axis of the halo. Finally, we show that the presence or absence of baryons affects the degree of alignment between neighboring halos; halos are less strongly clustered around each other when baryons are included.",
        "watermark_text": "We present the results of an analysis of the shapes, orientations, and alignments of dark material subhalos in cosmological N - body simulations with different levels of baryonic physics included.We find that the inclusion of baryons has little effect on the shape distribution but does affect the spin parameter distributions significantly ; halos are more spherical when baryons are included than they would be if only gravitational were acting upon them.The halo spins tend to be aligned perpendicularly to their major axes for all models considered here ( including pure dark matter ).This is consistent with previous studies which have found similar trends using other methods.However we also find evidence that this trend may not hold at very tiny scales where there appears to be some correlation between the direction of the angular momentum vector and the minor axes of the halo.Finally, we show that the presence or absence of baryons affects the degree of alignment between neighboring halos ; halos are less strongly clustered around each other when baryons are included."
    },
    {
        "original_text": "The physisorption of nucleobases (adenine, cytosine, guanine and thymine) onto graphene is investigated by density functional theory calculations at the B3LYP/6-31G(d) level in vacuum conditions. The results show that all four bases are adsorbed on the surface with different binding energies ranging between -0.27 eV for adenine to -1.10 eV for cytosine. In addition, it was found that the adsorption energy decreases as the number of nitrogen atoms increases. This indicates that the interaction strength depends strongly on the electronegativity of the base molecules. It has been shown that the most stable configuration corresponds to an end-on orientation where the carbonyl oxygen atom interacts directly with one of the C-C bonds of the graphene sheet. \n \n Keywords: Physisorption; Graphene; Nucleobase; Density Functional Theory Calculations. Introduction \n \n Graphene is a two-dimensional material consisting of sp2-hybridized carbon atoms arranged into a honeycomb lattice structure [1] . Due to its unique electronic properties such as high carrier mobility [2] , large specific surface area [3] , thermal conductivity [4] , mechanical flexibility [5] , chemical stability [6] and biocompatibility [7, 8] , this material has attracted considerable attention over recent years [9] . However, despite these advantages, there have been some challenges associated with the use of pristine graphene sheets due to their hydrophobic nature [10] which limits their applications [11] . Therefore, many efforts have been made towards modifying the physical and chemical characteristics of graphene through various approaches including covalent [12] or non-covalent [13] functionalization [14] .\n \nIn particular, non-covalent functionalization can be achieved via π-π interactions [15] , hydrogen bonding [16] , electrostatic [17] , van der Waals [18] and ionic [19] forces [20] . Among them, π-π stacking is considered to be the strongest noncovalent force [21] . For example, several studies have reported that aromatic compounds [22] , fullerenes [23] , porphyrins [24] , metal complexes [25] and biomolecules [26] could interact with graphene surfaces via π-",
        "watermark_text": "The physisorption of nucleobases ( adenine, cytosine, guanine and thymine ) onto graphene is investigated by density functional theoretical calculations at the B3LYP / 6 - 31G ( d ) level in vacuum conditions.The results show that all four bases are adsorbed on the substrate with different binding energies ranging between - 0. 27 eV for adenine to - 1. 10 eV for cytosine.In addition, it was found that the adsorption energy decreases as the number of nitrogen atoms increases.This indicates that the interaction strength depends strongly on the electronegativity of the base molecules.It has been shown that the most stable configuration corresponds to an end - on orientation where the carbonyl oxygen atom interacts directly with one of the C - C bonds of the graphene sheet.Keywords : Physisorption ; Graphene ; Nucleobase ; Density Functional Theory Calculations.Introduction Graphene is a two - dimension material consisting of sp2 - hybridized carbon atoms arranged into a honeycomb lattice structure[ 1 ].Due to its unique electronic properties such as high carrier mobility [ 2 ], large specific surface area [ 3 ], thermal conductivity [ four ], mechanical flexibility [ 5 ], chemical stability [ 6 ] and biocompatibility [ 7, 8 ], this material has attracted considerable attention over recent years [ 9 ].However, despite these advantages, there have been some difficulties associated with the usage of pristine graphene sheets due to their hydrophobic nature[ 10 ] which limits their applications[ 11 ].Therefore, many attempts have been made towards modifying the physical and chemistry characteristics of graphene through various approaches including covalent[ 12 ] or non - covalent [ 13 ] functionalization[ 14 ].In particular, non - covalent functionalization can be achieved via π - π interactions [ 15 ], hydrogen bonding [ 16 ], electrostatic [ 17 ], van der Waals [ 18 ] and ionic [ 19 ] forces [ 20 ].Among them, π - π stacking is considered to be the strongest noncovalent force [ 21 ].For example, several studies have reported that aromatic compounds[ 22 ], fullerenes [ 23 ], porphyrins [ 24 ], metal complexes [ 25 ] and biomolecules [ 26 ] could interact with graphene surfaces via π -"
    },
    {
        "original_text": "We study the transport properties in a one-dimensional (1D) spin-orbit coupled system, where the electron-electron interactions are treated within the Hartree-Fock approximation. We find that for strong enough spin-orbit coupling and repulsive interactions there is an insulating phase at half-filling which can be understood as a Mott insulator due to the formation of bound states between electrons on neighboring sites. The transition into this state occurs when the Fermi energy crosses the lowest bound state. In addition we show how the presence of disorder changes these results. Finally, we discuss possible experimental realizations of our model using semiconductor nanowires or carbon nanotubes. Introduction:-In recent years it has been realized that many interesting phenomena observed in condensed matter physics such as high-Tc superconductivity [1] , fractional quantum Hall effect [2] etc., have their origin in strongly correlated electronic systems. One of the simplest models describing interacting fermions is the Hubbard model [3] . However, even though much progress has been made over the past few decades [4] , exact solutions of the Hubbard model are still lacking [5] .\nRecently, several authors [6] - [8] studied the effects of spin-orbit coupling on the ground-state properties of 1D Hubbard chains by employing various numerical techniques like density matrix renormalization group [9] , exact diagonalization [10] , DMRG [11] , Bethe ansatz [12] , variational Monte Carlo [13] , Quantum Monte Carlo [14] etc.. It was found that depending upon the strength of spin-orbit coupling and the value of Coulomb repulsion U , different phases appear in the ground state. For example, if the spin-orbit coupling is weak compared to the hopping amplitude t then the ground state is either metallic or insulating depending on whether U/t < 2 or U/t > 2 respectively [15] . On the other hand, if the spin-orbit",
        "watermark_text": "We study the transport properties in a one - dimensional ( 1D ) spin - orbit coupled scheme, where the electron - electron interactions are treated within the Hartree - Fock approximation.We find that for powerful enough spin - orbit coupling and repulsive interactions there is an insulating phase at half - filling which can be understood as a Mott insulator due to the formation of bound states between electrons on neighboring sites.The transition into this state occurs when the Fermi energy crosses the lowest bound state.In addition we show how the presence of disorder changes these findings.Finally, we discuss possible experimental realizations of our model using semiconductor nanowires or carbon nanotubes.Introduction : - In recent years it has been realized that many interesting phenomena noticed in condensed matter physics such as high - Tc superconductivity [ 1 ], fractional quantum Hall effect[ 2 ] etc., have their origin in strongly correlated electronic systems.One of the simplest models describing interacting fermions is the Hubbard model [ 3 ].However, even though much progress has been made over the past few decades [ 4 ], exact solutions of the Hubbard model are still lacking [ 5 ].Recently, several authors [ 6 ] - [ 8 ] studied the effects of spin - orbit pairing on the ground - state properties of 1D Hubbard chains by employing various numerical techniques like density matrix renormalization group[ 9 ], exact diagonalization[ 10 ], DMRG[ 11 ], Bethe ansatz[ 12 ], variational Monte Carlo[ 13 ], Quantum Monte Carlo[ 14 ] etc.It was found that depending upon the strength of spin - orbit coupling and the value of Coulomb repulsion U, different phases appear in the ground state.For example, if the spin - orbit coupling is weak compared to the hopping amplitude t then the ground state is either metallic or insulating depending on whether U / t 2 respectively [ 15 ].On the other hand, if the spin - orbit"
    },
    {
        "original_text": "The cumulative spectral power (CSP) is introduced as an alternative to the traditional method in analyzing earthquake data, which has been widely used by seismologists and geophysicists since it was first proposed by Aki(1957). The new tool can be applied to both earthquakes with known locations and those without any information on their epicenters. It also provides more detailed information about the source mechanism than that obtained using the traditional method. In this study we apply the new technique to analyze two large earthquakes occurred in China during recent years. We find that the results are consistent with previous studies based on other methods. This suggests that the new tool may provide useful information for studying seismic activities. Keywords: Earthquake; Source mechanism; Cumulative spectral power. 1 Introduction.\nSeismological research plays an important role in understanding the physical processes involved in earthquakes. Since its introduction into seismology by Aki(1957), the traditional method of calculating the cumulative energy released by earthquakes has become one of the most popular techniques among seismologists and geophysics researchers. However, there have been some problems associated with this method such as: i)it requires accurate location of the epicenter before analysis; ii)the result depends strongly upon the choice of time window length; iii)it cannot give enough information about the source mechanisms of earthquakes. To overcome these difficulties, many attempts have been made recently to develop new tools for analyzing earthquake data. For example, Sato et al.(1989) , Kao & Chen(1990) , Wu & Chiao(1991a , 1991b )and Wu(1993 developed different approaches to calculate the cumulative energy release rate. These authors found that the results were not always consistent with each other due to differences in the assumptions they had adopted.",
        "watermark_text": "The cumulative spectral power ( CSP ) is introduced as an alternative to the traditional method in analyzing earthquake data, which has been widely used by seismologists and geophysicists since it was first proposed by Aki ( 1957 ).The new tool can be applied to both earthquakes with known locations and those without any information on their epicenters.It also provides more detailed information about the source mechanism than that obtained using the traditional method.In this study we apply the new technique to analyze two big earthquakes occurred in China during recent years.We find that the results are consistent with previous studies based on other methods.This suggests that the new tool may provide helpful information for studying seismic activities.Keywords : Earthquake ; Source mechanism ; Cumulative spectral power.1 Introduction.Seismological research plays an significant role in understanding the physical processes involved in earthquakes.Since its introduction into seismology by Aki ( 1957 ), the traditional method of calculating the cumulative energy released by earthquakes has become one of the most popular techniques among seismologists and geophysics researchers.However, there have been some problems associated with this methodology such as : i ) it demands accurate location of the epicenter before analysis ; ii ) the result depends strongly upon the choice of time window length ; iii ) it cannot give sufficient information about the source mechanisms of earthquakes.To overcome these difficulties, many attempts have been made lately to develop novel tools for analyzing earthquake data.For example, Sato et al. ( 1989 ), Kao & Chen ( 1990 ), Wu & Chiao ( 1991a, 1991b ) and Wu ( 1993 developed different approaches to calculate the accumulated energy release rate.These authors found that the results were not always compatible with each other due to differences in the assumptions they had adopted."
    },
    {
        "original_text": "We have measured the Li abundance for 16 turn-off (TO) stars in the metal-rich open cluster 47 Tucanae, using high-resolution spectra obtained with UVES at VLT-UT2 telescope.  The TO stars are located between 0.8 and 1.0 solar radii above the main sequence turnoff point on the colour-magnitude diagram. We find that all but one star show an overabundance of Li compared to the Sun by factors ranging from 2 up to 6 times its solar value. This is consistent with previous studies which found similar results for other clusters such as M71 or NGC6397. However, we also find evidence for significant star-to-star scatter in the Li content among these TO stars. In particular, two out of our sample exhibit very low values of log(Li/H) = +0.3 dex and +0.4 dex respectively, while most of them display higher values around +1.1 dex.",
        "watermark_text": "We have measured the Li abundance for 16 turn - off ( TO ) stars in the metal - rich open cluster 47 Tucanae, using high - resolved spectra obtained with UVES at VLT - UT2 telescope.The TO stars are located between zero. 8 and 1. 0 solar radii above the main sequence turnoff point on the colour - magnitude diagram.We find that all but one star show an overabundance of Li compared to the Sun by factors ranging from 2 up to 6 times its solar value.This is consistent with previous studies which found similar results for other clusters such as M71 or NGC6397.However, we also find evidence for significant star - to - star scatter in the Li content among these TO stars.In particular, 2 out of our sample exhibit very low values of log ( Li / H ) = + 0. 3 dex and + zero. 4 dex respectively, while most of them display greater values around + 1. 1 dex."
    },
    {
        "original_text": "ZnO:Co nanocrystals were synthesized by the sol-gel method followed by annealing at different temperatures (500-700 °C). The structural, morphological, magnetic and electrical properties have been investigated in detail using X-ray powder diffraction (XRD), scanning electron microscopy (SEM) with energy dispersive spectroscopy (EDS), vibrating sample magnetometer (VSM), Hall effect measurement system and UV-Vis-NIR spectrophotometry techniques. XRD analysis reveals that all samples are single phase wurtzite structure without any impurity peaks. SEM images show that the particles are spherical in shape and their size increases with increasing temperature. VSM measurements reveal that the saturation magnetization decreases gradually as the annealing temperature is increased up to 700 °C due to the decrease in Co content. It was found that the resistivity shows an abrupt increase around 500 °C which indicates the occurrence of semiconductor-metal transition.",
        "watermark_text": "ZnO : Co nanocrystals were synthesized by the sol - gel method followed by annealing at various temperatures ( 500 - 700 °C ).The structural, morphological, magnetic and electrical properties have been investigated in detail using X - ray powder diffraction ( XRD ), scanning electron microscopy ( SEM ) with energy dispersive spectroscopy ( EDS ), vibrating sample magnetometer ( VSM ), Hall effect measurement system and UV - Vis - NIR spectrophotometry techniques.XRD analysis reveals that all samples are single phase wurtzite structure without any impurity spikes.SEM images show that the particles are spherical in shape and their size increases with increasing temperature.VSM measurements reveal that the saturation magnetization decreases gradually as the annealing temperature is increased up to 700 °C due to the decrease in Co content.It was found that the resistivity shows an abrupt increase near 500 °C which indicates the occurrence of semiconductor - metal transition."
    },
    {
        "original_text": "We report on the detection of the N VII hyperfine line at 1238 Å in the X-ray spectrum of the Galactic center source Sgr A* with Chandra and XMM-Newton observations. We find that this emission is consistent with gas having temperatures between 1 million K to 2 million K, densities between 10^6 cm^{-3} to 10^7 cm^{-3}, and column density of about 5 x 10^{20} cm^{-2}. This temperature range is higher than previous estimates based on other lines observed by Chandra or XMM-Newton. Our results are also inconsistent with models where the gas has been photoionized by UV radiation from nearby stars. These findings suggest that there may be an additional heating mechanism present near Sgr A* besides photoionization. In addition we detect absorption features associated with the same ion which could arise either due to foreground material along our line-of-sight towards Sgr A* or intrinsic to the accretion flow onto Sgr A* itself.",
        "watermark_text": "We report on the detection of the N VII hyperfine line at 1238 Å in the X - ray spectrum of the Galactic centre source Sgr A * with Chandra and XMM - Newton observations.We find that this emission is coherent with gas having temperatures between 1 million K to two million Ke, densities between 10 ^ 6 cm ^ { - three } to 10 ^ 7 cm ^ { - 3 }, and column density of about 5 x 10 ^ { twenty } cm ^ { - 2 }.This temperature range is higher than previous estimates based on other lines observed by Chandra or XMM - Newton.Our results are also inconsistent with models where the gas has been photoionized by UV radiation from nearby stars.These findings suggest that there may be an additional warming mechanism present near Sgr A * besides photoionization.In addition we detect absorption characteristics associated with the same ion which could arise either due to foreground matter along our line - of - sight towards Sgr A * or intrinsic to the accretion flow onto Sgr A * itself."
    },
    {
        "original_text": "We present new optical and near-infrared images, as well as archival radio data for the polar ring galaxy AM1934-563 (NGC4650A). The main results are summarized below:  1) We confirm that this galaxy is an edge-on S0/a with a bright nuclear point source surrounded by a faint disk.  2) A prominent dust lane crosses the central region in the north-south direction.  3) There appears to be no evidence for any recent star formation activity within the ring or along its edges.  4) The kinematics of the gas component show two distinct components; one associated with the ring itself and another which follows closely the rotation curve of the underlying stellar body.  5) The total mass of the gaseous ring amounts to about 10^9 M_sol. 6) The observed properties of NGC4650A can be explained if it has undergone a major merger event between two galaxies at least 0.5 Gyr ago.",
        "watermark_text": "We present new optical and near - infrared images, as well as archival radio data for the polar ring galaxy AM1934 - 563 ( NGC4650A ).The main results are summarized below : 1 )We confirm that this galaxy is an edge - on S0 / a with a brightly nuclear point source flanked by a faint disc.2 )A prominent dust lane crosses the center region in the north - south direction.3 ) There appears to be no proof for any latest star formation activity inside the ring or along its edges.4 )The kinematics of the gas component show two distinct components ; one affiliated with the ring itself and another which follows closely the rotation curve of the underlying star body.5 )The total mass of the gaseous ring amounts to about 10 ^ 9 M _ sol.6 )The observed properties of NGC4650A can be explained if it has undergone a major merging event between two galaxies at least 0. 5 Gyr ago."
    },
    {
        "original_text": "In this work, we consider the problem of multiuser detection (MUD) for code division multiple access systems with time-varying channels. We propose an algorithm that jointly performs user identification and data detection by using a maximum likelihood criterion. The proposed method is based on the expectation-maximization (EM) algorithm which iteratively estimates both the channel coefficients and transmitted symbols. In order to reduce computational complexity, we also develop a low-complexity suboptimal MUD scheme. Numerical results show that our proposed algorithms outperform existing schemes under various scenarios. Index Terms-Data detection, EM algorithm, Multiuser detection, Time varying channels. 1 Introduction Code-division-multiple-access (CDMA) has been widely used as one of the most promising technologies for next-generation wireless communications due to its high spectral efficiency [1] . However, CDMA suffers from severe interference between users caused by multipath propagation [2] , especially when the number of active users increases [3] .\nTo mitigate inter-user interference, multiuser detectors have been developed [4] - [6] . Among them, linear multiuser detectors are attractive because they can be implemented easily at low cost [7] . Unfortunately, these detectors suffer from performance loss compared to optimal multiuser detectors [8] . To improve their performance, nonlinear multiuser detectors such as successive interference cancellation [9] or parallel interference cancellation [10] were introduced. These detectors require accurate knowledge about the received signals [11] . Therefore, blind multiuser detectors [12] - [14] were proposed to estimate unknown parameters without any training sequence [15] . Although blind multiuser detectors do not need prior information about the received signal, they usually perform worse than conventional multiuser detectors [16] .\nRecently, there has been growing interest in developing multiuser detectors for time-varying channels [17] - [20] . Since the channel varies over time, it becomes more difficult to detect the transmitted symbol accurately [21] . Moreover, if the channel changes rapidly, then the detector may fail completely [22] . Thus, it is important to design robust multiuser detectors against rapid channel variations [23] .",
        "watermark_text": "In this work, we consider the problem of multiuser detection ( MUD ) for code subdivision multiple access systems with time - differing channels.We propose an algorithm that jointly performs user identification and data detector by utilizing a maximum likelihood criterion.The proposed method is based on the expectation - maximization ( EM ) algorithm which iteratively estimates both the channel coefficients and transmitted symbols.In order to reduce computational complexity, we also develop a low - complexity suboptimal MUD scheme.Numerical results show that our proposed algorithms outperform existing schemes under various scenarios.Index Terms - Data detection, EM algorithm, Multiuser detection, Time varying channels.1 Introduction Code - division - multiple - access ( CDMA ) has been widely utilized as one of the most promising technologies for next - generation wireless communications due to its high spectral efficiency [ 1 ].However, CDMA suffers from severe interference between users made by multiplepath propagation [ 2 ], particularly when the number of active users increases [ 3 ].To mitigate inter - user interference, multiuser detectors have been developed [ 4 ] - [ 6 ].Among them, linear multiuser detectors are attractive because they can be implemented easily at low cost [ 7 ].Unfortunately, these detectors suffer from performance loss compared to optimal multiuser detections [ 8 ].To improve their performance, nonlinear multiuser detectors such as successive interference cancellation [ 9 ] or parallel interference cancellation [ ten ] were introduced.These detectors require accurate knowledge about the received signals [ 11 ].Therefore, blind multiuser detectors[ 12 ] - [ 14 ] were proposed to estimate unknown parameters without any training sequence [ 15 ].Although blind multiuser detectors do not need prior information about the received signal, they usually perform worse than conventional multiuser detections [ 16 ].Recently, there has been growing interest in developing multiuser detectors for time - differing channels[ 17 ] -[ 20 ].Since the channel varies over time, it gets more difficult to detect the transmitted symbol accurately [ 21 ].Moreover, if the channel changes rapidly, then the detection may fail completely [ 22 ].Thus, it is important to design robust multiuser detectors against fast channel variants [ 23 ]."
    },
    {
        "original_text": "The vortex dynamics is studied numerically for fractal cluster structure (FCCS) superconductor by solving time-dependent Ginzburg-Landau equations under an external magnetic field. The FCCS has been proposed as one possible candidate to explain the origin of high-Tc cuprates, and it consists of randomly distributed clusters which are connected each other via Josephson coupling. We find that the resistivity increases rapidly when the applied current exceeds some threshold value Ic(H), where H denotes the strength of the external magnetic field. This behavior can be understood by considering the motion of vortices inside the clusters. In addition, we show that the critical current density Jc decreases gradually with increasing temperature T . Finally, we discuss how these results may be relevant to experiments on high-Tc cuprate superconductors. PACS: 74.20.-q; 74.25.+s; 74.60.Bz; 74.70.-k",
        "watermark_text": "The vortex dynamics is studied numerically for fractal cluster structure ( FCCS ) superconductor by solving time - dependent Ginzburg - Landau equations under an outside magnetic field.The FCCS has been proposed as one possible candidate to explain the origin of high - Tc cuprates, and it consists of random distributed clusters which are linked each other using Josephson coupling.We find that the resistivity increases rapidly when the applied current exceeds some threshold value Ic ( H ), where H denotes the strength of the outside magnetic field.This behavior can be understood by considering the motion of vortices inside the clusters.In addition, we show that the critical current density Jc decreases gradually with increasing heat T.Finally, we discuss how these outcomes may be relevant to experiments on high - Tc cuprate superconductors.PACS : 74. 20. - q ; 74. 25. + s ; 74. 60. Bz ; 74. 70. - k"
    },
    {
        "original_text": "We report the detection of beryllium (Be) lines in two ultra-low metallicity halo stars, CS 22892-052 and HE 0107-5240.  These are the first detections of Be in metal-poor halo stars with [Fe/H] < -2.5 dex. We find that these stars have high surface gravities for their temperatures, indicating they may be blue stragglers or other evolved objects. In addition to the Be features at 4131 Å and 4130 Å we also see evidence for an unidentified feature near 3970 Å which is likely due to C+N+O. This work was supported by NASA grant NAG5-9998. Keywords: Beryllium; Blue straggler; Metal poor star; Ultracool dwarf. 1. Introduction.\nThe discovery of extremely low-mass stars has opened up new avenues into understanding how planets form around very cool dwarfs. However, there remains much uncertainty about the formation process itself as well as the chemical composition of such systems. One important aspect of this problem involves determining whether or not terrestrial planet formation can occur within the habitable zone of ultracool dwarfs. To address this question it will be necessary to determine if the atmospheres of these stars contain significant amounts of heavy elements like carbon, nitrogen, oxygen, sulfur, sodium, potassium, magnesium, aluminum, silicon, calcium, titanium, iron, nickel, cobalt, copper, zinc, arsenic, selenium, silver, gold, mercury, lead, uranium, thorium, and plutonium. It should be noted that while some of these metals are produced during stellar nucleosynthesis others are synthesized only through cosmic ray spallation reactions occurring outside of stars.",
        "watermark_text": "We report the detection of beryllium ( Be ) lines in two ultra - low metallicity halo stars, CS 22892 - 052 and HE 0107 - 5240.These are the first detections of Be in metal - poor halo stars with [ Fe / H ] < - 2. 5 dex.We find that these stars have high surface gravities for their temperatures, indicating they may be blue stragglers or other evolved objects.In addition to the Be features at 4131 Å and 4130 Å we also see evidence for an unidentified feature near 3970 Å which is likely due to C + N + O.This work was supported by NASA grant NAG5 - 9998.Keywords : Beryllium ; Blue straggler ; Metal poor star ; Ultracool dwarf.1. Introduction.The discovery of extremely low - mass stars has opened up fresh avenues into understanding how planets form round very cool dwarfs.However, there remains much uncertainty about the formation process itself as long as the chemical composition of such systems.One important aspect of this problem involves determining whether or not terrestrial planetary formation can occur within the habitable zone of ultracool dwarfs.To address this question it will be necessary to determine if the atmospheres of these stars contain significant amounts of heavy elements like carbon, nitrogen, oxygen, sulfur, sodium, potassium, magnesium, aluminium, silicon, calcium, titanium, iron, nickel, cobalt, copper, zinc, arsenic, selenium, silver, gold, mercury, lead, uranium, thorium, and plutonium.It should be noted that while some of these metals are produced during stellar nucleosynthesis another are synthesized only through cosmic ray spallation reactions occurring outside of stars."
    },
    {
        "original_text": "We study theoretically and numerically the effect of spatial dispersion (SD) on the shape of a light pulse propagating through an InGaAs/GaAs quantum well (QW). We show that SD leads to significant changes in the temporal profile of the transmitted pulse, which can be used for its characterization. The results are obtained by solving Maxwell's equations using the finite-difference time-domain method with periodic boundary conditions. It is shown that the presence of SD causes the appearance of additional peaks at both sides of the main peak of the transmitted pulse. These peaks become more pronounced as the QW width increases. \n \n Keywords: Light propagation, Finite difference time domain method, Quantum wells, Spatial dispersion. 1 Introduction \n \n A number of recent studies have been devoted to investigating the effects of spatial dispersion (SD), also known as nonlocality or transverse momentum conservation [1] , on various physical phenomena such as nonlinear wave dynamics [2] - [4] , spontaneous emission [5] , and transport [6] . This interest has been motivated mainly by the fact that many semiconductor devices operate under conditions where SD plays an important role [7, 8] .\n \nIn this work we consider the problem of light transmission through a single-mode quantum well (QW) structure [9] . Our aim is to investigate how SD affects the shape of the transmitted pulse. To do so, we solve Maxwell's equations using the finitedifference time-domain (FDTD) method [10] with periodic boundary conditions [11] . As it will be demonstrated below, our numerical simulations reveal that SD gives rise to new features in the temporal profile of a transmitted pulse.",
        "watermark_text": "We study theoretically and numerically the impact of spatial dispersion ( SD ) on the shape of a light pulse propagating through an InGaAs / GaAs quantum well ( QW ).We show that SD leads to significant changes in the temporal profile of the transmission pulse, which can be used for its characterization.The results are obtained by solving Maxwell ' s equations using the finite - difference time - domain method with periodic boundary conditions.It is shown that the presence of SD causes the look of additional peaks at both sides of the main peak of the transmitted pulse.These peaks become more pronounced as the QW width increases.Keywords : Light propagation, Finite difference time domain method, Quantum wells, Spatial dispersion.1 Introduction A number of recent studies have been devoted to exploring the effects of spatial dispersion ( SD ), also known as nonlocality or transverse momentum conservation[ 1 ], on various physical phenomena such as nonlinear wave dynamics [ 2 ] - [ 4 ], spontaneous emission [ 5 ], and transport [ 6 ].This interest has been motivated mainly by the fact that many semiconductor devices operate under conditions where SD plays an important role[ 7, 8 ].In this work we consider the problem of light transmitting through a single - mode quantum well ( QW ) structure[ 9 ].Our aim is to explore how SD affects the shape of the transmitted pulse.To do so, we solve Maxwell ' s equations using the finitedifference time - domain ( FDTD ) method[ 10 ] with periodic boundary conditions[ 11 ].As it will be demonstrated below, our numerical simulations reveal that SD gives birth to fresh features in the temporal profile of a transmitted pulse."
    },
    {
        "original_text": "We present high angular resolution observations (0.1′′) of dust continuum, molecular line emissions, and maser lines toward the prototypical massive star-forming region G29.96-0 . 02 with the Submillimeter Array (SMA). The SMA data reveal that this source is composed of two compact components separated by 0.3 ′′ , which are associated with different physical processes. One component shows strong thermal dust emission peaking at 345 GHz as well as intense methanol masers distributed along an arc-like structure centered on it. This component coincides spatially with a bright infrared source detected by Spitzer Space Telescope. We propose that this component represents a hot core where massive star formation takes place. The other component exhibits weak dust continuum emission but strong SiO(5-4), SO2(34-26), CH3OH(7-6), and CH 3 CN(12-11) lines. These results suggest that this component may be tracing shocked regions driven by outflows or jets from young stellar objects embedded within the hot core.",
        "watermark_text": "We present high angular resolution observations ( 0. 1 ′ ′ ) of dust continuum, molecular line emissions, and maser lines toward the prototypical massive star - formation region G29. 96 - 0. 02 with the Submillimeter Array ( SMA ).The SMA data reveal that this source is composed of 2 compact components apart by 0. 3 ″ ′, which are associated with different physical processes.One component shows strong thermal dust emission peaking at 345 GHz as well as intense methanol masers distributed along an arc - like design centered on it.This component coincides spatially with a bright infrared source detected by Spitzer Space Telescope.We propose that this component represents a hot core where massive star forming takes place.The other component exhibits weak dust continuum emission but strong SiO ( 5 - four ), SO2 ( 34 - 26 ), CH3OH ( seven - 6 ), and CH 3 CN ( 12 - 11 ) lines.These results suggest that this component may be tracing shocked regions driven by outflows or jets from early stellar items embedded within the hot core."
    },
    {
        "original_text": "The nullstellensatz is an important theorem in algebraic geometry, which states that if a system of polynomial equations has no solution over some field then it must have at least one solution over its algebraic closure.  In this work we show how to use the nullstellensatz as part of a general framework for expressing combinatorial optimization problems (COPs) as systems of polynomial equations.   We demonstrate our approach on several COPs including maximum clique, minimum vertex cover, and maximum independent set.   ... This research was supported by NSF grant CCF-0430020. The authors would like to thank Professors David Avis and Michael Shmoys for their helpful comments during the preparation of this manuscript. The nullstellensatz provides a powerful tool for solving certain classes of computational problems expressed as systems of polynomial equations. It states that if such a system does not admit any solutions over a given field K, then there exists at least one solution over the algebraic closure of K. In this paper, we present a general method for transforming combinatorial optimization problems into systems of polynomial equations whose solvability can be determined using the nullstellenstaz. Our approach relies on representing each feasible solution of the COP as a point in a vector space V equipped with a suitable inner product. Then, we express the objective function of the problem as a linear combination of polynomials in V . Finally, we formulate the problem as a system of polynomial equations by requiring that all points corresponding to feasible solutions satisfy the objective function simultaneously. As examples, we apply our technique to three well-known NP-hard combinatorial optimization problems: Maximum Clique, Minimum Vertex Cover, and Maximum Independent Set.",
        "watermark_text": "The nullstellensatz is an essential theorem in algebraic geometry, which states that if a system of polynomial equations has no solution over some field then it must have at least one solve over its algebraic closure.In this work we show how to utilize the nullstellensatz as part of a general framework for expressing combinatorial optimization problems ( COPs ) as systems of polynomial equations.We demonstrate our approach on several COPs including maximum clique, minimum vertex coverage, and maximum independent set..This research was supported by NSF grant CCF - 0430020.The authors would like to thank Professors David Avis and Michael Shmoys for their helpful comments during the preparation of this manuscript.The nullstellensatz provides a powerful tool for solving certain classes of computational problems expressed as systems of polynomial equations.It states that if such a system does not admit any solutions over a given field K, then there exists at least one solution over the algebraic closing of field. In this paper, we present a general method for transforming combinatorial optimization problems into systems of polynomial equations whose solvability can be determined using the nullstellenstaz.Our approach relies on representing each feasible solution of the COP as a point in a vector space V equipped with a appropriate inner product.Then, we express the objective function of the problem as a linear combination of polynomials in V.Finally, we formulate the problem as a system of polynomial equations by requiring that all points corresponding to feasible solutions satisfy the objective function concurrently.As examples, we apply our technique to three well - famous NP - hard combinatorial optimization problems : Maximum Clique, Minimum Vertex Cover, and Maximum Independent Set."
    },
    {
        "original_text": "We present new photometric observations in the visible range for five faint irregular satellites of Uranus (Sycorax, Prospero,  Stephano, Setebos; Trinculo) obtained with the 1-m telescope at the South African Astronomical Observatory during two observing runs on September 24-25th 2010 and March 28-29th 2011. The data were reduced using standard procedures within IRAF. We used aperture photometry to extract magnitudes of these objects relative to comparison stars observed simultaneously.  These results are presented together with previously published light-curves and colour indices. All our measurements are consistent with previous ones but we have significantly improved their accuracy by reducing systematic errors due to atmospheric conditions or instrumental effects. Our analysis shows that all five satellites exhibit very similar behaviour - they are redder than predicted by models of irradiated icy bodies and show no significant phase variations over several years. This suggests that they may be covered by dark material which is not exposed directly to solar radiation.",
        "watermark_text": "We present new photometric observations in the visible range for five faint irregular satellites of Uranus ( Sycorax, Prospero, Stephano, Setebos ; Trinculo ) obtained with the 1 - m telescope at the South African Astronomical Observatory during two observing runs on September 24 - 25th 2010 and March 28 - 29th 2011.The data were reduced using standard procedures inside IRAF.We utilized aperture photometry to extract magnitudes of these objects relative to comparison stars observed simultaneously.These results are presented together with previously published light - curves and color indices.All our measurements are aligned with previous ones but we have significantly improved their accuracy by reducing systematic errors due to atmospheric conditions or instrumental effects.Our analysis shows that all 5 satellites exhibit very similarly behaviour - they are redder than predicted by models of irradiated ice bodies and show no significant phase variations over several years.This suggests that they may be covered by black material which is not exposed directly to sun radiation."
    },
    {
        "original_text": "We propose to use photonic molecules, which are composed of two or more coupled microcavities with different resonant wavelengths, as building blocks for novel types of lasers and optoelectronics devices. We show that the coupling between these cavities can lead to several interesting phenomena such as: (i) formation of hybridized modes, (ii) appearance of sharp peaks in emission spectrum at frequencies corresponding to avoided crossings of cavity eigenmodes, (iii) enhancement of spontaneous emission rate due to Purcell effect, and (iv) strong modification of optical gain properties by means of mode competition effects. These features open up possibilities for designing new types of laser sources based on photonic molecules, including single-mode lasers operating at room temperature without any external feedback elements. \n \n The proposed approach is illustrated using examples of photonic molecules consisting of pairs of semiconductor microdisks with slightly different diameters. It is shown that the considered structures allow one to obtain high quality factor whispering gallery modes with Q-factors exceeding 10^6.",
        "watermark_text": "We propose to use photonic molecules, which are composed of two or more coupled microcavities with different resonant wavelengths, as building blocks for new types of lasers and optoelectronics devices.We show that the coupling between these cavities can go to several interesting phenomena such as : ( i ) formation of hybridized modes, ( ii ) appearance of sharp peaks in emission spectrum at frequencies corresponding to avoided crossings of cavity eigenmodes, ( iii ) enhancement of spontaneous emission rate due to Purcell effect, and ( iv ) strong modification of optical gain properties by means of mode competition effects.These features open up possibilities for designing novel types of laser sources based on photonic molecules, including single - mode lasers operating at room temperature without any external feedback elements.The proposed approach is illustrated using examples of photonic molecules consisting of pairs of semiconductor microdisks with slightly different diameters.It is shown that the considered structures allow one to obtain high quality factor whispering gallery modes with Q - factors exceeding 10 ^ six."
    },
    {
        "original_text": "We study the universal substructure distribution (USSD) for dark matter halos in the Lambda-Cold Dark Matter model, and its dependence on halo mass and redshift. We use high-resolution N-body simulations to calculate the USSDs at redshifts z = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 . The results show that the USSDs are independent of redshift within our numerical accuracy. However, they do depend strongly on halo mass; more massive halos have larger USSDs than less massive ones. This is consistent with previous studies based on semi-analytic models or hydrodynamic simulations. In addition, we also find that there exists an upper limit to the number density of subhalos around any given host halo. Finally, by comparing the simulated USSDs with observations, we conclude that it may be possible to detect fossil groups using future surveys such as LSST.",
        "watermark_text": "We study the universal substructure distribution ( USSD ) for dark matter halos in the Lambda - Cold Dark Matter model, and its dependence on halo mass and redshift.We use high - resolution N - body simulations to calculate the USSDs at redshifts z = 0, 1, 2, three, 4, 5, six, 7, 8, 9.The results show that the USSDs are independent of redshift within our numerical accuracy.However, they do rely strongly on halo mass ; more massive halos have bigger USSDs than less massive ones.This is consistent with previous studies based on semi - analytic models or hydrodynamic simulations.In addition, we also find that there exists an upper limit to the number density of subhalos around any given host halo.Finally, by comparing the simulated USSDs with observations, we conclude that it may be feasible to detect fossil groups using future surveys such as LSST."
    },
    {
        "original_text": "We report on detection of a high amplitude (~40% rms) QPO at ~1258 Hz in the ultracompact X-ray binary 1A 1246-581 using data obtained with RXTE/PCA and Swift/BAT telescopes during its 2010 outburst. The source was observed for about 100 days, starting from March 24 to May 31, 2010. We find that this QPO is present only when the source luminosity exceeds 3×1036 erg s-1. This QPO has been detected previously by other authors but never reported as such strong. It may be associated with the spin frequency of the neutron star or orbital motion around it. \n \n Keywords: Quasi-Periodic Oscillation, Ultracompact X-Ray Binary, Spin Frequency, Orbital Motion, High Amplitude QPOs, Neutron Star, Black Hole, Pulsar, Accretion Disk",
        "watermark_text": "We report on detection of a high amplitude ( ~ 40 % rms ) QPO at ~ 1258 Hz in the ultracompact X - ray binary 1A 1246 - 581 using data obtained with RXTE / PCA and Swift / BAT telescopes during its 2010 outburst.The source was observed for about 100 days, starting from March 24 to Mai 31, 2010.We find that this QPO is present only when the source luminosity exceeds 3×1036 erg s - 1.This QPO has been detected previously by other authors but never reported as such strong.It may be associated with the spin frequency of the neutron star or orbital motion around it.Keywords : Quasi - Periodic Oscillation, Ultracompact X - Ray Binary, Spin Frequency, Orbital Motion, High Amplitude QPOs, Neutron Star, Black Hole, Pulsar, Accretion Disk"
    },
    {
        "original_text": "We present an analytic expression for the thermal Casimir force acting on two parallel plates made out of different materials, one being metallic (silver) while another is dielectric (silicon dioxide). The result obtained agrees with that derived by Lifshitz theory within 1% accuracy in the whole range of separations considered here. We also show how our results can be used to calculate the temperature dependence of the Casimir pressure at fixed separation distance. \n \n In this work we consider the case where one plate consists of silver and other of silicon dioxide. Silver has been chosen because it is widely used as a coating material in microelectromechanical systems (MEMS), whereas SiO2 is often employed as a substrate or insulator layer in MEMS devices. Our results are applicable not only to these specific cases but also to any system consisting of two parallel plates separated by vacuum gap filled with gas medium. This includes such diverse situations like semiconductor heterostructures, quantum dots, nanowires etc., which have attracted considerable attention recently due to their potential applications in nanotechnology. \n \n It should be noted that the problem under consideration was first addressed theoretically more than 50 years ago [1] . However, despite numerous attempts [2] , no exact solution has yet been found. Therefore, most theoretical studies were performed using approximate methods [3] - [6] . These approaches include various modifications of the proximity force approximation [7, 8] , the Derjaguin-Muller-Toporov method [9] , the multiple reflection expansion [10] , the scattering matrix formalism [11] , the Green's function technique [12] , the density functional theory [13] , the mode summation [14] , the fluctuating surface charge model [15] , the effective-medium theory [16] , the generalized plasmon-pole model [17] , the Drude-Lorentz model [18] , the hydrodynamic model [19] , the nonlocal response [20] , the local field correction [21] , the random phase approximation [22] , the Monte Carlo simulation [23] , the finite element method [24] , the numerical integration [25] , the variational principle [26] , the perturbation theory [27] , the renormalization group [28] , the self-consistent screening [29] ,",
        "watermark_text": "We present an analytic expression for the thermal Casimir force acting on two parallel plates formed out of different materials, one being metallic ( silver ) while another is dielectric ( silicon dioxide ).The result obtained agrees with that derived by Lifshitz theory within 1 % accurate in the whole range of separations considered here.We also show how our outcomes can be used to calculate the temperature dependence of the Casimir pressure at fixed separation distance.In this work we consider the case where one plate consists of silver and other of silicon dioxide.Silver has been chosen because it is widely utilized as a coating material in microelectromechanical systems ( MEMS ), whereas SiO2 is often employed as a substrate or insulator layer in MEMS devices.Our results are applicable not only to these specific cases but additionally to any scheme consisting of two parallel plates split by vacuum gap filled with gas medium.This includes such diverse situations like semiconductor heterostructures, quantum dots, nanowires etc., which have attracted considerable attention recently due to their possible applications in nanotechnology.It should be noted that the problem under consideration was first addressed theoretically more than 50 years ago[ 1 ].However, despite numerous attempts [ 2 ], no exact solution has yet been found.Therefore, most theoretical studies were performed using approximate techniques [ 3 ] - [ 6 ].These approaches include various modifications of the proximity force approximation [ 7, 8 ], the Derjaguin - Muller - Toporov method[ 9 ], the multiple reflection expansion[ 10 ], the scattering matrix formalism [ 11 ], the Green ' s function technique[ 12 ], the density functional theory [ 13 ], the mode summation[ 14 ], the fluctuating surface charge model[ 15 ], the effective - medium theory [ 16 ], the generalized plasmon - pole model[ 17 ], the Drude - Lorentz model[ 18 ], the hydrodynamic model [ 19 ], the nonlocal response [ 20 ], the local field correction[ 21 ], the random phase approximation[ 22 ], the Monte Carlo simulation [ 23 ], the finite element method[ 24 ], the numerical integration [ 25 ], the variational principle[ 26 ], the perturbation theory [ 27 ], the renormalization group[ 28 ], the self - consistent screening[ 29 ],"
    },
    {
        "original_text": "We have studied the polarizability and hyperpolarizability tensors for clusters Li_n (n = 2, 3) using density-functional theory with the B3LYP functional in combination with large basis sets. The results are compared to those obtained by other authors as well as experimental data available for n=2. We find that our calculated values agree very well with previous theoretical work but disagree significantly with experiment. This is attributed mainly to the fact that we use an atomic orbital basis set which does not include diffuse functions. \n \n Keywords: Polarizability tensor; Hyperpolarizability tensor; Clustering; Density-functional theory; Basis set; Diffuse functionals; Lithium cluster; B3LYP functional. 1 Introduction \n \n In recent years there has been considerable interest in studying the optical properties of small metal clusters due to their potential applications in optoelectronic devices such as lasers [1] , light-emitting diodes [2] , solar cells [3] , etc.. These materials can be used either directly or incorporated into more complex structures [4] . For example, it was shown recently that gold nanocluster films could be prepared on glass substrates [5] . It should also be noted that these materials may exhibit interesting nonlinear optical effects [6] .\n \nThe study of the optical response of clusters requires knowledge about both linear and nonlinear optical susceptibilities [7, 8] . The latter quantity describes how strongly the material responds when exposed simultaneously to two or more laser beams [9] . A convenient way to calculate this property is through the so-called sum-over-states approach [10] where one calculates the imaginary part of the third-order susceptibility χ(3) (ω1, ω2, ω3). Here, the frequencies ωi correspond to different wavelengths of incident radiation. If all three frequencies coincide then the corresponding susceptibility is called the static hyperpolarizability β0 [11] .",
        "watermark_text": "We have studied the polarizability and hyperpolarizability tensors for clusters Li _ n ( n = 2, three ) using density - functional theory with the B3LYP functional in combination with large basis sets.The results are compared to those obtained by other writers as well as experimental data available for n = 2.We find that our calculated values agree very well with previous theoretical work but disagree significantly with experimental.This is attributed mainly to the fact that we use an atomic orbital basis set which does not cover diffuse functions.Keywords : Polarizability tensor ; Hyperpolarizability tensor ; Clustering ; Density - functional theory ; Basis set ; Diffuse functionals ; Lithium cluster ; B3LYP functional.1 Introduction In recent years there has been considerable interest in studying the optical properties of little metal clusters due to their potential applications in optoelectronic devices such as lasers[ 1 ], light - emitting diodes [ 2 ], solar cells[ 3 ], etc.These materials can be used either directly or incorporated into more complex structures [ 4 ].For example, it was shown recently that gold nanocluster films could be prepared on glass surfaces [ 5 ].It should also be noted that these materials may exhibit interesting nonlinear optical effects [ 6 ].The study of the optical response of clusters requires knowing about both linear and nonlinear optical susceptibilities [ 7, 8 ].The latter quantity describes how strongly the material responds when exposed simultaneously to two or more laser streams [ 9 ].A convenient way to calculate this property is through the so - called sum - over - states approach [ 10 ] where one calculates the imaginary part of the third - order susceptibility χ ( 3 ) ( ω1, ω2, ω3 ).Here, the frequencies ωi correspond to different wavelengths of incident radiation.If all three frequencies coincide then the respective susceptibility is called the static hyperpolarizability β0 [ 11 ]."
    },
    {
        "original_text": "The main goal of this research is the study and analysis of how different users can contribute in an open source software project, by sharing their knowledge through comments on issues or pull requests (PRs). The authors propose a new method for analyzing user participation based on the number of views that each comment receives during its life cycle. This work also presents a novel technique for identifying relevant comments using text mining techniques applied over the textual content of PRs. Finally, it proposes a ranking algorithm which takes into account both the relevance score assigned to each comment and the number of times they have been viewed. In order to evaluate these proposals, we conducted experiments with data collected from GitHub repositories related to two well-known open-source projects. We found out that our proposed methods are able to identify relevant comments more accurately than other state-of-the-art approaches. Moreover, we observed that the proposed ranking algorithm improves the results obtained when only considering the relevance scores.",
        "watermark_text": "The main goal of this research is the study and analysis of how different users can contribute in an open source software project, by sharing their knowledge through comments on problems or pull requests ( PRs ).The authors propose a novel method for analyzing user participation based on the number of views that each comment receives during its life cycle.This work also presents a novel technique for identifying relevant remarks using text mining techniques applied over the textual content of PRs.Finally, it proposes a ranking algorithm which takes into account both the relevance score assigned to each remark and the number of times they have been watched.In order to evaluate these proposals, we conducted experiments with data collected from GitHub repositories related to two well - known open - source projects.We found out that our proposed techniques are able to identify relevant comments more accurately than other state - of - the - art approaches.Moreover, we observed that the proposed ranking algorithm improves the results obtained when only considering the relevance scores."
    },
    {
        "original_text": "We study the existence and uniqueness of equilibrium states for some classes of potentials in the presence of an external magnetic field, using results on the asymptotic behavior of solutions to Schrödinger equations obtained by J. Bourgain and M. Goldstein.  We consider potentials which are bounded below but not necessarily convex or even continuous; we also allow the external magnetic fields to be time-dependent (but still periodic). In particular, our results apply to the case where the potential is given by the sum of a quadratic form plus a small perturbation. The main tool used here is the so-called ``Bourgain-Goldstein method'', which consists in studying the evolution of the Wigner transform of the solution to the Schrödinger equation under the action of the unitary group generated by the corresponding Hamiltonian. \nIntroduction\n\nThe purpose of this article is to prove that there exists at most one equilibrium state associated to certain classes of potentials in the context of quantum mechanics when these potentials interact with an external magnetic field. This result was first proved by D. Ruelle [Ru] , who showed that if V : T d → R satisfies suitable conditions then there exists exactly one equilibrium measure µV . These assumptions include the fact that V should have superlinear growth at infinity and satisfy a condition known as ``uniform ellipticity''. However, it turns out that many interesting examples do not fall into this category. For example, let us mention the following two examples:  • If V = −|x| 2 + |y| 2 , then V does not grow faster than linearly at infinity.",
        "watermark_text": "We study the existence and uniqueness of equilibrium states for some classes of potentials in the presence of an external magnetic field, utilizing results on the asymptotic behavior of solutions to Schrödinger equations obtained by J. Bourgain and M. Goldstein.We consider potentials which are bounded below but not always convex or even continuous ; we also allow the external magnetic fields to be time - dependent ( but still periodic ).In particular, our results apply to the case where the potential is given by the sum of a quadratic form plus a little perturbation.The main tool used here is the so - called ` ` Bourgain - Goldstein methodology ' ', which comprises in studying the evolution of the Wigner transform of the solution to the Schrödinger equation under the action of the unitary group produced by the corresponding Hamiltonian.Introduction The purpose of this article is to prove that there exists at most one equilibrium state associated to certain classes of potentials in the context of quantum mechanics when these potentials interact with an external magnetic field.This result was first proved by D. Ruelle[ Ru ], who showed that if V : T d → R satisfies suitable conditions then there exists exactly one equilibrium measure µV.These assumptions include the fact that V should have superlinear growth at infinity and satisfy a condition known as ` ` uniform ellipticity ' '.However, it turns out that many interesting examples do not fall into this category.For example, let us mention the following two examples : •If V = − | x | 2 + | y | 2, then V does not grow quicker than linearly at infinity."
    },
    {
        "original_text": "We have studied the variation of the Amati relation (Amati et al., 2002) in a sample of about 100 GRBs detected by Swift satellite and we found that it is not constant, but varies as a function of redshift z. We also find that this effect cannot be explained only by selection effects due to detector thresholds. \n \n The observed evolution can be described by a power law dependence on cosmological time t~(1+z)3.5. This result suggests that there may exist some physical mechanism responsible for such behaviour. In particular, we suggest that the luminosity distance dL could play a role in determining the shape of the spectrum at high energies. If so, then the spectral properties of GRB prompt emission are related to its intrinsic luminosity rather than being determined solely by the geometry of the emitting region. \nThe results presented here support previous claims that the Amati relation should be used cautiously when applied to distant bursts.",
        "watermark_text": "We have studied the variance of the Amati relation ( Amati et al., 2002 ) in a sample of about 100 GRBs detected by Swift satellite and we found that it is not constant, but varies as a function of redshift z.We also find that this effect neither be understood only by selection effects due to detector thresholds.The observed evolution can be described by a power law dependence on cosmological time t ~ ( 1 + z ) three. 5.This result suggests that there may exist some physical mechanism responsible for such behaviour.In particular, we suggest that the luminosity distance dL could play a role in determining the shape of the spectral at high energies.If so, then the spectral properties of GRB prompt emission are related to its inherent luminosity rather than being determined solely by the geometry of the emitting region.The results presented here support previous claims that the Amati relationship should be used cautiously when applied to distant bursts."
    },
    {
        "original_text": "The low energy effective theories for superstrings are supergravity and supersymmetric gauge theories in four dimensions, which can be obtained by compactifying the extra six spatial dimensions on a Calabi-Yau manifold.  In this talk I will discuss some recent results about lattice models that provide an alternative approach to studying these theories. The basic idea is to use Monte Carlo simulations to study supersymmetric field theories defined on a finite number of points (the sites) of a regular d-dimensional hypercubic lattice with periodic boundary conditions. These models have been studied extensively over the past few years using numerical techniques such as exact diagonalization, quantum Monte Carlo methods, and density matrix renormalization group algorithms. Recently we developed new Monte Carlo simulation techniques based on the worm algorithm that allow us to simulate large systems at very high temperatures where conventional Monte Carlo methods fail because they suffer from critical slowing down. We used our new method to calculate the free energies of several different supersymmetric lattice models including the N = 4 supersymmetric Yang-Mills theory and the N = 1 supersymmetric U(1) gauge theory coupled to matter fields in various representations.",
        "watermark_text": "The low energy effective theories for superstrings are supergravity and supersymmetric gauge theories in 4 dimensions, which can be obtained by compactifying the extra six spatial dimensions on a Calabi - Yau manifold.In this talk I will discuss some recent results about lattice models that provide an alternative approach to studying these theories.The basic idea is to use Monte Carlo simulations to study supersymmetric field theories defined on a finite number of points ( the sites ) of a regular d - dimensional hypercubic lattice with periodic border conditions.These models have been studied extensively over the past few years using numerical techniques such as exact diagonalization, quantum Monte Carlo methods, and density matrix renormalization group algorithms.Recently we developed new Monte Carlo simulation techniques based on the worm algorithm that enable us to simulate large systems at very high temperatures where conventional Monte Carlo methods fail because they suffer from critical slowing down.We used our new technique to calculate the free energies of several different supersymmetric lattice models including the N = 4 supersymmetric Yang - Mills theory and the N = 1 supersymmetric U ( 1 ) gauge theoretical coupled to matter fields in various representations."
    },
    {
        "original_text": "We present an atomistic multiscale approach to the study of charge transport through stretched single-stranded DNA (ssDNA). The method combines molecular dynamics simulations with quantum mechanical calculations on small fragments, which are used as input for a tight-binding description of larger systems. We show that this scheme allows us to reproduce experimental results obtained by scanning tunneling microscopy experiments performed at room temperature. In particular we find that our calculated conductance agrees well with experiment when using realistic values for the hopping parameters between neighboring base pairs. Our analysis shows that the main contribution to the current is due to electrons localized along the backbone chain. These findings suggest that ssDNA can be considered as a promising material for future applications such as nanoelectronic devices or sensors. \n \n Introduction \n \n Single stranded DNA has been studied extensively over many years both experimentally [1]-[3] and theoretically [4]-[6] . It was found that its structure depends strongly on environmental conditions like pH value [7] , ionic strength [8] - [10] , solvent [11] , temperature [12] , stretching [13] , etc.. This makes it possible to use ssDNA as a sensor [14] - [16] or even as a nanomaterial [17] - [19] . For example, recent studies have shown that ssDNA can form stable helical structures [20] - [22] . Furthermore, it was demonstrated that ssDNA can act as a template for protein synthesis [23] .\n \nIn addition to these structural properties there is growing interest in understanding how charge carriers move through ssDNA [24] - [26] . Recent theoretical investigations showed that electron transfer rates depend sensitively on the conformation of the molecule [27] - [29] . Experimentally, it was observed that the conductivity decreases exponentially with increasing length [30] - [32] . However, the exact mechanism behind this effect remains unclear [33] . \n \n Here we propose a new computational scheme combining classical molecular dynamics (MD) simulations [34] with density functional theory (DFT) [35] based quantum chemical calculations [36] [ Fig. 1(a) ]. Using this approach we calculate the transmission function T(E), i.e., the probability amplitude for an electron injected into one end of the system to reach the other end",
        "watermark_text": "We present an atomistic multiscale approach to the study of charge transport through stretched single - stranded DNA ( ssDNA ).The method combines molecular dynamics simulations with quantum mechanical calculations on small fragments, which are used as input for a tight - binding description of wider systems.We show that this system allows us to reproduce experimental results obtained by scanning tunneling microscopy experiments performed at room fever.In particular we find that our calculated conductance agrees well with experiment when using realistic levels for the hopping parameters between neighbouring base pairs.Our analysis shows that the main contribution to the current is owing to electrons localized along the backbone chain.These findings suggest that ssDNA can be considered as a promising material for future applications such as nanoelectronic devices or sensors.Introduction Single stranded DNA has been studied extensively over long years both experimentally [ 1 ] - [ 3 ] and theoretically [ four ] - [ 6 ].It was found that its structure depends strongly on environmental conditions including pH value [ 7 ], ionic strength[ 8 ] - [ 10 ], solvent[ 11 ], temperature[ 12 ], stretching [ 13 ], etc.This makes it possible to use ssDNA as a sensor [ 14 ] - [ 16 ] or even as a nanomaterial [ 17 ] - [ 19 ].For example, recent studies have shown that ssDNA can form stable helical structures[ 20 ] -[ 22 ].Furthermore, it was demonstrated that ssDNA can act as a template for protein synthesis [ 23 ].In addition to these structural properties there is growing interest in understanding how charge carriers move through ssDNA[ 24 ] -[ 26 ].Recent theoretical investigations showed that electron transfer rates depend sensitively on the conformation of the molecule[ 27 ] -[ 29 ].Experimentally, it was observed that the conductivity decreases exponentially with increasing length[ 30 ] -[ 32 ].However, the exact mechanism behind this effect remains unclear [ 33 ].Here we propose a novel computational scheme combining classical molecular dynamics ( MD ) simulations[ 34 ] with density functional theory ( DFT ) [ 35 ] based quantum chemical calculations [ 36 ] [ Fig. 1 ( a ) ].Using this approach we calculate the transmission function T ( E ), i. e., the probability amplitude for an electron injected into one end of the system to reach the other end"
    },
    {
        "original_text": "We study the propagation of traveling waves (TWs) in excitable media with spatially distributed parameters, which are subject to both external forcing and internal fluctuations. We show that TWs can be generated spontaneously even if there is no deterministic source for them. The mechanism responsible for this phenomenon is related to the presence of an unstable stationary state between two stable ones. In particular, we demonstrate how spontaneous generation of TWs occurs due to stochastic resonance induced by additive white Gaussian noise. Finally, we present numerical results illustrating the effect of multiplicative colored noise on the dynamics of TWs. Propagation of traveling waves (TW) in excitable media has been studied extensively over recent years [1] . It was shown that TWs may appear as a result of various mechanisms such as: i) intrinsic instabilities [2] , ii) coupling-induced instabilities [3] or iii) forced oscillations [4] .\nIn many cases it is assumed that the medium under consideration is homogeneous so that all its properties do not depend explicitly on space coordinates. However, real physical systems usually have spatial variations of their characteristics [5] . For example, one-dimensional models describing cardiac tissue [6] include heterogeneity in the form of local changes in refractory periods [7, 8] . Another important factor influencing wave propagation is noise [9] . Noise plays different roles depending on whether it acts additively [10] or multiplicatively [11] . Moreover, noise may also affect the shape of the propagating front [12] .",
        "watermark_text": "We study the propagation of traveling waves ( TWs ) in excitable media with spatially distributed parameters, which are subject to both external forcing and internal fluctuations.We show that TWs can be generated spontaneously regardless if there is no deterministic source for them.The mechanism responsible for this phenomenon is related to the presence of an unstable stationary state between 2 stable ones.In particular, we demonstrate how spontaneous generation of TWs occurs due to stochastic resonance caused by additive white Gaussian noise.Finally, we present quantitative results illustrating the effect of multiplicative colored noise on the dynamics of TWs.Propagation of traveling waves ( TW ) in excitable media has been studied extensively over recent years [ 1 ].It was shown that TWs may appear as a result of different mechanisms such as : i ) intrinsic instabilities [ 2 ], ii ) coupling - induced instabilities[ 3 ] or iii ) forced oscillations[ 4 ].In many cases it is presumed that the medium under consideration is homogeneous so that all its properties do not depend explicitly on space coordinates.However, real physical systems usually have spatial variants of their characteristics[ 5 ].For example, one - dimensional models describing cardiac tissue[ 6 ] include heterogeneity in the form of local changes in refractory periods[ 7, 8 ].Another important factor influencing wave propagation is noise[ 9 ].Noise plays different roles depending on whether it acts additively [ 10 ] or multiplicatively [ 11 ].Moreover, noise may also affect the shape of the propagating front [ 12 ]."
    },
    {
        "original_text": "We present results on searches for gravitational wave (GW) burst signals using data collected by the Laser Interferometer Gravitational-Wave Observatory during its fourth science run, which took place between September 2005 and January 2007. We use two different search methods to look for GW bursts: one based on matched filtering with template waveforms and another that uses an optimal filterbank method. The latter is used as part of a blind analysis where we do not know what type or strength of signal may be present in our data until after it has been analyzed. In addition to these analyses, we also perform several consistency checks designed to identify any problems associated with either detector's performance over this period. No significant candidates are found in any of these searches. Using simulated signals injected into the data at random times, we estimate upper limits on the rate density of binary black hole mergers detectable within a given range of total mass.",
        "watermark_text": "We present results on searches for gravity wave ( GW ) burst signals using data collected by the Laser Interferometer Gravitational - Wave Observatory during its 4th science run, which took place between Sept 2005 and January 2007.We utilize two different search mechanisms to look for GW bursts : one based on matched filtering with template waveforms and another that uses an optimal filterbank method.The latter is used as part of a blind analysis where we do not know what type or strength of signal might be present in our data until after it has been analyzed.In addition to these analyses, we also perform several consistency tests designed to identify any issues associated with either detector ' s performance over this period.No significant candidates are found in any of these searches.Using simulated signals injected into the data at random times, we approximate upper limits on the rate density of binary darkness hole mergers detectable within a given range of total mass."
    },
    {
        "original_text": "We present the first detailed analysis of the X-ray spectrum of the Seyfert 1 galaxy NGC 3783 using data obtained by the High Energy Transmission Grating Spectrometer (HETGS) on board the Chandra Observatory. The source was in an active state during our observation, and we find that its emission is dominated by strong absorption lines due to highly ionized species such as O viii-xxii, Ne ix-xiii, Mg xii-xv, Si xiv-xxvi, S xix-xxxi, Ar xxviii-xxxviii, Ca xx-xxxi, Fe xxv-xxvi, and Ni xxviii-xxix. We detect several narrow emission features which are likely associated with resonant scattering of continuum photons off ions located along the line-of-sight towards the central engine. In addition, there appears to be evidence for broad emission components at energies above 10 keV.",
        "watermark_text": "We present the first detailed analysis of the X - ray spectrum of the Seyfert 1 galaxy NGC 3783 using data obtained by the High Energy Transmission Grating Spectrometer ( HETGS ) on aboard the Chandra Observatory.The source was in an ongoing state during our monitoring, and we find that its emission is dominated by strongly absorption lines due to highly ionized species such as O viii - xxii, Ne ix - xiii, Mg xii - xv, Si xiv - xxvi, S xix - xxxi, Ar xxviii - xxxviii,Ca xx - xxxi, Fe xxv - xxvi, and Ni xxviii - xxix.We detect several narrow emission features which are likely associated with resonant scattering of continuum photons off ions located along the line - of - sight towards the center engine.In addition, there appears to be evidence for wide emission parts at energies above 10 keV."
    },
    {
        "original_text": "We present an analytical solution to the steady-state forster energy transfer between two freely diffusing membrane-bound fluorophores in close proximity (<10 nm). The model is based on the assumption that both donor and acceptor molecules are bound to the same lipid bilayer with their transition dipole moments parallel to each other but perpendicular to the plane of the membrane. We show how this simple geometry can be used to derive a closed-form expression for the fluorescence lifetime of the donor molecule as well as its dependence on the concentration of acceptors. This approach allows us to extract information about the distance distribution between donors and acceptors directly from experimental data without any additional assumptions or fitting parameters. In addition we demonstrate how our results can be applied to study the lateral organization of proteins within biological membranes using single-molecule spectroscopy. Single-molecule FRET experiments have been widely used over recent years to investigate protein-protein interactions at the molecular level1-5 . However, despite significant progress made during last decade6-9 , there still remain several challenges associated with extracting quantitative structural information from such measurements10-13 .\nIn particular, it has recently become apparent that many commonly employed methods for analyzing single-molecule FRET data suffer from systematic errors due to various factors including photophysical properties of fluorescent dyes14-16 , heterogeneity of sample17-19 , presence of multiple species20-22 , etc. . To overcome these difficulties, several groups23-26 have developed sophisticated statistical approaches which allow one to obtain reliable estimates of key physical quantities characterizing the system under investigation by performing global fits to large sets of experimental data27-29 . Unfortunately, however, most of these techniques require extensive computational resources and/or involve complicated numerical procedures making them difficult...",
        "watermark_text": "We present an analysis solution to the steady - state forster energy transfer between two freely diffusing membrane - bound fluorophores in close proximity ( < 10 nm ).The model is based on the assumption that both donor and acceptor molecules are attached to the same lipid bilayer with their transition dipole moments parallel to each other but perpendicular to the plane of the membrane.We show how this simple geometry can be used to derive a closed - form expression for the fluorescence lifetime of the donor molecule as well as its dependence on the concentration of acceptors.This approach enables us to extract information about the distance distribution between donors and acceptors directly from experimental data lacking any additional assumptions or fitting parameters.In addition we demonstrate how our results can be applied to study the lateral organization of proteins within biological membranes using single - molecule spectroscopy.Single - molecule FRET experiments have been widely used over modern years to investigate protein - protein interactions at the molecular level1 - five.However, despite significant progress made during last decade6 - 9, there still remain several challenges involved with extracting quantitative structural data from such measurements10 - 13.In particular, it has recently become apparent that many commonly employed methods for analyzing single - molecule FRET data suffer from systematic errors due to various factors including photophysical properties of fluorescent dyes14 - 16, heterogeneity of specimen17 - 19, presence of multiple species20 - 22, etc..To overcome these difficulties, several groups23 - 26 have developed sophisticated statistical approaches which allow one to obtain reliable estimates of key physical quantities characterizing the system under investigation by performing global fits to large sets of experimental data27 - 29.Unfortunately, however, most of these methods require intensive computational resources and / or involve complex numerical processes making them difficult."
    },
    {
        "original_text": "We report the discovery and characterization of TrES-3b, an extrasolar planet with mass M = 1.3 MJup orbiting its host star every 31 hours at 0.081 AU (1.7 stellar radii). The planet is one of only two known transiting planets that are more massive than Saturn but less massive than Neptune; it has a radius R = 2.2 RJup and effective temperature T eff = 2400 K. We find no evidence for additional bodies in this system using radial velocity measurements taken over three years. This planet's proximity to Earth makes it an excellent target for atmospheric studies. \n \n Keywords: Extrasolar planet - Discovery - Transit photometry - Radial velocities - Atmosphere - Planetary systems \n \n \n \n Introduction \n \n In recent years there have been several discoveries of giant exoplanets with orbital periods shorter than four days. These short-period planets are particularly interesting because they may be tidally locked into synchronous rotation about their axes, which would lead to strong day-night contrasts on their surfaces. Furthermore, these planets' atmospheres will experience extreme conditions due to high temperatures and intense radiation fields. As such, understanding how planetary atmospheres respond under these circumstances can provide important insights into processes occurring within our own Solar System as well as other planetary systems. \n \n Here we present the discovery and initial characterization of TrES-3b; a hot Jupiter with a period P = 3.09 d discovered by the transit method. Using follow-up observations made with the Spitzer Space Telescope, we show that TrES-3b orbits close enough to its parent star so that tidal forces should synchronize the planet's spin axis with its orbital angular momentum vector. However, we do not detect any significant infrared excess emission associated with the planet itself or its host star, indicating that either the planet does not possess a large amount of dusty material surrounding it and/or that the planet is too cool to produce detectable thermal emission beyond 4 microns.",
        "watermark_text": "We report the discovery and characterization of TrES - 3b, an extrasolar world with mass M = 1. 3 MJup orbiting its host star every 31 hours at zero. 081 AU ( 1. 7 stellar radii ).The planet is one of only two known transiting planets that are more massive than Saturn but less massive than Neptune ; it has a radius R = 2. 2 RJup and effective temperature T eff = 2400 K.We find no proof for extra bodies in this system using radial velocity measurements taken over 3 years.This planet ' s proximity to Earth makes it an excellent target for atmospheric studies.Keywords : Extrasolar planet - Discovery - Transit photometry - Radial velocities - Atmosphere - Planetary systems Introduction In recent years there have been several discoveries of giant exoplanets with orbital periods shorter than 4 days.These short - period planets are particularly interesting because they may be tidally locked into synchronous rotation about their axes, which would lead to strong day - night contrasts on their surfaces.Furthermore, these planets ' atmospheres will experience severe conditions due to high heat and intense radiation fields.As such, understanding how planetary atmospheres respond under these circumstances can provide crucial insights into processes occurring within our own Solar System as well as other planet systems.Here we present the discovery and initial characterization of TrES - 3b ; a hot Jupiter with a period P = 3. 09 d discovered by the transit method.Using follow - up observations made with the Spitzer Space Telescope, we show that TrES - threeb orbits near enough to its parent star so that tidal stresses should synchronize the planet ' s spin axis with its orbital angular momentum vector.However, we do not detect any significant infrared excess emission involved with the planet itself or its host star, indicating that either the planet does not contain a large excess of dust material surrounding it and / or that the planet is too cold to produce detectable thermal excess beyond 4 microns."
    },
    {
        "original_text": "We present forecasts for cosmological constraints on dark energy parameters using galaxy clusters, weak lensing tomography, and supernovae data in combination with Planck CMB temperature anisotropy measurements. We use an approximate treatment to account for all relevant covariances between these probes. The results are presented as two-dimensional marginalized likelihoods over pairs of dark energy parameters. Forecasted errors on w0 and wa range from 0.01-0.02 at 1-sigma confidence level (CL) when combining all three probes together. This is comparable or better than current state-of-the-art constraints obtained by other authors. In addition we show that our method can be used to obtain joint constraints on additional parameters such as neutrino masses. Finally, we demonstrate how this approach could be extended to include more complicated models beyond simple flat ΛCDM scenarios. We also discuss possible extensions of our analysis which would allow us to improve upon existing constraints further.",
        "watermark_text": "We present forecasts for cosmological constraints on dark energy parameters using galaxy clusters, weak lensing tomography, and supernovae data in combination with Planck CMB temperature anisotropy measurements.We use an estimated treatment to account for all relevant covariances between these probes.The results are presented as two - dimensions marginalized likelihoods over pairs of dark energy parameters.Forecasted errors on w0 and wa range from zero. 01 - 0. 02 at 1 - sigma confidence level ( CL ) when combining all three probes together.This is comparable or better than current state - of - the - art constraints obtained by other authors.In addition we show that our method can be used to obtain joint constraints on additional parameters such as neutrino masses.Finally, we demonstrate how this approach could be extended to involve more complicated models outside simple flat ΛCDM scenarios.We also discuss potential extensions of our analysis which would allow us to improve upon existing constraints further."
    },
    {
        "original_text": "We have studied the minimal size of a barchan by means of numerical simulations and found that it is determined by the balance between the sand flux at its crest, which decreases with decreasing height, and the wind shear stress over the slip face, which increases with decreasing height.  We show that this leads to an optimal height for the barchan dunes in agreement with observations. The results are presented below. \nThe authors thank Jens Egeberg Hansen (University of Southern Denmark) for useful discussions. Sand transport occurs when grains are lifted up into the air due to aerodynamic forces exerted by the wind. This process can be described as saltation [1] , where individual particles jump across the surface before being deposited again. Saltating particles transfer momentum to the surrounding fluid through collisions [2] . In turn, these collisions generate turbulence [3] .\nSaltation also causes erosion [4] and deposition [5] . Erosion takes place if the net force acting on a grain is directed away from the ground [6] . Deposition happens if the net force acts towards the ground [7, 8] . These processes lead to the formation of bedforms such as ripples [9] or dunes [10] . Dunes are formed under conditions where the sediment supply exceeds the rate of removal [11] . They occur naturally [12] but they may also form artificially [13] . Barchan dunes are crescent-shaped structures [14] . Their shape has been explained theoretically [15] and observed experimentally [16] . It was shown [17] that their width W scales linearly with length L according to: W = 0.6L + const., while their height H scales as: H ∝ L 1/3 . Here we study how the height of a barchan depends on other parameters using numerical simulations [18] .",
        "watermark_text": "We have studied the minimum size of a barchan by way of numerical simulations and found that it is determined by the balance between the sand flux at its crest, which decreases with decreasing height, and the wind shear stress over the slip face, which increases with decreasing height.We show that this leads to an ideal height for the barchan dunes in agreement with observations.The results are presented below.The authors thank Jens Egeberg Hansen ( University of Southern Denmark ) for helpful discussions.Sand transport occurs when grains are lifted up into the air due to aerodynamic forces exerted by the wind.This process can be described as saltation [ 1 ], where individual particles jump across the surface before being deposited again.Saltating particles transfer momentum to the surrounding fluid through collisions [ 2 ].In turn, these collisions generate turbulence [ 3 ].Saltation also causes erosion [ 4 ] and deposition[ 5 ].Erosion takes place if the net force acting on a grain is directed away from the ground [ 6 ].Deposition happens if the net force acts towards the ground [ 7, 8 ].These processes lead to the formation of bedforms such as ripples [ 9 ] or dunes [ 10 ].Dunes are formed under conditions where the sediment supply exceeds the rate of extraction [ 11 ].They occur naturally [ 12 ] but they might also form artificially [ 13 ].Barchan dunes are crescent - formed structures [ 14 ].Their shape has been explained theoretically[ 15 ] and observed experimentally[ 16 ].It was shown [ 17 ] that their width W scales linearly with length L according to : W = 0. 6L + const., while their height H scales as : H [UNK] L 1 / 3.Here we study how the height of a barchan depends on other criteria using numerical simulations [ 18 ]."
    },
    {
        "original_text": "We consider the gravitational effect on the Casimir force between two parallel plates in an accelerating frame, and show that it is possible to obtain a repulsive force at short distances even if the initial state has no net charge or current density. We also discuss how this result can be obtained by using the concept of local energy-momentum tensor for electromagnetic fields. The possibility of obtaining such a repulsive force was first suggested by Yukawa in 1951 as a way to explain nuclear forces without introducing new particles. \n \n In recent years there have been several attempts to measure experimentally the Casimir force (see e.g., Refs. [1]-[6]). However, all these experiments are performed with macroscopic objects which do not allow one to test directly the predictions of QED concerning the behavior of the vacuum fluctuations near boundaries [7, 8] . \n \n On the other hand, the measurement of the Casimir force between microscopic bodies would provide information about the properties of the vacuum [9] , and could lead to tests of QED [10] - [12] . \n \n It should be noted that the experimental determination of the Casimir force requires very accurate measurements because its magnitude is extremely small compared to gravity [13] . For example, the most precise experiment so far [6] gives only a relative accuracy of 0.1%. This means that any systematic error will dominate over statistical errors. Therefore, it is important to understand theoretically the dependence of the Casimir force upon external parameters like temperature [14] , pressure [15] , and velocity [16] .",
        "watermark_text": "We consider the gravity effect on the Casimir force between 2 parallel plates in an accelerating frame, and show that it is possible to obtain a repulsive force at short distances even if the initial state has no net charge or current density.We also discuss how this result can be obtained by using the concept of local energy - momentum tensor for electromagnetic fields.The possibility of obtaining such a repulsive force was first suggested by Yukawa in 1951 as a way to explain nuclear forces without introducing new particles.In recent years there have been several attempts to measure experimentally the Casimir force ( see e. g., Refs.[ 1 ] - [ 6 ] ).However, all these experiments are performed with macroscopic objects which do not allow one to test directly the predictions of QED concerning the behavior of the vacuum fluctuations near boundaries[ 7, 8 ].On the other hand, the measurement of the Casimir force between microscopic bodies would provide information about the properties of the vacuum [ 9 ], and could lead to tests of QED[ 10 ] - [ 12 ].It should be noted that the experimental determination of the Casimir force requires very accurate readings because its magnitude is extremely small compared to gravity[ 13 ].For example, the most precise experiment so far [ 6 ] gives only a relative accuracy of 0. 1 %.This means that any systematic error will dominate over statistical errors.Therefore, it is important to understand theoretically the dependence of the Casimir force onto external parameters like temperature[ 14 ], pressure [ 15 ], and velocity[ 16 ]."
    },
    {
        "original_text": "We present an exact hierarchical description of the reduced state and dynamics of open quantum systems in terms of a set of coupled equations, which we call the Hierarchy of Density Tensors (HDT). The HDT is derived by applying the Nakajima-Zwanzig projection operator technique to the von Neumann equation describing the evolution of the total system. We show that this approach allows one to retrieve all relevant information about the environment-induced decoherence process on arbitrary timescales. In particular, it provides access to the full spectrum of relaxation rates characterizing the decay of off-diagonal elements of the reduced density matrix as well as the stationary states reached at late times. As an example, we apply our formalism to study the dissipative spin-boson model with Ohmic dissipation. Our results are compared against numerical simulations based on the Quantum Monte Carlo Wavefunction method. \nI. INTRODUCTORY REMARK\nThe understanding of how macroscopic objects behave under the influence of their environments has been a central issue in physics since its very beginning [1, 2] . This problem becomes particularly challenging when dealing with complex many-body systems such as condensed matter or biological ones [3, 4] , where the number of degrees of freedom involved can be extremely large. A powerful theoretical tool to tackle these problems consists in studying the dynamics of the reduced state of the system of interest S conditioned upon some specific measurement performed over the environmental degrees of freedom E [5, 6] .\nIn recent years there have been several attempts to develop efficient methods to describe the time-evolution of the reduced state [7, 8] . Among them, the so-called Hierarchy of Density Matrices (HDM) [9] represents a promising alternative to other approaches [10, 11] due to its ability to capture non-Markovian effects [12] . However, despite being able to provide accurate predictions for short-time evolutions [13] , the HDM fails to reproduce correctly the asymptotic behavior of the system [14] . To overcome this limitation, here we introduce a new formulation of the HDM, called Hierarchy of Density...",
        "watermark_text": "We present an exact hierarchical description of the reduced state and dynamics of open quantum systems in terms of a set of coupled equations, which we call the Hierarchy of Density Tensors ( HDT ).The HDT is derived by applying the Nakajima - Zwanzig projection operator technique to the von Neumann equation describing the evolution of the total system.We show that this approach permits one to retrieve all relevant information about the environment - induced decoherence process on arbitrary timescales.In particular, it provides access to the full spectrum of relaxation rates characterizing the decay of off - diagonal elements of the reduced density matrix as also as the stationary states reached at late periods.As an example, we apply our formalism to study the dissipative spin - boson model with Ohmic dissipation.Our results are compared against numerical simulations based on the Quantum Monte Carlo Wavefunction method.I. INTRODUCTORY REMARK The understanding of how macroscopic objects behave under the influence of their environments has been a central issue in physics since its very beginning[ 1, 2 ].This problem gets particularly challenging when dealing with complex many - body systems such as condensed matter or bio ones[ 3, 4 ], where the number of degrees of freedom involved can be incredibly large.A powerful theoretical tool to tackle these problems consists in studying the dynamics of the reduction state of the system of interest S conditioned onto some specific measurement performed over the environment degrees of free E[ 5, 6 ].In recent years there have been several attempts to develop efficient methods to describe the time - evolution of the reduced state[ 7, 8 ].Among them, the so - called Hierarchy of Density Matrices ( HDM )[ 9 ] represents a promising alternative to other approaches[ 10, 11 ] due to its ability to capture non - Markovian effects [ 12 ].However, despite being able to provide accurate predictions for short - time evolutions [ 13 ], the HDM fails to reproduce correctly the asymptotic behaviour of the system [ 14 ].To overcome this limitation, here we introduce a new formulation of the HDM, called Hierarchy of Density."
    },
    {
        "original_text": "The Min system is responsible for the correct positioning of the Z ring and division site at mid-cell during bacterial cell division.  The Min system consists of three components, MinC, MinD, and MinE that oscillate back-and-forth across the cytoplasm to create an inhibitory gradient along the length of the cell.  This gradient prevents assembly of new FtsZ rings outside of mid-cell until all existing FtsZ rings have disassembled.   In this study we use computational modeling techniques to investigate how the Min system partitions its components into two daughter cells following cytokinesis.  We find that the Min system can be divided into four distinct phases based on the distribution of Min protein complexes within each cell.  During phase I (0-60 s), MinD-E2-MinC complexes are distributed throughout both mother and daughter cells with higher concentrations near the poles than at mid-cell.  Phase II (60-120 s) begins when MinD-E2-MinCs accumulate at mid-cell forming a band-like structure.  During phase III (120-240 s), MinD-E2-",
        "watermark_text": "The Min system is responsible for the correct positioning of the Z ring and division site at middle - cell during bacterial cell division.The Min system consists of three components, MinC, MinD, and MinE that oscillate back - and - forth across the cytoplasm to create an inhibitory gradient along the length of the cell.This gradient prevents assembly of new FtsZ rings outside of mid - cell until all existing FtsZ rings have disassembled.In this study we utilize computational modeling technologies to investigate how the Min system partitions its components into two daughter cells following cytokinesis.We find that the Min system can be divided into four distinct phases based on the distribution of Min protein structures within each cell.During phase I ( 0 - 60 s ), MinD - E2 - MinC complexes are distributed across both mother and daughter cells with higher concentrations near the poles than at mid - cell.Phase II ( 60 - 120 s ) begins when MinD - E2 - MinCs accumulate at mid - cell forming a band - like structure.During phase III ( 120 - 240 s ), MinD - E2 -"
    },
    {
        "original_text": "We study the effect of Coulomb gauge fixing on the gluon propagator in Landau gauge, using lattice simulations with two different actions for SU(2) Yang-Mills theory. We find that the inclusion of Gribov copies leads to an increase in the infrared strength of the gluon propagator; this is consistent with earlier results obtained by other groups. \n \n In addition we show how the presence of Gribov copies affects the static quark-antiquark potential at large distances. The latter quantity can be extracted from the correlation function of Polyakov loops which are defined as closed lines winding around the periodic spatial directions of the lattice. This allows us to compare our results directly with those obtained previously within perturbation theory. Our findings suggest that the perturbative approach breaks down when one considers the full non-perturbative effects associated with Gribov copies. Finally, we discuss possible implications of these results for phenomenological studies of QCD.",
        "watermark_text": "We study the effect of Coulomb gauge fixing on the gluon propagator in Landau gauge, using lattice simulations with two different actions for SU ( 2 ) Yang - Mills theory.We find that the inclusion of Gribov copies leads to an rise in the infrared strength of the gluon propagator ; this is consistent with earlier results obtained by other groups.In addition we show how the presence of Gribov copies affects the static quark - antiquark potential at big distances.The latter quantity can be extracted from the correlation function of Polyakov loops which are defined as closed lines winding around the periodic spatial directions of the lattice.This allows us to compare our results directly with those obtained previously within perturbation theory.Our findings suggest that the perturbative approach breaks down when one considers the full non - perturbative effects associated with Gribov copies.Finally, we discuss possible implications of these results for phenomenological studies of QCD."
    },
    {
        "original_text": "We study the dynamical stability properties of rapidly-rotating, axisymmetric neutron star models with different equations of state (EOS). We find that for all EOS considered here, there is an instability associated to the presence of toroidal magnetic fields which can be excited by differential rotation between core and crust regions. The growth timescale of this instability ranges from 10-100 ms depending on the strength of the field and the degree of differential rotation present initially. \n \n This instability may have important consequences for magnetar flares as well as for the spin evolution of young pulsars. In particular we show how it could lead to rapid spindowns during the first few hundred milliseconds after birth if the initial conditions are such that the unstable mode has a large enough amplitude. Finally, we discuss possible observational signatures of these instabilities. Dynamical non-axisymmetric modes in rapidly-rotating relativistic stars",
        "watermark_text": "We study the dynamical stability properties of rapidly - rotating, axisymmetric neutron star models with different equations of state ( EOS ).We find that for all EOS considered here, there is an instability associated to the existence of toroidal magnetic fields which can be excited by differential rotation between core and crust areas.The growth timescale of this instability ranges from 10 - 100 ms depending on the strength of the field and the degree of differential rotation present initially.This instability may have important consequences for magnetar flares as much as for the spin evolution of young pulsars.In particular we show how it could lead to rapid spindowns during the first few hundred milliseconds after birth if the first conditions are such that the instability mode has a large enough amplitude.Finally, we discuss potential observational signatures of these instabilities.Dynamical non - axisymmetric modes in rapidly - rotating relativistic stars"
    },
    {
        "original_text": "We present deep near-infrared imaging and spectroscopy for two fields in the Hubble Deep Field South (HDF-S) covering an area of 0.5 square degrees each, centered on RA = 03:32:47.6 Dec = -27:48:30 (J2000). The data were obtained with ISAAC at VLT as part of our ESO Large Programme \"First Stars First Galaxies\". We have detected more than 1000 galaxies down to KsAB = 24 mag over this field using SExtractor. In addition we have spectroscopically confirmed about 100 objects selected by their photometric redshifts between z=0.7-1.3. This is one of the largest samples of high-z galaxies ever assembled. Our sample includes both Lyman-break galaxies and sub-millimeter sources which are likely to be dusty starbursting systems. These results will allow us to study galaxy formation and evolution up to redshift 1.",
        "watermark_text": "We present deep near - infrared imaging and spectroscopy for two fields in the Hubble Deep Field South ( HDF - S ) covering an area of zero. 5 square degrees each, centered on RA = 03 : 32 : 47. 6 Dec = - 27 : 48 : 30 ( J2000 ).The data were obtained with ISAAC at VLT as part of our ESO Large Programme \" First Stars First Galaxies \".We have identified more than 1000 galaxies down to KsAB = 24 mag over this field using SExtractor.In addition we have spectroscopically confirmed about 100 objects selected by their photometric redshifts between z = 0. 7 - 1. 3.This is one of the largest samples of high - z galaxies ever assembled.Our sample includes both Lyman - break galaxies and sub - millimeter sources which are probable to be dusty starbursting systems.These results will allow us to study galaxy formation and evolution up to redshift one."
    },
    {
        "original_text": "We introduce the notion of intersection bodies in arbitrary dimensions, generalizing the classical concept for dimension two to higher dimensions. We show that intersection bodies are characterized by their Fourier transforms which we call generalized cosine transforms (GCT). The GCTs can be used as an alternative tool to study intersection bodies. In particular, we prove that intersection bodies have positive volume if and only if they are convex. This is done using a new characterization of intersection bodies via their support functions. Finally, we give some examples of intersection bodies in three dimensions. Keywords: Intersection body; Support function; Convexity; Volume; Fourier transform; Three-dimensional space. 1 Introduction Let K n denote the set of all origin-symmetric convex bodies in R n . For any K ∈ K n , let V(K) = |K|/|B n 2 | where | · | denotes Lebesgue measure on R n . Then V : K n → [0, 1] is called the volume functional. A compactly supported continuous function f : S n−1 → C with unit integral will be called a spherical harmonic of degree m. If f has no zeros then it is uniquely determined up to multiplication by a constant. It follows immediately that every spherical harmonic of degree m satisfies the following properties:\n(1) |f (x)| ≤ 1; (2) f (−x) = f (x), x ∈ S n−1 ; (3) (Spherical harmonics form an orthonormal basis.) Definition 1. An origin-symmetric convex body K ∈ K n is said to be an intersection body if there exists a non-negative real number λ such that its surface area measure σ K satisfies",
        "watermark_text": "We introduce the notion of intersection bodies in arbitrary dimensions, generalizing the classical concept for dimension two to upper dimensions.We show that intersection bodies are characterized by their Fourier transforms which we call generalized cosine transforms ( GCT ).The GCTs can be used as an alternative tool to study intersection bodies.In particular, we prove that intersection bodies have positive volume if and only if they are convex.This is done using a novel characterization of intersection bodies via their support functions.Finally, we give some examples of intersection bodies in 3 dimensions.Keywords : Intersection body ; Support function ; Convexity ; Volume ; Fourier transform ; Three - dimensional space.1Introduction Let K n denote the set of all origin - symmetric convex bodies in R n.For any K ∈ K n, let V ( K )= | K | / | B n 2 | where | · | denotes Lebesgue measure on R n.Then V : K n → [ 0, 1 ] is called the volume functional.A compactly supported continuous function f : S n−1 → C with unit integral will be called a spherical harmonic of degree m.If f has no zeros then it is uniquely determined up to multiplication by a constant.It follows immediately that every spherical harmonic of degree m satisfies the following properties : ( 1 ) | f ( x ) | ≤ 1 ; ( 2 ) f ( −x ) = f ( x ), x ∈ S n−1 ; ( 3 ) ( Spherical harmonics form an orthonormal basis. )Definition 1.An origin - symmetric convex body K ∈ K n is said to be an intersection body if there exists a non - negative real number λ such that its surface area measure σ K satisfies"
    },
    {
        "original_text": "The nonlinear dynamics of phonon stimulated emission (PSE) is investigated for microwave solid-state resonators with nonautonomous phase-locked loop generators. The PSE process is described by means of an extended version of the Lang-Kobayashi model, which takes into account the influence of the external driving field on the gain medium and includes additional terms describing the effect of spontaneous emission noise. It has been shown that the presence of these new effects leads to significant changes in the behavior of the system under consideration as compared to autonomous systems. In particular, it was found that the generation of chaotic regimes becomes possible even at relatively small values of the pumping parameter. This fact can be used to develop novel types of chaos-based devices based on microwave solid-state oscillators. \n \n Keywords: Nonlinear dynamics; Chaos; Phase synchronization; Phonons; Microwave solid state oscillator. PACS: 42.65.Tt; 42.65.Pq; 42.65.Re",
        "watermark_text": "The nonlinear dynamics of phonon stimulated emission ( PSE ) is investigated for microwave solid - state resonators with nonautonomous phase - locked loop generators.The PSE process is described by means of an extension version of the Lang - Kobayashi model, which takes into account the influence of the external driver field on the gain medium and includes additional terms describing the effect of spontaneous emitted noise.It has been shown that the presence of these new effects leads to significant changes in the behavior of the system under consideration as compared to autonomous systems.In particular, it was found that the generation of chaos regimes becomes feasible even at relatively small values of the pumping parameter.This fact can be used to develop new types of chaos - based devices based on microwave solid - state oscillators.Keywords : Nonlinear dynamics ; Chaos ; Phase synchronization ; Phonons ; Microwave solid state oscillator.PACS :42. 65. Tt ; 42. 65. Pq ; 42. 65. Re"
    },
    {
        "original_text": "We consider the problem of time evolution for quantum fields on the Milne universe, which is an open FRW cosmology with negative spatial curvature and vanishing cosmological constant. We show that there are no normalizable solutions to the Klein-Gordon equation corresponding to massive particles at early times (t → −∞). This result can be understood as follows. The Milne universe has a singularity at t = 0 where all physical quantities diverge. In particular, the energy density diverges like $1/t^2$ near this point. As a consequence, any particle state localized around $t=0$ will have infinite energy. Therefore it cannot correspond to a physically meaningful solution of the field equations. On the other hand, we find that there exist normalizable states describing massless particles at early times. These states represent gravitons or photons propagating into the past along geodesics towards the big bang singularity.",
        "watermark_text": "We consider the problem of time evolution for quantum fields on the Milne universe, which is an open FRW cosmology with negative spatial curvature and vanishing cosmological constant.We show that there are no normalizable solutions to the Klein - Gordon equation corresponding to massive particles at early times ( t → −∞ ).This result can be understood as follows.The Milne universe has a singularity at t = 0 where all physical quantities diverge.In particular, the energy density diverges like $ 1 / t ^ 2 $ near this point.As a consequence, any particle state localized around $ t = 0 $ will have infinite energy.Therefore it cannot correspond to a physically meaningful solution of the field equations.On the other hand, we find that there exist normalizable states describing massless particles at early periods.These states represent gravitons or photons propagating into the past along geodesics towards the big bang singularity."
    },
    {
        "original_text": "We present the results of an analysis of galaxy-galaxy lensing data for three different types of galaxies in dark matter halos, using the Millennium Simulation and semi-analytic models to predict their properties.  We find that early-type galaxies are aligned with each other along filaments, while late-types show no alignment signal at all.  The intermediate type shows some evidence for alignments perpendicularly to the filamentary structure.  These findings can be explained by tidal torques acting on the gas during its infall into the halo potential well, which is more efficient for early-type than for latetype galaxies.  This effect may also explain why we do not see any significant alignment between the shapes of dark matter haloes themselves. Our results suggest that the observed alignments of galaxies could be caused by large-scale gravitational fields rather than being primordial effects. In this work we study how the shape of dark matter halos affects the distribution of satellite galaxies around them. Using N-body simulations, we investigate whether there exists a correlation between the orientation of the major axis of the host halo and the position angle of satellites relative to it. We find that such correlations exist only if the mass ratio between the primary and secondary halo is large enough (M1/M2 > 10). For smaller mass ratios, the orientations of both halos become uncorrelated due to dynamical friction.",
        "watermark_text": "We present the results of an analysis of galaxy - galaxy lensing data for 3 different types of galaxies in dark matter halos, using the Millennium Simulation and semi - analytic models to predict their properties.We find that early - type galaxies are aligned with each other along filaments, while late - types show no alignment signal at all.The intermediate type shows some evidence for alignments perpendicularly to the filamentary design.These findings can be explained by tidal torques acting on the gas during its infall into the halo potential well, which is more efficient for early - type than for latetype galaxies.This effect may also explain why we do not see any significant alignment between the shapes of dark matter haloes themselves.Our results suggest that the observed alignments of galaxies could be caused by large - scale gravitational fields rather than being primordial effects.In this work we study how the shape of dark matter halos effect the distribution of satellite galaxies around them.Using N - body simulations, we investigate either there exists a correlation between the orientation of the major axis of the host halo and the place angle of satellites relative to it.We find that such correlations exist only if the mass ratio between the primary and secondary halo is big enough ( M1 / M2 > 10 ).For smaller mass ratios, the orientations of both halos become uncorrelated due to dynamical friction."
    },
    {
        "original_text": "We present the latest advances in optical frequency combs and their applications to precision metrology, including calibration techniques for high-resolution spectroscopy instruments such as Fourier transform spectrometers (FTS). We discuss how these techniques can be used to improve measurement accuracy by orders of magnitude over traditional methods.  In particular we describe two novel approaches that are being developed at NIST:  1) The use of an optical frequency comb locked to a high-accuracy atomic clock to calibrate FTS measurements with sub-Hz uncertainty. 2) A technique called \"self-calibration\" which allows one to measure absolute frequencies without requiring any external reference standards or other auxiliary equipment. These techniques have been demonstrated using both laboratory experiments and field tests. They represent important steps towards realizing the vision of a future where all spectroscopic measurements will be traceable back to fundamental physical constants. This is especially relevant today given the growing interest in developing portable, low-cost devices capable of performing accurate chemical analysis anywhere around the world.",
        "watermark_text": "We present the latest advances in optical frequency combs and their applications to precision metrology, including calibration techniques for high - resolution spectroscopy instruments such as Fourier transform spectrometers ( FTS ).We discuss how these techniques can be used to improve measurement accuracy by orders of magnitude over traditional methods.In particular we describe two novel approaches that are being developed at NIST : 1 )The use of an optical frequency comb locked to a high - accurate atomic clock to calibrate FTS measurements with sub - Hz uncertainty.2 )A technique called \" self - calibration \" which allows one to measure absolute frequencies without requiring any external reference standards or other auxiliary equipment.These techniques have been demonstrated using both lab experiments and field trials.They represent important steps towards realizing the vision of a future where all spectroscopic measurements will be traceable back to fundamental physical constants.This is especially relevant today given the growing interest in developing portable, low - cost devices capable of executing accurate chemical analyze anywhere around the world."
    },
    {
        "original_text": "We present the results of our analysis of a sample of 25 high-resolution quasar absorption line systems with metallicities ranging between 1/100 and 1/10 solar, selected to have low dust content (i.e., < 0.1 mag extinction at 2200 A). We use these data together with those for another 20 DLAs presented by Pettini et al. (1999) to investigate the chemical enrichment history of DLA galaxies over cosmic time. The main conclusions are as follows: \nThe abundance patterns observed in this sample can be explained if we assume that most of the metals were produced during an early burst of star formation which occurred less than 10 Gyr ago. \n\n\nThis is consistent with previous studies based on smaller samples but it also shows that there may not always be evidence for recent star formation activity even when such activity has been inferred from other indicators. \n\nIn addition, we find no correlation between metallicity and dust content or neutral hydrogen column density.\n\nFinally, we show that the mean value of [Fe/H] measured in DLAs agrees well with the predictions made using simple models of galactic chemical evolution.",
        "watermark_text": "We present the results of our analysis of a sample of 25 high - resolution quasar absorption line systems with metallicities ranging between 1 / 100 and one / ten solar, selected to have little dust content ( i. e., < 0. 1 mag extinction at 2200 A ).We use these data together with those for another 20 DLAs presented by Pettini e al. ( 1999 ) to investigate the chemistry enrichment history of DLA galaxies over cosmic time.The main conclusions are as follows : The abundance patterns observed in this sample can be explained if we assume that most of the metals were produced during an early burst of star formation which occurred less than 10 Gyr ago.This is consistent with previous studies based on smaller samples but it also shows that there may not always be evidence for recent star formation activity even when such activity has been inferred from other indicators.In addition, we find no correlation between metallicity and dust concentration or neutral hydrogen column density.Finally, we show that the mean value of [ Fe / H ] measured in DLAs agrees well with the predictions made utilizing simple models of galactic chemistry evolution."
    },
    {
        "original_text": "We study temperature driven phase transitions between different charge ordered states in one-dimensional quarter-filled Hubbard model with nearest-neighbor hopping and on-site Coulomb repulsion using density matrix renormalization group (DMRG) method. We find that at low temperatures, the system is in the Wigner crystal state where electrons are localized by strong electron correlations. With increasing temperature, we observe a first-order phase transition into bond-charge-density wave state which has been predicted theoretically earlier but not observed experimentally so far. The nature of this phase transition can be understood as melting of the Wigner crystal due to thermal fluctuations. Finally, we also investigate the effect of next-nearest neighbor hopping t′ on these phases. Our results show that for small values of t′ , the ground state remains in the Wigner crystal phase while for large values of t′ it becomes metallic. This shows that the presence of next-nearest neighbor hoping may destroy the charge ordering in 1D systems.",
        "watermark_text": "We study heat driven phase transitions between different charge ordered states in one - dimensional quarter - filled Hubbard model with nearest - neighbor hopping and on - site Coulomb repulsion using density matrix renormalization group ( DMRG ) method.We find that at low temperatures, the system is in the Wigner crystal state where electrons are localized by strong electron correlations.With increasing temperature, we observe a first - order phase transition into bond - charge - dense wave state which has been predicted theoretically earlier but not observed experimentally so far.The nature of this phase transition can be understood as melting of the Wigner crystal owing to thermal fluctuations.Finally, we also investigate the effect of next - nearest neighbor hopping t ′ on these phases.Our results show that for small values of t ′, the ground state remains in the Wigner crystal stage while for large values of t • it becomes metallic.This shows that the presence of next - closest neighbor hoping may destroy the charge ordering in 1D systems."
    },
    {
        "original_text": "We present new observations of the central region of the nearby Seyfert galaxy NGC 4258, which show that its nuclear disk is warped by an angle of ~20 degrees with respect to the plane of the host galaxy's stellar bulge (see Figure 1 ). The warp has been detected using near-infrared integral field spectroscopy obtained at Gemini Observatory on Mauna Kea, Hawaii. \n \n We also report the detection of significant rotation about the minor axis of this warped structure, as well as evidence for counter-rotation within the innermost few hundred parsecs of the nucleus. These results are consistent with previous studies based on optical data alone. \n \n In addition, we find that the kinematics of the gas in the outer regions of the nuclear disk can be explained if it orbits around the supermassive black hole located at the center of the galaxy under the influence of both gravitational forces and magnetic fields. This result suggests that the observed warps may have their origin in the magneto-rotational instability (MRI) operating in accretion disks surrounding massive black holes. \n \n Finally, we discuss how these findings could help us understand the physics behind the so-called \"Bardeen-Petterson effect\": i.e., the alignment between the spin axes of the stars and the angular momentum vector of the accreting material onto the central supermassive black hole.",
        "watermark_text": "We present fresh observations of the central region of the nearby Seyfert galaxy NGC 4258, which show that its nuclear disk is warped by an angle of ~ 20 degrees with respect to the plane of the host galaxy ' s stellar bulge ( see Figure 1 ).The warp has been detected using near - infrared integral field spectroscopy achieved at Gemini Observatory on Mauna Kea, Hawaiian.We also report the detection of significant rotation about the minor axis of this warped structure, as well as indication for counter - rotation within the innermost few hundred parsecs of the nucleus.These results are consistent with previous studies based on optical data alone.In addition, we find that the kinematics of the gas in the outer regions of the nuclear disk can be explained if it orbits around the supermassive black hole located at the center of the galaxy under the influence of both gravitational forces and magnetic fields.This result suggests that the observed warps may have their origin in the magneto - rotational instability ( MRI ) operating in accretion disks surrounding massive pale holes.Finally, we discuss how these findings could help us understand the physics behind the so - called \" Bardeen - Petterson effect \" : i. e., the alignment between the spin axes of the stars and the angular momentum vector of the accreting material upon the central supermassive black hole."
    },
    {
        "original_text": "We present the results of our study on the correlation between black hole mass and spheroidal luminosity in nearby galaxies, using data obtained with the Hubble Space Telescope (HST). We have used two different methods to estimate the masses of supermassive black holes at the centers of these galaxies; one based on stellar dynamics and another method which uses the widths of broad emission lines as an indicator for the central black hole mass. The sample consists of 29 elliptical galaxies within 40 Mpc distance. Our main result is that we find no significant difference between the black hole masses derived by both methods. This indicates that there exists a tight relationship between the black hole mass and the total luminosity of its host galaxy. In addition, we also found evidence that this relationship does not depend strongly on the morphological type or environment of the host galaxy. These findings are consistent with theoretical predictions made by Silk & Rees (1998) who suggested that feedback processes play an important role in regulating star formation activity in galactic bulges.",
        "watermark_text": "We present the results of our study on the correlation between black hole mass and spheroidal luminosity in nearby galaxies, using data obtained with the Hubble Space Telescope ( HST ).We have used two different methods to estimate the masses of supermassive black holes at the centers of these galaxies ; one based on stellar dynamics and another method which uses the widths of broad emission lines as an indicator for the central glass hole mass.The sample consists of 29 elliptical galaxies within 40 Mpc distant.Our main result is that we find no significant difference between the black hole masses derived by both methods.This indicates that there remains a tight relationship between the dark hole mass and the total luminosity of its host galaxy.In addition, we also discovered evidence that this relation does not depend strongly on the morphological type or environment of the host galaxy.These findings are consistent with theoretical predictions made by Silk & Rees ( 1998 ) who suggested that feedback processes play an key role in regulating star forming activity in galactic bulges."
    },
    {
        "original_text": "We present an overview of recent progress in the development and application of techniques to cool molecules by exploiting their interaction with optical cavities. We discuss how these methods can be used to prepare samples of cold, trapped molecules that are suitable for precision measurements or quantum information processing applications. In particular we focus on two different approaches which have been developed recently at our laboratory: (i) The use of electromagnetically induced transparency (EIT), combined with stimulated Raman adiabatic passage (STIRAP), to produce large numbers of optically trapped ground-state polar molecules. (ii) Cavity-enhanced photoassociation spectroscopy as a tool to study ultracold collisions between alkali-metal atoms. Finally, we briefly outline some possible future directions for this research area. Molecules offer many advantages over atomic systems when it comes to implementing novel quantum technologies such as high-precision metrology [1] , quantum simulation [2] , and quantum networks [3] . However, most molecular species cannot be directly cooled using conventional laser cooling schemes because they lack closed cycling transitions [4] .\nIn order to overcome this problem several alternative cooling strategies have been proposed [5] - [8] . One promising approach is based on the combination of electromagnetically-induced transparency (EIT) [9] and stimulated Raman adiabatic passages (STIRAP) [10] . This method has been successfully applied to create dense ensembles of ground state polar molecules [11] - [13] . Another possibility consists in trapping molecules via photoassociative processes [14] - [16] . Here one exploits the fact that the spontaneous emission rate into bound states increases exponentially with decreasing temperature [17] . By coupling the excited molecular levels to high-finesse optical cavities [18] - [20] , the resulting increase in radiative lifetime leads to efficient trapping [21] - [23] . These techniques allow us to trap up to 10 5 molecules per cm 3 inside a single-mode optical resonator [24] .",
        "watermark_text": "We present an overview of latest progress in the development and application of techniques to cool molecules by exploiting their interaction with optical cavities.We discuss how these ways can be used to prepare samples of cold, trapped molecules that are appropriate for precision readings or quantum information processing applications.In particular we focus on two different approaches which have been devised recently at our laboratory : ( i )The use of electromagnetically induced transparency ( EIT ), combined with stimulated Raman adiabatic passage ( STIRAP ), to produce large numbers of optically trapped ground - state polar molecules.( ii ) Cavity - enhanced photoassociation spectroscopy as a tool to study ultracold collisions between alkali - metal atoms.Finally, we briefly outline some possible future directions for this research area.Molecules offer many advantages over atomic systems when it comes to applying novel quantum technologies such as high - precision metrology [ 1 ], quantum simulation[ 2 ], and quantum networks [ 3 ].However, most molecular species cannot be directly cooled utilizing conventional laser cooling schemes because they cannot closed cycling transitions [ 4 ].In order to overcome this problem several alternative cooling tactics have been proposed [ 5 ] - [ 8 ].One promising approach is based on the combination of electromagnetically - induced transparency ( EIT )[ 9 ] and stimulated Raman adiabatic passages ( STIRAP )[ 10 ].This method has been well applied to create dense ensembles of ground state polar molecules[ 11 ] - [ 13 ].Another possibility consists in trapping molecules via photoassociative processes[ 14 ] -[ 16 ].Here one exploits the fact that the spontaneous emission rate into bound states increases exponentially with decreasing temperature [ 17 ].By coupling the excited molecular levels to high - finesse optical cavities [ 18 ] - [ 20 ], the resulting increase in radiative lifetime leads to efficient trapping [ 21 ] -[ 23 ].These techniques allow us to trap up to 10 5 molecules per cm three inside a single - mode optical resonator[ 24 ]."
    },
    {
        "original_text": "Social networks are ubiquitous in our daily life, and have been studied extensively by researchers across many disciplines. However, the analysis of social network data is often challenging due to its complexity. In this work we propose NodeTrix, an efficient hybrid representation that can be used to analyze large-scale social networks efficiently. We show how NodeTrix can be applied to solve several important problems including community detection, link prediction, node classification, and influence maximization. Our experiments on real-world datasets demonstrate that NodeTrix outperforms state-of-the-art approaches significantly both in terms of efficiency and effectiveness. 1 Introduction Social networks play an increasingly important role in people's lives. They provide us with new ways to communicate with each other, share information, collaborate, or even make friends. As such, they have attracted much attention from researchers across various fields ranging from sociology [1] , psychology [2] , biology [3] , computer science [4] , engineering [5] , etc.. The rapid development of online social media has led to unprecedented growth in the amount of available social network data [6] . For example, Facebook alone now contains more than one billion active users [7] .\nHowever, analyzing large volumes of social network data remains a challenge because it usually involves complex relationships among nodes [8] . To tackle these challenges, recent research efforts focus on developing effective representations for social networks [9] - [11] . These representations aim at capturing different aspects of social networks while being able to scale up well when dealing with massive amounts of data [12] . Among them, matrix factorization techniques [13] - [15] have shown great promise as they allow us to represent social networks using low-rank matrices [16] . Matrix factorization methods decompose a given adjacency matrix into two smaller matrices (i.e., latent factors) which capture structural properties of the original graph [17] .",
        "watermark_text": "Social networks are ubiquitous in our daily life, and have been studied extensively by researchers across many disciplines.However, the analysis of social network data is often challenging owing to its complexity.In this work we propose NodeTrix, an efficient hybrid representation that can be used to analyze large - scale socio networks effectively.We show how NodeTrix can be applied to solve several important problems including community detection, line prediction, node classification, and influence maximization.Our experiments on real - world datasets demonstrate that NodeTrix outperforms state - of - the - art approaches significantly both in terms of efficiency and effectiveness.1 Introduction Social networks play an increasing important role in people ' s lives.They provide us with new ways to communicate with each other, share information, cooperate, or even make friends.As such, they have attracted much attention from researchers across various fields ranging from sociology[ 1 ], psychology [ 2 ], biology[ 3 ], computer science[ 4 ], engineering [ 5 ], etc.The rapid development of online social media has led to unprecedented development in the amount of available social network data [ 6 ].For example, Facebook alone now contains more than 1 billion active users[ 7 ].However, analyzing large volumes of social network data remains a challenge because it usually involves complex relationships among nodes[ 8 ].To tackle these challenges, recent research efforts focus on developing efficient representations for social networks [ 9 ] - [ 11 ].These representations aim at capturing different features of social networks while being able to scale up well when dealing with massive amounts of data [ 12 ].Among them, matrix factorization techniques [ 13 ] - [ 15 ] have shown great promise as they allow us to represent social networks utilizing low - rank matrices[ 16 ].Matrix factorization methods decompose a given adjacency matrix into two smaller matrices ( i. e., latent factors ) which capture structural properties of the original graph[ 17 ]."
    },
    {
        "original_text": "We present the results of an optical to infrared multiwavelength survey of a sample of 12 massive (M* > 10 11 Msun) galaxies in the redshift range 1.9 < z < 2.7, selected using their rest-frame UV colors as Lyman-break analogs. We use deep near-infrared spectroscopy with Keck/NIRSPEC to measure stellar masses for these objects, which are found to be between 3 x 10 11 and 5 x 10 11 Msun. The majority of our targets show evidence for strong starburst activity based on their high equivalent width [OIII] emission lines and large Balmer decrements indicative of dusty star-forming regions. Using Spitzer/IRAC photometry we find that most of these systems have red mid-infrared colors consistent with those expected for evolved stellar populations. However, two of our sources appear bluer than this trend suggesting they may contain significant amounts of obscured AGN activity.",
        "watermark_text": "We present the results of an optical to infrared multiwavelength survey of a sample of 12 massive ( M * > 10 11 Msun ) galaxies in the redshift range 1. 9 < z < 2. 7, selected using their rest - frame UV colors as Lyman - break analogs.We use deep near - infrared spectroscopy with Keck / NIRSPEC to measure stellar masses for these objects, which are found to be between 3 × 10 11 and five x ten 11 Msun.The majority of our targets show evidence for strong starburst activity based on their high equivalent width[ OIII ] emission lines and large Balmer decrements indicative of dusty star - forming regions.Using Spitzer / IRAC photometry we find that most of these systems have reddish mid - infrared colors consistent with those expected for evolved stellar populations.However, two of our sources appear bluer than this tendency suggesting they may contain significant amounts of obscured AGN activity."
    },
    {
        "original_text": "We have studied the low temperature (T < 1 K) electron spin relaxation rate, T1e-1/T1e = 1/(1 + T2e), for gold-palladium alloys with different compositions by using pulsed muon-spin rotation and relaxation measurements. The results show that the observed relaxation rates are consistent with those expected from Elliott-Yafet scattering mechanism at high temperatures but deviate significantly below 0.5 K. We find that this deviation can be explained if we assume an additional contribution to the relaxation rate due to spin-orbit interaction between conduction electrons and localized magnetic moments associated with Pd atoms. This is supported by our theoretical calculations based on density functional theory which predict a large enhancement of the spin-orbit coupling strength as one moves away from the center of the Brillouin zone towards the Fermi surface. Our findings suggest that the presence of localised magnetic moment may play an important role in determining the transport properties of these materials even though they do not order magnetically down to lowest measured temperatures.",
        "watermark_text": "We have studied the low temperature ( T < 1 K ) electron spin relaxation rate, T1e - 1 / T1e = 1 / ( 1 + T2e ), for gold - palladium alloys with different compositions by utilizing pulsed muon - spin rotation and relaxation measurements.The results show that the observed relaxation rates are consistent with those expected from Elliott - Yafet scattering mechanism at high temperatures but deviate significantly below zero. 5 K. We find that this deviation can be explained if we assume an additional contribution to the relaxation rate due to spin - orbit interaction between conduction electrons and localized magnetic moments associated with Pd atoms.This is supported by our theoretical calculations based on density functional theory which predict a large enhancement of the spin - orbit coupling strength as one moves away from the centre of the Brillouin zone towards the Fermi surface.Our findings suggest that the presence of localised magnetic moment may play an important role in determining the transfer properties of these materials even though they do not order magnetically down to lowest measured temperatures."
    },
    {
        "original_text": "We have studied the decay of muons into two neutrinos, one electron-positron pair and one photon by using the Feynman diagram method. We found that there are three types of emitted neutrinos; type I is emitted when the energy of the emitted photon is less than half of the rest mass of the muon; type II is emitted when the energy is greater than or equal to half but less than twice the rest mass of themuon;andtype IIIisemittedwhentheenergyofthespin-1/2particlesissmallerthantwice therespectivestandardmass.Theprobabilitydistributionfunctionsforthese3typesareshown  for different values of the parameter x = Eγ / (2 mμ). The results obtained here agree with those given previously. \n \n Keywords: muon decay, neutrino emission, Feynman diagram technique, probability distribution function, standard model",
        "watermark_text": "We have studied the decay of muons into two neutrinos, 1 electron - positron pair and 1 photon by using the Feynman diagram method.We found that there are 3 types of emitted neutrinos ; type I is emitted when the energy of the emitted photon is low than half of the rest mass of the muon ; type II is emission when the energetic is higher than or equal to half but less than twice the rest mass of themuon ; andtype IIIisemittedwhentheenergyofthespin - 1 / 2particlesissmallerthantwice therespectivestandardmass.Theprobabilitydistributionfunctionsforthese3typesareshown for different values of the parameter x = Eγ / ( 2 mμ ).The results obtained here agree with those given previously.Keywords : muon decay, neutrino emission, Feynman diagram technique, probability distribution function, standard model"
    },
    {
        "original_text": "We propose that the fuzzball proposal for black holes can be extended to include internal degrees of freedom, which are excited by infalling matter and produce Hawking radiation.  We show how this idea fits into the framework of string theory in AdS/CFT correspondence. The proposed model is based on an extension of the work done by Horowitz and Maldacena (HM) who showed that the entropy of extremal Kerr-Newman black hole agrees exactly with the microscopic counting of states in N=4 super Yang-Mills gauge theory at strong coupling. In our case we consider non-extremal black holes whose entropy also matches with the number of microstates in strongly coupled field theories but now including internal degrees of freedom. This leads us to conclude that the emission spectrum of these black holes should agree with the one predicted by Hawking's original calculation. Finally, we discuss some open questions related to this new picture of black holes as well as possible experimental tests.",
        "watermark_text": "We propose that the fuzzball proposal for black holes can be extended to include internal degrees of liberty, which are excited by infalling matter and produce Hawking radiation.We show how this idea fits into the frame of string theory in AdS / CFT correspondence.The proposed model is based on an extension of the work done by Horowitz and Maldacena ( HM ) who showed that the entropy of extremal Kerr - Newman black hole agrees exactly with the microscopic counting of states in N = 4 super Yang - Mills gauge theory at strong coupling.In our case we consider non - extremal dark holes whose entropy also matches with the count of microstates in strongly coupled field theories but now including internal degrees of freedom.This leads us to conclude that the emission spectrum of these dark holes should agree with the one predicted by Hawking ' s original calculation.Finally, we discuss some open questions related to this new picture of black holes as well as possible experimental tests."
    },
    {
        "original_text": "We present new near-infrared (NIR) polarimetric observations of the GG Tau system, which reveal that its circumstellar disk is highly structured and contains several bright regions with different polarization properties. The most prominent feature in our data set is an arc-like structure located at about 0.5 arcsec to the south-east of the central binary star. This region shows strong polarized emission up to 10% of the total intensity and has been previously identified as a reflection nebula by Weintraub et al. (1993) . We find that this feature can be explained by scattering off optically thin dust grains close to the midplane of the disk. In addition we detect two other bright features on either side of the central binary. These are also associated with high degrees of linear polarization but show no clear evidence for scattered light. Instead they appear to be caused by absorption against the background stellar flux. Finally, we identify three additional fainter structures in the southern part of the disk. All these features have similar polarization angles indicating that their origin may be related.",
        "watermark_text": "We present newly near - infrared ( NIR ) polarimetric observations of the GG Tau system, which reveal that its circumstellar disk is highly structured and contains several bright regions with different polarization properties.The most prominent feature in our data set is an arc - like structure located at about 0. 5 arcsec to the south - eastern of the central binary star.This region shows strong polarized emission up to 10 % of the total intensity and has been previous identified as a reflection nebula by Weintraub est al. ( 1993 ).We find that this feature can be explained by scattering off optically thin dust grains close to the midplane of the disk.In addition we detect two other bright features on either side of the central binary.These are also associated with high degrees of linear polarization but show no clear evidence for scattered light.Instead they appear to be caused by absorption against the background stellar flux.Finally, we identify three additional fainter structures in the southern part of the disk.All these features have similarly polarization angles indicating that their source may be related."
    },
    {
        "original_text": "We present new photometric data for stars near the main-sequence turn-off (MSTO) in three fields in the Small Magellanic: Cloud, obtained with the Wide Field Imager at the MPG/ESO 2.2 m telescope. The observations were carried out during two runs in August and September 2002. We have used these data to derive ages and metallicities for about 1000 MSTO stars using theoretical isochrones. Our results show that there are significant differences between the age distributions derived for different fields. In particular we find evidence for an extended period of star formation in field 1, which contains the open cluster NGC 1818. This result supports previous suggestions based on studies of red giant branch stars. \n \n Keywords: Age distribution; Open clusters; Small Magellanic Cloud; Stellar population synthesis; Wide-field imaging. Subject headings: Galaxy: Magellanic Clouds",
        "watermark_text": "We present new photometric data for stars near the main - sequence turn - off ( MSTO ) in three fields in the Small Magellanic : Cloud, obtained with the Wide Field Imager at the MPG / ESO 2. 2 m telescope.The observations were carried out during two runs in August and Sept 2002.We have used these data to derive ages and metallicities for about 1000 MSTO stars using theoretical isochrones.Our results show that there are significantly differences between the age distributions derived for different fields.In particular we find evidence for an extended period of star formation in field 1, which contains the open cluster NGC 1818.This result supports previous suggestions based on studies of red giant limb stars.Keywords : Age distribution ; Open clusters ; Small Magellanic Cloud ; Stellar population synthesis ; Wide - field imaging.Subject headings : Galaxy : Magellanic Clouds"
    },
    {
        "original_text": "The purpose of this article is to present an interdisciplinary framework that can be used in describing and analyzing contextually mediated change (CMC). The proposed framework consists of three main components, namely, (1) contextual mediation, (2) individual agency, and (3) social structure. These components are interrelated through two key processes -contextualization and recontextualization. In addition, we propose four dimensions along which CMC may occur. Finally, we discuss how our framework contributes to existing theories on organizational change as well as some potential applications of it. Keywords: Organizational change; Individual agency; Social structure; Contextualization; Recontextualization. This article presents an interdisciplinary framework that describes and analyzes contextually mediated change (CMChange). We argue that CMChange occurs when individuals engage with their contexts by interpreting them differently than they were previously interpreted. As such, CMChange involves both contextualization and recontextualizatton. Contextualization refers to the process whereby individuals make sense of their contexts based on their own experiences and perspectives. Recontextualization refers to the act of reinterpreting one's interpretation of his/her context(s), thereby changing its meaning and/or significance. Our framework also proposes four dimensions along which CMChange may take place. First, there is the dimension of time. Second, there is the dimension",
        "watermark_text": "The purpose of this article is to present an interdisciplinary framework that can be used in describing and analyzing contextually mediated change ( CMC ).The proposed framework consists of three main components, namely, ( 1 ) contextual mediation, ( 2 ) individual agency, and ( 3 ) social system.These components are interrelated through two key processes - contextualization and recontextualization.In addition, we propose four dimensions along which CMC may occur.Finally, we discuss how our framework contributes to established theories on organizational change as also as some potential applications of it.Keywords : Organizational change ; Individual agency ; Social structure ; Contextualization ; Recontextualization.This article presents an interdisciplinary framework that describes and analyzes contextually mediated change ( CMChange ).We argue that CMChange occurs when individuals engage with their contexts by interpreting them differently than they were previously interpreted.As such, CMChange involves both contextualization and recontextualizatton.Contextualization refers to the process whereby individuals make sense of their contexts based on their own experiences and perspectives.Recontextualization refers to the act of reinterpreting one ' s interpretation of his / her context ( s ), thereby changing its meaning and / or significance.Our framework even proposes four dimensions along which CMChange may take place.First, there is the dimension of time.Second, there is the dimension"
    },
    {
        "original_text": "The purpose of this article is to give an overview of the theory of weight structures on triangulated categories developed by A. Bondal and M. Kapranov.  We will explain how it can be applied to construct new cohomology theories for algebraic varieties over finite fields or number fields.   In particular we will discuss the construction of motivic cohomology using weight structures on derived categories of mixed Tate motives.    The main results are due to J. Ayoub, D. Gaitsgory, R. Hain, S. Katzarkov, V. Lafforgue, C. Soulé, B. Stienstra, and others. This article was written as part of the author's Ph.D thesis at Utrecht University under supervision of Prof. Dr. Wim van der Kallen. It has been published online by the author with permission of the supervisor. For more information about the content see the introduction below.",
        "watermark_text": "The purpose of this article is to give an overview of the theory of weight structures on triangulated categories developed by A. Bondal and M. Kapranov.We will explain how it can be applied to construct new cohomology theories for algebraic varieties over finite fields or number fields.In particular we will discuss the construction of motivic cohomology using weight structures on derived categories of mixed Tate motives.The main results are due to J. Ayoub, D. Gaitsgory, R. Hain, S. Katzarkov, V. Lafforgue, C. Soulé, B. Stienstra, and others.This article was written as part of the author ' s Ph. D thesis at Utrecht University under supervisor of Prof. Dr. Wim van der Kallen.It has been published online by the author with authorization of the supervisor.For more information about the content see the introduction below."
    },
    {
        "original_text": "We study the non-equilibrium evolution of an interacting onedimensional Bose gas initially prepared in a coherent state with finite particle number fluctuations and show that it exhibits universal features, which are independent of microscopic details such as interactions or initial conditions. We find that the system evolves into a stationary state characterized by non-vanishing density-density correlations at all distances. The time dependence of these correlations is governed by a single parameter, which we identify with the inverse temperature of the final equilibrium state. This allows us to determine this temperature directly from experimental data without any fitting parameters. Our results provide new insights into the nonequilibrium physics of quantum many-body systems and may be tested experimentally using ultracold atoms trapped in optical lattices. \nI. INTRODUCTORY REMARK\nThe recent development of techniques for trapping and manipulating cold atomic gases has opened up exciting possibilities for studying strongly correlated quantum matter far from thermal equilibrium [1] . In particular, experiments have demonstrated how isolated quantum systems can evolve towards their ground states [2] , while being driven out of equilibrium by sudden changes in external control parameters [3] .\nIn this work, we consider the case where the system is suddenly quenched across a phase transition [4] . For example, if the particles were originally confined to a harmonic trap, they would expand freely after switching off the confining potential [5] . Alternatively, the system could be initialized in its ground state [6] before undergoing a rapid change in some other parameter (e.g., magnetic field) [7, 8] . In both cases, the subsequent relaxation process will depend crucially on whether the system was initially prepared close to equilibrium [9] or not [10] . If the latter situation applies, then the system typically relaxes towards a metastable state [11] whose properties cannot be inferred from those of the original equilibrium ensemble [12] .",
        "watermark_text": "We study the non - equilibrium evolution of an interacting onedimensional Bose gas originally prepared in a coherent state with finite particle number fluctuations and show that it exhibits universal features, which are independent of microscopic details such as interactions or initial conditions.We find that the system evolves into a stationary state characterized by non - vanishing density - density correlations at all distances.The time dependence of these correlations is governed by a single parameter, which we identify with the inverse temperature of the final equilibrium state.This allows us to determine this temperature directly from experiment data without any fitting parameters.Our results provide fresh insights into the nonequilibrium physics of quantum many - body systems and might be tested experimentally using ultracold atoms trapped in optical lattices.I. INTRODUCTORY REMARKThe recent development of techniques for trapping and manipulating cold atomic gases has opened up exciting possibilities for studying strongly correlated quantum material far from thermal equilibrium[ 1 ].In particular, experiments have shown how isolated quantum systems can evolution towards their ground states [ 2 ], while being driven out of equilibrium by sudden changes in external control parameters [ 3 ].In this work, we consider the case where the system is abruptly quenched along a phase transition [ 4 ].For example, if the particles were originally confined to a harmonic trap, they could expand free after switching off the confining potential [ 5 ].Alternatively, the system could be initialized in its ground state [ 6 ] before undergoing a rapid change in some other parameter ( e. g., magnetic field )[ 7, 8 ].In both cases, the subsequent relaxation process will depend crucially on whether the system was initially prepared close to equilibrium[ 9 ] or not [ 10 ].If the latter situation applies, then the system typically relaxes around a metastable state [ 11 ] whose properties cannot be inferred from those of the original equilibrium ensemble [ 12 ]."
    },
    {
        "original_text": "We study the minimal size of a barchan, which is one of the most common types of sand dunes in nature. We show that this problem can be formulated as an optimal control problem for a nonlinear partial differential equation with nonlocal boundary conditions and prove existence of solutions by using variational methods. The numerical results are obtained by applying finite element method to discretize the state equations and then solving them by Newton's iteration scheme. Finally we present some examples illustrating our theoretical findings. Sand dunes are among the most beautiful natural phenomena on Earth. They have been studied extensively since the 19th century [1] . One of the simplest forms of sand dunes is called barchan [2] , see Figure 1 (a). It has a crescent shape with its horns pointing away from the wind direction. Barchans occur naturally over large areas around the world such as Australia [3] , Namibia [4] , Saudi Arabia [5] , China [6] , Japan [7] , etc.. In recent years there has been growing interest in studying mathematical models describing formation of sand dunes [8, 9, 10] .\nIn this work we consider the following model proposed by Kroy et al [11] : \nwhere u(x) denotes the height of the sand bed at position x ∈ Ω = [0, L] × R + ; f > 0 represents the rate of deposition; g ≥ 0 stands for the erosion coefficient; h(u) describes the effect of surface tension; p(x), q(x) represent the pressure terms due to gravity and friction respectively; α > 0 measures the strength of the wind blowing along x-axis; β > 0 characterizes the resistance against the flow of air; γ > 0 is related to the cohesion between grains of sand; θ is the angle of repose of sand particles; c > 0 is the constant volume fraction of sand per unit area; finally, n is the outward normal vector to the boundary Γ = {0 < x < L} × {0} ∪ {L} × R + . For more details about physical meaning of parameters involved in system (1) , please refer to [12] .",
        "watermark_text": "We study the minimum size of a barchan, which is 1 of the most common kinds of sand dunes in nature.We show that this issue can be formulated as an optimal control problem for a nonlinear partial differential equation with nonlocal border conditions and prove existence of solutions by using variational methods.The numerical results are obtained by applying finite element method to discretize the state equations and then solving them by Newton ' s iteration system.Finally we present some examples illustrating our theoretical findings.Sand dunes are among the most beautiful natural phenomena on Earth.They have been studied extensively since the 19th century [ 1 ].One of the simplest forms of sand dunes is called barchan [ 2 ], see Figure 1 ( a ).It has a crescent shape with its horns pointing away from the breeze direction.Barchans occur naturally over large areas around the world such as Australia [ 3 ], Namibia[ 4 ], Saudi Arabia[ 5 ], China[ 6 ], Japan[ 7 ], etc.In recent years there has been growing interest in studying mathematical models describing forming of sand dunes[ 8, 9, 10 ].In this work we consider the following model proposed by Kroy et al[ 11 ] : where u ( x ) denotes the height of the sand bed at position x ∈ [UNK] =[ 0, L ] × R + ; f > 0 represents the rate of deposition ; g ≥ 0 stands for the erosion coefficient ; h ( u ) describes the effect of surface tension ; p ( x ), q ( x ) represent the pressure terms due to gravity and friction respectively ; α > 0 measures the strength of the wind blowing along x - axis ; β > 0 characterizes the resistance against the flow of air ; γ > 0 is related to the cohesion between grains of sand ; θ is the angle of repose of sand particles ; c > 0 is the constant volume fraction of sand per unit area ; finally, n is the outward normal vector to the boundary Γ = { 0 < x < L } × { 0 } ∪ { L } × R +.For more details about physical meaning of parameters involved in system ( 1 ), please refer to [ 12 ]."
    },
    {
        "original_text": "We present an experimental investigation into complementarity and quantum nonlocality using a photonic implementation of the Einstein-Bohr photon box thought experiment. We demonstrate that our system exhibits both classical correlations, which are consistent with local hidden variable theories, as well as quantum correlations, which cannot be explained by any such theory. Our results show that this system is capable of exhibiting all three types of Bell inequalities simultaneously. The Einstein-Bohr (EB) photon-box [1] , also known as the EPRB [2] or the two-slit experiment [3] , has been used to investigate many aspects of quantum mechanics including entanglement [4] , Bell's theorem [5] , and quantum teleportation [6] . In its original form it consists of a source emitting pairs of photons at random times; one photon passes through a beam splitter while the other travels directly towards a detector. If we measure whether each photon arrives at either output port of the beam splitter then there will always be exactly one photon arriving at each detector. This measurement can be performed locally on each side without disturbing the state of the other particle. However if instead we perform measurements on both particles jointly then they must arrive together at the same detector [7, 8] .\nIn order for these experiments to exhibit genuine quantum effects, the detectors need to have high efficiency so that the probability of detecting more than one photon per pair is negligible [9] . Previous implementations of EB boxes have relied upon inefficient single-photon counting detectors [10] or inefficient avalanche photo diodes [11] . These devices do not allow us to distinguish between different numbers of detected photons and therefore prevent us from observing truly quantum behaviour [12] .",
        "watermark_text": "We present an experimental investigation into complementarity and quantum nonlocality utilizing a photonic implementation of the Einstein - Bohr photon box thought experimental.We demonstrate that our system exhibits both classical correlations, which are consistent with local hidden variable theories, as also as quantum correlations, which cannot be explained by any such theory.Our results show that this system is capable of exhibiting all 3 types of Bell inequalities concurrently.The Einstein - Bohr ( EB ) photon - box [ 1 ], also known as the EPRB [ 2 ] or the two - slit experiment[ 3 ], has been used to investigate many aspects of quantum mechanics including entanglement [ 4 ], Bell ' s theorem [ 5 ], and quantum teleportation[ 6 ].In its original form it consists of a source emitting pairs of photons at random times ; one photon passes through a beam splitter while the other travels directly towards a detection.If we measure whether each photon arrives at either output port of the beam splitter then there will always be exactly one photon arriving at each detection.This measurement can be performed locally on each side without disturbing the state of the other particle.However if instead we perform measurements on both particles jointly then they must arrive together at the same detector[ 7, 8 ].In order for these experiments to exhibit genuine quantum effects, the detectors require to have high efficiency so that the probability of detecting more than one photon per pair is negligible [ 9 ].Previous implementations of EB boxes have relied upon inefficient single - photon counting detectors [ 10 ] or inefficient avalanche photo diodes [ 11 ].These devices do not allow us to distinguish between various numbers of detected photons and therefore prevent us from observing truly quantum behavior [ 12 ]."
    },
    {
        "original_text": "We present global three-dimensional MHD simulations of the evolution of dust particles embedded in turbulent, stratified accretion disks around young stars. The disk is modeled as an axisymmetric torus with a radial density profile that follows a power law with index p = -1.5. We use two different numerical methods to solve for the gas dynamics: (1) a finite volume method based on the ZEUS code; and (2) a pseudo-spectral method using spherical harmonics expansions. In both cases we assume azimuthal symmetry about the central star. Our main goal is to study how the presence of magnetic fields affects the motion of solids through the disk. To this end, we consider three different initial field configurations: (a) purely toroidal, (b) purely poloidal, and (c) mixed toroidal-poloidal. For each configuration, we perform several runs varying the strength of the initial magnetic field.",
        "watermark_text": "We present globe three - dimensional MHD simulations of the evolution of dust particles embedded in turbulent, stratified accretion disks around young stars.The disk is modeled as an axisymmetric torus with a radial dense profile that follows a power law with index p = - 1. 5.We use two separate numerical methods to solve for the gas dynamics : ( 1 ) a finite volume methodology based on the ZEUS code ; and ( two ) a pseudo - spectral methodology using spherical harmonics expandings.In both cases we assume azimuthal symmetric about the central star.Our main goal is to study how the existence of magnetic fields affects the motion of solids through the disc.To this end, we consider three different initial field configurations : ( a ) purely toroidal, ( b ) purely poloidal, and ( c ) mixed toroidal - poloidal.For each configuration, we conduct several runs varying the strongest of the initial magnetic field."
    },
    {
        "original_text": "We present the first results on two massive binary systems with periods longer than 100 days that are potential targets for future space-based optical interferometers such as SIM or TPF-I. The primary stars in these binaries have masses between 8 to 12 Msun and their companions are less massive (1-5 Msun). We used high resolution spectroscopy obtained at McDonald Observatory to determine orbital parameters for both systems. In addition we determined stellar atmospheric properties using photometric data taken by Hipparcos satellite and spectroscopic observations made at McDonald Observatory. Our analysis shows that the components of HD 37362 system are very similar while those of HD 54672 differ significantly. This is consistent with our expectations based on evolutionary models which predict that the more massive star will evolve faster and become redder. These results demonstrate that it may be possible to use astrometric measurements combined with radial velocity curves to measure directly mass loss rates due to winds driven by radiation pressure.",
        "watermark_text": "We present the first results on two massive binary systems with periods longer than 100 days that are potential targets for future space - based optical interferometers such as SIM or TPF - I.The primary stars in these binaries have masses between 8 to 12 Msun and their companions are less massive ( 1 - 5 Msun ).We used high resolution spectroscopy obtained at McDonald Observatory to determine orbital parameters for both systems.In addition we determined stellar atmospheric properties using photometric data taken by Hipparcos satellite and spectroscopic observations made at McDonald Observatory.Our analysis shows that the components of HD 37362 system are very similar while those of H 54672 differ significantly.This is consistent with our expectations based on evolution models which predict that the more massive star will evolve faster and become redder.These results demonstrate that it may be possible to utilize astrometric measurements combined with radial velocity curves to measure directly mass loss rates due to winds driven by radiation pressure."
    },
    {
        "original_text": "We study the diameter and clustering coefficient for several classes of random graphs with power law degree distribution, including preferential attachment (PA) networks.  We show that PA networks have small diameters if their growth is slow enough; this result holds even when we allow multiple edges between nodes. For fast growing PA networks, however, there are examples where the diameter grows exponentially as a function of n. In addition to studying the diameter, we also consider the clustering coefficient of these networks. The clustering coefficient measures how well connected neighbors of a node are among themselves. We prove upper bounds on the clustering coefficients of PA networks which hold regardless of the rate at which new nodes join the network. Finally, we present some numerical results showing that our theoretical predictions agree very well with simulations. Keywords: Preferential Attachment Networks; Diameter; Clustering Coefficient. 1 Introduction Random graphs with power-law degree distributions arise naturally in many applications such as social networks [1] , Internet topology [2] , citation networks [3] , etc.. These types of networks can be generated by using various mechanisms known as \"network growth models\"; see [4] for an overview. One popular model is called \"preferential attachment\" or \"Power-Law Graphs\" [5] . This class of networks has been studied extensively over the past decade [6] - [8] .\nIn this work, we focus on two important properties of these graphs: the diameter and the clustering coefficient [9] . The diameter D(G) of a graph G = (V, E) is defined as max{d(u, v) | u, v ∈ V }, i.e., it is the maximum distance between any pair of vertices in G. The clustering coefficient C(v) of a vertex v is defined as the fraction of pairs of neighbors of v that are adjacent to each other [10] . It is easy to verify that both quantities depend only on the degrees of the nodes in the graph [11] ; hence they do not change under edge rewirings [12] .",
        "watermark_text": "We study the diameter and clustering coefficient for several classes of randomly graphs with power law degree distribution, including preferential attachment ( PA ) networks.We show that Pennsylvania networks have small diameters if their growth is slow sufficiently ; this result holds even when we allow multiple edges between nodes.For fast growing PA networks, however, there are examples where the diameter grows exponentially as a function of n.In addition to studying the diameter, we also consider the clustering coefficient of these networks.The clustering coefficient measures how well linked neighbors of a node are amongst themselves.We prove higher bounds on the clustering coefficients of PA networks which hold regardless of the rate at which newly nodes join the network.Finally, we present some numerical results showing that our theoretical predictions agree very well with simulations.Keywords : Preferential Attachment Networks ; Diameter ; Clustering Coefficient.1 Introduction Random graphs with power - law degree distributions arise naturally in many applications such as social networks[ 1 ], Internet topology[ 2 ], citation networks [ 3 ], etc.These types of networks can be generated by using various mechanisms known as \" network growth models \" ; see [ 4 ] for an overview.One popular model is called \" preferential attachment \" or \" Power - Law Graphs \" [ 5 ].This class of networks has been studied extensively over the past decade [ 6 ] - [ 8 ].In this work, we focus on two important properties of these graphs : the diameter and the clustering coefficient [ 9 ].The diameter D ( G ) of a graph G = ( V, E ) is defined as max { d ( u, v ) | u, v ∈ V }, i. e., it is the maximum distance between any pair of vertices in G.The clustering coefficient C ( v ) of a vertex v is defined as the fraction of pairs of neighbours of v that are adjoining to each other [ 10 ].It is easy to confirm that both quantities depend only on the degrees of the nodes in the graph [ 11 ] ; thus they do not change under edge rewirings [ 12 ]."
    },
    {
        "original_text": "The future evolution of the local large scale structure is investigated by using N-body simulations with different cosmological models, including dark energy (DE) and cold dark matter (CDM). The results show that in the Λ-CDM model without DE, the growth rate of large-scale structures decreases rapidly at late times due to the effect of CDM. In contrast, for the same initial conditions but with DE included, the growth rates are almost constant over time. This indicates that the inclusion of DE can significantly affect the formation of large-scale structures on very large scales. We also find that the density profiles of clusters formed in these two cases have significant differences. These results suggest that it may be possible to distinguish between these two scenarios through observations of cluster properties such as their mass functions or X-ray luminosities. Keywords: Cold dark matter; Dark energy; Growth factor; Clustering statistics; Density profile; Cosmology",
        "watermark_text": "The future evolution of the local large scale structure is investigated by using N - body simulations with different cosmological structures, including dark energy ( DE ) and cold dark matter ( CDM ).The results show that in the Λ - CDM mode without DE, the growth rate of big - scale structures decreases rapidly at late times due to the effect of CDM.In contrast, for the same initial conditions but with DE included, the growth rates are nearly constant over time.This indicates that the inclusion of DE can significantly affect the formation of large - series structures on very big scales.We also find that the density profiles of clusters formed in these 2 cases have significant differences.These results suggest that it may be possible to differentiate between these two scenarios through observations of cluster properties such as their mass functions or X - ray luminosities.Keywords : Cold dark matter ; Dark energy ; Growth factor ; Clustering statistics ; Density profile ; Cosmology"
    },
    {
        "original_text": "We present an analysis of the Bondi accretion rate onto primordial black holes (PBHs) during the radiation-dominated era, taking into account the effects of pressure and viscosity on the gas flow. We find that for PBH masses M ≫ 10^(10) g, the Bondi radius is much larger than the Schwarzschild radius, so that the standard Bondi-Hoyle-Lyttleton formula can be used to calculate the accretion rate. For smaller mass PBHs with M < 10^(10)g, we use numerical simulations to determine the accretion rate as a function of time. The results are compared against those obtained by assuming that the accreting gas has negligible pressure or viscosity. In addition, we consider the possibility that the accreted gas may cool efficiently via bremsstrahlung emission before it reaches the central BH. Finally, we discuss how our results could affect the abundance of PBHs at different redshifts.",
        "watermark_text": "We present an analysis of the Bondi accretion rate onto primordial black holes ( PBHs ) during the radiation - dominated era, taking into account the effects of pressure and viscosity on the gas flow.We find that for PBH masses M [UNK] 10 ^ ( 10 ) g, the Bondi radius is much larger than the Schwarzschild radius, so that the standard Bondi - Hoyle - Lyttleton formula can be used to calculate the accretion rate.For smaller mass PBHs with M < 10 ^ ( 10 ) g, we utilize numerical simulations to determine the accretion rate as a function of time.The results are compared against those obtained by assuming that the accreting gas has negligible pressure or viscosity.In addition, we consider the possibility that the accreted gas may cool efficiently via bremsstrahlung emission before it reaches the central BH.Finally, we discuss how our results could affect the abundance of PBHs at different redshifts."
    },
    {
        "original_text": "We report on an observation made with Chandra's High Energy Transmission Grating Spectrometer (HETGS) that shows dramatic variability of absorption lines in the spectrum of the black hole candidate Cygnus X1, which is known to have strong winds and outflows. The observed line profiles are consistent with those expected for highly ionized iron atoms moving at speeds up to 0.2c along our line-of-sight toward the central source. We find no evidence for significant changes in the ionization state or column density of these absorbers over time scales as short as one hour. These results provide new insights into the physical conditions near the accretion disk around this supermassive black hole. This work was supported by NASA under contract NAS8-03060. \n \n Keywords: Black holes; Winds; Outflows; Accretion disks \n \n Introduction \n \n In recent years there has been growing interest in studying the properties of winds and outflows associated with active galactic nuclei (AGN). Such flows may play important roles in regulating the growth of supermassive black holes through their effects on both the surrounding gas and radiation fields. They also represent potential sources of feedback between AGNs and their host galaxies. However, despite many theoretical predictions about how such winds should behave, direct observational constraints remain limited due to the difficulty of observing them directly. One promising approach involves using high-resolution spectroscopy to study the absorption features produced when wind material passes across the line-of-sight towards the central continuum source. Recent observations of several nearby Seyfert 1 galaxies show clear evidence for variable absorption lines arising from photoionized plasma flowing outward from the nucleus at velocities ranging from ~100-1000 km/sec (e.g., Kaspi et al. 2002; Crenshaw & Kraemer 2003; McKernan et al. 2007 ). Here we present another example of this phenomenon based on a deep Chandra/HETG observation of the brightest member of the class of Galactic black hole candidates (GBHCs), Cygnus X1. \n \n Cygnus X1 is located only 2 kpc away from Earth in the",
        "watermark_text": "We report on an observation made with Chandra ' s High Energy Transmission Grating Spectrometer ( HETGS ) that shows dramatic variability of absorbing lines in the spectral of the black hole candidate Cygnus X1, which is known to have strong winds and outflows.The observed line profiles are consistent with those expected for highly ionized iron atoms moving at speeds up to zero. 2c along our line - of - sight toward the central source.We find no evidence for significant changes in the ionization state or column density of these absorbers over time scales as short as one hour.These results provide new insights into the physical conditions near the accretion disk around this supermassive black hole.This work was supported by NASA under contract NAS8 - 03060.Keywords : Black holes ; Winds ; Outflows ; Accretion disks Introduction In recent years there has been growing curiosity in studying the properties of winds and outflows associated with active galactic nuclei ( AGN ).Such flows may play important roles in regulating the growth of supermassive black holes through their effects on both the observing gas and radiation fields.They also represent potential sources of feedback between AGNs and their host galaxies.However, despite many theoretical predictions about how such winds should behave, direct observational constraints remain limited due to the challenge of observing them directly.One promising approach involves using high - resolution spectroscopy to study the absorbing features produced when wind material passes cross the line - of - sight towards the center continuum source.Recent observations of several nearby Seyfert 1 galaxies show clear evidence for variable absorption lines arising from photoionized plasma flowing outward from the nucleus at velocities ranging from ~ 100 - 1000 km / sec ( e. g., Kaspi et al. 2002 ; Crenshaw & Kraemer 2003 ; McKernan et al. 2007 ).Here we present another example of this phenomenon based on a deep Chandra / HETG observation of the brightest member of the class of Galactic black hole candidates ( GBHCs ), Cygnus X1.Cygnus X1 is located only 2 kpc away from Earth in the"
    },
    {
        "original_text": "We study the dynamics of an epidemic system consisting of two strains and three classes, susceptible (S), infected (I) and recovered/removed (R). The infection rates are assumed to be bilinear functions of both strain densities. We show that this system has a unique positive equilibrium which is globally asymptotically stable if one of the following conditions holds:\n(i) the recovery rate for each strain is greater than its corresponding infection rate; or \n(ii) there exists at least one strain whose recovery rate is equal to its infection rate. \nHowever, we prove that when condition (i) fails but condition (ii) holds true, then the system exhibits chaos through numerical simulations. Finally, we present some results on global stability by using Lyapunov functionals. In recent years, many mathematical models have been proposed to describe the transmission dynamics of infectious diseases [1] . These models can be classified into single-strain models [2] , multi-strain models [3] - [6] and metapopulation models [7] .\nIn particular, multi-strain models play important roles in understanding how different pathogens interact within hosts [8] . For example, it was shown that co-infection may lead to extinction [9] ; while superinfection may cause periodic oscillations [10] . Recently, Li et al. [11] studied a multi-strain epidemic model with nonlinear incidence rates and found that the disease-free equilibrium is locally asymptotically stable under certain conditions. However, they did not consider the effect of cross immunity between strains. Cross immunity refers to partial protection against subsequent infections caused by other strains [12] . It plays an important role in preventing epidemics [13] . Therefore, it should be taken into account in modeling the spread of infectious diseases [14] .",
        "watermark_text": "We study the dynamics of an epidemic system consisting of two strains and 3 classes, susceptible ( S ), infected ( I ) and recovered / removed ( R ).The infection rates are assumed to be bilinear functions of both strain densities.We show that this system has a unique positive equilibrium which is globally asymptotically stability if one of the following conditions holds : ( i ) the recovery rate for each strain is greater than its corresponding infection rate ; or ( ii ) there exists at least one strain whose recovery rate is equal to its infection rate.However, we prove that when condition ( i ) fails but condition ( ii ) holds true, then the scheme exhibits chaos through numerical simulations.Finally, we present some findings on global stability by using Lyapunov functionals.In recent years, many mathematical models have been proposed to describe the transmission dynamics of infected diseases [ 1 ].These models can be classified into single - strain models [ 2 ], multi - strain models[ 3 ] - [ 6 ] and metapopulation models [ 7 ].In particular, multi - strain models play important roles in understanding how various pathogens interact within hosts [ 8 ].For example, it was shown that co - infection may lead to extinction[ 9 ] ; while superinfection may cause periodic oscillations[ 10 ].Recently, Li et al.[ 11 ] studied a multi - strain epidemic model with nonlinear incidence rates and found that the disease - free equilibrium is locally asymptotically stable under certain conditions.However, they did not consider the impact of cross immunity between strains.Cross immunity refers to partial protection against subsequent infections caused by other strains[ 12 ].It plays an important role in preventing epidemics [ 13 ].Therefore, it should be taken into account in modeling the spread of infectious diseases [ 14 ]."
    },
    {
        "original_text": "We present the results of multi-wavelength studies towards southern hot molecular cores (HMCs) using ammonia, water vapour, and continuum data at 1.3 cm and 3 mm wavelengths obtained with the Australia Telescope Compact Array (ATCA). The HMCs are associated with high-mass star formation regions in which massive young stellar objects have been detected through infrared surveys. We find that all our targets show compact emission features on scales of 0.1 pc or less. These sources appear to be dense clumps embedded within larger-scale structures extending up to several parsecs. In addition, we detect extended emission components surrounding these compact clumps. Our analysis shows that the physical conditions derived for the compact clumps are consistent with those expected for hot molecular gas heated by protostellar outflows. On the other hand, the properties of the extended emission suggest that it is likely tracing an envelope around each source.",
        "watermark_text": "We present the results of multiple - wavelength studies towards southern hot molecule cores ( HMCs ) using ammonia, water vapour, and continuum data at 01. 3 cm and 3 mm wavelengths obtained with the Australia Telescope Compact Array ( ATCA ).The HMCs are associated with high - mass stellar formation areas in which massive young stellar objects have been detected through infrared surveys.We find that all our targets show compact emission features on scales of 0. 1 pc or less.These sources appear to be dense clumps embedded inside larger - scale constructions extending up to several parsecs.In addition, we detect extended emission components surrounding these compact clumps.Our analysis shows that the physical conditions derived for the compact clumps are consistent with those expected for hot molecular gas heated by protostellar outflows.On the other hand, the properties of the expanded emission suggest that it is probably tracing an envelope surrounding each source."
    },
    {
        "original_text": "We study central limit theorems for estimators of parameters in linear regression models where errors are not necessarily normally distributed but have an elliptical distribution, and we allow some explanatory variables to be non-normal. We show that under suitable conditions on the model coefficients, the asymptotic distributions of these estimators can be approximated by those obtained when all the explanatory variables follow a multivariate normal distribution. The results are illustrated through simulation experiments. Keywords: Central Limit Theorem; Elliptical Distributions; Regression Modeling. 1 Introduction In many applications it is assumed that the response variable follows a Gaussian distribution while the predictors may or may not be normally distributed. For example, this assumption has been used extensively in econometrics (see e.g., Greene [2003] ). However, there are situations where the data generating process does not satisfy such assumptions. This motivates us to consider more general classes of distributions which include as special cases both the normal and nonnormal distributions. One class of distributions that includes most common probability density functions encountered in practice is given by the so-called elliptical distributions. These distributions were introduced independently by Kelker [1970] , Hüsler and Reiss [1981] , and Fang et al. [1987] . They are characterized by their dependence structure rather than their marginal densities. A random vector X = (X1, ..., Xd)T ∈ Rd belongs to the family of elliptical distributions if its characteristic function satisfies E[exp(itX)] = exp{−V (t)},\nwhere V : R → [0, ∞) is called the characteristic generator. If V ≡ 0 then X is said to belong to the family of spherical distributions. Examples of elliptical distributions include:",
        "watermark_text": "We study central limit theorems for estimators of parameters in linear regression models where mistakes are not necessarily normally distributed but have an elliptical distribution, and we allow some explanatory variables to be non - normal.We show that under suitable conditions on the model coefficients, the asymptotic distributions of these estimators can be approximated by those achieved when all the explanatory variables follow a multivariate normal distribution.The results are illustrated through simulation experiments.Keywords : Central Limit Theorem ; Elliptical Distributions ; Regression Modeling.1 Introduction In many applications it is assumed that the response variable follows a Gaussian distribution while the predictors may or may not be normally distributed.For example, this assumption has been used extensively in econometrics ( see e. g., Greene [ 2003 ] ).However, there are situations where the data generating procedure does not fulfill such assumptions.This motivates us to consider more general classes of distributions which include as special cases both the norm and nonnormal distributions.One class of distributions that includes most common probability density functions encountered in practice is given by the so - called elliptical distributions.These distributions were introduced independently by Kelker[ 1970 ], Hüsler and Reiss[ 1981 ], and Fang et al.[ 1987 ].They are characterized by their dependence system rather than their marginal densities.A random vector X = ( X1,., Xd ) T ∈ Rd belongs to the family of elliptical distributions if its characteristic function satisfies E [ exp ( itX ) ]= exp { −V ( t ) }, where V : R → [ 0, ∞ ) is called the characteristic generator.If V ≡ 0 then X is said to belong to the family of spherical distributions.Examples of elliptical distributions include :"
    },
    {
        "original_text": "The production of particles with large transverse momenta is studied in the fragmentation region for gluons and quarks produced by photons, Z bosons or W bosons.  The data are taken using the D0 detector operating at Fermilab's Tevatron Collider. Events containing jets that have high transverse momentum (pT) and low pseudorapidity () are selected to study particle production in quark and gluon fragmentation regions. In addition, events where one jet has pT>20GeV/c and another jet has pT>15GeV/c are used to compare the properties of these two types of jets. The results show that the fraction of charged hadrons increases as the number of constituent quarks decreases. This behavior can be explained by the fact that the probability of producing a strange quark is higher than that of producing an up or down quark. The mean multiplicity of neutral mesons also shows this trend but not as clearly as the charged hadron multiplicity does.",
        "watermark_text": "The production of particles with big transverse momenta is studied in the fragmentation region for gluons and quarks produced by photons, Z bosons or WA bosons.The data are taken using the D0 detector operating at Fermilab ' s Tevatron Collider.Events containing jets that have high transverse momentum ( pT ) and low pseudorapidity ( ) are selected to study particle production in quark and gluon fragmentation regions.In addition, events where one jet has pT > 20GeV / c and another jet has pT > 15GeV / c are used to compare the properties of these 2 types of jets.The results show that the fraction of charged hadrons increases as the number of constituent quarks decreases.This behavior can be explained by the fact that the probability of generating a strange quark is higher than that of producing an up or down quark.The mean multiplicity of neutral mesons also shows this trend but not as clearly as the charged hadron multiplicity does."
    },
    {
        "original_text": "We report the discovery of an isolated white dwarf (WD) in the Sloan Digital Sky Survey Data Release 7, SDSSJ104341.53 + 085558.2, which has a large infrared excess and is surrounded by dusty material that may be part of a debris disc. The WD's temperature is T eff = 13000 ± 1000 K, its radius R wd = 0.0120 ± 0.0010 R ⊙ , and it has log g = 8.0 ± 0.1 cm s −2 . We find no evidence for binarity or accretion activity associated with this object. This is only the second known example of such a system; the first was GD 362. Our results suggest that these systems are rare but not unique among WDs. If confirmed, they would provide important constraints on models of planetary formation around WDs. \n \n Keywords: White dwarfs",
        "watermark_text": "We report the discovery of an isolated white dwarf ( WD ) in the Sloan Digital Sky Survey Data Release 7, SDSSJ104341. 53 + 085558. 2, which has a large infrared excess and is surrounded by dusty material that may be part of a debris disc.The WD ' s temperature is T eff = 13000 ± 1000 K, its radius R wd = 0. 0120 ± 0. 0010 R [UNK], and it has log g = 8. 0 ± 0. 1 cm s −2.We find no evidence for binarity or accretion action associated with this object.This is only the second known example of such a system ; the first was GD 362.Our results suggest that these systems are rare but not unique among WDs.If confirmed, they would provide important constraints on models of planetary formation around WDs.Keywords : White dwarfs"
    },
    {
        "original_text": "We present the results of our survey for southern M-dwarf binaries with separations between 0.1 AU and 10 AU, using data obtained by the Wide Field Camera 3 (WFC3) on board HST as part of program GO-12775. We find that about half of all systems are unresolved or only marginally resolved at these distances. The fraction of close binaries is higher among lower mass objects than it is among more massive ones; we estimate that this difference may be due to observational biases rather than intrinsic differences in formation mechanisms. \n \n In addition, we have identified several new candidate companions around known nearby ultracool dwarfs: GJ 436Bb, GJ 581Cc, GJ 674Ab, and GJ 758Aa. These candidates will require further observations before their status can be confirmed. Finally, we report the discovery of two previously unknown substellar objects: 2MASS J03552385+1133413AB and 2MASS J16252618-2434439AB.",
        "watermark_text": "We present the results of our survey for south M - dwarf binaries with separations between zero. 1 AU and 10 AU, using data obtained by the Wide Field Camera 3 ( WFC3 ) on board HST as part of program GO - 12775.We find that about half of all systems are unresolved or only marginally resolved at these distances.The fraction of close binaries is higher among lower mass items than it is among more massive ones ; we estimate that this distinction may be owing to observational biases rather than intrinsic differences in formation mechanisms.In addition, we have identified multiple new candidate companions around known nearby ultracool dwarfs : GJ 436Bb, GJ 581Cc, GJ 674Ab, and GJ 758Aa.These candidates will require further observations before their status can be confirmed.Finally, we report the discovery of two previously unknown substellar objects : 2MASS J03552385 + 1133413AB and twoMASS J16252618 - 2434439AB."
    },
    {
        "original_text": "We present an extension of the Continuous Time Random Walk (CTRW) formalism to describe non-Markovian processes in terms of a stochastic Liouville equation with memory kernel. The latter is obtained by solving the corresponding Fokker-Planck equation for the probability distribution function, which can be done analytically only under certain conditions on the form of the memory kernel. We show that this problem can be overcome by introducing a new concept of \"stochastic propagator\", which allows us to obtain exact solutions even when the memory kernel does not have any particular functional dependence on time or space variables. Finally we discuss how our results are related to previous works based on fractional calculus techniques. In recent years there has been growing interest in studying systems whose dynamics cannot be described within the standard framework of Markovian processes [1] . This is mainly due to the fact that many physical phenomena exhibit complex temporal behavior characterized by power law relaxation [2] , aging [3] , intermittency [4] , etc., all of them being typical features of nonMarkovian processes [5] .\nIn order to deal with these problems it was proposed [6] to use the so-called Continuous Time Random Walk (CWTRW) formalism [7, 8] . Within such a description one considers a system evolving continuously in time according to some deterministic laws but interrupted at random times by jumps between different states. These jumps occur as a consequence of interactions with other degrees of freedom, e.g. phonons [9] , electrons [10] , photons [11] , etc.. As shown in Ref. [12] , the CWTRW formalism provides a very general description of non-Markovian dynamics since it includes both discrete state models [13] and fractional diffusion equations [14] as special cases. However, despite its great flexibility, the application of the CWTRW formal-",
        "watermark_text": "We present an extension of the Continuous Time Random Walk ( CTRW ) formalism to describe non - Markovian procedures in terms of a stochastic Liouville equation with memory kernel.The latter is obtained by solving the corresponding Fokker - Planck equation for the probability distribution function, which can be done analytically only under certain conditions on the form of the memory kernel.We show that this problem can be overcome by introducing a new concept of \" stochastic propagator \", which allows us to obtain exact solutions even when the memory kernel does not have any specific functional dependence on time or spatial variables.Finally we discuss how our outcomes are related to previous works based on fractional calculus techniques.In recent years there has been growing interest in studying systems whose dynamics cannot be described within the standard framework of Markovian processes [ 1 ].This is mainly due to the fact that many physical phenomena exhibit complex temporal behavior characterized by power law relaxation [ 2 ], aging [ 3 ], intermittency [ 4 ], et., all of them being typical features of nonMarkovian processes [ 5 ].In order to deal with these problems it was proposed [ 6 ] to use the so - called Continuous Time Random Walk ( CWTRW ) formalism[ 7, 8 ].Within such a description one considers a system evolving continuously in time according to some deterministic laws but interrupted at random times by jumps between different states.These jumps occur as a consequence of interactions with other degrees of freedom, e. g. phonons [ 9 ], electrons[ 10 ], photons[ 11 ], etc.As shown in Ref.[ 12 ], the CWTRW formalism provides a very general description of non - Markovian dynamics given it includes both discrete state models[ 13 ] and fractional diffusion equations [ 14 ] as special cases.However, despite its great flexibility, the application of the CWTRW formal -"
    },
    {
        "original_text": "We present an accurate and efficient fundamental-measure density-functional (FMT) approach to describe fluids composed of rigidly-aligned hard hexagons, which are relevant as model systems for liquid crystals or colloidal suspensions with anisotropic interactions. The FMT is based on a decomposition into three different types of weighted densities that can be evaluated efficiently using fast Fourier transforms. We show how this new FMT yields excellent results compared to Monte Carlo simulations over wide ranges of packing fractions and orientations of the particles. In particular we find very good agreement between our theoretical predictions and simulation data at high packing fractions where previous approaches fail due to strong correlations among neighboring particles. Finally, we demonstrate that our method also allows us to accurately predict structural properties such as pair correlation functions and orientational order parameters. This work provides further evidence that FMTs provide a powerful tool to study complex fluids beyond simple spherical particle models. \nI. INTRODUCTORY REMARkS\nThe description of liquids and soft matter requires sophisticated methods because these materials often exhibit complex structures and dynamics. Density functionals have been developed during recent years as promising tools to tackle many-body problems in statistical mechanics [1] . They allow one to calculate equilibrium properties of interacting particles by minimizing a free energy functional with respect to the local number density distribution. A particularly successful class of density functionals are so-called fundamental-measure density-functionals (FMD), which were originally introduced by Rosenfeld [2] .\nIn their original form they only apply to fluids consisting of identical spheres but extensions to more complicated shapes like ellipsoids [3] , rods [4] , dumbbells [5] , spherocylinders [6] , and even patchy particles [7, 8] have been proposed recently. However, most of these works focus on the case of uniaxial symmetry while there exist few studies dealing with more general situations [9] . Here we consider a system of rigidly-aligned",
        "watermark_text": "We present an accurate and efficient fundamental - measure density - functional ( FMT ) approach to describe fluids composed of rigidly - aligned hard hexagons, which are relevant as model systems for liquid crystals or colloidal suspensions with anisotropic interactions.The FMT is based on a decomposition into three different kinds of weighted densities that can be evaluated efficiently using fast Fourier transforms.We show how this new FMT yields excellent results relative to Monte Carlo simulations over wide ranges of packing fractions and orientations of the particles.In particular we find very good agreement between our theoretical predictions and simulation data at high packing fractions where past approaches fail due to strong correlations among neighboring particles.Finally, we demonstrate that our methodology also allows us to accurately forecast structural properties such as pair correlation functions and orientational order parameters.This work provides further evidence that FMTs provide a powerful tool to study complex fluids beyond simple sphere particle models.I. INTRODUCTORY REMARkSThe description of liquids and soft matter requires sophisticated methods because these materials often exhibit complex structures and dynamics.Density functionals have been developed during recent years as promising tools to address many - body problems in statistical mechanics [ 1 ].They allow one to calculate equilibrium properties of interacting particles by minimizing a free energetic functional with respect to the local number density distribution.A particularly successful class of dense functionals are so - called fundamental - measure density - functionals ( FMD ), which were originally introduced by Rosenfeld [ 2 ].In their original form they only apply to fluids consisting of identical spheres but extensions to more complex shapes like ellipsoids[ 3 ], rods[ 4 ], dumbbells [ 5 ], spherocylinders [ 6 ], and even patchy particles[ 7, 8 ] have been proposed recently.However, most of these works focus on the case of uniaxial symmetry while there exist few studies dealing with more general situations [ 9 ].Here we consider a system of rigidly - aligned"
    },
    {
        "original_text": "We present integral formulas for the steady-state distribution and current in the asymmetric simple exclusion process (ASEP) with open boundaries, which is one of the most important models to describe non-equilibrium phenomena such as traffic flow on highways or biochemical reactions at molecular motors.  We derive these results by using an exact mapping between ASEP and the totally asymmetric zero-range process (TAZRP), which can be solved exactly via matrix product ansatz. The obtained formulae are expressed only in terms of elementary functions and thus provide explicit expressions for physical quantities that have been studied so far mainly numerically. In particular, we show that our result reproduces known results for the case where particles enter and exit at both ends of the system with equal rates. Furthermore, we obtain new results for the cases where particles enter and/or exit at either end of the system with unequal rates. \nI. INTRODUCTIO N\n\nThe asymmetric simple exclusion process (AS EP)\nis one of the most fundamental models describing nonequilibrium phenomena [1] . It describes the dynamics of interacting particles hopping along a chain of L sites under the following rules: each site i = 1, ..., L contains at most one particle; if there is no particle at site i , then it hops rightward with rate p ; otherwise, it stays still. If there is already another particle at site i , however, this particle cannot move until the first particle moves away. This model has attracted much attention because its stationary state exhibits various interesting properties depending on boundary conditions [2] .\nIn recent years, several studies have focused on the so-called open-boundary condition [3] - [8] : Particles enter into the leftmost site of the chain with probability α per unit time and leave from the rightmost site with probability β per unit time. For example, when α = β = 1/2, the stationary state becomes uniform regardless of the initial configuration [9] . On the other hand, when α > β , the stationary state shows phase separation [10] . Moreover, when α < β , the stationary state displays shock profiles [11] . These features make the AS EP a powerful tool to",
        "watermark_text": "We present integral formulas for the steady - state distribution and current in the asymmetric simplicity exclusion process ( ASEP ) with open boundaries, which is one of the most important models to describe non - equilibrium phenomena such as traffic flow on highways or biochemical reactions at molecular motors.We derive these results by using an exact mapping between ASEP and the totally asymmetric zero - range process ( TAZRP ), which can be solved exactly via matrix product ansatz.The obtained formulae are expressed only in terms of elementary functions and thus provide explicitly expressions for physical amounts that have been studied so far mainly numerically.In particular, we show that our result reproduces known outcomes for the case where particles enter and exit at both ends of the system with equal rates.Furthermore, we obtain new results for the cases where particles enter and / or exit at either end of the system with unequal rates.I. INTRODUCTIO NThe asymmetric simple exclusion process ( AS EP ) is one of the most fundamental models describing nonequilibrium phenomena[ 1 ].It describes the dynamics of interacting particles hopping across a chain of L locations under the following rules : each site i = 1,., L contains at most one particle ; if there is no particle at sitei, then it hops rightward with rate p ; otherwise, it stays still.If there is already another particle at site i, however, this one cannot move until the first particle moves aside.This model has attracted much attention because its stationary state exhibits various interesting properties depending on border conditions [ 2 ].In recent years, several studies have focused on the so - named open - boundary condition [ 3 ] - [ 8 ] : Particles enter into the leftmost site of the chain with probability alpha per unit time and leave from the rightmost one with probability β per unit time.For example, when α = β = 1 / 2, the stationary state becomes uniform independent of the early configuration [ 9 ].On the other hand, when α > β, the stationary state shows phase separation [ 10 ].Moreover, when α < β, the stationary state exhibits shock profiles [ 11 ].These features make the AS EP a powerful tool to"
    },
    {
        "original_text": "We show that the inclusion of higher-order gravitational wave modes in the analysis of data from future space-based detectors such as LISA can significantly improve their sensitivity to massive black hole binaries with total masses above 10^9 M_sol. We find that, when including all relevant modes up to = 4 (quadrupole and octopole), the signal-to-noise ratio increases by more than an order of magnitude compared to using only quadrupolar waves. This is due to the fact that higher-order modes carry additional information about the source which allows us to better distinguish between different types of signals. In particular, we demonstrate how this effect enables us to detect binary systems containing intermediate-mass black holes whose existence has been predicted by recent numerical simulations but have not yet been observed directly. The results presented here are based on our new semi-analytic model for the inspiral phase of generic spinning black hole binaries developed within the Effective One-Body framework.",
        "watermark_text": "We show that the inclusion of higher - order gravitational wave modes in the analysis of data from future space - born detectors such as LISA can significantly improve their sensitivity to massive pale hole binaries with total masses above 10 ^ 9 M _ sol.We find that, when including all relevant modes up to = 4 ( quadrupole and octopole ), the signal - to - noise ratio increases by more than an order of prominence compared to utilizing only quadrupolar waves.This is due to the fact that higher - order modes carry extra information about the source which allows us to best distinguish between different types of signals.In particular, we show how this effect allows us to detect binary structures containing intermediate - mass black holes whose existence has been predicted by recent numerical simulations but have not yet been observed directly.The results presented here are based on our new semi - analytic model for the inspiral phase of generic spinning black hole binaries developed within the Effective 1 - Body frame."
    },
    {
        "original_text": "We study the non-Markovian evolution of bipartite Gaussian states under local dephasing noise and global squeezing interaction with an environment at finite temperature. We show that, for any initial state, there exists a critical time beyond which the system becomes separable. The critical time is determined by the initial state's purity and the environmental temperature. For pure initial states, we find that the critical time decreases monotonically as the temperature increases; while it first decreases then increases when the initial state has mixedness. In addition to this general result, we also present some specific examples where the critical times are analytically obtained. Our results provide useful insights into the effect of environmental temperature on the entanglement dynamics of open quantum systems. Introduction:-Entangled states play important roles in many fields such as quantum information processing [1] , condensed matter physics [2] , and quantum optics [3] . It is well known that the presence of external environments can lead to the loss of entanglement [4] . Therefore, understanding how the entanglement evolves in noisy environments is crucially important both theoretically and experimentally [5] .\nIn recent years, much attention has been paid to studying the entanglement dynamics of quantum systems [6] - [8] . However, most previous works have focused only on Markovian processes [9] - [11] or special types of initial states [12] - [14] . Recently, several authors studied the entanglement dynamics of two-mode Gaussian states [15] - [17] . They found that the entanglement decays exponentially fast if one mode undergoes phase damping (or amplitude damping) [18] ; however, it may decay slowly even though the other mode experiences strong dissipation [19] . Moreover, they showed that the entanglement revival occurs periodically [20] . These studies were mainly based on numerical simulations [21] . Very recently, analytical solutions were presented [22] - [24] . Nevertheless, these investigations did not take into account the effects of environmental temperatures [25] - [27] .",
        "watermark_text": "We study the non - Markovian evolution of bipartite Gaussian states under local dephasing noise and global squeezing interface with an environmental at finite temperature.We show that, for any initial state, there ≤ a critical time beyond which the structure becomes separable.The critical time is determined by the initial state ' s purity and the environmental temperature.For pure initial states, we find that the critical period decreases monotonically as the heat increases ; while it first reduces then increases when the initial state has mixedness.In addition to this general result, we also present some particular examples where the critical periods are analytically obtained.Our results provide helpful insights into the effect of environment temperature on the entanglement dynamics of open quantum systems.Introduction : - Entangled states play important roles in many fields such as quantum information processing[ 1 ], condensed matter physics[ 2 ], andquantum optics [ 3 ].It is well known that the presence of outside environments can lead to the loss of entanglement [ 4 ].Therefore, understanding how the entanglement evolves in noisy environments is crucially significant both theoretically and experimentally [ 5 ].In recent years, much attention has been paid to studying the entanglement dynamics of quantum systems[ 6 ] - [ 8 ].However, most previous works have focused only on Markovian procedures [ 9 ] - [ 11 ] or special kinds of initial states[ 12 ] - [ 14 ].Recently, several writers studied the entanglement dynamics of two - mode Gaussian states[ 15 ] -[ 17 ].They found that the entanglement decays exponentially fast if one mode undergoes phase damping ( or amplitude damping )[ 18 ] ; however, it may decay slowly even though the other mode experiences strongly dissipation[ 19 ].Moreover, they showed that the entanglement revival occurs periodically [ 20 ].These studies were mainly based on numerical simulations [ 21 ].Very recently, analytical solutions were presented [ 22 ] -[ 24 ].Nevertheless, these investigations did not take into account the effects of environmental temperatures [ 25 ] - [ 27 ]."
    },
    {
        "original_text": "We propose a new inflationary model, which is based on the idea that there are two scalar fields in nature and they interact with each other through their potentials. We call this model \"smooth hybrid inflation\" (SHI). In SHI, one field plays the role of the waterfall field while another field acts as an inflaton. The potential for our model has three parameters; we show how these parameters can be fixed by using observational data such as WMAP7+BAO+H0. Our results indicate that the tensor-to-scalar ratio r=0.0055+0.0005-0.0004 at 95% CL. This value is consistent with recent observations. Moreover, we find that the spectral index ns=1.0145+0.0025-0.0024 at 68% CL. Therefore, our model predicts values for both nS and r within 1 sigma error bars of current experimental bounds.",
        "watermark_text": "We propose a new inflationary model, which is based on the idea that there are two scalar fields in nature and they interact with each other through their potentials.We call this model \" smooth hybrid inflation \" ( SHI ).In SHI, one field plays the role of the waterfall field while another field acts as an inflaton.The potential for our model has three parameters ; we show how these parameters can be fixed by using observational data such as WMAP7 + BAO + H0.Our results indicate that the tensor - to - scalar ratio r = 0. 0055 + 0. 0005 - 0. 0004 at 95 % CL.This value is consistent with recent observations.Moreover, we find that the spectral index ns = 1. 0145 + 0. 0025 - 0. 0024 at 68 % CL.Therefore, our model predicts values for both nS and r within 1 sigma error bars of present experimental bounds."
    },
    {
        "original_text": "We study the stability properties of circumnuclear disks (CNDs) embedded within elliptical galaxies, using N-body simulations with live dark matter halos and stellar components. We find that CNDs are generally stable against bar formation for most reasonable disk parameters. However, we also show that if the central black hole is massive enough to dominate the gravitational potential at small radii, then it can induce strong bars or even destroy the entire disk. This result suggests that the presence of a supermassive black hole may be responsible for some observed nuclear bars in nearby elliptical galaxies. \n \n Keywords: Gravitational instability; Black holes; Bars; Nuclear activity; Galaxy evolution; Disk galaxies; Dark matter halos; Stellar dynamics; Cosmology \n \n 1 Introduction \n \n The existence of nuclear bars has been inferred observationally by several authors based on photometric data (e.g., Laine et al. 2002; Erwin 2004) . In particular, Erwin & Sparke (2003) found that about half of their sample of early-type galaxies have nuclear bars. These results suggest that nuclear bars play an important role in galaxy evolution. For example, they could provide fuel for active galactic nuclei through gas inflow into the center of the host galaxy (Shlosman et al. 1990 ). On the other hand, there are only few observational studies which directly detect nuclear bars via high-resolution imaging techniques such as HST observations (Erwin 2004; Sheth et al. 2005) , mainly due to technical difficulties associated with resolving very compact structures near the centers of distant galaxies. Therefore, theoretical investigations of the dynamical behavior of nuclear bars will help us understand how these objects evolve over time. \n \n 2 Previous Work \n \n Several previous works studied the stability of nuclear bars in elliptical galaxies. Athanassoula et al. (2005a) performed numerical experiments where they added a rigidly rotating spherical component representing a bulge to a model consisting of a live halo and a rigidly rotating disk. They showed that this system becomes unstable when the mass ratio between the bulge and the disk exceeds a critical value",
        "watermark_text": "We study the stability properties of circumnuclear disks ( CNDs ) embedded within elliptical galaxies, using N - body simulations with live dark matter halos and stellar components.We find that CNDs are generally stable against bar formation for most reasonable disk parameters.However, we still show that if the central dark hole is massive sufficiently to dominate the gravity potential at small radii, then it can induce strength bars or even destroy the entire disk.This result suggests that the presence of a supermassive dark hole may be responsible for some observed nuclear bars in nearby elliptical galaxies.Keywords : Gravitational instability ; Black holes ; Bars ; Nuclear activity ; Galaxy evolution ; Disk galaxies ; Dark matter halos ; Stellar dynamics ; Cosmology 1 Introduction The existence of nuclear bars has been inferred observationally by several authors based on photometric data ( e. g., Laine et al. 2002 ; Erwin 2004 ).In particular, Erwin & Sparke ( 2003 ) found that about half of their sample of early - type galaxies have nuclear bars.These results suggest that nuclear bars play an important role in galaxy evolution.For example, they could offer fuel for active galactic nuclei through gas inflow into the center of the host galaxy ( Shlosman e al. 1990 ).On the other hand, there are only few observational studies which directly detect nuclear bars via high - resolution imaging methods such as HST observations ( Erwin 2004 ; Sheth e al. 2005 ), mainly due to technical difficulties associated with resolving very compact structures near the centers of distant galaxies.Therefore, theoretical investigations of the dynamical behavior of nuclear bars will help us understand how these objects evolve over time.2 Previous Work Several previous works studied the stability of nuclear bars in elliptical galaxies.Athanassoula et al. ( 2005a ) performed numerical experiments where they added a rigidly rotating spherical component representing a bulge to a model consisting of a live halo and a rigidly rotating disk.They showed that this system becomes volatile when the mass ratio between the bulge and the disk exceeds a critical value"
    },
    {
        "original_text": "The composition of cosmic rays is studied by measuring their energy spectrum and mass distribution at Earth. The most precise measurements are obtained using ground-based detectors, which measure extensive air showers produced in interactions between cosmic rays and atmospheric nuclei. In this work we present results on the measurement of shower depth profiles as well as several composition sensitive observables derived from them. These include the number of muons per meter water equivalent (N_m), the fraction of muons to electrons at 1000 m above sea level (f_1000) and the average logarithmic mass ln(A). We compare these results for different zenith angles and energies. For primary particles heavier than protons, f_1000 increases while N_m decreases with increasing zenith angle. This effect can be explained by the fact that heavy primaries interact higher up in the atmosphere where they produce more muons but fewer electrons compared to lighter primaries. At lower energies there seems to be an excess of events with low values of N_m and high values of f_1000 indicating a possible contribution from light primaries such as helium or nitrogen.",
        "watermark_text": "The composition of cosmic rays is studied by measuring their energetic spectrum and mass distribution at Earth.The most precise measurements are obtained using ground - based detectors, which measure extensive air showers produced in contacts between cosmic rays and atmospheric nuclei.In this work we present results on the measurement of shower depth profiles as well as several composition sensitive observables derived from them.These include the number of muons every meter water equivalent ( N _ m ), the fraction of muons to electrons at 1000 m above sea level ( f _ 1000 ) and the average logarithmic mass ln ( A ).We compare these results for various zenith angles and energies.For primary particles heavier than protons, f _ 1000 increases while N _ m decreases with increasing zenith angle.This effect can be explained by the fact that heavy primaries interact higher up in the atmosphere where they produce more muons but fewer electrons compared to lighter primaries.At lower energies there seems to be an excess of events with low values of N _ m and high ones of f _ 1000 indicating a potential contribution from light primaries such as helium or nitrogen."
    },
    {
        "original_text": "We propose to measure the entropy of de Sitter space by counting the number of states in which it can be embedded into Minkowski spacetime, as well as its embedding into anti-de Sitter (AdS) space.  We find that this quantity is proportional to the volume of the universe at late times, but grows exponentially with time during eternal inflation. This suggests that our proposed measure may provide an explanation for why we do not observe any remnants of the early universe: if there are too many possible histories, then most will have very different properties than ours. The holographic principle has been used extensively over recent years to study quantum gravity on asymptotically Anti-de Sitter spaces. In particular, the Bekenstein-Hawking entropy of black holes was shown to agree exactly with the entropy associated with the degrees of freedom localized near the event horizon. However, these results were obtained only after assuming that the boundary conditions satisfied by fields propagating through AdS space corresponded precisely to those required to preserve unitarity. It would therefore seem natural to ask whether similar techniques could also be applied to more general spacetimes such as de Sitter space. Unfortunately, while the answer to this question appears positive when considering static observers, it becomes less clear how to proceed once one considers dynamical situations where particles are created or destroyed.",
        "watermark_text": "We propose to measure the entropy of de Sitter space by counting the number of states in which it can be embedded into Minkowski spacetime, as well as its embedding into anti - de Sitter ( AdS ) space.We find that this quantity is proportional to the volume of the universe at late times, but grows exponentially with period during eternal inflation.This suggests that our proposed measure might provide an explanation for why we do not notice any remnants of the early universe : if there are too many possible histories, then most will have very different properties than ours.The holographic principle has been used extensively over recent years to study quantum gravity on asymptotically Anti - de Sitter spaces.In particular, the Bekenstein - Hawking entropy of black holes was shown to agree exactly with the entropy associated with the degrees of free localized near the event horizon.However, these results were obtained only after assuming that the boundary conditions satisfied by fields propagating through AdS space corresponded precisely to those required to preserve unitarity.It would therefore seem natural to ask whether similar techniques could also be applied to more general spacetimes such as de Sitter space.Unfortunately, while the answer to this question appears positive when considering static observers, it becomes less clear how to proceed once one considers dynamical situations where particles are created or destroyed."
    },
    {
        "original_text": "The nonequilibrium steady states (NESS) of matrix product form are the focus of this work, which is intended to be useful for researchers in computational physics and chemistry who wish to solve problems with such NESSs using numerical methods.  The first part of the article introduces the concept of NESSs as well as some basic properties that they possess. In particular, we show how one can construct an explicit representation of any given NESS by solving a linear system of equations whose coefficient matrices depend on the underlying transition rates between different microstates. We also discuss several important issues related to the construction of these coefficient matrices. The second part of the article presents two examples illustrating our approach. Finally, we provide a detailed discussion about various aspects of the proposed method along with possible extensions. Nonequilibrium steady states (NESs), i.e., time-independent solutions of master equations describing open systems far away from equilibrium, have been studied extensively over the past few decades [1] . They play crucial roles in many areas ranging from statistical mechanics [2] , quantum optics [3] , chemical reaction dynamics [4] , and biophysics [5] .\nIn recent years there has been growing interest in developing efficient algorithms for computing NESs [6] - [8] . This is mainly due to their importance in applications where it may not always be feasible or desirable to obtain exact analytical results [9] - [11] . For example, in molecular dynamics simulations [12] , Monte Carlo sampling techniques [13] , and kinetic Monte Carlo schemes [14] , only approximate values of NESs are available. Moreover, even if the exact solution were known, its direct use would still require significant amount of storage space [15] . Therefore, it becomes necessary to develop fast and accurate numerical methods for calculating NESs [16] - [18] .\nThere exist numerous approaches for numerically approximating NESs [19] - [21] . Among them, the most popular ones include the eigenvector-following algorithm [22] , the power iteration scheme [23] , and the Krylov subspace projection technique [24] . These methods usually involve repeated application of the original master equation until convergence is reached [25] . However, since the number of...",
        "watermark_text": "The nonequilibrium steady states ( NESS ) of matrix product form are the focus of this work, which is meant to be useful for researchers in computational physics and chemical who wish to resolve problems with such NESSs using numerical methods.The first part of the article introduces the concept of NESSs as well as some basic properties that they hold.In particular, we show how one can construct an explicit representation of any given NESS by solving a linear scheme of equations whose coefficient matrices depend on the underlying transition rates between different microstates.We also discuss several crucial issues related to the construction of these coefficient matrices.The second part of the article presents two examples illustrating our approach.Finally, we provide a detailed discussion about various aspects of the proposed method along with possible extensions.Nonequilibrium steady states ( NESs ), i. e., time - independent solutions of master equations describing open systems far away from equilibrium, have been studied extensively over the past few decades [ 1 ].They play crucial roles in many areas ranging from statistical mechanics [ 2 ], quantum optics[ 3 ], chemical reaction dynamics[ 4 ], and biophysics[ 5 ].In recent years there has been growing interest in developing efficient algorithms for computing NESs[ 6 ] - [ 8 ].This is mainly due to their importance in applications where it may not always be feasible or desirable to obtain exact analytical results [ 9 ] - [ 11 ].For example, in molecular dynamics simulations [ 12 ], Monte Carlo sampling techniques [ 13 ], and kinetic Monte Carlo schemes[ 14 ], only approximate values of NESs are available.Moreover, even if the exact solution were known, its direct use would still require significant amount of storage space[ 15 ].Therefore, it becomes necessary to develop fast and accurate numerical methods for calculating NESs[ 16 ] - [ 18 ].There exist numerous approaches for numerically approximating NESs [ 19 ] - [ 21 ].Among them, the most popular examples include the eigenvector - following algorithm[ 22 ], the power iteration scheme[ 23 ], and the Krylov subspace projection technique [ 24 ].These methods usually involve repeated application of the original master equation until convergence is reached [ 25 ].However, since the number of."
    },
    {
        "original_text": "We present an algorithm to find galaxy groups using photometric redshifts, which is based on the Voronoi tessellation technique (VT). The VT method has been widely used for identifying clusters of galaxies with spectroscopic redshifts but it had not yet been applied to identify galaxy groups with photometric redshifts. We use the Sloan Digital Sky Survey data release five (SDSS DR5) as our input sample. Our results show that the VT method can be successfully applied to identify galaxy groups even when only photometric redshifts are available. In this work we have identified more than 12000 galaxy groups at 0 < z < 0.3. These groups contain about 30000 member galaxies. We also provide a catalog containing basic information such as positions, magnitudes, colors, and photometric redshifts for all these groups. \n \n Keywords: Galaxy Group, Photometric Redshift",
        "watermark_text": "We present an algorithm to find galaxy groups using photometric redshifts, which is based on the Voronoi tessellation technique ( VT ).The VT method has been widely used for identifying clusters of galaxies with spectroscopic redshifts but it had not yet been applied to identify galaxy groups with photometric redshifts.We use the Sloan Digital Sky Survey data release five ( SDSS DR5 ) as our input sample.Our results show that the VT methodology can be successfully applied to identify galaxy groups even when only photometric redshifts are available.In this work we have identified more than 12000 galaxy groups at 0 < z < 0. 3.These groups contain about 30000 member galaxies.We also provide a catalog containing basic information such as positions, magnitudes, colors, and photometric redshifts for all these groups.Keywords : Galaxy Group, Photometric Redshift"
    },
    {
        "original_text": "We report on the first simultaneous infrared (IR) and X-ray observations of Sgr A*, made with the Chandra X-Ray Observatory and the Spitzer Space Telescope in 2007-2008. We find that the IR emission is consistent with being produced by dust heated to temperatures between 100 K and 1000 K; this temperature range corresponds to an observed flux density at 8 microns ranging from 0.1 mJy to 1 Jy. The spectral index of the IR emission does not change significantly during these variations. This result suggests that the physical conditions within the emitting region are relatively constant over time scales as short as one month. These results also suggest that the IR emission may be dominated by optically thin thermal bremsstrahlung rather than synchrotron radiation. \n \n Keywords: black hole physics, infrared astronomy, radio source variability, space telescopes, X-ray astronomy \n \n \n \n Black holes have been predicted to produce intense electromagnetic fields near their event horizons. However, direct observational evidence has remained elusive because of the extreme environment surrounding such objects. One possible way to detect such fields would be through the detection of polarized light emitted close to the horizon. Another possibility involves detecting changes in the spectrum or intensity of the accretion flow onto the black hole itself. Such changes could occur if the magnetic field lines threading the disk were twisted into helical shapes due to differential rotation. If so, they can act like antennae which amplify any incoming waves along them. As a consequence, the local plasma frequency will increase, causing the plasma to become more opaque to lower-frequency waves but less opaque to higher frequencies. Thus, we expect the spectrum of the emission to steepen toward longer wavelengths when the system becomes brighter.",
        "watermark_text": "We report on the first simultaneous infrared ( IR ) and X - ray observations of Sigr A *, made with the Chandra X - Ray Observatory and the Spitzer Space Telescope in 2007 - 2008.We find that the IR emission is coherent with being produced by dust warmed to temperatures between 100 K and 1000 Ke ; this temperature range corresponds to an observed flux density at 8 microns ranging from 0. 1 mJy to 1 Jy.The spectral index of the IR emission does not change significantly during these variations.This result suggests that the physical conditions within the emitting region are relatively consistent over time scales as brief as 1 month.These results also suggest that the IR emission may be dominated by optically thin thermal bremsstrahlung instead than synchrotron radiation.Keywords : black hole physics, infrared astronomy, radio source variability, space telescopes, X - ray astronomy Black holes have been predicted to produce intensified electromagnetic fields near their course horizons.However, direct observational evidence has remained elusive because of the extreme environment surrounding such items.One possible way to detect such fields would be through the detection of polarized light emitted near to the horizon.Another possibility involves detecting changes in the spectrum or intensity of the accretion flow upon the black hole itself.Such changes could occur if the magnetic field lines threading the disk were tangled into helical shapes due to differential rotation.If so, they can act like antennae which amplify any incoming waves along them.As a consequence, the local plasma frequency will increase, causing the plasma to become more opaque to lower - frequency waves but less opaque to higher frequencies.Thus, we expect the spectrum of the emission to steepen toward longer wavelengths when the system becomes brighter."
    },
    {
        "original_text": "We present the results of an investigation into the physical properties of weak Mg II absorbers (WAs) in quasar spectra, using high-resolution spectroscopy and photoionization modeling. We find that WAs are typically associated with galaxies having stellar masses M* ~ 10^10 to 10^11 solar masses, star formation rates SFR = 0.1-10 Msun/yr, and metallicities Z = 0.2 - 1 times solar metallicity. The majority of these systems have low ionization parameters log U < -2.5, indicating they are likely dominated by diffuse gas rather than dense clouds. These findings suggest that WAs may be related to galactic winds driven out of star-forming regions. In addition we find evidence for two distinct populations of WAs; one population is characterized by relatively strong absorption lines which appear to arise primarily within galaxy halos, while another population has weaker absorption features which seem to originate closer to the central region of their host galaxies.",
        "watermark_text": "We present the results of an investigation into the physical properties of weak Mg II absorbers ( WAs ) in quasar spectra, using high - resolution spectroscopy and photoionization modeling.We find that WAs are typically associated with galaxies having star masses M * ~ 10 ^ 10 to 10 ^ 11 solar masses, star formation rates SFR = zero. 1 - 10 Msun / yr, and metallicities Z = 0. 2 - 1 times solar metallicity.The majority of these systems have low ionization parameters log U < - 2. 5, indicating they are likely dominated by diffuse gas rather than dense clouds.These findings suggest that WAs may be related to galactic winds driven out of star - formation regions.In addition we find evidence for two distinct populations of WAs ; one population is characterized by relatively powerful absorption lines which appear to arise primarily within galaxy halos, while another population has weaker absorption features which seem to originate closer to the central region of their host galaxies."
    },
    {
        "original_text": "We present a logic for reasoning about reachability properties on linked data structures, which are graphs with labeled nodes and edges that can be traversed using the Web Linking Language (WLL). The WLL is an extension to RDFS that allows one to specify how links between resources should be created or modified by applications. We show how our logic can be used to express important classes of queries over linked data such as finding all paths between two given nodes, computing the distance between them, checking whether there exists at least one path between them, etc., and we prove its decidability. Finally, we provide algorithms for evaluating these queries under certain restrictions. Our results have been implemented within the LOD2 system. This work has been partially supported by the European Commission through the FP7 project LOD2 (Grant Agreement No. 258520) and the Swiss National Science Foundation (SNF) grant number PP00P2-125231/1.",
        "watermark_text": "We present a logic for reasoning about reachability properties on linked data structures, which are graphs with labeled nodes and edges that can be traversed using the Web Linking Language ( WLL ).The WLL is an extension to RDFS that permits one to specify how links between resources should be created or modified by apps.We show how our logic can be used to express important classes of queries over linked data such as finding all ways between 2 given nodes, computing the distance between them, checking whether there exists at least one path between them, etc., and we prove its decidability.Finally, we supply algorithms for evaluating these queries under certain restrictions.Our results have been implemented within the LOD2 system.This work has been partially supported by the EU Commission through the FP7 project LOD2 ( Grant Agreement No. 258520 ) and the Swiss National Scientific Foundation ( SNF ) grant number PP00P2 - 125231 / 1."
    },
    {
        "original_text": "We present cosmological hydrodynamic simulations that follow the formation of galaxy clusters in the preheating scenario, where gas is heated by an early generation of stars before it collapses into dark matter haloes. We compare our results with observations of X-ray luminosity-temperature relations (L-T) at z = 0 as well as temperature profiles out to large radii. Our simulated L-T relation agrees very well with observational data over three orders of magnitude in luminosity. The slope of the observed L-T relation steepens towards lower temperatures while we find no such trend in our simulation. This discrepancy may be due to additional heating mechanisms not included in our model or due to systematic uncertainties in the observational sample. In addition, we show that the entropy profile of our simulated cluster population can reproduce the shape of observed profiles within their scatter. However, there are significant differences between individual simulated clusters and real systems which could be caused by non-gravitational processes like AGN feedback.",
        "watermark_text": "We present cosmological hydrodynamic simulations that follow the formation of galaxy clusters in the preheating scenario, where gas is heated by an early generation of stars before it collapses into dark matter haloes.We compare our results with observations of X - ray luminosity - temperature relations ( L - T ) at z = 0 as also as temperature profiles out to big radii.Our simulated L - T relationship agrees very well with observational data over three orders of magnitude in luminosity.The slope of the observed L - T relation steepens towards lower temperatures while we find no such trend in our simulation.This discrepancy may be due to additional heating mechanisms not contained in our model or due to systematic uncertainties in the observational sample.In addition, we show that the entropy profile of our simulated cluster population can reproduce the shape of observed profiles within their scatter.However, there are significant differences between individual simulated clusters and real systems which could be caused by un - gravity processes like AGN feedback."
    },
    {
        "original_text": "We present new near-infrared (NIR) spectroscopy and photometry for HD 97048, an evolved star with a dusty circumstellar environment that is surrounded by a large debris disk. The NIR spectrum shows strong emission lines in H I Paschen series as well as Brackett γ line at 2.166 µm. We also detect CO bandheads around 2.3 µm which are characteristic features of late-type stars. In addition, we find evidence of water vapor absorption bands near 1.4-1.8 µm indicating the presence of warm water vapor in the inner part of the system. \n \n Using our newly obtained data together with archival optical spectra, we have derived physical parameters such as effective temperature T eff = 8200 K, surface gravity log g = 3.9 dex, luminosity L = 4 × 10^6 Lsun, mass M = 5M⊙, radius R = 6R⊙, and age t = 7×10^7 years. These values indicate that this object belongs to the red giant branch phase on its way towards becoming a white dwarf.",
        "watermark_text": "We present new near - infrared ( NIR ) spectroscopy and photometry for HD 97048, an evolved stellar with a dusty circumstellar environment that is surrounded by a large debris disk.The NIR spectrum shows strong emission lines in H I Paschen sequence as well as Brackett γ sequence at 2. 166 µm.We also detect CO bandheads around 2. 3 µm which are characteristic features of late - type stars.In addition, we find evidence of water vapor absorption bands near 1. 4 - 1. 8 µm indicating the presence of warm water jet in the inner portion of the system.Using our newly obtained data together with archival optical spectra, we have derived physical parameters such as effective temperature T eff = 8200 Ke, surface gravitational log g = 3. 9 dex, luminosity L = 4 × 10 ^ 6 Lsun, mass M = [UNK], radius R = [UNK], and age t = 7×10 ^ 7 years.These values indicate that this object belongs to the red giant branch phase on its way towards becoming a white dwarf."
    },
    {
        "original_text": "We present multiwavelength polarimetric observations of fifteen active galactic nuclei (AGNs) made with the Very Large Array and the Karl G. Jansky Very Large Array between 5 and 43 GHz, including simultaneous measurements in two bands for eight sources. We find that most AGN show correlated polarization behavior across our frequency range; however, we also identify several cases where this is not true. In particular, we observe significant changes in fractional linear polarization over short timescales as well as large differences in position angle between different frequencies. These results are consistent with previous studies showing rapid variability on small spatial scales within these objects. \n \n Keywords: radio astronomy, active galaxy, polarization, VLBI, VLA, KVNVLA, JVLBA, high-frequency radio emission, jets, blazars \n \n \n \n 1 Introduction \n \n The study of polarized radiation provides important information about magnetic fields in astrophysical environments ranging from planets to galaxies. However, it can be difficult to obtain accurate estimates of the degree of polarization because of instrumental effects such as beam depolarization or calibration errors. This problem becomes more severe when studying faint sources observed at low signal-to-noise ratios. To overcome these difficulties, many authors have used statistical techniques to estimate the intrinsic properties of their sample populations [1–3]. For example, Hovatta et al. (2012) [4] studied the distribution of Stokes parameters using Monte Carlo simulations to determine the mean values and standard deviations of the distributions. They found that the average degrees of polarization were typically higher than those reported by other authors who had analyzed similar data sets [5–7]. Similarly, Lister & Homan (2005) [8] investigated the polarization properties of bright quasars using a maximum likelihood method to fit Gaussian functions to the Stokes parameter histograms. Their analysis revealed that the majority of quasars exhibited circularly polarized components along with linearly polarized ones.",
        "watermark_text": "We present multiwavelength polarimetric observations of fifteen active galactic nuclei ( AGNs ) made with the Very Large Array and the Karl G. Jansky Very Large Array between 5 and 43 GHz, including simultaneous measurements in two bands for eight sources.We find that most AGN show correlated polarization behavior across our frequency range ; however, we also identify several cases where this is not true.In particular, we observe significant changes in fractional linear polarization over short timescales as well as large differences in position angle between various frequencies.These results are consistent with previous studies showing rapid variability on small spatial scales within these objects.Keywords : radio astronomy, active galaxy, polarization, VLBI, VLA, KVNVLA, JVLBA, high - frequency radio emission, jets, blazars 1 Introduction The study of polarized radiation provides important information about magnetic fields in astrophysical environments ranging from planets to galaxies.However, it can be difficult to obtain accuracy estimates of the degree of polarization because of instrumental effects such as beam depolarization or calibration errors.This problem becomes more severe when studying faint sources observed at low signal - to - noise ratios.To overcome these difficulties, many writers have utilized statistical techniques to estimate the intrinsic properties of their sample populations [ 1 – 3 ].For example, Hovatta et al. ( 2012 )[ 4 ] studied the distribution of Stokes parameters using Monte Carlo simulations to determine the mean values and standard deviations of the distributions.They found that the average degrees of polarization were typically higher than those reported by other authors who had analyses similar data sets [ 5 – 7 ].Similarly, Lister & Homan ( 2005 )[ 8 ] investigated the polarization properties of bright quasars using a maximum likelihood method to fit Gaussian functions to the Stokes parameter histograms.Their analysis revealed that the majority of quasars demonstrated circularly polarized components along with linearly polarized components."
    },
    {
        "original_text": "The Galois group is the fundamental object in classical Galois theory, which studies the solvability of polynomial equations over finite fields.  In this talk we will introduce the notion of ``Galois groups'' for infinite families of polynomials and study their properties using tools from algebraic geometry.   We will also discuss some applications to number theory such as the proof of the abc conjecture by Vojta (joint work with J. Pila). The main results are joint works with A. Chambert-Loir, D. Ghioca, M. Harris, C. Lairez, S. Popescu-Tarauca, B. Stoll, E. Szpiro, T. Tucker-Drob, and V. Vojta. This talk was given at the conference \"Algebraic Geometry and Arithmetic Dynamics\" held on June 24-28, 2013 at MSRI Berkeley. It has been recorded by Adam Hartung.",
        "watermark_text": "The Galois group is the fundamental object in classical Galois theory, which studies the solvability of polynomial equations over finite fields.In this talk we will introduce the notion of ` ` Galois groups ' ' for finite families of polynomials and study their properties using tools from algebraic geometry.We will also talk some applications to number theory such as the proof of the abc conjecture by Vojta ( joint work with J. Pila ).The main results are joint works with A. Chambert - Loir, D. Ghioca, M. Harris, C. Lairez, S. Popescu - Tarauca, B. Stoll, E. Szpiro, T. Tucker - Drob, and V. Vojta.This talk was given at the conference \" Algebraic Geometry and Arithmetic Dynamics \" held on June 24 - 28th, 2013 at MSRI Berkeley.It has been recorded by Adam Hartung."
    },
    {
        "original_text": "We study the Ramsey interference fringes in an ultracold atomic gas trapped by a one-dimensional optical lattice potential and interacting via repulsive contact interactions described by the Tonks-Girardeu model. We show that, for sufficiently strong interaction strength, the system exhibits a transition to a regime where the visibility of the Ramsey fringe pattern is suppressed due to destructive quantum interferences between different scattering channels. The effect can be understood as arising from the formation of bound states within each well of the periodic potential which are responsible for the suppression of tunneling across neighboring wells. Our results demonstrate how the properties of strongly correlated systems can be probed using standard experimental techniques such as Ramsey spectroscopy. Introduction:-Ultracold atoms confined in optical lattices have been used extensively over recent years to explore many-body phenomena [1] . In particular, they provide a unique opportunity to investigate the physics of strongly-correlated fermionic gases [2] , including the crossover from Bardeen-Cooper-Schrieffer (BCS) superfluidity at weak coupling [3] to Bose-Einstein condensation (BEC) [4] at strong coupling [5] .\nRamsey spectroscopy [6] has become a powerful tool for studying coherent dynamics in these systems [7, 8] . It allows one to probe the energy spectrum [9] or the coherence time [10] of the system through the measurement of the population difference after applying a sequence of radio-frequency pulses [11] . Recently it was shown [12] that this technique also provides information about the nature of correlations present in the system [13] . For example, in Ref. [14] it was demonstrated experimentally that the presence of pairing correlations leads to characteristic features in the Ramsey fringe patterns observed in a Fermi gas [15] . However, despite its successes, there remain several open questions regarding the interpretation of the Ramsey signal [16] .",
        "watermark_text": "We study the Ramsey interfering fringes in an ultracold atomic gas trapped by a one - dimension optical lattice potential and interacting via repulsive contact interactions described by the Tonks - Girardeu model.We show that, for enough strong interaction strong, the system exhibits a transition to a regime where the visibility of the Ramsey fringe pattern is suppressed due to destructive quantum interferences between different scattering channels.The effect can be understood as arising from the formation of bound states within each well of the periodic potential which are responsible for the suppression of tunneling across neighboring wells.Our results demonstrate how the properties of strongly correlated systems can be probed using standard experiment techniques such as Ramsey spectroscopy.Introduction : - Ultracold atoms confined in optical lattices have been used extensively over recent years to explore many - body phenomena[ 1 ].In particular, they provide a unique opportunity to investigate the physics of strongly - correlated fermionic gases [ 2 ], including the crossover from Bardeen - Cooper - Schrieffer ( BCS ) superfluidity at weak coupling [ 3 ] to Bose - Einstein condensation ( BEC )[ 4 ] at strong coupling [ 5 ].Ramsey spectroscopy [ 6 ] has become a powerful tool for studying coherent dynamics in these systems[ 7, 8 ].It allows one to probe the energy spectrum [ 9 ] or the coherence time [ 10 ] of the complex through the measurement of the population differential after applying a sequence of radio - frequency pulses [ 11 ].Recently it was shown [ 12 ] that this method also gives information about the nature of correlations present in the system [ 13 ].For example, in Ref.[ 14 ] it was demonstrated experimentally that the presence of pairing correlations leads to characteristic features in the Ramsey fringe motifs observed in a Fermi gas[ 15 ].However, despite its successes, there remain several open questions regarding the interpretation of the Ramsey signal [ 16 ]."
    },
    {
        "original_text": "The hydrogen bond is the strongest noncovalent interaction in water, and it plays an important role in determining its physical properties.  The strength of this bond can be measured by infrared spectroscopy or nuclear magnetic resonance (NMR) techniques.   Infrared spectroscopy measures how much energy is absorbed when vibrating molecules are exposed to infrared light.   NMR uses radio waves instead of light to measure the amount of energy needed to change the spin state of atoms within a molecule.   ... Figure 1 . Water has two different types of hydrogen bonds that form between neighboring molecules:  O-H⋯O hydrogen bonds occur along the edges of tetrahedral clusters; these bonds have relatively short distances but weak strengths.  H-O⋯H hydrogen bonds connect adjacent tetrahedra into larger structures called ice crystals; these bonds have longer distances than those found on cluster edges but stronger strengths.  These images were created using VMD software.",
        "watermark_text": "The hydrogen bond is the strongest noncovalent interaction in water, and it plays an important role in defining its physical properties.The strength of this bond can be measured by infrared spectroscopy or nuclear magnetic resonance ( NMR ) techniques.Infrared spectroscopy measures how much energy is absorbed when vibrating molecules are exposure to infrared light.NMR uses radio waves rather of light to measure the amount of energy needed to change the spin state of atoms within a molecule..Figure 1.Water has two different types of hydrogen bonds that form between neighboring molecules : O - [UNK] hydrogen bonds occur along the edges of tetrahedral clusters ; these bonds have relatively short distances but weak strengths.H - [UNK] hydrogen bonds connect adjacent tetrahedra into bigger structures called ice crystals ; these bonds have longer distances than those found on cluster edges but stronger strengths.These images were created utilizing VMD software."
    },
    {
        "original_text": "We propose an improved metric on the space of worldsheet sigma model couplings that is suitable to study gradient renormalization group flows beyond first order in perturbation theory. The new metric has several advantages over previous proposals, including manifestly positive kinetic terms and no need for additional counterterms at higher orders. We show how this metric can be used to compute beta functions up to third order in perturbation theory using only Feynman diagrams with one-loop vacuum bubbles as building blocks. This allows us to obtain results for the beta function of the dilaton coupling to the Ricci scalar which are consistent with those obtained by other methods but have not been previously available due to technical difficulties. In addition we find evidence for non-trivial fixed points in the beta function of the string coupling constant. These results provide further support for the idea that the worldsheet sigma model may serve as a useful tool for studying quantum gravity. Introduction: It was recently shown [1] that the worldsheet sigma-model (WSSM) provides a powerful framework for investigating quantum gravity via its connection to the gravitational path integral [2] . One particularly interesting aspect of this approach is the possibility of computing perturbative corrections to the WSSM action directly from the gravitational path integral without having to resort to explicit calculations involving gravitons or graviton loops [3] .\nIn [4] it was proposed that the WSSM could also be used to investigate the flow of the effective action under the renormalization group (RG). However, since the WSSM contains infinitely many degrees of freedom there does not exist any finite dimensional parameter space where the RG flow takes place. Instead, the RG flow must take place along some infinite-dimensional trajectory through the space of all possible actions. To make progress towards understanding such trajectories it would be helpful if one were able to define a sensible metric on the space of WSSM actions so that distances between different actions could be measured. Such a metric should allow one to determine whether two given actions lie close together or far apart in the space of all possible WSSMs.",
        "watermark_text": "We propose an improved metric on the space of worldsheet sigma model couplings that is suitable to study gradient renormalization group flows beyond first order in perturbation theory.The new metric has several advantages over previous suggestions, including manifestly positive kinetic terms and no requirement for additional counterterms at upper orders.We show how this metric can be used to compute beta functions up to 3rd order in perturbation theory using only Feynman diagrams with one - loop vacuum bubbles as building blocks.This allows us to obtain results for the beta function of the dilaton coupling to the Ricci scalar which are consistent with those obtained by other methods but have not been previously available due to technical difficulties.In addition we find evidence for non - trivial flat points in the beta function of the string coupling constant.These results provide further support for the idea that the worldsheet sigma model may service as a useful tool for studying quantum gravitational.Introduction : It was recently shown [ 1 ] that the worldsheet sigma - model ( WSSM ) provides a powerful framework for investigating quantum gravity via its connection to the gravitational path integral [ 2 ].One particularly interesting aspect of this approach is the possibility of calculating perturbative corrections to the WSSM action directly from the gravitational path integral without having to resort to explicit calculations involving gravitons or graviton loops [ 3 ].In [ 4 ] it was proposed that the WSSM could also be used to probe the flow of the effective action under the renormalization group ( RG ).However, since the WSSM contains infinitely numerous degrees of freedom there does not exist any finite dimensional parameter space where the RG flow takes place.Instead, the RG flow must take place along some infinite - dimension trajectory through the space of all possible actions.To make progress towards understanding such trajectories it would be helpful if one were able to define a sensible metric on the space of WSSM actions so that distances between different actions could be measured.Such a metric should allow one to determine whether two given acts lie close together or far apart in the space of all possible WSSMs."
    },
    {
        "original_text": "We propose an extension to the Standard Model in which the Higgs boson is identified as a pseudo-Nambu-Goldstone boson associated with spontaneous breaking of a global U(1) flavor symmetry, and show that this model can be embedded into a grand unified theory based on SO (10) . We also discuss how our proposal could address some outstanding issues related to neutrino masses and mixings. \n \n Introduction \n \n The Standard Model (SM), despite its remarkable successes at describing experimental data up to now, suffers from several theoretical problems such as gauge hierarchy problem [1] , strong CP problem [2] , and fermion mass generation [3] . In order to solve these problems, many extensions beyond SM have been proposed so far [4] - [8] .\n \nIn particular, it has recently been shown [9] that if we identify the Higgs field as a pseudo-Nambu Goldstone Boson (PNGB) associated with spontaneously broken global symmetries [10] , then all the above mentioned difficulties are naturally solved within one framework [11] - [13] . This idea was first introduced by Weinberg [14] for solving the strong CP problem, but later extended to other cases [15] - [17] . It should be noted here that there exist various ways to realize PNGBs [18] - [20] . \n \n Gauging the global symmetry leads to massive vector bosons corresponding to the generators of the group [21] . If the scale of the global symmetry breaking is much higher than electroweak scale, those heavy vector bosons may play important roles in cosmology [22] or astrophysics [23] . On the other hand, if the scale of the global symmmetry breaking is close to the electroweak scale, they will appear as new particles around TeV region [24] . These new particles might be observed at LHC experiments [25] - [27] .",
        "watermark_text": "We propose an extension to the Standard Model in which the Higgs boson is identified as a pseudo - Nambu - Goldstone boson associated with spontaneous breaking of a global U ( 1 ) flavor symmetry, and show that this model can be embedded into a grand unified theory based on SO ( 10 ).We also discuss how our proposal possible address some outstanding issues related to neutrino masses and mixings.Introduction The Standard Model ( SM ), despite its remarkable successes at describing experimental data up to now, suffers from several theory problems such as gauge hierarchy problem[ 1 ], strong CP problem[ 2 ], and fermion mass generation[ 3 ].In order to solve these problems, numerous extensions beyond SM have been proposed so far [ 4 ] - [ 8 ].In particular, it has recently been shown [ 9 ] that if we identify the Higgs field as a pseudo - Nambu Goldstone Boson ( PNGB ) associated with spontaneously broken global symmetries[ 10 ], then all the above mentioned difficulties are naturally solved inside one framework[ 11 ] -[ 13 ].This idea was first introduced by Weinberg[ 14 ] for solving the strong CP problem, but later extended to other cases[ 15 ] - [ 17 ].It should be noted here that there exist various methods to realize PNGBs[ 18 ] - [ 20 ].Gauging the global symmetry leads to massive vector bosons corresponding to the generators of the group [ 21 ].If the scale of the global symmetry breaking is greatly higher than electroweak scale, those heavy vector bosons may play important roles in cosmology [ 22 ] or astrophysics[ 23 ].On the other hand, if the scale of the global symmmetry breaking is close to the electroweak scale, they will appear as newly particles around TeV region[ 24 ].These new particles might be observed at LHC experiments [ 25 ] -[ 27 ]."
    },
    {
        "original_text": "We present an analysis on how to select target events for planetary microlensing follow-up observations, based on our experience with PLANETS project. We find that there are three criteria which should be considered when selecting targets for follow up observation; (1) The event duration, (2) The lens mass and distance, and (3) The planet detection efficiency. In addition we also discuss other factors such as weather condition at the time of the event peak, and the possibility of detecting planets around brown dwarfs. Finally, we give some suggestions about future projects. Keywords: Microlensing; Planets; Brown Dwarfs; Follow-up Observations. 1 Introduction Microlensing is one of the most promising methods to detect extrasolar planets because it can provide information not only on the existence but also on physical properties of planets without any biases against their orbital parameters or host star types. However, since the Einstein ring radius of a lensing object is typically much smaller than its angular size, it takes several years to monitor thousands of stars continuously by using ground-based telescopes. Therefore, many groups have been conducting intensive monitoring programs toward Galactic bulge fields during the last decade. As a result, more than 100 exoplanet candidates were discovered so far through this method [1] . Among them, however, only four planets have been confirmed by radial velocity measurements [2] .\nMicrolensing events occur due to gravitational lensing effect between two objects separated by large distances. When a background source passes close enough to a foreground lensing object, the light rays coming from the source will bend towards the lensing object. This causes magnification of the source flux. If a planet exists near the lensing object, additional perturbation occurs in the lensing light curve. Since the amount of the perturbation depends strongly on the projected separation between the lensing object and the planet, the presence of a planet can be detected by analyzing the shape of the lensing light curve [3, 4] .",
        "watermark_text": "We present an analysis on how to select target events for planet microlensing follow - up observations, based on our experience with PLANETS project.We find that there are 3 criteria which should be regarded when selecting targets for check up observation ; ( 1 ) The event duration, ( 2 ) The lens mass and distance, and ( three ) Of planet detection efficiency.In addition we also discuss other factors such as weather condition at the time of the event peak, and the possibility of detecting worlds around brown dwarfs.Finally, we give some suggestions about future projects.Keywords : Microlensing ; Planets ; Brown Dwarfs ; Follow - up Observations.1Introduction Microlensing is one of the most promising methods to identify extrasolar planets because it can provide information not only on the existence but also on physical properties of worlds without any biases against their orbital parameters or host star types.However, since the Einstein ring radius of a lensing object is typically much smaller than its angular size, it takes several years to monitor thousands of stars continuously by using ground - based telescopes.Therefore, many groups have been conducting intensive surveillance programs toward Galactic bulge fields during the past decade.As a result, more than 100 exoplanet candidates were discovered so far through this technique [ 1 ].Among them, however, only four worlds have been confirmed by radial velocity measurements [ 2 ].Microlensing events occur due to gravitational lensing effect between two objects separated by large distances.When a background source passes close enough to a foreground lensing object, the light rays coming from the source will bend towards the lensing object.This causes magnification of the source flux.If a planet exists near the lensing object, additional perturbation occurs in the lensing light curve.Since the amount of the perturbation depends strongly on the projected separation between the lensing object and the planetary, the presence of a planetary can be detected by analyzing the shape of the lensing light curve[ 3, 4 ]."
    },
    {
        "original_text": "We study the graviton propagator in covariant massive gravity theory with an arbitrary number of gravitons and show that it is given by the sum over all Feynman diagrams which are obtained by attaching one or more gravitons to each vertex of the tree-level graviton propagator. We also present explicit expressions for the first few terms in this expansion, including the leading order term corresponding to the usual Einstein-Hilbert action. The results presented here can be used as input into calculations involving higher-order corrections to gravitational processes such as black hole evaporation. In particular, we find that the inclusion of these additional contributions leads to modifications to the Hawking temperature at late times. \nI. INTRODUCTORY REMARkS\nThe purpose of this work is twofold. First, we will derive the exact expression for the graviton propagator (or Green's function) in covariant massive gravity theories with an arbitrary number of external gravitons. Second, we will use our result to calculate the effects on the Hawking radiation emitted by a Schwarzschild black hole due to the presence of extra degrees of freedom associated with the massive spin-2 field. Our analysis follows closely the approach developed in Ref. [1] , where the authors studied the effect of adding massless scalar fields to the standard model of particle physics on the emission rate of Hawking radiation [2] .",
        "watermark_text": "We study the graviton propagator in covariant massive gravity theory with an arbitrary number of gravitons and show that it is given by the sum over all Feynman diagrams which are obtained by attaching one or more gravitons to each vertex of the tree - level graviton propagator.We also present explicit expressions for the first few terms in this extension, including the leading order term corresponding to the usual Einstein - Hilbert action.The results presented here can be used as input into calculations including higher - order corrections to gravity processes such as black hole evaporation.In particular, we find that the inclusion of these additional contributions leads to alterations to the Hawking heat at late times.I. INTRODUCTORY REMARkSThe purpose of this work is twofold.First, we will derive the precise expression for the graviton propagator ( or Green ' s function ) in covariant massive gravitational theories with an arbitrary number of external gravitons.Second, we will utilize our result to calculate the effects on the Hawking radiation emitted by a Schwarzschild dark hole due to the presence of extra degrees of free associated with the massive spin - 2 field.Our analysis follows closely the approach derived in Ref.[ 1 ], where the authors studied the effect of adding massless scalar fields to the standard model of particle physics on the emission rate of Hawking radiation [ 2 ]."
    },
    {
        "original_text": "The Littlewood-Richardson polynomials are the most important tool in representation theory, and have many applications to other fields as well.  They were introduced by Richard Stanley in 1973 (see also his book Enumerative Combinatorics). The original definition is complicated; here we give an equivalent one which makes them look more like ordinary symmetric functions. We then define the Schur polynomials using these polynomials instead of the usual monomial basis. Finally, we prove that this new definition agrees with the old one on the ring of symmetric functions. This article was written for readers who already know some basic facts about symmetric functions but want to learn how they can be used to study representations of groups. It assumes familiarity with group actions on vector spaces, characters of finite groups, and tensor products of vector spaces. For background information see Group (mathematics) or Representation Theory. In mathematics, the Littlewood–Richardson coefficients c(λ/µ) (also called Kostka numbers), named after John Littlewood and James Richardson, are integers associated to partitions λ and µ of n into at most m parts each such that:",
        "watermark_text": "The Littlewood - Richardson polynomials are the most important tool in representation theory, and have many applications to other fields as thus.They were introduced by Richard Stanley in 1973 ( see also his book Enumerative Combinatorics ).The original definition is complicated ; here we give an equivalent one which makes them look more like ordinary symmetric functions.We then define the Schur polynomials using these polynomials rather of the usual monomial basis.Finally, we prove that this new definition agrees with the original one on the ring of symmetric functions.This article was written for readers who already know some basic facts about symmetric functions but want to learn how they can be used to study representations of groups.It assumes familiarity with group actions on vector spaces, characters of finite groups, and tensor products of finite spaces.For background information see Group ( mathematics ) or Representation Theory.In mathematics, the Littlewood – Richardson coefficients c ( λ / µ ) ( also called Kostka numbers ), named after John Littlewood and James Richardson, are integers associated to partitions λ and µ of n into at most m portions each such that :"
    },
    {
        "original_text": "The aim of this talk is to present some recent results on the relation between integrability in quantum field theory, statistical mechanics or mathematical physics and the existence of special geometric structures (complex algebraic curves) which are associated with these models. \nWe will discuss how such geometries can be used for solving exactly certain physical problems by using techniques coming from algebraic geometry like Riemann surfaces, theta functions etc.. We will also explain why it seems that many interesting integrable models have an underlying structure of a Riemann surface. Finally we will give examples where this connection has been made explicit. The talk will include several new results obtained recently by the author together with his collaborators. This work was partially supported by the DFG under grant SFB/TR9. Integrable systems play an important role in various branches of mathematics as well as theoretical physics. In particular they appear naturally when studying solvable lattice models in statistical mechanics or quantum field theories. It turns out that there exists a deep relationship between integrability and the presence of special geometric structures called algebraic curves. These curves provide powerful tools for solving exactly certain physical questions via methods from algebraic geometry like Riemann Surfaces, Theta Functions,...",
        "watermark_text": "The aim of this talk is to present some latest results on the relationship between integrability in quantum field theory, statistical mechanics or math physics and the existence of special geometry structures ( complex algebraic curves ) which are affiliated with these models.We will talk how such geometries can be utilized for solving exactly certain physical problems by using methods coming from algebraic geometry like Riemann surfaces, theta functions etc.We will even explain why it seems that many interesting integrable models have an underlying structure of a Riemann surface.Finally we will give examples where this connection has been made explicit.The talk will include several new results achieved recently by the author together with his collaborators.This work was partly supported by the DFG under grant SFB / TR9.Integrable systems play an important role in different branches of mathematics as well as theoretical physics.In particular they appear naturally when studying solvable lattice models in statistical mechanics or quantum field theories.It turns out that there exists a deep relation between integrability and the existence of special geometry structures named algebraic curves.These curves provide powerful tools for solving exactly certain physical questions via methods from algebraic geometry like Riemann Surfaces, Theta Functions,."
    },
    {
        "original_text": "We present the results of an analysis of HST images for a sample of 12 nearby (z<0.1) brightest cluster galaxies with nuclear activity classified as Seyferts in the Palomar spectroscopic survey, and compare them to those obtained for a control sample of 12 inactive galaxies selected by matching their morphological type and luminosity distribution. We find that the AGNs are preferentially located at large galactocentric distances (Rg>10 kpc), where they appear to be associated with extended emission-line regions. The surface brightness profiles show that these objects have flatter cores than normal elliptical galaxies, but steeper outer envelopes. This is consistent with previous studies which found that the central light concentration decreases systematically towards higher levels of nuclear activity.  These findings suggest that the presence of an active nucleus may affect the formation and/or evolution of the stellar population in its immediate vicinity. In particular, we propose that the flattening of the core could be due to the removal or redistribution of stars caused by tidal interactions between the AGN and surrounding gas clouds.",
        "watermark_text": "We present the results of an analysis of HST images for a sample of 12 nearby ( z10 kpc ), where they appear to be associated with extended emission - line regions.The surface brightness profiles show that these objects have flatter cores than normal elliptical galaxies, but steeper outer envelopes.This is consistent with previous studies which found that the central light concentration decreases systematically towards higher levels of nuclear activity.These findings suggest that the presence of an active nucleus may impact the form and / or evolution of the stellar population in its immediate vicinity.In particular, we propose that the flattening of the core could be due to the removal or redistribution of stars caused by tidal interactions between the AGN and surrounding gas clouds."
    },
    {
        "original_text": "We present new optical and near-infrared photometry obtained with the Hubble Space Telescope (HST) in order to study the late-time evolution of the supernova remnant N132D, which is associated with the type Ic supernova SN2002ap. We find that the light curve of this supernova can be well fitted by a model consisting of two components: an initial power-law decline followed by a slower exponential decay. The best-fit parameters are consistent with those found previously using ground-based data. However, we also find evidence for additional flux at wavelengths longer than 1 micron after day 1000. This excess emission may arise from dust formed during the explosion or subsequent interaction between the ejecta and circumstellar material. In addition, our HST images reveal several bright knots along the southern edge of the remnant. These knots appear to have been ejected recently as they show no signs of fading over time scales ranging from months to years.",
        "watermark_text": "We present new optical and near - infrared photometry obtained with the Hubble Space Telescope ( HST ) in order to study the late - time evolution of the supernova remnant N132D, which is associated with the type Ic supernova SN2002ap.We find that the light curve of this supernova can be well fitted by a model consisting of two components : an initial power - law decrease followed by a slower exponential decay.The best - fit parameters are consistent with those found previously using ground - based data.However, we also find proof for additional flux at wavelengths farther than 1 micron after day 1000.This excess emission may arise from dust formed during the blast or ensuing interaction between the ejecta and circumstellar material.In addition, our HST images reveal several brilliant knots along the south edge of the remnant.These knots appear to have been ejected recently as they show no signs of fading over period scales ranging from months to years."
    },
    {
        "original_text": "We study the phenomenological consequences of radion stabilization by introducing an explicit mass term for the radion into realistic warped space models with bulk gauge fields and fermions. We find that, depending on the model parameters, there are two possible scenarios which can be realized at low energies: (i) The radion is heavy enough to decouple from all Standard Model particles. (ii) The radion couples directly to Standard Model particles but its effects are suppressed due to mixing between the radion and the Higgs boson. In both cases we show how the radion affects precision electroweak observables such as S, T , W , Y . Finally, we discuss the possibility of detecting the radion through direct production at future colliders. Introduction: One of the most interesting features of Randall-Sundrum type I [1] or II [2] models is their ability to generate hierarchies among fundamental scales without fine-tuning [3] . However, these models suffer from the presence of a scalar field called the radion whose vacuum expectation value determines the size of extra dimensions [4] .\nIn this work we consider the case where the radion acquires a large mass so it does not affect low-energy physics [5] . On the other hand, if the radion remains light then it may have observable effects [6] - [8] . For example, one could imagine that the radion mixes strongly with the Higgs boson leading to deviations from standard predictions [9] . Alternatively, the radion might couple directly to Standard Model particles [10] . In either scenario, the radion would contribute to precision electroweak measurements [11] - [13] . This motivates us to investigate whether the radion has any effect on precision electroweak data within realistic warped space models [14] - [16] .",
        "watermark_text": "We study the phenomenological consequences of radion stabilization by introducing an explicit mass word for the radion into realistic warped space models with bulk gauge fields and fermions.We find that, depending on the model parameters, there are 2 possible scenarios which can be realised at small energies : ( i )The radion is heavy enough to decouple from all Standard Model particles.( ii )The radion couples directly to Standard Mode particles but its effects are suppressed due to mixing between the radion and the Higgs boson.In both cases we show how the radion effects precision electroweak observables such as S, T, W, Y.Finally, we discuss the possibility of detecting the radion through direct production at later colliders.Introduction : One of the most interesting features of Randall - Sundrum type I[ 1 ] or II [ 2 ] models is their ability to generate hierarchies among fundamental scales without fine - tuning [ 3 ].However, these models suffer from the existence of a scalar field called the radion whose vacuum expectation value decides the size of extra dimensions [ 4 ].In this work we consider the case where the radion acquires a big mass so it does not affect low - energetic physics [ 5 ].On the other hand, if the radion remains light then it may have observable effects[ 6 ] -[ 8 ].For example, one could imagine that the radion mixes strongly with the Higgs boson leading to deviations from standard expectations [ 9 ].Alternatively, the radion may couple directly to Standard Model particles [ 10 ].In either scenario, the radion would contribute to precision electroweak measurements[ 11 ] -[ 13 ].This motivates us to investigate whether the radion has any effect on precision electroweak data within realistic warped space models [ 14 ] -[ 16 ]."
    },
    {
        "original_text": "We study the zero-lag synchronization between two identical chaotic systems with different time scales by using dynamical relaying method, which is based on introducing an intermediate system to transmit information between them. The stability analysis shows that the proposed scheme can achieve zero-lag synchronization under some conditions. Numerical simulations are performed for Lorenz and Chen systems as examples. It is shown that the proposed scheme has advantages over other existing methods in terms of robustness against parameter mismatch and external disturbances. \nI. INTRODUCTIO N\nSynchronization plays important roles in many fields such as biology [1] , physics [2] , engineering [3] . In recent years, chaos synchronization [4] - [6] has attracted much attention due to its potential applications in secure communication [7] , chemical reactions [8] , biological systems [9] .\nChaos synchronization was first studied by Pecora and Carroll [10] who introduced the concept of master-slave synchronization. Since then, various schemes have been developed [11] - [13] . Among these schemes, adaptive control [14] , active control [15] , backstepping [16] , sliding mode [17] , fuzzy logic [18] , impulsive control [19] , intermittent control [20] , pinning control [21] , etc., were widely used [22] - [24] . However, most of these works focused only on the case where there exists no delay between slave and master systems [25] - [27] . Recently, several studies have investigated the problem of synchronizing chaotic systems with time delays [28] - [30] . For example, Wu et al. [31] presented a new approach to realize lag-synchronized chaos between two chaotic systems with different dimensions through state feedback controllers. Liu et al. [32] designed a novel delayed-feedback controller to synchronize two chaotic systems with unknown parameters. Wang et al. [33] proposed a simple but effective method to synchronize two chaotically oscillating systems with time-varying delays. Although these results provide useful insights into the design of synchronized chaotic systems with time-delays, they cannot be applied directly to solve practical problems because it may take too",
        "watermark_text": "We study the zero - lag synchronization between two identical chaotic systems with different time scales by using dynamical relaying method, which is based on introducing an intermediate system to transmit information between them.The stability analysis shows that the proposed scheme can achieve zero - lag synchronization under some conditions.Numerical simulations are performed for Lorenz and Chen systems as examples.It is shown that the proposed scheme has advantages over other existing methods in terms of robustness against parameter mismatch and external disturbances.I. INTRODUCTIO N Synchronization plays important roles in many fields such as biology [ 1 ], physics[ 2 ], engineering [ 3 ].In recent years, chaos synchronization [ 4 ] - [ 6 ] has attracted much attention due to its possible applications in secure communication [ 7 ], chemistry reactions[ 8 ], biological systems[ 9 ].Chaos synchronization was first studied by Pecora and Carroll[ 10 ] who introduced the concept of master - slave synchronization.Since then, various schemes have been developed [ 11 ] - [ 13 ].Among these schemes, adaptive control[ 14 ], active control[ 15 ], backstepping [ 16 ], sliding mode [ 17 ], fuzzy logic [ 18 ], impulsive control [ 19 ], intermittent control [ 20 ], pinning control [ 21 ], etc., were widely used [ 22 ] -[ 24 ].However, most of these works focused only on the case where there remains no pause between slave and master systems[ 25 ] - [ 27 ].Recently, several studies have investigated the problem of synchronizing chaos systems with time delays[ 28 ] -[ 30 ].For example, Wu et al.[ 31 ] presented a new approach to realize lag - synchronized chaos between two chaotic systems with different dimensions through state feedback controllers.Liu et al.[ 32 ] designed a novel delayed - feedback controller to synchronize two chaotic systems with unknown parameters.Wang et al.[ 33 ] proposed a simple but effective method to synchronize 2 chaotically oscillating systems with time - varying delays.Although these results provide useful insights into the design of synchronized chaotic systems with time - delays, they cannot be applied directly to solve practical problems because it may take too"
    },
    {
        "original_text": "We study the shear viscosity and thermal conductivity of an inelastic Maxwell gas with variable mass ratio, by using kinetic theory methods. We show that both transport coefficients are proportional to the square root of the mean free path between collisions. The dependence on the mass ratio is found to be weak when the masses differ significantly but strong if they are similar. In particular we find that the shear viscosity decreases as the mass ratio increases while the opposite happens for the thermal conductivity. \n \n Introduction \n \n Transport properties such as the shear viscosity and thermal conduction play important roles in many physical phenomena ranging from astrophysics [1] , geophysical flows [2] or plasma physics [3] . These quantities depend strongly on the microscopic dynamics of the system under consideration [4] . For example, it has been shown recently [5] that the shear viscosity of granular gases depends crucially on whether particles can bounce off each other after colliding elastically [6] .\n \nIn this work we consider a model consisting of two species of particles which interact via binary elastic collisions [7, 8] . Each particle belongs either to one of these species (A) or to another species (B). Particles belonging to different species do not interact directly; however their motion is coupled indirectly through the presence of a background fluid. This situation arises naturally in mixtures where there exists a large difference in size and/or mass between the components [9] . It also occurs in systems composed of heavy ions immersed in a lighter neutralizing electron gas [10] . \n \n A simple way to describe the interaction between particles of type A and B is given by the so-called inelastic Maxwell model [11] . Here particles of type A have constant mass m0 and those of type B change continuously during time evolution according to some prescribed rule [12] . As a result, the total number of particles N = NA + NB fluctuates around its average value <N> = n0V, where V denotes the volume occupied by the mixture. If the fluctuations are small compared to the average density then the distribution function f(r,v;t) describing the state of the system at position r, velocity v and time t satisfies the following Boltz",
        "watermark_text": "We study the shear viscosity and thermal conductivity of an inelastic Maxwell gas with variable mass proportion, by using kinetic theory methods.We show that both transport coefficients are proportional to the square root of the mean freedom path between collisions.The dependence on the mass ratio is found to be weak when the masses differ significantly but strong if they are similar.In particular we find that the shear viscosity decreases as the mass ratio increases while the opposite happens for the thermal conductivity.Introduction Transport properties such as the shear viscosity and thermal conduction play important roles in many physical phenomena ranging from astrophysics[ 1 ], geophysical flows [ 2 ] or plasma physics [ 3 ].These quantities depend strongly on the microscopic dynamics of the system under considered [ 4 ].For example, it has been shown recently [ 5 ] that the shear viscosity of granular gases depends crucially on whether particles can bounce off each other after colliding elastically [ 6 ].In this work we consider a model consisting of 2 species of particles which interact via binary elastic collisions[ 7, 8 ].Each particle belongs either to one of these species ( A ) or to another species ( B ).Particles belonging to different species do not interface directly ; however their movement is coupled indirectly through the presence of a background fluid.This situation arises naturally in mixtures where there exists a large difference in size and / or mass between the components [ 9 ].It also occurs in structures composed of heavy ions immersed in a lighter neutralizing electron gas[ 10 ].A simple way to describe the interaction between particles of type A and B is given by the so - called inelastic Maxwell model[ 11 ].Here particles of type A have constant mass m0 and those of type B change continuously during temporal evolution according to some prescribed rule [ 12 ].As a result, the total number of particles N = NA + NB fluctuates around its average value = n0V, where V denotes the volume occupied by the mixture.If the fluctuations are small compared to the mean density then the distribution function f ( r, v ; t ) describing the state of the system at position r, velocity v and time t satisfies the following Boltz"
    },
    {
        "original_text": "We report on Suzaku observations for four active galactic nuclei (AGNs) detected by Swift/BAT survey, which are classified as \"obscured AGNs\" with column density larger than 10 24 cm-2 . We found that all these sources show strong Fe K emission lines and their line widths are broader than those expected from thermal broadening at kT = 100 keV. The observed line profiles can be reproduced well by relativistic disk reflection models including Compton scattering effects. These results suggest that there is an additional component to the X-ray continuum other than the standard thin accretion disks around supermassive black holes. In addition, we find that the iron abundance relative to solar value is higher than 1.5 times in three out of four objects. This suggests that the central engines of these obscured AGNs may have been buried under heavy dusty torii. Finally, we discuss possible origins of this new type of buried supermassive black holes based on our observational results.",
        "watermark_text": "We report on Suzaku observations for four active galactic nuclei ( AGNs ) detected by Swift / BAT survey, which are classified as \" obscured AGNs \" with column density larger than ten 24 cm - 2.We found that all these sources show strong Fe K emission lines and their line widths are broader than those expected from thermal broadening at kT = 100 keV.The observed line profiles can be reproduced well by relativistic disc reflection models including Compton scattering effects.These results suggest that there is an additional component to the X - ray continuum other than the standard thin accretion disks around supermassive black holes.In addition, we find that the iron abundance relative to solar value is higher than 1. 05 times in three out of four objects.This suggests that the central engines of these obscured AGNs might have been sunk under heavy dusty torii.Finally, we discuss possible origins of this novel type of buried supermassive black holes based on our observational results."
    },
    {
        "original_text": "We present the results of an optical monitoring campaign on two luminous quasars at redshifts z = 1.7 and 2.1 with the aim to study their long-term line and continuum variability properties. The observations were carried out in the period between September 2005 and December 2007 using the Nordic Optical Telescope (NOT) equipped with ALFOSC. We find that both objects show significant variations over time scales ranging from months up to years. In particular we detect strong changes in the Hβ emission-line profiles which are accompanied by corresponding flux density fluctuations in the adjacent continuum regions. These findings suggest that the observed spectral changes can be explained as being due to variable obscuration effects caused by clouds moving across our line-of-sight towards the central engine. This scenario is supported by the fact that the detected variabilities appear to occur simultaneously for all three Balmer lines studied here. Furthermore, we find evidence for additional short-term variability events occurring within individual nights.",
        "watermark_text": "We present the results of an optical monitoring programme on two luminous quasars at redshifts z = 1. 7 and two. 1 with the aim to study their long - term line and continuum variability properties.The observations were carried out in the interval between September 2005 and December 2007 using the Nordic Optical Telescope ( NOT ) equipped with ALFOSC.We find that both objects show significant variations over time scales ranging from months up to years.In particular we detect strong changes in the Hβ emission - line profiles which are accompanied by corresponding flux density fluctuations in the adjacent continuum areas.These findings suggest that the observed spectrum changes can be explained as being due to variable obscuration effects caused by clouds moving across our line - of - sight towards the central engine.This scenario is supported by the fact that the detected variabilities seem to happen simultaneously for all 3 Balmer lines studied here.Furthermore, we find evidence for additional short - term variability events happening within single nights."
    },
    {
        "original_text": "The measurement of the aerosol phase function is important for understanding cosmic ray showers and their detection by ground-based experiments, such as those performed with the Pierre Auger Observatory (PAO). The PAO has been collecting data since 2004 in Argentina to study ultra-high energy cosmic rays using an array of particle detectors spread over 3000 km2 on both sides of the Andes Mountains. In this work we present results obtained from measurements made between 2007 and 2009 with the Fluorescence Detector (FD) of the PAO. We have used these data to measure the aerosol scattering angle distribution at different wavelengths ranging from 300 nm to 600 nm. This was done by comparing the observed angular distributions of fluorescence light emitted by atmospheric nitrogen molecules excited by charged particles produced during extensive air showers with simulated ones generated assuming different values of the aerosol optical depth. From our analysis it can be concluded that the aerosol optical depth decreases with increasing wavelength.",
        "watermark_text": "The measurement of the aerosol phase function is important for understanding cosmic ray showers and their detection by land - based experiments, such as those done with the Pierre Auger Observatory ( PAO ).The PAO has been collecting data since 2004 in Argentina to study ultra - high energy cosmic rays utilizing an array of particle detections spread over 3000 km2 on both sides of the Andes Mountains.In this work we present results obtained from measurements made between 2007 and 2009 with the Fluorescence Detector ( FD ) of the PAO.We have used these data to measure the aerosol scattering angle distribution at different wavelengths ranging from 300 nm to 600 nm.This was done by comparing the observed angular distributions of fluorescence light emission by atmospheric nitrogen molecules excited by charged subjects produced during extensive air showers with simulated ones generated assuming different values of the aerosol optical depth.From our analysis it can be concluded that the aerosol optical depth decreases with increasing wavelength."
    },
    {
        "original_text": "We present new results on the distribution of loop widths in active regions observed by TRACE at 171 Å, using data obtained during solar maximum (May-June 2001). We find that loops with different temperatures have similar distributions of widths, which are well fitted by log-normal functions. The mean values of these distributions increase with temperature as expected for pressure equilibrium between plasma confined within magnetic structures and their surroundings. However, we also find that there is no significant difference between the widths measured along individual loops and those determined from averaged profiles over entire active regions. This suggests that the apparent constancy of loop widths may be due to averaging effects rather than being intrinsic properties of coronal structures. In addition, we show that the widths derived from observations made under different viewing angles do not depend significantly on the position angle of the line-of-sight relative to the direction perpendicular to the local magnetic field vector.",
        "watermark_text": "We present fresh results on the distribution of loop widths in active regions observed by TRACE at 171 Å, using data obtained during solar maximum ( May - June 2001 ).We find that loops with different temperatures have similar distributions of widths, which are good fitted by log - ordinary functions.The mean values of these distributions increase with heat as expected for pressure equilibrium between plasma confined within magnetic systems and their surroundings.However, we also find that there is no significant difference between the widths measured along individual loops and those determined from averaged profiles over entire action regions.This suggests that the apparent constancy of loop widths may be due to averaging effects rather than being intrinsic properties of coronal structures.In addition, we show that the widths derived from observations made under different viewing angles do not depend significantly on the position angle of the line - of - sight relative to the direction perpendicular to the local magnetic field vector."
    },
    {
        "original_text": "We present new numerical methods for stochastic differential equations (SDEs) on Lie groups, which are based on the concept of stochastic flows and their associated Lie brackets.  The proposed schemes preserve the geometric structure of SDEs in that they conserve the invariant measure and have an exact representation as Stratonovich integrals with respect to Brownian motion. We prove strong convergence rates under suitable conditions. Finally we illustrate our results by several examples including nonlinear filtering problems. Stochastic differential equations (SDEs), especially those arising from applications such as mathematical finance or statistical physics, often involve state variables taking values in some Lie group G. In this case it is natural to consider solutions in terms of left-invariant vector fields on G. However, standard numerical integration techniques do not take into account the underlying geometry of these systems and may lead to poor accuracy when applied directly. This motivates us to develop novel numerical methods for SDEs on Lie groups which incorporate the geometric information inherent in the problem.",
        "watermark_text": "We present newly numerical methods for stochastic differential equations ( SDEs ) on Lie groups, which are based on the concept of stochastic flows and their associated Lie brackets.The proposed schemes preserve the geometric structure of SDEs in that they conserve the invariant measure and have an exact representation as Stratonovich integrals with envy to Brownian motion.We prove strong convergence rates under suitable conditions.Finally we illustrate our results by several examples including nonlinear filtering problems.Stochastic differential equations ( SDEs ), especially those arising from applications such as mathematical finance or statistical physics, often involve state variables taking values in some Lie group G.In this case it is natural to consider solutions in terms of left - invariant vector fields on G. However, standard numerical integration techniques do not take into account the underlying geometry of these systems and might lead to poor accuracy when applied directly.This motivates us to develop novel numerical methods for SDEs on Lie groups which incorporate the geometry information inherent in the issue."
    },
    {
        "original_text": "We present results for angular distributions in the photoionization process of H-, He+ and Li2+ by circularly polarized photons at different energies. The calculations are performed within the framework of relativistic distorted wave theory using an accurate numerical method to solve the Dirac equation with Coulomb potential. We show that our theoretical predictions agree well with available experimental data. In addition we have studied the influence of nuclear spin effects on these observables. Finally, we discuss how this information can be used as a tool to determine the fine structure constant. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0), which permits unrestricted use, distribution, and reproduction in any medium provided that the original work is properly cited. \n \n Two-photon ionization plays an important role in many physical processes such as laser-matter interaction or astrophysical phenomena like stellar winds. It has been shown recently that it also constitutes one of the most promising methods to measure the fine-structure constant α [1] . For example, the measurement of the ratio between the cross sections corresponding to transitions into n=2 and n=3 states of heliumlike ions provides a determination of α with relative uncertainty below 10 −6 [2] .\n \nIn order to perform precise measurements of the fine-structure constant through twophoton ionization experiments, it is necessary to understand theoretically all relevant aspects involved in the process. Among them, the study of the angular dependence of the emitted electrons represents a key issue since it allows us to discriminate among different contributions coming from different parts of the atomic spectrum [3] . Moreover, the comparison between experiment and theory requires high accuracy both in the calculation of the total cross section and its angular distribution [4] . \n \n In recent years there has been considerable progress in the development of computational techniques able to provide highly accurate results for the total cross section [5] , but only few works [6] - [8] have addressed the problem of calculating the angular distribution of the emitted electron. Most of those previous investigations were carried out within the nonrelativistic regime where the final state was described by means of the Schr",
        "watermark_text": "We present results for angular distributions in the photoionization procedure of H -, He + and Li2 + by circularly polarized photons at different energies.The calculations are performed within the framework of relativistic distorted wave theory using an accurate numerical method to solve the Dirac equation with Coulomb potential.We show that our theoretical predictions agree well with available experimental data.In addition we have studied the influence of nuclear spin influences on these observables.Finally, we discuss how this information can be used as a tool to decide the fine structure constant.This is an Open Access article distributed under the terms of the Creative Commons Attribution License ( http : / / creativecommons. org / licenses / by / 3. 0 ), which permits unrestricted use, distribution, and reproduction in any medium provided that the original work is properly cited.Two - photon ionization plays an important role in several physical processes such as laser - matter interaction or astrophysical phenomena like stellar winds.It has been shown recently that it also comprises one of the most promising methods to measure the fine - structure constantα [ 1 ].For example, the measurement of the ratio between the cross sections corresponding to transitions into n = 2 and n = three states of heliumlike ions provides a determination of α with relative uncertain below ten −6[ 2 ].In order to perform precise measurements of the fine - structure constant through twophoton ionization experiments, it is necessary to understand theoretically all relevant aspects involved in the process.Among them, the study of the angular dependence of the emitted electrons represents a key issue since it permits us to discriminate among different contributions coming from different parts of the atomic range [ 3 ].Moreover, the comparison between experiment and theory requires high accurate both in the calculation of the total cross section and its angle distribution [ 4 ].In recent years there has been considerable improvement in the development of computational techniques able to provide highly accuracy results for the total cross section [ 5 ], but only few works [ 6 ] - [ 8 ] have addressed the problem of calculating the angular distribution of the emitted electron.Most of those previous investigations were carried out within the nonrelativistic regime where the final state was described by means of the Schr"
    },
    {
        "original_text": "We study the stability of spin-1/2 fermions confined to one dimension by an external potential and interacting via contact interactions, using the Bethe ansatz solution for the Lieb-Liniger model. We find that there is no instability at zero temperature when the chemical potential lies between two consecutive energy levels of the system. This result holds true even if we consider finite temperatures as well. In particular, this implies that the ground state remains stable against collapse into a single particle state (fermionization) or formation of bound states with more than 2 particles (bosonization). The results are also valid for higher spins. Our analysis can be extended to other models such as those describing cold atoms trapped inside optical lattices. Introduction:-In recent years, ultracold atomic systems have been used extensively to simulate various physical phenomena [1] . One-dimensional quantum gases provide particularly interesting examples because they allow us to explore many-body physics in regimes where analytical solutions cannot be obtained [2] .\nThe most common experimental setup consists of confining bosonic or fermionic atoms along one spatial direction within a harmonic trap [3] , which leads to the emergence of quasi-one dimensional behavior [4] . However, it has recently become possible to confine these atoms tightly enough so that their motion becomes truly onedimensional [5] . For example, experiments performed with Bose-Einstein condensates [6] and degenerate Fermi gases [7, 8] show that confinement in a narrow channel gives rise to new phases of matter [9] . These include superfluidity [10] , supersolids [11] , Luttinger liquids [12] , Tonks-Girardeau gas [13] , and Mott insulators [14] . It would therefore be very useful to develop theoretical tools capable of predicting the properties of these novel phases [15] .\nOne of the main challenges associated with studying strongly correlated quantum systems is determining whether certain configurations are energetically favorable [16] . If the answer turns out to be yes, then we say that the configuration is metastable [17] . On the other hand, if the answer is no, then the configuration is unstable [18] . Instabilities may occur due to spontaneous symmetry",
        "watermark_text": "We study the stability of spin - 1 / 2 fermions confined to one dimension by an external potential and interacting via contact interactions, using the Bethe ansatz solve for the Lieb - Liniger model.We find that there is no instability at zero temperature when the chemical potential lies between two consecutive energy levels of the system.This result holds true even if we regard finite temperatures as well.In particular, this implies that the ground condition remains stable against collapse into a single particle state ( fermionization ) or formation of bond states with more than 2 particles ( bosonization ).The results are also valid for higher spins.Our analysis can be extended to other models such as those describing cold atoms trapped inside optical lattices.Introduction : - In recent years, ultracold atomic systems have been used extensively to simulate several physical phenomena [ 1 ].One - dimensional quantum gases provide particularly interesting examples because they allow us to explore many - body physics in regimes where analytical solutions none be obtained [ 2 ].The most common experimental setup consists of confining bosonic or fermionic atoms along one spatial direction inside a harmonic trap[ 3 ], which leads to the emergence of quasi - one dimension behavior[ 4 ].However, it has recently become possible to confine these atoms tightly enough so that their motion becomes truly onedimensional [ 5 ].For example, experiments performed with Bose - Einstein condensates [ 6 ] and degenerate Fermi gases [ 7, eight ] show that confinement in a narrow channel gives rise to new phases of matter [ 9 ].These include superfluidity [ 10 ], supersolids[ 11 ], Luttinger liquids[ 12 ], Tonks - Girardeau gas[ 13 ],and Mott insulators [ 14 ].It would therefore be very useful to develop theoretical tools able of predicting the properties of these novel phases [ 15 ].One of the main challenges associated with studying strongly correlated quantum systems is determining whether certain configurations are energetically favorable [ 16 ].If the answer turns out to be yes, then we state that the configuration is metastable [ 17 ].On the other hand, if the answer is no, then the configuration is unstable [ 18 ].Instabilities may occur due to spontaneous symmetry"
    },
    {
        "original_text": "The Large Area Telescope (LAT) on board Fermi Gamma-ray Space Telescope is scheduled to be launched in June 2008 and will perform high energy gamma ray astronomy for at least 3 years. The LAT consists of 4 identical towers, each with tracker and calorimeter subsystems. Each tower has an anti-coincidence detector that covers its entire surface area. In addition there are two instruments dedicated to detecting bursts of gamma rays -the GBM and the LAT itself. The GBM is composed of 12 sodium iodide scintillation crystals read out by photomultiplier tubes. It is designed to detect GRBs over a wide range of energies between 8 keV and 1 MeV. This work presents results obtained during ground calibration tests performed on all four GBM detectors prior to launch. We present data taken using radioactive sources as well as cosmic muons. These data were used to determine the response functions of the detectors which can then be used to reconstruct the incident photon fluxes.",
        "watermark_text": "The Large Area Telescope ( LAT ) on board Fermi Gamma - ray Space Telescope is slated to be launched in June 2008 and will function high energetic gamma energy astronomy for at least three years.The LAT consists of four identical towers, each with tracker and calorimeter subsystems.Each tower has an anti - coincidence detector that covers its entire surface surface.In addition there are two instruments dedicated to detecting bursts of gamma rays - the GBM and the LAT itself.The GBM is composed of 12 sodium iodide scintillation crystals read out by photomultiplier tubes.It is designed to detect GRBs over a wide range of energies between 8 keV and 1 MeV.This work presents results obtained during ground calibration tests performed on all 4 GBM detectors prior to launch.We present data taken utilizing radioactive sources as well as cosmic muons.These data were used to determine the responding functions of the detectors which can then be used to reconstruct the incident photon fluxes."
    },
    {
        "original_text": "The new reactor is based on the principle that nuclear fusion can be achieved by heating plasma to high temperatures in magnetic fields.  The proposed design uses an array of magnets and electrodes, which are powered by microwave generators, to heat hydrogen gas into plasma at 100 million degrees Celsius (1,000,000 K). This temperature is sufficient to cause nuclear fusion reactions between deuterium nuclei inside the plasma. In this way, energy is released as neutrons and gamma rays. These particles then bombard fuel pellets made up of tritium and lithium-6, causing them to release more energy through further nuclear fusion reactions. The resulting power plant would produce electrical power with no moving parts or radioactive waste products. It could also provide propulsion systems for spacecraft without requiring any chemical fuels. A conceptual drawing of the reactor system is shown below. Nuclear fusion has been studied extensively since its discovery over 50 years ago. However, it remains elusive because the conditions required to achieve fusion are extremely difficult to create experimentally.",
        "watermark_text": "The new reactor is based on the principle that nuclear fusion can be achieved by warming plasma to high temperatures in magnetic fields.The proposed design uses an array of magnets and electrodes, which are powered by microwave generators, to heat hydrogen gas into plasma at 100 million degrees Celsius ( 1, 000, 000 K ).This temperature is sufficient to cause nuclear fusion reactions between deuterium nuclei inside the plasma.In this way, energy is released as neutrons and gamma rays.These particles then bombard fuel pellets made up of tritium and lithium - 6, causing them to release more power through further nuclear fusion reactions.The resulting power plant would produce electrical energy with no movement parts or radiation waste products.It could also supply propulsion systems for spacecraft without requiring any chemical fuels.A conceptual drawing of the reactor system is shown below.Nuclear fusion has been studied extensively since its discovery over 50 years ago.However, it remains elusive because the conditions required to achieve fusion are extremely difficult to create experimentally."
    },
    {
        "original_text": "We study the dynamics of two interacting bosonic species confined to an optical lattice, with one species being initially prepared as a coherent state at each site while the other is initially prepared as a thermal cloud. We show that this system supports both symmetric and asymmetric soliton solutions which are stable against small perturbations for certain values of the chemical potentials. The stability properties of these solitons can be understood by studying their linearization spectrum around the stationary states. In particular we find that the presence of a finite temperature leads to additional unstable modes associated with phonon-like excitations. Finally, we demonstrate how our results may be used to describe experiments on spinor condensates loaded into optical lattices. Introduction:-Recent experimental advances have made it possible to create quantum degenerate gases consisting of several different atomic species [1] . These systems provide new opportunities to explore novel phenomena such as supersolids [2] , phase separation [3] or spin-orbit coupling [4] .\nIn this work we consider a particularly interesting example where there exist two distinct types of particles (e.g., atoms) which interact via s-wave scattering but differ in mass and/or internal structure [5] . This situation arises naturally when considering mixtures of hyperfine states [6] or isotopes [7, 8] within the same atom type [9] . For instance, recent experiments involving 87 Rb and 41 K [10] have demonstrated the formation of a mixture of two different hyperfine states after evaporative cooling [11] . Another possibility would involve using 40 K and 6 Li [12] . Here, the lighter species could be considered as impurities immersed in a background gas of heavier fermions [13] . Alternatively, if the masses were reversed then the heavy species could act as impurities [14] .",
        "watermark_text": "We study the dynamics of two interacting bosonic species confined to an optical lattice, with one species being originally prepared as a coherent state at each site while the other is initially prepared as a thermal cloud.We show that this system supports both symmetry and asymmetric soliton solutions which are stable against small perturbations for certain values of the chemistry potentials.The stability properties of these solitons can be understood by studying their linearization spectrum round the stationary states.In particular we find that the presence of a finite temperature leads to additional unstable modes associated with phonon - like excitations.Finally, we demonstrate how our outcomes may be used to describe experiments on spinor condensates loaded into optical lattices.Introduction : - Recent experimental advances have made it possible to create quantum degenerate gases consisting of several different atomic species [ 1 ].These systems provide additional opportunities to explore novel phenomena such as supersolids[ 2 ], phase separation [ 3 ] or spin - orbit coupling [ 4 ].In this work we consider a especially interesting example where there exist two distinct kinds of particles ( e. g., atoms ) which interface via s - wave scattering but differ in mass and / or internal structure[ 5 ].This situation arises naturally when thinking mixtures of hyperfine states [ 6 ] or isotopes [ 7, 8 ] within the same atom sort [ 9 ].For instance, recent experiments involving 87 Rb and 41 K [ 10 ] have demonstrated the formation of a mixture of two different hyperfine states after evaporative cooling [ 11 ].Another possibility would involve utilizing 40 K and 6 Li [ 12 ].Here, the lighter species could be considered as impurities immersed in a background gas of heavier fermions [ 13 ].Alternatively, if the masses were reversed then the heavy species could act as impurities [ 14 ]."
    },
    {
        "original_text": "We consider a wireless network where nodes selfishly forward packets to their neighbors, and study how cooperation among neighboring nodes can be used to improve performance. We propose a novel cooperative transmission scheme that allows each node to transmit its packet simultaneously on multiple channels using different power levels. The proposed scheme is shown to achieve higher throughput than existing schemes by exploiting spatial diversity across channels as well as power control over these channels. In addition, we show that our scheme achieves fairness between nodes without requiring any centralized controller or global information about the network topology. Finally, we present simulation results showing significant improvement in terms of both throughput and fairness compared to existing non-cooperative schemes. This work was supported by NSF under Grants CNS-0721440 (CAREER), ECCS-0701260, and CNS-0834753. Abstract: We consider a wireless network where all nodes are selfish and only cooperate when it benefits them. We propose a new cooperative transmission scheme which enables each node to transmit its own packet simultaneously on multiple channels at different power levels. Our scheme exploits spatial diversity across channels as wells as power control over those channels to increase the overall system throughput while maintaining fairness amongst competing nodes.",
        "watermark_text": "We consider a wireless network where nodes selfishly forward packets to their neighbours, and study how cooperation among neighboring nodes can be used to improve performance.We propose a novel cooperative transmission scheme that allows each node to transmit its packet concurrently on multiple channels using different power levels.The proposed scheme is shown to achieve higher throughput than existing schemes by exploiting spatial diversity across channels as also as power control over these channels.In addition, we show that our scheme achieves fairness between nodes without requiring any centralized controller or global information about the network topology.Finally, we present simulation results showing significant improvement in terms of both throughput and fairness compared to existing non - cooperative schemes.This work was supported by NSF under Grants CNS - 0721440 ( CAREER ), ECCS - 200701260, and CNS - 0834753.Abstract : We consider a wireless network where all nodes are selfish and only cooperate when it benefits them.We propose a fresh cooperative transmission scheme which enables each node to send its own packet simultaneously on multiple channels at different power levels.Our scheme exploits space diversity across channels as wells as power power over those channels to increase the overall system throughput while maintaining fairness amongst competing nodes."
    },
    {
        "original_text": "Reverberation is an important feature of brain function, but its role remains unclear. We show that reverberation can be generated by the interplay between calcium signaling and short-term plasticity (STP) at excitatory synapses. In our model, STP leads to bursts of spikes which are followed by periods of low firing rate due to depletion of neurotransmitter vesicles. The resulting slow recovery of transmitter release causes a build-up of residual calcium concentration [Ca] res , leading to facilitation of glutamate release during subsequent bursts. This positive feedback loop generates sustained reverberatory activity with multiple time scales. Our results suggest that reverberation may play a key role in information processing within neural circuits. Reverberation is one of the most prominent features of brain function [1] . It has been observed across different species [2] - [4] as well as in various brain areas including hippocampus [5] , neocortex [6] , thalamus [7] , striatum [8] , cerebellar cortex [9] , olfactory bulb [10] , and retina [11] .\nDespite its ubiquity, however, it still remains unknown what functional roles reverberation plays in the brain [12] . One possibility is that reverberation serves as a mechanism for memory storage [13] or retrieval [14] . Another hypothesis suggests that reverberation could serve as a substrate for working memory [15] . Yet another idea is that reverberation might provide a means for temporal coding [16] . Finally, some studies have suggested that reverberation may simply reflect ongoing spontaneous activity [17] .",
        "watermark_text": "Reverberation is an essential feature of brain activity, but its role remains unclear.We show that reverberation can be generated by the interplay between calcium signaling and short - time plasticity ( STP ) at excitatory synapses.In our model, STP leads to bursts of spikes which are followed by times of low firing rate due to depletion of neurotransmitter vesicles.The resulting slow recovery of transmitter release causes a build - up of remnant calcium concentration[ Ca ] res, leading to facilitation of glutamate release during subsequent bursts.This positive feedback loop generates sustained reverberatory activity with multi time scales.Our results suggest that reverberation may play a key role in information processing within neural circuits.Reverberation is one of the most notable features of brain function[ 1 ].It has been observed across different species [ 2 ] - [ 4 ] as also as in various brain areas including hippocampus [ 5 ], neocortex[ 6 ], thalamus[ 7 ], striatum [ 8 ], cerebellar cortex[ 9 ], olfactory bulb[ 10 ], and retina[ 11 ].Despite its ubiquity, however, it still remains unknown what functional roles reverberation plays in the brain [ 12 ].One possibility is that reverberation serves as a mechanism for memory storage[ 13 ] or retrieval[ 14 ].Another hypothesis suggests that reverberation could serve as a substrate for working memory [ 15 ].Yet another idea is that reverberation might provide a means for temporal coding [ 16 ].Finally, some studies have suggested that reverberation may simply reflect ongoing spontaneous action [ 17 ]."
    },
    {
        "original_text": "We propose an alternative approach to topological insulators based on the concept of Chern parity, which is defined as the product of all occupied bands in momentum space and can be viewed as a generalization of the Z2 index for time-reversal invariant systems. We show that this quantity has several useful properties such as being gauge independent and robust against disorder. In particular we demonstrate how it allows one to define new classes of topological insulators with nontrivial topology even when the system does not have inversion symmetry or time reversal invariance. Finally, we discuss possible experimental realizations using ultracold atoms trapped in optical lattices. Topological insulators are materials whose bulk states are insulating but their edges support gapless excitations protected by certain symmetries [1] . The most prominent example is provided by two-dimensional (2D) quantum spin Hall insulators [2] , where the edge states carry a single Dirac fermion per unit cell [3] .\nThe existence of these exotic states relies crucially on the presence of either timereversal [4] or particle-hole [5] symmetry. However, there exist other types of topological phases [6] characterized by different kinds of order parameters [7, 8] . For instance, 2D topological superconductors [9] are described by Majorana zero modes [10] while 3D Weyl semimetals [11] host chiral Fermi arcs [12] at their surfaces [13] . These novel phenomena cannot be captured within the standard classification scheme [14, 15] relying only on time-reversal and/or inversion symmetry [16] .\nIn this Letter, we introduce a new class of topological insulators [17] based on the concept of \"Chern parity\" [18] , which is defined as the sum over all occupied bands in reciprocal space [19] \nwhere |u nk ⟩ denotes the Bloch wavefunction corresponding to band n and crystal momentum k. This quantity plays a central role in our analysis since it provides a natural generalization of the Z 2 index [20] characterizing time-reversal invariant topological insulators [21] . Indeed, if the system preserves both time-reversal T and inversion P symmetries then C = 1 mod 4 [22] . On",
        "watermark_text": "We propose an alternative approach to topological insulators based on the concept of Chern parity, which is defined as the product of all occupied bands in momentum space and can be viewed as a generalization of the Z2 index for time - reversal invariant systems.We show that this quantity has several useful properties such as being gauge independent and robust against disorder.In particular we demonstrate how it allows one to define new classes of topological insulators with nontrivial topology even when the scheme does not have inversion symmetric or time reversal invariance.Finally, we discuss possible experimental realizations using ultracold atoms trapped in optical lattices.Topological insulators are materials whose bulk states are insulating but their edges support gapless excitations protected by certain symmetries [ 1 ].The most prominent example is provided by two - dimensional ( 2D ) quantum spin Hall insulators [ 2 ], where the edge states carry a single Dirac fermion per unit cell [ 3 ].The existence of these exotic states relies crucially on the presence of either timereversal [ 4 ] or particle - hole[ 5 ] symmetry.However, there exist other kinds of topological stages [ 6 ] characterized by different kinds of order parameters[ 7, 8 ].For instance, 2D topological superconductors [ 9 ] are described by Majorana zero modes[ 10 ] while 3D Weyl semimetals [ 11 ] host chiral Fermi arcs[ 12 ] at their surfaces [ 13 ].These novel phenomena cannot be captured within the standard classification scheme [ 14, 15 ] relying only on time - reversal and / or inversion symmetry [ 16 ].In this Letter, we introduce a new class of topological insulators [ 17 ] based on the concept of \" Chern parity \" [ 18 ], which is defined as the sum over all occupation bands in reciprocal space[ 19 ] where | u nk ⟩ denotes the Bloch wavefunction corresponding to band n and crystal momentum k.This quantity plays a central role in our analysis given it provides a natural generalization of the Z 2 index [ 20 ] characterizing time - reversal invariant topological insulators [ 21 ].Indeed, if the system preserves both time - reversal T and inversion P symmetries then C = 1 mod 4 [ 22 ].On"
    },
    {
        "original_text": "We show that the common origin of linear and nonlinear chiral multiplets is related to the existence of an extra dimension, which can be either time-like or space-like. We also discuss how this picture fits into the context of string theory. Theories with extended supersymmetry are known to have many interesting features such as duality symmetries [1] . In particular, theories with four supercharges (N = 4) possess remarkable properties [2] , including self-duality [3] .\nIn recent years there has been renewed interest in studying these theories due to their connection with string/M-theory [4] . For example, it was shown [5] that type-IIB strings on AdS 5 × S 5 background [6] correspond to maximally supersymmetric Yang-Mills theory in four dimensions [7, 8] . This correspondence allows one to study strongly coupled gauge theories using weakly-coupled gravitational description [9] . It turns out that the same idea works for other types of field theories [10] - [12] .",
        "watermark_text": "We show that the common origin of linear and nonlinear chiral multiplets is related to the existence of an extra dimensional, which can be either time - like or space - like.We also discuss how this picture fits into the context of string theory.Theories with extended supersymmetry are known to have many interesting features such as duality symmetries [ 1 ].In particular, theories with 4 supercharges ( N = 4 ) possess remarkable properties [ 2 ], including self - duality [ 3 ].In recent years there has been renewed interest in researching these theories due to their association with string / M - theory [ 4 ].For example, it was shown [ 5 ] that type - IIB strings on AdS 5 × S 5 background [ 6 ] correspond to maximally supersymmetric Yang - Mills theory in 4 dimensions[ 7, 8 ].This correspondence allows one to study strongly coupled gauge theories utilizing weakly - coupled gravitational description [ 9 ].It turns out that the same concept works for other types of field theories[ 10 ] -[ 12 ]."
    },
    {
        "original_text": "We study the transmission properties of defects in affine Toda field theories (ATFTs). We show that all ATFTs with simply-laced Lie algebras have only one type of defect, which is transmitted by itself and its images under the action of the Weyl group. This result generalizes previous results for A_n ATFTs to arbitrary ATFTs. In particular we find that the reflection coefficients are given by simple expressions involving the Coxeter number h of the underlying Lie algebra. The analysis presented here can be extended to other integrable models such as supersymmetric extensions or higher rank ATFTs. Defects play an important role in many physical systems ranging from condensed matter physics over particle physics to string theory. They appear when two different phases coexist at some point in space-time. For example they may arise if there exists a domain wall between two regions where the vacuum expectation values of certain fields differ. Another possibility is that defects occur due to impurities in solids or liquids. In this case it has been shown that the effective description of these defects leads to integrable models [1] . Integrability means that the scattering amplitudes factorize into products of two-body S-matrices [2] .\nIn recent years much progress was made on understanding the structure of defects in integrable quantum field theories [3] - [8] . It turned out that most of them can be classified according to their transmission properties [9] , i.e., whether they transmit themselves and their images under the action of a symmetry group G. If so, then the corresponding defect S-matrix is diagonalized simultaneously with the bulk S-matrix [10] . However, not every integrable model allows for such a classification [11] .",
        "watermark_text": "We study the transmission properties of faults in affine Toda field theories ( ATFTs ).We show that all ATFTs with simply - laced Lie algebras have only 1 type of defect, which is transferred by itself and its images under the action of the Weyl group.This result generalizes previous results for A _ n ATFTs to arbitrary ATFTs.In particular we find that the reflection coefficients are given by simple expressions involving the Coxeter number h of the underlying Lie algebra.The analysis presented here can be extended to other integrable models such as supersymmetric extensions or higher rank ATFTs.Defects play an important role in many physical systems ranging from condensed matter physics over particle matter to string theory.They appear when two different phases coexist at some point in space - time.For example they may arise if there exists a domain wall between 2 regions where the vacuum expectation values of certain fields differ.Another possibility is that defects occur due to impurities in solids or liquids.In this case it has been shown that the effective description of these flaws leads to integrable models[ 1 ].Integrability means that the scattering amplitudes factorize into products of two - body S - matrices [ 2 ].In recent years much progress was made on understanding the structure of defects in integrable quantum field theories [ 3 ] - [ 8 ].It turned out that most of them can be classified according to their transmission properties [ 9 ], i. e., whether they transmit themselves and their images under the act of a symmetrical group G.If so, then the corresponding defect S - matrix is diagonalized simultaneously with the bulk S - matrix [ 10 ].However, not every integrable model allows for such a classification [ 11 ]."
    },
    {
        "original_text": "We present evidence that the strong equivalence principle (SEP) holds in general relativity at least up to second post Newtonian order, by showing that the SEP is satisfied if it holds at first PN order.  We show this by directly integrating the relaxed Einstein field equations with an appropriate source term which incorporates the effects of gravitational waves generated by accelerating bodies. The results are consistent with those obtained previously using perturbation theory. This work was supported by NSF grant PHY-0456747. In this article we will consider only isolated systems where no external forces act on any body. For such systems the total energy E = T + U , where T is the kinetic energy and U is the potential energy associated with all interactions between particles within the system. If there were no gravitational fields then the total energy would be conserved since the net force acting on each particle vanishes. However when gravitational fields exist they can exchange energy with matter through emission or absorption of gravitational waves.",
        "watermark_text": "We present evidence that the strong equivalence principle ( SEP ) holds in general relativity at least up to second post Newtonian order, by showing that the SEP is satisfied if it holds at first PN order.We show this by direct integrating the relaxed Einstein field equations with an appropriate origin term which incorporates the effects of gravity waves generated by accelerating bodies.The results are consistent with those obtained previously via perturbation theory.This work was supported by NSF grant PHY - 0456747.In this article we will consider only isolated systems where no outside forces act on any body.For such systems the total energy E = T + U, where T is the kinetic energy and U is the potential one associated with all interactions between particles within the system.If there were no gravity fields then the total energy would be conserved since the net force acting on each particle vanishes.However when gravitational fields exist they can exchange energy with material through emission or absorbing of gravitational waves."
    },
    {
        "original_text": "We study the problem of reconstructing evolutionary histories that contain both reticulation events and vertical transmission, where reticulations are represented by hybridization or horizontal gene transfer (HGT). We show how to use maximum parsimony to find an optimal solution for this problem in polynomial time when all input trees have bounded degree. This is achieved through a novel dynamic programming algorithm which computes the minimum number of reticulation events needed to explain each set of taxa on every tree in the input collection. Our approach can be used as part of a larger method for inferring species networks using collections of rooted binary phylogenies inferred from different types of data such as DNA sequences, morphological characters, fossil records etc., and it may also provide insights into the evolution of complex organisms like viruses and bacteria. \nIntroduction\n\nThe reconstruction of evolutionary relationships among biological entities has been one of the central problems in biology since Darwin's On the Origin of Species was published 150 years ago [1] . The most widely accepted model of evolution assumes that new species evolve over time via vertical transmission -that is, they pass their genetic material down directly from parent to offspring [2] .\nHowever, there are many cases where we cannot assume that evolution proceeds strictly vertically; instead, some form of horizontal gene transfer (HG T) occurs between two lineages [3] , resulting in what is known as reticulate evolution [4] . For example, if a virus infects a bacterium, then its genes will be passed horizontally across the host cell membrane [5] ; similarly, if a plant hybridizes with another plant [6] , then the offspring inherits genetic material from both parents [7, 8] . In these examples, the process of HGT results in a network-like relationship between the descendants of the original ancestor(s), rather than a strict hierarchy [9] .",
        "watermark_text": "We study the problem of reconstructing evolutionary histories that contain both reticulation events and vertical transmission, where reticulations are represented by hybridization or horizontal gene transfer ( HGT ).We show how to utilize maximum parsimony to find an ideal solution for this problem in polynomial time when all input trees have bounded degree.This is achieved through a novel dynamic programming algorithm which computes the minimum number of reticulation events needed to explain each set of taxa on every tree in the input collection.Our approach can be used as part of a larger methodology for inferring species nets using collections of rooted binary phylogenies inferred from various types of data such as DNA sequences, morphological characters, fossil records etc., and it may also provide insights into the evolution of complex organisms like viruses and bacteria.Introduction The reconstruction of evolutionary relationships among biological entities has been part of the central problems in bio since Darwin ' s On the Origin of Species was published 150 years ago [ 1 ].The most widely supported model of evolution assumes that new species evolve over time via vertical transmission - that is, they pass their gene material down directly from parent to offspring [ 2 ].However, there are many cases where we cannot assume that evolution proceeds strictly vertically ; instead, some form of horizontal gene transfer ( HG T ) occurs between two lineages [ 3 ], yielding in what is known as reticulate evolution [ four ].For example, if a virus infects a bacteria, then its genetics will be passed horizontally along the host cellular membrane [ 5 ] ; similarly, if a plant hybridizes with another plant[ 6 ], then the offspring inherits genetic material from both parents[ 7, 8 ].In these examples, the process of HGT results in a network - like relation between the descendants of the original ancestor ( s ), rather than a strict hierarchy[ 9 ]."
    },
    {
        "original_text": "We consider the problem of detecting an unknown signal vector with a known covariance matrix, embedded in additive white Gaussian noise (AWGN). We propose to use sample eigenvalues as test statistics for this problem and derive their distributions under both hypotheses. The proposed method is shown to be robust against small perturbations on the covariance matrices. It also has low computational complexity compared to other existing methods. Finally we present simulation results that demonstrate its performance advantage over competing algorithms. In many applications such as radar systems or wireless communications, it is often desirable to detect whether there exists any signal component within noisy measurements. This problem can be formulated mathematically as: \nwhere x ∈ R N , s ∈ R M are respectively the signal and noise vectors; A ∈ R L×N denotes the sensing matrix which maps the signal space into the measurement space; y = Ax + n represents the observation vector where n ∼ N(0, σ 2 I) is AWGN. Herein, we assume that the number of observations L is much smaller than either N or M .",
        "watermark_text": "We consider the problem of detecting an unknown signal vector with a known covariance matrix, embedded in additive white Gaussian noisy ( AWGN ).We propose to use sample eigenvalues as test statistics for this issue and derive their distributions under both hypotheses.The proposed method is shown to be robust against small perturbations on the covariance matrices.It also has low calculation complexity compared to other existing methods.Finally we present simulation results that demonstrate its performance advantage over competing algorithms.In many applications such as radar systems or wireless communications, it is often desirable to detect whether there exists any signal component within noisy measurements.This problem can be formulated mathematically as : where x ∈ R N, s ∈ R M are respectively the signal and noise vectors ; A ∈ R L×N denotes the sensing matrix which maps the signal space into the measurement space ; y = Ax + n represents the observation vector where n [UNK] N ( 0, σ 2 I ) is AWGN.Herein, we assume that the number of observations L is much smaller than whether N or M."
    },
    {
        "original_text": "We present results on the composition of the eta-prime meson in terms of quarks and gluons, obtained by applying the QCD sum rule method to the correlation function of two pseudoscalars with different flavors.  We find that the eta prime is dominantly composed of strange quark pairs (ss) at low energies but becomes more nonstrange as energy increases. The mass difference between the eta and eta prime mesons can be explained if we assume that the eta prime contains an additional ss pair compared to the eta. This result supports our previous finding based on the analysis of the decay widths of these mesons into pions and kaons. \nPACS numbers: 11.10.Kk, 12.38.Gc, 13 .60.Hb  PACS number(s): 11.10.Kn, 12.38.Bx, 13 .60.Jz",
        "watermark_text": "We present results on the composition of the eta - prime meson in terms of quarks and gluons, obtained by applying the QCD sum rule method to the correlation function of two pseudoscalars with different flavors.We find that the eta prime is dominantly composition of strange quark pairs ( ss ) at low energies but becomes more nonstrange as energy increases.The mass difference between the eta and eta prime mesons can be explained if we assume that the eta prime contains an extra ss pair compared to the eta.This result supports our previous finding based on the analysis of the decay widths of these mesons into pions and kaons.PACS numbers : 11. 10. Kk, 12. 38. Gc, 13. 60. Hb PACS number ( s ) : 11. 10. Kn, 12. 38. Bx, 13. 60. Jz"
    },
    {
        "original_text": "The Galactic center (GC) is one of the most interesting regions in our Galaxy, but it has been difficult to study because of its proximity to the Sun. The GC contains many compact radio sources that are thought to be associated with young pulsars or magnetars. In this thesis we present results on two surveys at 1.4 GHz using the Australia Telescope Compact Array (ATCA). We have observed the central region of the Galaxy for about 100 hours over three epochs between 2005-2007. Our first survey covers an area of 2 degrees centered around Sgr A*. This survey was designed to search for new compact radio sources near the GC as well as to investigate the nature of the diffuse emission surrounding Sgr A*. Our second survey covered a larger area of 4 degrees centered around the GC. This survey was aimed at studying the distribution of molecular gas towards the GC by observing the 12 CO(J=1-0), 13 CO(J=1-0) and C 18 O(J=1-0) lines simultaneously.",
        "watermark_text": "The Galactic center ( GC ) is one of the most interesting regions in our Galaxy, but it has been difficult to study because of its proximity to the Sun.The GC contains many compact radio sources that are thought to be associated with young pulsars or magnetars.In this thesis we present results on 2 surveys at 1. 4 GHz using the Australia Telescope Compact Array ( ATCA ).We have observed the central region of the Galaxy for about 100 hours over three epochs between 2005 - 07.Our first survey covers an area of 2 ° centered around Sgr A *.This survey was designed to search for new compact radio sources near the GC as well as to investigate the nature of the diffuse emitted surrounding Sgr A *.Our second survey covered a larger area of 4 degrees centered around the GC.This survey was aimed at studying the distribution of molecular gas towards the GC by observing the 12 CO ( J = 1 - zero ), 13 CO ( J = 1 - 0 ) and C 18 O ( J = 1 - 0 ) lines simultaneously."
    },
    {
        "original_text": "Spin echoes are observed when the spin system is subjected to two successive radio-frequency (RF) pulses separated by an interval, known as the pulse separation time Tsep. The first RF pulse creates a macroscopic magnetization vector M0 that precesses around the external magnetic field Bext at Larmor frequency fL = γBext where γ is gyromagnetic ratio for nuclear spins. After the second RF pulse with flip angle θ2 and phase shift φ2 relative to the first one, the transverse component of the magnetization vector M2(t) decays exponentially due to dephasing caused by local magnetic fields created by neighboring nuclei. In this work we show how strong π-pulses can be used to generate spin echoes even if there is no net initial magnetization present before applying these pulses. We demonstrate theoretically and experimentally that such spin echoes originate intrinsically from the dipolar interactions between nuclear spins.",
        "watermark_text": "Spin echoes are observed when the spin system is subjected to two successive radio - frequency ( RF ) pulses separated by an interval, known as the pulse separation time Tsep.The first RF pulse creates a macroscopic magnetization vector M0 that precesses round the external magnetic field Bext at Larmor frequency fL = γBext where γ is gyromagnetic ratio for nuclear spins.After the second RF pulse with flip angle θ2 and phase shift φ2 relative to the first one, the transverse component of the magnetization vector M2 ( t ) decays exponentially due to dephasing caused by local magnetic fields created by neighboring nuclei.In this work we show how strong π - pulses can be utilized to generate spin echoes regardless if there is no net initial magnetization presence before applying these pulses.We demonstrate theoretically and experimentally that such spin echoes originate intrinsically from the dipolar interfaces between nuclear spins."
    },
    {
        "original_text": "We study the second-harmonic (SH) and third-harmonic (TH) generations in an inhomogeneously broadened cavity with two different resonance frequencies for fundamental wave (FW). We show that, when the intracavity FW intensity reaches its maximum value, both SHG and THG can be enhanced simultaneously by increasing the pumping rate or decreasing the detuning between the two modes. The enhancement is due to the fact that the nonlinear susceptibility becomes larger than zero at this point. This effect has been observed experimentally recently. \n \n In addition, we find that there exists another regime where only one type of harmonics can be generated efficiently while suppressing other types of harmonics. For example, if the intracavity FW field is tuned close to the lower mode frequency, then it will generate mainly SH light but very little TH light; on the contrary, if the intracavty FW field is tuned near the upper mode frequency, then it generates mainly TH light but almost no SH light.",
        "watermark_text": "We study the second - harmonic ( SH ) and 3rd - harmonic ( TH ) generations in an inhomogeneously broadened cavity with two different resonance frequencies for basic wave ( FW ).We show that, when the intracavity FW intensity reaches its maximum value, both SHG and THG can be enhanced simultaneously by increasing the pumping pace or decreasing the detuning between the two modes.The enhancement is due to the fact that the nonlinear susceptibility becomes larger than zero at this moment.This effect has been observed experimentally lately.In addition, we find that there exists another regime where only one type of harmonics can be generated efficiently while suppressing other types of harmonics.For example, if the intracavity FW field is tuned close to the bottom mode frequency, then it will produce mainly SH light but very little TH light ; on the contrary, if the intracavty FW field is tuned near the upper mode frequency, then it generates mainly TH light but almost no SH light."
    },
    {
        "original_text": "We present an analysis of the alignments between galaxy spins and tidal fields in real space, using data from the Two Mass Redshfit Survey (TMRS). We find that galaxies are preferentially aligned perpendicular to their local tidal field on scales larger than 1 Mpc/h. This alignment is stronger for more massive galaxies at higher redshifts. The observed spin-tide correlation can be explained by the effect of gravitational torques exerted by large-scale structures during the formation process of these galaxies. Our results suggest that this mechanism may play an important role in shaping galactic angular momenta. These findings have implications for understanding how dark matter halos acquire their angular momentum as well as for interpreting observations of cosmic shear statistics. Introduction: Galaxies form within overdense regions of the universe where they experience strong gravitational interactions with other objects such as neighboring galaxies or clusters of galaxies. During the formation process, these interactions induce gravitational torques which affect the orientation of the galactic angular momentum vector. In turn, the orientations of galactic angular momenta determine the shapes of galaxies through dynamical friction processes. Therefore, it has been suggested that the shape distribution of galaxies could provide information about the origin of galactic angular momentums (e.g., Catelan & Theuns 1996; Lee et al. 2008) . However, observational studies show conflicting results regarding whether there exists any preferred direction of galaxy spin axes relative to their neighbors' positions (see e.g., Faltenbacher et al. 2002; Bailin et al. 2005; Paz et al. 2008; Codis et al. 2012 , for recent works).\nIn order to understand the physical mechanisms responsible for determining the directions of galactic angular momentas, we need to study the statistical properties of galaxy spin distributions over large volumes of the universe. Recent surveys like Sloan Digital Sky Survey (SDSS) allow us to measure galaxy orientations accurately enough to perform such analyses. For example, Lee et al. (2008) used SDSS DR4 data to investigate the alignments between galaxy spin vectors and their nearest neighbor's position angles. They found no",
        "watermark_text": "We present an analysis of the alignments between galaxy spins and tidal fields in real space, using data from the 2 Mass Redshfit Survey ( TMRS ).We find that galaxies are preferentially aligned perpendicular to their local tidal field on scales bigger than 1 Mpc / h.This alignment is stronger for more massive galaxies at higher redshifts.The observed spin - tide correlation can be explained by the effect of gravitational torques exerted by big - series structures during the formation process of these galaxies.Our results suggest that this mechanism may play an important role in shaping galactic angular momenta.These findings have implications for understanding how dark matter halos acquire their angular momentum as also as for interpreting observations of cosmic shear statistics.Introduction : Galaxies form within overdense regions of the universe where they experience strong gravitational interactions with other objects such as neighboring galaxies or clusters of galaxies.During the formation process, these interactions induce gravitational torques which affect the inclination of the galactic angular momentum vector.In turn, the orientations of galactic angular momenta decide the forms of galaxies through dynamical friction activities.Therefore, it has been suggested that the shape distribution of galaxies could give information about the origin of galactic angular momentums ( e. g., Catelan & Theuns 96 ; Lee et ul. 2008 ).However, observational studies show conflicting results regarding either there exists any preferred direction of galaxy spin axes relative to their neighbors ' positions ( see e. g., Faltenbacher et al. 2002 ; Bailin et al. 2005 ; Paz et al. 2008 ; Codis et al. 2012, for recent works ).In order to understand the physical mechanisms responsible for determining the directions of galactic angular momentas, we require to study the statistical properties of galaxy spin distributions over big volumes of the universe.Recent surveys like Sloan Digital Sky Survey ( SDSS ) allow us to measure galaxy orientations accurately enough to perform such analyses.For example, Lee et al. ( 2008 ) used SDSS DR4 data to investigate the alignments between galaxy spin vectors and their closest neighbor ' s position angles.They found no"
    },
    {
        "original_text": "We present an automated method that uses machine learning techniques to classify supernova candidates in difference imaging data, and apply it to the Dark Energy Survey (DES). The DES is a five-year survey using a 1.2 deg2 camera on the 4-meter Blanco telescope at Cerro Tololo Inter-American Observatory (CTIO) in Chile. We use two different classification algorithms - Random Forests and Support Vector Machines - trained on simulated images generated by injecting artificial point sources into real DES images. Our results show that we can achieve high efficiency (>90%), purity (>80%), and completeness (>95%) when classifying objects as either stars or galaxies down to iAB = 24 mag. This enables us to find more supernovae per unit time than previous methods while reducing human biases associated with visual inspection. In addition, our technique allows us to identify new classes of transients such as tidal disruption events and microlensing flares.",
        "watermark_text": "We present an automated method that uses machine learning methods to classify supernova candidates in difference imaging data, and apply it to the Dark Energy Survey ( DES ).The DES is a five - year survey using a 1. 2 deg2 camera on the four - meter Blanco telescope at Cerro Tololo International - America Observatory ( CTIO ) in Chilean.We use two different classification algorithms - Random Forests and Support Vector Machines - trained on simulated images generated by injecting artificial point sources into real DES pictures.Our results show that we can achieve high efficiency ( > 90 % ), purity ( > 80 % ), and completeness ( > 95 % ) when classifying objects as either stars or galaxies down to iAB = 24 mag.This enables us to discover more supernovae every unit time than prior methods while reducing human biases associated with vision inspection.In addition, our technique allows us to identify new classes of transients such as tidal disruption events and microlensing flares."
    },
    {
        "original_text": "We present new spectroscopic observations in the near-infrared (NIR) range for the brightest member of the interacting pair of galaxies, NGC 7679/NGC 7682. The NIR spectrum shows strong narrow forbidden lines and permitted lines with P Cygni profiles characteristic to AGNs. We have detected blueshifted absorption components on both sides of Hα and [N II] 6584Å lines which are likely due to outflows driven by nuclear winds. In addition we found that the observed flux ratio between the two strongest optical emission lines is higher than expected value based on photoionization models. This indicates that there may be an additional source of ionization besides the central engine such as shocks or collisional heating. Our results suggest that this object could be classified as a composite Seyfert 2 galaxy where the contribution of starburst activity to the total luminosity is significant. Keywords: Near-infrared spectroscopy, Star formation rate",
        "watermark_text": "We present fresh spectroscopic observations in the near - infrared ( NIR ) range for the brightest member of the interacting pair of galaxies, NGC 7679 / NGC 7682.The NIR spectrum shows strong narrow forbidden lines and permitted lines with P Cygni profiles characteristic to AGNs.We have detected blueshifted absorbing components on both sides of Hα and [ N II ] 6584Å lines which are likely due to outflows driven by nuclear winds.In addition we found that the observed flux ratio between the two strongest optical emitted lines is higher than expected value based on photoionization models.This indicates that there may be an additional source of ionization besides the central engine such as shocks or collidedal heating.Our results suggest that this object could be classified as a composite Seyfert 2 galaxy where the contribution of stellarburst activity to the total luminosity is significantly.Keywords : Near - infrared spectroscopy, Star formation rate"
    },
    {
        "original_text": "We present an alternative method to the usual Feynman path integral description for calculating the probability amplitudes in quantum walk models, based on the concept of scattering states and their associated S-matrix elements. We show that this new formalism allows us to obtain exact results for several interesting cases where standard methods fail or are not applicable. In particular we consider two different types of boundary conditions at one end of the chain (the origin) which lead to completely different behaviour of the system as time evolves. The first type is known as Dirichlet boundary condition, corresponding to reflecting particles back into the origin after they have left it once; while the second case corresponds to absorbing particles when they reach the origin. For both these cases we calculate exactly the evolution operator over all times t > 0 using our new method. Finally, by applying the inverse Fourier transform to the evolution operator we can recover the full probability distribution function of finding the walker at any position x along the chain at time t.",
        "watermark_text": "We present an alternative method to the usual Feynman pathway integral description for calculating the likelihood amplitudes in quantum walk models, based on the concept of scattering states and their associated S - matrix elements.We show that this new formalism allows us to obtain exact results for several interesting cases where standard methods fail or are not applicable.In particular we consider 2 different kinds of boundary conditions at one end of the chain ( the origin ) which lead to completely different behaviors of the system as time evolves.The first type is known as Dirichlet boundary condition, corresponding to reflecting particles backward into the origin after they have left it once ; while the second case corresponds to absorbing particles when they reach the origin.For both these cases we calculate exactly the evolution operator over all times t > zero using our new method.Finally, by applying the inverse Fourier transform to the evolution operator we can recover the full probability distribution function of finding the walker at any position x along the chain at time t."
    },
    {
        "original_text": "We present results of numerical simulations of the nonlinear evolution of electrostatic waves excited by a localized source in a magnetized, collisionless plasma with nonuniform density and temperature profiles. The initial conditions are chosen to be close to those observed during experiments at the Large Plasma Device (LAPD) facility at UCLA. We find that the wave spectrum is dominated by two distinct branches corresponding to different types of waves: slow modes which propagate along magnetic field lines and fast modes which have oblique propagation angles relative to B. In addition we observe a number of other interesting phenomena such as generation of coherent structures, formation of shock fronts, etc., all of which can be explained within the framework of Zakharov's theory for Langmuir turbulence. \n \n Keywords: Nonlinear dynamics; Turbulence; Wave-particle interactions; Collisionless plasmas; LAPD; Fast-slow mode coupling; Waves",
        "watermark_text": "We present results of numerical simulations of the nonlinear evolution of electrostatic waves excited by a localized source in a magnetized, collisionless plasma with nonuniform density and thermal profiles.The initial conditions are chosen to be close to those observed during experimentation at the Large Plasma Device ( LAPD ) facility at UCLA.We find that the wave spectrum is dominated by 2 distinct branches corresponding to different types of waves : slow modes which propagate along magnetic field planes and fast modes which have oblique propagation angles relative to B.In addition we observe a number of other interesting phenomena such as generation of coherent structures, form of shock fronts, etc., all of which can be explained within the framework of Zakharov ' s theory for Langmuir turbulence.Keywords : Nonlinear dynamics ; Turbulence ; Wave - particle interactions ; Collisionless plasmas ; LAPD ; Fast - slow mode coupling ; Waves"
    },
    {
        "original_text": "We present an analytical solution to the problem of bending thin elastic shells with variable thickness under surface loads, which is applicable to the case where the shell's thickness varies by several orders of magnitude over its radius and where the load distribution is not necessarily axisymmetric.  We show that in this case it is possible to obtain accurate results using only two parameters instead of three as was previously thought necessary (the third parameter being the ratio between the maximum and minimum values of the shell's thickness). The new formulation allows us to calculate the deflection of the shell at any point on its surface without having to solve additional equations or perform numerical integration. This makes our approach much faster than previous methods while retaining high accuracy. Our method can be used to model the response of the Earth's crust to tectonic stresses and other processes such as volcanic loading and sedimentary deposition. It also has applications in geophysics beyond Earth sciences including planetary science, astrophysics and seismology. \nTheory\n\nIn order to study the deformation of the Earth's crust we need to know how the stress field changes across different regions of the planet. In particular, we are interested in understanding how the stress field evolves during plate boundary interactions like subduction zones and transform faults. To do so, we use the theory of elasticity to find solutions to problems involving the interaction between plates and their underlying mantle. However, solving these problems analytically requires simplifying assumptions about the geometry of the system and the mechanical properties of the materials involved. \n\nOne important simplification made when studying the mechanics of plate boundaries is to assume that they behave as if they were composed of thin elastic shells. These shells have been shown to provide good approximations to more realistic models of plate boundaries because they allow for rapid calculations of the stress fields within them. For example, Figure 1 shows a comparison between the predictions obtained using a simple spherical shell model and those produced by a finite element model of the San Andreas Fault System.\n\nFigure 1: Comparison between the predicted displacements along the San Andreas fault calculated using a spherical shell model (blue line) and a finite element model (red dots).",
        "watermark_text": "We present an analysis solution to the problem of bending thin elastic shells with variable thickness under surface loads, which is applicable to the case where the shell ' s thickness varies by several orders of magnitude over its radius and where the load distribution is not necessarily axisymmetric.We show that in this case it is possible to obtain accurate results using only two parameters instead of three as was previously thought necessary ( the third parameter being the ratio between the maximum and minimum values of the shell ' s thickness ).The new formulation allows us to calculate the deflection of the shell at any point on its surface without having to solve extra equations or perform numerical integration.This makes our approach much faster than previous methods while retaining high precision.Our method can be used to model the response of the Earth ' s crust to tectonic stresses and other processes such as volcanic loading and sedimentary deposition.It also has applications in geophysics beyond Earth scientists including planetary science, astrophysics and seismology.TheoryIn order to study the deformation of the Earth ' s crust we need to learn how the stress field changes across different areas of the planet.In particular, we are interested in understanding how the stress field evolves during plate border interactions like subduction zones and transform faults.To do so, we use the theory of elasticity to find solutions to problems involving the interface between plates and their underlying mantle.However, solving these problems analytically requires simplifying assumptions about the geometry of the system and the mechanical properties of the materials involved.One important simplification made when studying the mechanics of plate borders is to assume that they behavior as if they were composed of thin elastic shells.These shells have been shown to provide good approximations to more real models of plate boundaries because they allow for rapid calculations of the strain fields inside them.For example, Figure 1 shows a comparison between the predictions obtained using a simplified spherical shell model and those produced by a infinite element model of the Sant Andreas Fault System.Figure 1 : Comparison between the predicted displacements along the San Andreas fault calculated using a spherical shell model ( blue line ) and a finite element model ( red dots )."
    },
    {
        "original_text": "We have performed neutron powder diffraction experiments on the intermetallic compound Sm2IrIn8 in order to determine its magnetic structure and compare it with that proposed for YbMgGaO4, another member of this family of compounds. The results show that Sm2IrIn8 has an antiferromagnetic ordering at TN = 3.5 K with moments aligned along the c-axis. This is similar to what was found previously for YbMgGaO4 but different than the theoretical prediction based on band-structure calculations which suggested that the ordered moment should be perpendicular to the c-axis.  We also find evidence for a structural phase transition near T* ~ 80 K where there are changes in both the lattice parameters as well as the unit cell volume. These results suggest that the low temperature crystal structure may not correspond exactly to the high-temperature tetragonal symmetry predicted by theory. Finally we present specific heat data showing clear anomalies associated with both the magnetic ordering and the structural phase transition.",
        "watermark_text": "We have performed neutron powder diffraction experiments on the intermetallic compound Sm2IrIn8 in order to determine its magnetic structure and compare it with that suggested for YbMgGaO4, also member of this family of compounds.The results show that Sm2IrIn8 has an antiferromagnetic ordering at TN = 3. 5 K with moments aligned along the ca - axes.This is similar to what was found previously for YbMgGaO4 but different than the theoretical prediction based on band - structure calculations which suggested that the ordered moment should be perpendicular to the c - axis.We also find proof for a structural phase transition near T * ~ 80 K where there are shifts in both the lattice parameters as ill as the unit cellular volume.These results suggest that the low temperature crystal structure might not correspond exactly to the high - heat tetragonal symmetry predicted by theory.Finally we present particular heat data showing clear anomalies associated with both the magnetic ordering and the structural phase transition."
    },
    {
        "original_text": "The electronic structure, the equilibrium geometry and the finite-temperature properties are investigated for sodium clusters with 39 to 55 atoms by using density functional theory within generalized gradient approximation. The results show that the ground state is always in C_sv symmetry except for Na_55 which has D_5h symmetry as its lowest energy configuration. For all these clusters, we find that there exists an odd-even effect on their structural parameters such as bond length, bond angle and dihedral angle. We also investigate the vibrational frequencies and infrared intensities of these clusters at room temperature. It turns out that the calculated values agree well with those obtained experimentally. Finally, we study the thermodynamic stability of these clusters. Our calculations indicate that most of them have high melting temperatures but some of them may be unstable against dissociation into smaller fragments. \n \n Keywords: Sodium cluster, Electronic structure, Vibrational frequency, Infrared intensity",
        "watermark_text": "The electronic structure, the equilibrium geometry and the finite - temperature properties are investigated for sodium clusters with 39 to 55 atoms by using density functional theory within generalized gradient approximation.The results show that the ground state is always in C _ sv symmetry except for Na _ 55 which has D _ 5h symmetrical as its least energy configuration.For all these clusters, we find that there exists an odd - even influence on their structural parameters such as bond duration, structure angle and dihedral angle.We also investigate the vibrational frequencies and infrared intensities of these clusters at room temperature.It turns out that the calculated values agree well with those obtained experimentally.Finally, we study the thermodynamic stability of these clusters.Our calculations indicate that most of them have high melting temperatures but some of them may be unstable against dissociation into smaller fragments.Keywords : Sodium cluster, Electronic structure, Vibrational frequency, Infrared intensity"
    },
    {
        "original_text": "We propose that the high energy (HE) component in GRB spectra is produced via inverse Compton scattering between relativistic electrons accelerated at internal shocks, and soft photons emitted during the prompt phase.  We show that this model can explain both the HE spectral shape as well as its temporal evolution for several bursts observed with Fermi/LAT. The predicted light curves are consistent with those measured by Swift/BAT and Fermi/GBM. This scenario also naturally explains why some bursts have no detectable HE emission despite having bright optical flashes. Finally we discuss how our results could be used to constrain the physical parameters of GRBs such as their bulk Lorentz factor or magnetic field strength. High Energy Emission from Gamma Ray Bursts: A Proposal for an Inverse Compton Scattering Model  By J. Piran & M. Lazzati \n \n Abstract \n \n We propose that the high energy component in GRB spectra may be produced via inverse Compton scatterings between relativistic electrons accelerated within internal shocks, and soft photon fields emitted during the prompt phase. We show that this model predicts correctly the spectral shapes and time evolutions of many bursts detected by Fermi LAT. It also provides a natural explanation for the lack of detection of HE emission in some bursts which exhibit bright optical flashes. Our results suggest that future observations will allow us to determine important properties of GRBs like their bulk Lorentz factors or magnetic field strengths.",
        "watermark_text": "We propose that the high energy ( HE ) component in GRB spectra is produced via inverse Compton scattering between relativistic electrons accelerated at inner shocks, and soft photons emission during the prompt phase.We show that this model can explain both the HE spectrum shape as well as its time evolution for several bursts seen with Fermi / LAT.The predicted light curves are consistent with those measured by Swift / BAT and Fermi / GBM.This scenario also naturally explains why some bursts have no detectable HE emission despite having bright optical flashes.Finally we discuss how our outcomes could be used to constrain the physical parameters of GRBs such as their bulk Lorentz factor or magnetic field strength.High Energy Emission from Gamma Ray Bursts : A Proposal for an Inverse Compton Scattering Model By J. Piran & M. LazzatiAbstractWe propose that the high energy component in GRB spectra may be produced via inverse Compton scatterings between relativistic electrons accelerated within internal shocks, and soft photon fields emitted during the prompt phase.We show that this model predicts correctly the spectral shapes and time evolutions of much bursts detected by Fermi LAT.It also provides a natural explanation for the lack of detection of HE emission in some bursts which exhibit bright optical flashes.Our results suggest that future observations will allow us to determine important properties of GRBs including their bulk Lorentz factors or magnetic field strengths."
    },
    {
        "original_text": "We present an analysis of morphological properties for a sample of luminous compact galaxies (LCGs) selected in the Hubble Ultra Deep Field and studied with the Advanced Camera for Surveys on board the Hubble Space Telescope. We use GALFIT to fit single Sérsic profiles to all objects, allowing us to derive their structural parameters such as effective radius Re, Sérsic index n, axis ratio q, position angle PA, total magnitude mT , and half-light surface brightness SB e . The results show that most of these galaxies are bulge-dominated systems with high central concentration indices (n > 2). In addition, we find that there is no significant correlation between galaxy luminosity or size and its Sérsic index. Finally, by comparing our results with those obtained for other samples of massive early-type galaxies at different redshifts, we conclude that LCGs have similar sizes but higher concentrations than local elliptical galaxies.",
        "watermark_text": "We present an analysis of morphological properties for a sample of luminous compact galaxies ( LCGs ) selected in the Hubble Ultra Deep Field and studied with the Advanced Camera for Surveys on board the Hubble Space Telescope.We use GALFIT to fit single Sérsic profiles to all objects, allowing us to extract their structural parameters such as effective radius Re, Sérsic index n, axes ratio q, position angle PA, complete magnitude mT, and half - light surface brightness SB e.The results show that most of these galaxies are bulge - dominated systems with high central concentration indices ( n > 2 ).In addition, we find that there is no significant correlation between galaxy luminosity or size and its Sérsic index.Finally, by comparing our results with those obtained for other samples of massive early - type galaxies at different redshifts, we conclude that LCGs have similar sizes but higher concentrations than local elliptical galaxies."
    },
    {
        "original_text": "The noncommutative torus is an algebra which can be viewed as a deformation quantization of the ordinary torus, or equivalently as a quantum group at roots of unity.  The purpose of this article is to give a brief introduction into some aspects of the theory of these algebras, with emphasis on their representation theory.   We will first introduce the basic definitions in Section 1, then discuss the connection between the noncommutative toruses and the Riemann-Hilbertequivalence in Section 2.    In Section 3 we present the classification theorem for irreducible representations of the noncommutative two-torus, while in Section 4 we describe how one obtains explicit formulas for such representations by using theta functions. Finally, in Section 5 we explain how the results obtained so far are related to the study of integrable systems. This article is based on lectures given by the author during his stay at the Institute for Advanced Study (IAS) in Princeton, NJ, USA, in summer 2005.",
        "watermark_text": "The noncommutative torus is an algebra which can be viewed as a deformation quantization of the ordinary torus, or equivalently as a quantum group at roots of unity.The purpose of this article is to give a brief introduction into some aspects of the theory of these algebras, with emphasis on their representation theory.We will first introduce the basic definitions in Section 1, then discuss the link between the noncommutative toruses and the Riemann - Hilbertequivalence in Section 2.In Section 3 we present the classification theorem for irreducible representations of the noncommutative 2 - torus, while in Section 4 we describe how one obtains explicit formulas for such representations by using theta functions.Finally, in Section 5 we explain how the results obtained so far are related to the study of integrable systems.This article is based on lectures given by the writer during his stay at the Institute for Advanced Study ( IAS ) in Princeton, NJ, US, in summer 2005."
    },
    {
        "original_text": "In this work, we revisit some issues on netflow sample and export performance in terms of packet loss rate (PLR) and flow sampling accuracy (FSA). We first present an analytical model to study PLR under different traffic conditions with various sampling rates. Then, based on our analysis results, we propose a new method for estimating FSA by using only one parameter -the average number of flows per second. Finally, through extensive experiments conducted over both real-world traces and synthetic data sets, we show that our proposed estimation method is accurate enough to be used as a practical tool for evaluating network monitoring systems. The rest of this paper is organized as follows. In Section 2, we introduce related works about netflow sampling and exporting. In Section 3, we describe our experimental environment. In Section 4, we analyze the relationship between PLR and sampling rate. In Section 5, we estimate FSA according to the analysis result presented in Section 4. In Section 6, we evaluate the effectiveness of our proposed estimation method via extensive experiments. Finally, conclusions are drawn in Section 7.",
        "watermark_text": "In this work, we revisit some issues on netflow sample and export performance in terms of packet loss rate ( PLR ) and flow sampling accurate ( FSA ).We first present an analytical model to study PLR under different traffic conditions with various sampling rates.Then, based on our analysis results, we propose a novel method for estimating FSA by using only one parameter - the average number of flows per second.Finally, through extensive experiments conducted over both real - world traces and synthetic data sets, we demonstrate that our suggested estimation method is accuracy enough to be used as a practical tool for evaluating network watching systems.The rest of this paper is organized as follows.In Section 2, we introduce associated works about netflow sampling and exporting.In Section 3, we describe our experimental environment.In Section 4, we analyze the relationship between PLR and sampling rate.In Section 5, we estimate FSA according to the analysis result presented in § 4.In Section 6, we evaluate the effectiveness of our proposed estimation method via intensive experiments.Finally, conclusions are drawn in Section 7."
    },
    {
        "original_text": "We present an analysis of the evolution in the luminosity function (LF) and colour-magnitude relation (CMR) of galaxies selected by their rest-frame optical colours, using data from three large multi-wavelength surveys covering different areas on the sky. The first is the Spitzer Wide-area InfraRed Extragalactic survey (SWIRE), which covers about one quarter of the southern hemisphere at 24 microns with MIPS; the second is the VIMOS Very Deep Survey (VVDS), which has been carried out as part of the CFHT Legacy Survey (CFHTLS). This provides deep photometry in five bands to AB magnitude limits ranging from 26.5 to 27.7 mags in the u*gri filters. Finally we use near-infrared imaging obtained with WIRCam mounted on the Canada France Hawaii Telescope (CFHT) to select samples of massive galaxies at 1<z<1.4. We find that the LF evolves strongly towards fainter magnitudes since z=1.2, while there are no significant changes in its shape or normalisation. In addition, we show that the CMR becomes bluer with time, indicating that the fraction of quiescent systems increases significantly between these epochs.",
        "watermark_text": "We present an analysis of the evolution in the luminosity function ( LF ) and color - magnitude relation ( CMR ) of galaxies selected by their rest - frame optical colours, using data from three large multi - wavelength surveys covering different areas on the sky.The first is the Spitzer Wide - area InfraRed Extragalactic survey ( SWIRE ), which encompasses about one quarter of the south hemisphere at 24 microns with MIPS ; the second is the VIMOS Very Deep Survey ( VVDS ), which has been carried out as part of the CFHT Legacy Survey ( CFHTLS ).This provides deep photometry in five bands to AB magnitude limits ranging from 26. 5 to 27. 7 mags in the u * gri filters.Finally we use near - infrared imaging obtained with WIRCam mounted on the Canada France Hawaii Telescope ( CFHT ) to select samples of massive galaxies at 1 < z < 1. 4.We find that the LF evolves strongly towards fainter magnitudes given z = 1. 2, while there are no significant changes in its shape or normalisation.In addition, we show that the CMR becomes bluer with time, indicating that the fraction of quiescent systems increases significantly between these epochs."
    },
    {
        "original_text": "We present the prospects for high-precision measurement of the 1s2p 3P-1s2s 3S transition in atomic helium with an optical frequency comb (OFC). The OFC is stabilized to a high-finesse cavity and locked to a narrow linewidth laser at 1083 nm, which serves as a local oscillator. We show that this system can be used to measure the absolute frequencies of two transitions in helium with uncertainties below 100 kHz. This will allow us to determine the fine-structure constant α with relative uncertainty better than 2×10−10 by measuring the ratio between these two frequencies. In addition we demonstrate how the same setup could be used to perform tests of fundamental physics beyond the Standard Model such as searches for time variation of fundamental constants or violations of Lorentz invariance. Optical frequency combs are powerful tools for precise metrology [1–3] . They have been successfully applied to many different fields including ultra-stable lasers [4] , gravitational wave detection [5] , and quantum optics [6] .\nIn particular they provide unprecedented possibilities for high-precision measurement [7–9] . Here we propose to use them to improve our knowledge on the value of the fine structure constant [10] . To achieve this goal it is necessary to measure the absolute frequencies f(1s2p 3P1) = 929 072 631 770 Hz [11] and f(1s2s 3S1) = 929 073 761 828 Hz [12] of two transitions in helium. These values were determined previously with uncertainties of about 300 kHz [13] but recent theoretical calculations suggest that their accuracy may be improved significantly [14–18] .",
        "watermark_text": "We present the prospects for high - precision measurement of the 1s2p 3P - 1s2s 3S transition in atomic helium with an optical frequency comb ( OFC ).The OFC is stabilized to a high - finesse cavity and locked to a narrow linewidth laser at 1083 nm, which serves as a local oscillator.We show that this system can be used to measure the absolute frequencies of two transitions in helium with uncertainties below 100 kHz.This will allow us to decide the fine - structure constant α with relative uncertainty better than 2×10−10 by measuring the ratio between these 2 frequencies.In addition we demonstrate how the same setup could be utilized to perform tests of fundamental physics outside the Standard Model such as searches for time variation of fundamental constants or violations of Lorentz invariance.Optical frequency combs are powerful tools for accurate metrology [ 1 – 3 ].They have been successfully applied to many different fields like ultra - stable lasers [ 4 ], gravity wave detector [ 5 ], and quantum optics[ 6 ].In particular they provide unprecedented possibilities for high - precision measurement[ 7 – 9 ].Here we propose to use them to improve our understanding on the value of the fine structure constant [ 10 ].To achieve this goal it is necessary to measure the absolute frequencies f ( 1s2p 3P1 )= 929 072 631 770 Hz[ 11 ] and f ( 1s2s 3S1 )= 929 073 761 828 Hz[ 12 ] of two transitions in helium.These values were established previously with uncertainties of about 300 kHz [ 13 ] but recent theory calculations suggest that their precision may be improved significantly [ 14 – 18 ]."
    },
    {
        "original_text": "We present the results of three-dimensional hydrodynamic simulations of accretion disks around black holes, which include both gas pressure and radiation pressure as well as self-gravity. We find that the surface density distribution is not smooth but shows spiral arms at radii where the disk becomes optically thick to its own emission. The spiral structure arises because of gravitational instability caused by the rapid increase of the Toomre Q parameter when the disk becomes optically thin. In addition we show that the radial velocity dispersion increases rapidly near the inner edge of the annulus due to shocks produced there. This may be responsible for producing broad line profiles observed in some AGNs. \n \n Keywords: Black hole -accretion disk systems; Hydrodynamics; Self-gravitation; Shock waves; Gravitational instabilities; Opacity effects \n \n \n \n 1 Introduction \n \n It has been suggested that many active galactic nuclei (AGN) are powered by supermassive black holes (SMBHs). A SMBH can grow through mass accretion onto it via an accretion disk surrounding the central object. Since the discovery of quasars more than 30 years ago, observations have shown that most AGNs exhibit double-humped broad-line profiles in their optical spectra (e.g., [1; 2]), indicating that they contain rotating accretion disks [3] . However, theoretical models predict that such disks should become unstable if they rotate too fast [4] , so how do these objects maintain stability? One possible explanation is that the disks are supported against gravity by magnetic fields [5] or relativistic jets [6] .\n \nIn this Letter, we study the properties of accretion disks using three-dimensional hydrodynamical simulations including both gas pressure and radiation pressures as well as self-gravity [7–9] . Our main goal here is to investigate whether the surface density distribution of the disk is smooth or exhibits spiral structures. If the latter case occurs, then what causes them?\n2 Model Description\n\nModel Setup\nThe basic equations governing our model are given by:",
        "watermark_text": "We present the results of three - dimension hydrodynamic simulations of accretion discs around dark holes, which include both gas pressure and radiation pressure as well as self - gravity.We find that the surface density distribution is not smooth but displays spiral arms at radii where the disk becomes optically thick to its own emission.The spiral structure arises because of gravitational instability caused by the rapid rise of the Toomre Q parameter when the disk becomes optically thin.In addition we show that the radial velocity dispersion increases rapidly near the inner edge of the annulus owing to shocks produced there.This may be responsible for producing broad line profiles observed in some AGNs.Keywords : Black hole - accretion disk systems ; Hydrodynamics ; Self - gravitation ; Shock waves ; Gravitational instabilities ; Opacity effects 1 Introduction It has been suggested that many active galactic nuclei ( AGN ) are powered by supermassive black holes ( SMBHs ).A SMBH can grow through mass accretion upon it via an accretion disk surrounding the central object.Since the discovery of quasars more than 30 years ago, observations have shown that most AGNs exhibit twice - humped broad - line profiles in their optical spectra ( e. g., [ 1 ; 2 ] ), indicating that they contain rotating accretion disks [ 3 ].However, theoretical models predict that such discs should become instability if they spin too fast [ 4 ], so how do these objects maintain stability?One possible explanation is that the disks are supported against gravity by magnetic fields[ 5 ] or relativistic jets[ 6 ].In this Letter, we study the properties of accretion discs using three - dimensional hydrodynamical simulations including both gas pressure and radiation pressures as well as self - gravity [ 7 – 9 ].Our main goal here is to explore whether the surface density distribution of the disk is flat or exhibits spiral shapes.If the latter case occurs, then what causes them?2Model Description Model SetupThe basic equations governing our model are given by :"
    },
    {
        "original_text": "We present the theory for two-photon interactions in broadband down-converted light, including entanglement between photons generated by spontaneous parametric down conversion (SPDC). We show that this leads to new effects such as photon bunching at zero time delay and antibunching at nonzero delays. These results are compared against experimental data obtained using SPDC sources based on periodically poled lithium niobate waveguides. The theoretical model is also used to predict the effect of varying pump bandwidths and crystal lengths on the degree of second-order coherence g(2)(0) measured experimentally. This work was supported by EPSRC grant EP/G037656/1. \n \n In recent years there has been growing interest in quantum optics experiments involving broadband down-conversion [1–3]. Such experiments have led to demonstrations of novel phenomena such as single-photon switching [4], sub-Poissonian statistics [5], squeezing [6], and nonclassical correlations [7, 8]. However, many aspects of these experiments remain poorly understood due to difficulties associated with modelling the complicated nonlinear processes involved [9, 10]. Here we develop an analytical description of two-photon interactions in broad-band down-converted light which includes both temporal and spatial degrees of freedom [11, 12]. Our approach allows us to calculate the joint spectral intensity distribution of the down-converted field [13], which can then be used to determine the probability density function describing the arrival times of pairs of photons produced via spontaneous parametric downconversion [14–18]. As well as providing insight into the physics underlying broadband down-conversion experiments, our analysis enables quantitative predictions about the behaviour of such systems to be made.",
        "watermark_text": "We present the theory for two - photon interactions in broadband down - converted light, including entanglement between photons generated by spontaneous parametric down conversion ( SPDC ).We show that this leads to new effects such as photon bunching at zero time delay and antibunching at nonzero delays.These results are compared against experimental data obtained utilizing SPDC sources based on periodically poled lithium niobate waveguides.The theoretical model is also used to forecast the impact of varying pump bandwidths and crystal lengths on the degree of second - order coherence g ( 2 ) ( 0 ) measured experimentally.This work was supported by EPSRC grant EP / G037656 / 1.In recent years there has been growing interest in quantum optics experiments involving broadband down - converted [ 1 – 3 ].Such experiments have led to demonstrations of novel phenomena such as single - photon switching [ 4 ], sub - Poissonian statistics[ 5 ], squeezing [ 6 ], and nonclassical correlations[ 7, 8 ].However, many aspects of these experiments remain poorly understood due to difficulties linked with modelling the complex nonlinear processes involved[ 9, 10 ].Here we develop an analysis description of two - photon interactions in broad - band down - converted light which covers both temporal and spatial degrees of free [ 11, 12 ].Our approach allows us to calculate the joint spectral intensity distribution of the down - converted field[ 13 ], which can then be used to determine the probability density function describing the arrival times of pairs of photons produced via spontaneous parametric downconversion[ 14 – 18 ].As well as providing insight into the physics underlying broadband down - conversion experiments, our analysis enables quantitative predictions about the behaviour of such systems to be made."
    },
    {
        "original_text": "The Sloan Digital Sky Survey (SDSS) is an ambitious project to map one quarter of the sky in five photometric bands, and obtain spectra for over 100 million galaxies, quasars, stars, and other celestial objects.  The survey has been completed on two thirds of its original footprint; it will be complete by 2008. This talk describes some of the science that can be done using this data set. It also discusses how astronomers are working together to make use of these vast resources. In particular I describe my own work on studying galaxy clusters as dark matter halos, measuring their masses through gravitational lensing effects, and determining their evolution across cosmic time. Finally, I discuss plans for future surveys which will build upon SDSS's successes. The Sloan Digital Sky Survey is an ambitious project to measure the positions and redshifts of more than 100 million galaxies, quasARS, stars, and other objects in our Universe.",
        "watermark_text": "The Sloan Digital Sky Survey ( SDSS ) is an ambitious project to map one quarter of the sky in five photometric bands, and obtain spectra for over 100 million galaxies, quasars, stars, and other celestial objects.The survey has been completed on 2 thirds of its original footprint ; it will be complete by 2008.This talk describes some of the science that can be done utilizing this data set.It also discusses how astronomers are working jointly to make use of these vast resources.In particular I describe my own work on studying galaxy clusters as dark matter halos, measuring their masses through gravitational lensing effects, and determining their evolution throughout cosmic time.Finally, I discuss plans for future surveys which will build upon SDSS ' s successes.The Sloan Digital Sky Survey is an ambitious project to measure the positions and redshifts of more than 100 million galaxies, quasARS, stars, and other objects in our Universe."
    },
    {
        "original_text": "In this work, we study the renormalization group equations (RGEs) for extra U(1) supersymmetric string inspired model with heavy Z' prime and its effects on gauge coupling unification at one-loop level. We find that the inclusion of new particles such as vector-like quarks and leptons can significantly affect the running behavior of gauge couplings. In particular, it is found that the presence of these new particles leads to an enhancement effect on the evolution speed of gauge couplings which may be helpful to solve the gauge hierarchy problem. Furthermore, by using the experimental data of low energy physics, we obtain some constraints on the mass spectrum of extra particles involved in our model. Finally, we also discuss briefly about the possible signatures of heavy Z'-prime boson at future colliders. The results are summarized below. \nI. INTRODUCTORY REMARK\nThe Standard Model (SM), based on SU(3) C ×SU(2) L ×U(1) Y gauge symmetry, has been very successful in describing all known phenomena upto TeV scale energies [1] . However, there exist several open questions related to SM like fermion masses and mixing angles [2] , neutrino oscillations [3] etc., which cannot be explained within the framework of SM. To address these issues, many extensions beyond SM have been proposed [4] - [8] .\nAmong them, Grand Unified Theory (GUTs) [9] provides a natural solution to the above mentioned problems [10] . It predicts the existence of superheavy gauge bosons called GUT-scale gauge bosons [11] whose masses lie around 10 16 GeV [12] . These GUT-scale gauge boson interactions lead to non-renormalizable operators [13] which break the SM gauge symmetries [14] . Therefore, they should not appear in any physical process [15] . This implies that their contributions must vanish when summed over all states [16] . Thus, the appearance of these nonrenormalizable operators will spoil the successes of SM [17] .",
        "watermark_text": "In this work, we study the renormalization group equations ( RGEs ) for extra U ( 1 ) supersymmetric string inspired model with heavy Z ' prime and its effects on gauge coupling unity at 1 - loop level.We find that the inclusion of new particles such as vector - like quarks and leptons can considerably affect the running behavior of gauge couplings.In particular, it is found that the presence of these novel particles leads to an enhancement effect on the evolution speed of gauge couplings which may be helpful to solve the scale hierarchy problem.Furthermore, by using the experimental data of low energy physics, we obtain some constraints on the mass spectral of extra particles concerned in our model.Finally, we also discuss briefly about the possible signatures of heavy Z ' - prime boson at later colliders.The results are summarized below.I. INTRODUCTORY REMARK The Standard Model ( SM ), based on SU ( 3 ) C ×SU ( 2 ) L ×U ( 1 )Y gauge symmetry, has been very successful in describing all known phenomena upto TeV scale energies [ 1 ].However, there exist several open questions related to SM including fermion masses and mixing angles [ 2 ], neutrino oscillations[ 3 ] etc., which cannot be explained within the framework of SM.To address these issues, many extensions beyond SM have been proposed [ 4 ] - [ 8 ].Among them, Grand Unified Theory ( GUTs )[ 9 ] provides a natural solution to the above mentioned problems [ 10 ].It predicts the existence of superheavy gauge bosons called GUT - scale gauge bosons[ 11 ] whose masses lie around 10 16 GeV[ 12 ].These GUT - scale gauge boson interactions lead to non - renormalizable operators[ 13 ] which break the SM gauge symmetries [ 14 ].Therefore, they should not appear in any material process [ 15 ].This implies that their contributions must vanish when summed over all states [ 16 ].Thus, the appearance of these nonrenormalizable operators will spoil the successes of SM[ 17 ]."
    },
    {
        "original_text": "In this work, we present the results of an extensive measurement study on the characteristics and dynamics of peer-to-peer (P2P) Internet Protocol Television (IPTV). We collected traffic traces for more than two months in three different countries using several hundred dedicated monitoring hosts deployed at ISPs around the world. Our analysis shows that P2P-TV is responsible for up to 80% of all video streaming traffic observed by these monitors. In addition, our measurements reveal significant differences between the behavior of various P2P-TV systems. Finally, we show how such knowledge can be used to detect P2P-TV streams with high accuracy even when they are encrypted or use proxies. The rest of this paper is organized as follows. Section 2 presents related work. Section 3 describes our experimental setup. Sections 4-7 present detailed analyses of the data obtained during our experiments. Finally, Section 8 concludes the paper. This section provides background information about P2P-TV systems and summarizes previous research efforts aimed at characterizing their traffic.",
        "watermark_text": "In this work, we present the results of an extensive measurement research on the characteristics and dynamics of peer - to - peer ( P2P ) Internet Protocol Television ( IPTV ).We collected traffic traces for more than two months in 3 different countries using several 200 dedicated monitoring hosts installed at ISPs around the world.Our analysis shows that P2P - TV is responsible for up to 80 % of all video streaming traffic observed by these monitors.In addition, our measurements reveal significant differences between the behavior of various P2P - TV systems.Finally, we show how such knowledge can be used to detect P2P - TV streams with high precision even when they are encrypted or use proxies.The rest of this paper is organized as follows.Section 2 presents related work.Section 3 describes our experiment setup.Sections 4 - 7 present detailed analyses of the data obtained during our experiments.Finally, Section 8 concludes the paper.This section provides background information about P2P - television systems and summarizes previous research efforts aimed at characterizing their traffic."
    },
    {
        "original_text": "We present an analysis of high-resolution near-infrared images obtained with NACO/VLT and SPHERE/ZIMPOL/ESO to study the photometric variability of the exoplanet HD 189733b in its transit across the stellar disk. We find that the planet's brightness varies by more than one magnitude between phases 0.8-0.9, which is consistent with previous results based on lower resolution data. The observed phase curve shows two maxima at phases 0.85 and 0.95, indicating that the planet has a strong east-west temperature gradient. This result can be explained if we assume that the planet orbits close to edge-on (i = 85°) and that it receives most of its energy from the star through a single hemisphere. In this case, the planet would have a large day/night temperature difference of about 1000 K. Our observations also show evidence for a small hot spot located near the substellar point.",
        "watermark_text": "We present an analysis of high - resolution near - infrared images obtained with NACO / VLT and SPHERE / ZIMPOL / ESO to study the photometric variability of the exoplanet HD 189733b in its transit across the stellar disk.We find that the planet ' s brightness varies by more than one magnitude between phases zero. 8 - zero. 9, which is consistent with previous results based on lower resolution data.The observed phase curve shows two maxima at phases 0. 85 and 0. 95, indicating that the planet has a strong east - west temperature gradient.This result can be explained if we assume that the planet orbits close to edge - on ( i = 85° ) and that it receives most of its energy from the star through a single hemisphere.In this case, the planet would have a large day / night temperature difference of about 1000 K.Our observations also show evidence for a small hot spot situated near the substellar point."
    },
    {
        "original_text": "The concept of tensegrity is used to describe the structural behavior of many biological systems, such as muscles and tendons.  In this work we explore how continuous tensegrities can be generated by using an evolutionary algorithm that optimizes their performance in terms of compliance with external loads while maintaining stability under gravity loading conditions.   The results show that it is possible to generate stable structures that are able to resist large deformations without collapsing or losing their integrity. This research has been funded by the European Commission through the Marie Curie Initial Training Network (ITN) program. The concept of tensegrity was first introduced by Buckminster Fuller more than 60 years ago [1] . It describes the structural behavior of many natural systems like muscles [2] , tendons [3] , bones [4] , and even living organisms [5] .\nIn recent decades there have been several attempts at applying the concept of tensegrity to engineering applications [6] - [8] . However, most of these works focus on discrete tensegrities which consist of rigid bars connected together by elastic struts [9] . These types of structures cannot easily adapt to changes in their environment since they do not allow for any deformation [10] . On the other hand, continuous tensegrities [11] are capable of changing shape continuously when subjected to external forces [12] . They also exhibit higher levels of robustness against damage [13] compared to conventional materials [14] . Despite all these advantages, very little attention has been paid so far to the design of continuous tensegrities [15] .\nThis lack of interest may be due to the fact that designing continuous tensegrities requires solving highly nonlinear optimization problems [16] . Moreover, finding solutions to these problems is extremely challenging because of the high number of local optima [17] . To overcome these difficulties, researchers usually use heuristic search algorithms [18] - [20] instead of exact methods [21] .",
        "watermark_text": "The concept of tensegrity is used to describe the structural behavior of many biological systems, such as muscles and tendons.In this work we explore how continuous tensegrities can be generated by utilizing an evolutionary algorithm that optimizes their performance in terms of compliance with outside loads while maintaining stability under gravitational loading conditions.The results show that it is possible to generate stable structures that are capable to resist big deformations without collapsing or losing their integrity.This research has been funded by the EU Commission through the Marie Curie Initial Training Network ( ITN ) program.The concept of tensegrity was first introduced by Buckminster Fuller more than sixty years ago [ 1 ].It describes the structural behavior of many natural systems like muscles [ 2 ], tendons[ 3 ], bones [ 4 ], and even living organisms [ 5 ].In recent decades there have been several attempts at applying the concept of tensegrity to engineering applications[ 6 ] - [ 8 ].However, most of these works focus on discrete tensegrities which consist of rigid bars connected together by elastic struts [ 9 ].These types of buildings cannot easily adapt to changes in their environment since they do not allow for any deformation [ 10 ].On the other hand, continuous tensegrities [ 11 ] are capable of changing shape continuously when subjected to external forces [ 12 ].They also exhibit upper levels of robustness against damage[ 13 ] compared to conventional materials [ 14 ].Despite all these advantages, very less attention has been paid so long to the design of continuous tensegrities [ 15 ].This lack of interest may be due to the fact that designing continuous tensegrities requires solving highly nonlinear optimization issues [ 16 ].Moreover, finding solutions to these issues is extremely challenging because of the high number of local optima [ 17 ].To overcome these difficulties, researchers usually use heuristic search algorithms[ 18 ] - [ 20 ] instead of exact methods[ 21 ]."
    },
    {
        "original_text": "We present the results of an optical spectroscopic survey aimed at finding tidal dwarf galaxies (TDGs) candidates among a sample of ultraluminous infrared galaxies (ULIRG). We have obtained spectra with FORS2@VLT and GMOS-N@Gemini telescopes, covering the wavelength range between 3600 Å and 9200 Å , for a total of 16 ULIRGs selected on the basis of their high far-infrared luminosity (L FIR > 10 12 L ⊙ ) and low redshift (z < 0.1).\nThe main goal is to find TDGs that are expected to be found around interacting systems such as ULIRGs. The presence of young stars in these objects would make them detectable through strong emission lines like Hα or [OII] . However, we do not detect any significant excess of emission line flux over what can be explained by star formation occurring within the host galaxy itself. This result suggests either that there are no TDGs associated with our sample of ULIRGs or that they are too faint and/or too red to be detected using current facilities.",
        "watermark_text": "We present the results of an optical spectroscopic survey aimed at finding tidal dwarf galaxies ( TDGs ) candidates amongst a sample of ultraluminous infrared galaxies ( ULIRG ).We have obtained spectra with FORS2 @ VLT and GMOS - N @ Gemini telescopes, covering the wavelength range between 3600 Å and 9200 Å, for a total of 16 ULIRGs selected on the basis of their high far - infrared luminosity ( L FIR > 10 12 L [UNK] ) and low redshift ( z < 0. 1 ).The main goal is to find TDGs that are anticipated to be found around interacting systems such as ULIRGs.The presence of young stars in these objects would make them detectable through strong emission lines like Hα or [ OII ].However, we do not detect any significant excess of emission line flux over what can be explained by stellar formation happening within the host galaxy itself.This result suggests either that there are no TDGs associated with our sample of ULIRGs or that they are too light and / or too red to be detected using current facilities."
    },
    {
        "original_text": "We study the statistical properties of simulated dark matter halos in cosmological N-body simulations, focusing on their shapes and orientations with respect to each other. We find that these quantities are strongly correlated for pairs of halos separated by less than one virial radius (the region within which the density is roughly constant). This correlation persists even when we consider only those pairs whose mutual separation lies along the line-of-sight between them. The correlations can be understood as arising due to tidal forces exerted by neighboring halos. In particular, we show that the distribution of halo shapes depends sensitively upon whether or not they lie close to an axis of symmetry of the local gravitational potential field. Finally, we compare our results against observations of galaxy clusters obtained using weak lensing techniques. Our analysis suggests that the observed cluster morphologies may provide useful constraints on the nature of primordial fluctuations responsible for structure formation in the universe.",
        "watermark_text": "We study the statistical properties of simulated dark matter halos in cosmological N - body simulations, focusing on their forms and inclinations with respect to each other.We find that these quantities are strongly correlated for pairs of halos separated by less than one virial radius ( the area within which the dense is roughly constant ).This correlation persists even when we consider only those pairs whose mutual separation lies along the line - of - sight between them.The correlations can be understood as arising due to tidal forces exerted by neighbouring halos.In particular, we show that the distribution of halo shapes depends sensitively onto whether or not they lay close to an axis of symmetry of the local gravity potential field.Finally, we compare our results against observations of galaxy clusters obtained using weak lensing techniques.Our analysis suggests that the observed cluster morphologies may provide helpful constraints on the nature of primordial fluctuations responsible for structure formation in the cosmic."
    },
    {
        "original_text": "We propose an algorithm for reconstructing the signaling network in which each node is associated with multiple time series data, and we assume that only some nodes are observed at any given time point. The proposed method consists of two steps: (1) estimating the state vector by solving a sparse reconstruction problem; (2) inferring the edge set using the estimated states as features. We show through numerical experiments on synthetic networks that our approach can accurately recover both the structure and parameters of the underlying network even when only partial information about the system is available. Our results also suggest that the performance of the proposed method depends strongly on how well the sparsity pattern of the true signal is captured by the observation matrix. Finally, we apply this method to analyze the dynamics of protein phosphorylation in yeast cells responding to heat shock stress. In particular, we identify several key proteins involved in regulating the response process. This work was supported by NIH grant R01GM084283-01A1",
        "watermark_text": "We propose an algorithm for reconstructing the signaling network in which each node is affiliated with multiple time series data, and we assume that only some nodes are observed at any given time point.The proposed method consists of two steps : ( 1 ) estimating the state vector by solving a sparse reconstruction problem ; ( 2 ) inferring the edge set using the estimated states as features.We show through numerical experiments on artificial networks that our approach can accurately recover both the structure and parameters of the underlying network even when only partial information about the system is available.Our results also suggest that the performance of the proposed methodology depends strongly on how well the sparsity pattern of the true signal is captured by the observation matrix.Finally, we apply this method to analyze the dynamics of protein phosphorylation in yeast cells responding to heat shock stress.In particular, we identify several key proteins involved in regulating the response process.This work was supported by NIH grant R01GM084283 - 2001A1"
    },
    {
        "original_text": "We propose an algorithm for network tomography that is able to reconstruct the internal structure of a network by using only one-dimensional (1-D) measurements, i.e., link counts between pairs of nodes in the network. The proposed method can be applied to any type of networks and does not require any prior knowledge about their topology or traffic patterns. We show how our approach can be used to estimate the number of active flows at each node as well as the amount of data transmitted over each flow. Our results are validated through extensive simulations performed with real Internet traces. Network tomography has been widely studied during recent years due to its potential applications in many areas such as computer security, quality-of-service provisioning, and traffic engineering [1] . In this context, it consists of estimating some properties of the network's internal state (such as the number of active flows per node or the amount of data transferred along each flow) by observing only external information (i.e., link-level statistics). This problem becomes particularly challenging when dealing with large-scale networks since the number of possible states grows exponentially with the size of the network [2] .\nIn order to overcome these limitations, several approaches have been recently proposed which exploit specific characteristics of the underlying network [3] , e.g., sparsity [4] - [6] , symmetry [7] , or regularity [8] . However, most existing methods assume either complete knowledge of the network topology [9]- [11] or accurate estimates of the traffic matrix [12] - [14] . Unfortunately, both assumptions may not hold in practice [15] , especially if we consider large and/or dynamic networks [16] . For example, in IP-based networks, the exact location of routers cannot always be determined [17] while the traffic matrix is usually unknown [18] . Moreover, even if the network topology were known, collecting all necessary information would still be impractical because of scalability issues [19] . Finally, obtaining accurate estimates of the traffic...",
        "watermark_text": "We propose an algorithm for network tomography that is able to reconstruct the internal structure of a network by utilizing only one - dimension ( 1 - D ) measurements, i. pro., link counts between pairs of nodes in the network.The proposed method can be applied to any type of networks and does not demand any prior knowledge about their topology or travel patterns.We show how our approach can be used to estimate the number of active flows at each node as also as the amount of data transmitted over each flow.Our results are validated through extensive simulations completed with real Internet traces.Network tomography has been widely studied during recent years due to its possible applications in many applications such as computer security, quality - of - service provisioning, and traffic engineering[ 1 ].In this context, it consists of estimating some properties of the network ' s inner state ( such as the number of active flows per node or the amount of data transferred along each transfer ) by observing only outside information ( i. e., link - level statistics ).This problem gets particularly challenging when dealing with large - scale networks since the number of possible states grows exponentially with the size of the network[ 2 ].In order to overcome these limitations, several approaches have been newly proposed which exploit specific characteristics of the underlying network[ 3 ], e. g., sparsity [ 4 ] -[ 6 ], symmetry [ 7 ], or regularity [ 8 ].However, most existing methods assume either full knowledge of the net topology[ 9 ] - [ 11 ] or accurate estimates of the traffic matrix[ 12 ] -[ 14 ].Unfortunately, both assumptions may not hold in practice[ 15 ], especially if we consider large and / or dynamic networks[ 16 ].For example, in IP - based networks, the exact location of routers cannot consistently be determined [ 17 ] while the traffic matrix is usually unknown [ 18 ].Moreover, even if the network topology were known, collecting all necessary information would still be impractical because of scalability issues [ 19 ].Finally, obtaining accurate estimates of the traffic."
    },
    {
        "original_text": "We study anonymity systems that operate over unstructured networks, such as Tor and Mixminion. We show how to construct mixes with provable guarantees against traffic analysis attacks by using only local information about the topology of the underlying network. Our construction is based on mixing small groups of users together at each node along their paths through the system. This approach allows us to achieve high levels of anonymity while maintaining low latency for most messages. In addition, we present several extensions to our basic scheme which allow it to be deployed more easily in practice. Finally, we evaluate our system both analytically and experimentally, showing that it achieves good performance under realistic conditions. Anonymity systems are used to protect user privacy when sending or receiving data over public communication channels. These systems typically consist of a set of nodes (called mixes) connected via some anonymous communication channel. Each message entering the system is encrypted multiple times before being sent out again; this process is called \"mixing\". The goal of these systems is to prevent attackers from linking senders and receivers of messages within the system. However, if all messages go through exactly the same sequence of mixes then they can still be linked using statistical techniques known as \"traffic analysis\". Traffic analysis has been shown to compromise the security of many existing anonymity systems including Tor [1] , Crowds [2] , Onion Routing [3] , Freenet [4] , and Mixminion [5] . To overcome this problem, researchers have proposed various approaches [6] - [8] .\nIn this work, we focus on anonymity systems operating over unstructured networks [9]- [11] . Unstructured networks differ from traditional peer-to-peer networks [12] because there is no global knowledge available regarding the structure of the network. Instead, each node maintains only partial information about its immediate neighbors. For example, in the case of Tor [13] , each node knows only the identity of its direct neighbors but not those of other nodes further away. As another example, in Mixminion [14] , each node knows only whether two given nodes are directly connected or not",
        "watermark_text": "We study anonymity systems that operate over unstructured networks, such as Tor and Mixminion.We show how to construct mixes with provable promises against traffic analysis attacks by using only local information about the topology of the underlying network.Our construction is based on mixing small groups of users together at each node across their paths through the system.This approach allows us to achieve high degrees of anonymity while maintaining low latency for most messages.In addition, we present multiple extensions to our basic scheme which allow it to be deployed more easily in practice.Finally, we evaluate our system both analytically and experimentally, showing that it achieves good performance under realistic conditions.Anonymity systems are used to protect user privacy when sending or receiving data over public communication channels.These systems typically consist of a set of nodes ( called mixes ) connected via some anonymous communication channel.Each message entering the system is encrypted multiple times before being put out again ; this process is called \" mixing \".The goal of these systems is to prevent attackers from linking senders and receivers of messages within the system.However, if all messages go through exactly the same series of mixes then they can still be connected using statistical techniques known as \" traffic analysis \".Traffic analysis has been shown to compromise the security of many existing anonymity systems like Tor [ 1 ], Crowds[ 2 ], Onion Routing[ 3 ], Freenet[ 4 ], and Mixminion[ 5 ].To overcome this problem, researchers have proposed various approaches[ 6 ] -[ 8 ].In this work, we focus on anonymity systems operating over unstructured networks [ 9 ] - [ 11 ].Unstructured networks differ from traditional peer - to - peer ones [ 12 ] because there is no global knowledge available regarding the structure of the network.Instead, each node maintains only partial information about its immediate neighbours.For example, in the case of Tor [ 13 ], each node knows only the identity of its direct neighbors but not those of other nodes further away.As another example, in Mixminion[ 14 ], each node knows only whether two given nodes are direct connected or not"
    },
    {
        "original_text": "We present the first measurement of the gamma-ray emission associated with the hot gas in galaxy clusters using data collected by Fermi Large Area Telescope (LAT). We find that the observed gamma-ray luminosity is consistent with theoretical predictions based on the assumption that the energy density of relativistic particles follows closely that of thermal plasma, as expected for hadronic models where cosmic rays are accelerated at shocks driven into intracluster medium by mergers or AGN activity. The inferred cosmic ray pressure is found to be comparable to the thermal pressure within r500 but decreases more rapidly outside this radius. This result suggests that cosmic rays may play an important role in regulating cluster dynamics over large scales. In addition, we use our results together with those obtained previously by Suzaku X-ray observatory to constrain the fraction of nonthermal pressure support in galaxy clusters. Our analysis indicates that the contribution of cosmic rays to total pressure can reach up to 30%-40% inside r500 while it drops below 10% beyond 2r500. Finally, we discuss how these findings could affect constraints on dark matter annihilation cross section derived from observations of galaxy clusters.",
        "watermark_text": "We present the first measurement of the gamma - ray emission involved with the hot gas in galaxy clusters utilizing data collected by Fermi Large Area Telescope ( LAT ).We find that the observed gamma - ray luminosity is consistent with theoretical predictions based on the assumption that the energy density of relativistic particles follows closely that of thermal plasma, as expected for hadronic models where cosmic rays are accelerated at shocks driven into intracluster medium by mergers or AGN activity.The inferred cosmic ray pressure is found to be comparable to the heat pressure within r500 but decreases more rapidly outside this radius.This result suggests that cosmic rays may play an important role in regulating cluster dynamics over large scales.In addition, we use our results together with those acquired previously by Suzaku X - ray observatory to constrain the fraction of nonthermal pressure support in galaxy clusters.Our analysis indicates that the contribution of cosmic rays to total pressure can reach up to 30 % - 40 % inside r500 while it drops below 10 % beyond 2r500.Finally, we discuss how these discoveries could affect constraints on dark matter annihilation cross sector derived from observations of galaxy clusters."
    },
    {
        "original_text": "We report on the rapid diffusion of dipolar order in liquid crystals, which is responsible for an enhanced nuclear spin-lattice relaxation rate and thus for a higher degree of dynamic nuclear polarization (DNP). The DNP effect was studied by means of electron paramagnetic resonance spectroscopy at X-band frequencies using a home-built high-field spectrometer equipped with a commercial microwave bridge operating at 2.5 GHz. We found that the enhancement factor increases strongly when approaching the nematic-isotropic phase transition temperature TNI = 35 °C. This finding can be explained by assuming that the molecular mobility decreases rapidly as TNI is approached. In addition to this observation we find that the maximum achievable enhancement factor depends critically on the sample geometry. For samples having a thickness d < 1 mm it reaches values up to 100 times larger than those observed for thicker samples. These results are important for future applications of DNP in NMR experiments performed under extreme conditions such as low temperatures or strong magnetic fields.",
        "watermark_text": "We report on the rapid diffusion of dipolar order in liquid crystals, which is responsible for an enhanced nuclear spin - lattice relaxation rate and thus for a higher degree of dynamic nuclear polarization ( DNP ).The DNP effect was studied by means of electron paramagnetic resonance spectroscopy at X - band frequencies using a home - made high - field spectrometer equipped with a commercial microwave bridge operating at two. 5 GHz.We found that the enhancement factor increases strongly when approaching the nematic - isotropic phase transformation temperature TNI = 35 °C.This finding can be explained by assuming that the molecule mobility decreases rapidly as TNI is approached.In addition to this observation we find that the maximum achievable enhancement factor relies critically on the specimen geometry.For samples having a thickness d < 1mm it reaches values up to 100 times larger than those observed for thicker samples.These results are important for future applications of DNP in NMR experiments performed under extreme conditions such as low temperatures or strongly magnetic fields."
    },
    {
        "original_text": "Quantum zero-knowledge proofs are quantum protocols that allow one party to prove knowledge of some secret information without revealing any other information about it.  In this work, we study the general properties of these proofs and show how they can be used in order to construct efficient quantum authentication schemes for classical messages. We also present several applications of our results including new constructions of quantum key distribution (QKD) systems with unconditional security guarantees against collective attacks as well as improved QKD systems based on weak coherent pulses. Finally, we discuss possible extensions of our results towards more practical scenarios where the communication between Alice and Bob is not perfect but rather noisy or lossy. Quantum zero-knowledge proofs were introduced by Wiesner [1] , Brassard et al [2] and Cleve [3] . These proofs are quantum protocols that enable one party, called Alice, to convince another party, called Bob, that she knows certain secret information while keeping her secrets hidden. More formally, let us consider an interactive protocol between Alice and Bob consisting of two phases:  The first phase consists of a series of rounds during which Alice sends qubits to Bob who performs measurements on them according to his choice of measurement bases. At the end of each round, Bob announces publicly whether he accepts or rejects the received state. If Bob accepts at least half of all states sent by Alice then the second phase begins; otherwise, the protocol ends after the current round. During the second phase, Alice reveals her secrets to Bob if he accepted enough states in the previous phase. Otherwise, both parties abort the protocol. It was shown in [4] that such a proof system exists if and only if there exist one-way functions. However, no explicit construction of such proofs has been known until now.",
        "watermark_text": "Quantum zero - knowledge proofs are quantum protocols that allow one party to prove knowing of some hidden information without revealing any other information about it.In this work, we study the general properties of these proofs and show how they can be used in advance to construct efficient quantum authentication systems for classical messages.We also present several applications of our results namely new constructions of quantum key distribution ( QKD ) systems with unconditional security guarantees against collective attacks as also as improved QKD systems based on weak coherent pulses.Finally, we discuss possible extensions of our results towards more practical scenarios where the communication between Alice and Bob is not perfect but rather noise or lossy.Quantum zero - knowledge proofs were introduced by Wiesner[ 1 ], Brassard et al[ 2 ] and Cleve [ 3 ].These proofs are quantum protocols that facilitate one party, called Alice, to convince another party, called Bob, that she knows certain secret information while keeping her secrets hidden.More formally, let us consider an interactive protocol between Alice and Bob consisting of 2 phases : The first phase consists of a sequence of rounds during which Alice sends qubits to Bob who performs measurements on them according to his choosing of measurement bases.At the end of each round, Bob announces publicly whether he agrees or rejects the received state.If Bob accepts at least half of all states sent by Alice then the second stage begins ; otherwise, the protocol ends after the modern round.During the second phase, Alice reveals her secrets to Bob if he accepted sufficient states in the previous phase.Otherwise, both parties abort the protocol.It was shown in [ 4 ] that such a proof system exists if and only if there exist one - day functions.However, no explicitly construction of such proofs has been known until now."
    },
    {
        "original_text": "We present an algorithm for solving the Graph Isomorphism Problem (GIP) based on Quantum Walks and Grover's search algorithm. The proposed method is inspired by the classical algorithms that use random walks, but it uses Grover's operator instead of the Hadamard matrix in order to speed up the process. We show how this new technique can be used to solve GIP with high probability when the number of vertices in both graphs are equal or differ at most one unit. Finally we compare our results against other state-of-the-art methods. In recent years there has been growing interest in developing efficient solutions to problems related to computational complexity theory such as the Graph Isomorphism Problem(GIP). This problem consists of determining whether two given graphs are isomorphic or not; i.e., if they have the same structure regardless of their labels. \n \n Classical approaches to solve GIP usually rely on Random Walks techniques combined with some heuristics. However these methods require exponential time in the worst case scenario. On the other hand, Quantum Algorithms provide polynomial-time solutions to many NP-complete problems including GIP. These algorithms exploit the superposition principle which allows them to explore all possible states simultaneously. For example, Shor's Algorithm solves integer factorization in polynomial time while Grover's Search finds any item within a database in quadratic time.",
        "watermark_text": "We present an algorithm for solving the Graph Isomorphism Problem ( GIP ) based on Quantum Walks and Grover ' s search algorithm.The proposed method is inspired by the classical algorithms that use random walks, but it utilizes Grover ' s operator instead of the Hadamard matrix in order to speed up the process.We show how this new technique can be used to solve GIP with high chance when the number of vertices in both graphs are even or differ at most one unit.Finally we compare our results against other state - of - the - art methods.In recent years there has been growing interest in developing effective solutions to problems related to computational complexity theory such as the Graph Isomorphism Problem ( GIP ).This problem consists of determining whether two given graphs are isomorphic or not ; i. e., if they have the same structure regardless of their labels.Classical approaches to solve GIP usually rely on Random Walks techniques combined with some heuristics.However these methods require exponential time in the worst case scenario.On the other hand, Quantum Algorithms offer polynomial - time solutions to many NP - complete problems including GIP.These algorithms exploit the superposition principle which allows them to explore all possible states concurrently.For example, Shor ' s Algorithm solves integer factorization in polynomial time while Grover ' s Search finds any item within a database in quadratic time."
    },
    {
        "original_text": "The equivalence principle is one of the most important concepts in general relativity, and it states that all physically equivalent solutions to Einstein's field equations are locally indistinguishable.  In this article we show how the concept can be extended to three dimensions by considering two different classes of exact solutions to the vacuum Einstein field equations with cosmological constant.   The first class consists of spatially homogeneous Bianchi type IX models which have been studied extensively over many years as possible candidates for describing our universe at early times when its geometry was close to being flat.   We prove that these models are globally diffeomorphic (homeomorphic) if their spatial volume forms agree up to sign.   ... This article shows how the concept of local physical equivalence between solutions to Einstein's field equation can be extended to three-dimensions. Two different classes of exact solutions are considered; spatially homogeneous Bianchi Type IX models and spherically symmetric Schwarzschild-de Sitter solutions. It is shown that both types of solution are globally diffeomorphic under certain conditions on their respective volume forms.",
        "watermark_text": "The equivalence principle is one of the most significant concepts in general relativity, and it states that all physically equivalent solutions to Einstein ' s field equations are locally indistinguishable.In this article we show how the concept can be extended to 3 dimensions by considering two different classes of exact solutions to the vacuum Einstein field equations with cosmological constant.The first class consists of spatially homogeneous Bianchi type IX models which have been studied extensively over many years as possible candidates for describing our universe at early periods when its geometric was near to being flat.We prove that these models are globally diffeomorphic ( homeomorphic ) if their spatial volume forms agree up to sign..This article shows how the concept of local physical equivalence between solutions to Einstein ' s field equation can be extended to 3 - dimensions.Two different classes of exact solutions are considered ; spatially homogeneous Bianchi Type IX models and spherically symmetric Schwarzschild - de Sitter solutions.It is shown that both types of solution are globally diffeomorphic under certain conditions on their respective volume formations."
    },
    {
        "original_text": "We have carried out an extensive survey for dying radio galaxies at 1.4 GHz using the Australia Telescope Compact Array (ATCA). The sample consists of all known FRII-type radio galaxies with redshifts less than 0.1 and angular extents greater than 10 arcsec, excluding those that are too close to bright background sources or other nearby radio galaxies. We find no evidence for any significant number of such objects within our sample. This is consistent with previous studies which suggest that most radio galaxies die before they can be detected as extended structures on arcminute scales. However we do detect several examples of compact steep spectrum emission associated with previously identified dying radio galaxies. These may represent the final stages of evolution prior to complete cessation of nuclear activity. In addition there appears to be some correlation between the presence of these features and the optical properties of their host galaxies. Finally we present new observations of two well studied dying radio galaxies, 3C31 and NGC315, showing that both continue to evolve over time.",
        "watermark_text": "We have carried out an extensive survey for dying radio galaxies at 1. 4 GHz utilizing the Australia Telescope Compact Array ( ATCA ).The sample consists of all known FRII - type radio galaxies with redshifts less than 0. 1 and angular extents greater than ten arcsec, minus those that are too close to bright background sources or other nearby radio galaxies.We find no proof for any significant number of such objects within our specimen.This is consistent with previous studies which suggest that most radio galaxies decay before they can be detected as extended structures on arcminute scales.However we do detect several examples of compact steep spectral emission involved with previously identified dying radio galaxies.These may represent the final stages of evolution prior to complete cessation of nuclear activity.In addition there appears to be some correlation between the existence of these features and the optical properties of their host galaxies.Finally we present new observations of two well studied dying radio galaxies, 3C31 and NGC315, showing that both continue to evolve over time."
    },
    {
        "original_text": "We study the dynamics of string cosmologies with nontrivial dilaton potentials, focusing on their chaotic behavior. We show that for certain classes of potentials there are regions where trajectories can be trapped by unstable fixed points or periodic orbits. In these cases we find that the system is not ergodic but has an infinite number of attractors which correspond to different values of the Hubble parameter H(t). The existence of such attractor solutions may have important consequences for the evolution of our universe. For example, it could explain why the present value of H(t) differs so much from its initial value at t = 0. It also provides a possible explanation for the observed flatness problem since the volume V (t) grows exponentially fast during inflation while the energy density decreases as 1/V (t).\nThe results presented here were obtained using numerical methods based on the fourth-order Runge-Kutta algorithm combined with Newton's method for finding roots.",
        "watermark_text": "We study the dynamics of string cosmologies with nontrivial dilaton potentials, focusing on their chaotic behavior.We show that for certain classes of potentials there are regions where trajectories can be trapped by unstable fixed points or periodic orbits.In these cases we find that the system is not ergodic but has an infinite number of attractors which relate to different values of the Hubble parameter H ( t ).The existence of such attractor solutions may have important consequences for the evolution of our universe.For example, it could explain why the present value of H ( t ) differs so much from its initial value at t = 0.It also provides a possible explanation for the observed flatness problem since the vol V ( t ) grows exponentially rapidly during inflation while the energy density reduces as 1 / VA ( t ).The results presented here were obtained using numerical techniques based on the fourth - order Runge - Kutta algorithm combined with Newton ' s method for finding roots."
    },
    {
        "original_text": "In this article, we present the pure spinor superfield formalism for superstring theory in ten dimensions and its application to the Green-Schwarz action. We show that the pure spinor superfields are related with the usual superfields by some gauge transformations. The BRST transformation is also introduced as an operator acting on these superfields. In addition, we discuss how to construct the covariant derivatives which act on the superfields. Finally, we give several examples of calculations using our formalism. This work was supported by JSPS KAKENHI Grant Number JP16K05481. 1 Introduction Superstring theories have been studied extensively since they were proposed about thirty years ago [1] . They provide us not only with a consistent quantum gravity but also with various phenomenological models such as D-branes [2] , M-theory [3] , etc.. However, it seems difficult to quantize them exactly because their actions contain infinite number of fields. Therefore, many attempts have been made so far to find suitable formulations for superstrings [4] .\nOne of the most successful approaches is the light-cone formulation [5] - [8] where one can treat all the degrees of freedom at once without any truncation or approximation [9] . Another approach is based on the background field method [10] - [12] . It has been shown recently that both methods lead to equivalent results [13] - [15] . On the other hand, there exists another interesting approach called the pure spinor formalism [16] - [20] . Although it does not seem easy to apply directly to the full string theory [21] , it provides useful information on the structure of superstring theories [22] - [26] .",
        "watermark_text": "In this article, we present the pure spinor superfield formalism for superstring theory in ten dimensions and its application to the Green - Schwarz action.We show that the pure spinor superfields are related with the usual superfields by some gauge transformations.The BRST transformation is also introduced as an operator acting on these superfields.In addition, we discuss how to build the covariant derivatives which act on the superfields.Finally, we give several examples of calculations using our formalism.This work was supported by JSPS KAKENHI Grant Number JP16K05481.1 Introduction Superstring theories have been studied extensively since they were proposed about 30 years ago[ 1 ].They provide us not only with a consistent quantum gravity but also with various phenomenological models such as D - branes [ 2 ], M - theory [ 3 ], etc.However, it seems difficult to quantize them exactly because their actions contain infinite number of fields.Therefore, many attempts have been taken so far to find suitable formulations for superstrings [ 4 ].One of the most successful approaches is the light - cone formulation[ 5 ] -[ 8 ] where one can treat all the degrees of freedom at once without any truncation or approximation [ 9 ].Another approach is based on the background field method [ 10 ] -[ 12 ].It has been shown recently that both methods lead to equivalent results[ 13 ] -[ 15 ].On the other hand, there exists another interesting approach called the pure spinor formalism [ 16 ] - [ 20 ].Although it does not seem easy to apply directly to the full string theorist [ 21 ], it provides useful information on the structure of superstring theories [ 22 ] - [ 26 ]."
    },
    {
        "original_text": "We study numerically and experimentally the dynamics of a liquid droplet bouncing on an inclined plane covered with superhydrophobic coating, which is known to be able to support stable levitation of drops in air.  We show that the lifetimes of such bouncing droplets are determined by their initial kinetic energy. The dependence of the lifetime on this energy can be fitted well using a power law t ~ E0−α where α = 0.5 ± 0.1 for both numerical simulations and experiments. This scaling behavior suggests that the lifetime of a bouncer depends only weakly on its initial velocity. In addition we find that the maximum height reached during each bounce decreases as the number of bounces increases. Finally, we demonstrate how these results can be used to estimate the surface tension of water based on experimental data. Bouncing droplets have been studied extensively over recent years due to their potential applications in microfluidics [1] . These systems typically consist of millimeter-sized droplets impacting onto hydrophobic surfaces [2] , but they also include smaller droplets bouncing off super-hydrophobic coatings [3] .\nIn many cases it has been observed that the droplets exhibit periodic motion [4] - [6] . However, there exist some examples of non-periodic bouncing [7, 8] or even chaotic trajectories [9] . It was shown recently [10] that the lifetimes (i.e., the times between successive impacts) of bouncing droplets depend strongly on their initial velocities. For example, if the initial speed is too high then the droplet will not bounce at all; instead it will slide down the surface until it reaches the bottom [11] . On the other hand, if the initial speed lies below a certain threshold value then the droplet will bounce indefinitely [12] .",
        "watermark_text": "We study numerically and experimentally the dynamics of a liquid droplet bouncing on an inclined plane covered with superhydrophobic coating, which is known to be able to support stable levitation of drops in air.We show that the lifetimes of such bouncing droplets are determined by their early kinetic energy.The dependence of the lifetime on this energy can be fitted well utilizing a power law t ~E0−α where α = 0. 5 ± 0. 1 for both numerical simulations and experiments.This scaling behavior suggests that the lifetime of a bouncer depends only weakly on its early velocity.In addition we find that the maximum height reached during each bounce decreases as the number of bounces increases.Finally, we demonstrate how these results can be used to estimate the surface tension of water based on experiment data.Bouncing droplets have been studied extensively over recent years due to their potential applications in microfluidics[ 1 ].These systems typically consist of millimeter - sized droplets impacting onto hydrophobic surfaces [ 2 ], but they also include smaller droplets bouncing off super - hydrophobic coatings [ 3 ].In many cases it has been observed that the droplets demonstrate periodic motion [ 4 ] -[ 6 ].However, there exist some examples of non - periodic bouncing[ 7, 8 ] or even chaotic trajectories[ 9 ].It was presented recently [ 10 ] that the lifetimes ( i. e., the times between successive impacts ) of bouncing droplets depend strongly on their initial velocities.For example, if the initial speed is too high then the droplet will not bounce at all ; instead it will slide down the surface until it arrives the bottom [ 11 ].On the other hand, if the initial speed lies below a certain threshold level then the droplet will bounce indefinitely [ 12 ]."
    },
    {
        "original_text": "The Chandra X-ray Observatory has observed the supernova remnant (SNR) produced by SN1987A in the Large Magellanic Cloud for over ten years, providing an unprecedented view into this young and energetic object.  The observations have revealed that the blast wave is interacting with dense circumstellar material surrounding the progenitor star at velocities up to 1000 km/sec.  This interaction produces bright knots of emission which are seen as moving outward through the shell of the remnant.  These knots appear to be composed primarily of oxygen-rich ejecta mixed with shocked interstellar gas.  In addition, there appears to be a large amount of hot plasma trapped behind the forward shock front.  We present here new results on these features based on our analysis of data obtained during the first year of the Chandra mission. The Chandra X-ray Observatory has observed  the supernova remnant ( SNR ) produced by SN1987A , in the Large Magellan ic Cloud , for over ten years . It provides an unprecedented view into this y oung and en erg i c obj ect .  T he obse rvations ha ve reve al ed tha t th e b las t wa ve is interactin g wi th d ens e circumstell ar m aterial surroundi ng th e proge nitor star-at-rou nd -velocities up to 1 000 k m/ sec . Thi s interac tion produ ces brigh t kn ots of emi ssion wh ich appea r to be co mp osed pri marily of oxyg ene -rico h ej ec ta mixe d w ith sh ocked int erstel lar ga s .",
        "watermark_text": "The Chandra X - ray Observatory has observed the supernova remnant ( SNR ) produced by SN1987A in the Large Magellanic Cloud for over ten years, providing an unprecedented view into this young and energy object.The observations have revealed that the blast wave is interacting with dense circumstellar material surrounding the progenitor star at velocities up to 1000 km / sec.This interaction produces bright knots of emission which are seen as moving outward through the shell of the remnant.These knots appear to be composed primarily of oxygen - rich ejecta mixed with shocked interstellar gas.In addition, there appears to be a big amount of hot plasma trapped behind the forward shock front.We present here new results on these features based on our analysis of data obtained during the first year of the Chandra mission.The Chandra X - ray Observatory has observed the supernova remnant ( SNR ) produced by SN1987A, in the Large Magellanic Cloud, for over ten years.It provides an unprecedented view into this y oung and en erg i c obj ect.T he obse rvations ha ve reve al edtha t th e b las t wa ve is interactin g withd ens e circumstell ar m aterial surroundi ng th e proge nitor star - at - rou nd - velocities up to 1 000 k m / sec.Thi s interac tion produ ces brigh t kn ots of emi ssion wh ich appea r to be co mp osed pri marily of oxyg ene - ricohej ec ta mixe d w ith sh ocked int erstel lar ga s."
    },
    {
        "original_text": "We present the results for neutrino mixing angles, CP violating phases and mass squared differences obtained by using the Fritzsch ansatz to generate the charged fermion masses within an extended supersymmetric grand unified theory based on SO(10). We find that this model can accommodate all experimental data with only one free parameter which is related to the ratio between the two vacuum expectation values of the Higgs fields responsible for breaking down the Pati-Salam gauge symmetry into the Standard Model gauge group. The CKM matrix elements are predicted as well as the Majorana phase associated with leptonic CP violation. In addition we show how the tri-bimaximal pattern observed experimentally in the lepton sector emerges naturally when the quark-lepton unification hypothesis is imposed at high energies. Finally we discuss briefly some phenomenological consequences of our scenario such as neutrinoless double beta decay and proton decay. PACS numbers: 11.30.Pb, 12.60.Cn",
        "watermark_text": "We present the results for neutrino mixing angles, CP violating phases and mass squared differences obtained by using the Fritzsch ansatz to create the charged fermion masses within an extended supersymmetric grand unified theorist based on SO ( 10 ).We find that this model can accommodate all experimental data with only one free parameter which is related to the ratio between the 2 vacuum expectation values of the Higgs fields responsible for breaking down the Pati - Salam gauge symmetry into the Standard Model model group.The CKM matrix elements are predicted as well as the Majorana phase associated with leptonic c violation.In addition we show how the tri - bimaximal pattern observed experimentally in the lepton sector emerges naturally when the quark - lepton unification hypothesis is imposed at high energies.Finally we discuss briefly some phenomenological consequences of our scenario such as neutrinoless double beta decay and proton degradation.PACS numbers : 11. 30. Pb, 12. 60. Cn"
    },
    {
        "original_text": "We present new astrometric measurements for the candidate exoplanet companion to HD 33636, obtained with the Fine Guidance Sensor (FGS) on board the Hubble Space Telescope (HST). These data are combined with previously published radial velocities in order to determine the mass of this object. We find that it is most likely an M dwarf star with a mass between 0.3 and 1.0 times that of Jupiter's mass. The orbital parameters derived here agree well with those determined by previous authors using different techniques. This system may be similar to our own solar system at early stages of formation when planets were still forming around young stars. Keywords: Extrasolar planet -Astrometry -Radial velocity -HST -Mass determination -HD 33636 . \nIntroduction\n\nThe detection of extrasolar giant planets has been one of the major accomplishments of modern astronomy over the past decade. However, only about 10% of all known planetary systems contain such massive objects. Most of these have been discovered through high-precision Doppler spectroscopy or direct imaging methods. In contrast, very few low-mass companions have been found so far because they produce smaller reflex motions and/or lower luminosity than their more massive counterparts. As a result, there exists a large gap in the distribution of masses among known extra-solar planets ranging from several Earth masses down to Neptune-like masses. It is therefore important to search for low-mass companions as well since they can provide valuable information regarding the formation process of planetary systems. \n \n One possible way to detect low-mass companions is to use high-angular resolution observations made with space-based telescopes like HST. Such observations allow us to measure the position angle of the host star relative to its nearby neighbors. If we assume that the observed motion is due solely to gravitational interaction with another body then we can derive the projected separation and position angle of the companion. By combining these results with accurate radial-velocity measurements taken simultaneously, we can obtain the full three-dimensional orbit of the companion which allows us to calculate its mass.",
        "watermark_text": "We present new astrometric measurements for the candidate exoplanet companion to HD 33636, obtained with the Fine Guidance Sensor ( FGS ) on board the Hubble Space Telescope ( HST ).These data are combined with previously published radial velocities in order to determine the mass of this object.We find that it is most likely an M dwarf star with a mass between zero. 3 and one. 00 times that of Jupiter ' s mass.The orbital parameters derived here agree well with those determined by previous authors utilizing different techniques.This system may be similar to our own solar one at early phases of formation when worlds were still forming around young stars.Keywords : Extrasolar planet - Astrometry - Radial velocity - HST - Mass determination - HD 33636.Introduction The detection of extrasolar giant planets has been 1 of the major accomplishments of modern astronomy over the last decade.However, only about 10 % of all identified planetary systems contain such massive objects.Most of these have been found through high - precision Doppler spectroscopy or direct imaging methods.In contrast, very few low - mass companions have been found so far because they produce smaller reflex motions and / or lower luminosity than their more massive counterparts.As a result, there exists a large gap in the distribution of masses among known extra - solar planets ranging from several Earth masses down to Neptune - like planets.It is therefore important to search for low - mass companions as well since they can provide valuable information regarding the forming process of planet systems.One possible way to detect low - mass companions is to use high - angular resolved observations made with space - based telescopes like HST.Such observations allow us to measure the position angle of the host star relative to its nearby neighbors.If we assume that the observed motion is due solely to gravitational interaction with different body then we can derive the projected separation and position angle of the companion.By combining these results with accurate radial - velocity measurements taken simultaneously, we can obtain the full three - dimensions orbit of the companion which allows us to calculate its mass."
    },
    {
        "original_text": "We present the spectral index distribution (SID) of blazars detected by the Energetic Gamma Ray Experiment Telescope (EGRET). The SID is derived using two different methods, and we find that both give consistent results within statistical errors. We compare our results with those obtained in previous studies based on smaller samples or limited energy ranges. Our sample contains all sources listed as \"blazar candidates\" in the Third EGRET Catalog (3EG), which includes 157 objects. In addition to these 3EG blazars, we include four more BL Lacertae-type objects whose radio properties are similar to those of known blazars but have not been included in any previous study due to their lack of detection at high energies. These additional sources were found through cross-correlation between the Véron-Cetty & Véron catalog of active galactic nuclei and the NRAO VLA Sky Survey. Using this combined sample consisting of 161 blazars, we calculate the fraction of flat-spectrum (FSRQ-like) and steep-spectrum (BL Lac-like) blazars among the total number of blazars observed by EGRET. This fraction depends strongly on the assumed value of the high-energy cutoff E_cutof f . For example, if we assume E_cutof f = 10 GeV, then FSRQ-like blazars constitute about 80% of the entire population; however, if we adopt an extremely low value such as 1 MeV, only 20% of the blazars can be classified as FSRQ-like.",
        "watermark_text": "We present the spectral index distribution ( SID ) of blazars detected by the Energetic Gamma Ray Experimental Telescope ( EGRET ).The SID is derived using 2 different methods, and we find that both give consistent results within statistical mistakes.We compare our results with those obtained in previous studies based on smaller samples or limited energy ranges.Our sample contains all sources listed as \" blazar candidates \" in the Third EGRET Catalog ( 3EG ), which includes 157 objects.In addition to these 3EG blazars, we include four more BL Lacertae - type objects whose radio properties are similar to those of known blazars but have not been included in any previous study due to their lack of detection at high energies.These additional sources were found through cross - correlation between the Véron - Cetty & Véron catalogue of active galactic nuclei and the NRAO VLA Sky Survey.Using this combined sample consisting of 161 blazars, we calculate the fraction of flat - spectrum ( FSRQ - like ) and steep - spectrum ( BL Lac - like ) blazars among the total number of blazars observed by EGRET.This fraction depends strongly on the assumed value of the high - energetic cutoff E _ cutof f.For example, if we assume E _ cutof f = 10 GeV, then FSRQ - like blazars constitute about 80 % of the entire population ; however, if we adopt an extremely low value such as 1 MeV, only 20 % of the blazars can be classified as FSRQ - like."
    },
    {
        "original_text": "The effect of oxygen vacancies (V) on the magnetic properties of titanium dioxide was investigated by using X-ray photoelectron spectroscopy, Mössbauer spectroscopy and magnetization measurements.  The results show that V can induce ferromagnetic ordering at room temperature with an effective moment of 1.6μB per formula unit. This is attributed to the formation of small clusters of V ions which are antiferromagnetically coupled through superexchange interactions between neighboring O-2p orbitals. These findings provide new insights into the origin of ferromagnetism observed in some transition metal oxides. Titanium dioxide has been widely used as photocatalysts for water splitting under visible light irradiation due to its high activity and stability [1] . However, it shows no intrinsic magnetic property because there is only one unpaired electron in each Ti atom [2] , so it cannot be directly applied in spintronic devices such as spin-valve transistors or giant magnetoresistance sensors [3] .\nRecently, several groups have reported that doping TiO2 with non-magnetic elements like Nb [4] , Ta [5] , Zr [6] , Al [7] , Si [8] , Ge [9] , Sn [10] , Sb [11] , W [12] , Mo [13] , Fe [14] , Co [15] , Ni [16] , Cu [17] , Zn [18] , Ga [19] , In [20] , Ag [21] , Au [22] , Pt [23] , Pd [24] , Rh [25] , Ir [26] , Ru [27] , Re [28] , Os [29] , Bi [30] , Y [31] , Gd [32] , Dy [33] , Yb [34] , Er [35] , Nd [36] , Sm [37] , Eu [38] , Tb [39] , Ho [40] , Tm [41] , Lu [42] , Pr [43] , La [44] , Ce [45] , Th [46] , U [47] , Hg [48] , Tl [49] , Pb [50] , Bi [51] , As [52] , Se [53] , Te [54] , S [55] , P [56] , N [57] , F [58] , Cl [59] , Br [60] , I [61] , B [62] , C",
        "watermark_text": "The effect of oxygen vacancies ( V ) on the magnetic properties of titanium dioxide was investigated by using X - ray photoelectron spectroscopy, Mössbauer spectroscopy and magnetization measurements.The results show that V can induce ferromagnetic ordering at room temperature with an effective moment of 1. 6μB per formula unit.This is attributed to the formation of small clusters of V ions which are antiferromagnetically coupled through superexchange interactions between neighboring O - 2p orbitals.These findings provide new insights into the origin of ferromagnetism observed in some transition metal oxides.Titanium dioxide has been widely used as photocatalysts for water splitting under visible light irradiation due to its high action and stability[ 1 ].However, it shows no intrinsic magnetic property because there is only one unpaired electron in each Ti atom[ 2 ], so it cannot be directly applied in spintronic devices such as spin - valve transistors or giant magnetoresistance sensors[ 3 ].Recently, several organizations have reported that doping TiO2 with non - magnetic elements like Nb [ 4 ], Ta [ 5 ], Zr[ 6 ], Al [ 7 ], Si[ 8 ], Ge [ 9 ], Sn[ 10 ], Sb [ 11 ], W[ 12 ], Mo [ 13 ], Fe[ 14 ], Co[ 15 ], Ni[ 16 ], Cu[ 17 ], Zn[ 18 ], Ga[ 19 ], In [ 20 ], Ag[ 21 ], Au[ 22 ], Pt[ 23 ], Pd[ 24 ], Rh[ 25 ], Ir [ 26 ], Ru[ 27 ], Re [ 28 ], Os [ 29 ], Bi[ 30 ], Y[ 31 ], Gd [ 32 ], Dy[ 33 ], Yb[ 34 ], Er[ 35 ], Nd[ 36 ], Sm[ 37 ], Eu[ 38 ], Tb [ 39 ], Ho[ 40 ], Tm [ 41 ], Lu[ 42 ], Pr [ 43 ], La [ 44 ], Ce[ 45 ], Th[ 46 ], U[ 47 ], Hg[ 48 ], Tl[ 49 ], Pb[ 50 ], Bi[ 51 ], As [ 52 ], Se[ 53 ], Te [ 54 ], S [ 55 ], P [ 56 ], N [ 57 ], F [ 58 ], Cl[ 59 ], Br[ 60 ], I [ 61 ], B[ 62 ], C"
    },
    {
        "original_text": "The driving mechanism for jets and outflows is still an open question, especially when the jet/outflow source has no clear central engine such as black holes or protostars. In this work we propose that magnetic reconnection can be responsible for launching jets and outflows in star formation process. We show that magnetic reconnection can accelerate particles to relativistic energies efficiently via Fermi acceleration at shocks driven by the reconnecting current sheet (RCS). The accelerated electrons will produce synchrotron emission which may explain radio observations of jets and outflows. Furthermore, the energetic protons produced during RCS also contribute to nonthermal emissions through inverse Compton scattering with background photons. Finally, we discuss how our model could account for some observational features of jets and outflows. \n \n Keywords: Magnetic reconnection; Jet; Particle acceleration; Shocks; Synchrotron radiation; Nonthermal emission",
        "watermark_text": "The driving mechanism for jets and outflows is still an open question, especially when the jet / outflow source has no clear central engine such as black holes or protostars.In this work we propose that magnetic reconnection can be responsible for launching jets and outflows in stellar formation process.We show that magnetic reconnection can accelerate particles to relativistic energies efficiently via Fermi acceleration at shocks powered by the reconnecting current sheet ( RCS ).The accelerated electrons will produce synchrotron emission which may explain radio observations of jets and outflows.Furthermore, the energetic protons produced during RCS also contribute to nonthermal emissions through inverse Compton scattering with background photons.Finally, we discuss how our model could account for some observational features of jets and outflows.Keywords : Magnetic reconnection ; Jet ; Particle acceleration ; Shocks ; Synchrotron radiation ; Nonthermal emission"
    },
    {
        "original_text": "We present new observations of intervening metal systems at z ~ 1.5-2.0 towards the gamma-ray burst (GRB) 050525A, which is one of only two GRBs with spectroscopic redshifts known to date. We detect absorption lines due to Mg ii λλ2796, 2803, Feii λ2382, 2344+2600, Ciii λ977, Siiv λ1394, 1403, Ovi λ1032, 1038, Nv λ1239, 1243, Lyα, and Lyβ associated with an absorber at z = 2.01 ± 0.02. This system has log NHI/cm−2 = 19.6 +0.2 −0.1 , corresponding to a total hydrogen column density of 5 × 1020 cm−2 . It also shows strong low-ionization transitions such as Al iii λ1854, 1854 + 1862, and S iv λ1063, 1073 that are not seen in typical high-redshift absorbers. These features suggest that this absorber may be similar to those found along quasar sightlines.",
        "watermark_text": "We present fresh observations of intervening metal systems at z ~ 1. 5 - 2. 0 towards the gamma - ray burst ( GRB ) 050525A, which is one of only two GRBs with spectroscopic redshifts known to date.We detect absorption lines due to Mg ii λλ2796, 2803, Feii λ2382, 2344 + 2600, Ciii λ977, Siiv λ1394, 1403, Ovi λ1032, 1038, Nv λ1239, 1243, Lyα, and Lyβ associated with an absorber at z = 2. 01 ± 0. 02.This system has log NHI / cm−2 = 19. 6 + 0. 2 −0. 1, corresponding to a total hydrogen column density of 5 x 1020 cm−2.It also shows powerful low - ionization transitions such as Al iii λ1854, 1854 + 1862, and S iv λ1063, 1073 that are not seen in typical high - redshift absorbers.These features suggest that this absorber may be similar to those found along quasar sightlines."
    },
    {
        "original_text": "We have searched for radio transients with flux densities between 0.1 and 1 mJy at frequencies ranging from 4 to 8 GHz using archival data obtained by the Very Large Array (VLA) over the past 20 years. We find that most of these sources are extragalactic, but we also detect several Galactic objects including pulsars, supernova remnants, and flare stars. The majority of our sample is comprised of previously uncatalogued sources; however, we recover many known variable sources such as blazars and gamma-ray burst afterglows. Our results demonstrate the power of combining large amounts of archival VLA data into one coherent dataset. This work was supported by NSF grant AST-0907860. In this Letter, we present an analysis of all available archived Very Large Array (V LA) observations taken since 1990. These data were collected during various observing programs aimed primarily at studying distant galaxies or nearby star forming regions. However, they contain valuable information about fainter transient phenomena occurring within our Galaxy. By searching through more than 10 000 hours of observation time spread across nearly 2000 epochs, we identify thousands of new faint radio sources which appear only once or twice in each epoch's data set. Most of these sources are extragalaxtic, but we also detect numerous Galactic objects including pulsar wind nebulae, supernova remnants, flare stars, and other types of active galactic nuclei. Many of these newly discovered sources are not included in existing catalogs because their low signal-to-noise ratio makes them difficult to detect when observed individually. However, by combining multiple epochs together, we can boost the sensitivity of our survey enough to detect even very weak signals.",
        "watermark_text": "We have searched for radio transients with flux densities between 0. 1 and 1 mJy at frequencies ranging from four to 8 GHz using archival data obtained by the Very Large Array ( VLA ) over the past 20 years.We find that most of these sources are extragalactic, but we also detect several Galactic items including pulsars, supernova remnants, and flare stars.The majority of our sample is comprised of previously uncatalogued sources ; however, we recover many known variable sources such as blazars and gamma - ray burst afterglows.Our results demonstrate the power of combining large amounts of archival VLA data into one coherent dataset.This work was supported by NSF grant AST - 0907860.In this Letter, we present an analysis of all available archived extremely Large Array ( V LA ) observations taken since 1990.These data were collected during various observing projects aimed primarily at studying distant galaxies or near star forming regions.However, they contain useful information about fainter transient phenomena occurring within our Galaxy.By searching through more than 10 000 hours of observation time spread across nearly 2000 epochs, we identify thousands of new faint radio sources which seem only once or twice in each epoch ' s data set.Most of these sources are extragalaxtic, but we also detect numerous Galactic objects including pulsar wind nebulae, supernova remnants, flare stars, and other types of active galactic nuclei.Many of these newly discovered sources are not included in existing catalogs because their low signal - to - noise ratio makes them difficult to detect when observed individually.However, by combining multiple epochs together, we can boost the sensitivity of our survey enough to spot even very weak signals."
    },
    {
        "original_text": "The fossil record is replete with examples of periodic extinction events, but it has been unclear whether these are driven by external factors or internal dynamics within ecosystems. Here we show that biodiversity cycles can be generated solely through interactions between species and their environment without any need to invoke additional mechanisms such as mass extinctions. We use an agent-based model to simulate how communities evolve over time under different environmental conditions. Our results suggest that biodiversity cycles may have played an important role in shaping Earth's biosphere throughout its history. The fossil record contains numerous examples of periodic extinction events (1), which have led some researchers to propose that there must exist underlying periodicity in ecosystem processes (2). However, it remains unknown what causes this apparent regularity in the fossil record; one possibility is that periods of high diversity alternate with intervals during which many species go extinct simultaneously (3) (4) . In addition, it is not clear if all observed patterns of biodiversity cycling represent true cyclical behavior or simply reflect stochastic variation around a mean value (5-7).\nHere we present evidence suggesting that biodiversity cycles can arise spontaneously from ecological interactions alone, without requiring any additional mechanism like mass extinctions. To test our hypothesis, we used an agent-based model to explore how communities evolve over time when subjected to varying levels of environmental stress. This approach allowed us to examine how changes in community composition affect population abundances across multiple trophic levels. By simulating thousands of replicate runs using different parameter values, we were able to identify robust statistical signatures associated with biodiversity cycles.",
        "watermark_text": "The fossil record is replete with examples of periodic extinction events, but it has been unclear whether these are driven by external factors or internal dynamics within ecosystems.Here we show that biodiversity cycles can be generated solely through interactions between species and their environment without any need to invoke additional mechanisms such as mass extinctions.We use an agent - type model to simulate how communities evolve over time under different environmental conditions.Our results suggest that biodiversity cycles may have played an important role in shaping Earth ' s biosphere across its history.The fossil record contains numerous examples of periodic extinction events ( 1 ), which have led some researchers to propose that there must exist underlying periodicity in ecosystem processes ( 2 ).However, it remains unknown what causes this apparent regularity in the fossil record ; one possibility is that periods of high diversity alternate with intervals during which numerous species go extinct concurrently ( 3 ) ( 4 ).In addition, it is not clear if all observed patterns of biodiversity cycling represent true cyclical behaviour or simply reflect stochastic variation around a mean value ( 5 - 7 ).Here we present evidence suggesting that biodiversity cycles can arise spontaneously from ecological interactions alone, without requiring any additional mechanism like mass extinctions.To test our hypothesis, we used an agent - based model to explore how communities evolve over time when imposed to varying levels of environmental stress.This approach allowed us to examine how changes in community composition affect population abundances across multiple trophic levels.By simulating thousands of replicate runs using different parameter values, we were able to identify robust statistical signatures associated with biodiversity cycles."
    },
    {
        "original_text": "We present new observations of the solar atmosphere obtained with the Solar Ultraviolet Imager (SUVI) onboard the Coriolis satellite, which show dynamic fibrils in both H-alpha and CIV lines. The SUVI data are compared to simultaneous ground-based observations made at Big Bear Observatory using the 1-meter telescope equipped with an H-Alpha filter and a Fabry-Perot interferometer tuned to the CIV line. We find that the observed structures have similar properties as those seen previously by other authors but we also see some differences between them. In particular, our results suggest that the fibril structure is more complex than it was thought before. This complexity may be related to the fact that these structures are formed under different physical conditions. Our analysis shows that the observed features can be explained by assuming that they represent plasma flows along magnetic field lines. These flows could play important role in heating up the upper layers of the solar atmosphere.",
        "watermark_text": "We present new observations of the solar atmosphere obtained with the Solar Ultraviolet Imager ( SUVI ) onboard the Coriolis spacecraft, which show active fibrils in both H - alpha and CIV lines.The SUVI data are compared to simultaneous ground - borne observations made at Big Bear Observatory using the 1 - metre telescope fitted with an H - Alpha filter and a Fabry - Perot interferometer tuned to the CIV line.We find that the observed structures have comparable properties as those seen previously by other writers but we also see some differences between them.In particular, our results suggest that the fibril structure is more complex than it was thought before.This complexity may be related to the fact that these structures are formed under different physical conditions.Our analysis shows that the observed features can be explained by assuming that they represent plasma flows along magnetic field lines.These flows could play important part in heating up the higher layers of the solar atmosphere."
    },
    {
        "original_text": "The PVLAS collaboration has recently reported results on light-by-light scattering in vacuum, which are inconsistent with Standard Model predictions.  In this note we discuss possible interpretations of these data within the framework of quantum field theory and string theory. We argue that the most natural interpretation is to assume that the observed effect arises due to new particles coupling to photons via an effective dimension-8 operator. The required mass scale for such particles can be as low as 10 GeV or even lower if one assumes that they couple only weakly to ordinary matter. If confirmed by further experiments, these observations would have profound implications both for particle physics phenomenology and cosmological models. The PVLAS collaboration has recently announced their measurement of light-by-light scattering in vacuo [1] . This process violates parity conservation at tree level and thus cannot occur in the Standard Model (SM) [2] , but it could arise through loop effects [3] .\nIn particular, the authors report observing a signal consistent with the SM prediction [4] \nwhere G F = 1.1663787(6) × 10−5GeV−2 is Fermi's constant [5] , θ W ≈ 0.23 is the weak mixing angle [6] , m e is the electron mass, and M Pl ≡ 1/ √ 8πG N ≈ 2×10 18 GeV is the reduced Planck mass [7, 8] . However, the measured value of the cross section exceeds the theoretical expectation by more than three standard deviations,\nThis discrepancy between experiment and theory may indicate the presence of new physics beyond the SM [9] .",
        "watermark_text": "The PVLAS collaboration has recently reported results on light - by - light scattering in vacuum, which are inconsistent with Standard Model predictions.In this note we address possible interpretations of these data within the framework of quantum field theory and string theory.We argue that the most natural interpretation is to assume that the observed effect arises owing to new particles coupling to photons via an effective dimensional - 8 operator.The required mass scale for such particles can be as low as 10 GeV or even lower if one assumes that they pair only weakly to ordinary matter.If confirmed by further experiments, these observations would have profound implications both for particle physics phenomenology and cosmological models.The PVLAS collaboration has recently announced their measurement of light - by - light scattering in vacuo [ 1 ].This process violates parity conservation at tree level and thus cannot occur in the Standard Model ( SM )[ 2 ], but it could arise through loop effects [ 3 ].In particular, the authors report observing a signal consistent with the SM forecast [ 4 ] where G F = 1. 1663787 ( 6 )× 10−5GeV−2 is Fermi ' s constant [ 5 ], θ W ≈ 0. 23 is the weak mixing angle[ 6 ], m e is the electron mass, and M Pl ≡ 1 / √ 8πG N≈ 2×10 18 GeV is the reduced Planck mass[ 7, 8 ].However, the measured value of the cross section exceeds the theoretical expectation by more than three standard deviations, The discrepancy between experiment and theoretical may indicate the existence of new physics outside the SM[ 9 ]."
    },
    {
        "original_text": "We consider the effective inverse spectral problems (EISP) associated with rational Lax matrices, which are generalizations of classical EISP in terms of Jacobi matrices. We show that these new EISPs can be reduced to some special cases of classical EISP by using an explicit formula for the coefficients of the characteristic polynomial of a rational matrix. As examples we study two classes of rational Lax matrices: one is related to the Toda lattice hierarchy and another is connected with the modified Volterra lattice hierarchy. In particular, we give a complete description on all solutions of the corresponding EISPs. Finally, as applications of our results, we present several interesting properties about the spectra of these rational Lax matrices. The research was supported by NSFC under Grant No.11571040. Keywords: Effective inverse spectral problem; Rational Lax matrices; Toda lattice hierarchy; Modified Volterra lattice hierarchy",
        "watermark_text": "We consider the effective inverse spectral problems ( EISP ) associated with rational Lax matrices, which are generalizations of classical EISP in terms of Jacobi matrices.We show that these new EISPs can be reduced to some special instances of classical EISP by utilizing an explicit formula for the coefficients of the characteristic polynomial of a rational matrix.As examples we study 2 classes of rational Lax matrices : one is related to the Toda lattice hierarchy and one is connected with the modified Volterra lattice hierarchy.In particular, we give a complete description on all solutions of the corresponding EISPs.Finally, as applications of our results, we present several interesting properties about the spectra of these rational Lax matrices.The research was supported by NSFC under Grant No. 11571040.Keywords : Effective inverse spectral problem ; Rational Lax matrices ; Toda lattice hierarchy ; Modified Volterra lattice hierarchy"
    },
    {
        "original_text": "We show that the ground state wave function for composite fermions in the lowest Landau level is equal to the vacuum expectation value of a correlator of chiral primary fields in N = 2 superconformal Chern-Simons-matter theories with gauge group U(1)Nc−1 and matter content consisting of one hypermultiplet in the fundamental representation, where Nc denotes the number of colors. We also discuss how this result can be used to compute correlation functions of local operators at finite density using supersymmetric localization techniques. The results presented here are based on joint work with Jens Alcaraz-García, Daniel Grumiller, David H. Kaplan, Michael Lüst, and Thomas Schroer. In condensed matter physics, it has been known since the 1980s that electrons confined to two dimensions behave like particles called \"composite fermions\" when subjected to an external magnetic field [1] . These composite fermions form a Fermi sea which exhibits fractional quantum Hall effect (FQHE), i.e., they exhibit plateaus in their Hall conductance at fractions of e/2πh [2] .\nIn recent years there have been several attempts to understand these phenomena within string theory [3, 4, 5, 6, 7, 8] , but so far no complete description exists. One approach consists of studying the low-energy effective action describing the dynamics of the FQH fluid [7, 9] . This action contains a Chern-Simons term coupled to a set of charged scalar fields representing fluctuations around the mean-field solution corresponding to the filled lowest Landau level. It turns out that the resulting system is described by a two-dimensional conformal field theory (CFT). Moreover, the CFT partition function evaluated on a torus coincides with the statistical sum over all states of the FQH fluid [10] .",
        "watermark_text": "We show that the ground state wave function for composite fermions in the lowest Landau level is equal to the vacuum expectation value of a correlator of chiral primary fields in N = 2 superconformal Chern - Simons - matter theories with gauge group U ( 1 ) Nc−1 and matter content consisting of one hypermultiplet in the fundamental representation, where Nc denotes the number of colors.We also discuss how this outcome can be used to compute correlation functions of local operators at finite density using supersymmetric localization techniques.The results presented here are based on joint work with Jens Alcaraz - García, Dan Grumiller, David H. Kaplan, Michael Lüst, and Thomas Schroer.In condensed matter physics, it has been known since the 1980s that electrons confined to 2 dimensions behave resembling particles called \" composite fermions \" when subjected to an external magnetic field [ 1 ].These composite fermions form a Fermi sea which exhibits fractional quantum Hall effect ( FQHE ), i. e., they exhibit plateaus in their Hall conductance at fractions of e / 2πh[ 2 ].In recent years there have been several attempts to understand these phenomena within string theory [ 3, 4, 5, 6, 7, eight ], but so far no complete description exists.One approach consists of studying the low - energy effective act describing the dynamics of the FQH fluid[ 7, 9 ].This action contains a Chern - Simons term coupled to a set of charged scalar fields representing fluctuations round the mean - field solution corresponding to the filled lowest Landau level.It turns out that the resulting system is described by a two - dimension conformal field theory ( CFT ).Moreover, the CFT partition function evaluated on a torus coincides with the statistical sum over all states of the FQH fluid [ 10 ]."
    },
    {
        "original_text": "We study information diffusion on networks with multiple communities, where each community has its own set of nodes and edges. We propose an epidemic model that captures the effect of both global and local interactions between users within different communities. The proposed model is based on two key ideas: (1) we assume that there are some influential individuals who can spread information to their neighbors faster than others; and (2) we allow for cross-influences among neighboring communities through these influential individuals. Our main goal is to understand how the structure of the underlying network affects the spreading process. In particular, our contributions include:  1. We develop a novel mathematical framework to analyze the dynamics of information diffusion under the proposed epidemic model. 2. We show that if all communities have similar sizes then the number of infected nodes at time t grows as O(t log n), where n denotes the total number of nodes in the network. 3. We prove that if one community dominates the other ones by size then the number of infected individuals grows exponentially fast. 4. Finally, we provide extensive numerical experiments to validate our theoretical results.",
        "watermark_text": "We study information diffusion on networks with multiple communities, where each community has its own set of nodes and edges.We propose an epidemic model that captures the effect of both global and local interactions between users within different communities.The proposed model is based on 2 key notions : ( 1 ) we assume that there are some influential individuals who can spread information to their neighbors faster than another ; and ( 2 ) we permit for cross - influences among neighboring communities through these influential individuals.Our main goal is to comprehend how the structure of the underlying network affects the propagation process.In particular, our contributions include : 1.We develop a novel mathematical framework to analyze the dynamics of info diffusion under the proposed epidemic model.2.We show that if all communities have similarly sizes then the number of infected nodes at time t grows as O ( t log n ), where n denotes the total number of nodes in the net.3.We prove that if 1 community dominates the other ones by size then the number of infected individuals grows exponentially fast.4.Finally, we provide extensive numerical experimentation to validate our theoretical results."
    },
    {
        "original_text": "We present the results on the infrared (IR) properties of X-ray selected AGN in the HELLAS2Xray sample, based on observations with the Infrared Array Camera (IRAC; Fazio et al., 2004 ) and Multiband Imaging Photometer for Spitzer (MIPS; Rieke et al., 2004 ) . We find that the IR luminosity is dominated by emission at wavelengths longer than 24 microns, which we interpret as thermal dust emission heated by an active nucleus. This result confirms previous findings obtained using ISO data (e.g. , Rowan-Robinson & Crawford , 1991 ; Haas et al. , 2003 ) , but it also shows that this component can be detected even when the nuclear activity is heavily obscured along our line-of-sight to the central engine. Our analysis indicates that the fraction of absorbed sources increases towards higher redshifts, suggesting that most of these objects are Compton-thick candidates.",
        "watermark_text": "We present the results on the infrared ( IR ) properties of X - ray selected AGN in the HELLAS2Xray sample, based on observations with the Infrared Array Camera ( IRAC ; Fazio et al., 2004 ) and Multiband Imaging Photometer for Spitzer ( MIPS ; Rieke et al., 2004 ).We find that the IR luminosity is dominated by emission at wavelengths farther than 24 microns, which we interpret as thermal dust emission heated by an active nucleus.This result confirms previous findings obtained using ISO data ( e. g., Rowan - Robinson & Crawford, 1991 ; Haas e al., 2003 ), but it also shows that this component can be detected even when the nuclear activity is heavily obscured along our line - of - sight to the central engine.Our analysis indicates that the fraction of absorbed sources increases towards higher redshifts, suggesting that most of these objects are Compton - thick candidates."
    },
    {
        "original_text": "We present the results of an analysis of galaxy cluster data in terms of their gravitational lensing properties and X-ray emission, with particular emphasis on the comparison between observed and predicted values for the mass-to-light ratio M/L. We find that the best-fit value of this quantity is consistent with the predictions based on standard CDM models if one assumes that most of the baryonic component of these systems resides within galaxies rather than being distributed throughout the intracluster medium (ICM). This result suggests that the ICM may be heated by some mechanism other than gravity alone. \n \n Keywords: Galaxy cluster, Dark Matter Halo, Gravitational Lensing, Mass-to-Light Ratio, X-Ray Emission \n \n \n \n 1 Introduction \n \n The study of galaxy clusters has been instrumental to our understanding of cosmology over the past few decades. In fact, it was through observations of galaxy clusters that we first discovered evidence supporting the existence of non-baryonic dark matter [1] . Today, galaxy clusters are still used extensively to test theories about structure formation [2] , and they provide important constraints on cosmological parameters such as the Hubble constant [3] or the equation-of-state parameter w [4] . \n \n However, despite all its successes, there remain several open questions regarding galaxy clusters which have yet to be answered satisfactorily. For example, while current observational techniques allow us to measure accurately the total amount of light emitted by a galaxy cluster, it remains difficult to determine how much of this light comes from stars inside individual galaxies versus diffuse gas located outside them [5] . Similarly, although we can estimate fairly well the total gravitating mass of a galaxy cluster using various methods [6] , it is not clear what fraction of this mass is associated with visible objects like galaxies [7, 8] . Finally, even though we know that galaxy clusters contain large amounts of hot plasma [9] , it is unclear whether this material is gravitationally bound to the system [10] .\n \nIn order to address these issues, we will use two different datasets obtained from the Chandra Observatory [11] : the sample of galaxy clusters studied by Vikhlinin et",
        "watermark_text": "We present the results of an analysis of galaxy cluster data in terms of their gravity lensing properties and X - ray emission, with particular emphasis on the comparison between observed and predicted values for the mass - to - light ratio M / L.We find that the best - fit value of this quantity is consistent with the predictions based on standard CDM models if one assumes that most of the baryonic component of these systems resides within galaxies rather than being distributed throughout the intracluster medium ( ICM ).This result suggests that the ICM may be warmed by some mechanism other than gravity alone.Keywords : Galaxy cluster, Dark Matter Halo, Gravitational Lensing, Mass - to - Light Ratio, X - Ray Emission 1 Introduction The study of galaxy clusters has been instrumental to our understanding of cosmology over the past few decades.In fact, it was through observations of galaxy clusters that we first discovered evidence supporting the presence of non - baryonic dark matter [ 1 ].Today, galaxy clusters are still utilized extensively to test theories about structure formation [ 2 ], and they provide important constraints on cosmological parameters such as the Hubble constant [ 3 ] or the equation - of - state parameter w [ 4 ].However, despite all its successes, there remain several open questions regarding galaxy clusters which have yet to be answered satisfactorily.For example, while current observational techniques allow us to measure accurately the total quantity of light emission by a galaxy cluster, it remains difficult to determine how much of this emission comes from stars inside individual galaxies versus diffuse gas situated outside them [ 5 ].Similarly, although we can estimate fairly well the total gravitating mass of a galaxy cluster using various ways [ 6 ], it is not clear what fraction of this mass is associated with visible objects like galaxies[ 7, 8 ].Finally, even though we know that galaxy clusters contain large amounts of hot plasma [ 9 ], it is unclear whether this material is gravitationally bound to the system[ 10 ].In order to address these issues, we will utilize two different datasets obtained from the Chandra Observatory[ 11 ] : the sample of galaxy clusters studied by Vikhlinin et"
    },
    {
        "original_text": "We report on multiwavelength observations of the X-ray, optical and radio afterglows of the short-hard gamma-ray burst (GRB) 050724 detected by Swift satellite at 07:24:06 UT on 24 July 2005. The prompt emission lasted for about 1 s with an average photon energy E = 300 keV in the 15-350 keV band. We find that the temporal decay index is ~1.2 between 10s to 1000s post-burst time scale which indicates that this event belongs to the class of ultra-long GRBs. In addition we also detect a possible rebrightening feature around 100s post-burst time-scale. Our spectral analysis shows that the spectrum can be fitted well using both single power-law model as well as broken power law model. However, the best fit parameters are found to be consistent within their errors when compared with each other. Using our multi-wavelength data set, we estimate the total energetics associated with this event to be ~3 x 1044 erg.",
        "watermark_text": "We report on multiwavelength observations of the X - ray, optical and radio afterglows of the short - hard gamma - ray burst ( GRB ) 050724 detected by Swift satellite at 07 : 24 : 06 UT on 24 July 2005.The prompt emission lasted for about 1 s with an average photon energetic E = 300 keV in the 15 - 350 keV band.We find that the temporal decay index is ~ 1. 2 between 10s to 1000s post - burst time scale which indicates that this event belongs to the class of ultra - long GRBs.In addition we also detect a potential rebrightening feature around 100s post - burst time - scale.Our spectral analysis shows that the spectrum can be equipped well using both single power - law model as well as broken power law model.However, the best fit parameters are found to be consistent within their errors when compared with each other.Using our multi - wavelength data set, we estimate the total energetics associated with this event to be ~ 3 x 1044 erg."
    },
    {
        "original_text": "The NASA Exoplanet Exploration Program (NExEP) has been tasked with finding Earth-like planets in other solar systems, but how can we find these worlds? The authors present an approach to identifying nearby stars that are similar to our Sun by using data from the Space Interferometry Mission (SIM), which is scheduled to launch in 2009, along with Hipparcos astrometric measurements.  They show that this method will allow us to identify thousands of candidate targets within 25 pc of the Sun where future space missions could search for exoplanets. This white paper was presented at the 2007 International Astronomical Union General Assembly meeting held August 24-30, 2007 in Prague, Czech Republic. The NASA Exoplanet Explorations Program (NExEP)  has been tasked with  finding Earth-like planets in  other solar systems.   How do we find them?  In this white paper,  the authors present an approach to  identifying nearby stars that are  similar to our Sun by  using data from the  Space Interferometry Mission  (SIM),  which is scheduled to launch  in 2009,   along with Hipparcos  astrometric measurements.  They  show that this method will  allow us to  identify thousands of  candidate targets within  25 pc of the Sun   where future space missions  could search for exoplanet",
        "watermark_text": "The NASA Exoplanet Exploration Program ( NExEP ) has been tasked with discovering Earth - like worlds in other sun systems, but how can we find these worlds?The authors present an approach to identifying nearby stars that are similar to our Sun by using data from the Space Interferometry Mission ( SIM ), which is slated to launch in 2009, together with Hipparcos astrometric measurements.They show that this method will allow us to identify thousands of candidate targets within 25 pc of the Sun where future space missions could search for exoplanets.This white paper was presented at the 2007 International Astronomical Union General Assembly assembly held Aug 24 - 30, 07 in Prague, Czech Republic.The NASA Exoplanet Explorations Program ( NExEP ) has been tasked with finding Earth - like planets in other sun systems.How do we find them?In this white paper, the authors present an approach to identifying nearby stars that are similarly to our Sun by using data from the Space Interferometry Mission ( SIM ), which is scheduled to launch in 2009, along with Hipparcos astrometric measurements.They show that this method will allow us to identify thousands of candidate targets within 25 pc of the Sun where future space missions could search for exoplanet"
    },
    {
        "original_text": "We consider the problem of sampling from an arbitrary probability distribution over graphs with fixed number of nodes and edges, where each node has a given degree constraint. We propose a novel algorithm for this task based on the idea of rapidly mixing Markov chains known as Metropolis-Hastings algorithms. Our approach is to use a special type of graph called a tree decomposition which allows us to decompose our original problem into smaller problems in such a way that we can efficiently sample from these smaller problems using existing techniques. In particular, we show how to construct a tree decomposition of any input graph G = (V , E) by first constructing a tree decomposition of its line graph L(G). Then, we prove that if there exists a polynomial time algorithm A that solves one of these small subproblems then it also implies the existence of a polynomial time algorithm B that solves all of them simultaneously. Finally, we present experimental results showing that our proposed method outperforms state-of-the-art methods when applied to several real-world datasets.",
        "watermark_text": "We consider the problem of sampling from an arbitrary probability distribution over graphs with fixed number of nodes and edges, where each node has a given degree constraint.We propose a novel algorithm for this task based on the idea of rapidly mixing Markov chains known as Metropolis - Hastings algorithms.Our approach is to use a special type of graph called a tree decomposition which enables us to decompose our original problem into smaller problems in such a way that we can efficiently sample from these smaller problems using existing techniques.In particular, we show how to build a tree decomposition of any input graph G = ( V, E ) by firstly constructing a tree decomposition of its line matching L ( G ).Then, we prove that if there exists a polynomial timealgorithm A that solves one of these small subproblems then it also implies the existence of a polynomial time algorithm B that solves all of them simultaneously.Finally, we present experimental results showing that our proposed method outperforms state - of - the - art methods when applied to several real - world datasets."
    },
    {
        "original_text": "We report on two new searches for giant planets around young stars using direct imaging at 1.25 mm (L band). The first is an unbiased survey of 23 nearby, low-mass members of the Tucana-Horologium association with ages between 10-50 Myr. We find no evidence for companions down to masses as small as 0.1 M Jup . In addition we present results from a targeted search for companions to three young stars in the Beta Pic Moving Group that are known to harbor debris disks. These targets have ages ranging from 12-30 Myr and were selected because they show signs of youthful activity such as accretion or outflows. No companions were detected within projected separations of 100 AU. Our non-detections suggest that either these systems do not form planetary mass objects beyond 50 AU over this age range, or that any companions formed closer-in but have since been ejected by dynamical interactions.",
        "watermark_text": "We report on two new searches for giant worlds around young stars using direct imaging at 1. 25 mm ( L band ).The first is an unbiased survey of 23 nearby, low - mass members of the Tucana - Horologium association with ages between 10 - 50 Myr.We find no proof for companions down to masses as small as 0. 1 M Jup.In addition we present results from a targeted search for companions to 3 young stars in the Beta Pic Moving Group that are known to harbor debris disks.These targets have ages ranging from 12 - 30 Myr and were selected because they show signs of youthful activity such as accretion or outflows.No companions were detected within projected separations of 100 AU.Our non - detections suggest that either these systems do not form planetary mass objects beyond 50 AU over this age range, or that any companions formed closer - in but have since been ejected by dynamical interactions."
    },
    {
        "original_text": "The lecture notes are available at http://arxiv.org/abs/quant-ph/0405033 . The lecture notes cover the following topics:  - Introduction to quantum information theory and quantum computation - Basic concepts in optics, such as polarization states, coherent light sources etc.  - Single photon sources - Linear optical elements (beam splitters, phase shifters) - Nonlinear optical elements (optical parametric oscillators)  - Entangled photons - Photon detectors - Quantum gates based on linear optics - Quantum gates based on nonlinear optics - Measurement-based quantum computing - Summary of experimental results - References This is an introductory course for students interested in learning about quantum information processing using photonic qubits. It covers basic concepts in optics, single photon sources, linear and nonlinear optical elements, entangled photons, photon detectors, quantum gates based on linear op- tics, quantum gates based on nonlinear op- tics, measurement-based quantum com- puting, and summary of experimen- tal results.",
        "watermark_text": "The lecture notes are available at http : / / arxiv. org / abs / quant - pph / 0405033.The lecture notes cover the following topics : - Introduction to quantum information theory and quantum computation - Basic concepts in optics, such as polarization states, coherent light sources etc. - Single photon sources - Linear optical elements ( beam splitters, phase shifters ) - Nonlinear optical elements ( optical parametric oscillators ) - Entangled photons - Photon detectors - Quantum gates based on linear optics - Quantum gates based on nonlinear optics - Measurement - based quantum computing - Summary of experimental results - References This is an introductory course for students interested in learning about quantum information processing using photonic qubits.It covers basic concepts in optics, single photon sources, linear and nonlinear optical elements, entangled photons, photon detectors, quantum gates based on linear op - tics, quantum gates based on nonlinear op - tics, measurement - based quantum com - puting, and summary of experimen -tal results."
    },
    {
        "original_text": "We present the first results for a new template family, called SEOBNRv4HM, which is designed to detect gravitational waves (GWs) emitted by comparable mass black hole binaries with total masses between 10 and 100 solar masses. We show that this template family can be used in searches for GW signals from binary black holes at current ground-based detectors such as Advanced LIGO/Virgo and KAGRA. In addition we demonstrate how these templates are useful for parameter estimation studies using simulated data sets. Finally, we discuss possible improvements on our work. Keywords: Binary black hole -Gravitational wave detector -Template family -Parameter estimation -SEOBNRv4HM -Advanced Virgo -LIGO -KAGRA -Black hole -Binary system -Gravitational wave signal -Gravitational wave astronomy -Gravitational wave source -Signal-to-noise ratio -Search algorithm -Simulation",
        "watermark_text": "We present the first results for a fresh template family, called SEOBNRv4HM, which is designed to detect gravitational waves ( GWs ) emitted by comparable mass quiet hole binaries with total masses between 10 and 100 sun masses.We show that this template family can be used in searches for GW signals from binary black holes at current ground - based detectors such as Advanced LIGO / Virgo and KAGRA.In addition we demonstrate how these templates are useful for parameter estimation studies using simulated data sets.Finally, we discuss possible improvements on our work.Keywords : Binary black hole - Gravitational wave detector - Template family - Parameter estimation - SEOBNRv4HM - Advanced Virgo - LIGO - KAGRA- Black hole - Binary system - Gravitational wave signal - Gravitational wave astronomy - Gravitational wave source - Signal - to - noise ratio - Search algorithm - Simulation"
    },
    {
        "original_text": "We introduce the concept of generalized conditional random fields (GCRFs) and show how they can be used to model arbitrary probability distributions over structured data sets, such as sequences or trees.  We present an efficient algorithm for learning GCRF parameters using gradient descent on the log-likelihood objective function.   Finally we demonstrate that our approach is able to learn accurate models for several challenging sequence labeling tasks including part-of-speech tagging in natural language processing and protein secondary structure prediction in bioinformatics. Conditional Random Fields (CRFs) (Lafferty et al., 2001 ) are undirected graphical models which have been successfully applied to many problems involving sequential data, e.g. (Sha & Pereira, 2003) . In this work, we propose Generalized Conditional Random Fields (GCRFs), a generalization of CRFs which allows us to represent any distribution over structured data sets like sequences or trees. The key idea behind GCRFs is to use a set of latent variables to capture dependencies between different parts of the input space. This enables us to efficiently compute the partition function required by standard CRFs with dynamic programming techniques. Furthermore, it also makes it possible to train GCRFs using gradient-based methods similar to those employed for Maximum Entropy Markov Models (MEMMs). To evaluate the performance of our method, we apply it to two important applications: part-of-speech taggin",
        "watermark_text": "We introduce the concept of generalized conditional random fields ( GCRFs ) and show how they can be used to model arbitrary probability distributions over structured data sets, such as sequences or trees.We present an efficient algorithm for learning GCRF parameters using gradient descending on the log - likelihood objective function.Finally we demonstrate that our approach is able to learn accuracy models for several challenging sequence labeling tasks like part - of - speech tagging in natural language processing and protein secondary structure prediction in bioinformatics.Conditional Random Fields ( CRFs ) ( Lafferty et al., 2001 ) are undirected graphical models which have been effectively applied to many problems affecting sequential data, e. g. ( Sha & Pereira, 2003 ).In this work, we propose Generalized Conditional Random Fields ( GCRFs ), a generalization of CRFs which allows us to representation any distribution over structured data sets like sequences or trees.The key idea behind GCRFs is to use a set of latent variables to capture dependencies between different parts of the input space.This enables us to efficiently compute the partition function required by standard CRFs with dynamic programming technologies.Furthermore, it also makes it possible to train GCRFs using gradient - based methods similar to those employed for Maximum Entropy Markov Models ( MEMMs ).To evaluate the performance of our method, we apply it to two important applications : part - of - speech taggin"
    },
    {
        "original_text": "We present the first direct determination of the stellar radius in an interacting binary system, using interferometric observations obtained with the VLTI and AMBER instrument. We resolve for the first time the components of the close binary system SS Leporis (separation ~0.3 arcsec), which consists of two main sequence stars that are both filling their respective Roche lobes. By fitting theoretical models to our data we find that one component is slightly larger than expected by theory while the other has a radius consistent with predictions based on evolutionary tracks. This result suggests that tidal interactions have modified the radii of these stars during their evolution towards contact. Our results also show that the orbital inclination angle i = 60 ± 5 degrees, as determined previously through radial velocity measurements, agrees well with our new estimate derived directly from the observed separation between the two stars. Keywords: Interferometry; Binary Stars; Stellar Radius",
        "watermark_text": "We present the first direct determination of the star radius in an interacting binary system, utilizing interferometric observations obtained with the VLTI and AMBER instrument.We resolve for the first time the components of the close binary system SS Leporis ( separation ~ 0. 3 arcsec ), which consists of 2 main sequence stars that are both filling their respective Roche lobes.By fitting theoretical models to our data we find that one component is little larger than expected by model while the other has a radius consistent with expectations based on evolutionary tracks.This result suggests that tidal interactions have modified the radii of these stars during their evolution towards touch.Our results also show that the orbital orientation angle i = 60 ± five degrees, as determined previously through radial velocity observations, agrees well with our new estimate derived directly from the recorded separation between the two stars.Keywords : Interferometry ; Binary Stars ; Stellar Radius"
    },
    {
        "original_text": "The present work is devoted to the study of the relationship between two different approaches to geometric complexity theory, namely the one based on the notion of ``saturated'' problems introduced by Mulmuley et al., and that based on ``positive integer programs'' (PIP) developed by Agrawal et al.. We show how these two notions are related through the concept of ``flip'' which we define as an operation transforming any PIP into its corresponding saturated problem. In particular, this allows us to prove that all known NP-complete problems can be transformed into their equivalent saturated versions using only polynomial-time reductions. Finally, we give some applications of our results to computational commutative algebra and algebraic geometry. The present work was supported by NSF grant DMS-0504520. Geometric complexity theory has been studied extensively over the past decade with many important contributions made both in theoretical computer science and mathematics. One of the main goals of this field is to understand what kind of computational problems have efficient solutions when restricted to certain classes of input objects such as graphs or matrices. A central question here is: What does it mean for a computational problem to have an efficient solution?",
        "watermark_text": "The present work is devoted to the study of the relationship between two different approaches to geometric complexity theory, namely the one based on the notion of ` ` saturated ' ' issues introduced by Mulmuley et al., and that based on ` ` positive integer programs ' ' ( PIP ) developed by Agrawal et al.We show how these two notions are related through the concept of ` ` flip ' ' which we define as an operation transforming any PIP into its corresponding saturated problem.In particular, this allows us to prove that all known NP - complete issues can be transformed into their equivalent saturated versions using only polynomial - time reductions.Finally, we give some applications of our results to computational commutative algebra and algebraic geometry.The present work was supported by NSF grant DMS - 0504520.Geometric complexity theory has been studied extensively over the past decade with many important contributors made both in theoretical computer science and mathematics.One of the main goals of this field is to comprehend what kind of computational problems have efficient answers when restricted to certain classes of input objects such as graphs or matrices.A central question here is : What does it mean for a computational problem to have an efficient solution?"
    },
    {
        "original_text": "We present optical variability measurements for infrared power law-selected galaxies and X-ray sources in the Chandra Deep Field South (CDFS). We use data obtained with the Hubble Space Telescope's Advanced Camera for Surveys to measure photometric redshifts, rest-frame absolute magnitudes, stellar masses, star formation rates, and specific star-formation rates for these objects over an eight-year baseline. The sample consists of 16,000 galaxies at 0 < z < 5 selected by their mid-infrared colors using Spitzer/IRAC observations as well as 1,500 X-ray point sources detected in deep Chandra observations. We find that both galaxy samples show significant levels of intrinsic variation on timescales ranging from days to years. For example, we detect more than 50% of our IRAC-selected galaxies at 3.6 microns and 80% at 4.5 microns showing >0.1 mag variations between epochs separated by one year or less. These results are consistent with previous studies which have found similar levels of variability among optically-selected quasars. However, we also find evidence suggesting that this level of variability is not driven solely by AGN activity but may be associated with other physical processes such as mergers and/or interactions within the host galaxy itself.",
        "watermark_text": "We present optical variability measurements for infrared power law - selected galaxies and X - ray sources in the Chandra Deep Field South ( CDFS ).We utilize data obtained with the Hubble Space Telescope ' s Advanced Camera for Surveys to measure photometric redshifts, rest - frame absolute magnitudes, stellar masses, star formation rates, and specific star - forming rates for these objects over an eight - year baseline.The sample consists of 16, 000 galaxies at 0 0. 1mag variations between epochs separated by one year or less.These results are consistent with previous studies which have found similar levels of variability among optically - chosen quasars.However, we also find evidence suggesting that this degree of variability is not driven solely by AGN activity but may be associated with other physical processes such as mergers and / or interactions inside the host galaxy itself."
    },
    {
        "original_text": "We report on X-ray timing observations of the pulsar candidate PSR J1930+1855 located at the center of the supernova remnant (SNR) G54.1+0. \n \n The source was discovered by Chandra and confirmed as a pulsar with XMM-Newton, but its spin period is not stable over time scales longer than one day. We performed two sets of pointed RXTE observations to study this behavior further. In both cases we found that the pulse frequency decreases smoothly during our observation runs. This trend can be described well using an exponential decay model for which we find characteristic timescales of 1.1 days and 0.7 days respectively. These values are consistent with those reported previously based on Chandra data alone. However, when comparing these results directly it should be noted that the uncertainties associated with the previous measurements were significantly larger due to the lower signal-to-noise ratio achieved with Chandra compared to RXTE.",
        "watermark_text": "We report on X - ray timing observations of the pulsar candidate PSR J1930 + 1855 located at the center of the supernova remnant ( SNR ) G54. 1 + 0.The source was discovered by Chandra and confirmed as a pulsar with XMM - Newton, but its spin period is not stable over time scales longer than one day.We performed 2 sets of pointed RXTE observations to study this behavior further.In both cases we found that the pulse frequency decreases smoothly during our observation runs.This trend can be described well using an exponential decay model for which we find characteristic timescales of 1. 1 days and 0. 7 days respectively.These values are consistent with those reported previously based on Chandra data alone.However, when comparing these outcomes directly it should be noted that the uncertainties involved with the previous measurements were significantly bigger due to the smaller signal - to - noise ratio achieved with Chandra compared to RXTE."
    },
    {
        "original_text": "We present analytic models for the potentials that can produce multiple images in strong gravitational lenses, and we use these to study how well different mass profiles are constrained by observations. We find that it is possible to obtain good constraints on both the total enclosed mass within an Einstein radius (the projected distance at which two images merge) and the slope of the density profile outside this radius using only three or four multiply-imaged systems with accurate photometric redshifts.  The results presented here should be useful for planning future surveys aimed at measuring dark matter properties through gravitational lensing. Gravitational lensing provides one of our most powerful tools for studying the distribution of dark matter in galaxies and clusters. In particular, if a galaxy cluster has been lensed into several distinct images, then the positions and fluxes of those images provide information about the shape of the cluster's gravitational potential as a function of position along its line-of-sight. This allows us to measure the total enclosed mass within some characteristic scale length, such as the Einstein radius, where two images merge together. However, because there are many degeneracies between the parameters describing the lens model, it is not always straightforward to determine what kind of mass profile best describes the data.",
        "watermark_text": "We present analytic models for the potentials that can produce multiple imagery in strong gravitational lenses, and we use these to study how well different mass profiles are constrained by observations.We find that it is possible to obtain good constraints on both the total enclosed mass inside an Einstein radius ( the projected distance at which two images merge ) and the slope of the density profile outside this radius using only three or 4 multiply - imaged systems with accurate photometric redshifts.The results presented here should be useful for planning future surveys aimed at measuring dark matter properties through gravity lensing.Gravitational lensing provides one of our most powerful tools for studying the distribution of dark matter in galaxies and clusters.In particular, if a galaxy cluster has been lensed into several distinct imagery, then the positions and fluxes of those imagery provide information about the shape of the cluster ' s gravity potential as a function of position along its line - of - sight.This allows us to measure the total enclosed mass inside some characteristic scale long, such as the Einstein radius, where 2 images merge together.However, because there are many degeneracies between the parameters describing the lens model, it is not always straightforward to determine what kind of mass profile best describes the data."
    },
    {
        "original_text": "We report the observation of magnetic fluctuations at low temperatures and high fields in single crystals of YBa2Cu3O6+x (YBCO) with x=0.4, 0.45, and 0.5 using muon spin relaxation measurements. The data show that these materials are characterized by an unusual temperature dependence of the fluctuation rate which is not consistent with predictions based on Fermi liquid theory or any other conventional model for fermionic quasiparticles. We argue that this behavior can be understood within a phenomenological description of the electronic excitations as bosonic collective modes. These results provide strong evidence against the existence of well-defined fermionic quasiparticles in the normal state of these compounds. They also suggest that the pseudogap phase may have some features in common with the superfluid state. \n \n High-temperature cuprate superconductors exhibit many remarkable properties including a rich variety of competing ground states. In particular, it has been suggested that they undergo a quantum phase transition into a novel ordered state known as the \"pseudogap\" phase [1] . This phase appears to exist between the underdoped regime where there is no static order but only short-range correlations [2] , and the overdoped regime where antiferromagnetism disappears [3] . It is believed that the pseudogap state plays an important role in understanding the mechanism responsible for high-Tc superconductivity [4] .\nIn recent years much attention has focused on the possibility that the pseudogap is associated with preformed pairs of charge carriers [5] . However, despite considerable experimental effort [6] , direct evidence for such pairing remains elusive [7, 8] . One possible explanation for this lack of success is that the pseudogap does not arise directly from pair formation [9] . Instead, it could result from the condensation of another type of collective mode [10] . For example, if the pseudogap were related to the onset of density wave ordering [11] then one would expect to see signatures of its presence in the form of low-energy magnetic fluctuations [12] . Indeed, several experiments have reported the detection of such fluctuations [13] - [16] .",
        "watermark_text": "We report the observation of magnetic fluctuations at low temperatures and high fields in single crystals of YBa2Cu3O6 + x ( YBCO ) with x = 0. 4, zero. 45, and 0. 5 using muon spin relaxation measurements.The data show that these materials are characterized by an unusual temperature dependence of the fluctuation rate which is not consistent with predictions based on Fermi fluid theory or any other conventional model for fiermionic quasiparticles.We argue that this behaviour can be understood within a phenomenological description of the electronic excitations as bosonic collective modes.These results provide strong evidence against the presence of well - defined fermionic quasiparticles in the normal state of these compounds.They also suggest that the pseudogap stage may have some features in common with the superfluid state.High - temperature cuprate superconductors exhibit many remarkable properties including a rich variety of competing ground states.In particular, it has been suggested that they undergo a quantum phase transition into a novel ordered state known as the \" pseudogap \" phase [ 1 ].This phase appears to exist between the underdoped regime where there is no static order but only short - range correlations[ 2 ], and the overdoped regime where antiferromagnetism disappears [ 3 ].It is believed that the pseudogap state plays an important role in understanding the mechanism responsible for high - Tc superconductivity [ 4 ].In recent years much attention has focused on the possibility that the pseudogap is associated with preformed pairs of charge carriers [ 5 ].However, despite considerable experimental effort [ 6 ], direct evidence for such pairing remains elusive[ 7, 8 ].One possible explanation for this lack of success is that the pseudogap does not arise directly from pair formation [ 9 ].Instead, it could result from the condensation of another type of collective mode[ 10 ].For example, if the pseudogap were related to the onset of dense wave ordering [ 11 ] then one would expect to see signatures of its existence in the form of low - energy magnetic fluctuations [ 12 ].Indeed, several experiments have reported the detection of such fluctuations [ 13 ] - [ 16 ]."
    },
    {
        "original_text": "The aim of this work is to present the results obtained by applying the method of R-matrix theory for solving problems related with scattering processes on complex systems, such as atomic nuclei and molecules. The main idea behind the approach presented here consists in using an effective interaction potential which takes into account all possible interactions between particles involved in the process under consideration. This allows one to obtain solutions that are valid at any distance between interacting objects. In particular we have applied our formalism to study elastic electron-atom collisions within the framework of the Born approximation. We show how it can be used to calculate cross sections for different types of atoms (hydrogen-like ions) and compare them with those calculated within other approaches. \n \n Keywords: Elastic Scattering, Cross Section, Electron Atom Collision, R-Matrix Theory, Effective Interaction Potential, Hydrogen-Like Ions. 1 Introduction \n \n The problem of calculating cross section for elastic electron-atom collision has been studied extensively during last decades both theoretically and experimentally [1] . It was shown [2] , however, that even if the exact wave function describing the system is known, the calculation of the corresponding cross section requires very complicated numerical procedures. Therefore various approximate methods were developed [3] - [6] . Among these approximations the most popular ones are: the first Born approximation [7] , the second Born approximation [8] , the distorted-wave Born approximation [9] , the Kohn variational principle [10] , etc.. All these methods allow one to find analytical expressions for the total cross section but they require some additional assumptions about the form of the wave functions or potentials describing the system under investigation. For example, in order to apply the first Born approximation one needs to know the exact solution of Schrödinger equation for the initial state of the system while the second Born approximation requires knowledge of the exact wave function for final states only [11] . On the other hand, the distorted-wave Born",
        "watermark_text": "The aim of this work is to present the results obtained by applying the method of R - matrix theory for solving problems related with scattering processes on complex systems, such as atomic nuclei and molecules.The main idea behind the approach presented here consists in utilizing an efficient interaction potential which takes into mention all potential interactions between particles involved in the process under consider.This allows one to obtain solutions that are valid at any distance between interacting objects.In particular we have applied our formalism to research elastic electron - atom collisions within the framework of the Born approximation.We show how it can be used to calculate cross sections for different types of atoms ( hydrogen - like ions ) and compare them with those calculated within other approaches.Keywords : Elastic Scattering, Cross Section, Electron Atom Collision, R - Matrix Theory, Effective Interaction Potential, Hydrogen - Like Ions.1Introduction The problem of calculating cross section for elastic electron - atom collision has been studied extensively during last decades both theoretically and experimentally [ 1 ].It was shown [ 2 ], however, that even if the exact wave function describing the system is known, the calculation of the corresponding cross section requires very complicated numerical procedures.Therefore various approximate methods were developed [ 3 ] - [ 6 ].Among these approximations the most popular ones are : the first Born approximation[ 7 ], the second Born approximation[ 8 ], the distorted - wave Born approximation[ 9 ], the Kohn variational principle[ 10 ], etc.All these techniques allow one to find analytical expressions for the total cross section but they require some additional assumptions about the form of the wave functions or potentials describing the system under investigation.For example, in order to apply the first Born approximation one needs to know the precise solution of Schrödinger equation for the early state of the system while the second Born approximation requires knowledge of the precise wave function for final states only [ 11 ].On the other hand, the distorted - wave Born"
    },
    {
        "original_text": "We present an approach to quantify the evolutionary dynamics of social groups, based on their internal structure and interactions with other groups. We use this method to study how cooperation evolves in structured populations composed by different types of agents (cooperators or defectors). Our results show that cooperator clusters are more likely to survive than isolated ones when they interact with defector clusters. This effect is stronger for larger cluster sizes. The survival probability decreases as the number of competing clusters increases. Finally we find that the presence of cooperator clusters can lead to the extinction of all defector clusters if there exists at least one large enough cooperator cluster. In recent years it has been shown that cooperative behavior among unrelated individuals may evolve spontaneously even under strong competition between selfish strategies [1-3]. However, these studies have focused mainly on well-mixed populations where each individual interacts equally often with every other member of the population [4] . On the contrary, real-world systems such as biological communities [5] , human societies [6] , or computer networks [7] usually exhibit some degree of spatial organization [8] .\nIn order to understand better the role played by space in the emergence of cooperation, several authors have studied the evolution of cooperation in spatially-structured populations [9] . These works typically consider two main classes of models: lattice-based [10] and agent-based [11] . Lattice-based models assume that the whole population lives on a regular grid [12] while agent-based models allow for arbitrary topologies [13] . Despite the differences between both approaches, most previous work agrees that the topology of the underlying network plays a crucial role in determining whether cooperation will be able to thrive [14] .",
        "watermark_text": "We present an approach to quantify the evolutionary dynamics of social groups, based on their internal structure and interactions with other entities.We use this method to study how cooperation evolves in structured populations composed by different kinds of agents ( cooperators or defectors ).Our results show that cooperator clusters are more likely to survive than isolated ones when they interact with defector ones.This effect is stronger for larger cluster sizes.The survival likelihood decreases as the number of competing clusters increases.Finally we find that the presence of cooperator clusters can lead to the extinction of all defector clusters if there exists at greatest one big enough cooperator cluster.In recent years it has been shown that collaborative behavior among unrelated individuals may evolve spontaneously even under strong competition between selfish strategies [ 1 - 3 ].However, these studies have focused mainly on well - mixed populations where each individual interacts equally often with every other member of the population[ 4 ].On the contrary, real - world systems such as biological communities [ 5 ], human societies [ 6 ], or computer networks [ seven ] usually exhibit some degree of spatial organization[ 8 ].In order to understand better the part played by space in the emergence of cooperation, several authors have studied the evolution of cooperation in spatially - structured populations [ 9 ].These works typically consider two main classes of models : lattice - based [ 10 ] and agent - based [ eleven ].Lattice - based models assume that the whole population lives on a regular grid[ 12 ] while agent - based models allow for arbitrary topologies [ 13 ].Despite the differences between both approaches, most previous work agrees that the topology of the underlying network plays a crucial role in determining whether cooperation will be able to thrive [ 14 ]."
    },
    {
        "original_text": "We present results on the direct measurement of interfacial tension between two coexisting phases in a model system consisting of freely-jointed tangent hard-sphere chains (FJTHSC). The FJTHSC are modeled by an off-lattice Monte Carlo algorithm that allows us to study systems with up to N = 1000 particles at temperatures ranging from T = 0.5 to 1.0 and densities ranging from ρ = 0.6 to 0.8. We find that the interfacial tension is strongly dependent upon temperature, density, chain length, and bond angle distribution. In particular we show how the interfacial tension can be used as a probe into the local structure near interfaces. \n \n Keywords: Interfacial tension, Computer simulations, Hard spheres, Chain molecules, Phase separation, Structure factor, Bond angle distribution, Local order parameter, Order-disorder transition, Freely-jointed",
        "watermark_text": "We present results on the direct measurement of interfacial tension between 2 coexisting phases in a model system consisting of freely - jointed tangent hard - sphere chains ( FJTHSC ).The FJTHSC are modeled by an off - lattice Monte Carlo algorithm that allows us to study systems with up to N = 1000 particles at temperatures ranging from T = 0. 5 to 1. 0 and densities ranging from ρ = 0. 6 to 0. 8.We find that the interfacial tension is strongly dependent upon temperature, density, chain long, and bond angle spread.In particular we show how the interfacial tension can be used as a probe into the local structure near interfaces.Keywords : Interfacial tension, Computer simulations, Hard spheres, Chain molecules, Phase separation, Structure factor, Bond angle distribution, Local order parameter, Order - disorder transition, Freely - jointed"
    },
    {
        "original_text": "We consider sparse multipath channels with random delays, where each path is modeled as an independent Rayleigh fading channel. We derive exact expressions for ergodic capacity and outage probability over such channels under wideband regime (i.e., when bandwidth grows without bound). Our results show that both ergodic capacity and outages are determined by the number of paths N , their average power Pn = E{|hn(t)|2}, and delay spread T . In particular, we find that ergodic capacity scales linearly with bandwidth W at high SNR if N > 2W/πT or N < πT /4W; otherwise it saturates to a constant value. Moreover, our analysis shows that outage probability decays exponentially fast with increasing bandwidth W if N > 4W/πT ; otherwise it decreases only polynomially. Finally, numerical examples illustrate how these scaling laws depend on various system parameters.",
        "watermark_text": "We consider sparse multipath channels with random delays, where each path is modeled as an independent Rayleigh fading channel.We derive exact expressions for ergodic capacity and outage likelihood over such channels under wideband regime ( i. e., when bandwidth grows without bound ).Our results show that both ergodic capacity and outages are determined by the number of pathways N, their average power Pn = E { | hn ( t ) | 2 }, and delay distribution T.In particular, we find that ergodic capacity scales linearly with bandwidth W at height SNR if N > 2W / πT or N 4W / πT ; otherwise it decreases only polynomially.Finally, numerical examples illustrate how these scaling laws depend on various system parameters."
    },
    {
        "original_text": "We present the results of an X-ray study of supernova remnant (SNR) G299.2-2.9 using data obtained with Chandra and XMM-Newton observatories. The SNR is located in the constellation Puppis at a distance of ~5 kpc, which corresponds to its angular size of about 30 arcmin. We find that the spectrum of this object can be described by two thermal components with temperatures T1=7×10^6 K and T2=2×10^6 K. In addition, we detect non-thermal emission above 10 keV. Using these parameters, we estimate the age of the SNR as t=4000 yr. This value agrees well with the characteristic time for the expansion of the shell into the surrounding medium. Based on our analysis, we conclude that the observed morphology of the SNR is consistent with the model of a spherical explosion expanding into a uniform interstellar medium.",
        "watermark_text": "We present the results of an X - ray study of supernova remnant ( SNR ) G299. 2 - 2. 9 using data obtained with Chandra and XMM - Newton observatories.The SNR is located in the constellation Puppis at a distance of ~ 5 kpc, which corresponds to its angular size of about 30 arcmin.We find that the spectrum of this object can be described by 2 thermal components with heat T1 = 7×10 ^ 6 K and T2 = 2×10 ^ six K.In addition, we detect non - thermal emission above 10 keV. Using these parameters, we estimate the era of the SNR as t = 4000 yr.This value agrees well with the characteristic time for the expansion of the shell into the surrounding medium.Based on our analysis, we conclude that the observed morphology of the SNR is consistent with the model of a spherical explosion expansion into a uniform interstellar medium."
    },
    {
        "original_text": "Network on chip (NoC) is an emerging interconnection paradigm to interconnect large number of processing elements in parallel computing systems. NoCs are expected to be the dominant communication infrastructure in future multi-core and many-core processors, which will require high bandwidth and low latency communications between cores. However, traditional electrical NoCs suffer from power consumption issues due to their limited scalability with increasing core count. In this work we propose a novel bio-inspired optical NoC architecture that can provide higher bandwidth at lower energy cost than conventional electrical NoCs. The proposed NoC consists of two main components; photonic routers and optoelectronic transceivers. Photonic routers use silicon photonics technology to route data packets through multiple channels simultaneously using wavelength division multiplexing technique. Optoelectronic transceiver uses vertical-cavity surface-emitting laser diodes as transmitters and avalanche photo-diode detectors as receivers. We have developed a detailed simulation model based on SystemC to evaluate performance characteristics such as packet delay, throughput and power dissipation of our proposed NoC design. Our results show that the proposed NoC outperforms existing electrical NoCs by providing up to four times higher bandwidth per unit area while consuming less power. \n \n Keywords: Optical network on chip, Silicon photonics",
        "watermark_text": "Network on chip ( NoC ) is an emerging interconnection paradigm to interconnect large number of processing entities in parallel computing systems.NoCs are expected to be the dominant communication infrastructure in future multi - core and many - core processors, which will require high bandwidth and low latency communications between cores.However, traditional electrical NoCs lose from power consumption issues due to their limited scalability with increasing core count.In this work we propose a novel bio - inspired optical NoC architecture that can provide higher bandwidth at lower energy cost than conventional electrical NoCs.The proposed NoC consists of two main components ; photonic routers and optoelectronic transceivers.Photonic routers use silicon photonics technology to route data packets through multiple channels concurrently using wavelength divided multiplexing technique.Optoelectronic transceiver uses vertical - cavity surface - emitting laser diodes as transmitters and avalanche photo - diode detections as receivers.We have developed a detailed simulation model based on SystemC to evaluate performance characteristics such as packet delay, throughput and power dissipation of our proposed NoC design.Our results show that the proposed NoC outperforms existing electrical NoCs by offering up to four times higher bandwidth per unit area while consuming less power.Keywords : Optical network on chip, Silicon photonics"
    },
    {
        "original_text": "We study the elasticity of thin films with periodic microstructure, which are constrained to lie on an underlying substrate. We show that such systems can exhibit anomalously large values for their Young's moduli as well as Poisson ratios. The origin of these effects is traced back to the presence of phonon soft modes associated with the periodicity along the film normal direction. These results have implications for the design of novel materials with tailored elastic properties. \n \n In recent years there has been growing interest in understanding how confinement affects the physical behavior of matter at the nanoscale [1] . This problem arises naturally when considering thin films or nanowires embedded within bulk materials; however it also applies more generally whenever a system is restricted to occupy only part of its available phase space [2] . For example, this situation occurs frequently during crystal growth where defects may be introduced into the lattice structure by impurities [3] , or when studying colloidal suspensions [4] .\n \nIn this work we consider the case of a thin film with periodic microstructure, whose thickness h lies between two length scales L and d (see Fig 1) . Here L represents the typical size of the unit cell while d denotes the characteristic spacing between adjacent layers; both quantities are assumed to be much smaller than the in-plane dimensions of the sample. Such structures arise commonly in nature, e.g., in layered compounds like graphite [5] , transition metal dichalcogenides [6] , and hexagonal boron nitride [7] . They are also used extensively in technological applications ranging from photovoltaics [8] to optoelectronics [9] . \n \n Figure 1: Schematic illustration of our model geometry. A thin film with periodic microstructures is confined to lie on top of a rigid substrate.",
        "watermark_text": "We study the elasticity of thin films with periodic microstructure, which are constrained to lie on an embedded substrate.We show that such systems can manifest anomalously large values for their Young ' s moduli as well as Poisson ratios.The origin of these effects is traced back to the presence of phonon soft modes affiliated with the periodicity along the film normal direction.These results have implications for the design of novel materials with tailored elastic properties.In recent years there has been growing interest in understanding how confinement affects the physical behavior of material at the nanoscale[ 1 ].This problem arises naturally when thinking thin films or nanowires embedded inside bulk materials ; however it still applies more broadly whenever a system is limited to occupy only part of its available phase space[ 2 ].For example, this situation occurs frequently during crystal growth where faults may be introduced into the lattice structure by impurities [ 3 ], or when studying colloidal suspensions [ 4 ].In this work we consider the case of a thin film with periodic microstructure, whose thickness h lies between 2 length scales L and d ( see Fig 1 ).Here L represents the typical size of the unit cell while d denotes the characteristic spacing between adjacent layers ; both amounts are assumed to be much smaller than the in - plane dimensions of the sample.Such structures arise commonly in nature, e. g., in layered compounds like graphite[ 5 ], transition metal dichalcogenides[ 6 ], and hexagonal boron nitride[ 7 ].They are also used extensively in technological applications ranging from photovoltaics [ 8 ] to optoelectronics [ nine ].Figure 1 : Schematic illustration of our model geometry.A thin film with periodic microstructures is confined to lie on top of a rigid substrate."
    },
    {
        "original_text": "The collision between the Milky Way and its nearest neighbor, M31 (Andromeda), is predicted to occur in about 4 billion years.  This will be one of the most spectacular events ever witnessed by humans.   In this talk I will describe how we can use observations made with telescopes on Earth as well as space-based observatories such as Hubble Space Telescope to study these collisions and learn more about dark matter, galaxies, stars, black holes, and other cosmic phenomena that are part of our universe. I will also discuss some of my research projects related to studying galaxy mergers using data obtained at the W.M. Keck Observatory located on Mauna Kea, Hawaii. Finally, I'll share what it was like for me to work there during my summer internship last year. Keywords: Dark Matter, Galaxy merger, Black Hole, Cosmic Evolution, Cosmology, Astrophysics",
        "watermark_text": "The collision between the Milky Way and its nearest neighbor, M31 ( Andromeda ), is predicted to happen in about 4 billion periods.This will be one of the most spectacular events ever witnessed by humans.In this talk I will describe how we can use observations made with telescopes on Earth as well as space - based observatories such as Hubble Space Telescope to study these collisions and know more about dark matter, galaxies, stars, black holes, and other cosmic phenomena that are part of our universe.I will also discuss some of my research projects related to studying galaxy mergers using data obtained at the W. M. Keck Observatory located on Mauna Kea, Hawaii.Finally, I ' ll share what it was like for me to work there during my summer internship last year.Keywords : Dark Matter, Galaxy merger, Black Hole, Cosmic Evolution, Cosmology, Astrophysics"
    },
    {
        "original_text": "We present surface brightness profiles (SBPs) for a sample of globular clusters in the Large Magellanic Cloud (LMC), Small Magellanic Cloud (SMC) and Fornax galaxies obtained with the Hubble Space Telescope Advanced Camera for Surveys Wide Field Channel (ACS/WFC). The SBPs are derived using archival data taken as part of the ACS Nearby Galaxy Survey Treasury program. We use these new observations to investigate whether there is any difference between the SBPs of globular cluster systems belonging to different host galaxies. In addition we compare our results with those previously published by other authors who have studied similar samples of globular clusters. Our main conclusions are:  1. There appears to be no significant differences between the SBPs of the three different types of globular clusters that were observed.  2. The majority of the globular clusters appear to follow an exponential profile which can be described by: I(r) = Ie exp[-(r/rc)] where rc ~ 0.5 pc.",
        "watermark_text": "We present surface brightness profiles ( SBPs ) for a sample of globular clusters in the Large Magellanic Cloud ( LMC ), Small Magellanic Cloud ( SMC ) and Fornax galaxies obtained with the Hubble Space Telescope Advanced Camera for Surveys Wide Field Channel ( ACS / WFC ).The SBPs are derived utilizing archival data taken as part of the ACS Nearby Galaxy Survey Treasury programme.We use these new observations to investigate whether there is any differential between the SBPs of globular cluster systems belonging to various host galaxies.In addition we compare our results with those previously published by other authors who have studied similar samples of globular clusters.Our main conclusions are : 1.There appears to be no significant differences between the SBPs of the three different types of globular clusters that were observed.2.The majority of the globular clusters appear to repeat an exponential profile which can be described by : I ( r )= Ie exp [ - ( r / rc ) ] where rc ~ 0. 5 pc."
    },
    {
        "original_text": "We report on the discovery of an unexpected ring-like dark matter structure at the center of galaxy cluster CL0024+17, which is located about 3 billion light years away and has been studied extensively by many observational techniques including gravitational lensing.  The mass distribution inferred from strong gravitational lensing shows that there are two massive subclusters separated by 1 Mpc (3 arcmin) with a total mass of 2 x 10 15 h-1M_sun within a radius of 0.5h-1Mpc around their centers. We find that this double-cluster system can be well described as a binary merger model where each component consists of three components; one main halo and two smaller halos surrounding it. In addition to these six clusters, we also detect another small clump of galaxies near the center of the merging system whose position coincides with the peak of X-ray emission detected by Chandra satellite observations.",
        "watermark_text": "We report on the discovery of an unexpected ring - like dark matter structure at the center of galaxy cluster CL0024 + 17, which is located about three billion light years away and has been studied extensively by many observational techniques including gravitational lensing.The mass distribution inferred from strong gravitational lensing shows that there are two massive subclusters separated by one Mpc ( 3 arcmin ) with a total mass of two x 10 15 h - oneM _ sun within a radius of 0. 5h - oneMpc around their centers.We find that this double - cluster system can be well described as a binary merger model where each constituent consists of three components ; one main halo and two smaller halos surrounding it.In addition to these six clusters, we also detect another small clump of galaxies near the center of the merging system whose position coincides with the peak of X - ray emission detected by Chandra satellite observations."
    },
    {
        "original_text": "We report on high-resolution observations with Herschel PACS (Poglitsch et al., 2010) and SPIRE (Griffin et al., 2010 ) that reveal for the first time the presence of cold dust emission at temperatures as low as T = 20 K in two nearby ultraluminous infrared galaxies (ULIRGs), Arp220 and Mrk 231. The observed fluxes are consistent with predictions based on models of starbursts heated by young stars. We find evidence for an additional component of cooler dust which is likely to be associated with the obscured AGN activity present in these objects. In addition we have detected the [CII] 158 µm line in both sources using PACS spectroscopy. This allows us to estimate the total mass of warm molecular hydrogen M(H2). For Arp 220 this amounts to 1.5 x 10^9 solar masses within a radius of 100 pc around the nucleus.",
        "watermark_text": "We report on high - resolution observations with Herschel PACS ( Poglitsch et al., 2010 ) and SPIRE ( Griffin est al., 10 ) that reveal for the first time the presence of cold dust emission at temperatures as low as T = 20 K in two nearby ultraluminous infrared galaxies ( ULIRGs ), Arp220 and Mrk 231.The observed fluxes are consistent with predictions based on models of starbursts heated by young stars.We find evidence for an additional component of cooler dust which is probable to be associated with the obscured AGN activity present in these objects.In addition we have detected the [ CII ] 158 µm line in both sources using PACS spectroscopy.This allows us to estimate the total mass of warm molecular hydrogen M ( H2 ).For Arp 220 this amounts to 1. 5 x 10 ^ nine solar masses within a radius of 100 pc around the nucleus."
    },
    {
        "original_text": "We present new photometric and spectroscopic observations for two stars, HD 122563 (=HR 5171A) and BD+17°3248, which are suspected to be members of the proposed intermediate age population of helium-rich giants in the globular cluster Omega Cen.  We find that both stars have very similar atmospheric parameters as those found by previous studies for other candidate helium-rich giant candidates in Omega Cen: T eff = 8200 K; log g = 3.8; [Fe/H] = -1.0 dex. The observed spectra show no evidence for He II lines at 4686 Å or 5412 Å, but do exhibit strong Balmer line emission with equivalent widths ranging between -40 and -50 mÅ. These results suggest that these stars may not actually belong to this proposed class of objects. However, we cannot rule out the possibility that they are indeed helium-rich giants on the basis of our current data set alone.",
        "watermark_text": "We present fresh photometric and spectroscopic measurements for two stars, HD 122563 ( = HR 5171A ) and BD + 17°3248, which are suspected to be members of the proposed intermediate age population of helium - rich giants in the globular cluster Omega Cen.We find that both stars have very similar atmospheric parameters as those found by previous research for other candidate helium - rich giant stars in Omega Cen : T eff = 8200 K ; log g = 3. 8 ; [ Fe / H ] = - 1. 0 dex.The observed spectra show no evidence for He II lines at 4686 Å or 5412 Å, but do exhibit strong Balmer line emission with equivalent widths ranging between - 40 and - 50 mÅ.These results suggest that these stars might not actually belong to this proposed class of objects.However, we cannot rule out the possibility that they are indeed helium - rich giants on the basis of our present data set alone."
    },
    {
        "original_text": "We present new rest-UV spectra for four Lyman break galaxies (LBGs) with redshifts between 5 and 6, obtained using the Ultraviolet Echelle Spectrograph on board the Hubble Space Telescope.  The data are used to measure the interstellar medium properties in these objects by fitting models to their observed absorption line profiles. We find that all four LBGs have high metallicities ranging from 0.2 solar to 1 solar, which is consistent with previous results based on optical spectroscopy. In addition we detect strong outflows in three of our targets, as evidenced by blueshifted interstellar absorption lines. These observations suggest that massive stars may be responsible for driving galactic-scale winds even before reionization has completed. This work was supported by NASA grant HST-GO-10775.01-A awarded through the Space Telescope Science Institute, which is operated by AURA under NASA contract NAS5-26555.",
        "watermark_text": "We present new rest - UV spectra for four Lyman break galaxies ( LBGs ) with redshifts between 5 and six, obtained using the Ultraviolet Echelle Spectrograph on board the Hubble Space Telescope.The data are used to measure the interstellar medium characteristics in these objects by fitting models to their observed absorbing line profiles.We find that all four LBGs have high metallicities ranging from zero. 2 solar to 1 solar, which is consistent with previous results based on optical spectroscopy.In addition we detect strong outflows in three of our targets, as evidenced by blueshifted interstellar absorbed lines.These observations suggest that massive stars may be responsible for driving galactic - scale winds already before reionization has completed.This work was supported by NASA grant HST - GO - 10775. 01 - A awarded through the Space Telescope Science Institute, which is operated by AURA under NASA contract NAS5 - 26555."
    },
    {
        "original_text": "We present the results of an analysis of deep Chandra X-ray Observatory observations of two high redshift galaxies, MS1512-cB58 and APM 08279+5255 (z = 3.91). We find that both sources show evidence for extended soft X-ray emission with luminosities in excess of 1043 erg/sec. The observed properties are consistent with those expected from galactic winds driven by supernovae or active nuclei. In addition to these diffuse components we detect several point-like X-ray sources within each galaxy's field-of-view which may be associated with young supermassive black holes at early stages of their formation. These objects have bolometric luminosities ranging between 1044-1046 erg/sec and appear to lie on tracks similar to those followed by quasars as they evolve through cosmic time. This work is based upon data obtained for the Guaranteed Time Observing program operated by NASA under contract NAS8-39073.",
        "watermark_text": "We present the results of an analysis of deep Chandra X - ray Observatory observations of two high redshift galaxies, MS1512 - cB58 and APM 08279 + 5255 ( z = 3. 91 ).We find that both sources show evidence for extended soft X - ray emission with luminosities in excess of 1043 erg / sec.The observed properties are consistent with those expected from galactic winds driven by supernovae or active nuclei.In addition to these diffuse components we detect several point - like X - ray sources within each galaxy ' s field - of - view which may be involved with young supermassive black holes at early stages of their formation.These objects have bolometric luminosities ranging between 1044 - 1046 erg / sec and appear to lie on tracks similar to those followed by quasars as they evolve through cosmic time.This work is based upon data obtained for the Guaranteed Time Observing program operated by NASA under contractor NAS8 - 39073."
    },
    {
        "original_text": "Erbium-doped fiber amplifiers (EDFAs) are widely used in the field of telecommunication and sensing applications due to their high gain, low noise figure, wide bandwidths and compatibility with silica fibers. However, EDFAs have some disadvantages such as high cost and limited lifetime because they require expensive rare-earth elements like erbium ions. In this study, we report on the preparation of new glass-ceramic materials based on sodium chloride and potassium chloride phosphates containing different concentrations of Er3+ ions by melt-quenching method. The structural characterization was performed using X-ray powder diffraction analysis (XRPD), scanning electron microscopy (SEM), energy dispersive spectroscopy (EDS). Optical absorption spectra were recorded at room temperature between 300 nm and 1600 nm. Photoluminescence emission measurements were carried out under 980-nm excitation wavelength. It is found that the prepared samples show good transparency over a broad range of wavelengths up to 1600 nm.",
        "watermark_text": "Erbium - doped fiber amplifiers ( EDFAs ) are widely used in the field of telecommunication and sensor applications due to their good gain, low noise figure, wide bandwidths and compatibility with silica fibers.However, EDFAs have some disadvantages such as high cost and limited lifetime because they require costly rare - earth elements like erbium ions.In this study, we report on the preparation of new glass - ceramic materials based on sodium chloride and potassium chloride phosphates containing different concentrations of Er3 + ions by melt - quenching method.The structural characterization was performed using X - ray powder diffraction analysis ( XRPD ), scanning electron microscopy ( SEM ), energetic dispersive spectroscopy ( EDS ).Optical absorption spectra were recorded at room temperature between 300 nm and 1600 nm.Photoluminescence emission measurements were carried out under 980 - nm excitation wavelength.It is found that the prepared specimens show good transparency over a broad range of wavelengths up to 1600 nm."
    },
    {
        "original_text": "We present the first detection of absorption lines in the rest-frame ultraviolet spectrum of two galaxies at redshifts z = 2.3 and 3.1, which are likely to be associated with outflows driven by star formation activity. The observed properties of these winds are consistent with those predicted for massive (M > 1010 M⊙) star-forming galaxies at similar redshifts. We also find evidence that the gas is being accelerated up to velocities as large as 1000 km s-1 . These results suggest that such winds may play an important role in regulating galaxy evolution over cosmic time.  Keywords: Galaxy Evolution; Star Formation; Winds Galaxies evolve through mergers and interactions between their constituent dark matter halos and baryonic components. In addition, they grow via accretion onto existing structures or by forming new stars within them. However, it remains unclear how this growth proceeds on small scales. Recent observations have shown that many nearby galaxies contain supermassive black holes surrounded by dense gaseous disks. It has been suggested that feedback processes involving jets and/or winds produced by active galactic nuclei can regulate both the growth of the central black hole and its host galaxy. This process could explain why most galaxies do not appear to harbour supermassive black holes whose masses exceed the upper limit set by the relation between black-hole mass and bulge velocity dispersion.",
        "watermark_text": "We present the initial detection of absorption lines in the rest - frame ultraviolet spectrum of two galaxies at redshifts z = 2. 3 and 3. 1, which are likely to be associated with outflows driven by star formation activity.The observed properties of these winds are consistent with those forecast for massive ( M > 1010 [UNK] ) star - forming galaxies at similar redshifts.We also find evidence that the gas is being accelerated up to velocities as large as 1000 kilometres s - 1.These results suggest that such winds may play an important role in regulating galaxy evolution over cosmic period.Keywords : Galaxy Evolution ; Star Formation ; Winds Galaxies evolve through mergers and interactions between their constituent dark matter halos and baryonic components.In addition, they grow via accretion onto existing structures or by forming new stars within them.However, it remains unclear how this growth proceeds on small scales.Recent observations have shown that many nearby galaxies contain supermassive tone holes surrounded by dense gaseous discs.It has been suggested that feedback processes involving jets and / or winds produced by active galactic nuclei can regulate both the growth of the central pale hole and its host galaxy.This process could explain why most galaxies do not appear to harbour supermassive black holes whose masses exceed the upper limit established by the relationship between black - hole mass and bulge velocity dispersion."
    },
    {
        "original_text": "We present observations of the Mg II k line asymmetry during flares, which are compared with results obtained by numerical simulations using the RH code (Uitenbroek 2001). The observed profiles show that the blue wing is enhanced relative to the red one at all heights above the limb where we can see the flare emission. This effect is more pronounced for higher altitudes. We find that this behavior cannot be explained solely by Doppler shifts due to bulk plasma motions along the LOS. In addition, our modeling shows that the observed profile shapes cannot be reproduced without including nonthermal electron beams as an additional heating source. \n \n Keywords: Solar flare, chromospheric lines, nonthermal electrons, radiative hydrodynamics model, RH code, Mg II k line, line asymmetry. 1 Introduction \n \n During solar flares, intense energy release leads to rapid changes in physical conditions throughout the atmosphere of the Sun. These include temperature increases up to several million degrees Kelvin, strong magnetic fields, high densities, and large velocities. All these factors affect the shape of spectral lines emitted by different atmospheric layers. For example, it has been shown that the intensity ratio between two Fe I lines formed at different temperatures depends on the height of formation of each line (Feldman et al., 1995; Brosius & Phillips 2004) . Also, the presence of nonthermal electrons causes significant deviations from Maxwellian velocity distributions leading to asymmetric line profiles (e.g., Canfield et al. (1990) ; Doschek et al. (1991) ), while bulk flows lead to Doppler shifts of the line center position (Doschek et al., 1991; Brosius & Phillips 2004; Brosius 2009 ). Therefore, studying the temporal evolution of the line profiles provides important information about the dynamics of the flaring region. However, interpreting such data requires detailed knowledge of the underlying physics involved in the processes responsible for the observed phenomena. \n \n In particular, the study of the Mg II h&k lines offers unique opportunities to investigate various aspects of solar flares because they form over a wide range",
        "watermark_text": "We present observations of the Mg II k line asymmetry during flares, which are compared with results obtained by numerical simulations using the RH code ( Uitenbroek 2001 ).The observed profiles show that the blue wing is augmented relative to the red wing at all heights above the limb where we can see the flicker emission.This effect is more pronounced for upper altitudes.We find that this behavior cannot be explained solely by Doppler changes due to bulk plasma motions along the LOS.In addition, our modeling shows that the observed profile shapes neither be reproduced without including nonthermal electron beams as an additional heating source.Keywords : Solar flare, chromospheric lines, nonthermal electrons, radiative hydrodynamics model, RH code, Mg II k line, line asymmetry.1 Introduction During solar flares, intense energy release leads to rapid changes in physical conditions across the atmosphere of the Solar.These include temperature increases up to several million degrees Kelvin, strong magnetic fields, high densities, and big velocities.All these factors affect the shape of spectral lines emission by different atmospheric layers.For example, it has been shown that the intensity ratio between 2 Fe I lines formed at different temperatures depends on the height of formation of each line ( Feldman et al., 1995 ; Brosius & Philips 2004 ).Also, the presence of nonthermal electrons causes significant deviations from Maxwellian velocity distributions leading to asymmetric line profiles ( e. g., Canfield et al. ( 1990 ) ; Doschek et gal. ( 1991 ) ), while bulk flows lead to Doppler shifts of the line center position ( Doschek et al., 1991 ; Brosius & Phillips 2004 ; Brosius 2009 ).Therefore, studying the temporal evolution of the line profiles provides important information about the dynamics of the flaring area.However, interpreting such data requires detailed awareness of the underlying physics involved in the methods responsible for the observed phenomena.In particular, the study of the Mg II h & k lines offers unique opportunities to investigate various aspects of solar flares because they form over a wide range"
    },
    {
        "original_text": "We report on the absorption spectrum of an isolated single-wall carbon nanotube (SWNT) in solution, obtained by using a scanning near-field optical microscope with subwavelength resolution. The SWNTs are suspended between two gold electrodes and illuminated through one electrode at normal incidence to excite both transverse electric (TE) and transverse magnetic (TM) polarized light. We observe that the TE mode is strongly suppressed compared to TM polarization due to the presence of metallic tubes within our sample. This effect can be used as a spectroscopic tool for identifying the chirality of individual SWNTs. \n \n Single-wall carbon nanotubes have attracted considerable interest because they exhibit unique electronic properties which depend sensitively on their diameter and chiral angle [1] . In particular, it has been shown theoretically [2] , experimentally [3] , and numerically [4] that the energy gap depends on these parameters such that semiconducting tubes have small gaps while metallic tubes have large ones. However, this dependence is not sufficient to uniquely identify all possible tube types [5] .\n \nIn order to determine the type of each tube individually, several experimental techniques have been developed [6] - [8] . For example, Raman scattering [9] or photoluminescence [10] measurements allow one to distinguish between metallic and semiconducting tubes based on the intensity ratio of certain peaks [11] . Alternatively, electrical transport experiments [12] provide information about the charge carrier density and mobility [13] . Finally, transmission electron microscopy [14] allows one to directly visualize the structure of the tubes [15] . \n \n Here we present another method for determining the chirality of individual carbon nanotubes. Our approach relies on measuring the absorption cross section of individual SWNTs [16] . Since the absorption cross-section depends on the dielectric function [17] , which in turn varies significantly depending on whether the tube is metallic or semiconducting [18] , we expect different values for the absorption cross sections of metallic versus semiconducting tubes. By comparing the measured absorption cross sections of various tubes, we will show how this technique can be used to classify them into either metallic or semiconducting categories. \nExperimental setup\n\nThe samples were prepared following the",
        "watermark_text": "We report on the absorption spectrum of an individual single - wall carbon nanotube ( SWNT ) in solution, obtained by using a scanning near - field optical microscope with subwavelength resolution.The SWNTs are suspended between 2 gold electrodes and illuminated through 1 electrode at usual incidence to excite both transverse electric ( TE ) and trans magnetic ( TM ) polarized light.We observe that the TE mode is strongly suppressed compared to TM polarization due to the existence of metallic tubes within our specimen.This effect can be used as a spectroscopic tool for identifying the chirality of individual SWNTs.Single - wall carbon nanotubes have attracted considerable interest because they exhibit unique electronic properties which depend sensitively on their diameter and chiral angle[ 1 ].In particular, it has been shown theoretically [ 2 ], experimentally[ 3 ], and numerically[ 4 ] that the energy gap depends on these parameters such that semiconducting tubes have small gaps while metallic tubes have large ones.However, this dependence is not enough to uniquely identify all possible tube types [ 5 ].In order to determine the type of each tube individually, several experimental techniques have been developed [ 6 ] - [ 8 ].For example, Raman scattering [ 9 ] or photoluminescence [ 10 ] measurements allow one to distinguish between metallic and semiconducting tubes based on the intensity ratio of particular peaks [ 11 ].Alternatively, electrical transport experiments [ 12 ] provide information about the charge carrying density and mobility [ 13 ].Finally, transmission electron microscopy[ 14 ] allows one to direct visualize the structure of the tubes [ 15 ].Here we present another method for determining the chirality of individual carbon nanotubes.Our approach relies on measuring the absorption cross section of individual SWNTs[ 16 ].Since the absorption cross - section depends on the dielectric function[ 17 ], which in turn varies significantly depending on whether the tube is metallic or semiconducting [ 18 ], we expect different values for the absorbing cross sections of metallic vs semiconducting tubes.By comparing the measured absorption cross sections of various tubes, we will show how this technique can be used to classify them into whether metallic or semiconducting categories.Experimental setup The samples were prepared following the"
    }
]