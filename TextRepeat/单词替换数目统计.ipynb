{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watermark_REPEAT_NO_CONTEXT_BERT import watermark_model as repeat_no_context_model\n",
    "model = repeat_no_context_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:03<00:00, 261.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2604 / 800 => 3.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = 'nlp'\n",
    "file_name = f'text-quality/{model_name}/HC3/HC3.json'\n",
    "\n",
    "def preprocess_txt(original_text):\n",
    "    original_text = original_text.replace(\"\\\\n\", \" \")\n",
    "    original_text = original_text.replace('''\"''', \" \")\n",
    "    original_text = original_text.replace(\"'\", \" \")\n",
    "    original_text = original_text.replace(\"[\", \" \")\n",
    "    original_text = original_text.replace(\"]\", \" \")\n",
    "    original_text = original_text.replace(\",\", \" \")\n",
    "    original_text = original_text.replace(\".\", \" \")\n",
    "    # original_text = original_text.replace(r\"\\s+\", \" \")\n",
    "    return original_text\n",
    "\n",
    "def get_discharge(original_text, watermark_text):\n",
    "    original_words = model.tokenizer.tokenize(preprocess_txt(original_text))\n",
    "    watermark_words = model.tokenizer.tokenize(preprocess_txt(watermark_text))\n",
    "    discharge = abs(len(original_words) - len(watermark_words))\n",
    "    max_length = 0\n",
    "    if len(original_words) > len(watermark_words):\n",
    "        max_length = len(watermark_words)\n",
    "    else:\n",
    "        max_length = len(original_words)\n",
    "    for index in range(max_length):\n",
    "        if original_words[index] != watermark_words[index]:\n",
    "            discharge += 1\n",
    "    return discharge\n",
    "\n",
    "dataset = json.load(open(file_name))\n",
    "discharge = 0\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    data = dataset[i]\n",
    "    original_text = data['original_text']\n",
    "    watermark_text = data['watermark_text']\n",
    "    discharge += get_discharge(original_text, watermark_text)\n",
    "average_discharge = discharge / len(dataset)\n",
    "\n",
    "print(f'{discharge} / {len(dataset)} => {discharge / len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:03<00:00, 202.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "bloomz\n",
      "21724 / 800 => 27.155\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:04<00:00, 199.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "chatGPT\n",
      "20939 / 800 => 26.17375\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:04<00:00, 199.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "cohere\n",
      "19439 / 800 => 24.29875\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:04<00:00, 195.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "davinci\n",
      "19830 / 800 => 24.7875\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:04<00:00, 172.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "dolly\n",
      "20035 / 800 => 25.04375\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:03<00:00, 203.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "flant5\n",
      "18002 / 800 => 22.5025\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = 'ContextLS'\n",
    "dataset_name = ['bloomz', 'chatGPT', 'cohere', 'davinci', 'dolly', 'flant5']\n",
    "\n",
    "def preprocess_txt(original_text):\n",
    "    original_text = original_text.replace(\"\\\\n\", \" \")\n",
    "    original_text = original_text.replace('''\"''', \" \")\n",
    "    original_text = original_text.replace(\"'\", \" \")\n",
    "    original_text = original_text.replace(\"[\", \" \")\n",
    "    original_text = original_text.replace(\"]\", \" \")\n",
    "    original_text = original_text.replace(\",\", \" \")\n",
    "    original_text = original_text.replace(\".\", \" \")\n",
    "    # original_text = original_text.replace(r\"\\s+\", \" \")\n",
    "    return original_text\n",
    "\n",
    "def get_discharge(original_text, watermark_text):\n",
    "    original_words = model.tokenizer.tokenize(preprocess_txt(original_text))\n",
    "    watermark_words = model.tokenizer.tokenize(preprocess_txt(watermark_text))\n",
    "    discharge = abs(len(original_words) - len(watermark_words))\n",
    "    max_length = 0\n",
    "    if len(original_words) > len(watermark_words):\n",
    "        max_length = len(watermark_words)\n",
    "    else:\n",
    "        max_length = len(original_words)\n",
    "    for index in range(max_length):\n",
    "        if original_words[index] != watermark_words[index]:\n",
    "            discharge += 1\n",
    "    return discharge\n",
    "\n",
    "for name in dataset_name:\n",
    "    file_name = f'text-quality/{model_name}/M4/{name}.json'\n",
    "    dataset = json.load(open(file_name))\n",
    "    discharge = 0\n",
    "\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        data = dataset[i]\n",
    "        original_text = data['original_text']\n",
    "        watermark_text = data['watermark_text']\n",
    "        discharge += get_discharge(original_text, watermark_text)\n",
    "    average_discharge = discharge / len(dataset)\n",
    "\n",
    "    print(f'==========\\n{name}\\n{discharge} / {len(dataset)} => {discharge / len(dataset)}\\n==========')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
